<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>mit_all</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h1 id="mit">MIT</h1>
<h2 id="alj---8">ALJ - 8</h2>
<ul>
<li><details>
<summary>
(2025). Survival and evolutionary adaptation of populations under
disruptive habitat change: A study with darwinian cellular automata.
<em>ALJ</em>, <em>31</em>(1), 106–123. (<a
href="https://doi.org/10.1162/artl_a_00457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of living beings with continuous and consistent progress toward adaptation and ways to model evolution along principles as close as possible to Darwin’s are important areas of focus in Artificial Life. Though genetic algorithms and evolutionary strategies are good methods for modeling selection, crossover, and mutation, biological systems are undeniably spatially distributed processes in which living organisms interact with locally available individuals rather than with the entire population at once. This work presents a model for the survival of organisms during a change in the environment to a less favorable one, putting them at risk of extinction, such as many organisms experience today under climate change or local habitat loss or fragmentation. Local spatial structure of resources and environmental quality also impacts the capacity of an evolving population to adapt. The problem is considered on a probabilistic cellular automaton with update rules based on the principles of genetic algorithms. To carry out simulations according to the described model, the Darwinian cellular automata are introduced, and the software has been designed with the code available open source. An experimental evaluation of the behavioral characteristics of the model was carried out, completed by a critical evaluation of the results obtained, parametrically describing conditions and thresholds under which extinction or survival of the population may occur.},
  archive      = {J_ALJ},
  author       = {Derets, Hanna and Nehaniv, Chrystopher L.},
  doi          = {10.1162/artl_a_00457},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {106-123},
  shortjournal = {Artif. Life},
  title        = {Survival and evolutionary adaptation of populations under disruptive habitat change: A study with darwinian cellular automata},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergence of self-replicating hierarchical structures in a
binary cellular automaton. <em>ALJ</em>, <em>31</em>(1), 96–105. (<a
href="https://doi.org/10.1162/artl_a_00449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have discovered a novel transition rule for binary cellular automata (CAs) that yields self-replicating structures across two spatial and temporal scales from sparse random initial conditions. Lower-level, shape-shifting clusters frequently follow a transient attractor trajectory, generating new clusters, some of which periodically self-duplicate. When the initial distribution of live cells is sufficiently sparse, these clusters coalesce into larger formations that also self-replicate. These formations may further form the boundaries of an expanding complex on an even larger scale. This rule, dubbed “Outlier,” is rotationally symmetric and applies to 2-D Moore neighborhoods. It was evolved through genetic programming during an extensive search for rules that foster open-ended evolution in CAs. While self-replicating structures, both crafted and emergent, have been created in CAs with state sets intentionally designed for this purpose, the Outlier may be the first known rule to facilitate nontrivial emergent self-replication across two spatial scales in binary CAs.},
  archive      = {J_ALJ},
  author       = {Yang, Bo},
  doi          = {10.1162/artl_a_00449},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {96-105},
  shortjournal = {Artif. Life},
  title        = {Emergence of self-replicating hierarchical structures in a binary cellular automaton},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-reproduction and evolution in cellular automata: 25
years after evoloops. <em>ALJ</em>, <em>31</em>(1), 81–95. (<a
href="https://doi.org/10.1162/artl_a_00451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The year 2024 marks the 25th anniversary of the publication of evoloops, an evolutionary variant of Chris Langton’s self-reproducing loops, which proved constructively that Darwinian evolution of self-reproducing organisms by variation and natural selection is possible within deterministic cellular automata. Over the last few decades, this line of Artificial Life research has since undergone several important developments. Although it experienced a relative dormancy of activity for a while, the recent rise of interest in open-ended evolution and the success of continuous cellular automata models have brought researchers’ attention back to how to make spatiotemporal patterns self-reproduce and evolve within spatially distributed computational media. This article provides a review of the relevant literature on this topic over the past 25 years and highlights the major accomplishments made so far, the challenges being faced, and promising future research directions.},
  archive      = {J_ALJ},
  author       = {Sayama, Hiroki and Nehaniv, Chrystopher L.},
  doi          = {10.1162/artl_a_00451},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {81-95},
  shortjournal = {Artif. Life},
  title        = {Self-reproduction and evolution in cellular automata: 25 years after evoloops},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cell–cell interactions: How coupled boolean networks tend to
criticality. <em>ALJ</em>, <em>31</em>(1), 68–80. (<a
href="https://doi.org/10.1162/artl_a_00444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological cells are usually operating in conditions characterized by intercellular signaling and interaction, which are supposed to strongly influence individual cell dynamics. In this work, we study the dynamics of interacting random Boolean networks, focusing on attractor properties and response to perturbations. We observe that the properties of isolated critical Boolean networks are substantially maintained also in interaction settings, while interactions bias the dynamics of chaotic and ordered networks toward that of critical cells. The increase in attractors observed in multicellular scenarios, compared to single cells, allows us to hypothesize that biological processes, such as ontogeny and cell differentiation, leverage interactions to modulate individual and collective cell responses.},
  archive      = {J_ALJ},
  author       = {Braccini, Michele and Baldini, Paolo and Roli, Andrea},
  doi          = {10.1162/artl_a_00444},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {68-80},
  shortjournal = {Artif. Life},
  title        = {Cell–Cell interactions: How coupled boolean networks tend to criticality},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Special issue “the distributed ghost”—cellular
automata, distributed dynamical systems, and their applications to
intelligence. <em>ALJ</em>, <em>31</em>(1), 65–67. (<a
href="https://doi.org/10.1162/artl_e_00450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed dynamical systems like cellular automata (CAs) and random boolean networks (RBNs) (and everything in between) have long been used as models to understand computation and self-replication in biology, morphogenesis, gene regulation, life-as-it-could-be, and the Universe.Such complex system models have been extensively studied mathematically and experimentally in all their different variations, such as synchronous and asynchronous updates and dynamic automata networks that can grow and change their structure, including components and interconnection topology, as well as their robustness.Wuensche (1994) investigated the basins of attraction of CAs and RBNs and even suggested that they are the “ghost in the machine.”Recent advances in such models, including continuous CAs, such as Lenia (Chan, 2019), and neural-based CAs (Mordvintsev et al., 2020), have been proposed as substrates to study the emergence of a more general intelligence (Gregor &amp;amp; Besse, 2021; Hamon et al., 2022), thanks to their propensity to support properties like self-organization, emergence, and open-endedness.But what can we learn from CAs and distributed dynamical system models about intelligence? And how can CAs and distributed dynamical system models be used to study the emergence of intelligence?To address such questions, we organized a workshop at the 2023 Artificial Life conference in Sapporo, Japan, that aimed to bridge the gap between the ALife community working with CAs and distributed dynamical systems and the broader artificial intelligence (AI) community interested in exploring concepts from complex systems, self-organization, and Artificial Life for AI research and machine learning.The workshop was named “The Distributed Ghost,” inspired by the Artificial Life conference theme “Ghost in the Machine.” The workshop program (Nichele et al., 2023) consisted of two invited keynotes, by Bert Chan and Andrea Roli, and a set of 10 abstract-based presentations. After the workshop, four high-quality contributions were extended as full papers and have been collected in this special issue.In “Cell-Cell Interactions: How Coupled Boolean Networks Tend to Criticality,” Braccini and coauthors investigate interacting RBNs as a theoretical model of multicellular biological systems with cell–cell interactions. They find not only that the interacting versions of RBNs show the same general trends of dynamical properties as their individual counterparts but also that the networks in ordered or chaotic regimes tend toward a critical regime when turned into interacting networks (while individually critical networks remain critical). This result suggests the importance of the interconnected nature of a distributed multicellular system for its system-level criticality (and thus biological functioning) as a whole.In “Emergence of Self-Replicating Hierarchical Structures in a Binary Cellular Automaton,” using genetic programming to explore the vast space of binary CAs (with Moore neighborhood and rotationally symmetric rule sets in two dimensions) for open-ended temporal evolution, Yang reports on the discovery of a novel CA rule, the “Outlier.” Most strikingly, this CA and therefore also its distinct chiral twin (obtained by mirroring the rule table) are unique among known models of self-replication in that structures exhibit replication across two different nested spatiotemporal scales. Moreover, the self-replicating structures appear from sparse random initial conditions and follow characteristic attractor trajectories involving such multiscale self-replication.In “Survival and Evolutionary Adaptation of Populations Under Disruptive Habitat Change: A Study With Darwinian Cellular Automata,” Derets and Nehaniv focus on the evolution of living beings, emphasizing continuous adaptation akin to Darwinian principles within the domain of Artificial Life. The introduced model addresses the survival of organisms amid environmental changes, particularly during transitions to less favorable conditions (modeled using percolation theory). A probabilistic CA is employed based on update rules derived from genetic algorithm principles. Finally, an experimental investigation of the model’s behavioral features is presented, analyzing parameters and thresholds governing population survival or extinction outcomes.In “Self-Reproduction and Evolution in Cellular Automata: 25 Years After Evoloops,” Sayama and Nehaniv offer a comprehensive review of advancements in CAs subjected to Darwinian evolution. The contribution marks the 25th anniversary of the seminal work on evoloops (Sayama, 1999). The review highlights significant developments, ongoing challenges, and prospective research avenues in Artificial Life, focusing on self-reproducing and evolving patterns in distributed computational environments.We are continuing the tradition of the “distributed series” in 2024 by organizing a special session named “The Distributed Viking” at the Artificial Life conference in Copenhagen, Denmark. More information can be found at the special session web page (https://www.nichele.eu/ALIFE-DistributedViking/).},
  archive      = {J_ALJ},
  author       = {Nichele, Stefano and Sayama, Hiroki and Medvet, Eric and Nehaniv, Chrystopher and Pavone, Mario},
  doi          = {10.1162/artl_e_00450},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {65-67},
  shortjournal = {Artif. Life},
  title        = {Editorial: Special issue “The distributed Ghost”—Cellular automata, distributed dynamical systems, and their applications to intelligence},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guideless artificial life model for reproduction,
development, and interactions. <em>ALJ</em>, <em>31</em>(1), 31–64. (<a
href="https://doi.org/10.1162/artl_a_00466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reproduction, development, and individual interactions are vital yet complex natural processes. Tierra (an ALife model proposed by Thomas Ray) and cellular automata, which can manage these aspects in a complex manner, are significantly limited in their ability to express morphology and behavior. In contrast, the virtual creatures proposed by Karl Sims have a considerably higher degree of freedom in terms of morphology and behavior. However, they also exhibit a limited capacity for processes like reproduction, development, and individual interactions. In addition, they employ genetic algorithms, which can result in a loss of biological diversity, as their implementation necessitates predefining a fitness function. Contrarily, the evolution of natural life is determined by mutation and natural selection, rather than by a human-defined fitness function. This study carefully extracts the characteristics of these models to propose a new Artificial Life model that can simulate reproduction, development, and individual interactions while exhibiting a high expressive power for morphology and behavior. The model is based on the concept of incorporating Tierra and cellular automata mechanisms into a cell that moves freely in 3-D space. In this model, no predefined fitness function or form that qualifies as a living creature exists. In other words, this approach can be rephrased as searching for persistent patterns, which is similar to the approach of Conway’s Game of Life. The primary objective of this study was to conduct a proof-of-concept demonstration to showcase the capabilities of this model. Guideless simulation by the proposed model using mutation and natural selection resulted in the formation of two types of creatures—dumbbell shaped and reticulated. These creatures exhibit intriguing features, exploiting the degrees of freedom inherent to the proposed model. Particularly noteworthy is their unique method of reproduction, which bears a striking resemblance to that of real organisms. These results reinforce the potential of this approach in modeling intricate processes observed in actual organisms and its ability to generate virtual creatures with intriguing ecologies.},
  archive      = {J_ALJ},
  author       = {Utimula, Keishu},
  doi          = {10.1162/artl_a_00466},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {31-64},
  shortjournal = {Artif. Life},
  title        = {Guideless artificial life model for reproduction, development, and interactions},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling the mutation and competition of certain
nutrient-producing protocells by means of specific turing machines.
<em>ALJ</em>, <em>31</em>(1), 2–30. (<a
href="https://doi.org/10.1162/artl_a_00463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is very important to model the behavior of protocells as basic lifelike artificial organisms more and more accurately from the level of genomes to the level of populations. A better understanding of basic protocell communities may help us in describing more complex ecological systems accurately. In this article, we propose a new comprehensive, bilevel mathematical model of a community of three protocell species (one generalist and two specialists ). The aim is to achieve a model that is as basic/fundamental as possible while already displaying mutation, selection, and complex population dynamics phenomena (like competitive exclusion and keystone species). At the microlevel of genetic codes, the protocells and their mutations are modeled with Turing machines (TMs). The specialists arise from the generalist by means of mutation. Then the species are put into a common habitat, where, at the macrolevel of populations, they have to compete for the available nutrients, a part of which they themselves can produce. Because of different kinds of mutations, the running times of the species as TMs (algorithms) are different. This feature is passed on to the macrolevel as different reproduction times. At the macrolevel, a discrete-time dynamic model describes the competition. The model displays complex lifelike behavior known from population ecology, including the so-called competitive exclusion principle and the effect of keystone species. In future works, the bilevel model will have a good chance of serving as a simple and useful tool for studying more lifelike phenomena (like evolution) in their pure/abstract form.},
  archive      = {J_ALJ},
  author       = {Kicsiny, Richárd and Hufnagel, Levente and Lóczi, Lajos and Székely, László and Varga, Zoltán},
  doi          = {10.1162/artl_a_00463},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {2-30},
  shortjournal = {Artif. Life},
  title        = {Modeling the mutation and competition of certain nutrient-producing protocells by means of specific turing machines},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A word from the editors. <em>ALJ</em>, <em>31</em>(1), 1.
(<a href="https://doi.org/10.1162/artl_e_00469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This issue comprises two parts.A series of articles form a special issue on “The Distributed Ghost,” an outcome of a workshop held at the 2023 Artificial Life conference in Sapporo, Japan. This has been compiled by editors Stefano Nichele, Hiroki Sayama, Eric Medvet, Chrystopher Nehaniv, and Mario Pavone. Two preceding standard research articles neatly align with the special issue in that they also consider the dynamics of interacting biological systems using traditional computational approaches (cellular automata, Tierra-like assembly languages, feed-forward neural networks, and Turing machines) for modeling activities, from a behavioral rather than an intelligential perspective. Tackling central themes of ALife, they study the emergence of persistent morphologies and the behaviors of mutant specialists and generalists competing for resources in a well-mixed environment. These articles demonstrate two approaches to investigating attributes of interacting populations of simple computational, protocellular creatures.},
  archive      = {J_ALJ},
  author       = {Dorin, Alan and Stepney, Susan},
  doi          = {10.1162/artl_e_00469},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {1},
  shortjournal = {Artif. Life},
  title        = {A word from the editors},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="coli---9">COLI - 9</h2>
<ul>
<li><details>
<summary>
(2025). Automatic language identification in texts. <em>COLI</em>,
<em>51</em>(1), 339–341. (<a
href="https://doi.org/10.1162/coli_r_00521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language identification (LI) for text data, in the ideal scenario, determines the human languages used at every location in a corpus. In practice this often means choosing the likeliest language at the document level: This is already quite useful, for example, when presenting a webpage to the user and deciding (a) whether to translate it and (b) which model to use for that purpose. However, nuances like code-switching (language alternation), dialect variation, and ambiguously short content are increasingly common with the ubiquity of digital communication like text messaging and micro-blogs. Geographic areas like Africa and the Indian subcontinent bring enormous linguistic diversity and flexibility that break the document-level LI paradigm. While standard references (Jurafsky and Martin 2023) introduce LI, touch on these subtleties, and often present related methods and models in other contexts, Automatic Language Identification in Texts is specifically dedicated to LI in its full practical variety.In the course of producing a broad and thorough survey, perhaps the most striking takeaway from Jauhiainen et al. is the chaotic state of research on this critical task. This might be due to the view that, for digitally well-attested languages occurring in domains with monolingual documents of at least modest length, LI is solved: These circumstances are common, and the emphasis on massive data sets can make the rarer cases seem less important. When challenges arise in specific, applied downstream research, they are often addressed in an ad hoc fashion, such as through active learning techniques for gathering human annotations or linear programming to incorporate prior knowledge (Lippincott and Van Durme 2016), without consolidation into broader outcomes for the research community. Throughout Automatic Language Identification in Texts, the authors have the consistent goal of improving this situation. The book is structured into six chapters:Chapter 1 introduces the history of LI, stretching from early feature-engineering approaches to still-standard models based on character n-grams closely related to fundamental models of communication (Shannon 1948), and the burgeoning collection of shared tasks aimed at specific domains, such as ancient scripts or regional dialects. Unlike much of machine learning for natural language processing tasks, traditional models have remained highly competitive for LI compared with deep neural networks: perhaps data sparsity prevents effective training, or traditional features are already well-suited for LI. Downstream use-cases and challenges are summarized, with copious citations to prior and ongoing work.Chapter 2 begins with the authors’ efforts to standardize the discourse around LI by specifying a common notation that subsumes the variety utilized in the literature. While the notation is a modest shift from those that treat data as a sequence of fully distinct documents, treating documents as boundaries within a single large sequence of characters consolidates the spectrum of methods that will be covered. In terms of linguistic features, the focus is on character n-grams, and the authors address several standard concerns: weighting, smoothing, and incorporating linguistic knowledge. The latter is particularly interesting and perhaps under-explored, since there is often less practical motivation to move beyond the immediate use-case and consider, for example, the phylogenetic structure of world languages. The bulk of the chapter is devoted to describing a wide range of classification methods that use these features, some standard (e.g., logistic regression, naive Bayes), others the specific ensembles or statistical tests adopted by existing research.Chapter 3 addresses evaluation, the other end of the experimental pipeline that requires standardization. While a handful of metrics have been used historically, most research has converged on macro balanced F-score, which equally weights precision and recall as well as performance on each language. In the absence of a clearly articulated reason to do otherwise, this is the most even-handed approach. The bulk of the chapter is devoted to a survey of standard data sets and shared tasks, both historical and ongoing. This is a useful reference for researchers in search of venues aimed at their specific goals, or looking for broader patterns in outcomes.Chapter 4 considers the primary axes that may elevate LI from “solved” to “challenging”: language similarity, low-resource languages, orthographic systems and variation, short text, and code-switching. Some of these involve questions of representation: What do we treat as a “language”? What is the “correct” label of a short text that’s valid in multiple languages, such as “quando?”, which is a common question in Portuguese and Italian? How should one label a text containing multiple languages, such as “I’ll ask mi hombre next time I see him”? Chapter 5 then considers the pursuit of a maximally general model capable of characterizing massive collections of heterogeneous content, unknown languages, and domain shift.Chapter 6 discusses several prominent or otherwise compelling uses of LI, from the pragmatic needs of machine translation to subtle tasks like determining the native language based on characteristic patterns in a second language. For instance, corpora of writing from known L2 speakers of English are widespread due to the popularity of English as a second language throughout education, allowing the study of orthographic mistakes grounded in phonetic properties of a native language. Stylistics and authorship attribution share useful features with LI, as they strive to avoid learning topical properties that are often correlated with language.The authors conclude by reiterating the diversity of phenomena that existing LI techniques rarely treat as first-order challenges (until they become immediately relevant), and the difficulty of drawing broader conclusions from the current literature. The book effectively catalogues these challenges and heterogeneity while also providing a stable reference for the community working to organize and extend research in this area. This is useful for several audiences and purposes: Students seeking to understand the history and landscape of LIResearchers hoping to unify or extend existing methodsPractitioners or stakeholders who need to select and justify an approach to a specific taskThe only notable “limitation” of the book is in fact endemic to the topic: The poorly mapped variety of LI research is naturally going to show through any thorough survey. The authors are up-front about this state of affairs and succeed at improving on it.},
  archive      = {J_COLI},
  author       = {Lippincott, Tom},
  doi          = {10.1162/coli_r_00521},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {339-341},
  shortjournal = {Comput. Lingu.},
  title        = {Automatic language identification in texts},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on LLM-generated text detection: Necessity,
methods, and future directions. <em>COLI</em>, <em>51</em>(1), 275–338.
(<a href="https://doi.org/10.1162/coli_a_00549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable ability of large language models (LLMs) to comprehend, interpret, and generate complex language has rapidly integrated LLM-generated text into various aspects of daily life, where users increasingly accept it. However, the growing reliance on LLMs underscores the urgent need for effective detection mechanisms to identify LLM-generated text. Such mechanisms are critical to mitigating misuse and safeguarding domains like artistic expression and social networks from potential negative consequences. LLM-generated text detection, conceptualized as a binary classification task, seeks to determine whether an LLM produced a given text. Recent advances in this field stem from innovations in watermarking techniques, statistics-based detectors, and neural-based detectors. Human-assisted methods also play a crucial role. In this survey, we consolidate recent research breakthroughs in this field, emphasizing the urgent need to strengthen detector research. Additionally, we review existing datasets, highlighting their limitations and developmental requirements. Furthermore, we examine various LLM-generated text detection paradigms, shedding light on challenges like out-of-distribution problems, potential attacks, real-world data issues, and ineffective evaluation frameworks. Finally, we outline intriguing directions for future research in LLM-generated text detection to advance responsible artificial intelligence. This survey aims to provide a clear and comprehensive introduction for newcomers while offering seasoned researchers valuable updates in the field. 1},
  archive      = {J_COLI},
  author       = {Wu, Junchao and Yang, Shu and Zhan, Runzhe and Yuan, Yulin and Chao, Lidia Sam and Wong, Derek Fai},
  doi          = {10.1162/coli_a_00549},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {275-338},
  shortjournal = {Comput. Lingu.},
  title        = {A survey on LLM-generated text detection: Necessity, methods, and future directions},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural semantic parsing with extremely rich symbolic meaning
representations. <em>COLI</em>, <em>51</em>(1), 235–274. (<a
href="https://doi.org/10.1162/coli_a_00542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current open-domain neural semantics parsers show impressive performance. However, closer inspection of the symbolic meaning representations they produce reveals significant weaknesses: Sometimes they tend to merely copy character sequences from the source text to form symbolic concepts, defaulting to the most frequent word sense based in the training distribution. By leveraging the hierarchical structure of a lexical ontology, we introduce a novel compositional symbolic representation for concepts based on their position in the taxonomical hierarchy. This representation provides richer semantic information and enhances interpretability. We introduce a neural “taxonomical” semantic parser to utilize this new representation system of predicates, and compare it with a standard neural semantic parser trained on the traditional meaning representation format, employing a novel challenge set and evaluation metric for evaluation. Our experimental findings demonstrate that the taxonomical model, trained on much richer and complex meaning representations, is slightly subordinate in performance to the traditional model using the standard metrics for evaluation, but outperforms it when dealing with out-of-vocabulary concepts. We further show through neural model probing that training on a taxonomic representation enhances the model’s ability to learn the taxonomical hierarchy. This finding is encouraging for research in computational semantics that aims to combine data-driven distributional meanings with knowledge-based symbolic representations.},
  archive      = {J_COLI},
  author       = {Zhang, Xiao and Bouma, Gosse and Bos, Johan},
  doi          = {10.1162/coli_a_00542},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {235-274},
  shortjournal = {Comput. Lingu.},
  title        = {Neural semantic parsing with extremely rich symbolic meaning representations},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating synthetic data generation from user generated
text. <em>COLI</em>, <em>51</em>(1), 191–233. (<a
href="https://doi.org/10.1162/coli_a_00540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User-generated content provides a rich resource to study social and behavioral phenomena. Although its application potential is currently limited by the paucity of expert labels and the privacy risks inherent in personal data, synthetic data can help mitigate this bottleneck. In this work, we introduce an evaluation framework to facilitate research on synthetic language data generation for user-generated text. We define a set of aspects for assessing data quality, namely, style preservation, meaning preservation, and divergence, as a proxy for privacy. We introduce metrics corresponding to each aspect. Moreover, through a set of generation strategies and representative tasks and baselines across domains, we demonstrate the relation between the quality aspects of synthetic user generated content, generation strategies, metrics, and downstream performance. To our knowledge, our work is the first unified evaluation framework for user-generated text in relation to the specified aspects, offering both intrinsic and extrinsic evaluation. We envisage it will facilitate developments towards shareable, high-quality synthetic language data.},
  archive      = {J_COLI},
  author       = {Chim, Jenny and Ive, Julia and Liakata, Maria},
  doi          = {10.1162/coli_a_00540},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {191-233},
  shortjournal = {Comput. Lingu.},
  title        = {Evaluating synthetic data generation from user generated text},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compositionality and sentence meaning: Comparing semantic
parsing and transformers on a challenging sentence similarity dataset.
<em>COLI</em>, <em>51</em>(1), 139–190. (<a
href="https://doi.org/10.1162/coli_a_00536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major outstanding questions in computational semantics is how humans integrate the meaning of individual words into a sentence in a way that enables understanding of complex and novel combinations of words, a phenomenon known as compositionality. Many approaches to modeling the process of compositionality can be classified as either “vector-based” models, in which the meaning of a sentence is represented as a vector of numbers, or “syntax-based” models, in which the meaning of a sentence is represented as a structured tree of labeled components. A major barrier in assessing and comparing these contrasting approaches is the lack of large, relevant datasets for model comparison. This article aims to address this gap by introducing a new dataset, STS3k, which consists of 2,800 pairs of sentences rated for semantic similarity by human participants. The sentence pairs have been selected to systematically vary different combinations of words, providing a rigorous test and enabling a clearer picture of the comparative strengths and weaknesses of vector-based and syntax-based methods. Our results show that when tested on the new STS3k dataset, state-of-the-art transformers poorly capture the pattern of human semantic similarity judgments, while even simple methods for combining syntax- and vector-based components into a novel hybrid model yield substantial improvements. We further show that this improvement is due to the ability of the hybrid model to replicate human sensitivity to specific changes in sentence structure. Our findings provide evidence for the value of integrating multiple methods to better reflect the way in which humans mentally represent compositional meaning.},
  archive      = {J_COLI},
  author       = {Fodor, James and Deyne, Simon De and Suzuki, Shinsuke},
  doi          = {10.1162/coli_a_00536},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {139-190},
  shortjournal = {Comput. Lingu.},
  title        = {Compositionality and sentence meaning: Comparing semantic parsing and transformers on a challenging sentence similarity dataset},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine translation meta evaluation through translation
accuracy challenge sets. <em>COLI</em>, <em>51</em>(1), 73–137. (<a
href="https://doi.org/10.1162/coli_a_00537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent machine translation (MT) metrics calibrate their effectiveness by correlating with human judgment. However, these results are often obtained by averaging predictions across large test sets without any insights into the strengths and weaknesses of these metrics across different error types. Challenge sets are used to probe specific dimensions of metric behavior but there are very few such datasets and they either focus on a limited number of phenomena or a limited number of language pairs. We introduce ACES , a contrastive challenge set spanning 146 language pairs, aimed at discovering whether metrics can identify 68 translation accuracy errors. These phenomena range from basic alterations at the word/character level to more intricate errors based on discourse and real-world knowledge. We conducted a large-scale study by benchmarking ACES on 47 metrics submitted to the WMT 2022 and WMT 2023 metrics shared tasks. We also measure their sensitivity to a range of linguistic phenomena. We further investigate claims that large language models (LLMs) are effective as MT evaluators, addressing the limitations of previous studies by using a dataset that covers a range of linguistic phenomena and language pairs and includes both low- and medium-resource languages. Our results demonstrate that different metric families struggle with different phenomena and that LLM-based methods are unreliable. We expose a number of major flaws with existing methods: Most metrics ignore the source sentence; metrics tend to prefer surface level overlap; and over-reliance on language-agnostic representations leads to confusion when the target language is similar to the source language. To further encourage detailed evaluation beyond singular scores, we expand ACES to include error span annotations, denoted as SPAN-ACES, and we use this dataset to evaluate span-based error metrics, showing that these metrics also need considerable improvement. Based on our observations, we provide a set of recommendations for building better MT metrics, including focusing on error labels instead of scores, ensembling, designing metrics to explicitly focus on the source sentence, focusing on semantic content rather than relying on the lexical overlap, and choosing the right pre-trained model for obtaining representations.},
  archive      = {J_COLI},
  author       = {Moghe, Nikita and Fazla, Arnisa and Amrhein, Chantal and Kocmi, Tom and Steedman, Mark and Birch, Alexandra and Sennrich, Rico and Guillou, Liane},
  doi          = {10.1162/coli_a_00537},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {73-137},
  shortjournal = {Comput. Lingu.},
  title        = {Machine translation meta evaluation through translation accuracy challenge sets},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ERST: A signaled graph theory of discourse relations and
organization. <em>COLI</em>, <em>51</em>(1), 23–72. (<a
href="https://doi.org/10.1162/coli_a_00538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we present Enhanced Rhetorical Structure Theory (eRST), a new theoretical framework for computational discourse analysis, based on an expansion of Rhetorical Structure Theory (RST). The framework encompasses discourse relation graphs with tree-breaking, non-projective and concurrent relations, as well as implicit and explicit signals which give explainable rationales to our analyses. We survey shortcomings of RST and other existing frameworks, such as Segmented Discourse Representation Theory, the Penn Discourse Treebank, and Discourse Dependencies, and address these using constructs in the proposed theory. We provide annotation, search, and visualization tools for data, and present and evaluate a freely available corpus of English annotated according to our framework, encompassing 12 spoken and written genres with over 200K tokens. Finally, we discuss automatic parsing, evaluation metrics, and applications for data in our framework.},
  archive      = {J_COLI},
  author       = {Zeldes, Amir and Aoyama, Tatsuya and Liu, Yang Janet and Peng, Siyao and Das, Debopam and Gessler, Luke},
  doi          = {10.1162/coli_a_00538},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {23-72},
  shortjournal = {Comput. Lingu.},
  title        = {ERST: A signaled graph theory of discourse relations and organization},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MUCking in, or fifty years in information extraction.
<em>COLI</em>, <em>51</em>(1), 7–22. (<a
href="https://doi.org/10.1162/coli_a_00547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I want to thank the ACL for this Lifetime Achievement Award. I am deeply honored to be receiving it. I would also like to thank the students, faculty, and researchers who were members of the Proteus Project during most of my professional lifetime. It was an honor to serve that group.},
  archive      = {J_COLI},
  author       = {Grishman, Ralph},
  doi          = {10.1162/coli_a_00547},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {7-22},
  shortjournal = {Comput. Lingu.},
  title        = {MUCking in, or fifty years in information extraction},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Opening a new chapter for computational linguistics.
<em>COLI</em>, <em>51</em>(1), 1–5. (<a
href="https://doi.org/10.1162/coli_e_00552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By the end of 2024, the journal Computational Linguistics has reached a significant milestone: It has published exactly 50 volumes over the past half-century. As we launch the first issue of Volume 51, this is an opportune moment to reflect on the journal’s legacy, ongoing evolution, and the exciting changes that lie ahead. Together, we embark on a journey to open a new chapter for this storied publication.},
  archive      = {J_COLI},
  author       = {Lu, Wei},
  doi          = {10.1162/coli_e_00552},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {1-5},
  shortjournal = {Comput. Lingu.},
  title        = {Opening a new chapter for computational linguistics},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jmlr---1">JMLR - 1</h2>
<ul>
<li><details>
<summary>
(2025). Gsplat: An open-source library for gaussian splatting.
<em>JMLR</em>, <em>26</em>(34), 1–17. (<a
href="https://jmlr.org/papers/v26/24-1476.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {gsplat is an open-source library designed for training and developing Gaussian Splatting methods. It features a front-end with Python bindings compatible with the PyTorch library and a back-end with highly optimized CUDA kernels. gsplat offers numerous features that enhance the optimization of Gaussian Splatting models, which include optimization improvements for speed, memory, and convergence times. Experimental results demonstrate that gsplat achieves up to 10% less training time and 4x less memory than the original implementation. Utilized in several research projects, gsplat is actively maintained on GitHub. Source code is available at https://github.com/nerfstudio-project/gsplat under Apache License 2.0. We welcome contributions from the open-source community.},
  archive      = {J_JMLR},
  author       = {Vickie Ye and Ruilong Li and Justin Kerr and Matias Turkulainen and Brent Yi and Zhuoyang Pan and Otto Seiskari and Jianbo Ye and Jeffrey Hu and Matthew Tancik and Angjoo Kanazawa},
  journal      = {Journal of Machine Learning Research},
  number       = {34},
  pages        = {1-17},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Gsplat: An open-source library for gaussian splatting},
  url          = {https://jmlr.org/papers/v26/24-1476.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="neco---7">NECO - 7</h2>
<ul>
<li><details>
<summary>
(2025). Nearly optimal learning using sparse deep ReLU networks in
regularized empirical risk minimization with lipschitz loss.
<em>NECO</em>, <em>37</em>(4), 815–870. (<a
href="https://doi.org/10.1162/neco_a_01742">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a sparse deep ReLU network (SDRN) estimator of the regression function obtained from regularized empirical risk minimization with a Lipschitz loss function. Our framework can be applied to a variety of regression and classification problems. We establish novel nonasymptotic excess risk bounds for our SDRN estimator when the regression function belongs to a Sobolev space with mixed derivatives. We obtain a new, nearly optimal, risk rate in the sense that the SDRN estimator can achieve nearly the same optimal minimax convergence rate as one-dimensional nonparametric regression with the dimension involved in a logarithm term only when the feature dimension is fixed. The estimator has a slightly slower rate when the dimension grows with the sample size. We show that the depth of the SDRN estimator grows with the sample size in logarithmic order, and the total number of nodes and weights grows in polynomial order of the sample size to have the nearly optimal risk rate. The proposed SDRN can go deeper with fewer parameters to well estimate the regression and overcome the overfitting problem encountered by conventional feedforward neural networks.},
  archive      = {J_NECO},
  author       = {Huang, Ke and Liu, Mingming and Ma, Shujie},
  doi          = {10.1162/neco_a_01742},
  journal      = {Neural Computation},
  month        = {3},
  number       = {4},
  pages        = {815-870},
  shortjournal = {Neural Comput.},
  title        = {Nearly optimal learning using sparse deep ReLU networks in regularized empirical risk minimization with lipschitz loss},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced EEG forecasting: A probabilistic deep learning
approach. <em>NECO</em>, <em>37</em>(4), 793–814. (<a
href="https://doi.org/10.1162/neco_a_01743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting electroencephalography (EEG) signals, that is, estimating future values of the time series based on the past ones, is essential in many real-time EEG-based applications, such as brain–computer interfaces and closed-loop brain stimulation. As these applications are becoming more and more common, the importance of a good prediction model has increased. Previously, the autoregressive model (AR) has been employed for this task; however, its prediction accuracy tends to fade quickly as multiple steps are predicted. We aim to improve on this by applying probabilistic deep learning to make robust longer-range forecasts. For this, we applied the probabilistic deep neural network model WaveNet to forecast resting-state EEG in theta- (4–7.5 Hz) and alpha-frequency (8–13 Hz) bands and compared it to the AR model. WaveNet reliably predicted EEG signals in both theta and alpha frequencies 150 ms ahead, with mean absolute errors of 1.0 ± 1.1 µV (theta) and 0.9 ± 1.1 µV (alpha), and outperformed the AR model in estimating the signal amplitude and phase. Furthermore, we found that the probabilistic approach offers a way of forecasting even more accurately while effectively discarding uncertain predictions. We demonstrate for the first time that probabilistic deep learning can be used to forecast resting-state EEG time series. In the future, the developed model can enhance the real-time estimation of brain states in brain–computer interfaces and brain stimulation protocols. It may also be useful for answering neuroscientific questions and for diagnostic purposes.},
  archive      = {J_NECO},
  author       = {Pankka, Hanna and Lehtinen, Jaakko and Ilmoniemi, Risto J. and Roine, Timo},
  doi          = {10.1162/neco_a_01743},
  journal      = {Neural Computation},
  month        = {3},
  number       = {4},
  pages        = {793-814},
  shortjournal = {Neural Comput.},
  title        = {Enhanced EEG forecasting: A probabilistic deep learning approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge as a breaking of ergodicity. <em>NECO</em>,
<em>37</em>(4), 742–792. (<a
href="https://doi.org/10.1162/neco_a_01741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct a thermodynamic potential that can guide training of a generative model defined on a set of binary degrees of freedom. We argue that upon reduction in description, so as to make the generative model computationally manageable, the potential develops multiple minima. This is mirrored by the emergence of multiple minima in the free energy proper of the generative model itself. The variety of training samples that employ N binary degrees of freedom is ordinarily much lower than the size 2 N of the full phase space. The nonrepresented configurations, we argue, should be thought of as comprising a high-temperature phase separated by an extensive energy gap from the configurations composing the training set. Thus, training amounts to sampling a free energy surface in the form of a library of distinct bound states, each of which breaks ergodicity. The ergodicity breaking prevents escape into the near continuum of states comprising the high-temperature phase; thus, it is necessary for proper functionality. It may, however, have the side effect of limiting access to patterns that were underrepresented in the training set. At the same time, the ergodicity breaking within the library complicates both learning and retrieval. As a remedy, one may concurrently employ multiple generative models—up to one model per free energy minimum.},
  archive      = {J_NECO},
  author       = {He, Yang and Lubchenko, Vassiliy},
  doi          = {10.1162/neco_a_01741},
  journal      = {Neural Computation},
  month        = {3},
  number       = {4},
  pages        = {742-792},
  shortjournal = {Neural Comput.},
  title        = {Knowledge as a breaking of ergodicity},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning in wilson-cowan model for metapopulation.
<em>NECO</em>, <em>37</em>(4), 701–741. (<a
href="https://doi.org/10.1162/neco_a_01744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Wilson-Cowan model for metapopulation, a neural mass network model, treats different subcortical regions of the brain as connected nodes, with connections representing various types of structural, functional, or effective neuronal connectivity between these regions. Each region comprises interacting populations of excitatory and inhibitory cells, consistent with the standard Wilson-Cowan model. In this article, we show how to incorporate stable attractors into such a metapopulation model’s dynamics. By doing so, we transform the neural mass network model into a biologically inspired learning algorithm capable of solving different classification tasks. We test it on MNIST and Fashion MNIST in combination with convolutional neural networks, as well as on CIFAR-10 and TF-FLOWERS, and in combination with a transformer architecture (BERT) on IMDB, consistently achieving high classification accuracy.},
  archive      = {J_NECO},
  author       = {Marino, Raffaele and Buffoni, Lorenzo and Chicchi, Lorenzo and Patti, Francesca Di and Febbe, Diego and Giambagli, Lorenzo and Fanelli, Duccio},
  doi          = {10.1162/neco_a_01744},
  journal      = {Neural Computation},
  month        = {3},
  number       = {4},
  pages        = {701-741},
  shortjournal = {Neural Comput.},
  title        = {Learning in wilson-cowan model for metapopulation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active inference and intentional behavior. <em>NECO</em>,
<em>37</em>(4), 666–700. (<a
href="https://doi.org/10.1162/neco_a_01738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in theoretical biology suggest that key definitions of basal cognition and sentient behavior may arise as emergent properties of in vitro cell cultures and neuronal networks. Such neuronal networks reorganize activity to demonstrate structured behaviors when embodied in structured information landscapes. In this article, we characterize this kind of self-organization through the lens of the free energy principle, that is, as self-evidencing. We do this by first discussing the definitions of reactive and sentient behavior in the setting of active inference, which describes the behavior of agents that model the consequences of their actions. We then introduce a formal account of intentional behavior that describes agents as driven by a preferred end point or goal in latent state-spaces. We then investigate these forms of (reactive, sentient, and intentional) behavior using simulations. First, we simulate the in vitro experiments, in which neuronal cultures modulated activity to improve gameplay in a simplified version of Pong by implementing nested, free energy minimizing processes. The simulations are then used to deconstruct the ensuing predictive behavior, leading to the distinction between merely reactive, sentient, and intentional behavior with the latter formalized in terms of inductive inference. This distinction is further studied using simple machine learning benchmarks (navigation in a grid world and the Tower of Hanoi problem) that show how quickly and efficiently adaptive behavior emerges under an inductive form of active inference.},
  archive      = {J_NECO},
  author       = {Friston, Karl J. and Salvatori, Tommaso and Isomura, Takuya and Tschantz, Alexander and Kiefer, Alex and Verbelen, Tim and Koudahl, Magnus and Paul, Aswin and Parr, Thomas and Razi, Adeel and Kagan, Brett J. and Buckley, Christopher L. and Ramstead, Maxwell J. D.},
  doi          = {10.1162/neco_a_01738},
  journal      = {Neural Computation},
  month        = {3},
  number       = {4},
  pages        = {666-700},
  shortjournal = {Neural Comput.},
  title        = {Active inference and intentional behavior},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spiking neuron-astrocyte networks for image recognition.
<em>NECO</em>, <em>37</em>(4), 635–665. (<a
href="https://doi.org/10.1162/neco_a_01740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From biological and artificial network perspectives, researchers have started acknowledging astrocytes as computational units mediating neural processes. Here, we propose a novel biologically inspired neuron-astrocyte network model for image recognition, one of the first attempts at implementing astrocytes in spiking neuron networks (SNNs) using a standard data set. The architecture for image recognition has three primary units: the preprocessing unit for converting the image pixels into spiking patterns, the neuron-astrocyte network forming bipartite (neural connections) and tripartite synapses (neural and astrocytic connections), and the classifier unit. In the astrocyte-mediated SNNs, an astrocyte integrates neural signals following the simplified Postnov model. It then modulates the integrate-and-fire (IF) neurons via gliotransmission, thereby strengthening the synaptic connections of the neurons within the astrocytic territory. We develop an architecture derived from a baseline SNN model for unsupervised digit classification. The spiking neuron-astrocyte networks (SNANs) display better network performance with an optimal variance-bias trade-off than SNN alone. We demonstrate that astrocytes promote faster learning, support memory formation and recognition, and provide a simplified network architecture. Our proposed SNAN can serve as a benchmark for future researchers on astrocyte implementation in artificial networks, particularly in neuromorphic systems, for its simplified design.},
  archive      = {J_NECO},
  author       = {Lorenzo, Jhunlyn and Rico-Gallego, Juan-Antonio and Binczak, Stéphane and Jacquir, Sabir},
  doi          = {10.1162/neco_a_01740},
  journal      = {Neural Computation},
  month        = {3},
  number       = {4},
  pages        = {635-665},
  shortjournal = {Neural Comput.},
  title        = {Spiking neuron-astrocyte networks for image recognition},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-sensitive processing in a model neocortical
pyramidal cell with two sites of input integration. <em>NECO</em>,
<em>37</em>(4), 588–634. (<a
href="https://doi.org/10.1162/neco_a_01739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neocortical layer 5 thick-tufted pyramidal cells are prone to exhibiting burst firing on receipt of coincident basal and apical dendritic inputs. These inputs carry different information, with basal inputs coming from feedforward sensory pathways and apical inputs coming from diverse sources that provide context in the cortical hierarchy. We explore the information processing possibilities of this burst firing using computer simulations of a noisy compartmental cell model. Simulated data on stochastic burst firing due to brief, simultaneously injected basal and apical currents allow estimation of burst firing probability for different stimulus current amplitudes. Information-theory-based partial information decomposition (PID) is used to quantify the contributions of the apical and basal input streams to the information in the cell output bursting probability. Four different operating regimes are apparent, depending on the relative strengths of the input streams, with output burst probability carrying more or less information that is uniquely contributed by either the basal or apical input, or shared and synergistic information due to the combined streams. We derive and fit transfer functions for these different regimes that describe burst probability over the different ranges of basal and apical input amplitudes. The operating regimes can be classified into distinct modes of information processing, depending on the contribution of apical input to output bursting: apical cooperation, in which both basal and apical inputs are required to generate a burst; apical amplification, in which basal input alone can generate a burst but the burst probability is modulated by apical input; apical drive, in which apical input alone can produce a burst; and apical integration, in which strong apical or basal inputs alone, as well as their combination, can generate bursting. In particular, PID and the transfer function clarify that the apical amplification mode has the features required for contextually modulated information processing.},
  archive      = {J_NECO},
  author       = {Graham, Bruce P. and Kay, Jim W. and Phillips, William A.},
  doi          = {10.1162/neco_a_01739},
  journal      = {Neural Computation},
  month        = {3},
  number       = {4},
  pages        = {588-634},
  shortjournal = {Neural Comput.},
  title        = {Context-sensitive processing in a model neocortical pyramidal cell with two sites of input integration},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="netn---21">NETN - 21</h2>
<ul>
<li><details>
<summary>
(2025). Firing rate distributions in plastic networks of spiking
neurons. <em>NETN</em>, <em>9</em>(1), 447–474. (<a
href="https://doi.org/10.1162/netn_a_00442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recurrent networks of leaky integrate-and-fire neurons, the mean-field theory has been instrumental in capturing the statistical properties of neuronal activity, like firing rate distributions. This theory has been applied to networks with either homogeneous synaptic weights and heterogeneous connections per neuron or vice versa. Our work expands mean-field models to include networks with both types of structural heterogeneity simultaneously, particularly focusing on those with synapses that undergo plastic changes. The model introduces a spike trace for each neuron, a variable that rises with neuron spikes and decays without activity, influenced by a degradation rate r p and the neuron’s firing rate ν . When the ratio α = ν / r p is significantly high, this trace effectively estimates the neuron’s firing rate, allowing synaptic weights at equilibrium to be determined by the firing rates of connected neurons. This relationship is incorporated into our mean-field formalism, providing exact solutions for firing rate and synaptic weight distributions at equilibrium in the high α regime. However, the model remains accurate within a practical range of degradation rates, as demonstrated through simulations with networks of excitatory and inhibitory neurons. This approach sheds light on how plasticity modulates both activity and structure within neuronal networks, offering insights into their complex behavior. Networks of spiking neurons are complex systems where the structure of connections and the activity patterns generated are deeply intertwined, a relationship often studied using mathematical approaches like the mean-field theory. However, previous studies have primarily focused on networks with limited structural variability, where either the connection strength is nearly identical across the network or the number of connections varies little from one neuron to another. This work takes a step forward by combining both types of structural variability and allowing connection strengths to adapt over time, thereby providing an extended mean-field theory. We derive exact solutions for the distribution of spiking rates and connection strengths at equilibrium and demonstrate their accuracy through numerical simulations, even beyond the defining parameter ranges, offering a more comprehensive and realistic perspective on the interplay between activity and structure in neuronal networks.},
  archive      = {J_NETN},
  author       = {Vegué, Marina and Allard, Antoine and Desrosiers, Patrick},
  doi          = {10.1162/netn_a_00442},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {447-474},
  shortjournal = {Netw. Neuroscience},
  title        = {Firing rate distributions in plastic networks of spiking neurons},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Validating MEG estimated resting-state connectome with
intracranial EEG. <em>NETN</em>, <em>9</em>(1), 421–446. (<a
href="https://doi.org/10.1162/netn_a_00441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetoencephalography (MEG) is widely used for studying resting-state brain connectivity. However, MEG source imaging is ill posed and has limited spatial resolution. This introduces source-leakage issues, making it challenging to interpret MEG-derived connectivity in resting states. To address this, we validated MEG-derived connectivity from 45 healthy participants using a normative intracranial EEG (iEEG) atlas. The MEG inverse problem was solved using the wavelet-maximum entropy on the mean method. We computed four connectivity metrics: amplitude envelope correlation (AEC), orthogonalized AEC (OAEC), phase locking value (PLV), and weighted-phase lag index (wPLI). We compared spatial correlation between MEG and iEEG connectomes across standard canonical frequency bands. We found moderate spatial correlations between MEG and iEEG connectomes for AEC and PLV. However, when considering metrics that correct/remove zero-lag connectivity (OAEC/wPLI), the spatial correlation between MEG and iEEG connectomes decreased. MEG exhibited higher zero-lag connectivity compared with iEEG. The correlations between MEG and iEEG connectomes suggest that relevant connectivity patterns can be recovered from MEG. However, since these correlations are moderate/low, MEG connectivity results should be interpreted with caution. Metrics that correct for zero-lag connectivity show decreased correlations, highlighting a trade-off; while MEG may capture more connectivity due to source-leakage, removing zero-lag connectivity can eliminate true connections. The ill-posed nature and low spatial resolution of EEG/magnetoencephalography (MEG) source imaging affects functional connectivity estimates, which become more complicated in the resting state due to the low signal-to-noise ratio. Several connectivity metrics have been proposed to address source leakage by removing zero-lag connectivity, although this can eliminate true neuronal zero-lag connections. Intracranial EEG (iEEG) is the gold standard for validating noninvasive measurements. In this study, we validated MEG-estimated connectivity for healthy subjects using the iEEG atlas of normal brain activity ( Frauscher et al., 2018 ) as ground truth at a group level. We employed two amplitude-based metrics and two phase-based metrics. Our findings highlight how MEG connectivity compares with the iEEG atlas and provide valuable insights for resting-state EEG/MEG connectomic studies, particularly in the choice of connectivity metrics.},
  archive      = {J_NETN},
  author       = {Afnan, Jawata and Cai, Zhengchen and Lina, Jean-Marc and Abdallah, Chifaou and Pellegrino, Giovanni and Arcara, Giorgio and Khajehpour, Hassan and Frauscher, Birgit and Gotman, Jean and Grova, Christophe},
  doi          = {10.1162/netn_a_00441},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {421-446},
  shortjournal = {Netw. Neuroscience},
  title        = {Validating MEG estimated resting-state connectome with intracranial EEG},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Whole-brain causal discovery using fMRI. <em>NETN</em>,
<em>9</em>(1), 392–420. (<a
href="https://doi.org/10.1162/netn_a_00438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant research, discovering causal relationships from fMRI remains a challenge. Popular methods such as Granger causality and dynamic causal modeling fall short in handling contemporaneous effects and latent common causes. Methods from causal structure learning literature can address these limitations but often scale poorly with network size and need acyclicity. In this study, we first provide a taxonomy of existing methods and compare their accuracy and efficiency on simulated fMRI from simple topologies. This analysis demonstrates a pressing need for more accurate and scalable methods, motivating the design of Causal discovery for Large-scale Low-resolution Time-series with Feedback (CaLLTiF). CaLLTiF is a constraint-based method that uses conditional independence between contemporaneous and lagged variables to extract causal relationships. On simulated fMRI from the macaque connectome, CaLLTiF achieves significantly higher accuracy and scalability than all tested alternatives. From resting-state human fMRI, CaLLTiF learns causal connectomes that are highly consistent across individuals, show clear top-down flow of causal effect from attention and default mode to sensorimotor networks, exhibit Euclidean distance dependence in causal interactions, and are highly dominated by contemporaneous effects. Overall, this work takes a major step in enhancing causal discovery from whole-brain fMRI and defines a new standard for future investigations. Discovering causal relationships from fMRI data is challenging due to contemporaneous effects and latent causes. Popular methods like Granger causality and dynamic causal modeling struggle with these issues, especially in large networks. To address this, we introduce Causal discovery for Large-scale Low-resolution Time-series with Feedback (CaLLTiF), a scalable method that uses both lagged and contemporaneous variables to identify causal relationships. CaLLTiF outperforms various existing techniques in accuracy and scalability on simulated fMRI data. When applied to human resting-state fMRI, it reveals consistent and biologically plausible patterns across individuals, with a clear top-down causal flow from attention and default mode networks to sensorimotor areas. Overall, this work advances the field of causal discovery in large-scale fMRI studies.},
  archive      = {J_NETN},
  author       = {Arab, Fahimeh and Ghassami, AmirEmad and Jamalabadi, Hamidreza and Peters, Megan A. K. and Nozari, Erfan},
  doi          = {10.1162/netn_a_00438},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {392-420},
  shortjournal = {Netw. Neuroscience},
  title        = {Whole-brain causal discovery using fMRI},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-retest reliability of dynamic functional connectivity
parameters for a two-state model. <em>NETN</em>, <em>9</em>(1), 371–391.
(<a href="https://doi.org/10.1162/netn_a_00437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability of imaging parameters is of pivotal importance for further correlation analyses. Here, we investigated the test-retest reliability of two dynamic functional connectivity (dFC) brain states and related parameters for different scan length, atlases with 116 versus 442 regions, and data centering in 23 participants and reproduced the findings in 501 subjects of the Human Connectome Project. Results showed an integrated and a segregated brain state with high intraclass correlation coefficient (ICC) values of the states between sessions (0.67 ≥ ICC ≥ 0.99). The most reliable dFC parameter was state prevalence with an ICC ≈ 0.5 for ∼15 min of uncentered data, while other parameters, such as mean dwell time, were much less reliable. While shorter scans and within-subject data centering further reduce reliability, the atlas choice had no effects. Spearman’s correlations among dFC parameters strongly depend on data centering. The effect of global signal regression and a higher number of states is discussed. In conclusion, we recommend formulating hypotheses on cross-sectional differences and correlations between dFC measures of brain integration and other subject-specific measures in terms of state prevalence, especially in small-scale studies. We investigated the reliability of popular parameters characterizing dynamic brain states in two datasets. We found high reliability of clustering results with a two-state model but only medium to low reliability of the parameters, of which state prevalence across different strategies was the most reliable.},
  archive      = {J_NETN},
  author       = {Fang, Xiaojing and Marxen, Michael},
  doi          = {10.1162/netn_a_00437},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {371-391},
  shortjournal = {Netw. Neuroscience},
  title        = {Test-retest reliability of dynamic functional connectivity parameters for a two-state model},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Translational network neuroscience: Nine roadblocks and
possible solutions. <em>NETN</em>, <em>9</em>(1), 352–370. (<a
href="https://doi.org/10.1162/netn_a_00435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Translational network neuroscience aims to integrate advanced neuroimaging and data analysis techniques into clinical practice to better understand and treat neurological disorders. Despite the promise of technologies such as functional MRI and diffusion MRI combined with network analysis tools, the field faces several challenges that hinder its swift clinical translation. We have identified nine key roadblocks that impede this process: (a) theoretical and basic science foundations; (b) network construction, data interpretation, and validation; (c) MRI access, data variability, and protocol standardization; (d) data sharing; (e) computational resources and expertise; (f) interdisciplinary collaboration; (g) industry collaboration and commercialization; (h) operational efficiency, integration, and training; and (i) ethical and legal considerations. To address these challenges, we propose several possible solution strategies. By aligning scientific goals with clinical realities and establishing a sound ethical framework, translational network neuroscience can achieve meaningful advances in personalized medicine and ultimately improve patient care. We advocate for an interdisciplinary commitment to overcoming translational hurdles in network neuroscience and integrating advanced technologies into routine clinical practice.},
  archive      = {J_NETN},
  author       = {Fekonja, Lucius S. and Forkel, Stephanie J. and Aydogan, Dogu Baran and Lioumis, Pantelis and Cacciola, Alberto and Lucas, Carolin Weiß and Tournier, Jacques-Donald and Vergani, Francesco and Ritter, Petra and Schenk, Robert and Shams, Boshra and Engelhardt, Melina Julia and Picht, Thomas},
  doi          = {10.1162/netn_a_00435},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {352-370},
  shortjournal = {Netw. Neuroscience},
  title        = {Translational network neuroscience: Nine roadblocks and possible solutions},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Individualized mouse brain network models produce asymmetric
patterns of functional connectivity after simulated traumatic injury.
<em>NETN</em>, <em>9</em>(1), 326–351. (<a
href="https://doi.org/10.1162/netn_a_00431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The functional and cognitive effects of traumatic brain injury (TBI) are poorly understood, as even mild injuries (concussion) can lead to long-lasting, untreatable symptoms. Simplified brain dynamics models may help researchers better understand the relationship between brain injury patterns and functional outcomes. Properly developed, these computational models provide an approach to investigate the effects of both computational and in vivo injury on simulated dynamics and cognitive function, respectively, for model organisms. In this study, we apply the Kuramoto model and an existing mesoscale mouse brain structural network to develop a simplified computational model of mouse brain dynamics. We explore how to optimize our initial model to predict existing mouse brain functional connectivity collected from mice under various anesthetic protocols. Finally, to determine how strongly the changes in our optimized models’ dynamics can predict the extent of a brain injury, we investigate how our simulations respond to varying levels of structural network damage. Results predict a mixture of hypo- and hyperconnectivity after experimental TBI, similar to results in TBI survivors, and also suggest a compensatory remodeling of connections that may have an impact on functional outcomes after TBI. Recent research has investigated the consequences of traumatic brain injuries by combining computational models of human brain activity and structural models of the whole human brain or cortex. As experimental injury research can only be conducted using animal models, we apply a simplified computational model of whole-brain dynamics, the Kuramoto model, to a mouse brain structural network. We tune our model to best predict measurements of functional connectivity recorded from 58 fMRI scans of mice and lesion the network model to explore the effects of injury. Our findings predict that functional connectivity may increase or decrease in various regions of the brain, even at a high injury level, which may aid in future predictions of cognitive impairments after brain injury.},
  archive      = {J_NETN},
  author       = {Rayfield, Adam C. and Wu, Taotao and Rifkin, Jared A. and Meaney, David F.},
  doi          = {10.1162/netn_a_00431},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {326-351},
  shortjournal = {Netw. Neuroscience},
  title        = {Individualized mouse brain network models produce asymmetric patterns of functional connectivity after simulated traumatic injury},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional brain networks predicting sustained attention are
not specific to perceptual modality. <em>NETN</em>, <em>9</em>(1),
303–325. (<a href="https://doi.org/10.1162/netn_a_00430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustained attention is essential for daily life and can be directed to information from different perceptual modalities, including audition and vision. Recently, cognitive neuroscience has aimed to identify neural predictors of behavior that generalize across datasets. Prior work has shown strong generalization of models trained to predict individual differences in sustained attention performance from patterns of fMRI functional connectivity. However, it is an open question whether predictions of sustained attention are specific to the perceptual modality in which they are trained. In the current study, we test whether connectome-based models predict performance on attention tasks performed in different modalities. We show first that a predefined network trained to predict adults’ visual sustained attention performance generalizes to predict auditory sustained attention performance in three independent datasets ( N 1 = 29, N 2 = 60, N 3 = 17). Next, we train new network models to predict performance on visual and auditory attention tasks separately. We find that functional networks are largely modality general, with both model-unique and shared model features predicting sustained attention performance in independent datasets regardless of task modality. Results support the supposition that visual and auditory sustained attention rely on shared neural mechanisms and demonstrate robust generalizability of whole-brain functional network models of sustained attention. While previous work has demonstrated external validity of functional connectivity-based networks for the prediction of cognitive and attentional performance, testing generalization across visual and auditory perceptual modalities has been limited. The current study demonstrates robust prediction of sustained attention performance, regardless of perceptual modality models are trained or tested in. Results demonstrate that connectivity-based models may generalize broadly, capturing variance in sustained attention performance that is agnostic to the perceptual modality of model training.},
  archive      = {J_NETN},
  author       = {Corriveau, Anna and Ke, Jin and Terashima, Hiroki and Kondo, Hirohito M. and Rosenberg, Monica D.},
  doi          = {10.1162/netn_a_00430},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {303-325},
  shortjournal = {Netw. Neuroscience},
  title        = {Functional brain networks predicting sustained attention are not specific to perceptual modality},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional connectotomy of a whole-brain model reveals
tumor-induced alterations to neuronal dynamics in glioma patients.
<em>NETN</em>, <em>9</em>(1), 280–302. (<a
href="https://doi.org/10.1162/netn_a_00426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors can induce pathological changes in neuronal dynamics that are reflected in functional connectivity measures. Here, we use a whole-brain modeling approach to investigate pathological alterations to neuronal activity in glioma patients. By fitting a Hopf whole-brain model to empirical functional connectivity, we investigate glioma-induced changes in optimal model parameters. We observe considerable differences in neuronal dynamics between glioma patients and healthy controls, both on an individual and population-based level. In particular, model parameter estimation suggests that local tumor pathology causes changes in brain dynamics by increasing the influence of interregional interactions on global neuronal activity. Our approach demonstrates that whole-brain models provide valuable insights for understanding glioma-associated alterations in functional connectivity. This study investigates how gliomas affect neuronal activity and connectivity using a whole-brain computational model. By fitting this model to empirical data, we compare glioma patients with healthy individuals to uncover significant differences in brain dynamics. Our findings indicate that local tumor pathology enhances the influence of interregional interactions on overall neuronal activity. This approach underscores the utility of whole-brain computational models in revealing the complex alterations in functional connectivity associated with gliomas, advancing our understanding of their impact on brain function.},
  archive      = {J_NETN},
  author       = {Alexandersen, Christoffer G. and Douw, Linda and Zimmermann, Mona L. M. and Bick, Christian and Goriely, Alain},
  doi          = {10.1162/netn_a_00426},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {280-302},
  shortjournal = {Netw. Neuroscience},
  title        = {Functional connectotomy of a whole-brain model reveals tumor-induced alterations to neuronal dynamics in glioma patients},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal MRI accurately identifies amyloid status in
unbalanced cohorts in alzheimer’s disease continuum. <em>NETN</em>,
<em>9</em>(1), 259–279. (<a
href="https://doi.org/10.1162/netn_a_00423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amyloid- β (A β ) plaques in conjunction with hyperphosphorylated tau proteins in the form of neurofibrillary tangles are the two neuropathological hallmarks of Alzheimer’s disease. It is well-known that the identification of individuals with A β positivity could enable early diagnosis. In this work, we aim at capturing the A β positivity status in an unbalanced cohort enclosing subjects at different disease stages, exploiting the underlying structural and connectivity disease-induced modulations as revealed by structural, functional, and diffusion MRI. Of note, due to the unbalanced cohort, the outcomes may be guided by those factors rather than amyloid accumulation. The partial views provided by each modality are integrated in the model, allowing to take full advantage of their complementarity in encoding the effects of the A β accumulation, leading to an accuracy of 0.762 ± 0.04. The specificity of the information brought by each modality is assessed by post hoc explainability analysis (guided backpropagation), highlighting the underlying structural and functional changes. Noteworthy, well-established biomarker key regions related to A β deposition could be identified by all modalities, including the hippocampus, thalamus, precuneus, and cingulate gyrus, witnessing in favor of the reliability of the method as well as its potential in shedding light on modality-specific possibly unknown A β deposition signatures. In this work, we employed a multimodal MRI-based deep learning framework for the classification of unbalanced cohorts relying on the amyloid- β status in the Alzheimer’s disease continuum. To this end, structural, functional, and diffusion MRI data were used to feed a 3D-convolutional neural network and two different graph neural networks, respectively, reaching an accuracy of 0.762 ± 0.04. Post hoc explainability analysis was performed to extract the most relevant regions that led to the outcome, highlighting the involvement of different cortical and subcortical regions. This work provides evidence of the added value brought by exploiting different imaging modalities in decrypting the nature and extent of brain alterations in the amyloid-guided classification outcome.},
  archive      = {J_NETN},
  author       = {Dolci, Giorgio and Ellis, Charles A. and Cruciani, Federica and Brusini, Lorenza and Abrol, Anees and Galazzo, Ilaria Boscolo and Menegaz, Gloria and Calhoun, Vince D. and for the Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1162/netn_a_00423},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {259-279},
  shortjournal = {Netw. Neuroscience},
  title        = {Multimodal MRI accurately identifies amyloid status in unbalanced cohorts in alzheimer’s disease continuum},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing the brain’s dynamic response to targeted
stimulation using generative modeling. <em>NETN</em>, <em>9</em>(1),
237–258. (<a href="https://doi.org/10.1162/netn_a_00433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models of brain activity have been instrumental in testing hypothesized mechanisms underlying brain dynamics against experimental datasets. Beyond capturing the key mechanisms underlying spontaneous brain dynamics, these models hold an exciting potential for understanding the mechanisms underlying the dynamics evoked by targeted brain stimulation techniques. This paper delves into this emerging application, using concepts from dynamical systems theory to argue that the stimulus-evoked dynamics in such experiments may be shaped by new types of mechanisms distinct from those that dominate spontaneous dynamics. We review and discuss (a) the targeted experimental techniques across spatial scales that can both perturb the brain to novel states and resolve its relaxation trajectory back to spontaneous dynamics and (b) how we can understand these dynamics in terms of mechanisms using physiological, phenomenological, and data-driven models. A tight integration of targeted stimulation experiments with generative quantitative modeling provides an important opportunity to uncover novel mechanisms of brain dynamics that are difficult to detect in spontaneous settings. Generative models are important tools for testing hypothesized mechanisms of brain dynamics against experimental data. This review highlights an application of generative models in analyzing a form of brain activity evoked by emerging targeted stimulation techniques. We argue that analyzing targeted stimulation dynamics can uncover mechanisms that are hidden during commonly analyzed spontaneous dynamics and explore how integrating diverse targeted stimulation experiments with existing generative models offer a significant opportunity to uncover these novel mechanisms and thereby expand our mechanistic understanding of brain dynamics.},
  archive      = {J_NETN},
  author       = {Maran, Rishikesan and Müller, Eli J. and Fulcher, Ben D.},
  doi          = {10.1162/netn_a_00433},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {237-258},
  shortjournal = {Netw. Neuroscience},
  title        = {Analyzing the brain’s dynamic response to targeted stimulation using generative modeling},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A connectome manipulation framework for the systematic and
reproducible study of structure–function relationships through
simulations. <em>NETN</em>, <em>9</em>(1), 207–236. (<a
href="https://doi.org/10.1162/netn_a_00429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synaptic connectivity at the neuronal level is characterized by highly nonrandom features. Hypotheses about their role can be developed by correlating structural metrics to functional features. But, to prove causation, manipulations of connectivity would have to be studied. However, the fine-grained scale at which nonrandom trends are expressed makes this approach challenging to pursue experimentally. Simulations of neuronal networks provide an alternative route to study arbitrarily complex manipulations in morphologically and biophysically detailed models. Here, we present Connectome-Manipulator, a Python framework for rapid connectome manipulations of large-scale network models in Scalable Open Network Architecture TemplAte (SONATA) format. In addition to creating or manipulating the connectome of a model, it provides tools to fit parameters of stochastic connectivity models against existing connectomes. This enables rapid replacement of any existing connectome with equivalent connectomes at different levels of complexity, or transplantation of connectivity features from one connectome to another, for systematic study. We employed the framework in the detailed model of the rat somatosensory cortex in two exemplary use cases: transplanting interneuron connectivity trends from electron microscopy data and creating simplified connectomes of excitatory connectivity. We ran a series of network simulations and found diverse shifts in the activity of individual neuron populations causally linked to these manipulations.},
  archive      = {J_NETN},
  author       = {Pokorny, Christoph and Awile, Omar and Isbister, James B. and Kurban, Kerem and Wolf, Matthias and Reimann, Michael W.},
  doi          = {10.1162/netn_a_00429},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {207-236},
  shortjournal = {Netw. Neuroscience},
  title        = {A connectome manipulation framework for the systematic and reproducible study of structure–function relationships through simulations},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combined topological and spatial constraints are required to
capture the structure of neural connectomes. <em>NETN</em>,
<em>9</em>(1), 181–206. (<a
href="https://doi.org/10.1162/netn_a_00428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volumetric brain reconstructions provide an unprecedented opportunity to gain insights into the complex connectivity patterns of neurons in an increasing number of organisms. Here, we model and quantify the complexity of the resulting neural connectomes in the fruit fly, mouse, and human and unveil a simple set of shared organizing principles across these organisms. To put the connectomes in a physical context, we also construct contactomes, the network of neurons in physical contact in each organism. With these, we establish that physical constraints—either given by pairwise distances or the contactome—play a crucial role in shaping the network structure. For example, neuron positions are highly optimal in terms of distance from their neighbors. Yet, spatial constraints alone cannot capture the network topology, including the broad degree distribution. Conversely, the degree sequence alone is insufficient to recover the spatial structure. We resolve this apparent mismatch by formulating scalable maximum entropy models, incorporating both types of constraints. The resulting generative models have predictive power beyond the input data, as they capture several additional biological and network characteristics, like synaptic weights and graphlet statistics. We investigate the interplay of the spatial and topological structure of millimeter-scale neural connectomes in fly, mouse, and human. As a spatial observation, we demonstrate that the probability of synaptic connection decays exponentially with distance. Additionally, we show that the wiring length in neural connectomes is highly optimal. To quantify the physical constraints on synapse formation, we construct the physical contact network for each organism and demonstrate that contact edge probability follows the same exponential functional form as the connectome. At the same time, we show that spatial constraints are necessary but not sufficient to reconstruct the connectome topology. We present maximum-entropy models capturing key spatial and topological aspects of the connectomes and demonstrate their predictive power beyond the input data.},
  archive      = {J_NETN},
  author       = {Salova, Anastasiya and Kovács, István A.},
  doi          = {10.1162/netn_a_00428},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {181-206},
  shortjournal = {Netw. Neuroscience},
  title        = {Combined topological and spatial constraints are required to capture the structure of neural connectomes},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network embedding of functional microconnectome.
<em>NETN</em>, <em>9</em>(1), 159–180. (<a
href="https://doi.org/10.1162/netn_a_00424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our brains operate as a complex network of interconnected neurons. To gain a deeper understanding of this network architecture, it is essential to extract simple rules from its intricate structure. This study aimed to compress and simplify the architecture, with a particular focus on interpreting patterns of functional connectivity in 2.5 hr of electrical activity from a vast number of neurons in acutely sliced mouse brains. Here, we combined two distinct methods together: automatic compression and network analysis. Firstly, for automatic compression, we trained an artificial neural network named NNE (neural network embedding). This allowed us to reduce the connectivity to features, be represented only by 13% of the original neuron count. Secondly, to decipher the topology, we concentrated on the variability among the compressed features and compared them with 15 distinct network metrics. Specifically, we introduced new metrics that had not previously existed, termed as indirect-adjacent degree and neighbor hub ratio. Our results conclusively demonstrated that these new metrics could better explain approximately 40%–45% of the features. This finding highlighted the critical role of NNE in facilitating the development of innovative metrics, because some of the features extracted by NNE were not captured by the currently existed network metrics. Neural network embedding can compress large connectivity and has led to new metrics like indirect-adjacency degree and neighbor hub ratio.},
  archive      = {J_NETN},
  author       = {Shirakami, Arata and Hase, Takeshi and Yamaguchi, Yuki and Shimono, Masanori},
  doi          = {10.1162/netn_a_00424},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {159-180},
  shortjournal = {Netw. Neuroscience},
  title        = {Neural network embedding of functional microconnectome},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complexity in speech and music listening via neural manifold
flows. <em>NETN</em>, <em>9</em>(1), 146–158. (<a
href="https://doi.org/10.1162/netn_a_00422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the complex neural mechanisms underlying speech and music perception remains a multifaceted challenge. In this study, we investigated neural dynamics using human intracranial recordings. Employing a novel approach based on low-dimensional reduction techniques, the Manifold Density Flow (MDF), we quantified the complexity of brain dynamics during naturalistic speech and music listening and during resting state. Our results reveal higher complexity in patterns of interdependence between different brain regions during speech and music listening compared with rest, suggesting that the cognitive demands of speech and music listening drive the brain dynamics toward states not observed during rest. Moreover, speech listening has more complexity than music, highlighting the nuanced differences in cognitive demands between these two auditory domains. Additionally, we validated the efficacy of the MDF method through experimentation on a toy model and compared its effectiveness in capturing the complexity of brain dynamics induced by cognitive tasks with another established technique in the literature. Overall, our findings provide a new method to quantify the complexity of brain activity by studying its temporal evolution on a low-dimensional manifold, suggesting insights that are invisible to traditional methodologies in the contexts of speech and music perception. Understanding how the human brain processes speech and music is a fascinating and complex challenge. Our study explores how brain activity changes when people listen to naturalistic speech compared to when they listen to music or when they are at rest. We found that both speech and music engage the brain in more complex patterns of activity than rest, with speech leading to even greater complexity. To achieve this, we used a novel method to study the brain&#39;s activity in a simplified, low-dimensional space, representing the dynamical evolution of brain activity across different regions. This approach highlights the demands placed on brain function during the perception of speech and music, providing new insights into how we process these auditory experiences.},
  archive      = {J_NETN},
  author       = {Runfola, Claudio and Neri, Matteo and Schön, Daniele and Morillon, Benjamin and Trébuchon, Agnès and Rabuffo, Giovanni and Sorrentino, Pierpaolo and Jirsa, Viktor},
  doi          = {10.1162/netn_a_00422},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {146-158},
  shortjournal = {Netw. Neuroscience},
  title        = {Complexity in speech and music listening via neural manifold flows},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic brain states underlying advanced concentrative
absorption meditation: A 7-t fMRI-intensive case study. <em>NETN</em>,
<em>9</em>(1), 125–145. (<a
href="https://doi.org/10.1162/netn_a_00432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced meditation consists of states and stages of practice that unfold with mastery and time. Dynamic functional connectivity (DFC) analysis of fMRI could identify brain states underlying advanced meditation. We conducted an intensive DFC case study of a meditator who completed 27 runs of jhāna advanced absorptive concentration meditation (ACAM-J), concurrently with 7-T fMRI and phenomenological reporting. We identified three brain states that marked differences between ACAM-J and nonmeditative control conditions. These states were characterized as a DMN-anticorrelated brain state, a hyperconnected brain state, and a sparsely connected brain state. Our analyses indicate higher prevalence of the DMN-anticorrelated brain state during ACAM-J than control states, and the prevalence increased significantly with deeper ACAM-J states. The hyperconnected brain state was also more common during ACAM-J and was characterized by elevated thalamocortical connectivity and somatomotor network connectivity. The hyperconnected brain state significantly decreased over the course of ACAM-J, associating with self-reports of wider attention and diminished physical sensations. This brain state may be related to sensory awareness. Advanced meditators have developed well-honed abilities to move in and out of different altered states of consciousness, and this study provides initial evidence that functional neuroimaging can objectively track their dynamics. Advanced meditation research investigates states and stages of practice that unfold with increasing mastery and time, which may include altered states of consciousness such as a diminished sense of self. In the current study, we examined a 7-T fMRI case study of jhāna , an advanced concentrative absorptive meditation (ACAM-J). Specifically, we examined the temporal properties of dynamic connectivity brain states that could reflect mental states and phenomena during ACAM-J. We identified two brain states that were more prevalent during ACAM-J than control conditions. One state, involving default-mode network anticorrelations with the rest of the brain, increased across ACAM-J. Another state, involving hyperconnectivity across many cortical networks, was correlated with reports of narrow attention and greater sensory awareness, as well as diminished across ACAM-J.},
  archive      = {J_NETN},
  author       = {Treves, Isaac N. and Yang, Winson F. Z. and Sparby, Terje and Sacchet, Matthew D.},
  doi          = {10.1162/netn_a_00432},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {125-145},
  shortjournal = {Netw. Neuroscience},
  title        = {Dynamic brain states underlying advanced concentrative absorption meditation: A 7-T fMRI-intensive case study},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cell-type-specific contributions to theta-gamma coupled
rhythms in the hippocampus. <em>NETN</em>, <em>9</em>(1), 100–124. (<a
href="https://doi.org/10.1162/netn_a_00427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distinct inhibitory cell types participate in cognitively relevant nested brain rhythms, and particular changes in such rhythms are known to occur in disease states. Specifically, the coexpression of theta and gamma rhythms in the hippocampus is believed to represent a general coding scheme, but cellular-based generation mechanisms for these coupled rhythms are currently unclear. We develop a population rate model of the CA1 hippocampus that encompasses circuits of three inhibitory cell types (bistratified cells and parvalbumin [PV]-expressing and cholecystokinin [CCK]-expressing basket cells) and pyramidal cells to examine this. We constrain parameters and perform numerical and theoretical analyses. The theory, in combination with the numerical explorations, predicts circuit motifs and specific cell-type mechanisms that are essential for the coexistence of theta and gamma oscillations. We find that CCK-expressing basket cells initiate the coupled rhythms and regularize theta, and PV-expressing basket cells enhance both theta and gamma rhythms. Pyramidal and bistratified cells govern the generation of theta rhythms, and PV-expressing basket and pyramidal cells play dominant roles in controlling theta frequencies. Our circuit motifs for the theta-gamma coupled rhythm generation could be applicable to other brain regions. There are many different types of inhibitory cells in our brains that are differentially affected in disease. Concomitantly, coupled rhythms change in particular ways with disease. To help understand cell-type-specific changes in coupled rhythms, we develop a mathematical network model that is both respective of the cell type and also amenable to analyses. We focus on theta-gamma coupled rhythms in the hippocampus and include three different inhibitory cell types in our model circuits. By combining a theoretical analysis and numerical explorations, we find distinct contributions of these inhibitory cell types to coupled rhythms and predict motifs that are essential for the expression of theta-gamma coupled rhythms. Moving forward, we can leverage our model insights to help unravel cell-type contributions in disease states.},
  archive      = {J_NETN},
  author       = {Sengupta, Spandan and Talidou, Afroditi and Lefebvre, Jeremie and Skinner, Frances K.},
  doi          = {10.1162/netn_a_00427},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {100-124},
  shortjournal = {Netw. Neuroscience},
  title        = {Cell-type-specific contributions to theta-gamma coupled rhythms in the hippocampus},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The control costs of human brain dynamics. <em>NETN</em>,
<em>9</em>(1), 77–99. (<a
href="https://doi.org/10.1162/netn_a_00425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain is a complex system with high metabolic demands and extensive connectivity that requires control to balance energy consumption and functional efficiency over time. How this control is manifested on a whole-brain scale is largely unexplored, particularly what the associated costs are. Using the network control theory, here, we introduce a novel concept, time-averaged control energy (TCE), to quantify the cost of controlling human brain dynamics at rest, as measured from functional and diffusion MRI. Importantly, TCE spatially correlates with oxygen metabolism measures from the positron emission tomography, providing insight into the bioenergetic footing of resting-state control. Examining the temporal dimension of control costs, we find that brain state transitions along a hierarchical axis from sensory to association areas are more efficient in terms of control costs and more frequent within hierarchical groups than between. This inverse correlation between temporal control costs and state visits suggests a mechanism for maintaining functional diversity while minimizing energy expenditure. By unpacking the temporal dimension of control costs, we contribute to the neuroscientific understanding of how the brain governs its functionality while managing energy expenses. Understanding how the brain balances functional efficiency with energy conservation is a central question in neuroscience. The network control theory (NCT) views this question from a network perspective where the brain manages signal propagations along its structural connections to transition across desired activity states. Our study thus presents a novel framework based on the NCT to analyze the costs associated with transitioning across resting states, revealing that regions with high control costs on average are also metabolically demanding in terms of oxygen use. Our findings further show that transitions between sensory and association states are infrequent due to high control costs, while transitions within these states are more common. This suggests that the brain employs a mechanism to preserve functional diversity while minimizing energy costs.},
  archive      = {J_NETN},
  author       = {Ceballos, Eric G. and Luppi, Andrea I. and Castrillon, Gabriel and Saggar, Manish and Misic, Bratislav and Riedl, Valentin},
  doi          = {10.1162/netn_a_00425},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {77-99},
  shortjournal = {Netw. Neuroscience},
  title        = {The control costs of human brain dynamics},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A telescopic independent component analysis on functional
magnetic resonance imaging dataset. <em>NETN</em>, <em>9</em>(1), 61–76.
(<a href="https://doi.org/10.1162/netn_a_00421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain function can be modeled as dynamic interactions between functional sources at different spatial scales, and each spatial scale can contain its functional sources with unique information, thus using a single scale may provide an incomplete view of brain function. This paper introduces a novel approach, termed “telescopic independent component analysis (TICA),” designed to construct spatial functional hierarchies and estimate functional sources across multiple spatial scales using fMRI data. The method employs a recursive independent component analysis (ICA) strategy, leveraging information from a larger network to guide the extraction of information about smaller networks. We apply our model to the default mode network (DMN), visual network (VN), and right frontoparietal network (RFPN). We investigate further on the DMN by evaluating the difference between healthy people and individuals with schizophrenia. We show that the TICA approach can detect the spatial hierarchy of the DMN, VN, and RFPN. In addition, the TICA revealed DMN-associated group differences between cohorts that may not be captured if we focus on a single-scale ICA. In sum, our proposed approach represents a promising new tool for studying functional sources.},
  archive      = {J_NETN},
  author       = {Mirzaeian, Shiva and Faghiri, Ashkan and Calhoun, Vince D. and Iraji, Armin},
  doi          = {10.1162/netn_a_00421},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {61-76},
  shortjournal = {Netw. Neuroscience},
  title        = {A telescopic independent component analysis on functional magnetic resonance imaging dataset},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tangent space functional reconfigurations in individuals at
risk for alcohol use disorder. <em>NETN</em>, <em>9</em>(1), 38–60. (<a
href="https://doi.org/10.1162/netn_a_00419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human brain function dynamically adjusts to ever-changing stimuli from the external environment. Studies characterizing brain functional reconfiguration are, nevertheless, scarce. Here, we present a principled mathematical framework to quantify brain functional reconfiguration when engaging and disengaging from a stop signal task (SST). We apply tangent space projection (a Riemannian geometry mapping technique) to transform the functional connectomes (FCs) of 54 participants and quantify functional reconfiguration using the correlation distance of the resulting tangent-FCs. Our goal was to compare functional reconfigurations in individuals at risk for alcohol use disorder (AUD). We hypothesized that functional reconfigurations when transitioning to/from a task would be influenced by family history of AUD (FHA) and other AUD risk factors. Multilinear regression models showed that engaging and disengaging functional reconfiguration were associated with FHA and recent drinking. When engaging in the SST after a rest condition, functional reconfiguration was negatively associated with recent drinking, while functional reconfiguration when disengaging from the SST was negatively associated with FHA. In both models, several other factors contributed to the functional reconfiguration. This study demonstrates that tangent-FCs can characterize task-induced functional reconfiguration and that it is related to AUD risk. Human brain function constantly adapts to the external environment stimuli and transitions between cognitive states, which can be hindered by alcohol misuse and family history of alcohol use disorder (AUD). In this work, we used a novel methodology that applies Riemannian geometry concepts to functional connectivity to quantify functional reconfiguration of rest-to-task (engaging) and task-to-rest (disengaging) transitions. We ultimately aimed to determine the relationship between AUD risk factors and functional reconfiguration. Our findings showed that engaging functional reconfiguration was diminished in participants with a family history of AUD, whereas disengaging functional reconfiguration was diminished with greater recent drinking behavior. This study suggests that analysis of functional reconfiguration using Riemannian geometry is a promising avenue to better understand rest-to-task and task-to-rest brain transitions.},
  archive      = {J_NETN},
  author       = {Moghaddam, Mahdi and Dzemidzic, Mario and Guerrero, Daniel and Liu, Mintao and Alessi, Jonathan and Plawecki, Martin H. and Harezlak, Jaroslaw and Kareken, David A. and Goñi, Joaquín},
  doi          = {10.1162/netn_a_00419},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {38-60},
  shortjournal = {Netw. Neuroscience},
  title        = {Tangent space functional reconfigurations in individuals at risk for alcohol use disorder},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Localization of the epileptogenic network from scalp EEG
using a patient-specific whole-brain model. <em>NETN</em>,
<em>9</em>(1), 18–37. (<a
href="https://doi.org/10.1162/netn_a_00418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational modeling is a key tool for elucidating the neuronal mechanisms underlying epileptic activity. Despite considerable progress, existing models often lack realistic accuracy in representing electrophysiological epileptic activity. In this study, we used a comprehensive human brain model based on a neural mass model, which is tailored to the layered structure of the neocortex and incorporates patient-specific imaging data. This approach allowed the simulation of scalp EEGs in an epileptic patient suffering from type 2 focal cortical dysplasia (FCD). The simulation specifically addressed epileptic activity induced by FCD, faithfully reproducing intracranial interictal epileptiform discharges (IEDs) recorded with electrocorticography. For constructing the patient-specific scalp EEG, we carefully defined a clear delineation of the epileptogenic zone by numerical simulations to ensure fidelity to the topography, polarity, and diffusion characteristics of IEDs. This nuanced approach improves the accuracy of the simulated EEG signal, provides a more accurate representation of epileptic activity, and enhances our understanding of the mechanism behind the epileptogenic networks. The accuracy of the model was confirmed by a postoperative reevaluation with a secondary EEG simulation that was consistent with the lesion’s removal. Ultimately, this personalized approach may prove instrumental in optimizing and tailoring epilepsy treatment strategies. This study aimed to create a neurophysiologically grounded computer model of focal epilepsy. This is a feature frequently lacking to simulations in this domain, making the translation from in silico to in vivo results questionable and difficult to understand for clinical electrophysiologists. We adapted a whole-brain neuronal mass model for EEG generation in various conscious states to replicate the EEG patterns of a type 2 focal cortical dysplasia (FCD), a condition associated with epilepsy. Our model successfully simulated both intracranial and scalp EEGs of a complex patient with type 2 FCD, who was later cured through surgery. Importantly, the simulated lesion location matched the patient’s epileptogenic zone, and removing this area in the model eliminated epileptic activity in the EEG, demonstrating the model’s accuracy.},
  archive      = {J_NETN},
  author       = {Maliia, Mihai Dragos and Köksal-Ersöz, Elif and Benard, Adrien and Calas, Tristan and Nica, Anca and Denoyer, Yves and Yochum, Maxime and Wendling, Fabrice and Benquet, Pascal},
  doi          = {10.1162/netn_a_00418},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {18-37},
  shortjournal = {Netw. Neuroscience},
  title        = {Localization of the epileptogenic network from scalp EEG using a patient-specific whole-brain model},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thalamocortical interactions reflecting the intensity of
flicker light–induced visual hallucinatory phenomena. <em>NETN</em>,
<em>9</em>(1), 1–17. (<a
href="https://doi.org/10.1162/netn_a_00417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aberrant thalamocortical connectivity occurs together with visual hallucinations in various pathologies and drug-induced states, highlighting the need to better understand how thalamocortical interactions may contribute to hallucinatory phenomena. Flicker light stimulation (FLS) at 10-Hz reliably and selectively induces transient visual hallucinations in healthy participants. Arrhythmic flicker elicits fewer hallucinatory effects while delivering equal amounts of visual stimulation, together facilitating a well-controlled experimental setup to investigate the neural correlates of visual hallucinations driven by flicker rhythmicity. Using rhythmic and arrhythmic FLS during fMRI scanning, we found that rhythmic FLS elicited stronger activation in higher order visual cortices compared with arrhythmic control. Consistently, we found that rhythmic flicker selectively increased connectivity between ventroanterior thalamic nuclei and higher order visual cortices, which was also positively associated with the subjective intensity of visual hallucinatory effects. As these thalamic and cortical areas do not receive primary visual inputs, it suggests that the thalamocortical connectivity changes relate to a higher order function of the thalamus, such as in the coordination of cortical activity. In sum, we present novel evidence for the role of specific thalamocortical interactions with ventroanterior nuclei within visual hallucinatory experiences. Importantly, this can inform future clinical research into the mechanistic underpinnings of pathologic hallucinations. Flicker light stimulation induces an intense transient experience of elementary visual hallucinations, such as colored geometric patterns, that has phenomenal similarities to the visual experience induced by psychedelic drugs or during psychopathology. During fMRI scanning, we found that increased connectivity between ventroanterior thalamic nuclei and higher order visual cortices was associated with the reported intensity of the flicker-induced visual effects. Our results suggest that the role of thalamocortical hyperconnectivity during hallucinatory experiences may relate to a higher order function of the thalamus, such as the regulation of cortical activity. This novel finding results from a highly controlled experimental setup, which can be extended to inform the mechanistic underpinnings of hallucinatory experiences during psychopathology.},
  archive      = {J_NETN},
  author       = {Amaya, Ioanna A. and Nierhaus, Till and Schmidt, Timo T.},
  doi          = {10.1162/netn_a_00417},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Netw. Neuroscience},
  title        = {Thalamocortical interactions reflecting the intensity of flicker light–induced visual hallucinatory phenomena},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="tacl---9">TACL - 9</h2>
<ul>
<li><details>
<summary>
(2025). Transformers as transducers. <em>TACL</em>, <em>13</em>,
200–219. (<a href="https://doi.org/10.1162/tacl_a_00736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the sequence-to-sequence mapping capacity of transformers by relating them to finite transducers, and find that they can express surprisingly large classes of (total functional) transductions. We do so using variants of RASP, a programming language designed to help people “think like transformers,” as an intermediate representation. We extend the existing Boolean variant B-RASP to sequence-to-sequence transductions and show that it computes exactly the first-order rational transductions (such as string rotation). Then, we introduce two new extensions. B-RASP[ pos ] enables calculations on positions (such as copying the first half of a string) and contains all first-order regular transductions. S-RASP adds prefix sum, which enables additional arithmetic operations (such as squaring a string) and contains all first-order polyregular transductions. Finally, we show that masked average-hard attention transformers can simulate S-RASP.},
  archive      = {J_TACL},
  author       = {Strobl, Lena and Angluin, Dana and Chiang, David and Rawski, Jonathan and Sabharwal, Ashish},
  doi          = {10.1162/tacl_a_00736},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {200-219},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Transformers as transducers},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OPT-tree: Speculative decoding with adaptive draft tree
structure. <em>TACL</em>, <em>13</em>, 188–199. (<a
href="https://doi.org/10.1162/tacl_a_00735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoregressive language models demonstrate excellent performance in various scenarios. However, the inference efficiency is limited by its one-step-one-word generation mode, which has become a pressing problem recently as the models become increasingly larger. Speculative decoding employs a “draft and then verify” mechanism to allow multiple tokens to be generated in one step, realizing lossless acceleration. Existing methods mainly adopt fixed heuristic draft structures, which do not adapt to different situations to maximize the acceptance length during verification. To alleviate this dilemma, we propose OPT-Tree, an algorithm to construct adaptive and scalable draft trees, which can be applied to any autoregressive draft model. It searches the optimal tree structure that maximizes the mathematical expectation of the acceptance length in each decoding step. Experimental results reveal that OPT-Tree outperforms the existing draft structures and achieves a speed-up ratio of up to 3.2 compared with autoregressive decoding. If the draft model is powerful enough and the node budget is sufficient, it can generate more than ten tokens in a single step. Our code is available at https://github.com/Jikai0Wang/OPT-Tree .},
  archive      = {J_TACL},
  author       = {Wang, Jikai and Su, Yi and Li, Juntao and Xia, Qingrong and Ye, Zi and Duan, Xinyu and Wang, Zhefeng and Zhang, Min},
  doi          = {10.1162/tacl_a_00735},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {188-199},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {OPT-tree: Speculative decoding with adaptive draft tree structure},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A confidence-based acquisition model for self-supervised
active learning and label correction. <em>TACL</em>, <em>13</em>,
167–187. (<a href="https://doi.org/10.1162/tacl_a_00734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised neural approaches are hindered by their dependence on large, meticulously annotated datasets, a requirement that is particularly cumbersome for sequential tasks. The quality of annotations tends to deteriorate with the transition from expert-based to crowd-sourced labeling. To address these challenges, we present CAMEL ( C onfidence-based A cquisition M odel for E fficient self-supervised active L earning), a pool-based active learning framework tailored to sequential multi-output problems. CAMEL possesses two core features: (1) it requires expert annotators to label only a fraction of a chosen sequence, and (2) it facilitates self-supervision for the remainder of the sequence. By deploying a label correction mechanism, CAMEL can also be utilized for data cleaning. We evaluate CAMEL on two sequential tasks, with a special emphasis on dialogue belief tracking, a task plagued by the constraints of limited and noisy datasets. Our experiments demonstrate that CAMEL significantly outperforms the baselines in terms of efficiency. Furthermore, the data corrections suggested by our method contribute to an overall improvement in the quality of the resulting datasets. 1},
  archive      = {J_TACL},
  author       = {Niekerk, Carel van and Geishauser, Christian and Heck, Michael and Feng, Shutong and Lin, Hsien-chin and Lubis, Nurul and Ruppik, Benjamin and Vukovic, Renato and Gašić, Milica},
  doi          = {10.1162/tacl_a_00734},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {167-187},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {A confidence-based acquisition model for self-supervised active learning and label correction},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning syntax without planting trees: Understanding
hierarchical generalization in transformers. <em>TACL</em>, <em>13</em>,
121–141. (<a href="https://doi.org/10.1162/tacl_a_00733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers trained on natural language data have been shown to exhibit hierarchical generalization without explicitly encoding any structural bias. In this work, we investigate sources of inductive bias in transformer models and their training that could cause such preference for hierarchical generalization. We extensively experiment with transformers trained on five synthetic, controlled datasets using several training objectives and show that, while objectives such as sequence-to-sequence modeling, classification, etc., often fail to lead to hierarchical generalization, the language modeling objective consistently leads to transformers generalizing hierarchically. We then study how different generalization behaviors emerge during the training by conducting pruning experiments that reveal the joint existence of subnetworks within the model implementing different generalizations. Finally, we take a Bayesian perspective to understand transformers’ preference for hierarchical generalization: We establish a correlation between whether transformers generalize hierarchically on a dataset and if the simplest explanation of that dataset is provided by a hierarchical grammar compared to regular grammars exhibiting linear generalization. Overall, our work presents new insights on the origins of hierarchical generalization in transformers and provides a theoretical framework for studying generalization in language models.},
  archive      = {J_TACL},
  author       = {Ahuja, Kabir and Balachandran, Vidhisha and Panwar, Madhur and He, Tianxing and Smith, Noah A. and Goyal, Navin and Tsvetkov, Yulia},
  doi          = {10.1162/tacl_a_00733},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {121-141},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Learning syntax without planting trees: Understanding hierarchical generalization in transformers},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating critical period effects in language
acquisition through neural language models. <em>TACL</em>, <em>13</em>,
96–120. (<a href="https://doi.org/10.1162/tacl_a_00725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans appear to have a critical period (CP) for language acquisition: Second language (L 2 ) acquisition becomes harder after early childhood, and ceasing exposure to a first language (L 1 ) after this period (but not before) typically does not lead to substantial loss of L 1 proficiency. It is unknown whether these CP effects result from innately determined brain maturation or as a stabilization of neural connections naturally induced by experience. In this study, we use language models (LMs) to test the extent to which these phenomena are peculiar to humans, or shared by a broader class of language learners. We vary the age of exposure by training LMs on language pairs in various experimental conditions, and find that LMs, which lack any direct analog to innate maturational stages, do not show CP effects when the age of exposure of L 2 is delayed. Our results contradict the claim that CP effects are an inevitable result of statistical learning, and they are consistent with an innate mechanism for CP effects. We show that we can reverse-engineer the CP by introducing a regularizer partway through training to simulate a maturational decrease in plasticity. All in all, our results suggest that L 1 learning on its own may not be enough to induce a CP, and additional engineering is necessary to make language models more cognitively plausible.},
  archive      = {J_TACL},
  author       = {Constantinescu, Ionut and Pimentel, Tiago and Cotterell, Ryan and Warstadt, Alex},
  doi          = {10.1162/tacl_a_00725},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {96-120},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Investigating critical period effects in language acquisition through neural language models},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Salute the classic: Revisiting challenges of machine
translation in the age of large language models. <em>TACL</em>,
<em>13</em>, 73–95. (<a
href="https://doi.org/10.1162/tacl_a_00730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of Neural Machine Translation (NMT) has been significantly influenced by six core challenges (Koehn and Knowles, 2017 ) that have acted as benchmarks for progress in this field. This study revisits these challenges, offering insights into their ongoing relevance in the context of advanced Large Language Models (LLMs): domain mismatch , amount of parallel data , rare word prediction , translation of long sentences , attention model as word alignment , and sub-optimal beam search . Our empirical findings show that LLMs effectively reduce reliance on parallel data for major languages during pretraining and significantly improve translation of long sentences containing approximately 80 words, even translating documents up to 512 words. Despite these improvements, challenges in domain mismatch and rare word prediction persist. While NMT-specific challenges like word alignment and beam search may not apply to LLMs, we identify three new challenges in LLM-based translation: inference efficiency, translation of low-resource languages during pretraining, and human-aligned evaluation.},
  archive      = {J_TACL},
  author       = {Pang, Jianhui and Ye, Fanghua and Wong, Derek Fai and Yu, Dian and Shi, Shuming and Tu, Zhaopeng and Wang, Longyue},
  doi          = {10.1162/tacl_a_00730},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {73-95},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Salute the classic: Revisiting challenges of machine translation in the age of large language models},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLAPnq: Cohesive long-form answers from passages in natural
questions for RAG systems. <em>TACL</em>, <em>13</em>, 53–72. (<a
href="https://doi.org/10.1162/tacl_a_00729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieval Augmented Generation (RAG) has become a popular application for large language models. It is preferable that successful RAG systems provide accurate answers that are supported by being grounded in a passage without any hallucinations. While considerable work is required for building a full RAG pipeline, being able to benchmark performance is also necessary. We present CLAPnq , a benchmark Long-form Question Answering dataset for the full RAG pipeline. CLAPnq includes long answers with grounded gold passages from Natural Questions (NQ) and a corpus to perform either retrieval, generation, or the full RAG pipeline. The CLAPnq answers are concise , 3x smaller than the full passage, and cohesive , meaning that the answer is composed fluently, often by integrating multiple pieces of the passage that are not contiguous. RAG models must adapt to these properties to be successful at CLAPnq . We present baseline experiments and analysis for CLAPnq that highlight areas where there is still significant room for improvement in grounded RAG. CLAPnq is publicly available at https://github.com/primeqa/clapnq .},
  archive      = {J_TACL},
  author       = {Rosenthal, Sara and Sil, Avirup and Florian, Radu and Roukos, Salim},
  doi          = {10.1162/tacl_a_00729},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {53-72},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {CLAPnq: Cohesive long-form answers from passages in natural questions for RAG systems},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SpiRit-LM: Interleaved spoken and written language model.
<em>TACL</em>, <em>13</em>, 30–52. (<a
href="https://doi.org/10.1162/tacl_a_00728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce SpiRit-LM , a foundation multimodal language model that freely mixes text and speech. Our model is based on a 7B pretrained text language model that we extend to the speech modality by continuously training it on text and speech units. Speech and text sequences are concatenated as a single stream of tokens, and trained with a word-level interleaving method using a small automatically curated speech-text parallel corpus. SpiRit-LM comes in two versions: a Base version that uses speech phonetic units (HuBERT) and an Expressive version that models expressivity using pitch and style units in addition to the phonetic units. For both versions, the text is encoded with subword BPE tokens. The resulting model displays both the semantic abilities of text models and the expressive abilities of speech models. Additionally, we demonstrate that SpiRit-LM can learn new tasks in a few-shot fashion across modalities (i.e., ASR, TTS, Speech Classification). We make available model weights and inference code. 1 , 2},
  archive      = {J_TACL},
  author       = {Nguyen, Tu Anh and Muller, Benjamin and Yu, Bokai and Costa-jussa, Marta R. and Elbayad, Maha and Popuri, Sravya and Ropers, Christophe and Duquenne, Paul-Ambroise and Algayres, Robin and Mavlyutov, Ruslan and Gat, Itai and Williamson, Mary and Synnaeve, Gabriel and Pino, Juan and Sagot, Benoît and Dupoux, Emmanuel},
  doi          = {10.1162/tacl_a_00728},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {30-52},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {SpiRit-LM: Interleaved spoken and written language model},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dolomites: Domain-specific long-form methodical tasks.
<em>TACL</em>, <em>13</em>, 1–29. (<a
href="https://doi.org/10.1162/tacl_a_00727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experts in various fields routinely perform methodical writing tasks to plan, organize, and report their work. From a clinician writing a differential diagnosis for a patient, to a teacher writing a lesson plan for students, these tasks are pervasive, requiring to methodically generate structured long-form output for a given input. We develop a typology of methodical tasks structured in the form of a task objective, procedure, input, and output, and introduce DoLoMiTes, a novel benchmark with specifications for 519 such tasks elicited from hundreds of experts from across 25 fields. Our benchmark further contains specific instantiations of methodical tasks with concrete input and output examples (1,857 in total) which we obtain by collecting expert revisions of up to 10 model-generated examples of each task. We use these examples to evaluate contemporary language models, highlighting that automating methodical tasks is a challenging long-form generation problem, as it requires performing complex inferences, while drawing upon the given context as well as domain knowledge. Our dataset is available at https://dolomites-benchmark.github.io/ .},
  archive      = {J_TACL},
  author       = {Malaviya, Chaitanya and Agrawal, Priyanka and Ganchev, Kuzman and Srinivasan, Pranesh and Huot, Fantine and Berant, Jonathan and Yatskar, Mark and Das, Dipanjan and Lapata, Mirella and Alberti, Chris},
  doi          = {10.1162/tacl_a_00727},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {1-29},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Dolomites: Domain-specific long-form methodical tasks},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="tmlr---102">TMLR - 102</h2>
<ul>
<li><details>
<summary>
(2025). KAGNNs: Kolmogorov-arnold networks meet graph learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=03UB1MCAMr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Graph Neural Networks (GNNs) have become the de facto tool for learning node and graph representations. Most GNNs typically consist of a sequence of neighborhood aggregation (a.k.a., message-passing) layers, within which the representation of each node is updated based on those of its neighbors. The most expressive message-passing GNNs can be obtained through the use of the sum aggregator and of MLPs for feature transformation, thanks to their universal approximation capabilities. However, the limitations of MLPs recently motivated the introduction of another family of universal approximators, called Kolmogorov-Arnold Networks (KANs) which rely on a different representation theorem. In this work, we compare the performance of KANs against that of MLPs on graph learning tasks. We implement three new KAN-based GNN layers, inspired respectively by the GCN, GAT and GIN layers. We evaluate two different implementations of KANs using two distinct base families of functions, namely B-splines and radial basis functions. We perform extensive experiments on node classification, link prediction, graph classification and graph regression datasets. Our results indicate that KANs are on-par with or better than MLPs on all tasks studied in this paper. We also show that the size and training speed of RBF-based KANs is only marginally higher than for MLPs, making them viable alternatives. Code available at https://github.com/RomanBresson/KAGNN.},
  archive      = {J_TMLR},
  author       = {Roman Bresson and Giannis Nikolentzos and George Panagopoulos and Michail Chatzianastasis and Jun Pang and Michalis Vazirgiannis},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {KAGNNs: Kolmogorov-arnold networks meet graph learning},
  url          = {https://openreview.net/forum?id=03UB1MCAMr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). No need for ad-hoc substitutes: The expected cost is a
principled all-purpose classification metric. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5PPbvCExZs">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected cost (EC) is one of the main classification metrics introduced in statistical and machine learning books. It is based on the assumption that, for a given application of interest, each decision made by the system has a corresponding cost which depends on the true class of the sample. An evaluation metric can then be defined by taking the expectation of the cost over the data. Two special cases of the EC are widely used in the machine learning literature: the error rate (one minus the accuracy) and the balanced error rate (one minus the balanced accuracy or unweighted average recall). Other instances of the EC can be useful for applications in which some types of errors are more severe than others, or when the prior probabilities of the classes differ between the evaluation data and the use-case scenario. Surprisingly, the general form for the EC is rarely used in the machine learning literature. Instead, alternative ad-hoc metrics like the F-beta score and the Matthews correlation coefficient (MCC) are used for many applications. In this work, we argue that the EC is superior to these alternative metrics, being more general, interpretable, and adaptable to any application scenario. We provide both theoretically-motivated discussions as well as examples to illustrate the behavior of the different metrics.},
  archive      = {J_TMLR},
  author       = {Luciana Ferrer},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {No need for ad-hoc substitutes: The expected cost is a principled all-purpose classification metric},
  url          = {https://openreview.net/forum?id=5PPbvCExZs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing fairness in unsupervised graph anomaly detection
through disentanglement. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5zRs34Ls3C">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection (GAD) is becoming increasingly crucial in various applications, ranging from financial fraud detection to fake news detection. However, current GAD methods largely overlook the fairness problem, which might result in discriminatory decisions skewed toward certain demographic groups defined on sensitive attributes (e.g., gender). This greatly limits the applicability of these methods in real-world scenarios in light of societal and ethical restrictions. To address this critical gap, we make the first attempt to integrate fairness with utility in GAD decision-making. Specifically, we devise a novel DisEntangle-based FairnEss-aware aNomaly Detection framework on the attributed graph, named DEFEND. DEFEND first introduces disentanglement in GNNs to capture informative yet sensitive-irrelevant node representations, effectively reducing bias inherent in graphrepresentation learning. Besides, to alleviate discriminatory bias in evaluating anomalies, DEFEND adopts a reconstruction-based method, which concentrates solely on node attributes and avoids incorporating biased graph topology. Additionally, given the inherent association between sensitive-relevant and -irrelevant attributes, DEFEND further constrains the correlation between the reconstruction error and predicted sensitive attributes. Empirical evaluations on real-world datasets reveal that DEFEND performs effectively in GAD and significantly enhances fairness compared to state-of-the-art baselines. Our code is available at https://github.com/AhaChang/DEFEND.},
  archive      = {J_TMLR},
  author       = {Wenjing Chang and Kay Liu and Philip S. Yu and Jianjun Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing fairness in unsupervised graph anomaly detection through disentanglement},
  url          = {https://openreview.net/forum?id=5zRs34Ls3C},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DP-2Stage: Adapting language models as differentially
private tabular data generators. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=6nBIweDYzZ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating tabular data under differential privacy (DP) protection ensures theoretical privacy guarantees but poses challenges for training machine learning models, primarily due to the need to capture complex structures under noisy supervision signals. Recently, pre-trained Large Language Models (LLMs) -- even those at the scale of GPT-2 -- have demonstrated great potential in synthesizing tabular data. However, their applications under DP constraints remain largely unexplored. In this work, we address this gap by applying DP techniques to the generation of synthetic tabular data. Our findings shows that LLMs face difficulties in generating coherent text when fine-tuned with DP, as privacy budgets are inefficiently allocated to non-private elements like table structures. To overcome this, we propose DP-2Stage, a two-stage fine-tuning framework for differentially private tabular data generation. The first stage involves non-private fine-tuning on a pseudo dataset, followed by DP fine-tuning on a private dataset. Our empirical results show that this approach improves performance across various settings and metrics compared to directly fine-tuned LLMs in DP contexts. We release our code and setup at https://github.com/tejuafonja/DP-2Stage.},
  archive      = {J_TMLR},
  author       = {Tejumade Afonja and Hui-Po Wang and Raouf Kerkouche and Mario Fritz},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DP-2Stage: Adapting language models as differentially private tabular data generators},
  url          = {https://openreview.net/forum?id=6nBIweDYzZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-explainable heterogeneous GNN for relational deep
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8Q4qxe9a9Z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, significant attention has been given to the idea of viewing relational databases as heterogeneous graphs, enabling the application of graph neural network (GNN) technology for predictive tasks. However, existing GNN methods struggle with the complexity of the heterogeneous graphs induced by databases with numerous tables and relations. Traditional approaches either consider all possible relational meta-paths, thus failing to scale with the number of relations, or rely on domain experts to identify relevant meta-paths. A recent solution does manage to learn informative meta-paths without expert supervision, but assumes that a node’s class depends solely on the existence of a meta-path occurrence. In this work, we present a self-explainable heterogeneous GNN for relational data, that supports models in which class membership depends on aggregate information obtained from multiple occurrences of a meta-path. Experimental results show that in the context of relational databases, our approach effectively identifies informative meta-paths that faithfully capture the model’s reasoning mechanisms. It significantly outperforms existing methods in both synthetic and real-world scenarios.},
  archive      = {J_TMLR},
  author       = {Francesco Ferrini and Antonio Longa and Andrea Passerini and Manfred Jaeger},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A self-explainable heterogeneous GNN for relational deep learning},
  url          = {https://openreview.net/forum?id=8Q4qxe9a9Z},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long short-term imputer: Handling consecutive missing values
in time series. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=9NVJ0ZgEfT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encountered frequently in time series data, missing values can significantly impede time-series analysis. With the progression of deep learning, advanced imputation models delve into the temporal dependencies inherent in time series data, showcasing remarkable performance. This positions them as intuitive selections for time series imputation tasks which assume ``Miss Completely at Random&#39;&#39;. Nonetheless, long-interval consecutive missing values may obstruct the model&#39;s ability to grasp long-term temporal dependencies, consequently hampering the efficacy of imputation performance. To tackle this challenge, we propose Long Short-term Imputer (LSTI) to impute consecutive missing values with different length of intervals. Long-term Imputer is designed using the idea of bi-directional autoregression. A forward prediction model and a backward prediction model are trained with a consistency regularization, which is designed to capture long-time dependency and can adapt to long-interval consecutive missing values. Short-term Imputer is designed to capture short-time dependency and can impute the short-interval consecutive missing values effectively. A meta-weighting network is then proposed to take advantage of the strengths of two imputers. As a result, LSTI can impute consecutive missing values with different intervals effectively. Experiments demonstrate that our approach, on average, reduces the error by 57.4% compared to state-of-the-art deep models across five datasets.},
  archive      = {J_TMLR},
  author       = {Jiacheng You and Xinyang Chen and Yu Sun and Weili Guan and Liqiang Nie},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Long short-term imputer: Handling consecutive missing values in time series},
  url          = {https://openreview.net/forum?id=9NVJ0ZgEfT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The 2024 foundation model transparency index. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=38cwP8xVxD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models are increasingly consequential yet extremely opaque. To characterize the status quo, the Foundation Model Transparency Index was launched in October 2023 to measure the transparency of leading foundation model developers. The October 2023 Index (v1.0) assessed 10 major foundation model developers (e.g. OpenAI, Google) on 100 transparency indicators (e.g. does the developer disclose the wages it pays for data labor?). At the time, developers publicly disclosed very limited information with the average score being 37 out of 100. To understand how the status quo has changed, we conduct a follow-up study (v1.1) after 6 months: we score 14 developers against the same 100 indicators. While in v1.0 we searched for publicly available information, in v1.1 developers submit reports on the 100 transparency indicators, potentially including information that was not previously public. We find that developers now score 58 out of 100 on average, a 21 point improvement over v1.0. Much of this increase is driven by developers disclosing information during the v1.1 process: on average, developers disclosed information related to 16.6 indicators that was not previously public. We observe regions of sustained (i.e. across v1.0 and v1.1) and systemic (i.e. across most or all developers) opacity such as on copyright status, data access, data labor, and downstream impact. We publish transparency reports for each developer that consolidate information disclosures: these reports are based on the information disclosed to us via developers. Our findings demonstrate that transparency can be improved in this nascent ecosystem, the Foundation Model Transparency Index likely contributes to these improvements, and policymakers should consider interventions in areas where transparency has not improved.},
  archive      = {J_TMLR},
  author       = {Rishi Bommasani and Kevin Klyman and Sayash Kapoor and Shayne Longpre and Betty Xiong and Nestor Maslej and Percy Liang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The 2024 foundation model transparency index},
  url          = {https://openreview.net/forum?id=38cwP8xVxD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HARE: Human-in-the-loop algorithmic recourse. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=56EBglCFvx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are seeing increasing use as decision making systems in domains such as education, finance and healthcare. It is desirable that these models are trustworthy to the end-user, by ensuring fairness, transparency and reliability of decisions. In this work, we consider a key aspect of responsible and transparent AI models -- actionable explanations, viz. the ability of such models to provide recourse to end users adversely affected by their decisions. While algorithmic recourse has seen a variety of efforts in recent years, there have been very few efforts on exploring personalized recourse for a given user. Two users with the same feature profile may prefer vastly different recourses. The limited work in this direction hitherto rely on one-time feature preferences provided by a user. Instead, we present a human-in-the-loop formulation of algorithmic recourse that can incorporate both relative and absolute human feedback for a given test instance. We show that our formulation can extend any existing recourse generating method, enabling the generation of recourses that are satisfactory to the user. We perform experiments on 3 benchmark datasets on top of 6 popular baseline recourse methods where we observe that our framework performs significantly better on simulated user preferences.},
  archive      = {J_TMLR},
  author       = {Sai Srinivas Kancheti and Rahul Vigneswaran and Bamdev Mishra and Vineeth N. Balasubramanian},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HARE: Human-in-the-loop algorithmic recourse},
  url          = {https://openreview.net/forum?id=56EBglCFvx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolution of discriminator and generator gradients in GAN
training: From fitting to collapse. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=58gPkcVbFL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are powerful generative models but often suffer from mode mixture and mode collapse. We propose a perspective that views GAN training as a two-phase progression from fitting to collapse, where mode mixture and mode collapse are treated as inter-connected. Inspired by the particle model interpretation of GANs, we leverage the discriminator gradient to analyze particle movement and the generator gradient, specifically &quot;steepness,&quot; to quantify the severity of mode mixture by measuring the generator&#39;s sensitivity to changes in the latent space. Using these theoretical insights into evolution of gradients, we design a specialized metric that integrates both gradients to detect the transition from fitting to collapse. This metric forms the basis of an early stopping algorithm, which stops training at a point that retains sample quality and diversity. Experiments on synthetic and real-world datasets, including MNIST, Fashion MNIST, and CIFAR-10, validate our theoretical findings and demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_TMLR},
  author       = {Weiguo Gao and Ming Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evolution of discriminator and generator gradients in GAN training: From fitting to collapse},
  url          = {https://openreview.net/forum?id=58gPkcVbFL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The BrowserGym ecosystem for web agent research.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5298fKGmv3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The BrowserGym ecosystem addresses the growing need for efficient evaluation and benchmarking of web agents, particularly those leveraging automation and Large Language Models (LLMs) for web interaction tasks. Many existing benchmarks suffer from fragmentation and inconsistent evaluation methodologies, making it challenging to achieve reliable comparisons and reproducible results. In an earlier work, Drouin et al. (2024) introduced BrowserGym which aims to solve this by providing a unified, gym-like environment with well-defined observation and actionspaces, facilitating standardized evaluation across diverse benchmarks. We propose an extended BrowserGym-based ecosystem for web agent research, which unifies existing benchmarks from the literature and includes AgentLab, a complementary framework that aids in agent creation, testing, and analysis. Our proposed ecosystem offers flexibility for integrating new benchmarks while ensuring consistent evaluation and comprehensive experiment management. This standardized approach seeks to reduce the time and complexity of developing web agents, supporting more reliable comparisons and facilitating in-depth analysis of agent behaviors, and could result in more adaptable, capable agents, ultimately accelerating innovation in LLM-driven automation. As a supporting evidence, we conduct the first large-scale, multi-benchmark web agent experiment and compare the performance of 6 state-of-the-art LLMs across 6 popular web agent benchmarks made available in BrowserGym. Among other findings, our results highlight a large discrepancy between OpenAI and Anthropic’s latests models, with Claude-3.5-Sonnet leading the way on almost all benchmarks, except on vision-related tasks where GPT-4o is superior. Despite these advancements, our results emphasize that building robust and efficient web agents remains a significant challenge, due to the inherent complexity of real-world web environments and the limitations of current models.},
  archive      = {J_TMLR},
  author       = {Thibault Le Sellier de Chezelles and Maxime Gasse and Alexandre Lacoste and Massimo Caccia and Alexandre Drouin and Léo Boisvert and Megh Thakkar and Tom Marty and Rim Assouel and Sahar Omidi Shayegan and Lawrence Keunho Jang and Xing Han Lù and Ori Yoran and Dehan Kong and Frank F. Xu and Siva Reddy and Graham Neubig and Quentin Cappart and Russ Salakhutdinov and Nicolas Chapados},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The BrowserGym ecosystem for web agent research},
  url          = {https://openreview.net/forum?id=5298fKGmv3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing estimators of squared calibration errors in
classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=BPDVZajOW5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a mean-squared error-based risk that enables the comparison and optimization of estimators of squared calibration errors in practical settings. Improving the calibration of classifiers is crucial for enhancing the trustworthiness and interpretability of machine learning models, especially in sensitive decision-making scenarios. Although various calibration (error) estimators exist in the current literature, there is a lack of guidance on selecting the appropriate estimator and tuning its hyperparameters. By leveraging the bilinear structure of squared calibration errors, we reformulate calibration estimation as a regression problem with independent and identically distributed (i.i.d.) input pairs. This reformulation allows us to quantify the performance of different estimators even for the most challenging calibration criterion, known as canonical calibration. Our approach advocates for a training-validation-testing pipeline when estimating a calibration error on an evaluation dataset. We demonstrate the effectiveness of our pipeline by optimizing existing calibration estimators and comparing them with novel kernel ridge regression-based estimators on standard image classification tasks.},
  archive      = {J_TMLR},
  author       = {Sebastian Gregor Gruber and Francis R. Bach},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimizing estimators of squared calibration errors in classification},
  url          = {https://openreview.net/forum?id=BPDVZajOW5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lean dataset for international math olympiad: Small steps
towards writing math proofs for hard problems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CrKMqRAhBo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using AI to write formal proofs for mathematical problems is a challenging task that has seen some advancements in recent years. Automated systems such as Lean can verify the correctness of proofs written in formal language, yet writing the proofs in formal language can be challenging for humans and machines. The miniF2F benchmark has 20 IMO problems in its test set, yet formal proofs are available only for 6 of these problems (3 of which are only written by mathematicians). The model with best accuracy can only prove 2 of these 20 IMO problems, from 1950s and 60s, while its training set is a secret. In this work, we write complete, original formal proofs for the remaining IMO problems in Lean along with 3 extra problems from IMO 2022 and 2023. This effort expands the availability of proof currently in the public domain by creating 5,880 lines of Lean proof. The goal of the paper is to pave the way for developing AI models that can automatically write the formal proofs for all the IMO problems in miniF2F and beyond by providing an evaluation benchmark. In this pursuit, we devise a method to decompose the proofs of these problems into their building blocks, constructing a dataset of 1,329 lemmas with more than 40k lines of Lean code. These lemmas are not trivial, yet they are approachable, providing the opportunity to evaluate and diagnose the failures and successes of AI models. We evaluate the ability of the SOTA LLMs on our dataset and analyze their success and failure modes from different perspectives. Our dataset and code is available at: https://github.com/roozbeh-yz/IMO-Steps.},
  archive      = {J_TMLR},
  author       = {Roozbeh Yousefzadeh and Xuenan Cao},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A lean dataset for international math olympiad: Small steps towards writing math proofs for hard problems},
  url          = {https://openreview.net/forum?id=CrKMqRAhBo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual privacy auditing with diffusion models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=D3DA7pgpvn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data reconstruction attacks on machine learning models pose a substantial threat to privacy, potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) provides theoretical guarantees, determining appropriate DP parameters remains challenging. Current formal guarantees on the success of data reconstruction suffer from overly stringent assumptions regarding adversary knowledge about the target data, particularly in the image domain, raising questions about their real-world applicability. In this work, we empirically investigate this discrepancy by introducing a reconstruction attack based on diffusion models (DMs) that only assumes adversary access to real-world image priors and specifically targets the DP defense. We find that (1) real-world data priors significantly influence reconstruction success, (2) current reconstruction bounds do not model the risk posed by data priors well, and (3) DMs can serve as heuristic auditing tools for visualizing privacy leakage.},
  archive      = {J_TMLR},
  author       = {Kristian Schwethelm and Johannes Kaiser and Moritz Knolle and Sarah Lockfisch and Daniel Rueckert and Alexander Ziller},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Visual privacy auditing with diffusion models},
  url          = {https://openreview.net/forum?id=D3DA7pgpvn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out of spuriousity: Improving robustness to spurious
correlations without group annotations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EEeVYfXor5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are known to learn spurious correlations, i.e., features that have strong correlations with class labels but no causal relationship. Relying on these correlations leads to poor performance in data groups that do not contain these correlations, and poor generalization. Approaches to mitigate spurious correlations either rely on the availability of group annotations or require access to different model checkpoints to approximate these group annotations. We propose PruSC, a method for extracting a spurious-free subnetwork from a dense network. PruSC does not require prior knowledge of the spurious correlations and is able to mitigate the effect of multiple spurious attributes. Specifically, we observe that ERM training leads to clusters in representation space that are induced by spurious correlations. We then define a supervised contrastive loss to extract a subnetwork that distorts such clusters, forcing the model to learn only class-specific clusters, rather than attribute-class specific clusters. Our method outperforms all annotation-free methods, achieves worst-group accuracy competitive with methods that require annotations and can mitigate the effect of multiple spurious correlations. Our results show that in a fully trained dense network, there exists a subnetwork that uses only invariant features in classification tasks, thereby eliminating the influence of spurious features.},
  archive      = {J_TMLR},
  author       = {Phuong Quynh Le and Jörg Schlötterer and Christin Seifert},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Out of spuriousity: Improving robustness to spurious correlations without group annotations},
  url          = {https://openreview.net/forum?id=EEeVYfXor5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal discovery over high-dimensional structured hypothesis
spaces with causal graph partitioning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FecsgPCOHk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim in many sciences is to understand the mechanisms that underlie the observed distribution of variables, starting from a set of initial hypotheses. Causal discovery allows us to infer mechanisms as sets of cause and effect relationships in a generalized way---without necessarily tailoring to a specific domain. Causal discovery algorithms search over a structured hypothesis space, defined by the set of Directed Acyclic Graphs (DAG), to find the graph that best explains the data. For high-dimensional problems, however, this search becomes intractable and scalable algorithms for causal discovery are needed to bridge the gap. In this paper, we define a novel causal graph partition that allows for divide-and-conquer causal discovery with theoretical guarantees under the Maximal Ancestral Graph (MAG) class. We leverage the idea of a superstructure---a set of learned or existing candidate hypotheses---to partition the search space. We prove under certain assumptions that learning with a causal graph partition always yields the Markov Equivalence Class of the true causal graph. We show our algorithm achieves comparable accuracy and a faster time to solution for biologically-tuned synthetic networks and networks up to ${10^4}$ variables. This makes our method applicable to gene regulatory network inference and other domains with high-dimensional structured hypothesis spaces.},
  archive      = {J_TMLR},
  author       = {Ashka Shah and Adela Frances DePavia and Nathaniel C Hudson and Ian Foster and Rick Stevens},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Causal discovery over high-dimensional structured hypothesis spaces with causal graph partitioning},
  url          = {https://openreview.net/forum?id=FecsgPCOHk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-exploring language models: Active preference
elicitation for online alignment. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FoQK84nwY3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed dataset, online feedback collection from humans or AI on model generations typically leads to more capable reward models and better-aligned LLMs through an iterative process. However, achieving a globally accurate reward model requires systematic exploration to generate diverse responses that span the vast space of natural language. Random sampling from standard reward-maximizing LLMs alone is insufficient to fulfill this requirement. To address this issue, we propose a bilevel objective optimistically biased towards potentially high-reward responses to actively explore out-of-distribution regions. By solving the inner-level problem with the reparameterized reward function, the resulting algorithm, named Self-Exploring Language Models (SELM), eliminates the need for a separate RM and iteratively updates the LLM with a straightforward objective. Compared to Direct Preference Optimization (DPO), the SELM objective reduces indiscriminate favor of unseen extrapolations and enhances exploration efficiency. Our experimental results demonstrate that when fine-tuned on Zephyr-7B-SFT and Llama-3-8B-Instruct models, SELM significantly boosts the performance on instruction-following benchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard academic benchmarks in different settings.},
  archive      = {J_TMLR},
  author       = {Shenao Zhang and Donghan Yu and Hiteshi Sharma and Han Zhong and Zhihan Liu and Ziyi Yang and Shuohang Wang and Hany Hassan Awadalla and Zhaoran Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Self-exploring language models: Active preference elicitation for online alignment},
  url          = {https://openreview.net/forum?id=FoQK84nwY3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational neural stochastic differential equations with
change points. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GEilvtsFNV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we explore modeling change points in time-series data using neural stochastic differential equations (neural SDEs). We propose a novel model formulation and training procedure based on the variational autoencoder (VAE) framework for modeling time-series as a neural SDE. Unlike existing algorithms training neural SDEs as VAEs, our proposed algorithm only necessitates a Gaussian prior of the initial state of the latent stochastic process, rather than a Wiener process prior on the entire latent stochastic process. We develop two methodologies for modeling and estimating change points in time-series data with distribution shifts. Our iterative algorithm alternates between updating neural SDE parameters and updating the change points based on either a maximum likelihood-based approach or a change point detection algorithm using the sequential likelihood ratio test. We also discuss theoretical implications of the proposed change point detection scheme. Finally, we present an empirical evaluation that demonstrates the expressive power of our proposed model, showing that it can effectively model both classical parametric SDEs and some real datasets with distribution shifts.},
  archive      = {J_TMLR},
  author       = {Yousef El-Laham and Zhongchang Sun and Haibei Zhu and Tucker Balch and Svitlana Vyetrenko},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variational neural stochastic differential equations with change points},
  url          = {https://openreview.net/forum?id=GEilvtsFNV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cycle conditioning for robust representation learning from
categorical data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GkYOcbNLaW">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel diffusion-based method for learning representations from categorical data. Conditional diffusion models have demonstrated their potential to extract meaningful representations from input samples. However, they often struggle to yield versatile, general-purpose information, limiting their adaptability to unforeseen tasks. To address this, we propose a cycle conditioning approach for diffusion models, designed to capture expressive information from conditioning samples. However, cycle conditioning alone can be insufficient. Diffusion models may ignore conditioning samples that vary across training iterations, an issue that occurs within cycle conditioning. To counter this limitation, we introduce additional &quot;spelling&quot; information to guide the conditioning process, ensuring that the conditioning sample remains influential during denoising. While this supervision enhances the generalizability of extracted representations, it is constrained by the sparse nature of spelling information in categorical data, leading to sparse latent conditions. This sparsity reduces the robustness of the extracted representations for downstream tasks or as effective guidance in the diffusion process. To overcome this challenge, we propose a linear navigation strategy within the latent space of conditioning samples, allowing dense representations to be extracted even with sparse supervision. Our experiments demonstrate that our method achieves at least a 1.42\% improvement in AUROC and a 4.12\% improvement in AUCPR over the best results from existing state-of-the-art methods.},
  archive      = {J_TMLR},
  author       = {Mohsen Tabejamaat and Farzaneh Etminani and Mattias Ohlsson},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cycle conditioning for robust representation learning from categorical data},
  url          = {https://openreview.net/forum?id=GkYOcbNLaW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized tangent kernel: A unified geometric foundation
for natural gradient and standard gradient. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HOnL5hjaIt">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural gradients have been widely studied from both theoretical and empirical perspectives, and it is commonly believed that natural gradients have advantages over standard (Euclidean) gradients in capturing the intrinsic geometric structure of the underlying function space and being invariant under reparameterization. However, for function optimization, a fundamental theoretical issue regarding the existence of natural gradients on the function space remains underexplored. We address this issue by providing a geometric perspective and mathematical framework for studying both natural gradient and standard gradient that is more complete than existing studies. The key tool that unifies natural gradient and standard gradient is a generalized form of the Neural Tangent Kernel (NTK), which we name the Generalized Tangent Kernel (GTK). Using a novel orthonormality property of GTK, we show that for a fixed parameterization, GTK determines a Riemannian metric on the entire function space which makes the standard gradient as “natural&quot; as the natural gradient in capturing the intrinsic structure of the parameterized function space. Many aspects of this approach relate to RKHS theory. For the practical side of this theory paper, we showcase that our framework motivates new solutions to the non-immersion/degenerate case of natural gradient and leads to new families of natural/standard gradient descent methods.},
  archive      = {J_TMLR},
  author       = {Qinxun Bai and Steven Rosenberg and Wei Xu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalized tangent kernel: A unified geometric foundation for natural gradient and standard gradient},
  url          = {https://openreview.net/forum?id=HOnL5hjaIt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient mixture of experts: A holistic study of
compression techniques. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HTpMOl6xSI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling large language models has driven remarkable advancements across various domains, yet the continual increase in model size presents significant challenges for real-world deployment. The Mixture of Experts (MoE) architecture offers a promising solution by dynamically selecting and activating only a subset of experts during inference, thus substantially reducing computational costs while preserving high performance. Despite these benefits, MoE introduces new inefficiencies, such as excessive parameters and communication overhead. In this work, we present a holistic study of compression techniques for Mixture of Experts to enhance both efficiency and scalability. While recent efforts have focused on Expert Trimming, which reduces the number of experts, these approaches still suffer from considerable communication and computational costs. To address this, we propose more aggressive strategies, such as Layer Drop, which removes entire MoE layers, and Block Drop, which eliminates transformer blocks. Surprisingly, these aggressive pruning techniques not only preserve model performance but also substantially improve computation and memory efficiency. Furthermore, beyond Expert Trimming, we also introduce Expert Slimming, which compresses individual experts to further boost performance and can be seamlessly integrated with Expert Trimming. Extensive experimental results demonstrate the effectiveness of our proposed methods—Layer Drop and Block Drop—along with the comprehensive recipe that integrates Expert Slimming and Expert Trimming, achieving a 6.05× speedup with 77.1% reduced memory usage while maintaining over 92% of performance on Mixtral-8×7B. Our code is released at https://github.com/CASE-Lab-UMD/Unified-MoE-Compression.},
  archive      = {J_TMLR},
  author       = {Shwai He and Daize Dong and Liang Ding and Ang Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards efficient mixture of experts: A holistic study of compression techniques},
  url          = {https://openreview.net/forum?id=HTpMOl6xSI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlabelled compressive sensing under sparse permutation and
prior information. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HaAg9RN7Hi">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of unlabelled compressed sensing, where the correspondence between the measurement values and the rows of the sensing matrix is lost, the number of measurements is less than the dimension of the regression vector, and the regression vector is sparse in the identity basis. Additionally, motivated by practical situations, we assume that we accurately know a small number of correspondences between the rows of the measurement matrix and the measurement vector. We propose a tractable estimator, based on a modified form of the \textsc{Lasso}, to estimate the regression vector, and we derive theoretical error bounds for the estimate. This is unlike previous approaches to unlabelled compressed sensing, which either do not produce theoretical bounds or which produce bounds for intractable estimators. We show that our algorithm outperforms a hard thresholding pursuit (\textsc{Htp}) approach and an $\ell_1$-norm estimator used to solve a similar problem across diverse regimes. We also propose a modified \textsc{Htp} based estimator which has superior properties to the baseline \textsc{Htp} estimator. Lastly, we show an application of unlabelled compressed sensing in image registration, demonstrating the utility of a few known point correspondences.},
  archive      = {J_TMLR},
  author       = {Garweet Sresth and Satish Mulleti and Ajit Rajwade},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unlabelled compressive sensing under sparse permutation and prior information},
  url          = {https://openreview.net/forum?id=HaAg9RN7Hi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep active learning in the open world. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HkmymFPODz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models deployed in open-world scenarios often encounter unfamiliar conditions and perform poorly in unanticipated situations. As AI systems advance and find application in safety-critical domains, effectively handling out-of-distribution (OOD) data is crucial to building open-world learning systems. In this work, we introduce ALOE, a novel active learning algorithm for open-world environments designed to enhance model adaptation by incorporating new OOD classes via a two-stage approach. First, diversity sampling selects a representative set of examples, followed by energy-based OOD detection to prioritize likely unknown classes for annotation. This strategy accelerates class discovery and learning, even under constrained annotation budgets. Evaluations on three long-tailed image classification benchmarks demonstrate that ALOE outperforms traditional active learning baselines, effectively expanding known categories while balancing annotation cost. Our findings reveal a crucial tradeoff between enhancing known-class performance and discovering new classes, setting the stage for future advancements in open-world machine learning.},
  archive      = {J_TMLR},
  author       = {Tian Xie and Jifan Zhang and Haoyue Bai and Robert D Nowak},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep active learning in the open world},
  url          = {https://openreview.net/forum?id=HkmymFPODz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing the convergence of game dynamics via
potentialness. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Is9APiPg4V">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the convergence landscape of multi-agent learning is a fundamental problem of great practical relevance in many applications of artificial intelligence and machine learning. While it is known that learning dynamics converge to Nash equilibrium in potential games, the behavior of dynamics in many important classes of games that do not admit a potential is poorly understood. To measure how ``close&#39;&#39; a game is to being potential, we consider a distance function, that we call ``potentialness&#39;&#39;, and which relies on a strategic decomposition of games introduced by Candogan et al. (2011). We introduce a numerical framework enabling the computation of this metric, which we use to calculate the degree of ``potentialness&#39;&#39; in generic matrix games, as well as (non-generic) games that are important in economic applications, namely auctions and contests. Understanding learning in the latter games has become increasingly important due to the wide-spread automation of bidding and pricing with no-regret learning algorithms. We empirically show that potentialness decreases and concentrates with an increasing number of agents or actions; in addition, potentialness turns out to be a good predictor for the existence of pure Nash equilibria and the convergence of no-regret learning algorithms in matrix games. In particular, we observe that potentialness is very low for complete-information models of the all-pay auction where no pure Nash equilibrium exists, and much higher for Tullock contests, first-, and second-price auctions, explaining the success of learning in the latter. In the incomplete-information version of the all-pay auction, a pure Bayes-Nash equilibrium exists and it can be learned with gradient-based algorithms. Potentialness nicely characterizes these differences to the complete-information version.},
  archive      = {J_TMLR},
  author       = {Martin Bichler and Davide Legacci and Panayotis Mertikopoulos and Matthias Oberlechner and Bary Pradelski},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Characterizing the convergence of game dynamics via potentialness},
  url          = {https://openreview.net/forum?id=Is9APiPg4V},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online control-informed learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LDzvZEVl5H">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an Online Control-Informed Learning (OCIL) framework, which employs the well-established optimal control and state estimation techniques in the field of control to solve a broad class of learning tasks in an online fashion. This novel integration effectively handles practical issues in machine learning such as noisy measurement data, online learning, and data efficiency. By considering any robot as a tunable optimal control system, we propose an online parameter estimator based on extended Kalman filter (EKF) to incrementally tune the system in an online fashion, enabling it to complete designated learning or control tasks. The proposed method also improves the robustness in learning by effectively managing noise in the data. Theoretical analysis is provided to demonstrate the convergence of OCIL. Three learning modes of OCIL, i.e. Online Imitation Learning, Online System Identification, and Policy Tuning On-the-fly, are investigated via experiments, which validate their effectiveness.},
  archive      = {J_TMLR},
  author       = {Zihao Liang and Tianyu Zhou and Zehui Lu and Shaoshuai Mou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Online control-informed learning},
  url          = {https://openreview.net/forum?id=LDzvZEVl5H},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble and mixture-of-experts DeepONets for operator
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MGdydNfWzQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel deep operator network (DeepONet) architecture for operator learning, the ensemble DeepONet, that allows for enriching the trunk network of a single DeepONet with multiple distinct trunk networks. This trunk enrichment allows for greater expressivity and generalization capabilities over a range of operator learning problems. We also present a spatial mixture-of-experts (MoE) DeepONet trunk network architecture that utilizes a partition-of-unity (PoU) approximation to promote spatial locality and model sparsity in the operator learning problem. We first prove that both the ensemble and PoU-MoE DeepONets are universal approximators. We then demonstrate that ensemble DeepONets containing a trunk ensemble of a standard trunk, the PoU-MoE trunk, and/or a proper orthogonal decomposition (POD) trunk can achieve 2-4x lower relative $\ell_2$ errors than standard DeepONets and POD-DeepONets on both standard and challenging new operator learning problems involving partial differential equations (PDEs) in two and three dimensions. Our new PoU-MoE formulation provides a natural way to incorporate spatial locality and model sparsity into any neural network architecture, while our new ensemble DeepONet provides a powerful and general framework for incorporating basis enrichment in scientific machine learning architectures for operator learning.},
  archive      = {J_TMLR},
  author       = {Ramansh Sharma and Varun Shankar},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Ensemble and mixture-of-experts DeepONets for operator learning},
  url          = {https://openreview.net/forum?id=MGdydNfWzQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning linear polytree structural equation model.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=N28FdYO2sH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the problem of learning the directed acyclic graph (DAG) when data are generated from a linear structural equation model (SEM) and the causal structure can be characterized by a polytree. Under the Gaussian polytree models, we study sufficient conditions on the sample sizes for the well-known Chow-Liu algorithm to exactly recover both the skeleton and the equivalence class of the polytree, which is uniquely represented by a CPDAG. On the other hand, necessary conditions on the required sample sizes for both skeleton and CPDAG recovery are also derived in terms of information-theoretic lower bounds, which match the respective sufficient conditions and thereby give a sharp characterization of the difficulty of these tasks. We also consider the problem of inverse correlation matrix estimation under the linear polytree models, and establish the estimation error bound in terms of the dimension and the total number of v-structures. We also consider an extension of group linear polytree models, in which each node represents a group of variables. Our theoretical findings are illustrated by comprehensive numerical simulations, and experiments on benchmark data also demonstrate the robustness of polytree learning when the true graphical structures can only be approximated by polytrees.},
  archive      = {J_TMLR},
  author       = {Xingmei Lou and Yu Hu and Xiaodong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning linear polytree structural equation model},
  url          = {https://openreview.net/forum?id=N28FdYO2sH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active diffusion subsampling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OGifiton47">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsampling is commonly used to mitigate costs associated with data acquisition, such as time or energy requirements, motivating the development of algorithms for estimating the fully-sampled signal of interest $x$ from partially observed measurements $y$. In maximum- entropy sampling, one selects measurement locations that are expected to have the highest entropy, so as to minimize uncertainty about $x$. This approach relies on an accurate model of the posterior distribution over future measurements, given the measurements observed so far. Recently, diffusion models have been shown to produce high-quality posterior samples of high-dimensional signals using guided diffusion. In this work, we propose Active Diffusion Subsampling (ADS), a method for designing intelligent subsampling masks using guided dif- fusion in which the model tracks a distribution of beliefs over the true state of $x$ throughout the reverse diffusion process, progressively decreasing its uncertainty by actively choosing to acquire measurements with maximum expected entropy, ultimately producing the pos- terior distribution $p(x | y)$. ADS can be applied using pre-trained diffusion models for any subsampling rate, and does not require task-specific retraining – just the specification of a measurement model. Furthermore, the maximum entropy sampling policy employed by ADS is interpretable, enhancing transparency relative to existing methods using black-box policies. Experimentally, we show that through designing informative subsampling masks, ADS significantly improves reconstruction quality compared to fixed sampling strategies on the MNIST and CelebA datasets, as measured by standard image quality metrics, includ- ing PSNR, SSIM, and LPIPS. Furthermore, on the task of Magnetic Resonance Imaging acceleration, we find that ADS performs competitively with existing supervised methods in reconstruction quality while using a more interpretable acquisition scheme design procedure. Code is available at https://active-diffusion-subsampling.github.io/.},
  archive      = {J_TMLR},
  author       = {Oisín Nolan and Tristan Stevens and Wessel L. van Nierop and Ruud Van Sloun},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Active diffusion subsampling},
  url          = {https://openreview.net/forum?id=OGifiton47},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence guarantees for RMSProp and adam in
generalized-smooth non-convex optimization with affine noise variance.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QIzRdjIWnS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides the first tight convergence analyses for RMSProp and Adam for non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. RMSProp is firstly analyzed, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to the dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and the first-order momentum. We develop a new upper bound on the first-order term in the descent lemma, which is also a function of the gradient norm. We show that Adam with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. Our complexity results for both RMSProp and Adam match with the complexity lower bound established in Arjevani et al. (2023).},
  archive      = {J_TMLR},
  author       = {Qi Zhang and Yi Zhou and Shaofeng Zou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Convergence guarantees for RMSProp and adam in generalized-smooth non-convex optimization with affine noise variance},
  url          = {https://openreview.net/forum?id=QIzRdjIWnS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State space models can express <span
class="math inline"><em>n</em></span>-gram languages. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QlBaDKb370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in recurrent neural networks (RNNs) have reinvigorated interest in their application to natural language processing tasks, particularly with the development of more efficient and parallelizable variants known as state space models (SSMs), which have shown competitive performance against transformer models while maintaining a lower memory footprint. While RNNs and SSMs (e.g., Mamba) have been empirically more successful than rule-based systems based on $n$-gram models, a rigorous theoretical explanation for this success has not yet been developed, as it is unclear how these models encode the combinatorial rules that govern the next-word prediction task. In this paper, we construct state space language models that can solve the next-word prediction task for languages generated from $n$-gram rules, thereby showing that the former are more expressive. Our proof shows how SSMs can encode $n$-gram rules using new theoretical results on their memorization capacity, and demonstrates how their context window can be controlled by restricting the spectrum of the state transition matrix. We conduct experiments with a small dataset generated from $n$-gram rules to show how our framework can be applied to SSMs and RNNs obtained through gradient-based optimization.},
  archive      = {J_TMLR},
  author       = {Vinoth Nandakumar and Qiang Qu and Peng Mi and Tongliang Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {State space models can express $n$-gram languages},
  url          = {https://openreview.net/forum?id=QlBaDKb370},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path-specific counterfactual fairness via dividend
correction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=RXoSmiyObR">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual fairness is a fundamental principle in machine learning that allows the analysis of the effects of sensitive attributes in each individual decision by integrating the knowledge of causal graphs. An issue in dealing with counterfactual fairness is that unfair causal effects are often context-specific, influenced by religious, cultural, and national differences, making it difficult to create a universally applicable model. This leads to the challenge of dealing with frequent adaptation to changes in fairness assessments when localizing a model. Thus, applicability across a variety of models and efficiency becomes necessary to meet this challenge. We propose the first efficient post-process approach to achieve path-specific counterfactual fairness by adjusting a model&#39;s outputs based on a given causal graph. This approach is model-agnostic, prioritizing on flexibility and generalizability to deliver robust results across various domains and model architectures. By means of the mathematical tools in cooperative game, the Möbius inversion formula and dividends, we demonstrate that our post-process approach can be executed efficiently. We empirically show that proposed algorithm outperforms existing in-process approaches for path-specific counterfactual fairness and a post-process approach for counterfactual fairness.},
  archive      = {J_TMLR},
  author       = {Daisuke Hatano and Satoshi Hara and Hiromi Arai},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Path-specific counterfactual fairness via dividend correction},
  url          = {https://openreview.net/forum?id=RXoSmiyObR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variation matters: From mitigating to embracing zero-shot
NAS ranking function variation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SbGt90dxdp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) is a powerful automatic alternative to manual design of a neural network. In the zero-shot version, a fast ranking function is used to compare architectures without training them. The outputs of the ranking functions often vary significantly due to different sources of randomness, including the evaluated architecture&#39;s weights&#39; initialization or the batch of data used for calculations. A common approach to addressing the variation is to average a ranking function output over several evaluations. We propose taking into account the variation in a different manner, by viewing the ranking function output as a random variable representing a proxy performance metric. During the search process, we strive to construct a stochastic ordering of the performance metrics to determine the best architecture. Our experiments show that the proposed stochastic ordering can effectively boost performance of a search on standard benchmark search spaces.},
  archive      = {J_TMLR},
  author       = {Pavel Rumiantsev and Mark Coates},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variation matters: From mitigating to embracing zero-shot NAS ranking function variation},
  url          = {https://openreview.net/forum?id=SbGt90dxdp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HoSNNs: Adversarially-robust homeostatic spiking neural
networks with adaptive firing thresholds. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UV58hNygne">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While spiking neural networks (SNNs) offer a promising neurally-inspired model of computation, they are vulnerable to adversarial attacks. We present the first study that draws inspiration from neural homeostasis to design a threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model and utilize TA-LIF neurons to construct the adversarially robust homeostatic SNNs (HoSNNs) for improved robustness. The TA-LIF model incorporates a self-stabilizing dynamic thresholding mechanism, offering a local feedback control solution to the minimization of each neuron&#39;s membrane potential error caused by adversarial disturbance. Theoretical analysis demonstrates favorable dynamic properties of TA-LIF neurons in terms of the bounded-input bounded-output stability and suppressed time growth of membrane potential error, underscoring their superior robustness compared with the standard LIF neurons. When trained with weak FGSM attacks (\(\epsilon = 2/255\)), our HoSNNs significantly outperform conventionally trained LIF-based SNNs across multiple datasets. Furthermore, under significantly stronger PGD7 attacks (\(\epsilon = 8/255\)), HoSNN achieves notable improvements in accuracy, increasing from 30.90% to 74.91% on FashionMNIST, 0.44% to 36.82% on SVHN, 0.54% to 43.33% on CIFAR10, and 0.04% to 16.66% on CIFAR100.},
  archive      = {J_TMLR},
  author       = {Hejia Geng and Peng Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HoSNNs: Adversarially-robust homeostatic spiking neural networks with adaptive firing thresholds},
  url          = {https://openreview.net/forum?id=UV58hNygne},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early directional convergence in deep homogeneous neural
networks for small initializations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VNM6V1gi3k">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the gradient flow dynamics that arise when training deep homogeneous neural networks assumed to have locally Lipschitz gradients and an order of homogeneity strictly greater than two. It is shown here that for sufficiently small initializations, during the early stages of training, the weights of the neural network remain small in (Euclidean) norm and approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of the recently introduced neural correlation function. Additionally, this paper also studies the KKT points of the neural correlation function for feed-forward networks with (Leaky) ReLU and polynomial (Leaky) ReLU activations, deriving necessary and sufficient conditions for rank-one KKT points.},
  archive      = {J_TMLR},
  author       = {Akshay Kumar and Jarvis Haupt},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Early directional convergence in deep homogeneous neural networks for small initializations},
  url          = {https://openreview.net/forum?id=VNM6V1gi3k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlearning personal data from a single image. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=VxC4PZ71Ym">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning aims to erase data from a model as if the latter never saw them during training. While existing approaches unlearn information from complete or partial access to the training data, this access can be limited over time due to privacy regulations. Currently, no setting or benchmark exists to probe the effectiveness of unlearning methods in such scenarios. To fill this gap, we propose a novel task we call One-Shot Unlearning of Personal Identities (1-SHUI) that evaluates unlearning models when the training data is not available. We focus on unlearning identity data, which is specifically relevant due to current regulations requiring personal data deletion after training. To cope with data absence, we expect users to provide a portraiting picture to aid unlearning. We design requests on CelebA, CelebA-HQ, and MUFAC with different unlearning set sizes to evaluate applicable methods in 1-SHUI. Moreover, we propose MetaUnlearn, an effective method that meta-learns to forget identities from a single image. Our findings indicate that existing approaches struggle when data availability is limited, especially when there is a dissimilarity between the provided samples and the training data.},
  archive      = {J_TMLR},
  author       = {Thomas De Min and Massimiliano Mancini and Stéphane Lathuilière and Subhankar Roy and Elisa Ricci},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unlearning personal data from a single image},
  url          = {https://openreview.net/forum?id=VxC4PZ71Ym},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed sparsity training: Achieving 4<span
class="math inline">×</span> FLOP reduction for transformer pretraining.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XosdLS7KVE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made significant strides in complex tasks, yet their widespread adoption is impeded by substantial computational demands. With hundreds of billion parameters, transformer-based LLMs necessitate months of pretraining across a high-end GPU cluster. However, this paper reveals a compelling finding: transformers exhibit considerable redundancy in pretraining computations, which motivates our proposed solution, Mixed Sparsity Training (MST), an efficient pretraining method that can reduce about $75$% of Floating Point Operations (FLOPs) while maintaining performance. MST integrates dynamic sparse training (DST) with Sparsity Variation (SV) and Hybrid Sparse Attention (HSA) during pretraining, involving three distinct phases: warm-up, ultra-sparsification, and restoration. The warm-up phase transforms the dense model into a sparse one, and the restoration phase reinstates connections. Throughout these phases, the model is trained with a dynamically evolving sparse topology and an HSA mechanism to maintain performance and minimize training FLOPs concurrently. Our experiment on GPT-2 showcases a FLOP reduction of $4\times$ without compromising performance.},
  archive      = {J_TMLR},
  author       = {Pihe Hu and Shaolong Li and Xun Wang and Longbo Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixed sparsity training: Achieving 4$\times$ FLOP reduction for transformer pretraining},
  url          = {https://openreview.net/forum?id=XosdLS7KVE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention overlap is responsible for the entity missing
problem in text-to-image diffusion models! <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Xv3ZrFayIO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image diffusion models such as Stable Diffusion and DALL-E have exhibited impressive capabilities in producing high-quality, diverse, and realistic images based on textual prompts. Nevertheless, a common issue arises where these models encounter difficulties in faithfully generating every entity specified in the prompt, leading to a recognized challenge known as entity missing in visual compositional generation. While previous studies indicated that actively adjusting cross-attention maps during inference could potentially resolve the issue, there has been a lack of systematic investigation into the specific objective function required for this task. In this work, we thoroughly investigate three potential causes of entity missing from the perspective of cross-attention maps: insufficient attention intensity, excessive attention spread, and significant overlap between attention maps of different entities. Through comprehensive empirical analysis, we found that optimizing metrics that quantify the overlap between attention maps of entities is highly effective at mitigating entity missing. We hypothesize that during the denoising process, entity-related tokens engage in a form of competition for attention toward specific regions through the cross-attention mechanism. This competition may result in the attention of a spatial location being divided among multiple tokens, leading to difficulties in accurately generating the entities associated with those tokens. Building on this insight, we propose four overlap-based loss functions that can be used to implicitly manipulate the latent embeddings of the diffusion model during inference: Intersection over union (IoU), center-of-mass (CoM) distance, Kullback–Leibler (KL) divergence, and clustering compactness (CC). Extensive experiments on a diverse set of prompts demonstrate that our proposed training-free methods substantially outperform previous approaches on a range of compositional alignment metrics, including visual question-answering, captioning score, CLIP similarity, and human evaluation. Notably, our method outperforms the best baseline by $9\%$ in human evaluation.},
  archive      = {J_TMLR},
  author       = {Arash Mari Oriyad and Mohammadali Banayeeanzade and Reza Abbasi and Mohammad Hossein Rohban and Mahdieh Soleymani Baghshah},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Attention overlap is responsible for the entity missing problem in text-to-image diffusion models!},
  url          = {https://openreview.net/forum?id=Xv3ZrFayIO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Buffer-based gradient projection for continual federated
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Xz5IcOizQ6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Federated Learning (CFL) is essential for enabling real-world applications where multiple decentralized clients adaptively learn from continuous data streams. A significant challenge in CFL is mitigating catastrophic forgetting, where models lose previously acquired knowledge when learning new information. Existing approaches often face difficulties due to the constraints of device storage capacities and the heterogeneous nature of data distributions among clients. While some CFL algorithms have addressed these challenges, they frequently rely on unrealistic assumptions about the availability of task boundaries (i.e., knowing when new tasks begin). To address these limitations, we introduce Fed-A-GEM, a federated adaptation of the A-GEM method, which employs a buffer-based gradient projection approach. Fed-A-GEM alleviates catastrophic forgetting by leveraging local buffer samples and aggregated buffer gradients, thus preserving knowledge across multiple clients. Our method is combined with existing CFL techniques, enhancing their performance in the CFL context. Our experiments on standard benchmarks show consistent performance improvements across diverse scenarios. For example, in a task-incremental learning scenario using the CIFAR-100 dataset, our method can increase the accuracy by up to 27%. Our code is available at https://github.com/shenghongdai/Fed-A-GEM.},
  archive      = {J_TMLR},
  author       = {Shenghong Dai and Jy-yong Sohn and Yicong Chen and S M Iftekharul Alam and Ravikumar Balakrishnan and Suman Banerjee and Nageen Himayat and Kangwook Lee},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Buffer-based gradient projection for continual federated learning},
  url          = {https://openreview.net/forum?id=Xz5IcOizQ6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeoMask3D: Geometrically informed mask selection for
self-supervised point cloud learning in 3D. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Yk7GUlJwGa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel approach to self-supervised learning for point clouds, employing a geometrically informed mask selection strategy called GeoMask3D (GM3D) to boost the efficiency of Masked Auto Encoders (MAE). Unlike the conventional method of random masking, our technique utilizes a teacher-student model to focus on intricate areas within the data, guiding the model’s focus toward regions with higher geometric complexity. This strategy is grounded in the hypothesis that concentrating on harder patches yields a more robust feature representation, as evidenced by the improved performance on downstream tasks. Our method also presents a feature-level knowledge distillation technique designed to guide the prediction of geometric complexity, which utilizes a comprehensive context from feature-level information. Extensive experiments confirm our method’s superiority over State-Of-The-Art (SOTA) baselines, demonstrating marked improvements in classification, segmentation, and few-shot tasks.},
  archive      = {J_TMLR},
  author       = {Ali Bahri and Moslem Yazdanpanah and Mehrdad Noori and Milad Cheraghalikhani and Gustavo Adolfo Vargas Hakim and David OSOWIECHI and Farzad Beizaee and Ismail Ben Ayed and Christian Desrosiers},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GeoMask3D: Geometrically informed mask selection for self-supervised point cloud learning in 3D},
  url          = {https://openreview.net/forum?id=Yk7GUlJwGa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An elementary concentration bound for gibbs measures arising
in statistical learning theory. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZInwrlkQ3f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an elementary concentration bound for Gibbs measures whose log-likelihood is a function of the empirical risk. This bound controls the distance between samples from the (random) Gibbs measure and the minimizers of the population risk function. This bound is a generalization of a recent inequality developed by Ramsay et al., 2024. As a corollary, we obtain sample complexity bounds and bounds on the inverse temperature so that the samples are within a prescribed error of the population value. The latter bound on the inverse temperature is essentially sharp. We demonstrate our work on three canonical classes of examples: classification of two component mixture models, robust regression, and spiked matrix and tensor models.},
  archive      = {J_TMLR},
  author       = {Kelly Ramsay and Aukosh Jagannath and Shojaeddin Chenouri},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An elementary concentration bound for gibbs measures arising in statistical learning theory},
  url          = {https://openreview.net/forum?id=ZInwrlkQ3f},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reset-free reinforcement learning with world models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZdMIXltJzK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is an appealing paradigm for training intelligent agents, enabling policy acquisition from the agent&#39;s own autonomously acquired experience. However, the training process of RL is far from automatic, requiring extensive human effort to reset the agent and environments. To tackle the challenging reset-free setting, we first demonstrate the superiority of model-based (MB) RL methods in such setting, showing that a straightforward adaptation of MBRL can outperform all the prior state-of-the-art methods while requiring less supervision. We then identify limitations inherent to this direct extension and propose a solution called model-based reset-free (MoReFree) agent, which further enhances the performance. MoReFree adapts two key mechanisms, exploration and policy learning, to handle reset-free tasks by prioritizing task-relevant states. It exhibits superior data-efficiency across various reset-free tasks without access to environmental reward or demonstrations while significantly outperforming privileged baselines that require supervision. Our findings suggest model-based methods hold significant promise for reducing human effort in RL. Website: https://yangzhao-666.github.io/morefree},
  archive      = {J_TMLR},
  author       = {Zhao Yang and Thomas M. Moerland and Mike Preuss and Aske Plaat and Edward S. Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reset-free reinforcement learning with world models},
  url          = {https://openreview.net/forum?id=ZdMIXltJzK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to leverage predictive uncertainty estimates for
reducing catastrophic forgetting in online continual learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dczXe0S1oL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications require machine-learning models to be able to deal with non-stationary data distributions and thus learn autonomously over an extended period of time, often in an online setting. One of the main challenges in this scenario is the so-called catastrophic forgetting (CF) for which the learning model tends to focus on the most recent tasks while experiencing predictive degradation on older ones. In the online setting, the most effective solutions employ a fixed-size memory buffer to store old samples used for replay when training on new tasks. Many approaches have been presented to tackle this problem and conflicting strategies are proposed to populate the memory. Are the easiest-to-forget or the easiest-to-remember samples more effective in combating CF? Furthermore, it is not clear how predictive uncertainty information for memory management can be leveraged in the most effective manner. Starting from the intuition that predictive uncertainty provides an idea of the samples&#39; location in the decision space, this work presents an in-depth analysis of different uncertainty estimates and strategies for populating the memory. The investigation provides a better understanding of the characteristics data points should have for alleviating CF. Then, we propose an alternative method for estimating predictive uncertainty via the generalised variance induced by the negative log-likelihood. Finally, we demonstrate that the use of predictive uncertainty measures helps in reducing CF in different settings.},
  archive      = {J_TMLR},
  author       = {Giuseppe Serra and Ben Werner and Florian Buettner},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How to leverage predictive uncertainty estimates for reducing catastrophic forgetting in online continual learning},
  url          = {https://openreview.net/forum?id=dczXe0S1oL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking knowledge transfer in learning using privileged
information. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dg1tqNIWg3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supervised machine learning, privileged information (PI) is information that is unavailable at inference, but is accessible during training time. Research on learning using privileged information (LUPI) aims to transfer the knowledge captured in PI onto a model that can perform inference without PI. It seems that this extra bit of information ought to make the resulting model better. However, finding conclusive theoretical or empirical evidence that supports the ability to transfer knowledge using PI has been challenging. In this paper, we critically examine the assumptions underlying existing theoretical analyses and argue that there is little theoretical justification for when LUPI should work. We analyze two main LUPI methods - generalized distillation and marginalization with weight sharing - and reveal that apparent improvements in empirical risk may not directly result from PI. Instead, these improvements often stem from dataset anomalies or modifications in model design misguidedly attributed to PI. Our experiments for a wide variety of application domains further demonstrate that state-of-the-art LUPI approaches fail to effectively transfer knowledge from PI. Thus, we advocate for practitioners to exercise caution when working with PI to avoid unintended inductive biases.},
  archive      = {J_TMLR},
  author       = {Danil Provodin and Bram van den Akker and Christina Katsimerou and Maurits Clemens Kaptein and Mykola Pechenizkiy},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rethinking knowledge transfer in learning using privileged information},
  url          = {https://openreview.net/forum?id=dg1tqNIWg3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The time-energy model: Selective time-series forecasting
using energy-based models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=iHYCdTAOqF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series forecasting is an important task in many domains, including finance, weather prediction, and energy consumption forecasting, and deep learning methods have emerged as the best-performing time-series forecasting methods over the last few years. However, most proposed time-series forecasting models are deterministic and are prone to errors when deployed in production, potentially causing significant losses and penalties when making predictions with low confidence. In this paper, we propose the Time-Energy Model (TEM), a framework that introduces so-called selective time-series forecasting using energy-based models. Selective forecasting estimates model confidence and allows the end-user to selectively reject forecasts while maintaining a desired target coverage. TEM is model-agnostic and can be used to improve forecasting accuracy of any encoder-decoder deterministic time-series forecasting model. TEM is trained using a combination of supervised and self-supervised learning, leveraging excellent single-point prediction accuracy while maintaining the ability to reject forecasts based on model confidence. Experimental results indicate that TEM generalizes well across 5 state-of-the-art deterministic time-series forecasting models and 5 benchmark time-series forecasting datasets. Using selective forecasting, TEM reduces prediction error by up to $49.1\%$ over 5 state-of-the-art deterministic models. Furthermore, TEM has up to $87.0\%$ lower error than selected baseline EBM models, and achieves significantly better performance than state-of-the-art selective deep learning models. Code for the proposed TEM framework is available at https://github.com/JonasBrusokas/Time-Energy-Model},
  archive      = {J_TMLR},
  author       = {Jonas Brusokas and Seshu Tirupathi and Dalin Zhang and Torben Bach Pedersen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The time-energy model: Selective time-series forecasting using energy-based models},
  url          = {https://openreview.net/forum?id=iHYCdTAOqF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards graph foundation models: A study on the
generalization of positional and structural encodings. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=mSoDRZXsqj">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in integrating positional and structural encodings (PSEs) into graph neural networks (GNNs) have significantly enhanced their performance across various graph learning tasks. However, the general applicability of these encodings and their potential to serve as foundational representations for graphs remain uncertain. This paper investigates the fine-tuning efficiency, scalability with sample size, and generalization capability of learnable PSEs across diverse graph datasets. Specifically, we evaluate their potential as universal pre-trained models that can be easily adapted to new tasks with minimal fine-tuning and limited data. Furthermore, we assess the expressivity of the learned representations, particularly, when used to augment downstream GNNs. We demonstrate through extensive benchmarking and empirical analysis that PSEs generally enhance downstream models. However, some datasets may require specific PSE-augmentations to achieve optimal performance. Nevertheless, our findings highlight their significant potential to become integral components of future graph foundation models. We provide new insights into the strengths and limitations of PSEs, contributing to the broader discourse on foundation models in graph learning.},
  archive      = {J_TMLR},
  author       = {Billy Joe Franks and Moshe Eliasof and Semih Cantürk and Guy Wolf and Carola-Bibiane Schönlieb and Sophie Fellenz and Marius Kloft},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards graph foundation models: A study on the generalization of positional and structural encodings},
  url          = {https://openreview.net/forum?id=mSoDRZXsqj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain generalization for time series: Enhancing drilling
regression models for stick-slip index prediction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nNN1pPJRVL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a comprehensive comparison of domain generalization techniques applied to time series data within a drilling context, focusing on the prediction of a continuous Stick-Slip Index (SSI), a critical metric for assessing torsional downhole vibrations at the drill bit. The study aims to develop a robust regression model that can generalize across domains by training on $60$~ second labeled sequences of $1$~Hz surface drilling data to predict the SSI. The model is tested in wells that are different from those used during training. To fine-tune the model architecture, a grid search approach is employed to optimize key hyperparameters. A comparative analysis of the Adversarial Domain Generalization (ADG), Invariant Risk Minimization (IRM) and baseline models is presented, along with an evaluation of the effectiveness of transfer learning (TL) in improving model performance. The ADG and IRM models achieve performance improvements of $10\%$ and $8\%$, respectively, over the baseline model. Most importantly, severe events are detected $60\%$ of the time, against $20\%$ for the baseline model. Overall, the results indicate that both ADG and IRM models surpass the baseline, with the ADG model exhibiting a slight advantage over the IRM model. Additionally, applying TL to a pre-trained model further improves performance. Our findings demonstrate the potential of domain generalization approaches in drilling applications, with ADG emerging as the most effective approach.},
  archive      = {J_TMLR},
  author       = {Hana YAHIA and Bruno Figliuzzi and Florent Di Meglio and Gerbaud and Stephane Menand and Mohamed MAHJOUB},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Domain generalization for time series: Enhancing drilling regression models for stick-slip index prediction},
  url          = {https://openreview.net/forum?id=nNN1pPJRVL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calibrated probabilistic forecasts for arbitrary sequences.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nuIUTHGlM5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data streams can change unpredictably due to distribution shifts, feedback loops and adversarial actors, which challenges the validity of forecasts. We present a forecasting framework ensuring valid uncertainty estimates regardless of how data evolves. Leveraging the concept of Blackwell approachability from game theory, we introduce a forecasting framework that guarantees calibrated uncertainties for outcomes in any compact space (e.g., classification or bounded regression). We extend this framework to recalibrate existing forecasters, guaranteeing calibration without sacrificing predictive performance. We implement both general-purpose gradient-based algorithms and algorithms optimized for popular special cases of our framework. Empirically, our algorithms improve calibration and downstream decision-making for energy systems.},
  archive      = {J_TMLR},
  author       = {Charles Marx and Volodymyr Kuleshov and Stefano Ermon},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Calibrated probabilistic forecasts for arbitrary sequences},
  url          = {https://openreview.net/forum?id=nuIUTHGlM5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unifying framework for generalised bayesian online
learning in non-stationary environments. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=osesw2V10u">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a unifying framework for methods that perform probabilistic online learning in non-stationary environments. We call the framework BONE, which stands for generalised (B)ayesian (O)nline learning in (N)on-stationary (E)nvironments. BONE provides a common structure to tackle a variety of problems, including online continual learning, prequential forecasting, and contextual bandits. The framework requires specifying three modelling choices: (i) a model for measurements (e.g., a neural network), (ii) an auxiliary process to model non-stationarity (e.g., the time since the last changepoint), and (iii) a conditional prior over model parameters (e.g., a multivariate Gaussian). The framework also requires two algorithmic choices, which we use to carry out approximate inference under this framework: (i) an algorithm to estimate beliefs (posterior distribution) about the model parameters given the auxiliary variable, and (ii) an algorithm to estimate beliefs about the auxiliary variable. We show how the modularity of our framework allows for many existing methods to be reinterpreted as instances of BONE, and it allows us to propose new methods. We compare experimentally existing methods with our proposed new method on several datasets, providing insights into the situations that make each method more suitable for a specific task. We provide a Jax open source library to facilitate the adoption of this framework.},
  archive      = {J_TMLR},
  author       = {Gerardo Duran-Martin and Leandro Sánchez-Betancourt and Alex Shestopaloff and Kevin Patrick Murphy},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A unifying framework for generalised bayesian online learning in non-stationary environments},
  url          = {https://openreview.net/forum?id=osesw2V10u},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlashAttention on a napkin: A diagrammatic approach to deep
learning IO-awareness. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=pF2ukh7HxA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing deep learning algorithms currently requires slow, manual derivation, potentially leaving much performance untapped. Methods like FlashAttention have achieved a x6 performance improvement over native PyTorch by avoiding unnecessary data transfers, but required three iterations over three years to be developed. Automated compiled methods have consistently lagged behind. This paper extends Neural Circuit Diagrams for deep learning models to consider resource usage and the distribution of tasks across a GPU hierarchy. We show how diagrams can use simple relabellings to derive high-level streaming and tiling optimization strategies along with performance models. We show how this high-level performance model allows the effects of quantization and multi-level GPU hierarchies to be readily considered. We develop a methodology for representing intermediate-level pseudocode with diagrams, allowing hardware-aware algorithms to be derived step-by-step. Finally, we show how our methodology can be used to better understand existing techniques like FlashAttention. This work uses a theoretical framework to link assumptions about GPU behaviour to claims about performance. We aim to lay the groundwork for a scientific approach to GPU optimization where experiments can address clear hypotheses rather than post-hoc rationalizations.},
  archive      = {J_TMLR},
  author       = {Vincent Abbott and Gioele Zardini},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FlashAttention on a napkin: A diagrammatic approach to deep learning IO-awareness},
  url          = {https://openreview.net/forum?id=pF2ukh7HxA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shedding light on problems with hyperbolic graph learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=rKAkp1f3R7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent papers in the graph machine learning literature have introduced a number of approaches for hyperbolic representation learning. The asserted benefits are improved performance on a variety of graph tasks, node classification and link prediction included. Claims have also been made about the geometric suitability of particular hierarchical graph datasets to representation in hyperbolic space. Despite these claims, our work makes a surprising discovery: when simple Euclidean models with comparable numbers of parameters are properly trained in the same environment, in most cases, they perform as well, if not better, than all introduced hyperbolic graph representation learning models, even on graph datasets previously claimed to be the most hyperbolic as measured by Gromov $\delta$-hyperbolicity (i.e., perfect trees). This observation gives rise to a simple question: how can this be? We answer this question by taking a careful look at the field of hyperbolic graph representation learning as it stands today, and find that a number of results do not diligently present baselines, make faulty modelling assumptions when constructing algorithms, and use misleading metrics to quantify geometry of graph datasets. We take a closer look at each of these three problems, elucidate the issues, perform an analysis of methods, and introduce a parametric family of benchmark datasets to ascertain the applicability of (hyperbolic) graph neural networks.},
  archive      = {J_TMLR},
  author       = {Isay Katsman and Anna Gilbert},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Shedding light on problems with hyperbolic graph learning},
  url          = {https://openreview.net/forum?id=rKAkp1f3R7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Align and distill: Unifying and improving domain adaptive
object detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ssXSrZ94sR">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, increasing the diversity of available DAOD benchmarks, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes $\rightarrow$ Foggy Cityscapes, +5.7 AP50 on Sim10k $\rightarrow$ Cityscapes (where ours is the only method to outperform a fair baseline), and +0.6 AP50 on CFC-DAOD. ALDI and ALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and DETR-based DAOD as well without additional hyperparameter tuning. Our framework, dataset, and method offer a critical reset for DAOD and provide a strong foundation for future research.},
  archive      = {J_TMLR},
  author       = {Justin Kay and Timm Haucke and Suzanne Stathatos and Siqi Deng and Erik Young and Pietro Perona and Sara Beery and Grant Van Horn},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Align and distill: Unifying and improving domain adaptive object detection},
  url          = {https://openreview.net/forum?id=ssXSrZ94sR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random walk diffusion for efficient large-scale graph
generation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tSFpsfndE7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph generation addresses the problem of generating new graphs that have a data distribution similar to real-world graphs. While previous diffusion-based graph generation methods have shown promising results, they often struggle to scale to large graphs. In this work, we propose ARROW-Diff (AutoRegressive RandOm Walk Diffusion), a novel random walk-based diffusion approach for efficient large-scale graph generation. Our method encompasses two components in an iterative process of random walk sampling and graph pruning. We demonstrate that ARROW-Diff can scale to large graphs efficiently, surpassing other baseline methods in terms of both generation time and multiple graph statistics, reflecting the high quality of the generated graphs.},
  archive      = {J_TMLR},
  author       = {Tobias Bernecker and Ghalia Rehawi and Francesco Paolo Casale and Janine Knauer-Arloth and Annalisa Marsico},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Random walk diffusion for efficient large-scale graph generation},
  url          = {https://openreview.net/forum?id=tSFpsfndE7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CroissantLLM: A truly bilingual french-english language
model. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uA19Xo1o31">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3T English and French tokens, to bring to the research and industrial community a high-performance, fully open-sourced bilingual model that runs swiftly on consumer-grade local hardware. To that end, we pioneer the approach of training an intrinsically bilingual model with a 1:1 English-to-French pretraining data ratio, a custom tokenizer, and bilingual finetuning datasets. We release the training dataset, notably containing a French split with manually curated, high-quality, and varied data sources. To assess performance outside of English, we craft a novel benchmark, FrenchBench, consisting of an array of classification and generation tasks, covering various orthogonal aspects of model performance in the French Language. Additionally, rooted in transparency and to foster further Large Language Model research, we release codebases, and dozens of checkpoints across various model sizes, training data distributions, and training steps, as well as fine-tuned Chat models, and strong translation models. We evaluate our model through the FMTI framework, and validate 81 % of the transparency criteria, far beyond the scores of even most open initiatives. This work enriches the NLP landscape, breaking away from previous English-centric work in order to strengthen our understanding of multilinguality in language models.},
  archive      = {J_TMLR},
  author       = {Manuel Faysse and Patrick Fernandes and Nuno M Guerreiro and António Loison and Duarte Miguel Alves and Caio Corrro and Nicolas Boizard and João Alves and Ricardo Rei and Pedro Henrique Martins and Antoni Bigata Casademunt and François Yvon and Andre Martins and Gautier Viaud and CELINE HUDELOT and Pierre Colombo},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CroissantLLM: A truly bilingual french-english language model},
  url          = {https://openreview.net/forum?id=uA19Xo1o31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reheated gradient-based discrete sampling for combinatorial
optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uPCvfyr2KP">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, gradient-based discrete sampling has emerged as a highly efficient, general-purpose solver for various combinatorial optimization (CO) problems, achieving performance comparable to or surpassing the popular data-driven approaches. However, we identify a critical issue in these methods, which we term ``wandering in contours&#39;&#39;. This behavior refers to sampling new different solutions that share very similar objective values for a long time, leading to computational inefficiency and suboptimal exploration of potential solutions. In this paper, we introduce a novel reheating mechanism inspired by the concept of critical temperature and specific heat in physics, aimed at overcoming this limitation. Empirically, our method demonstrates superiority over existing sampling-based and data-driven algorithms across a diverse array of CO problems.},
  archive      = {J_TMLR},
  author       = {Muheng Li and Ruqi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reheated gradient-based discrete sampling for combinatorial optimization},
  url          = {https://openreview.net/forum?id=uPCvfyr2KP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the robustness of kolmogorov-arnold networks: An
adversarial perspective. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uafxqhImPM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kolmogorov-Arnold Networks (KANs) have recently emerged as a novel paradigm for function approximation by leveraging univariate spline-based decompositions inspired by the Kolmogorov–Arnold theorem. Despite their theoretical appeal---particularly the potential for inducing smoother decision boundaries and lower effective Lipschitz constants---their adversarial robustness remains largely unexplored. In this work, we conduct the first comprehensive evaluation of KAN robustness in adversarial settings, focusing on both fully connected (FCKANs) and convolutional (CKANs) instantiations for image classification tasks. Across a wide range of benchmark datasets (MNIST, FashionMNIST, KMNIST, CIFAR-10, SVHN, and a subset of ImageNet), we compare KANs against conventional architectures using an extensive suite of attacks, including white-box methods (FGSM, PGD, C\&amp;W, MIM), black-box approaches (Square Attack, SimBA, NES), and ensemble attacks (AutoAttack). Our experiments reveal that while small- and medium-scale KANs are not consistently more robust than their standard counterparts, large-scale KANs exhibit markedly enhanced resilience against adversarial perturbations. An ablation study further demonstrates that critical hyperparameters---such as number of knots and spline order---significantly influence robustness. Moreover, adversarial training experiments confirm the inherent safety advantages of KAN-based architectures. Overall, our findings provide novel insights into the adversarial behavior of KANs and lay a rigorous foundation for future research on robust, interpretable network designs.},
  archive      = {J_TMLR},
  author       = {Tal Alter and Raz Lapid and Moshe Sipper},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the robustness of kolmogorov-arnold networks: An adversarial perspective},
  url          = {https://openreview.net/forum?id=uafxqhImPM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Respecting the limit: Bayesian optimization with a bound on
the optimal value. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=y5Hf0otJLk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world optimization problems, we have prior information about what objective function values are achievable. In this paper, we study the scenario that we have either exact knowledge of the minimum value or a, possibly inexact, lower bound on its value. We propose bound-aware Bayesian optimization (BABO), a Bayesian optimization method that uses a new surrogate model and acquisition function to utilize such prior information. We present SlogGP, a new surrogate model that incorporates bound information and adapts the Expected Improvement (EI) acquisition function accordingly. Empirical results on a variety of benchmarks demonstrate the benefit of taking prior information about the optimal value into account, and that the proposed approach significantly outperforms existing techniques. Furthermore, we notice that even in the absence of prior information on the bound, the proposed SlogGP surrogate model still performs better than the standard GP model in most cases, which we explain by its larger expressiveness.},
  archive      = {J_TMLR},
  author       = {Hanyang Wang and Juergen Branke and Matthias Poloczek},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Respecting the limit: Bayesian optimization with a bound on the optimal value},
  url          = {https://openreview.net/forum?id=y5Hf0otJLk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lower ricci curvature for efficient community detection.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EoiuRII7MQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Lower Ricci Curvature (LRC), a novel, scalable, and scale-free discrete curvature designed to enhance community detection in networks. Addressing the computational challenges posed by existing curvature-based methods, LRC offers a streamlined approach with linear computational complexity, which makes it well suited for large-scale network analysis. We further develop an LRC-based preprocessing method that effectively augments popular community detection algorithms. Through applications on multiple real-world datasets, including the NCAA football league network, the DBLP collaboration network, the Amazon product co-purchasing network, and the YouTube social network, we demonstrate the efficacy of our method in significantly improving the performance of various community detection algorithms.},
  archive      = {J_TMLR},
  author       = {Yun Jin Park and Didong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lower ricci curvature for efficient community detection},
  url          = {https://openreview.net/forum?id=EoiuRII7MQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing maritime trajectory forecasting via h3 index and
causal language modelling (CLM). <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tIfS6jyO9f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of ship trajectories is a growing field of study in artificial intelligence. Traditional methods rely on the use of LSTM, GRU networks, and even Transformer architectures for the prediction of spatio-temporal series. This study proposes a viable alternative for predicting these trajectories using only GNSS positions. It considers this spatio-temporal problem as a natural language processing problem. The latitude/longitude coordinates of AIS messages are transformed into cell identifiers using the H3 index. Thanks to the pseudo-octal representation, it becomes easier for language models to learn the spatial hierarchy of the H3 index. The method is qualitatively compared to a classical Kalman filter and quantitatively to Seq2Seq and TrAISformer models. The Fréchet distance is introduced as the main evaluation metric for these comparisons. We show that it is possible to predict ship trajectories quite precisely up to 8 hours ahead with 30 minutes of context, using solely GNSS positions, without relying on any additional information such as speed, course, or external conditions — unlike many traditional methods. We demonstrate that this alternative works well enough to predict trajectories worldwide.},
  archive      = {J_TMLR},
  author       = {Nicolas Drapier and Aladine Chetouani and Aurélien Chateigner},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing maritime trajectory forecasting via h3 index and causal language modelling (CLM)},
  url          = {https://openreview.net/forum?id=tIfS6jyO9f},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning optimizers for communication-efficient
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uRbf9ANAns">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication-efficient variants of SGD, specifically local SGD, have received a great deal of interest in recent years. These approaches compute multiple gradient steps locally on each worker, before averaging model parameters, helping relieve the critical communication bottleneck in distributed deep learning training. Although many variants of these approaches have been proposed, they can sometimes lag behind state-of-the-art adaptive optimizers for deep learning. In this work, we investigate if the recent progress in the emerging area of learned optimizers can potentially close this gap in homogeneous data and homogeneous device settings while remaining communication-efficient. Specifically, we meta-learn how to perform global updates given an update from local SGD iterations. Our results demonstrate that learned optimizers can substantially outperform local SGD and its sophisticated variants while maintaining their communication efficiency. Our learned optimizers can even generalize to unseen and much larger datasets and architectures, including ImageNet and ViTs, and to unseen modalities such as language modeling. We therefore show the potential of learned optimizers for improving communication-efficient distributed learning.},
  archive      = {J_TMLR},
  author       = {Charles-Étienne Joseph and Benjamin Thérien and Abhinav Moudgil and Boris Knyazev and Eugene Belilovsky},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning optimizers for communication-efficient learning},
  url          = {https://openreview.net/forum?id=uRbf9ANAns},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse decomposition of graph neural networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xdWP1d8BxI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNN) exhibit superior performance in graph representation learning, but their inference cost can be high, due to an aggregation operation that can require a memory fetch for a very large number of nodes. This inference cost is the major obstacle to deploying GNN models with \emph{online prediction} to reflect the potentially dynamic node features. To address this, we propose an approach to reduce the number of nodes that are included during aggregation. We achieve this through a sparse decomposition, learning to approximate node representations using a weighted sum of linearly transformed features of a carefully selected subset of nodes within the extended neighbourhood. The approach achieves linear complexity with respect to the average node degree and the number of layers in the graph neural network. We introduce an algorithm to compute the optimal parameters for the sparse decomposition, ensuring an accurate approximation of the original GNN model, and present effective strategies to reduce the training time and improve the learning process. We demonstrate via extensive experiments that our method outperforms other baselines designed for inference speedup, achieving significant accuracy gains with comparable inference times for both node classification and spatio-temporal forecasting tasks.},
  archive      = {J_TMLR},
  author       = {Yaochen Hu and Mai Zeng and Ge Zhang and Pavel Rumiantsev and Liheng Ma and Yingxue Zhang and Mark Coates},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparse decomposition of graph neural networks},
  url          = {https://openreview.net/forum?id=xdWP1d8BxI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Which backbone to use: A resource-efficient domain specific
comparison for computer vision. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XVSQnnf7QT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For computer vision applications on small, niche, and proprietary datasets, fine-tuning a neural network (NN) backbone that is pre-trained on a large dataset, such as the ImageNet, is a common practice. However, it is unknown whether the backbones that perform well on large datasets, such as vision transformers, are also the right choice for fine-tuning on smaller custom datasets. The present comprehensive analysis aims to aid machine learning practitioners in selecting the most suitable backbone for their specific problem. We systematically evaluated multiple lightweight, pre-trained backbones under consistent training settings across a variety of domains spanning natural, medical, deep space, and remote sensing images. We found that even though attention-based architectures are gaining popularity, they tend to perform poorly compared to CNNs when fine-tuned on small amounts of domain-specific data. We also observed that certain CNN architectures consistently perform better than others when controlled for network size. Our findings provide actionable insights into the performance trade-offs and effectiveness of different backbones for a broad spectrum of computer vision domains.},
  archive      = {J_TMLR},
  author       = {Pranav Jeevan P and Amit Sethi},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Which backbone to use: A resource-efficient domain specific comparison for computer vision},
  url          = {https://openreview.net/forum?id=XVSQnnf7QT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distilling datasets into less than one image. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=qsipSdfWeV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataset distillation aims to compress a dataset into a much smaller one so that a model trained on the distilled dataset achieves high accuracy. Current methods frame this as maximizing the distilled classification accuracy for a budget of K distilled images-per-class, where K is a positive integer. In this paper, we push the boundaries of dataset distillation, compressing the dataset into less than an image-per-class. It is important to realize that the meaningful quantity is not the number of distilled images-per-class but the number of distilled pixels-per-dataset. We therefore, propose Poster Dataset Distillation (PoDD), a new approach that distills the entire original dataset into a single poster. The poster approach motivates new technical solutions for creating training images and learnable labels. Our method can achieve comparable or better performance with less than an image-per-class compared to existing methods that use one image-per-class. Specifically, our method establishes a new state-of-the-art performance on CIFAR-10, CIFAR-100, and CUB200 on the well established 1 IPC benchmark, while using as little as 0.3 images-per-class.},
  archive      = {J_TMLR},
  author       = {Asaf Shul and Eliahu Horwitz and Yedid Hoshen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distilling datasets into less than one image},
  url          = {https://openreview.net/forum?id=qsipSdfWeV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On using secure aggregation in differentially private
federated learning with multiple local steps. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uxyWlXPuIg">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed learning setting where the main aim is to train machine learning models without having to share raw data but only what is required for learning. To guarantee training data privacy and high-utility models, differential privacy and secure aggregation techniques are often combined with federated learning. However, with fine-grained protection granularities, e.g., with the common sample-level protection, the currently existing techniques generally require the parties to communicate for each local optimization step, if they want to fully benefit from the secure aggregation in terms of the resulting formal privacy guarantees. In this paper, we show how a simple new analysis allows the parties to perform multiple local optimization steps while still benefiting from using secure aggregation. We show that our analysis enables higher utility models with guaranteed privacy protection under limited number of communication rounds.},
  archive      = {J_TMLR},
  author       = {Mikko A. Heikkilä},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On using secure aggregation in differentially private federated learning with multiple local steps},
  url          = {https://openreview.net/forum?id=uxyWlXPuIg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Illustrated landmark graphs for long-horizon policy
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0AOUWC4ss8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying learning-based approaches to long-horizon sequential decision-making tasks requires a human teacher to carefully craft reward functions or curate demonstrations to elicit desired behaviors. To simplify this, we first introduce an alternative form of task-specification, Illustrated Landmark Graph (ILG), that represents the task as a directed graph where each vertex corresponds to a region of the state space (a landmark), and each edge represents an easier to achieve sub-task. A landmark in the ILG is conveyed to the agent through a few illustrative examples grounded in the agent’s observation space. Second, we propose ILG-Learn, a human in the loop algorithm that interleaves planning over the ILG and sub-task policy learning. ILG-Learn adaptively plans through the ILG by relying on the human teacher’s feedback to estimate the success rates of learned policies. We conduct experiments on long-horizon block stacking and point maze navigation tasks, and find that our approach achieves considerably higher success rates (~ 50% improvement) compared to hierarchical reinforcement learning and imitation learning baselines. Additionally, we highlight how the flexibility of the ILG specification allows the agent to learn a sequence of sub-tasks that is better suited to its limited capabilities.},
  archive      = {J_TMLR},
  author       = {Christopher Watson and Arjun Krishna and Rajeev Alur and Dinesh Jayaraman},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Illustrated landmark graphs for long-horizon policy learning},
  url          = {https://openreview.net/forum?id=0AOUWC4ss8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Show or tell? Effectively prompting vision-language models
for semantic segmentation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0yPWtbR3MC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Vision-Language Models (VLMs) are increasingly being regarded as foundation models that can be instructed to solve diverse tasks by prompting, without task-specific training. We examine the seemingly obvious question: \emph{how to effectively prompt VLMs for semantic segmentation}. To that end, we systematically evaluate the segmentation performance of several recent models guided by either text or visual prompts on the out-of-distribution MESS dataset collection. We introduce a scalable prompting scheme, \emph{few-shot prompted semantic segmentation}, inspired by open-vocabulary segmentation and few-shot learning. It turns out that VLMs lag far behind specialist models trained for a specific segmentation task, by about 30\% on average on the Intersection-over-Union metric. Moreover, we find that text prompts and visual prompts are complementary: each one of the two modes fails on many examples that the other one can solve. Our analysis suggests that being able to anticipate the most effective prompt modality can lead to a 11\% improvement in performance. Motivated by our findings, we propose PromptMatcher, a remarkably simple training-free baseline that combines both text and visual prompts, achieving state-of-the-art results outperforming the best text-prompted VLM by 2.5\%, and the top visual-prompted VLM by 3.5\% on few-shot prompted semantic segmentation.},
  archive      = {J_TMLR},
  author       = {Niccolò Avogaro and Thomas Frick and Mattia Rigotti and Andrea Bartezzaghi and Filip Janicki and A. Cristiano I. Malossi and Konrad Schindler and Roy Assaf},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Show or tell? effectively prompting vision-language models for semantic segmentation},
  url          = {https://openreview.net/forum?id=0yPWtbR3MC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A vector bernstein inequality for self-normalized
martingales. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4ZJjr9YbBw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove a Bernstein inequality for vector-valued self-normalized martingales. We first give an alternative perspective of the corresponding sub-Gaussian bound due to Abbasi-Yadkori et al. via a PAC-Bayesian argument with Gaussian priors. By instantiating this argument to priors drawn uniformly over well-chosen ellipsoids, we obtain a Bernstein bound.},
  archive      = {J_TMLR},
  author       = {Ingvar Ziemann},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A vector bernstein inequality for self-normalized martingales},
  url          = {https://openreview.net/forum?id=4ZJjr9YbBw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical insights into overparameterized models in
multi-task and replay-based continual learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4zGPT0ZwnU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) is a machine learning paradigm that aims to improve the generalization performance of a model on multiple related tasks by training it simultaneously on those tasks. Unlike MTL, where the model has instant access to the training data of all tasks, continual learning (CL) involves adapting to new sequentially arriving tasks over time without forgetting the previously acquired knowledge. Despite the wide practical adoption of CL and MTL and extensive literature on both areas, there remains a gap in the theoretical understanding of these methods when used with overparameterized models such as deep neural networks. This paper studies the overparameterized linear models as a proxy for more complex models. We develop theoretical results describing the effect of various system parameters on the model&#39;s performance in an MTL setup. Specifically, we study the impact of model size, dataset size, and task similarity on the generalization error and knowledge transfer. Additionally, we present theoretical results to characterize the performance of replay-based CL models. Our results reveal the impact of buffer size and model capacity on the forgetting rate in a CL setup and help shed light on some of the state-of-the-art CL methods. Finally, through extensive empirical evaluations, we demonstrate that our theoretical findings are also applicable to deep neural networks, offering valuable guidance for designing MTL and CL models in practice.},
  archive      = {J_TMLR},
  author       = {Mohammadamin Banayeeanzade and Mahdi Soltanolkotabi and Mohammad Rostami},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Theoretical insights into overparameterized models in multi-task and replay-based continual learning},
  url          = {https://openreview.net/forum?id=4zGPT0ZwnU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision-focused surrogate modeling for mixed-integer linear
optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=A6tOXkkE4Z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed-integer optimization is at the core of many online decision-making systems that demand frequent updates of decisions in real time. However, due to their combinatorial nature, mixed-integer linear programs (MILPs) can be difficult to solve, rendering them often unsuitable for time-critical online applications. To address this challenge, we develop a data-driven approach for constructing surrogate optimization models in the form of linear programs (LPs) that can be solved much more efficiently than the corresponding MILPs. We train these surrogate LPs in a decision-focused manner such that for different model inputs, they achieve the same or close to the same optimal solutions as the original MILPs. One key advantage of the proposed method is that it allows the incorporation of all of the original MILP’s linear constraints, which significantly increases the likelihood of obtaining feasible predicted solutions. Results from two computational case studies indicate that this decision-focused surrogate modeling approach is highly data-efficient and provides very accurate predictions of the optimal solutions. In these examples, the resulting surrogate LPs outperform state-of-the-art neural-network-based optimization proxies.},
  archive      = {J_TMLR},
  author       = {Shivi Dixit and Rishabh Gupta and Qi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Decision-focused surrogate modeling for mixed-integer linear optimization},
  url          = {https://openreview.net/forum?id=A6tOXkkE4Z},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering strong lottery tickets in graph transformers: A
path to memory efficient and robust graph learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=B1q9po4LPl">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Transformers (GTs) have recently demonstrated strong capabilities for capturing complex relationships in graph-structured data using global self-attention mechanisms. On the other hand, their high memory requirements during inference remain a challenge for practical deployment. In this study, we investigate the existence of strong lottery tickets (SLTs) — subnetworks within randomly initialized neural networks that can attain competitive accuracy without weight training — in GTs. Previous studies have explored SLTs in message-passing neural networks (MPNNs), showing that SLTs not only exist in MPNNs but also help mitigate over-smoothing problems and improve robustness. However, the potential of SLTs in GTs remains unexplored. With GTs having 4.5$\times$ more parameters than MPNNs, SLTs hold even greater application value in this context. We find that fixed random weights with a traditional SLT search method cannot adapt to imbalances of features in GTs, leading to highly biased attention that destabilizes model performance. To overcome this issue and efficiently search for SLTs, we introduce a novel approach called Adaptive Scaling. We empirically confirm the existence of SLTs within GTs and demonstrate their versatility through extensive experiments across different GT architectures, including NodeFormer, GRIT, and GraphGPS. Our findings demonstrate that SLTs achieve comparable accuracy while reducing memory usage by 2--32$\times$, effectively generalize to out-of-distribution data, and enhance robustness against adversarial perturbations. This work highlights that SLTs offer a resource-efficient approach to improving the scalability, efficiency, and robustness of GTs, with broad implications for applications involving graph data.},
  archive      = {J_TMLR},
  author       = {Hiroaki Ito and Jiale Yan and Hikari Otsuka and Kazushi Kawamura and Masato Motomura and Thiem Van Chu and Daichi Fujiki},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncovering strong lottery tickets in graph transformers: A path to memory efficient and robust graph learning},
  url          = {https://openreview.net/forum?id=B1q9po4LPl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Removing structured noise using diffusion models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=BvKYsaOVEn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving ill-posed inverse problems requires careful formulation of prior beliefs over the signals of interest and an accurate description of their manifestation into noisy measurements. Handcrafted signal priors based on e.g. sparsity are increasingly replaced by data-driven deep generative models, and several groups have recently shown that state-of-the-art score-based diffusion models yield particularly strong performance and flexibility. In this paper, we show that the powerful paradigm of posterior sampling with diffusion models can be extended to include rich, structured, noise models. To that end, we propose a joint conditional reverse diffusion process with learned scores for the noise and signal-generating distribution. We demonstrate strong performance gains across various inverse problems with structured noise, outperforming competitive baselines using normalizing flows, adversarial networks and various posterior sampling methods for diffusion models. This opens up new opportunities and relevant practical applications of diffusion modeling for inverse problems in the context of non-Gaussian measurement models.},
  archive      = {J_TMLR},
  author       = {Tristan Stevens and Hans van Gorp and Faik C Meral and Junseob Shin and Jason Yu and Jean-luc Robert and Ruud Van Sloun},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Removing structured noise using diffusion models},
  url          = {https://openreview.net/forum?id=BvKYsaOVEn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-agent cooperation learning through teammate
lookahead. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CeNNIQ8GJf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative Multi-Agent Reinforcement Learning (MARL) is a rapidly growing research field that has achieved outstanding results across a variety of challenging cooperation tasks. However, existing MARL algorithms typically overlook the concurrent updates of teammate agents. An agent always learns from the data that it cooperates with one set of (current) teammates, but then practices with another set of (updated) teammates. This phenomenon, termed as ``teammate delay&#39;&#39;, leads to a discrepancy between the agent&#39;s learning objective and the actual evaluation scenario, which can degrade learning stability and efficiency. In this paper, we tackle this challenge by introducing a lookahead strategy that enables agents to learn to cooperate with predicted future teammates, allowing the explicit awareness of concurrent teammate updates. This lookahead strategy is designed to seamlessly integrate with existing policy-gradient-based MARL methods, enhancing their performance without significant modifications to their underlying structures. The extensive experiments demonstrate the effectiveness of this approach, showing that the lookahead strategy can enhance the cooperation learning efficiency and achieve superior performance over the state-of-the-art MARL algorithms.},
  archive      = {J_TMLR},
  author       = {Feng Chen and Xinwei Chen and Rong-Jun Qin and Cong Guan and Lei Yuan and Zongzhang Zhang and Yang Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient multi-agent cooperation learning through teammate lookahead},
  url          = {https://openreview.net/forum?id=CeNNIQ8GJf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-context LLMs struggle with long in-context learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Cw2xlg0e46">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have made significant strides in handling long sequences. Some models like Gemini could even be capable of dealing with millions of tokens. However, their performance evaluation has largely been confined to metrics like perplexity and synthetic tasks, which may not fully capture their true abilities in more challenging, real-world scenarios. We introduce a benchmark (LongICLBench) for long in-context learning in extreme-label classification using six datasets with 28 to 174 classes and input lengths from 2K to 50K tokens. Our benchmark requires LLMs to comprehend the entire input to recognize the massive label spaces to make correct predictions. We evaluate on 15 long-context LLMs and find that they perform well on less challenging classification tasks with smaller label space and shorter demonstrations. However, they struggle with more challenging task like Discovery with 174 labels, suggesting a gap in their ability to process long, context-rich sequences. Further analysis reveals a bias towards labels presented later in the sequence and a need for improved reasoning over multiple pieces of information. Our study reveals that long context understanding and reasoning is still a challenging task for the existing LLMs. We believe LongICLBench could serve as a more realistic evaluation for the future long-context LLMs.},
  archive      = {J_TMLR},
  author       = {Tianle Li and Ge Zhang and Quy Duc Do and Xiang Yue and Wenhu Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Long-context LLMs struggle with long in-context learning},
  url          = {https://openreview.net/forum?id=Cw2xlg0e46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-modular classification: Learning to generalize with
memory replacement. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DcIW0idrg8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel memory-modular learner for image classification that separates knowledge memorization from reasoning. Our model enables effective generalization to new classes by simply replacing the memory contents, without the need for model retraining. Unlike traditional models that encode both world knowledge and task-specific skills into their weights during training, our model stores knowledge in the external memory of web-crawled image and text data. At inference time, the model dynamically selects relevant content from the memory based on the input image, allowing it to adapt to arbitrary classes by simply replacing the memory contents. The key differentiator that our learner meta-learns to perform classification tasks with noisy web data from unseen classes, resulting in robust performance across various classification scenarios. Experimental results demonstrate the promising performance and versatility of our approach in handling diverse classification tasks, including zero-shot/few-shot classification of unseen classes, fine-grained classification, and class-incremental classification.},
  archive      = {J_TMLR},
  author       = {Dahyun Kang and Ahmet Iscen and Eunchan Jo and Sua Choi and Minsu Cho and Cordelia Schmid},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Memory-modular classification: Learning to generalize with memory replacement},
  url          = {https://openreview.net/forum?id=DcIW0idrg8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster tree for nearest neighbor search. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ELtNtkGXoK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree-based algorithms are an important and widely used class of algorithms for Nearest Neighbor Search (NNS) with random partition (RP) tree being arguably the most well studied. However, in spite of possessing theoretical guarantees and strong practical performance, a major drawback of the RP tree is its lack of adaptability to the input dataset. Inspired by recent theoretical and practical works for NNS, we attempt to remedy this by introducing *ClusterTree*, a new tree based algorithm. Our approach utilizes randomness as in RP trees while adapting to the underlying cluster structure of the dataset to create well-balanced and meaningful partitions. Experimental evaluations on real world datasets demonstrate improvements over RP trees and other tree based methods for NNS while maintaining efficient construction time. In addition, we show theoretically and empirically that *ClusterTree* finds partitions which are superior to those found by RP trees in preserving the cluster structure of the input dataset.},
  archive      = {J_TMLR},
  author       = {Dan Kushnir and Sandeep Silwal},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cluster tree for nearest neighbor search},
  url          = {https://openreview.net/forum?id=ELtNtkGXoK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparsified state-space models are efficient highway
networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=G1p0YwrX8X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-space models (SSMs) offer a promising architecture for sequence modeling, providing an alternative to Transformers by replacing expensive self-attention with linear recurrences. In this paper, we propose a simple yet effective trick to enhance SSMs within given computational budgets by sparsifying them. Our intuition is that tokens in SSMs are highly redundant due to gradual recurrent updates, and dense recurrence operations block the delivery of past information. In particular, we observe that upper layers of SSMs tend to be more redundant as they encode global information, while lower layers encode local information. Motivated by this, we introduce Simba, a hierarchical sparsification method for SSMs based on token pruning. Simba sparsifies upper layers more than lower layers, encouraging the upper layers to behave like highways. To achieve this, we propose a novel token pruning criterion for SSMs, measuring the global impact of tokens on the final output by accumulating local recurrences. We demonstrate that Simba outperforms the baseline model, Mamba, with the same FLOPS in various natural language tasks. Moreover, we illustrate the effect of highways, showing that Simba not only enhances efficiency but also improves the information flow across long sequences. Code is available at https://github.com/woominsong/Simba.},
  archive      = {J_TMLR},
  author       = {Woomin Song and Jihoon Tack and Sangwoo Mo and Seunghyuk Oh and Jinwoo Shin},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparsified state-space models are efficient highway networks},
  url          = {https://openreview.net/forum?id=G1p0YwrX8X},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient training of multi-task neural solver for
combinatorial optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HJbcwRbMQQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently training a multi-task neural solver for various combinatorial optimization problems (COPs) has been less studied so far. Naive application of conventional multi-task learning approaches often falls short in delivering a high-quality, unified neural solver. This deficiency primarily stems from the significant computational demands and a lack of adequate consideration for the complexities inherent in COPs. In this paper, we propose a general and efficient training paradigm to deliver a unified combinarotial multi-task neural solver. To this end, we resort to the theoretical loss decomposition for multiple tasks under an encoder-decoder framework, which enables more efficient training via proper bandit task-sampling algorithms through an intra-task influence matrix. By employing theoretically grounded approximations, our method significantly enhances overall performance, regardless of whether it is within constrained training budgets, across equivalent training epochs, or in terms of generalization capabilities, when compared to conventional training schedules. On the real-world datasets of TSPLib and CVRPLib, our method also achieved the best results compared to single task learning and multi-task learning approaches. Additionally, the influence matrix provides empirical evidence supporting common practices in the field of learning to optimize, further substantiating the effectiveness of our approach. Our code is open-sourced and available at \url{https://github.com/LOGO-CUHKSZ/MTL-COP}.},
  archive      = {J_TMLR},
  author       = {Chenguang Wang and Zhang-Hua Fu and Pinyan Lu and Tianshu Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient training of multi-task neural solver for combinatorial optimization},
  url          = {https://openreview.net/forum?id=HJbcwRbMQQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent representations in networks trained with the
forward-forward algorithm. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JhYbGiFn3Y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Backpropagation algorithm has often been criticised for its lack of biological realism. In an attempt to find a more biologically plausible alternative, the recently introduced Forward-Forward algorithm replaces the forward and backward passes of Backpropagation with two forward passes. In this work, we show that the internal representations obtained by the Forward-Forward algorithm can organise into category-specific ensembles exhibiting high sparsity -- composed of a low number of active units. This situation is reminiscent of what has been observed in cortical sensory areas, where neuronal ensembles are suggested to serve as the functional building blocks for perception and action. Interestingly, while this sparse pattern does not typically arise in models trained with standard Backpropagation, it can emerge in networks trained with Backpropagation on the same objective proposed for the Forward-Forward algorithm.},
  archive      = {J_TMLR},
  author       = {Niccolo Tosato and Lorenzo Basile and Emanuele Ballarin and Giuseppe De Alteriis and Alberto Cazzaniga and Alessio ansuini},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Emergent representations in networks trained with the forward-forward algorithm},
  url          = {https://openreview.net/forum?id=JhYbGiFn3Y},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FRAP: Faithful and realistic text-to-image generation with
adaptive prompt weighting. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MKCwO34oIq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image (T2I) diffusion models have demonstrated impressive capabilities in generating high-quality images given a text prompt. However, ensuring the prompt-image alignment remains a considerable challenge, i.e., generating images that faithfully align with the prompt&#39;s semantics. Recent works attempt to improve the faithfulness by optimizing the latent code, which potentially could cause the latent code to go out-of-distribution and thus produce unrealistic images. In this paper, we propose FRAP, a simple, yet effective approach based on adaptively adjusting the per-token prompt weights to improve prompt-image alignment and authenticity of the generated images. We design an online algorithm to adaptively update each token&#39;s weight coefficient, which is achieved by minimizing a unified objective function that encourages object presence and the binding of object-modifier pairs. Through extensive evaluations, we show FRAP generates images with significantly higher prompt-image alignment to prompts from complex datasets, while having a lower average latency compared to recent latent code optimization methods, e.g., 4 seconds faster than D&amp;B on the COCO-Subject dataset. Furthermore, through visual comparisons and evaluation of the CLIP-IQA-Real metric, we show that FRAP not only improves prompt-image alignment but also generates more authentic images with realistic appearances. We also explore combining FRAP with prompt rewriting LLM to recover their degraded prompt-image alignment, where we observe improvements in both prompt-image alignment and image quality. We release the code at the following link: https://github.com/LiyaoJiang1998/FRAP/.},
  archive      = {J_TMLR},
  author       = {Liyao Jiang and Negar Hassanpour and Mohammad Salameh and Mohan Sai Singamsetti and Fengyu Sun and Wei Lu and Di Niu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FRAP: Faithful and realistic text-to-image generation with adaptive prompt weighting},
  url          = {https://openreview.net/forum?id=MKCwO34oIq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture-of-transformers: A sparse and scalable architecture
for multi-modal foundation models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Nu6N69i8SB">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of large language models (LLMs) has expanded to multi-modal systems capable of processing text, images, and speech within a unified framework. Training these models demands significantly larger datasets and computational resources compared to text-only LLMs. To address the scaling challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal transformer architecture that significantly reduces pretraining computational costs. MoT decouples non-embedding parameters of the model by modality -- including feed-forward networks, attention matrices, and layer normalization -- enabling modality-specific processing with global self-attention over the full input sequence. We evaluate MoT across multiple settings and model scales. In the Chameleon 7B setting (autoregressive text-and-image generation), MoT matches the dense baseline&#39;s performance using only 55.8% of the FLOPs. When extended to include speech, MoT reaches speech performance comparable to the dense baseline with only 37.2% of the FLOPs. In the Transfusion setting, where text and image are trained with different objectives, a 7B MoT model matches the image modality performance of the dense baseline with one third of the FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image generation metrics. System profiling further highlights MoT&#39;s practical benefits, achieving dense baseline image quality in 47.2% of the wall-clock time and text quality in 75.6% of the wall-clock time (measured on AWS p4de.24xlarge instances with NVIDIA A100 GPUs).},
  archive      = {J_TMLR},
  author       = {Weixin Liang and LILI YU and Liang Luo and Srini Iyer and Ning Dong and Chunting Zhou and Gargi Ghosh and Mike Lewis and Wen-tau Yih and Luke Zettlemoyer and Xi Victoria Lin},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixture-of-transformers: A sparse and scalable architecture for multi-modal foundation models},
  url          = {https://openreview.net/forum?id=Nu6N69i8SB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Daphne: Multi-pass compilation of probabilistic programs
into graphical models and neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OGCuDFab4b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Daphne is a probabilistic programming system that provides an expressive syntax to denote a large, but restricted, class of probabilistic models. Programs written in the Daphne language can be compiled into a general graph data structure of a corresponding probabilistic graphical model with simple link functions that can easily be implemented in a wide range of programming environments. Alternatively Daphne can also further compile such a graphical model into understandable and vectorized PyTorch code that can be used to train neural networks for inference. The Daphne compiler is structured in a layered multi-pass compiler framework that allows independent and easy extension of the syntax by adding additional passes. It leverages extensive partial evaluation to reduce all syntax extensions to the graphical model at compile time.},
  archive      = {J_TMLR},
  author       = {Christian Dietrich Weilbach and Frank Wood},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Daphne: Multi-pass compilation of probabilistic programs into graphical models and neural networks},
  url          = {https://openreview.net/forum?id=OGCuDFab4b},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive incentive design for markov decision processes with
unknown rewards. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Rwf31BYTAU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incentive design, also known as model design or environment design for Markov decision processes(MDPs), refers to a class of problems in which a leader can incentivize his follower by modifying the follower&#39;s reward function, in anticipation that the follower&#39;s optimal policy in the resulting MDP can be desirable for the leader&#39;s objective. In this work, we propose gradient-ascent algorithms to compute the leader&#39;s optimal incentive design, despite the lack of knowledge about the follower&#39;s reward function. First, we formulate the incentive design problem as a bi-level optimization problem and demonstrate that, by the softmax temporal consistency between the follower&#39;s policy and value function, the bi-level optimization problem can be reduced to single-level optimization, for which a gradient-based algorithm can be developed to optimize the leader&#39;s objective. We establish several key properties of incentive design in MDPs and prove the convergence of the proposed gradient-based method. Next, we show that the gradient terms can be estimated from observations of the follower&#39;s best response policy, enabling the use of a stochastic gradient-ascent algorithm to compute a locally optimal incentive design without knowing or learning the follower&#39;s reward function. Finally, we analyze the conditions under which an incentive design remains optimal for two different rewards which are policy invariant. The effectiveness of the proposed algorithm is demonstrated using a small probabilistic transition system and a stochastic gridworld.},
  archive      = {J_TMLR},
  author       = {Haoxiang Ma and Shuo Han and Ahmed Hemida and Charles A kamhoua and Jie Fu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive incentive design for markov decision processes with unknown rewards},
  url          = {https://openreview.net/forum?id=Rwf31BYTAU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation-based bayesian inference from privacy protected
data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SB7JzhDG45">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many modern statistical analysis and machine learning applications require training models on sensitive user data. Under a formal definition of privacy protection, differentially private algorithms inject calibrated noise into the confidential data or during the data analysis process to produce privacy-protected datasets or queries. However, restricting access to only privatized data during statistical analysis makes it computationally challenging to make valid statistical inferences. In this work, we propose simulation-based inference methods from privacy-protected datasets. In addition to sequential Monte Carlo approximate Bayesian computation, we adopt neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and with ordinary linear regression models. Illustrating the privacy-utility trade-off, our experiments and analysis demonstrate the necessity and feasibility of designing valid statistical inference procedures to correct for biases introduced by the privacy-protection mechanisms.},
  archive      = {J_TMLR},
  author       = {Yifei Xiong and Nianqiao Ju and Sanguo Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Simulation-based bayesian inference from privacy protected data},
  url          = {https://openreview.net/forum?id=SB7JzhDG45},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuron-based explanations of neural networks sacrifice
completeness and interpretability. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UWNa9Pv6qA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High quality explanations of neural networks (NNs) should exhibit two key properties. Completeness ensures that they accurately reflect a network’s function and interpretability makes them understandable to humans. Many existing methods provide explanations of individual neurons within a network. In this work we provide evidence that for AlexNet pretrained on ImageNet, neuron-based explanation methods sacrifice both completeness and interpretability compared to activation principal components. Neurons are a poor basis for AlexNet embeddings because they don’t account for the distributed nature of these representations. By examining two quantitative measures of completeness and conducting a user study to measure interpretability, we show the most important principal components provide more complete and interpretable explanations than the most important neurons. Much of the activation variance may be explained by examining relatively few high-variance PCs, as opposed to studying every neuron. These principal components also strongly affect network function, and are significantly more interpretable than neurons. Our findings suggest that explanation methods for networks like AlexNet should avoid using neurons as a basis for embeddings and instead choose a basis, such as principal components, which accounts for the high dimensional and distributed nature of a network&#39;s internal representations. Interactive demo and code available at https://ndey96.github.io/neuron-explanations-sacrifice.},
  archive      = {J_TMLR},
  author       = {Nolan Simran Dey and Eric Taylor and Alexander Wong and Bryan P. Tripp and Graham W. Taylor},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neuron-based explanations of neural networks sacrifice completeness and interpretability},
  url          = {https://openreview.net/forum?id=UWNa9Pv6qA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On using certified training towards empirical robustness.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UaaT2fI9DC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training is arguably the most popular way to provide empirical robustness against specific adversarial examples. While variants based on multi-step attacks incur significant computational overhead, single-step variants are vulnerable to a failure mode known as catastrophic overfitting, which hinders their practical utility for large perturbations. A parallel line of work, certified training, has focused on producing networks amenable to formal guarantees of robustness against any possible attack. However, the wide gap between the best-performing empirical and certified defenses has severely limited the applicability of the latter. Inspired by recent developments in certified training, which rely on a combination of adversarial attacks with network over-approximations, and by the connections between local linearity and catastrophic overfitting, we present experimental evidence on the practical utility and limitations of using certified training towards empirical robustness. We show that, when tuned for the purpose, a recent certified training algorithm can prevent catastrophic overfitting on single-step attacks, and that it can bridge the gap to multi-step baselines under appropriate experimental settings. Finally, we present a conceptually simple regularizer for network over-approximations that can achieve similar effects while markedly reducing runtime.},
  archive      = {J_TMLR},
  author       = {Alessandro De Palma and Serge Durand and Zakaria Chihani and François Terrier and Caterina Urban},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On using certified training towards empirical robustness},
  url          = {https://openreview.net/forum?id=UaaT2fI9DC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust symbolic regression for dynamical system
identification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZfPbCFZQbx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world complex systems often miss high-fidelity physical descriptions and are typically subject to partial observability. Learning the dynamics of such systems is a challenging and ubiquitous problem, encountered in diverse critical applications which require interpretability and qualitative guarantees.Our paper addresses this problem in the case of sparsely observed probability distribution flows, governed by ODEs. Specifically, we devise a {\it white box} approach -dubbed Symbolic Distribution Flow Learner (\texttt{SDFL})- leveraging symbolic search with a Wasserstein-based loss function, resulting in a robust model-recovery scheme which naturally lends itself to cope with partial observability. Additionally, we furnish the proposed framework with theoretical guarantees on the number of required {\it snapshots} to achieve a certain level of fidelity in the model-discovery. We illustrate the performance of the proposed scheme on the prototypical problem of Kuramoto networks and a standard benchmark of single-cell RNA sequence trajectory data. The numerical experiments demonstrate the competitive performance of \texttt{SDFL} in comparison to the state-of-the-art.},
  archive      = {J_TMLR},
  author       = {Ramzi Dakhmouche and Ivan Lunati and Hossein Gorji},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust symbolic regression for dynamical system identification},
  url          = {https://openreview.net/forum?id=ZfPbCFZQbx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedDr+: Stabilizing dot-regression with global feature
distillation for federated learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=a6WthNFhL2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has emerged as a pivotal framework for the development of effective global models (global FL) or personalized models (personalized FL) across clients with heterogeneous, non-iid data distribution. A key challenge in FL is client drift, where data heterogeneity impedes the aggregation of scattered knowledge. Recent studies have tackled the client drift issue by identifying significant divergence in the last linear (classifier) layer. To mitigate this divergence, strategies such as freezing the classifier weights and aligning the feature extractor accordingly have proven effective. Although the local alignment between classifier and feature extractor has been studied as a crucial factor in FL, we observe that it may lead the model to overemphasize the observed classes and underestimate the unobserved classes within each client. Therefore, our goals are twofold: (1) improving local alignment and (2) maintaining the representation of unseen class samples, ensuring that the solution seamlessly incorporates knowledge from individual clients, thus enhancing performance in both global and personalized FL. To achieve this, we introduce a novel algorithm named FedDr+, which empowers local model alignment using dot-regression loss. FedDr+ freezes the classifier as a simplex ETF to align the features and improves aggregated global models by employing a feature distillation mechanism to retain information about unseen/missing classes. Our empirical results demonstrate that FedDr+ not only outperforms methods with a frozen classifier but also surpasses other state-of-the-art approaches, ensuring robust performance across diverse data distributions.},
  archive      = {J_TMLR},
  author       = {Seongyoon Kim and Minchan Jeong and Sungnyun Kim and Sungwoo Cho and Sumyeong Ahn and Se-Young Yun},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FedDr+: Stabilizing dot-regression with global feature distillation for federated learning},
  url          = {https://openreview.net/forum?id=a6WthNFhL2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified view of double-weighting for marginal distribution
shift. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=aPyJilTiIb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised classification traditionally assumes that training and testing samples are drawn from the same underlying distribution. However, practical scenarios are often affected by distribution shifts, such as covariate and label shifts. Most existing techniques for correcting distribution shifts are based on a reweighted approach that weights training samples, assigning lower relevance to the samples that are unlikely at testing. However, these methods may achieve poor performance when the weights obtained take large values at certain training samples. In addition, in multi-source cases, existing methods do not exploit complementary information among sources, and equally combine sources for all instances. In this paper, we establish a unified learning framework for distribution shift adaptation. We present a double-weighting approach to deal with distribution shifts, considering weight functions associated with both training and testing samples. For the multi-source case, the presented methods assign source-dependent weights for training and testing samples, where weights are obtained jointly using information from all sources. We also present generalization bounds for the proposed methods that show a significant increase in the effective sample size compared with existing approaches. Empirically, the proposed methods achieve enhanced classification performance in both synthetic and empirical experiments.},
  archive      = {J_TMLR},
  author       = {José I. Segovia-Martín and Santiago Mazuelas and Anqi Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A unified view of double-weighting for marginal distribution shift},
  url          = {https://openreview.net/forum?id=aPyJilTiIb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning population-based methods for reinforcement
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=d9htascfP8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) algorithms are highly sensitive to their hyperparameter settings. Recently, numerous methods have been proposed to dynamically optimize these hyperparameters. One prominent approach is Population-Based Bandits (PB2), which uses time-varying Gaussian processes (GP) to dynamically optimize hyperparameters with a population of parallel agents. Despite its strong overall performance, PB2 experiences slow starts due to the GP initially lacking sufficient information. To mitigate this issue, we propose four different methods that utilize meta-data from various environments. These approaches are novel in that they adapt meta-learning methods to accommodate the time-varying setting. Among these approaches, MultiTaskPB2, which uses meta-learning for the surrogate model, stands out as the most promising approach. It outperforms PB2 and other baselines in both anytime and final performance across two RL environment families.},
  archive      = {J_TMLR},
  author       = {Johannes Hog and Raghu Rajan and André Biedenkapp and Noor Awad and Frank Hutter and Vu Nguyen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning population-based methods for reinforcement learning},
  url          = {https://openreview.net/forum?id=d9htascfP8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic neural operators for functional uncertainty
quantification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gangoPXSRw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators aim to approximate the solution operator of a system of differential equations purely from data. They have shown immense success in modeling complex dynamical systems across various domains. However, the occurrence of uncertainties inherent in both model and data has so far rarely been taken into account\textemdash{}a critical limitation in complex, chaotic systems such as weather forecasting. In this paper, we introduce the probabilistic neural operator (PNO), a framework for learning probability distributions over the output function space of neural operators. PNO extends neural operators with generative modeling based on strictly proper scoring rules, integrating uncertainty information directly into the training process. We provide a theoretical justification for the approach and demonstrate improved performance in quantifying uncertainty across different domains and with respect to different baselines. Furthermore, PNO requires minimal adjustment to existing architectures, shows improved performance for most probabilistic prediction tasks, and leads to well-calibrated predictive distributions and adequate uncertainty representations even for long dynamical trajectories. Implementing our approach into large-scale models for physical applications can lead to improvements in corresponding uncertainty quantification and extreme event identification, ultimately leading to a deeper understanding of the prediction of such surrogate models.},
  archive      = {J_TMLR},
  author       = {Christopher Bülte and Philipp Scholl and Gitta Kutyniok},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Probabilistic neural operators for functional uncertainty quantification},
  url          = {https://openreview.net/forum?id=gangoPXSRw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAFE-NID: Self-attention with normalizing-flow encodings for
network intrusion detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=hDywd5AbIM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are increasingly adopted to monitor network traffic and detect intrusions. In this work, we introduce SAFE-NID, a novel machine learning approach for real-time packet-level traffic monitoring and intrusion detection that includes a safeguard to detect zero day attacks as out-of-distribution inputs. Unlike traditional models, which falter against zero-day attacks and concept drift, SAFE-NID leverages a lightweight encoder-only transformer architecture combined with a novel normalizing flows-based safeguard. This safeguard not only quantifies uncertainty but also identifies out-of-distribution (OOD) inputs, enabling robust performance in dynamic threat landscapes. Our generative model learns class-conditional representations of the internal features of the deep neural network. We demonstrate the effectiveness of our approach by converting publicly available network flow-level intrusion datasets into packet-level ones. We release the labeled packet-level versions of these datasets with over 50 million packets each and describe the challenges in creating these datasets. We withhold from the training data certain attack categories to simulate zero-day attacks. Existing deep learning models, which achieve an accuracy of over 99% when detecting known attacks, only correctly classify 1% of the novel attacks. Our proposed transformer architecture with normalizing flows model safeguard achieves an area under the receiver operating characteristic curve of over 0.97 in detecting these novel inputs, outperforming existing combinations of neural architectures and model safeguards. The additional latency in processing each packet by the safeguard is a small fraction of the overall inference task. This dramatic improvement in detecting zero-day attacks and distribution shifts emphasizes SAFE-NID’s novelty and utility as a reliable and efficient safety monitoring tool for real-world network intrusion detection.},
  archive      = {J_TMLR},
  author       = {Brian Matejek and Ashish Gehani and Nathaniel D. Bastian and Daniel J Clouse and Bradford J Kline and Susmit Jha},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SAFE-NID: Self-attention with normalizing-flow encodings for network intrusion detection},
  url          = {https://openreview.net/forum?id=hDywd5AbIM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Posterior sampling for reinforcement learning on graphs.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=kd6CfmdPfX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many Markov Decision Processes (MDPs) exhibit structure in their state and action spaces that is not exploited. We consider the case where the structure can be modelled using a directed acyclic graph (DAG) composed of nodes and edges. In this case, each node has a state, and the state transition dynamics are influenced by the states and actions at its parent nodes. We propose an MDP framework, \emph{Directed Acyclic Markov Decision Process} (DAMDP) that formalises this problem, and we develop algorithms to perform planning and learning. Crucially, DAMDPs retain many of the benefits of MDPs, as we can show that Dynamic Programming can find the optimal policy in known DAMDPs. We also demonstrate how to perform Reinforcement Learning in DAMDPs when the transition probabilities and the reward function are unknown. To this end, we derive a posterior sampling-based algorithm that is able to leverage the graph structure to boost learning efficiency. Moreover, we obtain a theoretical bound on the Bayesian regret for this algorithm, which directly shows the efficiency gain from considering the graph structure. We then conclude by empirically demonstrating that by harnessing the DAMDP, our algorithm outperforms traditional posterior sampling for Reinforcement Learning in both a maximum flow problem and a real-world wind farm optimisation task.},
  archive      = {J_TMLR},
  author       = {Arnaud Robert and Aldo A. Faisal and Ciara Pike-Burke},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Posterior sampling for reinforcement learning on graphs},
  url          = {https://openreview.net/forum?id=kd6CfmdPfX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compositionality in time series: A proof of concept using
symbolic dynamics and compositional data augmentation. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=msI02LXVJX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates whether time series of natural phenomena can be understood as being generated by sequences of latent states which are ordered in systematic and regular ways. We focus on clinical time series and ask whether clinical measurements can be interpreted as being generated by meaningful physiological states whose succession follows systematic principles. Uncovering the underlying compositional structure will allow us to create synthetic data to alleviate the notorious problem of sparse and low-resource data settings in clinical time series forecasting, and deepen our understanding of clinical data. We start by conceptualizing compositionality for time series as a property of the data generation process, and then study data-driven procedures that can reconstruct the elementary states and composition rules of this process. We evaluate the success of this methods using two empirical tests originating from a domain adaptation perspective. Both tests infer the similarity of the original time series distribution and the synthetic time series distribution from the similarity of expected risk of time series forecasting models trained and tested on original and synthesized data in specific ways. Our experimental results show that the test set performance achieved by training on compositionally synthesized data is comparable to training on original clinical time series data, and that evaluation of models on compositionally synthesized test data shows similar results to evaluating on original test data. In both experiments, performance based on compositionally synthesized data by far surpasses that based on synthetic data that were created by randomization-based data augmentation. An additional downstream evaluation of the prediction task of sequential organ failure assessment (SOFA) scores shows significant performance gains when model training is entirely based on compositionally synthesized data compared to training on original data, with improvements increasing with the size of the synthesized training set.},
  archive      = {J_TMLR},
  author       = {Michael Hagmann and Michael Staniek and Stefan Riezler},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Compositionality in time series: A proof of concept using symbolic dynamics and compositional data augmentation},
  url          = {https://openreview.net/forum?id=msI02LXVJX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplayer information asymmetric contextual bandits.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nMCJ8bFq4B">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-player contextual bandits are a well-studied problem in reinforcement learning that has seen applications in various fields such as advertising, healthcare, and finance. In light of the recent work on information asymmetric bandits, we propose a novel multiplayer information asymmetric contextual bandit framework where there are multiple players each with their own set of actions. At every round, they observe the same context vectors and simultaneously take an action from their own set of actions, giving rise to a joint action. However, upon taking this action the players are subjected to information asymmetry in (1) actions and/or (2) rewards. We designed an algorithm mLinUCB by modifying the classical single-player algorithm LinUCB in \cite{chu2011contextual} to achieve the optimal regret $O(\sqrt{T})$ when only one kind of asymmetry is present. We then propose a novel algorithm ETC that is built on explore-then-commit principles to achieve the same optimal regret when both types of asymmetry are present.},
  archive      = {J_TMLR},
  author       = {William Chang and Yuanhao Lu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multiplayer information asymmetric contextual bandits},
  url          = {https://openreview.net/forum?id=nMCJ8bFq4B},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding and robustifying sub-domain alignment for
domain adaptation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oAzu0gzUUb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unsupervised domain adaptation (UDA), aligning source and target domains improves the predictive performance of learned models on the target domain. A common methodological improvement in alignment methods is to divide the domains and align sub-domains instead. These sub-domain-based algorithms have demonstrated great empirical success but lack theoretical support. In this work, we establish a rigorous theoretical understanding of the advantages of these methods that have the potential to enhance their overall impact on the field. Our theory uncovers that sub-domain-based methods optimize an error bound that is at least as strong as non-sub-domain-based error bounds and is empirically verified to be much stronger. Furthermore, our analysis indicates that when the marginal weights of sub-domains shift between source and target tasks, the performance of these methods may be compromised. We therefore implement an algorithm to robustify sub-domain alignment for domain adaptation under sub-domain shift, offering a valuable adaptation strategy for future sub-domain-based methods. Empirical experiments across various benchmarks validate our theoretical insights, prove the necessity for the proposed adaptation strategy, and demonstrate the algorithm&#39;s competitiveness in handling label shift.},
  archive      = {J_TMLR},
  author       = {Yiling Liu and Juncheng Dong and Ziyang Jiang and Ahmed Aloui and Keyu Li and Michael Hunter Klein and Vahid Tarokh and David Carlson},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding and robustifying sub-domain alignment for domain adaptation},
  url          = {https://openreview.net/forum?id=oAzu0gzUUb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relationship between batch size and number of steps needed
for nonconvex optimization of stochastic gradient descent using
armijo-line-search learning rate. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=pqZ6nOm3WF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While stochastic gradient descent (SGD) can use various learning rates, such as constant or diminishing rates, previous numerical results showed that SGD performs better than other deep-learning optimizers when it uses learning rates given by line search methods. In this paper, we perform a convergence analysis on SGD with a learning rate given by an Armijo line search for nonconvex optimization indicating that the upper bound of the expectation of the squared norm of the full gradient becomes small when the number of steps and the batch size are large. Next, we show that, for SGD with the Armijo-line-search learning rate, the number of steps needed for nonconvex optimization is a monotone decreasing convex function of the batch size; that is, the number of steps needed for nonconvex optimization decreases as the batch size increases. Furthermore, we show that the stochastic first-order oracle (SFO) complexity, which is the stochastic gradient computation cost, is a convex function of the batch size; that is, there exists a critical batch size that minimizes the SFO complexity. Finally, we provide numerical results that support our theoretical results.},
  archive      = {J_TMLR},
  author       = {Yuki Tsukada and Hideaki Iiduka},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Relationship between batch size and number of steps needed for nonconvex optimization of stochastic gradient descent using armijo-line-search learning rate},
  url          = {https://openreview.net/forum?id=pqZ6nOm3WF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information theoretic approach to machine unlearning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=t1utIThKHD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To comply with AI and data regulations, the need to forget private or copyrighted information from trained machine learning models is increasingly important. The key challenge in unlearning is forgetting the necessary data in a timely manner, while preserving model performance. In this work, we address the zero-shot unlearning scenario, whereby an unlearning algorithm must be able to remove data given only a trained model and the data to be forgotten. We explore unlearning from an information theoretic perspective, connecting the influence of a sample to the information gain a model receives by observing it. From this, we derive a simple but principled zero-shot unlearning method based on the geometry of the model. Our approach takes the form of minimising the gradient of a learned function with respect to a small neighbourhood around a target forget point. This induces a smoothing effect, causing forgetting by moving the boundary of the classifier. We explore the intuition behind why this approach can jointly unlearn forget samples while preserving general model performance through a series of low-dimensional experiments. We perform extensive empirical evaluation of our method over a range of contemporary benchmarks, verifying that our method is competitive with state-of-the-art performance under the strict constraints of zero-shot unlearning.},
  archive      = {J_TMLR},
  author       = {Jack Foster and Kyle Fogarty and Stefan Schoepf and Zack Dugue and Cengiz Oztireli and Alexandra Brintrup},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An information theoretic approach to machine unlearning},
  url          = {https://openreview.net/forum?id=t1utIThKHD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence learning in complex systems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tUnyInYbjK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High sample complexity hampers the successful application of reinforcement learning methods, especially in real-world problems where simulating complex dynamics is computationally demanding. Influence-based abstraction (IBA) was proposed to mitigate this issue by breaking down the global model of large-scale distributed systems, such as traffic control problems, into small local sub-models. Each local model includes only a few state variables and a representation of the influence exerted by the external portion of the system. This approach allows converting a complex simulator into local lightweight simulators, enabling more effective applications of planning and reinforcement learning methods. However, the effectiveness of IBA critically depends on the ability to accurately approximate the influence of each local model. While there are a few examples showing promising results in benchmark problems, the question of whether this approach is feasible in more practical scenarios remains open. In this work, we take steps towards addressing this question by conducting an extensive empirical study of learning models for influence approximations in various realistic domains, and evaluating how these models generalize over long horizons. We find that learning the influence is often a manageable learning task, even for complex and large systems. Additionally, we demonstrate the efficacy of the approximation models for long-horizon problems. By using short trajectories, we can learn accurate influence approximations for much longer horizons.},
  archive      = {J_TMLR},
  author       = {Elena Congeduti and roberto rocchetta and Frans A Oliehoek},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Influence learning in complex systems},
  url          = {https://openreview.net/forum?id=tUnyInYbjK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building blocks for robust and effective semi-supervised
real-world object detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=vRYt8QLKqK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised object detection (SSOD) based on pseudo-labeling significantly reduces dependence on large labeled datasets by effectively leveraging both labeled and unlabeled data. However, real-world applications of SSOD often face critical challenges, including class imbalance, label noise, and labeling errors. We present an in-depth analysis of SSOD under real-world conditions, uncovering causes of suboptimal pseudo-labeling and key trade-offs between label quality and quantity. Based on our findings, we propose four building blocks that can be seamlessly integrated into an SSOD framework. Rare Class Collage (RCC): a data augmentation method that enhances the representation of rare classes by creating collages of rare objects. Rare Class Focus (RCF): a stratified batch sampling strategy that ensures a more balanced representation of all classes during training. Ground Truth Label Correction (GLC): a label refinement method that identifies and corrects false, missing, and noisy ground truth labels by leveraging the consistency of teacher model predictions. Pseudo-Label Selection (PLS): a selection method for removing low-quality pseudo-labeled images, guided by a novel metric estimating the missing detection rate while accounting for class rarity. We validate our methods through comprehensive experiments on autonomous driving datasets, resulting in up to 6% increase in SSOD performance. Overall, our investigation and novel, data-centric, and broadly applicable building blocks enable robust and effective SSOD in complex, real-world scenarios. Code is available at https://mos-ks.github.io/publications.},
  archive      = {J_TMLR},
  author       = {Moussa Kassem Sbeyti and Nadja Klein and Azarm Nowzad and Fikret Sivrikaya and Sahin Albayrak},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Building blocks for robust and effective semi-supervised real-world object detection},
  url          = {https://openreview.net/forum?id=vRYt8QLKqK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Salsa fresca: Angular embeddings and pre-training for ML
attacks on learning with errors. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=w4nd5695sq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with Errors (LWE) is a hard math problem underlying recently standardized post-quantum cryptography (PQC) systems for key exchange and digital signatures. Prior work proposed new machine learning (ML)-based attacks on LWE problems with small, sparse secrets, but these attacks require millions of LWE samples to train on and take days to recover secrets. We propose three key methods---better preprocessing, angular embeddings and model pre-training---to improve these attacks, speeding up preprocessing by $25\times$ and improving model sample efficiency by $10\times$. We demonstrate for the first time that pre-training improves and reduces the cost of ML attacks on LWE. Our architecture improvements enable scaling to larger-dimension LWE problems: this work is the first instance of ML attacks recovering sparse binary secrets in dimension $n=1024$, the smallest dimension used in practice for homomorphic encryption applications of LWE where sparse binary secrets are proposed, albeit for larger modulus $q$. Our ML-based approach is the only attack which has successfully recovered secrets for these parameters.},
  archive      = {J_TMLR},
  author       = {Samuel Stevens and Emily Wenger and Cathy Yuanchen Li and Niklas Nolte and Eshika Saxena and Francois Charton and Kristin E. Lauter},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Salsa fresca: Angular embeddings and pre-training for ML attacks on learning with errors},
  url          = {https://openreview.net/forum?id=w4nd5695sq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A limitation on black-box dynamics approaches to
reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wPHVijYksq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove a fundamental limitation on the computational efficiency of a large class of Reinforcement Learning (RL) methods. This limitation applies to model-free RL methods as well as some model-based methods, such as AlphaZero. We provide a formalism that describes this class and present a family of RL problems provably intractable for these methods. Conversely, the problems in the family can be efficiently solved by toy methods. We identify several types of algorithms proposed in the literature that can avoid our limitation, including algorithms that construct an inverse dynamics model, and planning algorithms that leverage an explicit model of the dynamics.},
  archive      = {J_TMLR},
  author       = {Brieuc Pinon and Raphael Jungers and Jean-Charles Delvenne},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A limitation on black-box dynamics approaches to reinforcement learning},
  url          = {https://openreview.net/forum?id=wPHVijYksq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What’s left after distillation? How knowledge transfer
impacts fairness and bias. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xBbj46Y2fN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Distillation is a commonly used Deep Neural Network (DNN) compression method, which often maintains overall generalization performance. However, we show that even for balanced image classification datasets, such as CIFAR-100, Tiny ImageNet and ImageNet, as many as 41% of the classes are statistically significantly affected by distillation when comparing class-wise accuracy (i.e. class bias) between a teacher/distilled student or distilled student/non-distilled student model. Changes in class bias are not necessarily an undesirable outcome when considered outside of the context of a model’s usage. Using two common fairness metrics, Demographic Parity Difference (DPD) and Equalized Odds Difference (EOD) on models trained with the CelebA, Trifeature, and HateXplain datasets, our results suggest that increasing the distillation temperature improves the distilled student model’s fairness, and the distilled student fairness can even surpass the fairness of the teacher model at high temperatures. Additionally, we examine individual fairness, ensuring similar instances receive similar predictions. Our results confirm that higher temperatures also improve the distilled student model’s individual fairness. This study highlights the uneven effects of distillation on certain classes and its potentially significant role in fairness, emphasizing that caution is warranted when using distilled models for sensitive application domains.},
  archive      = {J_TMLR},
  author       = {Aida Mohammadshahi and Yani Ioannou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {What’s left after distillation? how knowledge transfer impacts fairness and bias},
  url          = {https://openreview.net/forum?id=xBbj46Y2fN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting sub-population specific viral evolution.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Mae23iEqPS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting the change in the distribution of viral variants is crucial for therapeutic design and disease surveillance. This task poses significant modeling challenges due to the sharp differences in virus distributions across sub-populations (e.g., countries) and their dynamic interactions. Existing machine learning approaches that model the variant distribution as a whole are incapable of making location-specific predictions and ignore transmissions that shape the viral landscape. In this paper, we propose a sub-population specific protein evolution model, which predicts the time-resolved distributions of viral proteins in different locations. The algorithm explicitly models the transmission rates between sub-populations and learns their interdependence from data. The change in protein distributions across all sub-populations is defined through a linear ordinary differential equation (ODE) parametrized by transmission rates. Solving this ODE yields the likelihood of a given protein occurring in particular sub-populations. Multi-year evaluation on both SARS-CoV-2 and influenza A/H3N2 demonstrates that our model outperforms baselines in accurately predicting distributions of viral proteins across continents and countries. We also find that the transmission rates learned from data are consistent with the transmission pathways discovered by retrospective phylogenetic analysis.},
  archive      = {J_TMLR},
  author       = {Wenxian Shi and Menghua Wu and Regina Barzilay},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Predicting sub-population specific viral evolution},
  url          = {https://openreview.net/forum?id=Mae23iEqPS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposing the dark matter of sparse autoencoders.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sXq3Wb3vef">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse autoencoders (SAEs) are a promising technique for decomposing language model activations into interpretable linear features. However, current SAEs fall short of completely explaining model performance, resulting in ``dark matter&#39;&#39;: unexplained variance in activations. This work investigates dark matter as an object of study in its own right. Surprisingly, we find that much of SAE dark matter---about half of the error vector itself and $&gt;90\% $ of its norm---can be linearly predicted from the initial activation vector. Additionally, we find that the scaling behavior of SAE error norms at a per token level is remarkably predictable: larger SAEs mostly struggle to reconstruct the same contexts as smaller SAEs. We build on the linear representation hypothesis to propose models of activations that might lead to these observations, including postulating a new type of ``introduced error&#39;&#39;; these insights imply that the part of the SAE error vector that cannot be linearly predicted (``nonlinear&#39;&#39; error) might be fundamentally different from the linearly predictable component. To validate this hypothesis, we empirically analyze nonlinear SAE error and show that 1) it contains fewer not yet learned features, 2) SAEs trained on it are quantitatively worse, 3) it helps predict SAE per-token scaling behavior, and 4) it is responsible for a proportional amount of the downstream increase in cross entropy loss when SAE activations are inserted into the model. Finally, we examine two methods to reduce nonlinear SAE error: inference time gradient pursuit, which leads to a very slight decrease in nonlinear error, and linear transformations from earlier layer SAE outputs, which leads to a larger reduction.},
  archive      = {J_TMLR},
  author       = {Joshua Engels and Logan Riggs Smith and Max Tegmark},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Decomposing the dark matter of sparse autoencoders},
  url          = {https://openreview.net/forum?id=sXq3Wb3vef},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
