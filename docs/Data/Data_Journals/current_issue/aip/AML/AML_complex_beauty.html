<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AML_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aml---23">AML - 23</h2>
<ul>
<li><details>
<summary>
(2025). TOMFuN: A tensorized optical multimodal fusion network.
<em>AML</em>, <em>3</em>(1), 016121. (<a
href="https://doi.org/10.1063/5.0255883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a real-size, single-shot, high-speed, and energy-efficient tensorized optical multimodal fusion network (TOMFuN) on an electro-photonic large-scale III–V-on-Si in-memory compute engine. The TOMFuN architecture leverages a memory-efficient and low-complexity self-attention for the embedding network for the text information and tensor-train and CANDECOMP/PARAFAC decompositions for compressing the model parameters in the large-scale fully connected layers. Compared to full-size counterparts, our proposed network maintains a compatible inference accuracy in multimodal sentiment analysis tasks while requiring 92.8× fewer model parameters and 51.3× fewer hardware resources. Furthermore, the impact of photonic device imperfections on the TOMFuN architecture is investigated. The simulation results show that noise-aware on-chip training exhibits superior robustness. Finally, chip performance analysis shows that our TOMFuN inference accelerator has 230.73 PetaOps computational speed, 6.51 TOPS/W power efficiency, and 2.7 µ s latency with the input dimensions of 1024.},
  archive      = {J_AML},
  author       = {Xiao, Xian and Zhao, Yequan and Yuan, Yuan and Kurczveil, Geza and Fiorentino, Marco and Beausoleil, Ray and Zhang, Zheng},
  doi          = {10.1063/5.0255883},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016121},
  shortjournal = {APL Mach. Learn.},
  title        = {TOMFuN: A tensorized optical multimodal fusion network},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polarization current-based reservoir computing utilizing an
anti-ferroelectric-like HfZrO2 capacitor. <em>AML</em>, <em>3</em>(1),
016120. (<a href="https://doi.org/10.1063/5.0255149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have experimentally demonstrated the physical reservoir computing by employing the polarization switching current dynamics of an Hf 1−x Zr x O 2 (HZO)-based metal/ferroelectric/metal capacitor with Zr content x = 0, 0.5, and 0.75. The spatial distribution of the crystalline phase of an HZO film reveals that the tetragonal phase is a dominant crystal structure in the HZO film with [Zr] = 75%, resulting in anti-ferroelectric (AFE)-like double polarization switching. Analyses using t-distributed stochastic neighbor embedding (t-SNE) find that the AFE-HZO capacitor effectively transforms the 3-bit time-series input into eight different reservoir output states. In reservoir computing tasks, the AFE-HZO capacitor with [Zr] = 75% achieves improved computational capacities compared with the other MFM capacitors with [Zr] = 0% and 50%. The AFE-HZO capacitor can effectively diversify time-series input signals through dynamic double polarization switching, leading to a more sub-divided and dispersive weight distribution across the adjustable weights in the readout part of our RC system.},
  archive      = {J_AML},
  author       = {Min, Shin-Yi and Nako, Eishin and Nakane, Ryosho and Takenaka, Mitsuru and Toprasertpong, Kasidit and Takagi, Shinichi},
  doi          = {10.1063/5.0255149},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016120},
  shortjournal = {APL Mach. Learn.},
  title        = {Polarization current-based reservoir computing utilizing an anti-ferroelectric-like HfZrO2 capacitor},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic in-context learning with conversational models for
data extraction and materials property prediction. <em>AML</em>,
<em>3</em>(1), 016119. (<a
href="https://doi.org/10.1063/5.0254406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of natural language processing and large language models (LLMs) has revolutionized the extraction of data from unstructured scholarly papers. However, ensuring data trustworthiness remains a significant challenge. In this paper, we introduce PropertyExtractor , an open-source tool that leverages advanced conversational LLMs such as Google gemini-pro and OpenAI gpt-4 , blends zero-shot with few-shot in-context learning, and employs engineered prompts for the dynamic refinement of structured information hierarchies—enabling autonomous, efficient, scalable, and accurate identification, extraction, and verification of material property data. Our tests on material data demonstrate precision and recall that exceed 95% with an error rate of ∼9%, highlighting the effectiveness and versatility of the toolkit. Finally, databases for 2D material thicknesses, a critical parameter for device integration, and energy bandgap values are developed using PropertyExtractor . In particular, for the thickness database, the rapid evolution of the field has outpaced both experimental measurements and computational methods, creating a significant data gap. Our work addresses this gap and showcases the potential of PropertyExtractor as a reliable and efficient tool for the autonomous generation of various material property databases, advancing the field.},
  archive      = {J_AML},
  author       = {Ekuma, Chinedu E.},
  doi          = {10.1063/5.0254406},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016119},
  shortjournal = {APL Mach. Learn.},
  title        = {Dynamic in-context learning with conversational models for data extraction and materials property prediction},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic compact model for memory and threshold switching
memristors. <em>AML</em>, <em>3</em>(1), 016118. (<a
href="https://doi.org/10.1063/5.0255043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristors are electron devices whose resistance changes according to the history of electrical signals applied to their two terminals. These resistance changes can remain for very long times or relax after a short time. Thus, memristors can be used as electronic synapses and neurons in artificial neural networks implemented in hardware. These fully memristive neuromorphic circuits are mainly intended for artificial intelligence applications. In this work, we explore the properties of a stochastic compact model for the electrical behavior of memristors in the two regimes of long-time (non-volatile) and short-time (volatile) memory for synapse and neuron functions, respectively. In the case of non-volatile memristors, we focus on potentiation/depression transients, programming energy, programming time, and power requirements for writing conductance weights in artificial network crossbars. As for volatile memristors, we consider the modeling of their behavior in the context of a leaky-integrate-and-fire neuron, demonstrating how the model captures the threshold activation function and the input signal frequency dependence.},
  archive      = {J_AML},
  author       = {Suñé, Jordi and Miranda, Enrique},
  doi          = {10.1063/5.0255043},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016118},
  shortjournal = {APL Mach. Learn.},
  title        = {Stochastic compact model for memory and threshold switching memristors},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A memristive computational neural network model for
time-series processing. <em>AML</em>, <em>3</em>(1), 016117. (<a
href="https://doi.org/10.1063/5.0255168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce a novel computational framework inspired by the physics of memristive devices and systems, which we embed into the context of Recurrent Neural Networks (RNNs) for time-series processing. Our proposed memristive-friendly neural network architecture leverages both the principles of Reservoir Computing (RC) and fully trainable RNNs, providing a versatile platform for sequence learning. We provide a mathematical analysis of the stability of the resulting neural network dynamics, identifying the role of crucial RC-based architectural hyper-parameters. Through numerical simulations, we demonstrate the effectiveness of the proposed approach across diverse regression and classification tasks, showcasing performance that is competitive with both traditional RC and fully trainable RNN systems. Our results highlight the scalability and adaptability of memristive-inspired computational architectures, offering a promising path toward efficient neuromorphic computing for complex sequence-based applications.},
  archive      = {J_AML},
  author       = {Pistolesi, Veronica and Ceni, Andrea and Milano, Gianluca and Ricciardi, Carlo and Gallicchio, Claudio},
  doi          = {10.1063/5.0255168},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016117},
  shortjournal = {APL Mach. Learn.},
  title        = {A memristive computational neural network model for time-series processing},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniFIDES: Universal fractional integro-differential
equations solver. <em>AML</em>, <em>3</em>(1), 016116. (<a
href="https://doi.org/10.1063/5.0258122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of data-driven approaches for solving differential equations has led to numerous applications in science and engineering across many disciplines and remains a central focus of active scientific inquiry. However, a large body of natural phenomena incorporates memory effects that are best described via fractional integro-differential equations (FIDEs), in which the integral or differential operators accept non-integer orders. Addressing the challenges posed by nonlinear FIDEs is a recognized difficulty, necessitating the application of generic methods with immediate practical relevance. This work introduces the Universal Fractional Integro-Differential Equations Solver (UniFIDES), a comprehensive machine learning platform designed to expeditiously solve a variety of FIDEs in both forward and inverse directions, without the need for ad hoc manipulation of the equations. The effectiveness of UniFIDES is demonstrated through a collection of integer-order and fractional problems in science and engineering. Our results highlight UniFIDES’ ability to accurately solve a wide spectrum of integro-differential equations and offer the prospect of using machine learning platforms universally for discovering and describing dynamic and complex systems.},
  archive      = {J_AML},
  author       = {Saadat, Milad and Mangal, Deepak and Jamali, Safa},
  doi          = {10.1063/5.0258122},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016116},
  shortjournal = {APL Mach. Learn.},
  title        = {UniFIDES: Universal fractional integro-differential equations solver},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale simulation and machine learning facilitated
design of two-dimensional nanomaterials-based tunnel field-effect
transistors: A review. <em>AML</em>, <em>3</em>(1), 016115. (<a
href="https://doi.org/10.1063/5.0240004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional transistors based on complementary metal–oxide–semiconductor and metal–oxide–semiconductor field-effect transistors are facing significant limitations as device scaling reaches the limits of Moore’s law. These limitations include increased leakage currents, pronounced short-channel effects, and quantum tunneling through the gate oxide, leading to higher power consumption and deviations from ideal behavior. Tunnel Field-Effect Transistors (TFETs) can overcome these challenges by utilizing the quantum tunneling of charge carriers to switch between on and off states and achieve a subthreshold swing below 60 mV/decade. This allows for lower power consumption, continued scaling, and improved performance in low-power applications. This review focuses on the design and operation of TFETs, emphasizing the optimization of device performance through material selection and advanced simulation techniques. The discussion will specifically address the use of two-dimensional materials in TFET design and explore simulation methods ranging from multi-scale approaches to machine learning-driven optimization.},
  archive      = {J_AML},
  author       = {Tsang, Chloe Isabella and Pu, Haihui and Chen, Junhong},
  doi          = {10.1063/5.0240004},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016115},
  shortjournal = {APL Mach. Learn.},
  title        = {Multiscale simulation and machine learning facilitated design of two-dimensional nanomaterials-based tunnel field-effect transistors: A review},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Environment model construction toward auto-tuning of quantum
dot devices based on model-based reinforcement learning. <em>AML</em>,
<em>3</em>(1), 016114. (<a
href="https://doi.org/10.1063/5.0251336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semiconductor quantum dots (QDs) are promising hosts for quantum computers because of their scalability. In order to expedite the development process, there is a strong need for fully automated tuning of QDs that allows for en masse characterization of newly fabricated devices and control over large-scale systems with appreciable variability. Machine learning has been actively explored as a means to this end; however, challenges remain in terms of versatility for different tasks and device types. In this study, we explore a model-based reinforcement learning (MBRL) approach: unlike traditional reinforcement learning techniques, the learning process of MBRL progresses by constructing a model for the environment, which is to be diverted for other tasks and/or devices, thereby minimizing time-consuming learning processes. Using pre-measured data, we construct an environment model and, despite the intrinsic sparse reward distribution of the QD system, demonstrate its suitability for MBRL by emulating the process of auto-tuning to a single QD region. Our results highlight the potential of MBRL for more generic QD auto-tuning techniques, providing a promising step toward fully automated QD tuning.},
  archive      = {J_AML},
  author       = {Kondo, Chihiro and Mizokuchi, Raisei and Yoneda, Jun and Kodera, Tetsuo},
  doi          = {10.1063/5.0251336},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016114},
  shortjournal = {APL Mach. Learn.},
  title        = {Environment model construction toward auto-tuning of quantum dot devices based on model-based reinforcement learning},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the hyperparameter space of deep neural
network models for reaction coordinates. <em>AML</em>, <em>3</em>(1),
016113. (<a href="https://doi.org/10.1063/5.0252631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying reaction coordinates (RCs) is a key to understanding the mechanism of reactions in complex systems. Deep neural network (DNN) and machine learning approaches have become a powerful tool to find the RC. On the other hand, the hyperparameters that determine the DNN model structure can be highly flexible and are often selected intuitively and in a non-trivial and tedious manner. Furthermore, how the hyperparameter choice affects the RC quality remains obscure. Here, we explore the hyperparameter space by developing the hyperparameter tuning approach for the DNN model for RC and investigate how the parameter set affects the RC quality. The DNN model is built to predict the committor along the RC from various collective variables by minimizing the cross-entropy function; the hyperparameters are automatically determined using the Bayesian optimization method. The approach is applied to study the isomerization of alanine dipeptide in vacuum and in water, and the features that characterize the RC are extracted using the explainable AI (XAI) tools. The results show that the DNN models with diverse structures can describe the RC with similar accuracy, and furthermore, the features analyzed by XAI are highly similar. This indicates that the hyperparameter space is multimodal. The electrostatic potential from the solvent to the hydrogen H 18 plays an important role in the RC in water. The current study shows that the structure of the DNN models can be rather flexible, while the suitably optimized models share the same features; therefore, a common mechanism from the RC can be extracted.},
  archive      = {J_AML},
  author       = {Kawashima, Kyohei and Sato, Takumi and Okazaki, Kei-ichi and Kim, Kang and Matubayasi, Nobuyuki and Mori, Toshifumi},
  doi          = {10.1063/5.0252631},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016113},
  shortjournal = {APL Mach. Learn.},
  title        = {Investigating the hyperparameter space of deep neural network models for reaction coordinates},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Slim multi-scale convolutional autoencoder-based
reduced-order models for interpretable features of a complex dynamical
system. <em>AML</em>, <em>3</em>(1), 016112. (<a
href="https://doi.org/10.1063/5.0244416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, data-driven deep learning models have gained significant importance in the analysis of turbulent dynamical systems. Within the context of reduced-order models, convolutional autoencoders (CAEs) pose a universally applicable alternative to conventional approaches. They can learn nonlinear transformations directly from data, without prior knowledge of the system. However, the features generated by such models lack interpretability. Thus, the resulting model is a black-box that effectively reduces the complexity of the system but does not provide insights into the meaning of the latent features. To address this critical issue, we introduce a novel interpretable CAE approach for high-dimensional fluid flow data that maintains the reconstruction quality of conventional CAEs and allows for feature interpretation. Our method can be easily integrated into any existing CAE architecture with minor modifications of the training process. We compare our approach to Proper Orthogonal Decomposition (POD) and two existing methods for interpretable CAEs. We apply all methods to three different experimental turbulent Rayleigh–Bénard convection datasets with varying complexity. Our results show that the proposed method is lightweight, easy to train, and achieves relative reconstruction performance improvements of up to 6.4% over POD for 64 modes. The relative improvement increases to up to 229.8% as the number of modes decreases. In addition, our method delivers interpretable features similar to those of POD and is significantly less resource-intensive than existing CAE approaches, using less than 2% of the parameters. These approaches either trade interpretability for reconstruction performance or only provide interpretability to a limited extent.},
  archive      = {J_AML},
  author       = {Teutsch, Philipp and Pfeffer, Philipp and Sharifi Ghazijahani, Mohammad and Cierpka, Christian and Schumacher, Jörg and Mäder, Patrick},
  doi          = {10.1063/5.0244416},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016112},
  shortjournal = {APL Mach. Learn.},
  title        = {Slim multi-scale convolutional autoencoder-based reduced-order models for interpretable features of a complex dynamical system},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonideality-aware training makes memristive networks more
robust to adversarial attacks. <em>AML</em>, <em>3</em>(1), 016111. (<a
href="https://doi.org/10.1063/5.0241202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks are now deployed in a wide number of areas, from object classification to natural language systems. Implementations using analog devices such as memristors promise better power efficiency, potentially bringing these applications to a greater number of environments. However, such systems suffer from more frequent device faults, and overall, their exposure to adversarial attacks has not been studied extensively. In this work, we investigate how nonideality-aware training—a common technique to deal with physical nonidealities—affects adversarial robustness. We find that adversarial robustness is significantly improved, even with limited knowledge of what nonidealities will be encountered during test time.},
  archive      = {J_AML},
  author       = {Joksas, Dovydas and Muñoz-González, Luis and Lupu, Emil and Mehonic, Adnan},
  doi          = {10.1063/5.0241202},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016111},
  shortjournal = {APL Mach. Learn.},
  title        = {Nonideality-aware training makes memristive networks more robust to adversarial attacks},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic dataset generation technique applied to
data-driven automotive aerodynamics. <em>AML</em>, <em>3</em>(1),
016110. (<a href="https://doi.org/10.1063/5.0233367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel strategy for generating datasets has been developed within the context of drag prediction for automotive geometries using neural networks. A primary challenge in this field is constructing a training database of sufficient size and diversity. Our method relies on a small number of initial data points and provides a recipe to systematically interpolate between them, generating an arbitrary number of samples at the desired quality. We tested this strategy using a representative automotive geometry and demonstrated that convolutional neural networks perform exceptionally well at predicting drag coefficients and surface pressures. Promising results were obtained in testing extrapolation performance. Our method can be applied to other problems of aerodynamic shape optimization.},
  archive      = {J_AML},
  author       = {Benjamin, Mark and Iaccarino, Gianluca},
  doi          = {10.1063/5.0233367},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016110},
  shortjournal = {APL Mach. Learn.},
  title        = {A systematic dataset generation technique applied to data-driven automotive aerodynamics},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Morphology reconstruction from experimental small-angle
x-ray scattering patterns by physics-aware neural network. <em>AML</em>,
<em>3</em>(1), 016109. (<a
href="https://doi.org/10.1063/5.0246111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we developed a new methodology that can reconstruct the morphology from experimental small-angle x-ray scattering (SAXS) patterns directly without modeling by using a physics-aware neural network, SAXSNN. By incorporating the scattering physics of x rays into the network, SAXSNN could be trained to capture the complex mapping between the SAXS patterns in reciprocal space and the corresponding morphologies in real space in an unsupervised way. We demonstrated the performance of SAXSNN on the experimental SAXS patterns of semicrystalline and amorphous polymers, i.e., hard-elastic isotactic polypropylene (iPP) films and plasticized poly(vinyl butyral) (PVB). The morphologies reconstructed by SAXSNN are well consistent with our existing knowledge of the morphology of iPP films and PVB. The developed methodology here allows us to rapidly predict the morphologies for any given SAXS pattern without any in-prior phase information and, thus, provides an intuitive understanding of the microstructures of the measured samples. A real-time feedback of the morphologies of measured samples to SAXS beamline users at modern synchrotron radiation light sources will be feasible in the near future.},
  archive      = {J_AML},
  author       = {Zhao, Chenhao and Sun, Shenyang and Han, Xueqing and Zhu, Jianhe and Yu, Wancheng and Li, Liangbin},
  doi          = {10.1063/5.0246111},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016109},
  shortjournal = {APL Mach. Learn.},
  title        = {Morphology reconstruction from experimental small-angle x-ray scattering patterns by physics-aware neural network},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confidence evaluation for feature selection in expanded
feature space based on density of states. <em>AML</em>, <em>3</em>(1),
016108. (<a href="https://doi.org/10.1063/5.0245626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In materials informatics, feature selection and model selection are utilized in the knowledge extraction process, and the confidence evaluation of the selection result is crucial for ensuring the reliability of the extracted knowledge. In this study, we propose a novel method to quantitatively evaluate the significance of low-dimensional models obtained from an expanded feature space using the density of states (DoS) for the evaluation metrics. This method allows us to compare the performance of the selected model to those of other models and evaluate its significance. We further propose an evaluation method for feature importance based on marginal posterior probabilities using the Bayesian model averaging (BMA) framework, which considers all models. We demonstrate the effectiveness of our proposed methods through their application to a crystal structure dataset. Our results show that the DoS analysis reveals the presence of a large number of models with a comparable performance with the best model reported in a previous research work. This suggests that knowledge extracted from a single selected model can be unreliable and that considering other models is crucial. We also show that the BMA-based feature importance evaluation provides valuable insights into the importance of features, highlighting both primary features and functional forms. In addition, we demonstrate that the LASSO + L0 method commonly used in existing research deteriorates the search space for model selection. Our findings suggest that our proposed methods provide valuable tools for assessing the significance of low-dimensional models and extracting knowledge from large-scale data in materials informatics.},
  archive      = {J_AML},
  author       = {Obinata, Koki and Igarashi, Yasuhiko and Nagata, Kenji and Sodeyama, Keitaro and Okada, Masato},
  doi          = {10.1063/5.0245626},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016108},
  shortjournal = {APL Mach. Learn.},
  title        = {Confidence evaluation for feature selection in expanded feature space based on density of states},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entanglement engineering of optomechanical systems by
reinforcement learning. <em>AML</em>, <em>3</em>(1), 016107. (<a
href="https://doi.org/10.1063/5.0233470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entanglement is fundamental to quantum information science and technology, yet controlling and manipulating entanglement—so-called entanglement engineering—for arbitrary quantum systems remains a formidable challenge. There are two difficulties: the fragility of quantum entanglement and its experimental characterization. We develop a model-free deep reinforcement-learning (RL) approach to entanglement engineering, in which feedback control together with weak continuous measurement and partial state observation is exploited to generate and maintain desired entanglement. We employ quantum optomechanical systems with linear or nonlinear photon–phonon interactions to demonstrate the workings of our machine-learning-based entanglement engineering protocol. In particular, the RL agent sequentially interacts with one or multiple parallel quantum optomechanical environments, collects trajectories, and updates the policy to maximize the accumulated reward to create and stabilize quantum entanglement over an arbitrary amount of time. The machine-learning-based model-free control principle is applicable to the entanglement engineering of experimental quantum systems in general.},
  archive      = {J_AML},
  author       = {Ye, Li-Li and Arenz, Christian and Lukens, Joseph M. and Lai, Ying-Cheng},
  doi          = {10.1063/5.0233470},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016107},
  shortjournal = {APL Mach. Learn.},
  title        = {Entanglement engineering of optomechanical systems by reinforcement learning},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning for quantitative dynamic fragmentation
analysis. <em>AML</em>, <em>3</em>(1), 016106. (<a
href="https://doi.org/10.1063/5.0233739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have developed an image-based convolutional neural network that is applicable for quantitative time-resolved measurements of the fragmentation behavior of opaque brittle materials using ultra-high speed optical imaging. This model extends previous work on the U-net model. Here we trained binary-, three-, and five-class models using supervised learning on experimentally measured dynamic fracture experiments on various opaque structural ceramic materials that were adhered on transparent polymer (polycarbonate or acrylic) backing materials. Full details of the experimental investigations are outside the scope of this manuscript, but briefly, several different ceramics were loaded using spatially and time-varying mechanical loads to induce inelastic deformation and fracture processes that were recorded at frequencies as high as 5 MHz using high-speed optical imaging. These experiments provided a rich and diverse dataset that includes many of the common fracture modes found in static and dynamic fractures, including cone cracking, median cracking, comminution, and combined complex failure modes that involve effectively simultaneous activation and propagation of multiple fragmentation modes. While the training data presented here were obtained from dynamic fragmentation experiments, this study is applicable to static loading of these materials as the crack speeds are on the order of 1–10 km/s regardless of the loading rate. We believe the methodologies presented here will be useful in quantifying the failure processes in structural materials for protection applications and can be used for direct validation of engineering models used in design.},
  archive      = {J_AML},
  author       = {Cazares, Erwin and Schuster, Brian E.},
  doi          = {10.1063/5.0233739},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016106},
  shortjournal = {APL Mach. Learn.},
  title        = {Deep learning for quantitative dynamic fragmentation analysis},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable recurrence graph network for stratifying RhoB
texture dynamics in rectal cancer biopsies. <em>AML</em>, <em>3</em>(1),
016105. (<a href="https://doi.org/10.1063/5.0243636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scalable recurrence graph network (SRGNet) is introduced in this paper to improve the accuracy of predicting five-year survival outcomes in rectal cancer patients by analyzing RhoB texture dynamics in biopsies. RhoB, a key biomarker assessed via immunohistochemistry, is crucial in predicting responses to radiotherapy (RT), but variability in staining techniques and tumor heterogeneity often complicate these assessments. SRGNet integrates spatial statistics, nonlinear dynamics, graph theory, and graph convolutional networks to address these challenges. In testing, SRGNet outperformed 10 pre-trained convolutional neural networks, achieving 88% accuracy in biopsies from RT patients, with 67% accuracy for predicting survival under five years and 100% accuracy for survival over five years, along with 100% precision, an F1 score of 0.80, and an AUC of 0.73. For non-RT patients, SRGNet attained 91% accuracy, 100% precision for survival over five years, an F1 score of 0.86, and an AUC of 0.82. These results demonstrate SRGNet’s potential to enhance the precision and reliability of survival predictions in rectal cancer patients, overcoming challenges of RhoB expression variability and tumor heterogeneity.},
  archive      = {J_AML},
  author       = {Pham, Tuan D.},
  doi          = {10.1063/5.0243636},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016105},
  shortjournal = {APL Mach. Learn.},
  title        = {Scalable recurrence graph network for stratifying RhoB texture dynamics in rectal cancer biopsies},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale-aware data augmentation for reduced-order models
of high-dimensional flows. <em>AML</em>, <em>3</em>(1), 016104. (<a
href="https://doi.org/10.1063/5.0213700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional autoencoders have proven to be an adequate tool to perform reduced-order modeling for high-dimensional nonlinear dynamical systems. Their goal is to reduce dimensionality strongly while preserving the most characteristic features of the system. Here, we show that these models rely sensitively on the completeness of the provided data. This is particularly challenging for fully turbulent flows with their coherent structures ranging from large-scale superstructures to dissipative eddies over orders of magnitude in time and space. As a result, an unrealistically large number of data snapshots would be required to properly cover all the essential dynamics, whereas the features on small time and length scales require only a small number of snapshots of the respective flow, especially the long lasting large-scale structures that are difficult to characterize either numerically or experimentally. We demonstrate for three types of flows that a missing representation of large-scale turbulent structures leads to failures in the training process. We suggest a method to mitigate this shortcoming. This includes the transformation of data samples to new large-scale structures, which enhance the data. Furthermore, we skip augmentations that are more detrimental to the model performance. We evaluate our method for three datasets, two from numerical simulations of turbulent Rayleigh–Bénard convection flows and one from laboratory experiment for the flow past an array of cylinders. We show that the method can substantially improve model utility for high-dimensional data. In this way, we avoid an intensive grid search through possible augmentation combinations without further knowledge about the underlying system.},
  archive      = {J_AML},
  author       = {Teutsch, Philipp and Ghazijahani, Mohammad Sharifi and Heyder, Florian and Cierpka, Christian and Schumacher, Jörg and Mäder, Patrick},
  doi          = {10.1063/5.0213700},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016104},
  shortjournal = {APL Mach. Learn.},
  title        = {Large-scale-aware data augmentation for reduced-order models of high-dimensional flows},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dislocation cartography: Representations and unsupervised
classification of dislocation networks with unique fingerprints.
<em>AML</em>, <em>3</em>(1), 016103. (<a
href="https://doi.org/10.1063/5.0224710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting structure in data is the first step to arrive at meaningful representations for systems. This is particularly challenging for evolving dislocation networks evolving as a consequence of plastic deformation of crystalline materials. Our study employs Isomap, a manifold learning technique, to show the intrinsic structure of high-dimensional dislocation density field data of dislocation structures resulting from different compression axes. Our maps provide a systematic framework for quantitatively comparing dislocation structures and offer unique fingerprints based on dislocation density fields. It represents a novel, unbiased approach that contributes to the quantitative classification of dislocation structures, which can be systematically extended using different representations of dislocation systems.},
  archive      = {J_AML},
  author       = {Udofia, Benjamin and Jogi, Tushar and Stricker, Markus},
  doi          = {10.1063/5.0224710},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016103},
  shortjournal = {APL Mach. Learn.},
  title        = {Dislocation cartography: Representations and unsupervised classification of dislocation networks with unique fingerprints},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of nonlinear behavior of viscoelastic damping in
musical membranes using physics-informed self-organizing maps.
<em>AML</em>, <em>3</em>(1), 016102. (<a
href="https://doi.org/10.1063/5.0242985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research offers a new analytical tool that unravels the nonlinear relation between the parameters of Viscoelastic Damping (VD) and the resulting frequency spectrum in musical membranes. Understanding how variations in VD parameters influence the resulting sounds is crucial for developing new tools for artistic expression and for designing musical instruments with distinct sound qualities. In the case of membranophones, the external damping is well understood, while the internal damping due to viscoelastic properties of materials remains unclear. In previous research, VD in musical membranes has been modeled using a Finite-Difference Time-Domain (FDTD) model. Nonetheless, analyzing the complex relationships between the large parameter space of the model and the nonlinear behavior of VD is a challenging task. This study addresses this analysis through physics-based machine learning. We employed a FDTD model of a viscoelastically damped membrane to create a physics-informed dataset, which we subsequently analyzed using Self-Organizing Maps (SOMs). Our findings reveal that the damping coefficient is the primary criterion when clustering the data. Furthermore, we found the internal structure of the cluster to depend on the rate of decay of the memory effect, i.e., the rate at which the energy introduced back into the system decreases. The study also demonstrates the benefits of using principal component analysis for the SOM initialization.},
  archive      = {J_AML},
  author       = {Martínez Orellanos, Cristhiam Fidel and Bader, Rolf},
  doi          = {10.1063/5.0242985},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016102},
  shortjournal = {APL Mach. Learn.},
  title        = {Analysis of nonlinear behavior of viscoelastic damping in musical membranes using physics-informed self-organizing maps},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiency of machine learning optimizers and
meta-optimization for nanophotonic inverse design tasks. <em>AML</em>,
<em>3</em>(1), 016101. (<a
href="https://doi.org/10.1063/5.0238444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of deep learning has driven the proliferation and refinement of numerous non-convex optimization algorithms. Despite this growing array of options, the field of nanophotonic inverse design continues to rely heavily on quasi-Newton optimizers such as L-BFGS and basic momentum-based methods such as Adam. A systematic survey of these and other algorithms in the nanophotonics context remains lacking. Here, we compare 24 widely used machine learning optimizers on inverse design tasks. We study two prototypical nanophotonics inverse design problems—the mode splitter and wavelength demultiplexer—across various system sizes, using both hand-tuned and meta-learned hyperparameters. We find that Adam derivatives, as well as the Fromage optimizer, consistently outperform L-BFGS and standard gradient descent, regardless of system size. While meta-learning has a negligible-to-negative impact on Adam and Fromage, it significantly improves others, particularly AdaGrad derivatives and simple gradient descent, such that their performance is on par with Adam. In addition, we observe that the most effective optimizers exhibit the lowest correlation between initial and final performance. Our results and codebase (github.com/Ma-Lab-Cal/photonicsOptComp) provide a valuable framework for selecting and benchmarking optimizers in nanophotonic inverse design.},
  archive      = {J_AML},
  author       = {Morrison, Nathaniel and Ma, Eric Y.},
  doi          = {10.1063/5.0238444},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {016101},
  shortjournal = {APL Mach. Learn.},
  title        = {Efficiency of machine learning optimizers and meta-optimization for nanophotonic inverse design tasks},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: The intersection of machine learning and physical
sciences: Insights from the 2024 nobel prizes. <em>AML</em>,
<em>3</em>(1), 010401. (<a
href="https://doi.org/10.1063/5.0267892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Milano, Gianluca and Mehonic, Adnan},
  doi          = {10.1063/5.0267892},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {010401},
  shortjournal = {APL Mach. Learn.},
  title        = {Editorial: the intersection of machine learning and physical sciences: insights from the 2024 nobel prizes},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). APL machine learning reviewer acknowledgment for 2024.
<em>AML</em>, <em>3</em>(1), 010201. (<a
href="https://doi.org/10.1063/5.0265450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AML},
  author       = {Mehonic, Adnan},
  doi          = {10.1063/5.0265450},
  journal      = {APL Machine Learning},
  month        = {3},
  number       = {1},
  pages        = {010201},
  shortjournal = {APL Mach. Learn.},
  title        = {APL machine learning reviewer acknowledgment for 2024},
  volume       = {3},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
