<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ws_all</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h1 id="ws">WS</h1>
<h2 id="iet---5">IET - 5</h2>
<ul>
<li><details>
<summary>
(2025). A review of emerging technologies in wireless communication
systems. <em>IET</em>, <em>12</em>, 2550005. (<a
href="https://doi.org/10.1142/S2737599425500057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article reviews emerging technologies in wireless communication systems, focusing on their key concepts, principles, use cases, and challenges. It examines relevant studies in the telecommunication sector, with a focus on technologies that enhance connectivity, performance, and innovative applications across industries. The review highlights advancements such as fifth-generation (5G) networks, which offer faster data speeds, lower latency, and increased network capacity, enabling the development of applications like autonomous vehicles, smart cities, and Internet of Things (IoT) devices. IoT devices are increasingly connecting physical objects, driving innovation in sectors such as healthcare, agriculture, transportation, and manufacturing. Edge computing, by enabling real-time processing and reducing latency, supports IoT applications requiring immediate responses. Artificial intelligence (AI) and machine learning (ML) are being integrated to optimize network resources, improve spectrum management, and facilitate intelligent decision-making. Technologies such as massive multiple input, multiple output (MIMO) enhance spectral efficiency, network capacity, and interference reduction. Millimeter wave (mmWave) frequencies are being explored for high-speed wireless communication, enabling multi-gigabit data rates and applications in 5G, wireless backhaul, and ultra-high-definition video streaming. Software-defined networking (SDN) and network function virtualization (NFV) enable centralized management and greater network flexibility, while beam steering improves signal quality and coverage by directing wireless signals toward specific receivers. Quantum communication, leveraging quantum principles, provides secure communication channels, while quantum key distribution (QKD) ensures data confidentiality. Visible light communication (VLC) utilizes visible light for high-speed data transfer in environments where RF-based communication is not feasible. Despite the potential of these technologies, the article identifies challenges such as limited practical implementation, standardization issues, resource constraints, security and privacy concerns, and sustainability challenges. It concludes by discussing the practical implications of these emerging technologies, including enhanced data transfer speeds, improved network capacity, low-latency communication, IoT connectivity, ubiquitous coverage, industry transformation, and the security and privacy considerations that accompany these advancements.},
  archive      = {J_IET},
  author       = {Promise Elechi and Solomon Malcolm Ekolama and Ela Okowa and Shadrack Kukuchuku},
  doi          = {10.1142/S2737599425500057},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550005},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {A review of emerging technologies in wireless communication systems},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven healthcare systems: A personalized symptom-based
disease prognosis tool using RF, GNB, and SVC techniques. <em>IET</em>,
<em>12</em>, 2550003. (<a
href="https://doi.org/10.1142/S2737599425500033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) technology is being leveraged for multiple tasks in the healthcare sector, such as improving the diagnosis of disease, streamlining management services, and tailoring treatment procedures. Applying predictive analysis and performing robotic surgery helps patients in a way that reduces the burden on their caregivers. This study uses a healthcare disease prediction dataset using three robust machine learning algorithms: random forest (RF), Gaussian Na√Øve Bayes (GNB), and support vector classifier (SVC). The models learn to use other symptoms to detect the presence of various diseases. In model evaluation, cross-validation is done on the training set after data preprocessing is performed to ensure none of the groups is overrepresented in the final model. In both the training and the testing of each model, which were respectively 100%, the model was able to make perfect predictions. A vote of three classifiers reached the 100% precision mark over a test dataset on an ensemble model that combined all the classifiers. This research integrates the advances in AI technology into the healthcare setting in a bid to enhance healthcare delivery. Additionally, we created such a straightforward tool in the case of input symptoms and proposed a possible disease diagnosis. This study also adds to the expanding corpus of research on AI in healthcare by providing a practical method for symptom-based diagnosis.},
  archive      = {J_IET},
  author       = {Massoud Massoudi and Ruchika Malhotra},
  doi          = {10.1142/S2737599425500033},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550003},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {AI-driven healthcare systems: A personalized symptom-based disease prognosis tool using RF, GNB, and SVC techniques},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scrap steel price predictions for southwest china via
machine learning. <em>IET</em>, <em>12</em>, 2550002. (<a
href="https://doi.org/10.1142/S2737599425500021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasts of prices for a wide range of commodities have been a source of confidence for governments and investors throughout history. This study examines the difficult task of forecasting scrap steel prices, which are released every day for the southwest China market, leveraging time-series data spanning August 23, 2013 to April 15, 2021. Estimates have not been fully considered in previous studies for this important commodity price assessment. In this case, cross-validation procedures and Bayesian optimization techniques are used to develop Gaussian process regression strategies, and consequent price projections are built. Arriving at a relative root mean square error of 0.4691%, this empirical prediction approach yields fairly precise price projections throughout the out-of-sample stage spanning September 17, 2019 to April 15, 2021. Through the use of price research models, governments and investors may make well-informed judgments on regional markets of scrap steel.},
  archive      = {J_IET},
  author       = {Bingzi Jin and Xiaojie Xu},
  doi          = {10.1142/S2737599425500021},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550002},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Scrap steel price predictions for southwest china via machine learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research of ultra-low concentration ion implantation on chip
substrates using film delamination method combined with semiconductor
simulation technology. <em>IET</em>, <em>12</em>, 2550001. (<a
href="https://doi.org/10.1142/S273759942550001X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a novel ion implantation technique that combines the film delamination method with semiconductor simulation technology to achieve low-dose, high-uniformity semiconductor doping. The method involves depositing a protective layer on the substrate, implanting ions into the layer, performing high-temperature pre-diffusion, delaminating the protective layer, and completing the diffusion process. By integrating semiconductor simulation software, such as Silvaco TCAD, the research aims to optimize parameters for the protective layer and achieve precise control of doping concentrations. This innovative approach addresses the challenges of uniformity and cost in traditional ion implantation equipment.},
  archive      = {J_IET},
  author       = {Zhiwei Yang and Asim Abas and Yuanxun Cao},
  doi          = {10.1142/S273759942550001X},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550001},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Research of ultra-low concentration ion implantation on chip substrates using film delamination method combined with semiconductor simulation technology},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robotics in healthcare: A review. <em>IET</em>, <em>12</em>,
2530001. (<a href="https://doi.org/10.1142/S2737599425300016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From early industrial prototypes in the 1960s and 1970s to sophisticated systems integrated into contemporary medical practice, healthcare robotics has come a long way in the last 10 years. Human potential has been enhanced by robotics in many ways, most notably in the areas of safety, accuracy, and repeatability. When paired with artificial intelligence (AI), these developments have enormous potential for the healthcare industry in the 21st century. These days, robots help in various places, such as healthcare facilities, assisted living apartments, and rehabilitation centers. For example, Aethon‚Äôs TUG robots carry supplies throughout hospitals effectively and lessen the effort of hospital staff. The main applications of healthcare robotics, including telepresence, rehabilitation, and operating rooms, are outlined in this chapter. Giraff and other telepresence robots allow doctors to observe patients from a distance. Hugo TM RAS system from Medtronic has recently garnered notice because of its availability as a modular minimally invasive surgery solution that directly competes with the Da Vinci System in hospitals across the globe. Taking a focus on surgery rooms, telemedicine, and assistive care, this manuscript offers a broad review of the most recent advancements in healthcare robotics. It highlights the difficulties in properly integrating these technologies into the medical field.},
  archive      = {J_IET},
  author       = {Dinesh Bhatia and Tania Acharjee and Agnila Sengupta},
  doi          = {10.1142/S2737599425300016},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530001},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Robotics in healthcare: A review},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijcia---13">IJCIA - 13</h2>
<ul>
<li><details>
<summary>
(2025). Calendar of events. <em>IJCIA</em>, <em>24</em>(1), 2583001.
(<a href="https://doi.org/10.1142/S1469026825830019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026825830019},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2583001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective deep learning-based intrusion detection system
for the healthcare environment. <em>IJCIA</em>, <em>24</em>(1), 2450033.
(<a href="https://doi.org/10.1142/S1469026824500330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the medical field, Internet of Things (IoT) applications allow for real-time diagnosis and remote patient monitoring, commonly called Internet of Health Things (IoHT). However, cybersecurity attacks may interrupt hospital operations and threaten patients‚Äô health and well-being due to this integration. Hence, developing an Intrusion Detection System (IDS) suited explicitly for healthcare systems is essential to ensure efficiency and accuracy. Nevertheless, it is challenging to integrate anomaly-based IDS frameworks in healthcare systems as they necessitate additional processing time, temporal feature retention, and increased complexity. Therefore, a deep learning system based on SqueezeNet and NasNet is presented in this paper to detect intrusions in a healthcare setting. In this, SqueezeNet is employed to extract more significant features. On the other hand, network breaches while data transmission across distinct locations are detected by the NasNet-based classifier. In addition, the Rider Optimization Algorithm (ROA) is applied to adjust the classifier‚Äôs hyperparameters, guaranteeing that it would accurately detect attacks. Moreover, the Auxiliary Classifier Generative Adversarial Network (ACGAN) approach is integrated into the proposed framework to avoid data imbalance. Applying different performance constraints, the proposed approach is thoroughly assessed on three publicly available datasets (TON-IoT, ECU-IoHT, and WUSTL-EHMS). The results show that the proposed deep learning-based cybersecurity model outperforms traditional methods and produces better outcomes.},
  archive      = {J_IJCIA},
  author       = {K. Balaji and S. Satheesh Kumar and D. Vivek and S. Prem Kumar Deepak and K. V. Daya Sagar and S. Thabassum Khan},
  doi          = {10.1142/S1469026824500330},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450033},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {An effective deep learning-based intrusion detection system for the healthcare environment},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RN-STLSTM-GAN: Spatiotemporal-guided generative adversarial
network for time-evolving precipitation downscaling. <em>IJCIA</em>,
<em>24</em>(1), 2450032. (<a
href="https://doi.org/10.1142/S1469026824500329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) have been widely applied in the field of meteorological research, particularly in the downscaling of images due to their ability to generate super-resolution images. In recent years, numerous researchers have combined GANs with recurrent neural networks (RNNs) to address the issue of meteorological super-resolution. However, these models do not take into account the spatial variations of meteorological sequences. In this paper, we propose a super-resolution method named RN-STLSTM-GAN, which combines GANs with RN-STLSTM and ESA networks to learn the spatiotemporal features of meteorological sequences. Specifically, we first apply the RN-STLSTM at the initialization of the generator and discriminator to learn the spatiotemporal relationships between sequential images. Second, an ESA network is combined with the RN-STLSTM structure to enhance the learning of spatial features. Thirdly, LeakyReLU is used as the activation function for both the generator and discriminator to minimize the loss of image data during model training. Experiments conducted on the NJU-CPOL datasets demonstrate that our proposed method outperforms other existing methods and can generate realistic and temporally consistent super-resolution sequences for datasets at different heights.},
  archive      = {J_IJCIA},
  author       = {Meng Li and Ziting Xu and Zhengjie Li and Yajie Qi},
  doi          = {10.1142/S1469026824500329},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450032},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {RN-STLSTM-GAN: Spatiotemporal-guided generative adversarial network for time-evolving precipitation downscaling},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing the hybrid feature selection in the DNA
microarray for cancer diagnosis using fuzzy entropy and the giza pyramid
construction algorithm. <em>IJCIA</em>, <em>24</em>(1), 2450031. (<a
href="https://doi.org/10.1142/S1469026824500317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biotechnological analysis of DNA microarray genes provides valuable insights into the discovery and treatment of diseases such as cancer. It may also be crucial for the prevention and treatment of other genetic diseases. However, due to the large number of features and dimensions in a DNA microarray, the ‚Äúcurse of dimensions‚Äù problem is very common. Many machine learning methods require an effective subset of input genes to achieve high accuracy. Unfortunately, extracting features (genes) is an inherently NP-hard problem. Recently, the use of metaheuristics to overcome the NP-hardness of the feature extraction problem has attracted the attention of many researchers. In this paper, we use the combination of fuzzy entropy and Giza Pyramid Construction (GPC) for feature selection. First, redundant features in the microarray dataset are removed using the fuzzy entropy approach. GPC is then used to reduce the execution time. This results in the selection of a near-optimal subset of genes for cancer detection. Dimensionality reduction with GPC followed by classification with Convolutional Neural Network (CNN) creates a synergy to increase efficiency. The proposed method is tested on five well-known cancer patient datasets: leukemia, lymphoma, MLL, ovarian, and SRBCT. The performance of CNN was also measured with four well-known classifiers, including K-nearest neighbor, na√Øve Bayesian, decision tree, and logistic regression. Our results show that, on average, CNN has the highest accuracy, recall, precision, and F-measure in all datasets.},
  archive      = {J_IJCIA},
  author       = {Masoumeh Motevalli and Madjid Khalilian and Azam Bastanfard},
  doi          = {10.1142/S1469026824500317},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450031},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Optimizing the hybrid feature selection in the DNA microarray for cancer diagnosis using fuzzy entropy and the giza pyramid construction algorithm},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adadelta-CSA: Adadelta-chameleon swarm algorithm for
EEG-based epileptic seizure detection. <em>IJCIA</em>, <em>24</em>(1),
2450030. (<a href="https://doi.org/10.1142/S1469026824500305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is referred to as a neurological disorder, which is detected via examination and manual comprehension of Electroencephalogram (EEG) signals. In deep learning schemes, various enhancements have emerged to efficiently address complex issues by end-to-end learning. The major objective of this research is to propose a new seizure detection approach from EEG signals using a deep learning-based classification technique. The pre-processing is the initial stage, where denoising is performed using a Short-Time Fourier Transform (STFT). Subsequently, the statistical features, time-domain features and spectral features are extracted from the pre-processed signal. Finally, an efficient optimization approach, named Adadelta-Chameleon Swarm Algorithm (Adadelta-CSA), is proposed and employed to train Deep Neural Network (DNN) to carry out the precise seizure prediction. Here, the integration of the Adadelta concept in the Chameleon Swarm Algorithm (CSA) has resulted in Adadelta-CSA. At last, the performance of the Adadelta-CSA scheme-based DNN is compared with the existing techniques by considering accuracy, sensitivity and specificity, and it is found to produce better values of 0.951, 0.966, and 0.935, respectively.},
  archive      = {J_IJCIA},
  author       = {G. Indu Salini and I. Sowmy},
  doi          = {10.1142/S1469026824500305},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450030},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Adadelta-CSA: Adadelta-chameleon swarm algorithm for EEG-based epileptic seizure detection},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised image aesthetic assessment based on
transformer. <em>IJCIA</em>, <em>24</em>(1), 2450029. (<a
href="https://doi.org/10.1142/S1469026824500299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual aesthetics has always been an important area of computational vision, and researchers have continued exploring it. To further improve the performance of the image aesthetic evaluation task, we introduce a Transformer into the image aesthetic evaluation task. This paper pioneers a novel self-supervised image aesthetic evaluation model founded upon Transformers. Meanwhile, we expand the pretext task to capture rich visual representations, adding a branch for inpainting the masked images in parallel with the tasks related to aesthetic quality degradation operations. Our model‚Äôs refinement employs the innovative uncertainty weighting method, seamlessly amalgamating three distinct losses into a unified objective. On the AVA dataset, our approach surpasses the efficacy of prevailing self-supervised image aesthetic assessment methods. Remarkably, we attain results approaching those of supervised methods, even while operating with a limited dataset. On the AADB dataset, our approach improves the aesthetic binary classification accuracy by roughly 16% compared to other self-supervised image aesthetic assessment methods and improves the prediction of aesthetic attributes.},
  archive      = {J_IJCIA},
  author       = {Minrui Jia and Guangao Wang and Zibei Wang and Shuai Yang and Yongzhen Ke and Kai Wang},
  doi          = {10.1142/S1469026824500299},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450029},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Self-supervised image aesthetic assessment based on transformer},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stream fusion network for human energy expenditure
estimation with wearable sensor. <em>IJCIA</em>, <em>24</em>(1),
2450028. (<a href="https://doi.org/10.1142/S1469026824500287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing awareness of health, using wearable sensors to monitor individual activities and accurately estimate energy expenditure has become a current research focus. However, existing research encounters challenges including low estimation accuracy, a deficiency of frequency domain features, and difficulty in integrating time domain and frequency domain features. To address these issues, we propose an innovative framework called the Dual-Stream Fusion Network (DSFN). This framework combines the Time Domain Encoding (TDE) module, the Frequency Domain Hierarchical-Split Encoding (FDHSE) module, and a Two-Stage Feature Fusion (TSF) module. Specifically, the temporal stream of the framework employs the TDE module to capture deep temporal features that reflect the complex dynamic variations in time-series data. The frequency domain stream introduces the FDHSE module, which extracts frequency domain features using a multi-level, multi-scale approach, ensuring a comprehensive and diverse representation of frequency information. Through this dual-stream architecture, our model effectively learns both time and frequency domain features, addressing the limitations of frequency domain features observed in prior studies. Additionally, we propose the TSF module to fully integrate time and frequency domain features, effectively overcoming the challenge of fusing these two types of features. We conducted experiments on two public datasets, namely the GOTOV dataset (elderly people) and the JSI dataset (young people). Experimental results demonstrate that our method achieves excellent performance across different age groups. Compared to the baseline models, the proposed DSFN significantly improves the accuracy of human energy expenditure estimation.},
  archive      = {J_IJCIA},
  author       = {Shuo Xiao and Zhiyu Wang and Chaogang Tang and Zhenzhen Huang},
  doi          = {10.1142/S1469026824500287},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450028},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A dual-stream fusion network for human energy expenditure estimation with wearable sensor},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rural tourist attractions recommendation model based on
multi-feature fusion graph neural networks. <em>IJCIA</em>,
<em>24</em>(1), 2450027. (<a
href="https://doi.org/10.1142/S1469026824500275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of the rural tourism industry, traditional tourism recommendation technologies can no longer meet the necessary requirements. To address the issue of rural tourist attraction recommendations, a rural tourist attraction recommendation model is constructed based on a multi-feature fusion graph neural network. First, construct a feature map based on the relationship between tourists‚Äô preferences and tourist attractions, and incorporate the attention mechanism to enhance the model‚Äôs learning capabilities. Second, utilize a two-part graph model to extract positive and negative preference features of tourists, and a conversation graph model to extract tourists‚Äô transfer preference features. Finally, various features are utilized to generate suggested content by computing scores for tourists‚Äô travel preferences. To address the problem of recommending tourist groups, suitable features for random group matching are collected and the cosine function is employed to identify users with similar random group features. Finally, the multi-features are merged, and the tourists‚Äô interest preferences are scored to arrive at content recommendations. In the experiment on individualized attraction recommendations, data from the Chengdu area were used to test the proposed model. The accuracy of the model‚Äôs recommendations was 0.822 for five recommendations which outperformed the other models. In the experiment for group-based attraction recommendations, this experiment tested the Chengdu dataset. The proposed model achieved the highest accuracy of 0.972 when the group size was 70, outperforming the other two models. Additionally, with regards to different numbers of recommendations, the proposed model‚Äôs accuracy was 0.5241, which was the best performance among the three models when the number of recommendations was set to five. The proposed recommendation model performs optimally in suggesting tourist attractions and meets the needs of rural tourism. The research content provides crucial technical references for tourist traveling and rural tourism development.},
  archive      = {J_IJCIA},
  author       = {Xiangrong Zhang and Xueying Wang},
  doi          = {10.1142/S1469026824500275},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450027},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Rural tourist attractions recommendation model based on multi-feature fusion graph neural networks},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Music generation using dual interactive wasserstein fourier
acquisitive generative adversarial network. <em>IJCIA</em>,
<em>24</em>(1), 2450026. (<a
href="https://doi.org/10.1142/S1469026824500263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music composition, an intricate blend of human creativity and emotion, presents substantial challenges when generating melodies from lyrics which hinders effective learning in neural networks and the inadequate depiction of harmonic structure that fails to encapsulate the complex relationships between lyrics and melodies. The existing methods often struggle to balance emotional depth and structural coherence, leading to compositions that lack both the intended emotional resonance and musical consistency. To overcome these issues, this research introduces a novel approach named Dual Interactive Wasserstein Fourier Acquisitive Generative Adversarial Network (DIWFA-GAN), which integrates innovative techniques like swish activation functions and the Giant Trevally Optimizer (GTO) for parameter optimization. Meanwhile, the GTO, inspired by the movement patterns of the Giant Trevally fish, provides efficient and effective parameter optimization, improving the model‚Äôs convergence speed and accuracy. Comparative analysis against recent existing models reveals superior performance for both the LMD-full MIDI and Reddit MIDI datasets, with impressive metrics including inception scores of 9.36 and 2.98, Fr√©chet inception distances of 35.29 and 135.54 and accuracies of 99.98% and 99.95%, respectively. The DIWFA-GAN significantly outperforms existing models in generating high-fidelity melodies, as evidenced by superior inception scores, Fr√©chet inception distances, and accuracies on both datasets.},
  archive      = {J_IJCIA},
  author       = {Tarannum Shaikh and Ashish Jadhav},
  doi          = {10.1142/S1469026824500263},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450026},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Music generation using dual interactive wasserstein fourier acquisitive generative adversarial network},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-population competition adaptive interior search
algorithm based on reinforcement learning for flexible job shop
scheduling problem. <em>IJCIA</em>, <em>24</em>(1), 2450025. (<a
href="https://doi.org/10.1142/S1469026824500251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a bi-population competition adaptive interior search algorithm (BCAISA) based on a reinforcement learning strategy is proposed for the classical flexible job shop scheduling problem (FJSP) to optimize the makespan. First, the scheduling solution is represented using a machine-job-based two-segment integer encoding method, and various heuristic rules are then applied to generate the initial population. Secondly, a bi-population mechanism is introduced to partition the population into two distinct sub-populations. These sub-populations are specifically tailored for machine assignment and operation permutation, employing different search strategies respectively, aiming to facilitate an efficient implementation of parallel search. A competition mechanism is introduced to facilitate the information exchange between the two sub-populations. Thirdly, the ISA is adapted for the discrete scheduling problem by discretizing a series of search operators, which include composition optimization, mirror search, and random walk. A Q-learning-based approach is proposed to dynamically adjust a key parameter, aiming to strike a balance between the capacity for global exploration and local exploitation. Finally, extensive experiments are conducted based on 10 well-known benchmark instances of the FJSP.¬†The design of the experiment (DOE) method is employed to determine the algorithm‚Äôs parameters. Based on the computational results, the effectiveness of four improvement strategies is first validated. The BCAISA is then compared with fifteen published algorithms. The comparative data demonstrate that our algorithm outperforms other algorithms in 50% of benchmark instances. Additionally, according to the relative percentage deviation (RPD) from the state-of-the-art results, the BCAISA also exhibits superior performance. This highlights the effectiveness of our algorithm for solving the classical FJSP.¬†To enhance the practical application, the scope of the ISA will be broadened in future work to more complex problems in real-world scenarios.},
  archive      = {J_IJCIA},
  author       = {Tianhua Jiang and Lu Liu},
  doi          = {10.1142/S1469026824500251},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450025},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A bi-population competition adaptive interior search algorithm based on reinforcement learning for flexible job shop scheduling problem},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modified genetic algorithm for efficient high-utility
itemset mining. <em>IJCIA</em>, <em>24</em>(1), 2450024. (<a
href="https://doi.org/10.1142/S146902682450024X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In pattern mining, high-utility itemset mining (HUIM) is useful for discovering high-utility patterns. The study of HUIM using heuristic techniques reflects issues in producing better offspring. It is ineffective in terms of search space organization, population diversity, and utility calculation, which impact runtime and accuracy. It is observed that very few researchers have experimented with genetic algorithm (GA) and are still facing the same issues as mentioned before. To overcome these problems, a novel approach is proposed for HUIM using modified GA and optimized local search (HUIM-MGALS) with six potential contributions. First is linking the utility with the Bitmap dataset to reduce utility access time, leading to effective search space organization. Second, HUIM-MGALS employs a fitness scaling strategy to avoid redundancy. Third, a high-utility itemset (HUI) revision strategy is employed to explore significant HUIs. Modified population diversity maintenance strategy and iterative crossover help to preserve significant HUIs and improve search capability as fourth and fifth contributions. Sixth, the use of multiple mutations refines the wasted individuals to boost accuracy. Extensive experimentation showed that HUIM-MGALS significantly outperforms the presented algorithms, up to 8.6 times faster. It also demonstrates superior HUI discovery capabilities for both sparse and dense datasets. This is supported by the modified population diversity maintenance strategy, which is proved to be the most impactful modification for HUI discovery in HUIM-MGALS.},
  archive      = {J_IJCIA},
  author       = {Eduardus Hardika Sandy Atmaja and Kavita Sonawane},
  doi          = {10.1142/S146902682450024X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450024},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Modified genetic algorithm for efficient high-utility itemset mining},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Student apartment access control system based on
MTCNN-FaceNet algorithm. <em>IJCIA</em>, <em>24</em>(1), 2450022. (<a
href="https://doi.org/10.1142/S1469026824500226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the security management issues of student apartments, a study is conducted on a student apartment access control system based on multitasking cascaded convolutional networks and FaceNet. Firstly, a face detection model is built based on an improved multi-task cascaded convolutional network, and then a face recognition model is built using FaceNet. The results showed that the detection accuracy of the multi-task cascaded convolutional network using the improved non-maximum suppression algorithm was 98.7%, which was higher than the traditional multi-task cascaded convolutional network and effectively improved the detection performance of the multi-task cascaded convolutional network. The face detection model based on the improved multi-task cascaded convolutional network had the shortest average detection time of 361 s, the highest average detection accuracy of 90.3%, an accuracy of 99%, a recall rate of 98.5%, and an F 1 value of 99%. While maintaining high detection efficiency, it also ensured the accuracy of detection. The average accuracy of the mask detection method based on the MobileNet V2 network was relatively high, at 98.96%. The facial recognition model based on FaceNet achieved a recognition accuracy of 99.15% for faces without masks and 92.04% for faces with masks, with the highest accuracy and recall rates of 99.3% and 99.6%. The model constructed in the study has good application effects in face detection, which helps to improve the security of the student apartment access control system.},
  archive      = {J_IJCIA},
  author       = {Jing Zhang},
  doi          = {10.1142/S1469026824500226},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450022},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Student apartment access control system based on MTCNN-FaceNet algorithm},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial network optimization algorithm based
on adaptive data augmentation. <em>IJCIA</em>, <em>24</em>(1), 2450021.
(<a href="https://doi.org/10.1142/S1469026824500214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the research of deep learning, an Unsupervised deep convolution-generated Generated Adversarial Network (UGAN) usually needs a large number of data samples to train. However, when faced with some small samples, the performance of the algorithm is often degraded due to over-fitting. Combined with specially designed data enhancement methods, a generated adversarial network optimization algorithm based on adaptive data augmentation (AdauGAN) is proposed. The adaptive data augmentation module is added before the discriminant network, and a spatial transformation is carried out simultaneously at the probability distribution level of generated data and real data. To alleviate the over-fitting phenomenon in the training process, the current enhancement intensity is adjusted adaptively after the over-fitting occurs. The proposed algorithm is verified on SVHN, CelebA and CIFAR-10 data sets. The Frechet Inception Distance (FID) values of AdauGAN achieve 22.10, 23.94, 34.87, respectively, which is close to or even higher than the training results of Deep Convolution Generated Adversarial Network (DCGAN) under all data. Extensive experiment results show that the proposed Adaugan has an excellent performance in small samples. Besides, in some cases, it can catch up with the large sample results of existing algorithms.},
  archive      = {J_IJCIA},
  author       = {Yanan Yu and Dunhuang Shi and Qi Pan},
  doi          = {10.1142/S1469026824500214},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450021},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Generative adversarial network optimization algorithm based on adaptive data augmentation},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijfcs---6">IJFCS - 6</h2>
<ul>
<li><details>
<summary>
(2025). The longest wave subsequence problem: Generalizations of the
longest increasing subsequence problem. <em>IJFCS</em>, <em>36</em>(2),
203‚Äì218. (<a href="https://doi.org/10.1142/S012905412450014X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The longest increasing subsequence (LIS) problem aims to find the subsequence exhibiting an increasing trend in a numeric sequence with the maximum length. In this paper, we generalize the LIS problem to the longest wave subsequence (LWS) problem, which encompasses two versions: LWSt and LWSr. Given a numeric sequence A of distinct values and a target trend sequence T , the LWSt problem aims to identify the longest subsequence of A that preserves the trend of the prefix of T . And, the LWSr problem aims to find the longest subsequence of A within r segments, alternating increasing and decreasing subsequences. We propose two efficient algorithms for solving the two versions of the LWS problem. For the LWSt problem, the time complexity of our algorithm is O ( n log n ) , where n represents the length of the given numeric sequence A . Additionally, we propose an O ( r n log n ) -time algorithm for solving the LWSr problem. In both algorithms, we utilize the priority queues for the insertion, deletion, and successor operations.},
  archive      = {J_IJFCS},
  author       = {Guan-Zhi Chen and Chang-Biau Yang and Yu-Cheng Chang},
  doi          = {10.1142/S012905412450014X},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {203-218},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The longest wave subsequence problem: Generalizations of the longest increasing subsequence problem},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Eulerian and hamiltonian soft semigraphs. <em>IJFCS</em>,
<em>36</em>(2), 183‚Äì202. (<a
href="https://doi.org/10.1142/S0129054124500138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft set theory is a mathematical approach to address the challenges of handling vague or uncertain information. It is a more advanced version of classical set theory that deals with imprecise elements and enables the flexible representation of uncertain data. It involves categorizing the elements of the universe based on specific parameters. Semigraph is a generalization of a graph which is different from a hypergraph. A hypergraph extends the concept of a graph by allowing any subset of vertices to form an edge. Semigraphs, on the other hand, distinguish themselves from hypergraphs by imposing a specific order on the vertices within each edge. Soft semigraphs were developed using the principles of soft set theory applied to semigraphs. This study introduces Eulerian and Hamiltonian soft semigraphs. We establish a necessary and sufficient condition for a soft semigraph to be Eulerian, relying on parameters such as p -part consecutive adjacent degree, p -part end degree, and the p -part consecutive adjacency graph. Additionally, we provide the conditions for a soft semigraph to be Hamiltonian. We introduce the concept of maximal non-Hamiltonian p -part. Finally, we define the closure of a soft semigraph and demonstrate the relationship between a Hamiltonian soft semigraph and its closure.},
  archive      = {J_IJFCS},
  author       = {Bobin George and Jinta Jose and Rajesh K. Thumbakara},
  doi          = {10.1142/S0129054124500138},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {183-202},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Eulerian and hamiltonian soft semigraphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Paired domination integrity of graphs. <em>IJFCS</em>,
<em>36</em>(2), 161‚Äì181. (<a
href="https://doi.org/10.1142/S0129054124500126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of vulnerability in a communication network plays an important role when there is a disruption in the network. There exist several graph parameters that measure the vulnerability of a communication network. Domination integrity is one of the vulnerability parameters that measure the performance of a communication network. In this paper, we introduce the concept of paired domination integrity of a graph as a new measure of graph vulnerability. Let G = ( V , E ) be a simple, connected graph. A set of vertices in a graph G , say S , is a paired dominating set if the following two conditions are satisfied: (i) every vertex of G has a neighbor in S and (ii) the subgraph induced by S contains a perfect matching. The paired domination integrity of G , denoted by P D I ( G ) , is defined as P D I ( G ) = m i n { | S | + m ( G ‚àí S ) : S is¬†a¬†paired¬†dominating¬†set¬†of¬†G } , where m ( G ‚àí S ) is the order of the largest component in the induced subgraph of G ‚àí S . In this paper, we determine few bounds relating paired domination integrity with other graph parameters and the paired domination integrity of some classes of graphs.},
  archive      = {J_IJFCS},
  author       = {Annie Clare Antony and V. Sangeetha},
  doi          = {10.1142/S0129054124500126},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {161-181},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Paired domination integrity of graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional fractional matching preclusion number of graphs.
<em>IJFCS</em>, <em>36</em>(2), 143‚Äì159. (<a
href="https://doi.org/10.1142/S0129054124500114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conditional fractional matching preclusion number (CFMP number for short) f m p 1 ( G ) of a graph G is the minimum number of edges whose deletion results in a graph without isolated vertices and without fractional perfect matchings. In this paper, we study the CFMP number of complete graphs, complete bipartite graphs and twisted cubes. Also, we give Nordhaus‚ÄìGaddum-type results for the CFMP numbers of general graphs.},
  archive      = {J_IJFCS},
  author       = {Wen Li and Yuhu Liu and Yinkui Li and Eddie Cheng and Yaping Mao},
  doi          = {10.1142/S0129054124500114},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {143-159},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Conditional fractional matching preclusion number of graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improvement for error-correcting pairs of some special
MDS codes. <em>IJFCS</em>, <em>36</em>(2), 127‚Äì141. (<a
href="https://doi.org/10.1142/S0129054124500102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The error-correcting pair is a general algebraic decoding method for linear codes. Since every linear code is contained in an MDS linear code with the same minimum distance over some finite field extensions, we focus on MDS linear codes. Recently, He and Liao showed that for an MDS linear code ùíû with minimum distance 2 ‚Ñì + 2 , if it has an ‚Ñì -error-correcting pair, then the parameters of the pair have three possibilities. Moreover, for the first case, they gave a necessary condition for an MDS linear code ùíû with minimum distance 2 ‚Ñì + 2 to have an ‚Ñì -error-correcting pair, and for the other two cases, they only gave some counterexamples. For the second case, in this paper, we give a necessary condition for an MDS linear code ùíû with minimum distance 2 ‚Ñì + 2 to have an ‚Ñì -error-correcting pair, and then basing on the Product Singleton Bound, we prove that there are two cases for such pairs, and then give some counterexamples basing on twisted generalized Reed‚ÄìSolomon codes for these cases.},
  archive      = {J_IJFCS},
  author       = {Rui Xiao and Qunying Liao},
  doi          = {10.1142/S0129054124500102},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {127-141},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {An improvement for error-correcting pairs of some special MDS codes},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The h-component diagnosability of alternating group graphs.
<em>IJFCS</em>, <em>36</em>(2), 111‚Äì125. (<a
href="https://doi.org/10.1142/S0129054124300018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid expansion of multiprocessor systems, the fault diagnosis is becoming more and more important. The h -component diagnosability of a multiprocessor system, is proposed to extend the traditional diagnosability and has been investigated widely. In this paper, we prove that under both the PMC model and MM* model the 2 -component and 3 -component diagnosability of an n -dimensional alternating group graph are 2 n ‚àí 5 and 3 n ‚àí 7 respectively.},
  archive      = {J_IJFCS},
  author       = {Nengjin Zhuo and Shumin Zhang and Yalan Li and Chengfu Ye},
  doi          = {10.1142/S0129054124300018},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {2},
  pages        = {111-125},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {The h-component diagnosability of alternating group graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijitdm---11">IJITDM - 11</h2>
<ul>
<li><details>
<summary>
(2025). Reject inference using discriminative dual stack sparse
auto-encoders for consumer credit risk evaluation. <em>IJITDM</em>,
<em>24</em>(1), 327‚Äì353. (<a
href="https://doi.org/10.1142/S0219622025500038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit risk evaluation has gained substantial attention within financial institutions, serving as a pivotal tool to predict borrower repayment behavior and provide precise credit risk estimations. Traditional credit risk approaches discarded rejected applicants and were built only on accepted applicants, which posed sample selection bias issue. Previous reject inference methods solved the bias issue by incorporating information of rejected applicants. However, these methods assumed that the accepted and rejected samples had identical dimensions. In practical financial scenarios, financial institutions often encounter situations where the dimensions of accepted samples were larger than those of the rejected samples. Therefore, the additional features in accepted samples might not be fully utilized in the previous reject inference. In this study, we proposed a discriminative dual stack sparse auto-encoder (DD-SSAE) reject inference method that was suitable for the real scenarios. The proposed DD-SSAE has the following characteristics: (1) rejected samples were filtered based on our selection mechanism; (2) a stack sparse auto-encoder (SSAE), within a self-taught learning framework, was carried out to incorporate information of the selected rejected samples into the common features of accepted samples; and (3) a data fusion module, consisting of another SSAE network and a data fusion layer, was introduced to combine extra features with common features for accepted samples. The proposed method was verified on a Chinese consumer dataset and the findings illustrated its superiority over four conventional credit scoring models and five previous reject inference models.},
  archive      = {J_IJITDM},
  author       = {Gang Kou and Siqi Weng and Feng Shen and Fahd Saleh S. Alotaibi},
  doi          = {10.1142/S0219622025500038},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {327-353},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Reject inference using discriminative dual stack sparse auto-encoders for consumer credit risk evaluation},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple risks and uncertain portfolio management.
<em>IJITDM</em>, <em>24</em>(1), 297‚Äì325. (<a
href="https://doi.org/10.1142/S0219622023500190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies comparative static effects under uncertainty when investors face a portfolio decision problem with both an endogenous risk and a background risk. Since the security market is complex, there exists situation where security return and background asset return are given by experts‚Äô estimates when they cannot be reflected by historical data. Focusing on such a situation, an uncertain mean-chance model with background risk for optimal portfolio selection is developed, in which the use of chance of portfolio return failing to reach the threshold can help investors easily determine their tolerance toward risk and thus facilitate a decision making. Then we analyze the solution of the programming problem under different threshold return level, i.e., how different degrees of threshold return will affect allocation between risky asset and risk-free asset. Furthermore, we discuss the effects of changes in mean and standard deviation of risky asset and background asset on investment decisions when security return and background asset return follow normal uncertainty distributions. Finally, a real portfolio selection example is given as illustration.},
  archive      = {J_IJITDM},
  author       = {Guowei Jiang and Xiaoxia Huang and Tingting Yang},
  doi          = {10.1142/S0219622023500190},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {297-325},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multiple risks and uncertain portfolio management},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Megale: A metadata-driven graph-based system for data lake
exploration. <em>IJITDM</em>, <em>24</em>(1), 259‚Äì295. (<a
href="https://doi.org/10.1142/S0219622024500135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data lakes are storage repositories that contain large amounts of data (big data) in its native format; encompassing structured, semi-structured or unstructured. Data lakes are open to a wide range of use cases, such as carrying out advanced analytics and extracting knowledge patterns. However, the sheer dumping of data into a data lake would only lead to a data swamp. To prevent such a situation, enterprises can adopt best practices, among which to manage data lake metadata. A growing body of research has focused on proposing metadata systems and models for data lakes with a special interest on model genericness. However, existing models fail to cover all aspects of a data lake, due to their static modeling approach. Besides, they do not fully cover essential features for an effective metadata management, namely governance, visibility and uniform treatment of data lake concepts. In this paper, we propose a dynamic modeling approach to meet these features, based on two main constructs: data lake concept and data lake relationship . We showcase our approach by Megale, a graph-based metadata system for NoSQL data lake exploration. We present a proof-of-concept implementation of Megale and we show its effectiveness and efficiency in exploring the data lake.},
  archive      = {J_IJITDM},
  author       = {Doulkifli Boukraa and Meriem Bouraoui and Chaima Grine and Racha Ouahab},
  doi          = {10.1142/S0219622024500135},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {259-295},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Megale: A metadata-driven graph-based system for data lake exploration},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of trade credit on financing strategy in a dual
capital-constrained supply chain. <em>IJITDM</em>, <em>24</em>(1),
223‚Äì257. (<a href="https://doi.org/10.1142/S0219622022500687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study analyzes the financing strategy of a two-echelon supply chain, consisting of a manufacturer and a retailer, both subject to capital constraints. Specifically, the bank provides loans to the manufacturer, who then grants trade credit to the retailer. Based on the three-party game analysis framework of the bank, manufacturer, and retailer, this paper constructs a supply chain financing model under the information symmetry and information asymmetry structures, respectively; measures the maximum financing ability of the manufacturer; and discusses the influence of trade credit, moral hazard, and information structure on the manufacturer‚Äôs and bank‚Äôs strategies. The results show that under the trade credit situation, it is critical for the bank to provide loan to manufacturer who does not have moral hazard. The maximum financing capacity of the manufacturer is affected by the rate of return on moral hazard and the intensity of trade credit default. The increase of trade credit default intensity and risk exposure will lead to the increase of the interest rate of bank loan, and in the case of information asymmetry, the bank will often ask for a higher interest rate to deal with the information disadvantage. The strategy for the bank to make the credit line is more complex, and the degree of information asymmetry plays a positive moderating effect on the influence of trade credit on the credit line. Our findings provide implications for participants who implement financing actions to improve their financial performance and control the moral hazard and default risk along a supply chain.},
  archive      = {J_IJITDM},
  author       = {Xiaofeng Xie and Yang Yang and Xingyang Lyu and Fengying Zhang and Xiuying Hu and Zongfang Zhou},
  doi          = {10.1142/S0219622022500687},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {223-257},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {The impact of trade credit on financing strategy in a dual capital-constrained supply chain},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dwarf mongoose chimp optimization enabled RMDL for sentiment
categorization using cell phone data. <em>IJITDM</em>, <em>24</em>(1),
197‚Äì222. (<a href="https://doi.org/10.1142/S0219622025500026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is the process of looking through digital text to determine if the emotional tone of a text is positive, negative, or neutral. It helps companies improve their product, but a serious problem arises in classifying the polarity of certain texts with information, sentences or features to forecast their opinion. Therefore, sentiment classification should be done using new technology that classifies reviews as positive or negative so that users can make effective decisions. This research paper develops an effective model to classify sentiment using cell phone data. Initially, the Amazon phone document is passed to the BERT tokenization stage to split the acquired reviews. Then, the Aspect Term Extraction (ATE) is applied and the Term Frequency-Inverse Document Frequency (TF-IDF) is extracted as the first output. Afterward, Wordnet ontology features are extricated as the second output. Moreover, features like statistical, sarcasm linguistic, and N -gram features are extracted from BERT tokenization and considered as the third output. Finally, the sentiment is classified by subjecting the obtained three outputs to Random Multimodal Deep Learning (RMDL), which is tuned by Dwarf Mongoose Chimp Optimization (DMCO). DMCO is created by the combination of the Dwarf Mongoose Optimization (DMO) and the Chimp Optimization Algorithm (ChOA). The developed DMCO-RMDL approach attained high accuracy, True Positive Rate (TPR), True Negative Rate (TNR), precision, recall, and F 1-score values of 93%, 92.8%, 92.2%, 91.5%, 94.1%, and 94.8%, respectively.},
  archive      = {J_IJITDM},
  author       = {Minu P. Abraham and K. R. Udaya Kumar Reddy},
  doi          = {10.1142/S0219622025500026},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {197-222},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Dwarf mongoose chimp optimization enabled RMDL for sentiment categorization using cell phone data},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The best evaluation sequence method and application based on
quantum cognitive theory. <em>IJITDM</em>, <em>24</em>(1), 169‚Äì196. (<a
href="https://doi.org/10.1142/S0219622025500014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the credit risk evaluation process, considering that the decision maker‚Äôs irrational behavior may cause the interference effect between evaluation information, and further decrease the reliability of evaluation results. To solve this problem, the best evaluation sequence method and its application in credit risk evaluation based on quantum cognitive theory is proposed in this paper. First, the quantum cognition theory and the evaluation information given by the decision maker are used to get the interference degree between evaluation information. Second, the interference degree between evaluation information is aggregated to obtain the comprehensive interference degree of each alternative. Third, according to the idea that the greater the comprehensive interference degree of the alternative, the more backward the evaluation sequence of the alternative is, we determine the best evaluation sequence of alternatives. Finally, our proposed method is applied to obtain the best evaluation sequence of commercial bank credit risk.},
  archive      = {J_IJITDM},
  author       = {Wangwang Yu and Xinwang Liu and Yingping Zi},
  doi          = {10.1142/S0219622025500014},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {169-196},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {The best evaluation sequence method and application based on quantum cognitive theory},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision modeling approach for data acquisition systems of
the vehicle industry based on interval-valued linear diophantine fuzzy
set. <em>IJITDM</em>, <em>24</em>(1), 89‚Äì168. (<a
href="https://doi.org/10.1142/S0219622023500487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling data acquisition systems (DASs) can support the vehicle industry in the development and design of sophisticated driver assistance systems. Modeling DASs on the basis of multiple criteria is considered as a multicriteria decision-making (MCDM) problem. Although literature reviews have provided models for DASs, the issue of imprecise, unclear, and ambiguous information remains unresolved. Compared with existing MCDM methods, the robustness of the fuzzy decision by opinion score method II (FDOSM II) and fuzzy weighted with zero inconsistency II (FWZIC II) is demonstrated for modeling the DASs. However, these methods are implemented in an intuitionistic fuzzy set environment that restricts the ability of experts to provide membership and nonmembership degrees freely, simulate real-world ambiguity efficiently, utilize a narrow fuzzy number space, and deal with interval data. Thus, this study used a more efficient fuzzy environment interval-valued linear Diophantine fuzzy set (IVLDF) with FWZIC II for criterion weighting and IVLDF with FDOSM for DAS modeling to address the issues and support industrial community characteristics in the design and implementation of advanced driver assistance systems in vehicles. The proposed methodology comprises two consecutive phases. The first phase involves adapting a decision matrix that intersects DAS alternatives and criteria. The second phase (development phase) proposes a decision modeling approach based on formulation of IVLD-FWZIC II and IVLD-FDOSM II to model DASs. A total of 14 DASs were modeled on the basis of 15 DAS criteria, including seven subcriteria for ‚Äúcomprehensive complexity assessment‚Äù and eight subcriteria for ‚Äúdesign and implementation,‚Äù which had a remarkable effect on the DAS design when implemented by industrial communities. Systematic ranking, sensitivity analysis, and modeling checklists were conducted to demonstrate that the modeling results were subject to systematic ranking, as indicated by the high correlations across all described scenarios of changing criterion weight values, supporting the most important research points, and proposing a value-adding process in modeling the most desirable DAS.},
  archive      = {J_IJITDM},
  author       = {M. J. Baqer and H. A. AlSattar and Sarah Qahtan and A. A. Zaidan and Mohd Azri Mohd Izhar and Iraq T. Abbas},
  doi          = {10.1142/S0219622023500487},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {89-168},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A decision modeling approach for data acquisition systems of the vehicle industry based on interval-valued linear diophantine fuzzy set},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multidimensional analysis of investment priorities for
circular economy with quantum spherical fuzzy hybrid modeling.
<em>IJITDM</em>, <em>24</em>(1), 61‚Äì87. (<a
href="https://doi.org/10.1142/S021962202350075X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular economy aims recycling in the production process instead of destroying the products. With the help of this situation, waste can be considered in the remanufacturing process so that the rate of consumption of natural resources can be decreased. It is necessary to focus on certain investment issues to achieve a circular economy, but all investments have some risks. Hence, the economies should make priority analysis to take efficient actions. Investment priorities are identified to have circular economy. A novel fuzzy decision-making model has been created for this purpose. In the first stage, balanced scorecard criteria are evaluated with the help of multi stepwise weight assessment ratio analysis (M-SWARA). Later, the multidimensional investment priorities of circular economy are ranked. In this context, elimination and choice translating reality (ELECTRE) approach is taken into consideration. The main contribution of the paper is that a new methodology is created by the name of M-SWARA. Owing to these new improvements, cause and effect relationship among the items can be analyzed. It is identified that financial issues play the most crucial role for investments to improve circular economy. On the other side, it is also concluded that remanufacturing is the most significant investment alternative to develop circular economy. For the sustainability of the investment to improve circular economy, necessary financial analysis should be performed. With the help of this situation, these substances can be reintroduced into the production process in the form of raw materials. With the increase of remanufacturing, it will be possible to reduce waste and save scarce material resources.},
  archive      = {J_IJITDM},
  author       = {Hasan Din√ßer and Serhat Y√ºksel and Umit Hacƒ±oglu and Babek Erdebilli},
  doi          = {10.1142/S021962202350075X},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {61-87},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multidimensional analysis of investment priorities for circular economy with quantum spherical fuzzy hybrid modeling},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage integrated dynamic assessment method for urban
resilience based on multisource data. <em>IJITDM</em>, <em>24</em>(1),
29‚Äì59. (<a href="https://doi.org/10.1142/S0219622024410013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban resilience assessment (URA) is challenging because of urban system complexity and dynamic resilience variability. This paper develops a URA method with comprehensive feature consideration and integrated data use and then constructs a hierarchical URA criteria system. Subsequently, a two-stage integrated dynamic assessment method based on multisource data is presented, wherein the subjective‚Äìobjective combination weights are determined, and the dimensional and overall urban resilience (UR) indexes are constructed. The applicability and superiority of the proposed method to existing methods are verified using a case study in Beijing. The results showed that UR in Beijing has improved substantially in 2016‚Äì2020; social and ecological dimensions are important for UR improvement; and synergies exist between different UR dimensions, which are crucial for resilient urban development. This study provides a systematic solution for URA that features a dynamic perspective, multisource data utilization, and subjective‚Äìobjective combination weights, enhancing URA comprehensiveness and accuracy.},
  archive      = {J_IJITDM},
  author       = {Lulu Shen and Jianping Li and Xiaolei Sun and Weilan Suo},
  doi          = {10.1142/S0219622024410013},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {29-59},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Two-stage integrated dynamic assessment method for urban resilience based on multisource data},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear step-adjusting programming in factor space.
<em>IJITDM</em>, <em>24</em>(1), 7‚Äì28. (<a
href="https://doi.org/10.1142/S0219622023410018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent behavior that appears in a decision process can be treated as a point y , the dynamic state observed and controlled by the agent, moving in a factor space impelled by the goal factor and blocked by the constraint factors. Suppose that the feasible region is cut by a group of hyperplanes, when point y reaches the region‚Äôs wall, a hyperplane will block the moving, and the agent needs to adjust the moving direction such that the target is pursued as faithfully as possible. Since the wall is not able to be represented by a differentiable function, the gradient method cannot be applied to describe the adjusting process. We, therefore, suggest a new model, named linear step-adjusting programming (LSP) in this paper. LSP is similar to a kind of relaxed linear programming (LP). The difference between LP and LSP is that the former aims to find the ultimate optimal point, while the latter just does a direct action in a short period. Where will a blocker encounter? How do you adjust the moving direction? Where further blockers may be encountered next, and how should the direction be adjusted again? ‚Ä¶ If the ultimate best is found, that‚Äôs a blessing; if not, that‚Äôs fine. We request at least an adjustment should be got at the first time. However, the former is idealism, and the latter is realism. In place of a gradient vector, the projection of goal direction g in a subspace plays a core role in LSP. If a hyperplane block y goes ahead along with the direction d , then we must adjust the new direction d ‚Ä≤ as the projection of g in the blocking plane. Suppose there is only one blocker at a time. In that case, it is straightforward to calculate the projection, but how to calculate the projection when more than one blocker is encountered simultaneously? It is still an open problem for LP researchers. We suggest a projection calculation using the Hat matrix in the paper. LSP will attract interest in economic restructuring, financial prediction, and reinforcement learning.},
  archive      = {J_IJITDM},
  author       = {Jing He and Hui Zheng and Rozbeh Zarei and Ho-Chung Lui and Qi-Wei Kong and Yi-Mu Ji and Xingsen Li and Hailong Yang and Baorui Du and Yong Shi and Pingjiang Wang and Andre van Zundert},
  doi          = {10.1142/S0219622023410018},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {7-28},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Linear step-adjusting programming in factor space},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editor‚Äôs introduction. <em>IJITDM</em>, <em>24</em>(1), 1‚Äì5.
(<a href="https://doi.org/10.1142/S0219622025030014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622025030014},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {1-5},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor‚Äôs introduction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijns---5">IJNS - 5</h2>
<ul>
<li><details>
<summary>
(2025). End-user confidence in artificial intelligence-based
predictions applied to biomedical data. <em>IJNS</em>, <em>35</em>(4),
2550017. (<a href="https://doi.org/10.1142/S0129065725500170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of Artificial Intelligence (AI) are revolutionizing biomedical research and healthcare by offering data-driven predictions that assist in diagnoses. Supervised learning systems are trained on large datasets to predict outcomes for new test cases. However, they typically do not provide an indication of the reliability of these predictions, even though error estimates are integral to model development. Here, we introduce a novel method to identify regions in the feature space that diverge from training data, where an AI model may perform poorly. We utilize a compact precompiled structure that allows for fast and direct access to confidence scores in real time at the point of use without requiring access to the training data or model algorithms. As a result, users can determine when to trust the AI model‚Äôs outputs, while developers can identify where the model‚Äôs applicability is limited. We validate our approach using simulated data and several biomedical case studies, demonstrating that our approach provides fast confidence estimates ( &lt; 0 . 2 milliseconds per case), with high concordance to previously developed methods ( f - score &gt; 0 . 9 6 5 ). These estimates can be easily added to real-world AI applications. We argue that providing confidence estimates should be a standard practice for all AI applications in public use.},
  archive      = {J_IJNS},
  author       = {Zvi Kam and Lorenzo Peracchio and Giovanna Nicora},
  doi          = {10.1142/S0129065725500170},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550017},
  shortjournal = {Int. J. Neural Syst.},
  title        = {End-user confidence in artificial intelligence-based predictions applied to biomedical data},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimal neural network conditions for encoding future
interactions. <em>IJNS</em>, <em>35</em>(4), 2550016. (<a
href="https://doi.org/10.1142/S0129065725500169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space and time are fundamental attributes of the external world. Deciphering the brain mechanisms involved in processing the surrounding environment is one of the main challenges in neuroscience. This is particularly defiant when situations change rapidly over time because of the intertwining of spatial and temporal information. However, understanding the cognitive processes that allow coping with dynamic environments is critical, as the nervous system evolved in them due to the pressure for survival. Recent experiments have revealed a new cognitive mechanism called time compaction. According to it, a dynamic situation is represented internally by a static map of the future interactions between the perceived elements (including the subject itself). The salience of predicted interactions (e.g. collisions) over other spatiotemporal and dynamic attributes during the processing of time-changing situations has been shown in humans, rats, and bats. Motivated by this ubiquity, we study an artificial neural network to explore its minimal conditions necessary to represent a dynamic stimulus through the future interactions present in it. We show that, under general and simple conditions, the neural activity linked to the predicted interactions emerges to encode the perceived dynamic stimulus. Our results show that this encoding improves learning, memorization and decision making when dealing with stimuli with impending interactions compared to no-interaction stimuli. These findings are in agreement with theoretical and experimental results that have supported time compaction as a novel and ubiquitous cognitive process.},
  archive      = {J_IJNS},
  author       = {Sergio Diez-Hermano and Gonzalo Aparicio-Rodriguez and Paloma Manubens and Abel Sanchez-Jimenez and Carlos Calvo-Tapia and David Levcik and Jos√© Antonio Villacorta-Atienza},
  doi          = {10.1142/S0129065725500169},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550016},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Minimal neural network conditions for encoding future interactions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-assisted local attention in lower layers of visual
transformers. <em>IJNS</em>, <em>35</em>(4), 2550015. (<a
href="https://doi.org/10.1142/S0129065725500157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since vision transformers excel at establishing global relationships between features, they play an important role in current vision tasks. However, the global attention mechanism restricts the capture of local features, making convolutional assistance necessary. This paper indicates that transformer-based models can attend to local information without using convolutional blocks, similar to convolutional kernels, by employing a special initialization method. Therefore, this paper proposes a novel hybrid multi-scale model called Frequency-Assisted Local Attention Transformer (FALAT). FALAT introduces a Frequency-Assisted Window-based Positional Self-Attention (FWPSA) module that limits the attention distance of query tokens, enabling the capture of local contents in the early stage. The information from value tokens in the frequency domain enhances information diversity during self-attention computation. Additionally, the traditional convolutional method is replaced with a depth-wise separable convolution to downsample in the spatial reduction attention module for long-distance contents in the later stages. Experimental results demonstrate that FALAT-S achieves 83.0% accuracy on IN-1k with an input size of 2 2 4 √ó 2 2 4 using 29.9 M parameters and 5.6 G FLOPs. This model outperforms the Next-ViT-S by 0.9 AP b /0.8 AP m with Mask-R-CNN 1 √ó on COCO and surpasses the recent FastViT-SA36 by 3.1% mIoU with FPN on ADE20k.},
  archive      = {J_IJNS},
  author       = {Xin Zhou and Zeyu Jiang and Shihua Zhou and Zhaohui Ren and Yongchao Zhang and Tianzhuang Yu and Yulin Liu},
  doi          = {10.1142/S0129065725500157},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550015},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Frequency-assisted local attention in lower layers of visual transformers},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online and cross-user finger movement pattern recognition by
decoding neural drive information from surface electromyogram.
<em>IJNS</em>, <em>35</em>(4), 2550014. (<a
href="https://doi.org/10.1142/S0129065725500145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-user variability is a well-known challenge that leads to severe performance degradation and impacts the robustness of practical myoelectric control systems. To address this issue, a novel method for myoelectric recognition of finger movement patterns is proposed by incorporating a neural decoding approach with unsupervised domain adaption (UDA) learning. In our method, the neural decoding approach is implemented by extracting microscopic features characterizing individual motor unit (MU) activities obtained from a two-stage online surface electromyogram (SEMG) decomposition. A specific deep learning model is designed and initially trained using labeled data from a set of existing users. The model can update adaptively when recognizing the movement patterns of a new user. The final movement pattern was determined by a fuzzy weighted decision strategy. SEMG signals were collected from the finger extensor muscles of 15 subjects to detect seven dexterous finger-movement patterns. The proposed method achieved a movement pattern recognition accuracy of ( 9 3 . 9 4 ¬± 1 . 5 4 )% over seven movements under cross-user testing scenarios, much higher than that of the conventional methods using global SEMG features. Our study presents a novel robust myoelectric pattern recognition approach at a fine-grained MU level, with wide applications in neural interface and prosthesis control.},
  archive      = {J_IJNS},
  author       = {Haowen Zhao and Yunfei Liu and Xinhui Li and Xiang Chen and Xu Zhang},
  doi          = {10.1142/S0129065725500145},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550014},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Online and cross-user finger movement pattern recognition by decoding neural drive information from surface electromyogram},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Architecture knowledge distillation for evolutionary
generative adversarial network. <em>IJNS</em>, <em>35</em>(4), 2550013.
(<a href="https://doi.org/10.1142/S0129065725500133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are effective for image generation, but their unstable training limits broader applications. Additionally, neural architecture search (NAS) for GANs with one-shot models often leads to insufficient subnet training, where subnets inherit weights from a supernet without proper optimization, further degrading performance. To address both issues, we propose Architecture Knowledge Distillation for Evolutionary GAN (AKD-EGAN). AKD-EGAN operates in two stages. First, architecture knowledge distillation (AKD) is used during supernet training to efficiently optimize subnetworks and accelerate learning. Second, a multi-objective evolutionary algorithm (MOEA) searches for optimal subnet architectures, ensuring efficiency by considering multiple performance metrics. This approach, combined with a strategy for architecture inheritance, enhances GAN stability and image quality. Experiments show that AKD-EGAN surpasses state-of-the-art methods, achieving a Fr√©chet Inception Distance (FID) of 7.91 and an Inception Score (IS) of 8.97 on CIFAR-10, along with competitive results on STL-10 (FID: 20.32, IS: 10.06). Code and models will be available at https://github.com/njit-ly/AKD-EGAN .},
  archive      = {J_IJNS},
  author       = {Yu Xue and Yan Lin and Ferrante Neri},
  doi          = {10.1142/S0129065725500133},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550013},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Architecture knowledge distillation for evolutionary generative adversarial network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijprai---15">IJPRAI - 15</h2>
<ul>
<li><details>
<summary>
(2025). Generative artificial intelligence model for
multi-granularity power data simulation. <em>IJPRAI</em>,
<em>39</em>(2), 2559001. (<a
href="https://doi.org/10.1142/S0218001425590013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric power resources are essential for the efficient and orderly development of society. Accurate power load forecasting is a key driver for the low-carbon upgrade of power systems. Traditional forecasting methods often struggle to capture long-term dependencies. Additionally, extracting complex nonlinear features from data remains a significant challenge, making it challenging to meet the accuracy demands of modern power systems. Besides, current deep learning-based forecasting methods cannot simulate multi-granularity power load data. To address these challenges, this paper presents a Generative Pre-trained Transformer model, GPT4PLTS, designed for power data simulation and fine-grained power load forecasting. The model leverages the Transformer architecture, incorporating the first six layers of the GPT decoder structure. It utilizes a multi-head attention mechanism to extract temporal features and includes a time alignment layer to maintain the sequence of time-series data, addressing both short-term and long-term dependencies. Extensive experiments are conducted on load observations from 2000 enterprises. The results demonstrate that GPT4PLTS achieves high accuracy in data simulation and forecasts across different time granularities, particularly excelling in short and medium-term predictions. Future research could focus on optimizing the model structure to enhance the model‚Äôs generalization ability.},
  archive      = {J_IJPRAI},
  author       = {Yiwen Jiang and Sheng Xiang and Yihan Dai and Dawei Cheng},
  doi          = {10.1142/S0218001425590013},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2559001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Generative artificial intelligence model for multi-granularity power data simulation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AMP: Multi-task transfer learning via leveraging attention
mechanism on task embeddings. <em>IJPRAI</em>, <em>39</em>(2), 2557004.
(<a href="https://doi.org/10.1142/S0218001425570046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The attention mechanism has been successfully used in a sequence consisted of a series of word embeddings to improve the representation of the sequence. Inspired by this, we leverage the attention mechanism on a set of tasks to implement a multi-task transfer learning method called AMP (Attentions between Multiple Prompts). First, we encode a task into a prompt as task representation called task embedding. Second, we learn an attention component on all task embeddings to generate a combined prompt for each task, which is an attention-weighted sum of task embeddings. Each combined prompt incorporates the knowledge of all tasks. The word embedding is a vector, but the task embedding is a 2D matrix. The attention mechanism can be exploited on a set of vectors rather than on a set of matrices. The prior methods employ pooling or flattened method to transform the matrix to the vector for computing the attentions between matrices. We propose a method called DAM (Direct Attention Mechanism) which can compute attentions between matrices directly without transforming. DAM method can more exactly compute the attentions between matrices. Wide experiments demonstrate that AMP outperforms prompt-tuning method and prior prompt transfer methods.},
  archive      = {J_IJPRAI},
  author       = {Yangyang Yu and Keru Wang},
  doi          = {10.1142/S0218001425570046},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2557004},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {AMP: Multi-task transfer learning via leveraging attention mechanism on task embeddings},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lift-type power catwalk system based on dual closed-loop
error-driven active disturbance rejection control. <em>IJPRAI</em>,
<em>39</em>(2), 2557003. (<a
href="https://doi.org/10.1142/S0218001425570034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate the flutter instability observed during lift-type power catwalk operations, a Dual-Loop Error-Driven Adaptive Disturbance Rejection Control (EDDL-ADRC) strategy is proposed. This approach enhances the tracking accuracy and robustness of the electro-hydraulic servo system under variable load and large inertia conditions, effectively alleviating flutter induced by fluctuations in driving speed. Under low-frequency small load conditions, the EDDL-ADRC overcomes the limitations of traditional Active Disturbance Rejection Control (ADRC), particularly those related to system order, and demonstrates superior control performance compared to conventional ADRC. The dual-loop error-driven controller consists of two identical second-order ADRC modules. The primary controller operates in a conventional driving mode, while the error-driven controller utilizes both the system‚Äôs output error and control input as driving signals. This error-driven controller effectively compensates for phase lag in the main controller and the limited observation accuracy of the Extended State Observer (ESO), thereby improving overall system performance. The proposed control strategy‚Äôs effectiveness is validated via a joint simulation platform that integrates both the electro-hydraulic and mechanical systems of the catwalk mechanism.},
  archive      = {J_IJPRAI},
  author       = {Jia Chen and Li Xiong and Simin Kang and Yi Yang and Zhongfeng Li},
  doi          = {10.1142/S0218001425570034},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2557003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lift-type power catwalk system based on dual closed-loop error-driven active disturbance rejection control},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An indoor WiFi fingerprint positioning based on RSS and CSI.
<em>IJPRAI</em>, <em>39</em>(2), 2557002. (<a
href="https://doi.org/10.1142/S0218001425570022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous people to determine the location by wireless fingerprint technology indoors at present. The premise of fingerprint positioning is to assume that the received signal strength distance is consistent with the positioning distance. However, due to the interference of obstacles such as walls, desks, chairs, pedestrians, the closest distance selected using the received signal strength distance may not be the closest to the target at its corresponding position, which may lead to large positioning errors. To improve accuracy, this paper analyzes the advantages of the respective features of RSS and CSI, use algorithms to extract them, and proposes a novel WiFi fingerprint positioning algorithm for fusion to estimate the target location. The experimental data show that this method has certain advantages in improving positioning accuracy.},
  archive      = {J_IJPRAI},
  author       = {Kun Zhang and Feixue Cheng and Haifeng Wang and Yu Zhou and Qiang Geng and Jinyang Zhou and Yukang Fan and Wenting Pan},
  doi          = {10.1142/S0218001425570022},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2557002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {An indoor WiFi fingerprint positioning based on RSS and CSI},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rough intuitionistic fuzzy set based on inclusion degree.
<em>IJPRAI</em>, <em>39</em>(2), 2554002. (<a
href="https://doi.org/10.1142/S0218001425540023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper first proposes the notion of the intuitionistic fuzzy sets on inclusion degree, furthermore, a couple of dual operators‚Äô lower approximations, and upper approximations of fuzzy inclusion approximate space are provided, thus, a probabilistic intuitionistic fuzzy set model that stemmed from inclusion degree was obtained. A rough intuitionistic fuzzy set and histogram equalization-based image enhancement algorithm is proposed to address the shortcomings of excessive enhancement and loss of image detail information in fuzzy enhancement that cannot improve image contrast and histogram equalization enhancement. The fusion of rough intuitionistic blur enhancement and histogram equalization focuses on rough intuitionistic blur enhancement while suppressing the shortcomings of histogram equalization, which not only enhances the detailed information of the image but also improves its contrast. Finally, its effectiveness is verified through typical image enhancement examples.},
  archive      = {J_IJPRAI},
  author       = {Qiuna Zhang and Chunhai Hu and Ling Zhang},
  doi          = {10.1142/S0218001425540023},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2554002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Rough intuitionistic fuzzy set based on inclusion degree},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image deblurring algorithm incorporating self-attention
mechanism. <em>IJPRAI</em>, <em>39</em>(2), 2554001. (<a
href="https://doi.org/10.1142/S0218001425540011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acquisition of clear images is a critical aspect in various fields including computer vision, aerial detection, and medical imaging. The issue of image blur caused by object motion poses a challenge in obtaining clear images. To address this, an improved AT-DGAN network model is proposed in this paper. This model integrates the pyramid generator module of the DeblurGAN-v2 network with a self-attention mechanism. The feature pyramid is employed for image feature extraction and representation, while the self-attention mechanism dynamically adjusts the weight of important features in each pyramid layer and performs weighted fusion, thereby compensating for the information loss during feature extraction in the feature pyramid network. Additionally, a hinge loss function is designed for the proposed model to balance the discriminator and the generator, enhancing the stability and training efficiency of the generative adversarial network. The experimental results show that compared to other algorithms of the same type, this improved algorithm has increased the Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) of restored images by 0.58 dB and 1.5%, respectively.},
  archive      = {J_IJPRAI},
  author       = {Tingting Yu and Qiang Lv and Zhen Huang and Zhang Su and XiangLi Wang},
  doi          = {10.1142/S0218001425540011},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2554001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Image deblurring algorithm incorporating self-attention mechanism},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified model with multi-scale feature fusion and
multi-decoupled-head for detecting traffic object. <em>IJPRAI</em>,
<em>39</em>(2), 2550003. (<a
href="https://doi.org/10.1142/S021800142550003X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately and rapidly detecting traffic object has been attracted intensive attention due to its potential applications in the fields of autonomous driving, traffic flow monitoring, augmented reality (AR) and so on. However, there are many difficulties in the process of traffic object detection indeed, such as occlusion and aggregation between objects, insufficient feature extraction of objects, in particular the presence of a large number of small objects, which bring great challenges to these traffic objects detection. In this paper, an improved traffic object detection model based on You-Only-Look-Once version 5 small (YOLOv5s) is proposed to address the issues. By utilizing spatial pyramids to extract multi-scale spatial features and applying Squeeze-and-Excitation (SE) channel attention to capture more global and local semantic features, especially by designing a sub-network in the neck to fuse high-resolution information in shallow layers with more accurately semantic information in deep layers, the detection sensitivity of object features is enhanced. More importantly, by explanting decoupled-head into the network, outstanding performance of the model with high detection accuracy and rapid detection speed is realized. The experimental results on the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) and Laboratory for Intelligent and Safe Automobiles (LISA) traffic signs datasets both show that the modified model significantly improves the detection accuracy. Meanwhile, the high real-time performance is still maintained. Undoubtedly, the modified model proposed in this paper can effectively address many difficulties in traffic object detection under various complex scenes, which would be greatly helpful for its potential applications in the future.},
  archive      = {J_IJPRAI},
  author       = {Yongfan Duan and Hongtao Gong and Haoyang Yu and Kuijie Shi and Bingbing Wang and Daoxun Jin and Wenqian Wan and Zihua Wang and Shuqin Liu and Gang Liu},
  doi          = {10.1142/S021800142550003X},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2550003},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A modified model with multi-scale feature fusion and multi-decoupled-head for detecting traffic object},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using hybrid transformer and convolutional neural network
for malware detection in internet of things. <em>IJPRAI</em>,
<em>39</em>(2), 2550002. (<a
href="https://doi.org/10.1142/S0218001425500028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious firmware upgrading represents a critical security vulnerability in Internet of Things (IoT) devices. This study introduces HyCNNAt, a novel hybrid deep learning network for IoT malware detection that synergistically combines Convolutional Neural Networks (CNNs) with transformer attention mechanisms. HyCNNAt‚Äôs architecture vertically and horizontally stacks convolution and attention layers, enhancing the network‚Äôs generalization capabilities, capacity, and overall effectiveness. We evaluated HyCNNAt using a publicly available IoT firmware dataset, where it demonstrated superior performance with the highest accuracy ( 9 7 . 1 1 % ¬± 1 . 0 2 % ), F1-score ( 9 9 . 9 9 2 % ¬± 0 . 0 0 4 % ), and recall ( 9 7 . 4 8 % ¬± 2 . 6 5 5 6 % ), highlighting its robust classification capabilities, although its precision ( 9 1 . 2 7 % ¬± 4 5 . 0 8 % ) exhibited variability compared to state-of-the-art models such as CoAtNet, MobileViT, MobileNet, and MobileNet variants using transfer learning. These results underscore HyCNNAt‚Äôs potential as a robust solution for addressing the pressing challenge of IoT malware detection.},
  archive      = {J_IJPRAI},
  author       = {Yanhui Guo and Chunlai Du and Zelal Mustafaoglu and Abdulkadir Sengur and Harish Garg and Kemal Polat and Deepika Koundal},
  doi          = {10.1142/S0218001425500028},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2550002},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Using hybrid transformer and convolutional neural network for malware detection in internet of things},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biased block term tensor decomposition for temporal
pattern-aware QoS prediction. <em>IJPRAI</em>, <em>39</em>(2), 2550001.
(<a href="https://doi.org/10.1142/S0218001425500016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of cloud services make users pay more attention to Quality of Service (QoS). Generally, the user cannot call all services simultaneously to obtain corresponding QoS data and can only choose a service from a few known data, thus it‚Äôs critical to predict unknown QoS values. A third-order tensor can model temporal patterns of QoS data, and studies indicate that the tensor latent factor analysis models based on Canonical Polyadic (CP) decomposition can effectively capture temporal patterns to predict unknown data in QoS. However, the existing CP decomposition-based models limit their learning ability since rank-one tensors contain less structure information, which results in low prediction accuracy. Therefore, this paper proposes a Biased Block Term Tensor Decomposition (BBTTD) model to achieve high accuracy for temporal pattern-aware QoS prediction. It mainly adopts the following three-fold ideas: (a) implementing a tensor learning model by adopting the block term decomposition in rank-( L r , L r , 1) terms; (b) proposing the bias block term tensors to enhance the model‚Äôs prediction accuracy; (c) designing a nonnegative multiplication update algorithm to learning model parameters. Extensive experiments on two public dynamic QoS datasets demonstrate that BBTTD has higher prediction accuracy compared with several QoS prediction models.},
  archive      = {J_IJPRAI},
  author       = {Qu Wang and Xin Liao and Hao Wu},
  doi          = {10.1142/S0218001425500016},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2550001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Biased block term tensor decomposition for temporal pattern-aware QoS prediction},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bayesian network-based scenario-response model for
situation deduction in emergency management of rainstorm scenarios.
<em>IJPRAI</em>, <em>39</em>(2), 2530001. (<a
href="https://doi.org/10.1142/S0218001425300012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevalence of safety hazards has intensified, underscoring the pressing need for effective responses to sudden disasters and enhanced emergency management. The traditional forecast-response paradigm is no longer adequately addressing the management and decision-making needs for contemporary emergency incidents. Existing emergency management frameworks often struggle with the systemic characteristics of unexpected events. This study proposes a Bayesian network-based scenario-response framework for situation deduction in Emergency Management, taking the torrential rain disaster in Henan Province as a point of reference. In this context, the fundamental units of disaster-forming environment (E), emergency measures (M), and scenario state (S) are employed to construct a coherent and dynamic scenario evolution chain, which effectively depicts the progression of the scenario linkage process. This approach facilitates a deeper understanding of the evolution of emergencies and enhances predictive capacity.},
  archive      = {J_IJPRAI},
  author       = {Liming Zhang and Jiangqinzhe Liu and Ruijie Zhao and Fenghua Zhang and Huiyou Chang},
  doi          = {10.1142/S0218001425300012},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2530001},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A bayesian network-based scenario-response model for situation deduction in emergency management of rainstorm scenarios},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated human action recognition with improved graph
convolutional network-based pose estimation. <em>IJPRAI</em>,
<em>39</em>(2), 2457016. (<a
href="https://doi.org/10.1142/S0218001424570167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of utilizing Artificial Intelligence (AI) to identify and label human behaviors from unprocessed activity data gathered from various sources is known as Human Activity Recognition (HAR). Because of its potential applications across multiple areas, computer vision faces a significant challenge in recognizing human actions and the accompanying interactions with objects and the environment. Investigating the temporal and geographical characteristics of the skeleton sequence is essential for this endeavor, according to recent studies. However, efficiently extracting discriminative temporal and spatial information remains a difficult task. This work proposes a novel Human Action Recognition Model exploiting improved Graph Convolutional Network (GCN)-based pose estimation with a Hybrid Classifier (IGCN-HC). The phases carried out in this model are pre-processing, pose estimation, feature extraction, and activity recognition. Initially, the input video will be pre-processed and a frame from the input video stream will be generated. Subsequently, human pose estimation exploiting improved GCN will be accomplished. Further, human skeletal joints‚Äô coordinates in two- or three-dimensional spaces are determined via human pose estimation. Then, Shape Local Binary Texture (SLBT) and an improved hierarchy of skeleton features have been used to detect the variance in different activities. In the last phase, a hybrid classification model with the combination of Deep Maxout and customized CNN has been proposed for the recognition phase. The model utilizes two inputs pose estimation results (skeleton) and the extracted features for training purposes. Finally, the proposed trained model is evaluated for recognition on different test inputs and contrasted with the existing techniques.},
  archive      = {J_IJPRAI},
  author       = {Amit Baghel and Alok Kumar Singh Kushwaha and Roshan Singh},
  doi          = {10.1142/S0218001424570167},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2457016},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Automated human action recognition with improved graph convolutional network-based pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDC bit design based on deep learning for gravel layer.
<em>IJPRAI</em>, <em>39</em>(2), 2452023. (<a
href="https://doi.org/10.1142/S0218001424520232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are lots of gravel layers gradually increasing from east to west of Kuqa Piedstone in Tarim Basin, especially the thickest gravel layer, high gravel content, large particle size, high compressive strength and poor drillability in Bozi block, which are the key factors that result in low drilling efficiency and complex drilling accidents. Therefore, this paper presents a design scheme based on lithology characteristics deep learning and artificial intelligence analysis of bit failure mode and characteristics of large section gravel layer in fore-salt. The design scheme of a PDC special-shaped tooth bit with strong impact resistance has been formed through the structural design of anti-impact aggressive PDC teeth, rock breaking efficiency study, combined with the optimization design of bit layout. The design scheme not only improves the anti-impact but also improves the anti-eddy performance of the PDC special-shaped tooth bit. It effectively expands both the application range of PDC special tooth bit in the gravel layer and prolongs the bit life. The artificial intelligence optimized PDC special-shaped tooth bit has obtained a great effect in deep gravel stratum, in the meantime, it successfully solved the problems of slow drilling rate and short footage of single bit in Kuqa formation and other formations.},
  archive      = {J_IJPRAI},
  author       = {Yongxing Sun},
  doi          = {10.1142/S0218001424520232},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2452023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {PDC bit design based on deep learning for gravel layer},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class incremental learning based on playback images
generated by classification network. <em>IJPRAI</em>, <em>39</em>(2),
2451021. (<a href="https://doi.org/10.1142/S0218001424510212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification has surpassed human performance in numerous domains. However, in real-world scenarios, challenges such as storage constraints, privacy concerns, and commercial data protection necessitate the enhancement of existing models to accommodate new class classifications ‚Äî a critical area of research known as class incremental learning. Data replay stands out as a pivotal technique within this domain. The DeepInversion algorithm ingeniously employs classification networks to generate training set images of notable quality. In this study, we improve the DeepInversion algorithm, leveraging a pre-trained model to yield superior quality playback images for class incremental learning. Within the context of class incremental learning, we introduce a cosine orthogonal classification loss function, formulated on the basis of linear layer analysis, to guide image generation and augment class incremental learning. This loss function is designed to ensure the mutual orthogonality of all class centers while minimizing intra-class distances. In the realm of knowledge distillation, we harness a combination of limited real images, a profusion of synthesized images, and Mix virtual images to facilitate feature cosine distance distillation. Sufficient comparative experiments and analyses with similar latest methods underscore the efficacy of our proposed approach, and obtain the SOTA results. The code for the paper can be found at http://github.com/YunXiaooooo/Class-incremental-learning-based-on-playback-images-generated-by-classification-network},
  archive      = {J_IJPRAI},
  author       = {Qiuyu Zhu and Yunxiao Zhang and Yunhang Zhuo and Junli Chen},
  doi          = {10.1142/S0218001424510212},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2451021},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Class incremental learning based on playback images generated by classification network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diagnostic method for demagnetization fault of elevator
synchronous traction machine based on informer. <em>IJPRAI</em>,
<em>39</em>(2), 2451007. (<a
href="https://doi.org/10.1142/S0218001424510078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a fault diagnosis method for synchronous traction machine demagnetization based on the Informer model. The method utilizes the Informer model to analyze and model the sensor data of the synchronous traction machine, adaptively learn the feature representation of time series data, and predict the future states in order to accurately identify and predict demagnetization faults. The specific steps include: (1) collecting sensor data of the synchronous traction machine, including parameters such as current, voltage, and rotational speed; (2) preprocessing the data, including denoising, normalization, and feature extraction; (3) constructing the Informer model and training and optimizing it using the preprocessed sensor data; and (4) using the trained model to predict and determine new sensor data, thereby achieving an accurate diagnosis of demagnetization faults. The advantages of this method are as follows: (1) automatic learning and extraction of important features of time series data without the need for manual feature design, improving diagnostic accuracy; (2) ability to handle long sequence data and strong modeling capability for time dependencies, better predicting future states and fault occurrences; and (3) adaptability to the characteristics and data features of different elevator systems and strong generalization capability.},
  archive      = {J_IJPRAI},
  author       = {Peng Shao and Bo Zheng and Xiaozhou Tang and Chao Chen and Xuefeng Hou},
  doi          = {10.1142/S0218001424510078},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2451007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Diagnostic method for demagnetization fault of elevator synchronous traction machine based on informer},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTOT: An online training and offline testing system for 6D
object pose estimation. <em>IJPRAI</em>, <em>39</em>(2), 2351015. (<a
href="https://doi.org/10.1142/S0218001423510151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel system to assist 6D object pose estimation network training, which is only deployed in the training progress to optimize the network parameters, and does not work in the testing stage, called Online training and offline testing system (OTOT). OTOT consists of two modules: a feature fusion module and a supervision module. The feature fusion module fuses several feature maps from the pose estimation network in a specified order to obtain a fused feature. Then, the supervision module uses the encoder‚Äìdecoder structure network to implicitly extract useful features from the fused feature and optimizes the pose estimation network online through the back-propagation mechanism. OTOT can be migrated to any network with encoder‚Äìdecoder structure. The network trained with OTOT achieves 56.11% accuracy in terms of the VSD metric on the TLESS dataset using RGB inputs, compared to the 46.70% accuracy of the original network trained without OTOT. Experiments show that OTOT greatly improves the accuracy of the pose estimation network, and since OTOT is not deployed in the testing stage, it does not increase any parameters during testing and affect the original speed of the network.},
  archive      = {J_IJPRAI},
  author       = {Yilin Yuan and Qian Jiang and Quan Mu and Wenchao Jia and Boya Fu and Renzhi He and Jian Wen and Fei Liu and Qin Mao and Mingliang Zhou},
  doi          = {10.1142/S0218001423510151},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {2},
  pages        = {2351015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {OTOT: An online training and offline testing system for 6D object pose estimation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijseke---6">IJSEKE - 6</h2>
<ul>
<li><details>
<summary>
(2025). HCIA: Hierarchical change impact analysis based on hierarchy
program slices. <em>IJSEKE</em>, <em>35</em>(2), 263‚Äì292. (<a
href="https://doi.org/10.1142/S0218194025500056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change impact analysis (CIA) is an essential method in software maintenance and evolution. Its accuracy and usability play a crucial role in its application. However, most CIAs are coarse-grained and limited to class and method levels. Despite the fine-grained CIAs‚Äô success in giving the statement-level impact set, they are still limited without the sub-statement level dependency analysis, leading to low precision. Additionally, their unstructured impact sets make it challenging for users to comprehend the impact content. This paper proposes Hierarchical Change Impact Analysis (HCIA), a Hierarchical CIA technique based on the sub-statement level dependence graph. HCIA can perform a forward hierarchy program slicing on the change set from five levels: sub-statement, statement, method, class, and package. Based on the program slices, HCIA calculates the impact factor of the impact sets at the five levels to generate the final impact set. In the experiment, we evaluate the relationship between the impact factor and the actual affected codes and assess the most appropriate size of HCIA impact sets. Furthermore, we evaluate HCIA on 10 open-source projects by comparing our approach with popular CIAs at the five levels. The experimental result shows that HCIA is more accurate than the popular CIAs.},
  archive      = {J_IJSEKE},
  author       = {Jianming Chang and Lulu Wang and Zaixing Zhang},
  doi          = {10.1142/S0218194025500056},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {263-292},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {HCIA: Hierarchical change impact analysis based on hierarchy program slices},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-based evaluation metric for question answering
systems. <em>IJSEKE</em>, <em>35</em>(2), 243‚Äì262. (<a
href="https://doi.org/10.1142/S0218194025500032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the limitations of traditional evaluation metrics for Question Answering (QA) systems that primarily focus on syntax and n-gram similarity. We propose a novel model-based evaluation metric, MQA-metric, and create a human-judgment-based dataset, squad-qametric and marco-qametric, to validate our approach. The research aims to solve several key problems: the objectivity in dataset labeling, the effectiveness of metrics when there is no syntax similarity, the impact of answer length on metric performance, and the influence of real answer quality on metric results. To tackle these challenges, we designed an interface for dataset labeling and conducted extensive experiments with human reviewers. Our analysis shows that the MQA-metric outperforms traditional metrics like BLEU, ROUGE and METEOR. Unlike existing metrics, MQA-metric leverages semantic comprehension through large language models (LLMs), enabling it to capture contextual nuances and synonymous expressions more effectively. This approach sets a standard for evaluating QA systems by prioritizing semantic accuracy over surface-level similarities. The proposed metric correlates better with human judgment, making it a more reliable tool for evaluating QA systems. Our contributions include the development of a robust evaluation workflow, creation of high-quality datasets, and an extensive comparison with existing evaluation methods. The results indicate that our model-based approach provides a significant improvement in assessing the quality of QA systems, which is crucial for their practical application and trustworthiness.},
  archive      = {J_IJSEKE},
  author       = {Dilan Bakƒ±r and Mehmet S. Aktas and Beytullah Yƒ±ldƒ±z},
  doi          = {10.1142/S0218194025500032},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {243-262},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A model-based evaluation metric for question answering systems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method to evaluate the credibility of domain knowledge
network using validated expert knowledge. <em>IJSEKE</em>,
<em>35</em>(2), 217‚Äì241. (<a
href="https://doi.org/10.1142/S0218194025500020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are living in an era of knowledge explosion, where all kinds of knowledge are emerging and becoming more and more complicated with the development of new techniques and new ideas. When we study knowledge and apply them to understand and solve problems, the credibility of knowledge is becoming our main concerns. Usually, high credible domain knowledge can guide us correctly understand all concepts and the relationships between them in this domain. Due to its good layer structure and scalability, domain knowledge network is widely used to represent knowledge in knowledge engineering, artificial intelligence and others in recent years. How to ensure the credibility of domain knowledge network? This is an important and interesting topic. In this paper, we propose a method to evaluate the knowledge credibility for domain knowledge network, which means that we can start from the layer structure of domain knowledge network, and evaluate the credibility of knowledge layer by layer using validated expert knowledge such as domain dictionary, domain ontology and domain expert experience. We conduct experiments with six domain knowledge network constructed based on network data and six domain knowledge network constructed manually based on published books or domain dictionaries, which describe the same domain knowledge in pairs. Experimental results show that the knowledge credibility of domain knowledge network constructed from validated expert knowledge is significantly higher than the knowledge credibility of domain knowledge network constructed directly from network data, which satisfy our expectation and also prove the effectiveness of our credibility evaluation method.},
  archive      = {J_IJSEKE},
  author       = {Yin Li and Ying Zhou and Li Liao and Bixin Li},
  doi          = {10.1142/S0218194025500020},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {217-241},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A method to evaluate the credibility of domain knowledge network using validated expert knowledge},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RESEARCH NOTES: Design of a distributed and highly scalable
fog architecture for heterogeneous IoT infrastructures. <em>IJSEKE</em>,
<em>35</em>(2), 195‚Äì215. (<a
href="https://doi.org/10.1142/S0218194025430016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing can provide an effective solution to the challenges presented by today‚Äôs ever-emerging Internet of Things (IoT) infrastructures. As the number of interconnected devices progressively increases, these infrastructures require better solutions to ensure high scalability and processing capacity, along with an efficient use of available resources. This is why this paper presents a distributed Fog architecture, specifically designed to address the challenges and difficulties presented by heterogeneous IoT environments. This Fog architecture is used as an intermediate layer between the IoT devices and the final layer, it has been designed after the previous analysis of the requirements to be met for the solution, then the modularization of the architecture has been carried out so that it can be easily distributed, and finally, an implementation has been generated on a real environment as a validation case of the proposal.},
  archive      = {J_IJSEKE},
  author       = {Luc√≠a Arnau Mu√±oz and Jos√© Vicente Bern√° Mart√≠nez and Carlos Calatayud Asensi and David Saavedra Pastor},
  doi          = {10.1142/S0218194025430016},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {195-215},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {RESEARCH NOTES: Design of a distributed and highly scalable fog architecture for heterogeneous IoT infrastructures},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward a pattern-based comprehensive framework using process
mining for RBAC conformance checks. <em>IJSEKE</em>, <em>35</em>(2),
157‚Äì194. (<a href="https://doi.org/10.1142/S0218194025500019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event logs often record the execution of business process instances. Detecting traces in the event logs that do not comply with access control policies, such as role-based access control (RBAC) policies, is essential to ensuring system security. Moreover, process mining has been extensively utilized for security analysis in recent years. However, pattern-based approaches for designing and analyzing RBAC policies in the context of business processes through process mining are notably absent. In this paper, we present a systematic framework for checking the conformance of RBAC implemented in the event logs of business processes with the RBAC policies specified in domain knowledge. To facilitate the representation of the RBAC policies derived from the domain knowledge, we employ an RBAC domain-specific language (DSL) combined with our RBAC-driven object constraint language (OCL) invariant patterns built from the various types of RBAC constraints. The implemented RBAC in an event log is represented as snapshots within our framework. Then, we validate the snapshots with the RBAC policies to be able to detect RBAC conformance issues. The proposed framework is experimented with and evaluated on two business process logs, one simulated log and one real-world event log named ‚ÄúBPI Challenge 2017‚Äù.},
  archive      = {J_IJSEKE},
  author       = {Duc-Hieu Nguyen and Yuichi Sei and Yasuyuki Tahara and Akihiko Ohsuga},
  doi          = {10.1142/S0218194025500019},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {157-194},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Toward a pattern-based comprehensive framework using process mining for RBAC conformance checks},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software quality assessment model: A new approach for
software testing tools. <em>IJSEKE</em>, <em>35</em>(2), 139‚Äì155. (<a
href="https://doi.org/10.1142/S0218194024500517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of software testing is a crucial phase in determining the quality of software, and this phase requires significant costs and a considerable amount of time for testers. This paper discusses the development of a framework for software quality assessment, involving flexible choices of software testing methods and variables in the form of an application. The method used is experimental, developing a new framework based on previous research, where previous research was limited to specific methods and testing variables. The result of this research is the creation of a new framework for software quality assessment. It is hoped that this framework can serve as a reference for software companies in evaluating software quality. In terms of complexity, this framework has the advantage of allowing a tester to choose methods with more flexible or unlimited testing variables. Regarding the estimated time and costs, with PF = 4 , 5 and 1 0 , the practical application complexity of the developed framework is estimated to have the best costs, time and human resources at IDR 254,240,000, with an estimated time of 3,178 work hours and 6,356 work hours with a team of 3 people.},
  archive      = {J_IJSEKE},
  author       = {Zulkifli Zulkifli and Mardiana Mardiana and Dikpride Despa},
  doi          = {10.1142/S0218194024500517},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {139-155},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Software quality assessment model: A new approach for software testing tools},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijufks---7">IJUFKS - 7</h2>
<ul>
<li><details>
<summary>
(2025). Interval methods in knowledge representation.
<em>IJUFKS</em>, <em>33</em>(2), 255‚Äì256. (<a
href="https://doi.org/10.1142/S0218488525970037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  doi          = {10.1142/S0218488525970037},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {255-256},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Interval methods in knowledge representation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Acknowledgements to the referees. <em>IJUFKS</em>,
<em>33</em>(2), 253‚Äì254. (<a
href="https://doi.org/10.1142/S0218488525970025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  doi          = {10.1142/S0218488525970025},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {253-254},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Acknowledgements to the referees},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). V-SVR with imprecise observations. <em>IJUFKS</em>,
<em>33</em>(2), 235‚Äì252. (<a
href="https://doi.org/10.1142/S0218488525500102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector regression (SVR) has been widely used in academia and industry with excellent performance. Crisp data always be trained by classic SVR and its varieties. However, classic SVR is feeble if data are imprecise or low-quality. Hence, the uncertainty theory emerged as the times require, which can process the imprecise observations well. In this study, a novel SVR model be introduced into uncertainty theory, termed v -SVR with imprecise observations, designed to handle imprecise or low-quality data. Unlike the conventional Œµ -SVR with imprecise observations approach, v -SVR offers an automated computation of the accuracy parameter Œµ , thereby eliminating the need for manual selection. This results in improved performance with simplified parameter tuning. The effectiveness of the approach in this paper be demonstrated through a numerical example.},
  archive      = {J_IJUFKS},
  author       = {Hao Zhang and Yuhong Sheng},
  doi          = {10.1142/S0218488525500102},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {235-252},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {V-SVR with imprecise observations},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropic semi-supervised dimensionality reduction for
distance metric learning. <em>IJUFKS</em>, <em>33</em>(2), 219‚Äì234. (<a
href="https://doi.org/10.1142/S0218488525500096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance metric learning and nonlinear dimensionality reduction are intrinsically related, since they are both different perspectives of the same fundamental problem: to learn compact and meaningful data representations for classification and visualization. In this paper, we propose a graph-based generalization of Semi-Supervised Dimensionality Reduction (SSDR) algorithm that uses stochastic distances (Kullback-Leibler, Bhattacharyya and Cauchy-Schwarz divergences) to compute the similarity between local multivariate Gaussian distributions along the K Nearest Neighbors (KNN) graph build from the samples in the input high-dimensional space. In summary, there are two variants of the proposed method: one which uses only a fraction of the labeled samples (10%) and another that also uses a clustering method (Gaussian Mixture Models) to estimate the labels of the minimum spanning tree of the KNN graph, incorporating more information into the process. Experimental results with several real datasets show that the proposed method is able to improve the classification accuracy of several supervised classifiers and also the quality of the obtained clusters (Silhouette Coefficients) in comparison to the regular SSDR algorithm, making it a viable alternative for pattern classification problems.},
  archive      = {J_IJUFKS},
  author       = {Alexandre L.¬†M. Levada},
  doi          = {10.1142/S0218488525500096},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {219-234},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Entropic semi-supervised dimensionality reduction for distance metric learning},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-level alternating meta-learning for recurring concept
on evolving data streams instructions for typing. <em>IJUFKS</em>,
<em>33</em>(2), 193‚Äì217. (<a
href="https://doi.org/10.1142/S0218488525500084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans‚Äô learning involves remembering patterns of the past to better understand recurring concepts as their knowledge grows. However, a key issue that arises from these cases is that previous knowledge in deep neural networks could be gradually forgotten when they are trained for a new concept. We address this problem by learning a general representation that can remember the previous information and promote future learning. In this pursuit, a new controller is introduced by the meta-learning strategy that guides the network to keep the balance between the previously learned concepts and the new concept, hence it avoids catastrophic forgetting. Compared to previous online incremental learning for evolving data streams, our approach is dedicated to handling recurring concepts. When encountering recurring concepts, the model can remember and recall the previous knowledge and can quickly adapt to this change. In this paper, we propose a Bi-level Alternating Meta-learning approach for recurring concepts (BLAML), which emphasizes the hidden representation learning of different concepts in model-level learning, and obtains a set of shared parameters through the global meta-learning strategy. Through extensive experiments, the effectiveness of the proposed method is proved.},
  archive      = {J_IJUFKS},
  author       = {Jian-Wei Liu and Si-Si Zhang and Zhong-Lin Bao},
  doi          = {10.1142/S0218488525500084},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {193-217},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {A bi-level alternating meta-learning for recurring concept on evolving data streams instructions for typing},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An unconstrained primal based twin parametric insensitive
support vector regression. <em>IJUFKS</em>, <em>33</em>(2), 173‚Äì192. (<a
href="https://doi.org/10.1142/S0218488525500072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an efficient regression algorithm based on primal formulation of twin support vector machine. This is an efficient approach to solve the optimization problem leading to reduced computation time. The proposed method is termed as twin parametric insensitive support vector regression (UPTPISVR). The optimization problems of the proposed (UPTPISVR) are a pair of unconstrained convex minimization problems. Moreover, the objective functions of UPTPISVR are strongly convex, differentiable and piecewise quadratic. Therefore, an approximate solution is obtained in primal variables instead of solving the dual formulation. Further, an absolute value equation problem is solved by using a functional iterative algorithm for UPTPISVR, termed as FUPTPISVR. The objective function of the proposed formulation involves the plus function which is non-smooth and therefore, smooth approximation functions are used to replace the plus function, termed as SUPTPISVR. The Newton-Armijo algorithm is then used to iteratively obtain the solutions, thus eliminates the requirement of any optimization toolbox. Various numerical experiments on synthetic and benchmark real-world datasets are presented for justifying the applicability and effectiveness of the proposed UPTPISVR. The results clearly indicate that the proposed algorithms outperform the existing algorithms in terms of root mean square error (RMSE) on most datasets.},
  archive      = {J_IJUFKS},
  author       = {Deepak Gupta and Bharat Richhariya and Parashjyoti Borah},
  doi          = {10.1142/S0218488525500072},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {173-192},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {An unconstrained primal based twin parametric insensitive support vector regression},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple item support constraints based frequent pattern
mining using dynamic prefix tree. <em>IJUFKS</em>, <em>33</em>(2),
143‚Äì172. (<a href="https://doi.org/10.1142/S0218488525500060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structural complexity of the pattern mining algorithm depends on the types of datasets. Even though they are highly connected, it can be intriguing to identify patterns in some application areas where they do not usually occur. FP tree construction practice with traversal of conditional pattern base with conditional FP Tree, with path traversing, to address the issue of massive memory and time usage. The creation of a non-recursive single-label dynamic prefix tree with a rule generation method utilizing multiple-item support restrictions is the paper‚Äôs significant contribution. The effectiveness of our proposed method is also compared to the FP tree and state-of-the-art TIS tree on various datasets in terms of time and memory complexity.},
  archive      = {J_IJUFKS},
  author       = {Sudarsan Biswas and Diganta Saha and Rajat Pandit},
  doi          = {10.1142/S0218488525500060},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {2},
  pages        = {143-172},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Multiple item support constraints based frequent pattern mining using dynamic prefix tree},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
