<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJNS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijns---5">IJNS - 5</h2>
<ul>
<li><details>
<summary>
(2025). End-user confidence in artificial intelligence-based
predictions applied to biomedical data. <em>IJNS</em>, <em>35</em>(4),
2550017. (<a href="https://doi.org/10.1142/S0129065725500170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of Artificial Intelligence (AI) are revolutionizing biomedical research and healthcare by offering data-driven predictions that assist in diagnoses. Supervised learning systems are trained on large datasets to predict outcomes for new test cases. However, they typically do not provide an indication of the reliability of these predictions, even though error estimates are integral to model development. Here, we introduce a novel method to identify regions in the feature space that diverge from training data, where an AI model may perform poorly. We utilize a compact precompiled structure that allows for fast and direct access to confidence scores in real time at the point of use without requiring access to the training data or model algorithms. As a result, users can determine when to trust the AI model’s outputs, while developers can identify where the model’s applicability is limited. We validate our approach using simulated data and several biomedical case studies, demonstrating that our approach provides fast confidence estimates ( &lt; 0 . 2 milliseconds per case), with high concordance to previously developed methods ( f - score &gt; 0 . 9 6 5 ). These estimates can be easily added to real-world AI applications. We argue that providing confidence estimates should be a standard practice for all AI applications in public use.},
  archive      = {J_IJNS},
  author       = {Zvi Kam and Lorenzo Peracchio and Giovanna Nicora},
  doi          = {10.1142/S0129065725500170},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550017},
  shortjournal = {Int. J. Neural Syst.},
  title        = {End-user confidence in artificial intelligence-based predictions applied to biomedical data},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimal neural network conditions for encoding future
interactions. <em>IJNS</em>, <em>35</em>(4), 2550016. (<a
href="https://doi.org/10.1142/S0129065725500169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space and time are fundamental attributes of the external world. Deciphering the brain mechanisms involved in processing the surrounding environment is one of the main challenges in neuroscience. This is particularly defiant when situations change rapidly over time because of the intertwining of spatial and temporal information. However, understanding the cognitive processes that allow coping with dynamic environments is critical, as the nervous system evolved in them due to the pressure for survival. Recent experiments have revealed a new cognitive mechanism called time compaction. According to it, a dynamic situation is represented internally by a static map of the future interactions between the perceived elements (including the subject itself). The salience of predicted interactions (e.g. collisions) over other spatiotemporal and dynamic attributes during the processing of time-changing situations has been shown in humans, rats, and bats. Motivated by this ubiquity, we study an artificial neural network to explore its minimal conditions necessary to represent a dynamic stimulus through the future interactions present in it. We show that, under general and simple conditions, the neural activity linked to the predicted interactions emerges to encode the perceived dynamic stimulus. Our results show that this encoding improves learning, memorization and decision making when dealing with stimuli with impending interactions compared to no-interaction stimuli. These findings are in agreement with theoretical and experimental results that have supported time compaction as a novel and ubiquitous cognitive process.},
  archive      = {J_IJNS},
  author       = {Sergio Diez-Hermano and Gonzalo Aparicio-Rodriguez and Paloma Manubens and Abel Sanchez-Jimenez and Carlos Calvo-Tapia and David Levcik and José Antonio Villacorta-Atienza},
  doi          = {10.1142/S0129065725500169},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550016},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Minimal neural network conditions for encoding future interactions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-assisted local attention in lower layers of visual
transformers. <em>IJNS</em>, <em>35</em>(4), 2550015. (<a
href="https://doi.org/10.1142/S0129065725500157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since vision transformers excel at establishing global relationships between features, they play an important role in current vision tasks. However, the global attention mechanism restricts the capture of local features, making convolutional assistance necessary. This paper indicates that transformer-based models can attend to local information without using convolutional blocks, similar to convolutional kernels, by employing a special initialization method. Therefore, this paper proposes a novel hybrid multi-scale model called Frequency-Assisted Local Attention Transformer (FALAT). FALAT introduces a Frequency-Assisted Window-based Positional Self-Attention (FWPSA) module that limits the attention distance of query tokens, enabling the capture of local contents in the early stage. The information from value tokens in the frequency domain enhances information diversity during self-attention computation. Additionally, the traditional convolutional method is replaced with a depth-wise separable convolution to downsample in the spatial reduction attention module for long-distance contents in the later stages. Experimental results demonstrate that FALAT-S achieves 83.0% accuracy on IN-1k with an input size of 2 2 4 × 2 2 4 using 29.9 M parameters and 5.6 G FLOPs. This model outperforms the Next-ViT-S by 0.9 AP b /0.8 AP m with Mask-R-CNN 1 × on COCO and surpasses the recent FastViT-SA36 by 3.1% mIoU with FPN on ADE20k.},
  archive      = {J_IJNS},
  author       = {Xin Zhou and Zeyu Jiang and Shihua Zhou and Zhaohui Ren and Yongchao Zhang and Tianzhuang Yu and Yulin Liu},
  doi          = {10.1142/S0129065725500157},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550015},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Frequency-assisted local attention in lower layers of visual transformers},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online and cross-user finger movement pattern recognition by
decoding neural drive information from surface electromyogram.
<em>IJNS</em>, <em>35</em>(4), 2550014. (<a
href="https://doi.org/10.1142/S0129065725500145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-user variability is a well-known challenge that leads to severe performance degradation and impacts the robustness of practical myoelectric control systems. To address this issue, a novel method for myoelectric recognition of finger movement patterns is proposed by incorporating a neural decoding approach with unsupervised domain adaption (UDA) learning. In our method, the neural decoding approach is implemented by extracting microscopic features characterizing individual motor unit (MU) activities obtained from a two-stage online surface electromyogram (SEMG) decomposition. A specific deep learning model is designed and initially trained using labeled data from a set of existing users. The model can update adaptively when recognizing the movement patterns of a new user. The final movement pattern was determined by a fuzzy weighted decision strategy. SEMG signals were collected from the finger extensor muscles of 15 subjects to detect seven dexterous finger-movement patterns. The proposed method achieved a movement pattern recognition accuracy of ( 9 3 . 9 4 ± 1 . 5 4 )% over seven movements under cross-user testing scenarios, much higher than that of the conventional methods using global SEMG features. Our study presents a novel robust myoelectric pattern recognition approach at a fine-grained MU level, with wide applications in neural interface and prosthesis control.},
  archive      = {J_IJNS},
  author       = {Haowen Zhao and Yunfei Liu and Xinhui Li and Xiang Chen and Xu Zhang},
  doi          = {10.1142/S0129065725500145},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550014},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Online and cross-user finger movement pattern recognition by decoding neural drive information from surface electromyogram},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Architecture knowledge distillation for evolutionary
generative adversarial network. <em>IJNS</em>, <em>35</em>(4), 2550013.
(<a href="https://doi.org/10.1142/S0129065725500133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are effective for image generation, but their unstable training limits broader applications. Additionally, neural architecture search (NAS) for GANs with one-shot models often leads to insufficient subnet training, where subnets inherit weights from a supernet without proper optimization, further degrading performance. To address both issues, we propose Architecture Knowledge Distillation for Evolutionary GAN (AKD-EGAN). AKD-EGAN operates in two stages. First, architecture knowledge distillation (AKD) is used during supernet training to efficiently optimize subnetworks and accelerate learning. Second, a multi-objective evolutionary algorithm (MOEA) searches for optimal subnet architectures, ensuring efficiency by considering multiple performance metrics. This approach, combined with a strategy for architecture inheritance, enhances GAN stability and image quality. Experiments show that AKD-EGAN surpasses state-of-the-art methods, achieving a Fréchet Inception Distance (FID) of 7.91 and an Inception Score (IS) of 8.97 on CIFAR-10, along with competitive results on STL-10 (FID: 20.32, IS: 10.06). Code and models will be available at https://github.com/njit-ly/AKD-EGAN .},
  archive      = {J_IJNS},
  author       = {Yu Xue and Yan Lin and Ferrante Neri},
  doi          = {10.1142/S0129065725500133},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550013},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Architecture knowledge distillation for evolutionary generative adversarial network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
