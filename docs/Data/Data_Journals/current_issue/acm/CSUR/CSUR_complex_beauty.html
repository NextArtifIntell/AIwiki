<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CSUR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="csur---27">CSUR - 27</h2>
<ul>
<li><details>
<summary>
(2025). Explaining the explainers in graph neural networks: A
comparative study. <em>CSUR</em>, <em>57</em>(5), 1–37. (<a
href="https://doi.org/10.1145/3696444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following a fast initial breakthrough in graph-based learning, Graph Neural Networks (GNNs) have reached a widespread application in many science and engineering fields, prompting the need for methods to understand their decision process. GNN explainers have started to emerge in recent years, with a multitude of methods both novel or adapted from other domains. To sort out this plethora of alternative approaches, several studies have benchmarked the performance of different explainers in terms of various explainability metrics. However, these earlier works make no attempts at providing insights into why different GNN architectures are more or less explainable or which explainer should be preferred in a given setting. In this survey we fill these gaps by devising a systematic experimental study, which tests 12 explainers on eight representative message-passing architectures trained on six carefully designed graph and node classification datasets. With our results we provide key insights on the choice and applicability of GNN explainers, we isolate key components that make them usable and successful and provide recommendations on how to avoid common interpretation pitfalls. We conclude by highlighting open questions and directions of possible future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3696444},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Explaining the explainers in graph neural networks: A comparative study},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trustworthy AI-based performance diagnosis systems for cloud
applications: A review. <em>CSUR</em>, <em>57</em>(5), 1–37. (<a
href="https://doi.org/10.1145/3701740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance diagnosis systems are defined as detecting abnormal performance phenomena and play a crucial role in cloud applications. An effective performance diagnosis system is often developed based on artificial intelligence (AI) approaches, which can be summarized into a general framework from data to models. However, the AI-based framework has potential hazards that could degrade the user experience and trust. For example, a lack of data privacy may compromise the security of AI models, and low robustness can be hard to apply in complex cloud environments. Therefore, defining the requirements for building a trustworthy AI-based performance diagnosis system has become essential. This article systematically reviews trustworthiness requirements in AI-based performance diagnosis systems. We first introduce trustworthiness requirements and extract six key requirements from a technical perspective, including data privacy, fairness, robustness, explainability, efficiency, and human intervention. We then unify these requirements into a general performance diagnosis framework, ranging from data collection to model development. Next, we comprehensively provide related works for each component and concrete actions to improve trustworthiness in the framework. Finally, we identify possible research directions and challenges for the future development of trustworthy AI-based performance diagnosis systems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3701740},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Trustworthy AI-based performance diagnosis systems for cloud applications: A review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IoT authentication protocols: Challenges, and comparative
analysis. <em>CSUR</em>, <em>57</em>(5), 1–43. (<a
href="https://doi.org/10.1145/3703444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the ever-evolving information technology landscape, the Internet of Things (IoT) is a groundbreaking concept that bridges the physical and digital worlds. It is the backbone of an increasingly sophisticated interactive environment, yet it is a subject of intricate security challenges spawned by its multifaceted manifestations. Central to securing IoT infrastructures is the crucial aspect of authentication, necessitating a comprehensive examination of its nuances, including benefits, challenges, opportunities, trends, and societal implications. In this article, we thoroughly review the IoT authentication protocols (Aps), addressing the main challenges such as privacy protection, scalability, and human factors that may impact security. Through exacting analysis, we evaluate the strengths and weaknesses of existing APs and conduct a comparative performance analysis to evaluate their effectiveness and scalability in securing IoT environments and devices. At the end of this study, we summarize the main findings and suggest ways to improve the security of IoT devices in the future.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703444},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-43},
  shortjournal = {ACM Comput. Surv.},
  title        = {IoT authentication protocols: Challenges, and comparative analysis},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The internet of bio-nano things with insulin-glucose,
security and research challenges: A survey. <em>CSUR</em>,
<em>57</em>(5), 1–42. (<a
href="https://doi.org/10.1145/3703448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Bio-Nano Things (IoBNT) is collaborative cell biology and nanodevice technology interacting through Molecular Communication (MC). The IoBNT can be accomplished by using the Information and Communication Theory (ICT) study of biological networks. Various technologies such as the Internet of Nano Things (IoNT), the Internet of Bio-degradable Things (IoBDT), and the Internet of Ingestible Things (IoIT) contribute to the development of IoBNT. Our survey discussed the Bio-Nano network and the role of IoT-based technologies along with a comparative study from various literature. We surveyed the various applications of IoNT in which the drug delivery for Insulin-Glucose system is prominent. Our survey aims to provide information about the Insulin-Glucose system involving the IoBNT and MC. We described the details of various factors for a diabetes analysis. We surveyed the diffusion coefficients of Insulin, Glucose, and the various parameters that influence insulin production in the body. Our survey identifies the security aspects of IoBNT such as attacks in nanonetworks, bio-cyber interface, Insulin-Glucose system, and their possible mitigation techniques. Our survey also provides a hierarchical model of the Bio-Nano network collaborating all the related technologies. Finally, our survey includes the research challenges involved in the proper handling of the IoBNT.},
  archive      = {J_CSUR},
  doi          = {10.1145/3703448},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {The internet of bio-nano things with insulin-glucose, security and research challenges: A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of AI-generated content (AIGC). <em>CSUR</em>,
<em>57</em>(5), 1–38. (<a
href="https://doi.org/10.1145/3704262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Artificial Intelligence Generated Content (AIGC) has gained significant attention from society, especially with the rise of Generative AI (GAI) techniques such as ChatGPT, GPT-4 [ 165 ], DALL-E-3 [ 184 ], and Sora [ 137 ]. AIGC involves using AI models to create digital content, such as images, music, and natural language, with the goal of making the content creation process more efficient and accessible. Large-scale models have become increasingly important in AIGC as they provide better intent extraction and generation results. This survey provides a comprehensive review of the history of generative models and recent advances in AIGC, focusing on both unimodal and multimodal interaction. From the perspective of unimodality, we introduce the generation tasks and relative models of text and image. From the perspective of multimodality, we introduce the cross-application between the modalities mentioned above. Finally, the survey discusses the existing open problems and future challenges in AIGC. Overall, this survey serves as a valuable resource for individuals interested in understanding the background and secrets behind the impressive performance of AIGC techniques.},
  archive      = {J_CSUR},
  doi          = {10.1145/3704262},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of AI-generated content (AIGC)},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent advances of foundation language models-based
continual learning: A survey. <em>CSUR</em>, <em>57</em>(5), 1–38. (<a
href="https://doi.org/10.1145/3705725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, foundation language models (LMs) have marked significant achievements in the domains of natural language processing and computer vision. Unlike traditional neural network models, foundation LMs obtain a great ability for transfer learning by acquiring rich common sense knowledge through pre-training on extensive unsupervised datasets with a vast number of parameters. Despite these capabilities, LMs still struggle with catastrophic forgetting, hindering their ability to learn continuously like humans. To address this, continual learning (CL) methodologies have been introduced, allowing LMs to adapt to new tasks while retaining learned knowledge. However, a systematic taxonomy of existing approaches and a comparison of their performance are still lacking. In this article, we delve into a comprehensive review, summarization, and classification of the existing literature on CL-based approaches applied to foundation language models, such as pre-trained language models, large language models, and vision-language models. We divide these studies into offline and online CL, which consist of traditional methods, parameter-efficient-based methods, instruction tuning-based methods and continual pre-training methods. Additionally, we outline the typical datasets and metrics employed in CL research and provide a detailed analysis of the challenges and future work for LMs-based continual learning.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705725},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Recent advances of foundation language models-based continual learning: A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wi-fi sensing techniques for human activity recognition:
Brief survey, potential challenges, and research directions.
<em>CSUR</em>, <em>57</em>(5), 1–30. (<a
href="https://doi.org/10.1145/3705893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in wireless communication technologies have made Wi-Fi signals indispensable in both personal and professional settings. The utilization of these signals for Human Activity Recognition (HAR) has emerged as a cutting-edge technology. By leveraging the fluctuations in Wi-Fi signals for HAR, this approach offers enhanced privacy compared to traditional visual surveillance methods. The essence of this technique lies in detecting subtle changes when Wi-Fi signals interact with the human body, which are then captured and interpreted by advanced algorithms. This article initially provides an overview of the key methodologies in HAR and the evolution of non-contact sensing, introducing sensor-based recognition, computer vision, and Wi-Fi signal based approaches, respectively. It then explores tools for Wi-Fi-based HAR signal collection and lists several high-quality datasets. Subsequently, the article reviews various sensing tasks enabled by Wi-Fi signal recognition, highlighting the application of deep learning networks in Wi-Fi signal detection. Experimental results are then presented that assess the capabilities of different networks. The findings indicate significant variability in the generalization capacities of neural networks and notable differences in test accuracy for various motion analyses.},
  archive      = {J_CSUR},
  doi          = {10.1145/3705893},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-30},
  shortjournal = {ACM Comput. Surv.},
  title        = {Wi-fi sensing techniques for human activity recognition: Brief survey, potential challenges, and research directions},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource-efficient algorithms and systems of foundation
models: A survey. <em>CSUR</em>, <em>57</em>(5), 1–39. (<a
href="https://doi.org/10.1145/3706418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large foundation models, including large language models, vision transformers, diffusion, and large language model based multimodal models, are revolutionizing the entire machine learning lifecycle, from training to deployment. However, the substantial advancements in versatility and performance these models offer come at a significant cost in terms of hardware resources. To support the growth of these large models in a scalable and environmentally sustainable way, there has been a considerable focus on developing resource-efficient strategies. This survey delves into the critical importance of such research, examining both algorithmic and systemic aspects. It offers a comprehensive analysis and valuable insights gleaned from existing literature, encompassing a broad array of topics from cutting-edge model architectures and training/serving algorithms to practical system designs and implementations. The goal of this survey is to provide an overarching understanding of how current approaches are tackling the resource challenges posed by large foundation models and to potentially inspire future breakthroughs in this field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706418},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-39},
  shortjournal = {ACM Comput. Surv.},
  title        = {Resource-efficient algorithms and systems of foundation models: A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial binaries: AI-guided instrumentation methods for
malware detection evasion. <em>CSUR</em>, <em>57</em>(5), 1–36. (<a
href="https://doi.org/10.1145/3706573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial binaries are executable files that have been altered without loss of function by an AI agent in order to deceive malware detection systems. Progress in this emergent vein of research has been constrained by the complex and rigid structure of executable files. Although prior work has demonstrated that these binaries deceive a variety of malware classification models which rely on disparate feature sets, a consensus as to the best approach has not been reached, either in terms of the optimization algorithms or the instrumentation methods. Although inconsistencies in the data sets, target classifiers, and functionality verification methods make head-to-head comparisons difficult, we extract lessons learned and make recommendations for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706573},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adversarial binaries: AI-guided instrumentation methods for malware detection evasion},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic literature review of enterprise architecture
evaluation methods. <em>CSUR</em>, <em>57</em>(5), 1–36. (<a
href="https://doi.org/10.1145/3706582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enterprise Architecture (EA) is a systematic and holistic approach to designing and managing an organization&#39;s information systems components, aiding in optimizing resources, managing risk, and facilitating change. It weighs different architectural quality attributes against each other to achieve the most advantageous architecture. However, the evaluation of EA lacks a systematic approach. This study employs a Systematic Literature Review, analyzing, in detail, 109 articles carefully selected from 3644 papers published since 2005. The key outcome of the research reveals that a crucial factor for the extensive worldwide adoption of EA evaluation methods lies in the automation of the assessment and architecture modeling processes, particularly emphasizing the facet of data collection. The automation of EA evaluation will empower organizations to streamline their processes, make data-driven decisions, and respond more effectively to change, ultimately contributing to their competitiveness and long-term success in the global market. The study identifies diverse evaluation methods, determines evaluation criteria, examines the extent to which these methods have been verified in practice, and provides directions for further research and advancement.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706582},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {A systematic literature review of enterprise architecture evaluation methods},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on privacy-preserving caching at network edge:
Classification, solutions, and challenges. <em>CSUR</em>,
<em>57</em>(5), 1–38. (<a
href="https://doi.org/10.1145/3706630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Caching content at the edge network is a popular and effective technique widely deployed to alleviate the burden of network backhaul, shorten service delay, and improve service quality. However, there has been some controversy over privacy violations in caching content at the edge network. On the one hand, the multi-access open edge network provides an ideal entrance or interface for external attackers to obtain private data from edge caches by extracting sensitive information. On the other hand, privacy can be infringed on by curious edge caching providers through caching trace analysis targeting the achievement of better caching performance or higher profits. Therefore, an in-depth understanding of privacy issues in edge caching networks is vital and indispensable for creating a privacy-preserving caching service at the edge network. In this article, we are among the first to fill this gap by examining privacy-preserving techniques for caching content at the edge network. First, we provide an introduction to the background of privacy-preserving edge caching. Next, we summarize the key privacy issues and present a taxonomy for caching at the edge network from the perspective of private information. Additionally, we conduct a retrospective review of the state-of-the-art countermeasures against privacy leakage from content caching at the edge network. Finally, we conclude the survey and envision challenges for future research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3706630},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey on privacy-preserving caching at network edge: Classification, solutions, and challenges},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weakly-supervised semantic segmentation with image-level
labels: From traditional models to foundation models. <em>CSUR</em>,
<em>57</em>(5), 1–29. (<a
href="https://doi.org/10.1145/3707447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of deep learning has driven significant progress in image semantic segmentation—a fundamental task in computer vision. Semantic segmentation algorithms often depend on the availability of pixel-level labels (i.e., masks of objects), which are expensive, time consuming, and labor intensive. Weakly supervised semantic segmentation (WSSS) is an effective solution to avoid such labeling. It utilizes only partial or incomplete annotations and provides a cost-effective alternative to fully supervised semantic segmentation. In this article, our focus is on the WSSS with image-level labels, which is the most challenging form of WSSS. Our work has two parts. First, we conduct a comprehensive survey on traditional methods, primarily focusing on those presented at premier research conferences. We categorize them into four groups based on where their methods operate: pixel-wise, image-wise, cross-image, and external data. Second, we investigate the applicability of visual foundation models, such as the Segment Anything Model (SAM), in the context of WSSS. We scrutinize SAM in two intriguing scenarios: text prompting and zero-shot learning. We provide insights into the potential and challenges of deploying visual foundational models for WSSS, facilitating future developments in this exciting research area. Our code is provided at this link: https://github.com/zhaozhengChen/SAM_WSSS .},
  archive      = {J_CSUR},
  doi          = {10.1145/3707447},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-29},
  shortjournal = {ACM Comput. Surv.},
  title        = {Weakly-supervised semantic segmentation with image-level labels: From traditional models to foundation models},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial machine learning attacks and defences in
multi-agent reinforcement learning. <em>CSUR</em>, <em>57</em>(5), 1–35.
(<a href="https://doi.org/10.1145/3708320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Reinforcement Learning (MARL) is susceptible to Adversarial Machine Learning (AML) attacks. Execution-time AML attacks against MARL are complex due to effects that propagate across time and between agents. To understand the interaction between AML and MARL, this survey covers attacks and defences for MARL, Multi-Agent Learning (MAL), and Deep Reinforcement Learning (DRL). This survey proposes a novel perspective on AML attacks based on attack vectors. This survey also proposes a framework that addresses gaps in current modelling frameworks and enables the comparison of different attacks against MARL. Lastly, the survey identifies knowledge gaps and future avenues of research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708320},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Adversarial machine learning attacks and defences in multi-agent reinforcement learning},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed machine learning in edge computing: Challenges,
solutions and future directions. <em>CSUR</em>, <em>57</em>(5), 1–37.
(<a href="https://doi.org/10.1145/3708495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed machine learning on edges is widely used in intelligent transportation, smart home, industrial manufacturing, and underground pipe network monitoring to achieve low latency and real time data processing and prediction. However, the presence of a large number of sensing and edge devices with limited computing, storage, and communication capabilities prevents the deployment of huge machine learning models and hinders its application. At the same time, although distributed machine learning on edges forms an emerging and rapidly growing research area, there has not been a systematic survey on this topic. The article begins by detailing the challenges of distributed machine learning in edge environments, such as limited node resources, data heterogeneity, privacy, security issues, and summarizes common metrics for model optimization. We then present a detailed analysis of parallelism patterns, distributed architectures, and model communication and aggregation schemes in edge computing. we subsequently present a comprehensive classification and intensive description of node resource-constrained processing, heterogeneous data processing, attacks and protection of privacy. The article ends by summarizing the applications of distributed machine learning in edge computing and presenting problems and challenges for further research.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708495},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {Distributed machine learning in edge computing: Challenges, solutions and future directions},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on physical layer authentication
techniques: Categorization and analysis of model-driven and data-driven
approaches. <em>CSUR</em>, <em>57</em>(5), 1–35. (<a
href="https://doi.org/10.1145/3708496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The open and broadcast nature of wireless mediums introduces significant security vulnerabilities, making authentication a critical concern in wireless networks. In recent years, Physical-Layer Authentication (PLA) techniques have garnered considerable research interest due to their advantages over Upper-Layer Authentication (ULA) methods, such as lower complexity, enhanced security, and greater compatibility. The application of signal processing techniques in PLA serves as a crucial link between the extraction of Physical-Layer Features (PLFs) and the authentication of received signals. Different signal processing approaches, even with the same PLF, can result in varying authentication performances and computational demands. Despite this, there remains a shortage of comprehensive overviews on state-of-the-art PLA schemes with a focus on signal processing approaches. This article presents the first thorough survey of signal processing in various PLA schemes, categorizing existing approaches into model-based and Machine Learning (ML)-based schemes. We discuss motivation and address key issues in signal processing for PLA schemes. The applications, challenges, and future research directions of PLA are discussed in Part 3 of the Appendix, which can be found in supplementary materials online.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708496},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {A comprehensive survey on physical layer authentication techniques: Categorization and analysis of model-driven and data-driven approaches},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards trustworthy machine learning in production: An
overview of the robustness in MLOps approach. <em>CSUR</em>,
<em>57</em>(5), 1–35. (<a
href="https://doi.org/10.1145/3708497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI), and especially its sub-field of Machine Learning (ML), are impacting the daily lives of everyone with their ubiquitous applications. In recent years, AI researchers and practitioners have introduced principles and guidelines to build systems that make reliable and trustworthy decisions. From a practical perspective, conventional ML systems process historical data to extract the features that are consequently used to train ML models that perform the desired task. However, in practice, a fundamental challenge arises when the system needs to be operationalized and deployed to evolve and operate in real-life environments continuously. To address this challenge, Machine Learning Operations (MLOps) have emerged as a potential recipe for standardizing ML solutions in deployment. Although MLOps demonstrated great success in streamlining ML processes, thoroughly defining the specifications of robust MLOps approaches remains of great interest to researchers and practitioners. In this paper, we provide a comprehensive overview of the trustworthiness property of MLOps systems. Specifically, we highlight technical practices to achieve robust MLOps systems. In addition, we survey the existing research approaches that address the robustness aspects of ML systems in production. We also review the tools and software available to build MLOps systems and summarize their support to handle the robustness aspects. Finally, we present the open challenges and propose possible future directions and opportunities within this emerging field. The aim of this paper is to provide researchers and practitioners working on practical AI applications with a comprehensive view to adopt robust ML solutions in production environments.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708497},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Towards trustworthy machine learning in production: An overview of the robustness in MLOps approach},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of geometric optimization for deep learning: From
euclidean space to riemannian manifold. <em>CSUR</em>, <em>57</em>(5),
1–37. (<a href="https://doi.org/10.1145/3708498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has achieved remarkable success in tackling complex Artificial Intelligence tasks. The standard training of neural networks employs backpropagation to compute gradients and utilizes various optimization algorithms in the Euclidean space ℛ n . However, this optimization process faces challenges, such as the local optimal issues and the problem of gradient vanishing and exploding. To address these problems, Riemannian optimization offers a powerful extension to solve optimization problems in deep learning. By incorporating the prior constraint structure and the metric information of the underlying geometric information, Riemannian optimization-based DL offers a more stable and reliable optimization process, as well as enhanced adaptability to complex data structures. This article presents a comprehensive survey of applying geometric optimization in DL, including the basic procedure of geometric optimization, various geometric optimizers, and some concepts of the Riemannian manifold. In addition, it investigates various applications of geometric optimization in different DL networks for diverse tasks and discusses typical public toolboxes that implement optimization on the manifold. This article also includes a performance comparison among different deep geometric optimization methods in image recognition scenarios. Finally, this article elaborates on future opportunities and challenges in this field.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708498},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-37},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of geometric optimization for deep learning: From euclidean space to riemannian manifold},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent generation of graphical game assets: A
conceptual framework and systematic review of the state of the art.
<em>CSUR</em>, <em>57</em>(5), 1–38. (<a
href="https://doi.org/10.1145/3708499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Procedural content generation (PCG) can be applied to a wide variety of tasks in games, from narratives, levels, and sounds to trees and weapons. A large amount of game content is composed of graphical assets , such as clouds, buildings, or vegetation, that do not require gameplay function considerations. There is also a breadth of literature examining the procedural generation of such elements for purposes outside of games. The body of research, focused on specific methods for generating specific assets, provides a narrow view of the available possibilities. Hence, it is difficult to have a clear picture of all approaches and possibilities, with no guide for interested parties to discover possible methods and approaches for their needs and no facility to guide them through each technique or approach to map out the process of using them. Therefore, a systematic literature review has been conducted, yielding 239 accepted papers. This article explores state-of-the-art approaches to graphical asset generation, examining research from a wide range of applications, inside and outside of games. Informed by the literature, a conceptual framework has been derived to address the aforementioned gaps.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708499},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Intelligent generation of graphical game assets: A conceptual framework and systematic review of the state of the art},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterization of android malwares and their families.
<em>CSUR</em>, <em>57</em>(5), 1–31. (<a
href="https://doi.org/10.1145/3708500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, smartphones have made our lives easier and have become essential gadgets for us. Apart from calling, mobiles are used for various purposes, such as banking, chatting, data storage, connecting to the internet, and running apps, that make life easier. Therefore, attackers are developing new methods or malware to steal smartphone data. Primarily, the study outlines various types of Android malware families, the evolution of Android malware and its effects on detection techniques over time. We report malware timelines and Android app datasets with their source web links. Data are collected from various recent studies and reported. In this study, we have reported 384 Android malware families and their year of discovery, i.e., from 2001 to 2020. According to the malfunctions they perform on the device, we categorized the families into 11 types. Information about datasets is divided into three categories, along with their source links, and is presented. The categorization and timeline of malware will make it easy for researchers to focus on upcoming trends according to the malware category and activities they perform. Various open issues and future challenges are also addressed for future researchers.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708500},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-31},
  shortjournal = {ACM Comput. Surv.},
  title        = {Characterization of android malwares and their families},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual content privacy protection: A survey. <em>CSUR</em>,
<em>57</em>(5), 1–36. (<a
href="https://doi.org/10.1145/3708501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision is the most important sense for people, and it is also one of the main ways of cognition. As a result, people tend to utilize visual content to capture and share their life experiences, which greatly facilitates the transfer of information. Meanwhile, it also increases the risk of privacy violations, e.g., an image or video can reveal different kinds of privacy-sensitive information. Scholars have persistently pursued the advancement of tailored privacy protection measures. Various surveys attempt to consolidate these efforts from specific viewpoints. Nevertheless, these surveys tend to focus on particular issues, scenarios, or technologies, hindering a comprehensive overview of existing solutions on a broader scale. In this survey, a framework that encompasses various concerns and solutions for visual privacy is proposed, which allows for a macro understanding of privacy concerns from a comprehensive level. It is based on the fact that privacy concerns have corresponding adversaries, and divides privacy protection into three categories, based on computer vision (CV) adversary, based on human vision (HV) adversary, and based on CV &amp; HV adversary. For each category, we analyze the characteristics of the main approaches to privacy protection, and then systematically review representative solutions. Open challenges and future directions for visual privacy protection are also discussed.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708501},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Visual content privacy protection: A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ISP meets deep learning: A survey on deep learning methods
for image signal processing. <em>CSUR</em>, <em>57</em>(5), 1–44. (<a
href="https://doi.org/10.1145/3708516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The entire Image Signal Processor (ISP) of a camera relies on several processes to transform the data from the Color Filter Array (CFA) sensor, such as demosaicing, denoising, and enhancement. These processes can be executed either by some hardware or via software. In recent years, Deep Learning (DL) has emerged as one solution for some of them or even to replace the entire ISP using a single neural network for the task. In this work, we investigated several recent pieces of research in this area and provide deeper analysis and comparison among them, including results and possible points of improvement for future researchers.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708516},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-44},
  shortjournal = {ACM Comput. Surv.},
  title        = {ISP meets deep learning: A survey on deep learning methods for image signal processing},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserved and responsible recommenders: From
conventional defense to federated learning and blockchain.
<em>CSUR</em>, <em>57</em>(5), 1–35. (<a
href="https://doi.org/10.1145/3708982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RS) play an integral role in many online platforms. Exponential growth and potential commercial interests are raising significant concerns around privacy, security, fairness, and overall responsibility. The existing literature around responsible recommendation services is diverse and multidisciplinary. Most literature reviews cover a specific aspect or a single technology for responsible behavior, such as federated learning or blockchain. This study integrates relevant concepts across disciplines to provide a broader representation of the landscape. We review the latest advancements toward building privacy-preserved and responsible recommendation services for the e-commerce industry. The survey summarizes recent, high-impact works on diverse aspects and technologies that ensure responsible behavior in RS through an interconnected taxonomy. We contextualize potential privacy threats, practical significance, industrial expectations, and research remedies. From the technical viewpoint, we analyze conventional privacy defenses and provide an overview of emerging technologies including differential privacy, federated learning, and blockchain. The methods and concepts across technologies are linked based on their objectives, challenges, and future directions. In addition, we also develop an open source repository that summarizes a wide range of evaluation benchmarks, codebases, and toolkits to aid the further research. The survey offers a holistic perspective on this rapidly evolving landscape by synthesizing insights from both RS and responsible AI literature.},
  archive      = {J_CSUR},
  doi          = {10.1145/3708982},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-35},
  shortjournal = {ACM Comput. Surv.},
  title        = {Privacy-preserved and responsible recommenders: From conventional defense to federated learning and blockchain},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An in-depth analysis of password managers and two-factor
authentication tools. <em>CSUR</em>, <em>57</em>(5), 1–32. (<a
href="https://doi.org/10.1145/3711117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Passwords remain the primary authentication method in online services, a domain increasingly crucial in our digital age. However, passwords suffer from several well-documented security and usability issues. Addressing these concerns, password managers and two-factor authentication (2FA) have emerged as key solutions. This article examines these methods with a focus on enhancing password security without compromising usability. We utilize an adapted Bonneau et al. (IEEE S&amp;P 2012) framework tailored to the specific challenges of password managers and 2FA. This allows us to categorize and evaluate prominent solutions from both academic research and industry practice, with a focus on their security, privacy, and usability. A crucial aspect of our study involves evaluating the effectiveness of a combined PM+2FA system in balancing security and usability. This study not only examines current trends but also suggests potential areas for future research, offering valuable insights to both users and developers in the evolving landscape of digital security.},
  archive      = {J_CSUR},
  doi          = {10.1145/3711117},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-32},
  shortjournal = {ACM Comput. Surv.},
  title        = {An in-depth analysis of password managers and two-factor authentication tools},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-centric artificial intelligence: A survey.
<em>CSUR</em>, <em>57</em>(5), 1–42. (<a
href="https://doi.org/10.1145/3711118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI . The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages of the data lifecycle. We hope it can help the readers efficiently grasp a broad picture of this field, and equip them with the techniques and further research ideas to systematically engineer data for building AI systems. A companion list of data-centric AI resources will be regularly updated on https://github.com/daochenzha/data-centric-AI .},
  archive      = {J_CSUR},
  doi          = {10.1145/3711118},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-42},
  shortjournal = {ACM Comput. Surv.},
  title        = {Data-centric artificial intelligence: A survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of heuristics for profile and wavefront reductions.
<em>CSUR</em>, <em>57</em>(5), 1–16. (<a
href="https://doi.org/10.1145/3711120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article surveys heuristic methods for profile and wavefront reductions. These graph layout problems represent a challenge for optimization methods and heuristics especially. The article presents the graph layout problems with their formal definition. It provides an ample perspective of techniques for designing heuristic methods for these graph layout problems but concentrates on the approaches and methodologies that yield high-quality solutions. Thus, this work references the most relevant studies in the associated literature and discusses the current state-of-the-art heuristics for these graph layout problems.},
  archive      = {J_CSUR},
  doi          = {10.1145/3711120},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-16},
  shortjournal = {ACM Comput. Surv.},
  title        = {A survey of heuristics for profile and wavefront reductions},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Can graph neural networks be adequately explained? A survey.
<em>CSUR</em>, <em>57</em>(5), 1–36. (<a
href="https://doi.org/10.1145/3711122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the barrier caused by the black-box nature of Deep Learning (DL) for practical deployment, eXplainable Artificial Intelligence (XAI) has emerged and is developing rapidly. While significant progress has been made in explanation techniques for DL models targeted to images and texts, research on explaining DL models for graph data is still in its infancy. As Graph Neural Networks (GNNs) have shown superiority over various network analysis tasks, their explainability has also gained attention from both academia and industry. However, despite the increasing number of GNN explanation methods, there is currently neither a fine-grained taxonomy of them, nor a holistic set of evaluation criteria for quantitative and qualitative evaluation. To fill this gap, we conduct a comprehensive survey on existing explanation methods of GNNs in this article. Specifically, we propose a novel four-dimensional taxonomy of GNN explanation methods and summarize evaluation criteria in terms of correctness, robustness, usability, understandability, and computational complexity. Based on the taxonomy and criteria, we thoroughly review the recent advances in GNN explanation methods and analyze their pros and cons. In the end, we identify a series of open issues and put forward future research directions to facilitate XAI research in the field of GNNs.},
  archive      = {J_CSUR},
  doi          = {10.1145/3711122},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-36},
  shortjournal = {ACM Comput. Surv.},
  title        = {Can graph neural networks be adequately explained? a survey},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regulating information and network security: Review and
challenges. <em>CSUR</em>, <em>57</em>(5), 1–38. (<a
href="https://doi.org/10.1145/3711124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid expansion of internet activities in daily life has elevated cyberattacks to a significant global threat. As a result, protecting the networks and systems of industries, organizations, and individuals against cybercrimes has become an increasingly critical challenge. This monograph provides a comprehensive review and analysis of national, international, and industry regulations on cybercrimes. It presents empirical evidence of the effectiveness of these regulatory measures and their impacts at the national, organizational, and individual levels. We also examine the challenges posed by emerging technologies to these regulations. Finally, the monograph identifies limitations in the current regulatory framework and proposes future directions to enhance the cybersecurity ecosystem.},
  archive      = {J_CSUR},
  doi          = {10.1145/3711124},
  journal      = {ACM Computing Surveys},
  month        = {1},
  number       = {5},
  pages        = {1-38},
  shortjournal = {ACM Comput. Surv.},
  title        = {Regulating information and network security: Review and challenges},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
