<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TIST_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tist---6">TIST - 6</h2>
<ul>
<li><details>
<summary>
(2025). Fairness and diversity in recommender systems: A survey.
<em>TIST</em>, <em>16</em>(1), 1–28. (<a
href="https://doi.org/10.1145/3664928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RS) are effective tools for mitigating information overload and have seen extensive applications across various domains. However, the single focus on utility goals proves to be inadequate in addressing real-world concerns, leading to increasing attention to fairness-aware and diversity-aware RS. While most existing studies explore fairness and diversity independently, we identify strong connections between these two domains. In this survey, we first discuss each of them individually and then dive into their connections. Additionally, motivated by the concepts of user-level and item-level fairness, we broaden the understanding of diversity to encompass not only the item level but also the user level. With this expanded perspective on user and item-level diversity, we re-interpret fairness studies from the viewpoint of diversity. This fresh perspective enhances our understanding of fairness-related work and paves the way for potential future research directions. Articles discussed in this survey along with public code links are available at: https://github.com/YuyingZhao/Awesome-Fairness-and-Diversity-Papers-in-Recommender-Systems},
  archive      = {J_TIST},
  doi          = {10.1145/3664928},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {1},
  pages        = {1-28},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Fairness and diversity in recommender systems: A survey},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Misinformation resilient search rankings with webgraph-based
interventions. <em>TIST</em>, <em>16</em>(1), 1–27. (<a
href="https://doi.org/10.1145/3670410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of unreliable news domains on the internet has had wide-reaching negative impacts on society. We introduce and evaluate interventions aimed at reducing traffic to unreliable news domains from search engines while maintaining traffic to reliable domains. We build these interventions on the principles of fairness (penalize sites for what is in their control), generality (label/fact-check agnostic), targeted (increase the cost of adversarial behavior), and scalability (works at webscale). We refine our methods on small-scale webdata as a testbed and then generalize the interventions to a large-scale webgraph containing 93.9M domains and 1.6B edges. We demonstrate that our methods penalize unreliable domains far more than reliable domains in both settings and we explore multiple avenues to mitigate unintended effects on both the small-scale and large-scale webgraph experiments. These results indicate the potential of our approach to reduce the spread of misinformation and foster a more reliable online information ecosystem. This research contributes to the development of targeted strategies to enhance the trustworthiness and quality of search engine results, ultimately benefiting users, and the broader digital community.},
  archive      = {J_TIST},
  doi          = {10.1145/3670410},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {1},
  pages        = {1-27},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Misinformation resilient search rankings with webgraph-based interventions},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recommender system-induced eating disorder relapse: Harmful
content and the challenges of responsible recommendation. <em>TIST</em>,
<em>16</em>(1), 1–13. (<a
href="https://doi.org/10.1145/3675404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As users’ social media feeds have become increasingly driven by algorithmically recommended content, there is a need to understand the impact these recommendations have on users. People in recovery from eating disorders (ED) may try to avoid content that features severely underweight bodies or that encourages disordered eating. However, if recommender systems show them this type of content anyway, it may impact their recovery or even lead to relapse. In this study, we take a two-pronged approach to understanding the intersection of recommender systems, ED content, and users in recovery. We performed a content analysis of tweets about recommended ED content and conducted a small-scale study on Pinterest to show that ED content is recommended in response to interaction with posts about ED recovery. We discuss the implications for responsible recommendation and harm prevention.},
  archive      = {J_TIST},
  doi          = {10.1145/3675404},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {1},
  pages        = {1-13},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Recommender system-induced eating disorder relapse: Harmful content and the challenges of responsible recommendation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AVENUE: A novel deepfake detection method based on temporal
convolutional network and rPPG information. <em>TIST</em>,
<em>16</em>(1), 1–16. (<a
href="https://doi.org/10.1145/3702232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Deep Learning (DL), an adversary creates Deepfakes by manipulating facial features to fool someone. The Deepfakes pose a security threat to anyone’s privacy and a primary concern for our society. It can be detected by utilizing the texture and physiological properties of the face, like eye and lip movements; however, such methods are incompetent when Deepfakes are created using recent Generative Adversarial Networks (GAN). Alternatively, Remote Photoplethysmography (rPPG) information can be used for Deepfake detection because GANs neglect human physiological information for Deepfake generation. Such detection can be inaccurate when rPPG signals are affected by the noises induced by facial deformation and illumination variations. Furthermore, the exiting Deepfake detections are usually performed using sequential models, and such models fail to process the long sequence of temporal information. These issues are mitigated by our proposed method AVENUE , that is, \(A\) no \(V\) el d \(E\) epfake detectio \(N\) method based on temporal convol \(U\) tion n \(E\) twork and rPPG information. For mitigating the noise issues in the rPPG signals, the proposed method detects and employs relatively stable clips of the input video for Deepfake detection. The stable clips are those clips that are least affected by facial deformations. Also, we use a modified Temporal convolutional network to model the long sequence of Deepfake information rather than the sequential architectures. We performed the experimental result on publicly available datasets of Deepfake videos. It demonstrates that our proposed method performs better than the existing rPPG-based Deepfake detection methods.},
  archive      = {J_TIST},
  doi          = {10.1145/3702232},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {AVENUE: A novel deepfake detection method based on temporal convolutional network and rPPG information},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BeGin: Extensive benchmark scenarios and an easy-to-use
framework for graph continual learning. <em>TIST</em>, <em>16</em>(1),
1–22. (<a href="https://doi.org/10.1145/3702648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Learning (CL) is the process of learning ceaselessly a sequence of tasks. Most existing CL methods deal with independent data (e.g., images and text) for which many benchmark frameworks and results under standard experimental settings are available. Compared to them, however, CL methods for graph data (graph CL) are relatively underexplored because of (a) the lack of standard experimental settings, especially regarding how to deal with the dependency between instances, (b) the lack of benchmark datasets and scenarios, and (c) high complexity in implementation and evaluation due to the dependency. In this paper, regarding (a) we define four standard incremental settings (task-, class-, domain-, and time-incremental) for node-, link-, and graph-level problems, extending the previously explored scope. Regarding (b), we provide 35 benchmark scenarios based on 24 real-world graphs. Regarding (c), we develop BeGin , an easy and fool-proof framework for graph CL. BeGin is easily extended since it is modularized with reusable modules for data processing, algorithm design, and evaluation. Especially, the evaluation module is completely separated from user code to eliminate potential mistakes. Regarding benchmark results, we cover \(3\times\) more combinations of incremental settings and levels of problems than the latest benchmark. All assets for the benchmark framework are publicly available at https://github.com/ShinhwanKang/BeGin .},
  archive      = {J_TIST},
  doi          = {10.1145/3702648},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {1},
  pages        = {1-22},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {BeGin: Extensive benchmark scenarios and an easy-to-use framework for graph continual learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain HAR: Few-shot transfer learning for human
activity recognition. <em>TIST</em>, <em>16</em>(1), 1–35. (<a
href="https://doi.org/10.1145/3704921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquitous availability of smartphones and smartwatches with integrated inertial measurement units (IMUs) enables straightforward capturing of human activities through collecting movement data. For specific applications of sensor-based human activity recognition (HAR), however, logistical challenges and burgeoning costs render especially the ground-truth annotation of such data a difficult endeavor, resulting in limited scale and diversity of datasets available for deriving effective HAR systems and less than ideal recognition capabilities. Transfer learning, i.e., leveraging publicly available labeled datasets to first learn useful representations that can then be fine-tuned using limited amounts of labeled data from a target domain, can alleviate some of the performance issues of contemporary HAR systems. Yet they can fail when the differences between source and target conditions are too large and/or only few samples from a target application domain are available—each of which are typical challenges in real-world human activity recognition scenarios. In this article, we present an approach for economic use of publicly available labeled HAR datasets for effective transfer learning. We introduce a novel transfer learning framework—Cross-Domain HAR—which follows the teacher-student self-training paradigm to more effectively recognize activities with very limited label information. It bridges conceptual gaps between source and target domains, including sensor locations and type of activities. Cross-Domain HAR enables substantial performance improvements over the state-of-the-art in sensor-based HAR scenarios. Through our extensive experimental evaluation on a range of benchmark datasets we specifically demonstrate the effectiveness of our approach for practically relevant few-shot activity recognition scenarios. We also present a detailed analysis into how the individual components of our framework affect downstream performance and provide practical suggestions for using the framework in real-world applications.},
  archive      = {J_TIST},
  doi          = {10.1145/3704921},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {2},
  number       = {1},
  pages        = {1-35},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Cross-domain HAR: Few-shot transfer learning for human activity recognition},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
