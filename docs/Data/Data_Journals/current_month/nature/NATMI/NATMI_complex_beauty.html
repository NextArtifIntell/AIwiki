<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NATMI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="natmi---18">NATMI - 18</h2>
<ul>
<li><details>
<summary>
(2025). Benchmarking AI-powered docking methods from the perspective
of virtual screening. <em>NATMI</em>, <em>7</em>(3), 509–520. (<a
href="https://doi.org/10.1038/s42256-025-00993-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many artificial intelligence (AI)-powered protein–ligand docking and scoring methods have been developed, demonstrating impressive speed and accuracy. However, these methods often neglected the physical plausibility of the docked complexes and their efficacy in virtual screening (VS) projects. Therefore, we conducted a comprehensive benchmark analysis of four AI-powered and four physics-based docking tools and two AI-enhanced rescoring methods. We initially constructed the TrueDecoy set, a dataset on which the redocking experiments revealed that KarmaDock and CarsiDock surpassed all physics-based tools in docking accuracy, whereas all physics-based tools notably outperformed AI-based methods in structural rationality. The low physical plausibility of docked structures generated by the top AI method, CarsiDock, mainly stems from insufficient intermolecular validity. The VS results on the TrueDecoy set highlight the effectiveness of RTMScore as a rescore function, and Glide-based methods achieved the highest enrichment factors among all docking tools. Furthermore, we created the RandomDecoy set, a dataset that more closely resembles real-world VS scenarios, where AI-based tools obviously outperformed Glide. Additionally, we found that the employed ligand-based postprocessing methods had a weak or even negative impact on optimizing the conformations of docked complexes and enhancing VS performance. Finally, we proposed a hierarchical VS strategy that could efficiently and accurately enrich active molecules in large-scale VS projects. Artificial intelligence (AI)-based docking and scoring methods demonstrate considerable potential for virtual drug screening. Gu et al. go further by assessing the structural rationality of AI-predicted complex conformations from various sources.},
  archive      = {J_NATMI},
  author       = {Gu, Shukai and Shen, Chao and Zhang, Xujun and Sun, Huiyong and Cai, Heng and Luo, Hao and Zhao, Huifeng and Liu, Bo and Du, Hongyan and Zhao, Yihao and Fu, Chenggong and Zhai, Silong and Deng, Yafeng and Liu, Huanxiang and Hou, Tingjun and Kang, Yu},
  doi          = {10.1038/s42256-025-00993-0},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {509-520},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Benchmarking AI-powered docking methods from the perspective of virtual screening},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards a more inductive world for drug repurposing
approaches. <em>NATMI</em>, <em>7</em>(3), 495–508. (<a
href="https://doi.org/10.1038/s42256-025-00987-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug–target interaction (DTI) prediction is a challenging albeit essential task in drug repurposing. Learning on graph models has drawn special attention as they can substantially reduce drug repurposing costs and time commitment. However, many current approaches require high-demand additional information besides DTIs that complicates their evaluation process and usability. Additionally, structural differences in the learning architecture of current models hinder their fair benchmarking. In this work, we first perform an in-depth evaluation of current DTI datasets and prediction models through a robust benchmarking process and show that DTI methods based on transductive models lack generalization and lead to inflated performance when traditionally evaluated, making them unsuitable for drug repurposing. We then propose a biologically driven strategy for negative-edge subsampling and uncovered previously unknown interactions via in vitro validation, missed by traditional subsampling. Finally, we provide a toolbox from all generated resources, crucial for fair benchmarking and robust model design. The authors address the challenge of predicting drug–target interactions, which is crucial for drug repurposing, by introducing a robust benchmarking framework. Using a biologically driven strategy, they uncover previously unknown interactions.},
  archive      = {J_NATMI},
  author       = {de la Fuente, Jesus and Serrano, Guillermo and Veleiro, Uxía and Casals, Mikel and Vera, Laura and Pizurica, Marija and Gómez-Cebrián, Nuria and Puchades-Carrasco, Leonor and Pineda-Lucena, Antonio and Ochoa, Idoia and Vicent, Silve and Gevaert, Olivier and Hernaez, Mikel},
  doi          = {10.1038/s42256-025-00987-y},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {495-508},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Towards a more inductive world for drug repurposing approaches},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Teaching robots to build simulations of themselves.
<em>NATMI</em>, <em>7</em>(3), 484–494. (<a
href="https://doi.org/10.1038/s42256-025-01006-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of vision catalysed a pivotal evolutionary advancement, enabling organisms not only to perceive but also to interact intelligently with their environment. This transformation is mirrored by the evolution of robotic systems, where the ability to leverage vision to simulate and predict their own dynamics marks a leap towards autonomy and self-awareness. Humans utilize vision to record experiences and internally simulate potential actions. For example, we can imagine that, if we stand up and raise our arms, the body will form a ‘T’ shape without physical movement. Similarly, simulation allows robots to plan and predict the outcomes of potential actions without execution. Here we introduce a self-supervised learning framework to enable robots to model and predict their morphology, kinematics and motor control using only brief raw video data, eliminating the need for extensive real-world data collection and kinematic priors. By observing their own movements, akin to humans watching their reflection in a mirror, robots learn an ability to simulate themselves and predict their spatial motion for various tasks. Our results demonstrate that this self-learned simulation not only enables accurate motion planning but also allows the robot to detect abnormalities and recover from damage. Motion planning for a robot generally requires full knowledge of its structure. Here Hu and colleagues present a method for inferring the structure of a robot from visual information.},
  archive      = {J_NATMI},
  author       = {Hu, Yuhang and Lin, Jiong and Lipson, Hod},
  doi          = {10.1038/s42256-025-01006-w},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {484-494},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Teaching robots to build simulations of themselves},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards unveiling sensitive and decisive patterns in
explainable AI with a case study in geometric deep learning.
<em>NATMI</em>, <em>7</em>(3), 471–483. (<a
href="https://doi.org/10.1038/s42256-025-00998-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interpretability of machine learning models has gained increasing attention, particularly in scientific domains where high precision and accountability are crucial. This research focuses on distinguishing between two critical data patterns—sensitive patterns (model related) and decisive patterns (task related)—which are commonly used as model interpretations but often lead to confusion. Specifically, this study compares the effectiveness of two main streams of interpretation methods: post-hoc methods and self-interpretable methods, in detecting these patterns. Recently, geometric deep learning (GDL) has shown superior predictive performance in various scientific applications, creating an urgent need for principled interpretation methods. Here, therefore, we conduct our study using several representative GDL applications as case studies. We evaluate 13 interpretation methods applied to 3 major GDL backbone models, using 4 scientific datasets to assess how well these methods identify sensitive and decisive patterns. Our findings indicate that post-hoc methods tend to provide interpretations better aligned with sensitive patterns, whereas certain self-interpretable methods exhibit strong and stable performance in detecting decisive patterns. Moreover, our study offers valuable insights into improving the reliability of these interpretation methods. For example, ensembling post-hoc interpretations from multiple models trained on the same task can effectively uncover the task’s decisive patterns. Interpreting decisions made by machine learning systems remains difficult. Here Zhu et al. test interpretability methods on their ability to identify model-related and task-related patterns.},
  archive      = {J_NATMI},
  author       = {Zhu, Jiajun and Miao, Siqi and Ying, Rex and Li, Pan},
  doi          = {10.1038/s42256-025-00998-9},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {471-483},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Towards unveiling sensitive and decisive patterns in explainable AI with a case study in geometric deep learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Categorizing robots by performance fitness into the tree of
robots. <em>NATMI</em>, <em>7</em>(3), 459–470. (<a
href="https://doi.org/10.1038/s42256-025-00995-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are typically classified based on specific morphological features, like their kinematic structure. However, a complex interplay between morphology and intelligence shapes how well a robot performs processes. Just as delicate surgical procedures demand high dexterity and tactile precision, manual warehouse or construction work requires strength and endurance. These process requirements necessitate robot systems that provide a level of performance fitting the process. In this work, we introduce the tree of robots as a taxonomy to bridge the gap between morphological classification and process-based performance. It classifies robots based on their fitness to perform, for example, physical interaction processes. Using 11 industrial manipulators, we constructed the first part of the tree of robots based on a carefully deduced set of metrics reflecting fundamental robot capabilities for various industrial physical interaction processes. Through significance analysis, we identified substantial differences between the systems, grouping them via an expectation-maximization algorithm to create a fitness-based robot classification that is open for contributions and accessible. It is challenging to compare how well robots perform a task, as the evaluation depends on the process and skills required. It is proposed to group robots into a taxonomy based on their performance on a set of embodied skill benchmarks.},
  archive      = {J_NATMI},
  author       = {Kirschner, Robin Jeanne and Karacan, Kübra and Melone, Alessandro and Haddadin, Sami},
  doi          = {10.1038/s42256-025-00995-y},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {459-470},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Categorizing robots by performance fitness into the tree of robots},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep lead optimization enveloped in protein pocket and its
application in designing potent and selective ligands targeting LTK
protein. <em>NATMI</em>, <em>7</em>(3), 448–458. (<a
href="https://doi.org/10.1038/s42256-025-00997-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing the chemical structure of promising drug candidates through systematic modifications to improve potency and physiochemical properties is a vital step in the drug discovery pipeline. In contrast to the well-established de novo generation schemes, computational methods specifically tailored for lead optimization remain largely underexplored. Prior models are often limited to addressing specific subtasks, such as generating two-dimensional molecular structures, while neglecting crucial protein–ligand interactions in three-dimensional space. To overcome these challenges, we propose Delete (Deep lead optimization enveloped in protein pocket), a one-stop solution for lead optimization by combining generative artificial intelligence and structure-based approaches. Our model can handle all subtasks of lead optimization through a unified deleting (masking) strategy, and it accounts for intricate pocket–ligand interactions through an equivariant network design. Statistical assessments and retrospective studies across individual subtasks demonstrate that Delete has an outstanding ability to craft molecules with superior protein-binding energy and reasonable drug-likeness using given fragments or atoms. Subsequently, we utilize Delete to design inhibitors targeting the previously identified LTK protein. Among the ligands designed by Delete, CA-B-1 is successfully validated as a potent (1.36 nM) and selective inhibitor by in vitro and in vivo experiments. This work represents a successful implementation of the powerful structure-based lead optimization model, Delete, for rapid and controllable rational drug design. Chen et al. present a deep learning-based lead optimization model that combines generative artificial intelligence with structure-based approaches. The method is successfully applied to the design of drug-like molecules targeting the recently identified LTK protein target with high potency and selectivity.},
  archive      = {J_NATMI},
  author       = {Chen, Shicheng and Zhang, Odin and Jiang, Chenran and Zhao, Huifeng and Zhang, Xujun and Chen, Mengting and Liu, Yun and Su, Qun and Wu, Zhenxing and Wang, Xinyue and Qu, Wanglin and Ye, Yuanyi and Chai, Xin and Wang, Ning and Wang, Tianyue and An, Yuan and Wu, Guanlin and Yang, Qianqian and Chen, Jiean and Xie, Wei and Lin, Haitao and Li, Dan and Hsieh, Chang-Yu and Huang, Yong and Kang, Yu and Hou, Tingjun and Pan, Peichen},
  doi          = {10.1038/s42256-025-00997-w},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {448-458},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Deep lead optimization enveloped in protein pocket and its application in designing potent and selective ligands targeting LTK protein},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models for scientific discovery in molecular
property prediction. <em>NATMI</em>, <em>7</em>(3), 437–447. (<a
href="https://doi.org/10.1038/s42256-025-00994-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are a form of artificial intelligence system encapsulating vast knowledge in the form of natural language. These systems are adept at numerous complex tasks including creative writing, storytelling, translation, question-answering, summarization and computer code generation. Although LLMs have seen initial applications in natural sciences, their potential for driving scientific discovery remains largely unexplored. In this work, we introduce LLM4SD, a framework designed to harness LLMs for driving scientific discovery in molecular property prediction by synthesizing knowledge from literature and inferring knowledge from scientific data. LLMs synthesize knowledge by extracting established information from scientific literature, such as molecular weight being key to predicting solubility. For inference, LLMs identify patterns in molecular data, particularly in Simplified Molecular Input Line Entry System-encoded structures, such as halogen-containing molecules being more likely to cross the blood–brain barrier. This information is presented as interpretable knowledge, enabling the transformation of molecules into feature vectors. By using these features with interpretable models such as random forest, LLM4SD can outperform the current state of the art across a range of benchmark tasks for predicting molecular properties. We foresee it providing interpretable and potentially new insights, aiding scientific discovery in molecular property prediction. Zheng et al. developed LLM4SD, a framework using large language models to predict molecular properties. The method leverages the ability of large language models to synthesize knowledge from literature and to reason about scientific data with domain expertise.},
  archive      = {J_NATMI},
  author       = {Zheng, Yizhen and Koh, Huan Yee and Ju, Jiaxin and Nguyen, Anh T. N. and May, Lauren T. and Webb, Geoffrey I. and Pan, Shirui},
  doi          = {10.1038/s42256-025-00994-z},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {437-447},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Large language models for scientific discovery in molecular property prediction},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven federated learning in drug discovery with
knowledge distillation. <em>NATMI</em>, <em>7</em>(3), 423–436. (<a
href="https://doi.org/10.1038/s42256-025-00991-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A main challenge for artificial intelligence in scientific research is ensuring access to sufficient, high-quality data for the development of impactful models. Despite the abundance of public data, the most valuable knowledge often remains embedded within confidential corporate data silos. Although industries are increasingly open to sharing non-competitive insights, such collaboration is often constrained by the confidentiality of the underlying data. Federated learning makes it possible to share knowledge without compromising data privacy, but it has notable limitations. Here, we introduce FLuID (federated learning using information distillation), a data-centric application of federated distillation tailored to drug discovery aiming to preserve data privacy. We validate FLuID in two experiments, first involving public data simulating a virtual consortium and second in a real-world research collaboration between eight pharmaceutical companies. Although the alignment of the models with the partner specific domain remains challenging, the data-driven nature of FLuID offers several avenues to mitigate domain shift. FLuID fosters knowledge sharing among pharmaceutical organizations, paving the way for a new generation of models with enhanced performance and an expanded applicability domain in biological activity predictions. FLuID enables privacy-preserving knowledge sharing in drug discovery using knowledge distillation. The results show that the approach expands applicability domains and fosters collaboration across organizations without compromising data privacy or security.},
  archive      = {J_NATMI},
  author       = {Hanser, Thierry and Ahlberg, Ernst and Amberg, Alexander and Anger, Lennart T. and Barber, Chris and Brennan, Richard J. and Brigo, Alessandro and Delaunois, Annie and Glowienke, Susanne and Greene, Nigel and Johnston, Laura and Kuhn, Daniel and Kuhnke, Lara and Marchaland, Jean-François and Muster, Wolfgang and Plante, Jeffrey and Rippmann, Friedrich and Sabnis, Yogesh and Schmidt, Friedemann and van Deursen, Ruud and Werner, Stéphane and White, Angela and Wichard, Joerg and Yukawa, Tomoya},
  doi          = {10.1038/s42256-025-00991-2},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {423-436},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Data-driven federated learning in drug discovery with knowledge distillation},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable AI reveals clever hans effects in unsupervised
learning models. <em>NATMI</em>, <em>7</em>(3), 412–422. (<a
href="https://doi.org/10.1038/s42256-025-01000-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised learning has become an essential building block of artifical intelligence systems. The representations it produces, for example, in foundation models, are critical to a wide variety of downstream applications. It is therefore important to carefully examine unsupervised models to ensure not only that they produce accurate predictions on the available data but also that these accurate predictions do not arise from a Clever Hans (CH) effect. Here, using specially developed explainable artifical intelligence techniques and applying them to popular representation learning and anomaly detection models for image data, we show that CH effects are widespread in unsupervised learning. In particular, through use cases on medical and industrial inspection data, we demonstrate that CH effects systematically lead to significant performance loss of downstream models under plausible dataset shifts or reweighting of different data subgroups. Our empirical findings are enriched by theoretical insights, which point to inductive biases in the unsupervised learning machine as a primary source of CH effects. Overall, our work sheds light on unexplored risks associated with practical applications of unsupervised learning and suggests ways to systematically mitigate CH effects, thereby making unsupervised learning more robust. Building on recent explainable AI techniques, this Article highlights the pervasiveness of Clever Hans effects in unsupervised learning and the substantial risks associated with these effects in terms of the prediction accuracy on new data.},
  archive      = {J_NATMI},
  author       = {Kauffmann, Jacob and Dippel, Jonas and Ruff, Lukas and Samek, Wojciech and Müller, Klaus-Robert and Montavon, Grégoire},
  doi          = {10.1038/s42256-025-01000-2},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {412-422},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Explainable AI reveals clever hans effects in unsupervised learning models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models that replace human participants can
harmfully misportray and flatten identity groups. <em>NATMI</em>,
<em>7</em>(3), 400–411. (<a
href="https://doi.org/10.1038/s42256-025-00986-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) are increasing in capability and popularity, propelling their application in new domains—including as replacements for human participants in computational social science, user testing, annotation tasks and so on. In many settings, researchers seek to distribute their surveys to a sample of participants that are representative of the underlying human population of interest. This means that to be a suitable replacement, LLMs will need to be able to capture the influence of positionality (that is, the relevance of social identities like gender and race). However, we show that there are two inherent limitations in the way current LLMs are trained that prevent this. We argue analytically for why LLMs are likely to both misportray and flatten the representations of demographic groups, and then empirically show this on four LLMs through a series of human studies with 3,200 participants across 16 demographic identities. We also discuss a third limitation about how identity prompts can essentialize identities. Throughout, we connect each limitation to a pernicious history of epistemic injustice against the value of lived experiences that explains why replacement is harmful for marginalized demographic groups. Overall, we urge caution in use cases in which LLMs are intended to replace human participants whose identities are relevant to the task at hand. At the same time, in cases where the benefits of LLM replacement are determined to outweigh the harms (for example, engaging human participants may cause them harm, or the goal is to supplement rather than fully replace), we empirically demonstrate that our inference-time techniques reduce—but do not remove—these harms. Large language models are being considered to simulate responses from participants of different backgrounds in computational social science experiments. Here it is shown that this practice can misportray and flatten demographic groups in distinctively harmful ways.},
  archive      = {J_NATMI},
  author       = {Wang, Angelina and Morgenstern, Jamie and Dickerson, John P.},
  doi          = {10.1038/s42256-025-00986-z},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {400-411},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Large language models that replace human participants can harmfully misportray and flatten identity groups},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergy-based robotic quadruped leveraging passivity for
natural intelligence and behavioural diversity. <em>NATMI</em>,
<em>7</em>(3), 386–399. (<a
href="https://doi.org/10.1038/s42256-025-00988-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quadrupedal animals show remarkable capabilities in traversing diverse terrains and display a range of behaviours and gait patterns. Achieving similar performance by exploiting the natural dynamics of the system is a key goal for robotics researchers. Here we show a bioinspired approach to the design of quadrupeds that seeks to exploit the body and the passive properties of the robot while maintaining active controllability on the system through minimal actuation. Utilizing an end-to-end computational design pipeline, neuromechanical couplings recorded in biological quadrupeds are translated into motor synergies, allowing minimal actuation to control the full structure via multijoint compliant mechanical couplings. Using this approach, we develop PAWS, a passive automata with synergies. By leveraging the principles of motor synergies, the design incorporates variable stiffness, anatomical insights and self-organization to simplify control while maximizing its capabilities. The resulting synergy-based quadruped requires only four actuators and exhibits emergent, animal-like dynamical responses, including passive robustness to environmental perturbations and a wide range of actuated behaviours. The finding contributes to the development of machine physical intelligence and provides robots with more efficient and natural-looking robotic locomotion by combining synergistic actuation, compliant body properties and embodied compensatory strategies. Stella, Achkar and colleagues present a bio-inspired quadruped robot that uses passive dynamics, motor synergies, variable stiffness and self-organization to achieve robust, adaptive, animal-like movement with just four actuators.},
  archive      = {J_NATMI},
  author       = {Stella, Francesco and Achkar, Mickaël M. and Della Santina, Cosimo and Hughes, Josie},
  doi          = {10.1038/s42256-025-00988-x},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {386-399},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Synergy-based robotic quadruped leveraging passivity for natural intelligence and behavioural diversity},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum circuit optimization with AlphaTensor.
<em>NATMI</em>, <em>7</em>(3), 374–385. (<a
href="https://doi.org/10.1038/s42256-025-01001-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge in realizing fault-tolerant quantum computers is circuit optimization. Focusing on the most expensive gates in fault-tolerant quantum computation (namely, the T gates), we address the problem of T-count optimization, that is, minimizing the number of T gates needed to implement a given circuit. To achieve this, we develop AlphaTensor-Quantum, a method based on deep reinforcement learning that exploits the relationship between optimizing the T-count and tensor decomposition. Unlike existing methods for T-count optimization, AlphaTensor-Quantum can incorporate domain-specific knowledge about quantum computation and leverage gadgets, which substantially reduces the T-count of the optimized circuits. AlphaTensor-Quantum outperforms the existing methods for T-count optimization on a set of arithmetic benchmarks (even when compared without using gadgets). Remarkably, it discovers an efficient algorithm akin to Karatsuba’s method for multiplication in finite fields. AlphaTensor-Quantum also finds the best human-designed solutions for relevant arithmetic computations used in Shor’s algorithm and for quantum chemistry simulation, thus demonstrating that it can save hundreds of hours of research by optimizing relevant quantum circuits in a fully automated way. Ruiz and colleagues introduce AlphaTensor-Quantum, a deep reinforcement learning method for optimizing quantum circuits. It outperforms existing methods and is capable of finding the best human-designed solutions for relevant quantum computations in a fully automated way.},
  archive      = {J_NATMI},
  author       = {Ruiz, Francisco J. R. and Laakkonen, Tuomas and Bausch, Johannes and Balog, Matej and Barekatain, Mohammadamin and Heras, Francisco J. H. and Novikov, Alexander and Fitzpatrick, Nathan and Romera-Paredes, Bernardino and van de Wetering, John and Fawzi, Alhussein and Meichanetzidis, Konstantinos and Kohli, Pushmeet},
  doi          = {10.1038/s42256-025-01001-1},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {374-385},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Quantum circuit optimization with AlphaTensor},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast, scale-adaptive and uncertainty-aware downscaling of
earth system model fields with generative machine learning.
<em>NATMI</em>, <em>7</em>(3), 363–373. (<a
href="https://doi.org/10.1038/s42256-025-00980-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and high-resolution Earth system model (ESM) simulations are essential to assess the ecological and socioeconomic impacts of anthropogenic climate change, but are computationally too expensive to be run at sufficiently high spatial resolution. Recent machine learning approaches have shown promising results in downscaling ESM simulations, outperforming state-of-the-art statistical approaches. However, existing methods require computationally costly retraining for each ESM and extrapolate poorly to climates unseen during training. We address these shortcomings by learning a consistency model that efficiently and accurately downscales arbitrary ESM simulations without retraining in a zero-shot manner. Our approach yields probabilistic downscaled fields at a resolution only limited by the observational reference data. We show that the consistency model outperforms state-of-the-art diffusion models at a fraction of the computational cost and maintains high controllability on the downscaling task. Further, our method generalizes to climate states unseen during training without explicitly formulated physical constraints. A generative machine learning approach is proposed to improve the resolution of Earth system models in an efficient, adaptive and uncertainty-aware manner.},
  archive      = {J_NATMI},
  author       = {Hess, Philipp and Aich, Michael and Pan, Baoxiang and Boers, Niklas},
  doi          = {10.1038/s42256-025-00980-5},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {363-373},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Fast, scale-adaptive and uncertainty-aware downscaling of earth system model fields with generative machine learning},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformers and genome language models. <em>NATMI</em>,
<em>7</em>(3), 346–362. (<a
href="https://doi.org/10.1038/s42256-025-01007-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models based on the transformer deep learning architecture have revolutionized natural language processing. Motivated by the analogy between human language and the genome’s biological code, researchers have begun to develop genome language models (gLMs) based on transformers and related architectures. This Review explores the use of transformers and language models in genomics. We survey open questions in genomics amenable to the use of gLMs, and motivate the use of gLMs and the transformer architecture for these problems. We discuss the potential of gLMs for modelling the genome using unsupervised pretraining tasks, specifically focusing on the power of zero- and few-shot learning. We explore the strengths and limitations of the transformer architecture, as well as the strengths and limitations of current gLMs more broadly. Additionally, we contemplate the future of genomic modelling beyond the transformer architecture, based on current trends in research. This Review serves as a guide for computational biologists and computer scientists interested in transformers and language models for genomic data. Micaela Consens et al. discuss and review the recent rise of transformer-based and large language models in genomics. They also highlight promising directions for genome language models beyond the transformer architecture.},
  archive      = {J_NATMI},
  author       = {Consens, Micaela E. and Dufault, Cameron and Wainberg, Michael and Forster, Duncan and Karimzadeh, Mehran and Goodarzi, Hani and Theis, Fabian J. and Moses, Alan and Wang, Bo},
  doi          = {10.1038/s42256-025-01007-9},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {346-362},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Transformers and genome language models},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Materiality and risk in the age of pervasive AI sensors.
<em>NATMI</em>, <em>7</em>(3), 334–345. (<a
href="https://doi.org/10.1038/s42256-025-01017-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) systems connected to sensor-laden devices are becoming pervasive, which has notable implications for a range of AI risks, including to privacy, the environment, autonomy and more. There is therefore a growing need for increased accountability around the responsible development and deployment of these technologies. Here we highlight the dimensions of risk associated with AI systems that arise from the material affordances of sensors and their underlying calculative models. We propose a sensor-sensitive framework for diagnosing these risks, complementing existing approaches such as the US National Institute of Standards and Technology AI Risk Management Framework and the European Union AI Act, and discuss its implementation. We conclude by advocating for increased attention to the materiality of algorithmic systems, and of on-device AI sensors in particular, and highlight the need for development of a sensor design paradigm that empowers users and communities and leads to a future of increased fairness, accountability and transparency. Sloane and colleagues review emerging new dimensions of risks associated with materiality and AI algorithms run on pervasive sensors.},
  archive      = {J_NATMI},
  author       = {Sloane, Mona and Moss, Emanuel and Kennedy, Susan and Stewart, Matthew and Warden, Pete and Plancher, Brian and Reddi, Vijay Janapa},
  doi          = {10.1038/s42256-025-01017-7},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {334-345},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Materiality and risk in the age of pervasive AI sensors},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From data chaos to precision medicine. <em>NATMI</em>,
<em>7</em>(3), 332–333. (<a
href="https://doi.org/10.1038/s42256-025-01015-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More than 30 years have passed since the advent of omics technologies revolutionized biological and medical research. Research now highlights the unique opportunity to integrate and decode complex biological mechanisms for health and diseases with machine learning.},
  archive      = {J_NATMI},
  author       = {Schönhuth, Alexander},
  doi          = {10.1038/s42256-025-01015-9},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {332-333},
  shortjournal = {Nat. Mach. Intell.},
  title        = {From data chaos to precision medicine},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the gap between machine confidence and human
perceptions. <em>NATMI</em>, <em>7</em>(3), 330–331. (<a
href="https://doi.org/10.1038/s42256-025-01013-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Users often overestimate the accuracy of large language models (LLMs). A new approach examines user perceptions and finds that aligning LLM explanations with the models’ internal confidence improves user perception.},
  archive      = {J_NATMI},
  author       = {Yin, Ming},
  doi          = {10.1038/s42256-025-01013-x},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {330-331},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Bridging the gap between machine confidence and human perceptions},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transparency (in training data) is what we want.
<em>NATMI</em>, <em>7</em>(3), 329. (<a
href="https://doi.org/10.1038/s42256-025-01023-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As more powerful generative AI tools appear on the market, legal debates about the use of copyrighted content to develop such tools are intensifying. To resolve these issues, transparency regarding which copyrighted data have been used and where in the AI training pipeline needs to be a starting point.},
  archive      = {J_NATMI},
  doi          = {10.1038/s42256-025-01023-9},
  journal      = {Nature Machine Intelligence},
  month        = {3},
  number       = {3},
  pages        = {329},
  shortjournal = {Nat. Mach. Intell.},
  title        = {Transparency (in training data) is what we want},
  volume       = {7},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
