<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JIFS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jifs---24">JIFS - 24</h2>
<ul>
<li><details>
<summary>
(2025). Human activities recognition from video images by using
convolutional neural network. <em>JIFS</em>, <em>48</em>(6), 929–940.
(<a href="https://doi.org/10.3233/JIFS-236068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, automatic human activity recognition from video images is necessary for monitoring applications and caring for disabled people. The use of surveillance cameras and the processing of the obtained images leads to the achievement of a smart, accurate system for the recognition of human behavior. Since human detection in different scenes is associated with many challenges, several approaches have been implemented to detect human activity from video image processing. Due to the complexity of human activities, background noises and other factors affect the detection. For the solution of these problems, two deep learning-based algorithms have been described in the current article. According to the convolutional neural networks, the LSTM + CNN method and the 3D CNN method have been used to recognize the human activities in the images of the video. Each algorithm is explained and analyzed in detail. The experiments designed in this paper are performed by two datasets: the HMDB-51 dataset and the UCF101 dataset. In the HMDB-51 dataset, the highest obtained accuracy for CNN + LSTM method was equal to 70.2 and for method 3D CNN equal to 54.4. In the UCF101 dataset, the highest obtained accuracy for CNN + LSTM method was equal to 95.1 and for method 3D CNN equal to 90.8.},
  archive      = {J_JIFS},
  author       = {Wang, Dan and Yao, Jingfa and Zhang, Yanmin},
  doi          = {10.3233/JIFS-236068},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {929-940},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Human activities recognition from video images by using convolutional neural network},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep neural network for vehicle detection in aerial
images. <em>JIFS</em>, <em>48</em>(6), 915–927. (<a
href="https://doi.org/10.3233/JIFS-236059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research paper highlights the significance of vehicle detection in aerial images for surveillance systems, focusing on deep learning methods that outperform traditional approaches. However, the challenge of high computation complexity due to diverse vehicle appearances persists. The motivation behind this study is to highlight the crucial role of vehicle detection in aerial images for surveillance systems, emphasizing the superior performance of deep learning methods compared to traditional approaches. To address this, a lightweight deep neural network-based model is developed, striking a balance between accuracy and efficiency enabling real-time operation. The model is trained and evaluated on a standardized dataset, with extensive experiments demonstrating its ability to achieve accurate vehicle detection with significantly reduced computation costs, offering a practical solution for real-world aerial surveillance scenarios.},
  archive      = {J_JIFS},
  author       = {Du, Rong and Cheng, Yan},
  doi          = {10.3233/JIFS-236059},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {915-927},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A deep neural network for vehicle detection in aerial images},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hosoya polynomial and wiener index of abid-waheed graph (
AW) a 8 and ( AW) a 10. <em>JIFS</em>, <em>48</em>(6), 907–914. (<a
href="https://doi.org/10.3233/JIFS-236051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molecular structures are characterised by the Hosoya polynomial and Wiener index, ideas from mathematical chemistry and graph theory. The graph representation of a chemical compound that has atoms as vertices and chemical bonds as edges is called a molecular graph, and the Hosoya polynomial is a polynomial related to this graph. As a graph attribute that remains unchanged under graph isomorphism, the Hosoya polynomial is known as a graph invariant. It offers details regarding the quantity of distinct non-empty subgraphs within a specified graph. A topological metric called the Wiener index is employed to measure the branching complexity and size of a molecular graph. For every pair of vertices in a molecular network, the Wiener index is the total of those distances. In this paper, discussed the Hosoya polynomial, Wiener index and Hyper-Wiener index of the Abid-Waheed graphs (AW) a 8 and (AW) a 10 . This graph is similar to Jahangir’s graph. Further, we have extended the research work on the applications of the described graphs.},
  archive      = {J_JIFS},
  author       = {Meenakshi, A. and Bramila, M.},
  doi          = {10.3233/JIFS-236051},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {907-914},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Hosoya polynomial and wiener index of abid-waheed graph ( AW) a 8 and ( AW) a 10},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian optimization based bloat prevention for secure IoT
healthcare. <em>JIFS</em>, <em>48</em>(6), 895–906. (<a
href="https://doi.org/10.3233/JIFS-235933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health information technology is a subcategory of health technology that covers medical and healthcare information technology. It allows for the secure exchange of health information among consumers, providers, payers, and quality monitors, as well as the management of health information across computerized systems. In recent scenario, Internet of Medical Things (IoMT) collects the medical healthcare data via sensors, are further transmitted to remote servers, to be evaluated by the doctors for earlier disease detection. Conversely, there is always a threat on using wireless communication and the user’s private data can be targeted by the attackers. In this paper, Bayesian optimization-based bloat prevention for secure IoT healthcare, for identifying Attacks in secure healthcare system (BO-BLOAT). The gathered input datasets are pre-processed using the Natural Language Processing (NLP) techniques namely Sentence segmentation, Tokenization, Word Stemming and Removing stop words for removing irrelevant data. After preprocessing the features are extracted using RNN-BiLSTM and feature selection technique is done by Bayesian Optimization. The deep learning (DL) based Mobilenet network is utilized for attack detection. Finally, the classification and identifying the types of attack is performed by using DL based Ghost net. For performance analysis, the two dataset is utilized namely UNBDS-NB-15, KDD99. The classification results show that the proposed BO-BLOAT model attains higher rate of accuracy in attack detection than existing models. The proposed BO-BLOAT method has been simulated using MATLAB. The Proposed BO-BLOAT method improves the overall accuracy of the proposed BO-BLOAT, HFL, LRO-S, and GOL is 99.04%, 93.47%, 92.82% and 90.64% respectively.},
  archive      = {J_JIFS},
  author       = {Ramya, M. and Sudhakaran, Pradeep},
  doi          = {10.3233/JIFS-235933},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {895-906},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Bayesian optimization based bloat prevention for secure IoT healthcare},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart edge segmentation and localization method for building
detection in satellite imagery. <em>JIFS</em>, <em>48</em>(6), 875–894.
(<a href="https://doi.org/10.3233/JIFS-235150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancements in satellite imaging technology have brought about an unprecedented influx of high-resolution satellite imagery. One of the critical tasks in this domain is the automated detection of buildings within satellite imagery. Building detection holds substantial significance for urban planning, disaster management, environmental monitoring, and various other applications. The challenges in this field are manifold, including variations in building sizes, shapes, orientations, and surrounding environments. Furthermore, satellite imagery often contains occlusions, shadows, and other artifacts that can hinder accurate building detection. The proposed method introduces a novel approach to improve the boundary detection of detected buildings in high-resolution remote sensed images having shadows and irregular shapes. It aims to enhance the accuracy of building detection and classification. The proposed algorithm is compared with Customized Faster R-CNNs and Single-Shot Multibox Detectors to show the significance of the results. We have used different datasets for training and evaluating the algorithm. Experimental results show that SESLM for Building Detection in Satellite Imagery can detect 98.5% of false positives at a rate of 8.4%. In summary, SESLM showcases high accuracy and improved robustness in detecting buildings, particularly in the presence of shadows.},
  archive      = {J_JIFS},
  author       = {Hashmi, Hina and Dwivedi, Rakesh and Kumar, Anil and Kumar, Aman},
  doi          = {10.3233/JIFS-235150},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {875-894},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Smart edge segmentation and localization method for building detection in satellite imagery},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on end-route planning for community group
purchasing for vehicles with different energy sources. <em>JIFS</em>,
<em>48</em>(6), 859–873. (<a
href="https://doi.org/10.3233/JIFS-234773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the issue of final delivery route planning in the community group purchase model, this study takes into full consideration logistics vehicles of different energy types. With the goal of minimizing the sum of vehicle operating costs, delivery timeliness costs, goods loss costs, and carbon emissions costs, a multi-objective optimization model for community group purchase final delivery route planning is constructed. An improved genetic algorithm with a hill-climbing algorithm is utilized to enhance adaptive genetic operators, preventing the algorithm from getting stuck in local optima and improving the solution efficiency. Finally, a case study simulation is conducted to validate the feasibility of the model and algorithm. Experimental results indicate that currently, among the three types of vehicles, fuel logistics vehicles still have an advantage in terms of vehicle usage cost. Electric logistics vehicles exhibit the poorest performance with the highest cost per hundred kilometers, but their sole advantage lies in their high energy release efficiency, enabling optimal low-carbon vehicle performance. Battery-swapping logistics vehicles perform the best in terms of carbon emissions, combining the advantages of both fuel-based and electric logistics vehicles. Therefore, battery-swapping logistics vehicles are a favorable choice for replacing fuel-based logistics vehicles in the future, offering promising prospects for future development.},
  archive      = {J_JIFS},
  author       = {Wang, Jing and Gao, Tingting and Du, Hongxu and Tu, Chuang},
  doi          = {10.3233/JIFS-234773},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {859-873},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Research on end-route planning for community group purchasing for vehicles with different energy sources},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A text dependent copy-paste plagiarism and text-rewriting
plagiarism model. <em>JIFS</em>, <em>48</em>(6), 849–858. (<a
href="https://doi.org/10.3233/JIFS-234726">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plagiarism is common in English writing exams. Researchers classify plagiarism into copy-paste and text-rewriting plagiarism, but existing models need help with problems such as the single way of checking and unsatisfactory results. Aiming at the copy-paste problem in English writing plagiarism, this paper proposes a digital fingerprint model based on the N-Gram window jumping mechanism. The model incorporates a sliding window and an improved matching tool to solve the problems of excessive fingerprint density and low checking efficiency in text extraction. Meanwhile, the model adds a Fisher-Yates shuffle algorithm with a salt parameter to crack the hash collision in text matching. The experiments show that the model can detect copy-paste plagiarism in English composition. For text rewriting plagiarism, this paper designs a TextCNN-BiGRU-based model, which combines TextCNN and BiGRU so that the extracted text semantic information considers the text’s local and contextual features. The experiments show that the model improves the accuracy by 1.9 percentage points and the F1 value by 1.2 percentage points on the MRPC dataset compared with other models.},
  archive      = {J_JIFS},
  author       = {Guo, Qingkai and Huang, Guimin and Wang, Yabing and Zhou, Ya},
  doi          = {10.3233/JIFS-234726},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {849-858},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A text dependent copy-paste plagiarism and text-rewriting plagiarism model},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusion of GBDT and neural network for click-through rate
estimation. <em>JIFS</em>, <em>48</em>(6), 835–847. (<a
href="https://doi.org/10.3233/JIFS-234713">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the issue that the current click-through rate prediction methods ignore the varying impacts of different input features on prediction accuracy and exhibit low accuracy when dealing with large-scale data, a click-through rate prediction method (GBIFM) which combines Gradient Boosting Decision Tree (GBDT) and Input-aware Factorization Machine (IFM) is proposed in this paper. The proposed GBIFM method employs GBDT for data processing, which can flexibly handle various types of data without the need for one-hot encoding of discrete features. An Input-aware strategy is introduced to refine the weight vector and embedding vector of each feature for different instances, adaptively learning the impact of each input vector on feature representation. Furthermore, a fully connected network is incorporated to capture high-order features in a non-linear manner, enhancing the method’s ability to express and generalize complex structured data. A comprehensive experiment is conducted on the Criteo and Avazu datasets, the results show that compared to typical methods such as DeepFM, AFM, and IFM, the proposed method GBIFM can increase the AUC value by 10% –12% and decrease the Logloss value by 6% –20%, effectively improving the accuracy of click-through rate prediction.},
  archive      = {J_JIFS},
  author       = {Zhao, Bin and Cao, Wei and Zhang, Jiqun and Gao, Yilong and Li, Bin and Chen, Fengmei},
  doi          = {10.3233/JIFS-234713},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {835-847},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Fusion of GBDT and neural network for click-through rate estimation},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning model based glaucoma detection using retinal
images. <em>JIFS</em>, <em>48</em>(6), 823–834. (<a
href="https://doi.org/10.3233/JIFS-234131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The retinal illness that causes vision loss frequently on the globe is glaucoma. Hence, the earlier detection of Glaucoma is important. In this article, modified AlexNet deep leaning model is proposed to category the source retinal images into either healthy or Glaucoma through the detection and segmentations of optic disc (OD) and optic cup (OC) regions in retinal pictures. The retinal images are preprocessed and OD region is detected and segmented using circulatory filter. Further, OC regions are detected and segmented using K-means classification algorithm. Then, the segmented OD and OC region are classified and trained by the suggested AlexNet deep leaning model. This model classifies the source retinal image into either healthy or Glaucoma. Finally, performance measures have been estimated in relation to ground truth pictures in regards to accuracy, specificity and sensitivity. These performance measures are contrasted with the other previous Glaucoma detection techniques on publicly accessible retinal image datasets HRF and RIGA. The suggested technique as described in this work achieves 91.6% GDR for mild case and also achieves 100% GDR for severe case on HRF dataset. The suggested method as described in this work achieves 97.7% GDR for mild case and also achieves 100% GDR for severe case on RIGA dataset.},
  archive      = {J_JIFS},
  author       = {Ruby Elizabeth, J. and Kesavaraja, D. and Juliet, S. Ebenezer},
  doi          = {10.3233/JIFS-234131},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {823-834},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A deep learning model based glaucoma detection using retinal images},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ComMatch: A semi-supervised learning classification
algorithm based on model calibration. <em>JIFS</em>, <em>48</em>(6),
811–822. (<a href="https://doi.org/10.3233/JIFS-233940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) aims to reduce reliance on labeled data. Achieving high performance often requires more complex algorithms, therefore, generic SSL algorithms are less effective when it comes to image classification tasks. In this study, we propose ComMatch, a simpler and more effective algorithm that combines negative learning, dynamic thresholding, and predictive stability discriminations into the consistency regularization approach. The introduction of negative learning is to help facilitate training by selecting negative pseudo-labels during stages when the network has low confidence. And ComMatch filters positive and negative pseudo-labels more accurately as training progresses by dynamic thresholds. Since high confidence does not always mean high accuracy due to network calibration issues, we also introduce network predictive stability, which filters out samples by comparing the standard deviation of the network output with a set threshold, thus largely reducing the influence of noise in the training process. ComMatch significantly outperforms existing algorithms over several datasets, especially when there is less labeled data available. For example, ComMatch achieves 1.82% and 3.6% error rate reduction over FlexMatch and FixMatch on CIFAR-10 with 40 labels respectively. And with 4000 labeled samples, ComMatch achieves 0.54% and 2.65% lower error rates than FixMatch and MixMatch, respectively.},
  archive      = {J_JIFS},
  author       = {Li, Ye and Zhou, Jingkang},
  doi          = {10.3233/JIFS-233940},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {811-822},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {ComMatch: A semi-supervised learning classification algorithm based on model calibration},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective community detection with topic modeling in article
recommender systems using LS-SLM and PCC-LDA. <em>JIFS</em>,
<em>48</em>(6), 793–809. (<a
href="https://doi.org/10.3233/JIFS-233851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an innovative approach, the LS-SLM (Local Search with Smart Local Moving) technique, for enhancing the efficiency of article recommendation systems based on community detection and topic modeling. The methodology undergoes rigorous evaluation using a comprehensive dataset extracted from the “dblp. v12.json” citation network. Experimental results presented herein provide a clear depiction of the superior performance of the LS-SLM technique when compared to established algorithms, namely the Louvain Algorithm (LA), Stochastic Block Model (SBM), Fast Greedy Algorithm (FGA), and Smart Local Moving (SLM). The evaluation metrics include accuracy, precision, specificity, recall, F-Score, modularity, Normalized Mutual Information (NMI), betweenness centrality (BTC), and community detection time. Notably, the LS-SLM technique outperforms existing solutions across all metrics. For instance, the proposed methodology achieves an accuracy of 96.32%, surpassing LA by 16% and demonstrating a 10.6% improvement over SBM. Precision, a critical measure of relevance, stands at 96.32%, showcasing a significant advancement over GCR-GAN (61.7%) and CR-HBNE (45.9%). Additionally, sensitivity analysis reveals that the LS-SLM technique achieves the highest sensitivity value of 96.5487%, outperforming LA by 14.2%. The LS-SLM also demonstrates superior specificity and recall, with values of 96.5478% and 96.5487%, respectively. The modularity performance is exceptional, with LS-SLM obtaining 95.6119%, significantly outpacing SLM, FGA, SBM, and LA. Furthermore, the LS-SLM technique excels in community detection time, completing the process in 38,652 ms, showcasing efficiency gains over existing techniques. The BTC analysis indicates that LS-SLM achieves a value of 94.6650%, demonstrating its proficiency in controlling information flow within the network.},
  archive      = {J_JIFS},
  author       = {Rachamadugu, Sandeep Kumar and Pushphavathi, T.P.},
  doi          = {10.3233/JIFS-233851},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {793-809},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Effective community detection with topic modeling in article recommender systems using LS-SLM and PCC-LDA},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical analysis of evolutionary computing approaches
for IoT security assessment. <em>JIFS</em>, <em>48</em>(6), 779–791. (<a
href="https://doi.org/10.3233/JIFS-233759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) strategy enables physical objects to easily produce, receive, and exchange data. IoT devices are getting more common in our daily lives, with diverse applications ranging from consumer sector to industrial and commercial systems. The rapid expansion and widespread use of IoT devices highlight the critical significance of solid and effective cybersecurity standards across the device development life cycle. Therefore, if vulnerability is exploited directly affects the IoT device and the applications. In this paper we investigated and assessed the various real-world critical IoT attacks/vulnerabilities that have affected IoT deployed in the commercial, industrial and consumer sectors since 2010. Subsequently, we evoke the vulnerabilities or type of attack, exploitation techniques, compromised security factors, intensity of vulnerability and impacts of the expounded real-world attacks/vulnerabilities. We first categorise how each attack affects information security parameters, and then we provide a taxonomy based on the security factors that are affected. Next, we perform a risk assessment of the security parameters that are encountered, using two well-known multi-criteria decision-making (MCDM) techniques namely Fuzzy-Analytic Hierarchy Process (F-AHP) and Fuzzy-Analytic Network Process (F-ANP) to determine the severity of severely impacted information security measures.},
  archive      = {J_JIFS},
  author       = {Kumar Sahu, Vinay and Pandey, Dhirendra and Singh, Priyanka and Haque Ansari, Md Shamsul and Khan, Asif and Varish, Naushad and Khan, Mohd Waris},
  doi          = {10.3233/JIFS-233759},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {6},
  pages        = {779-791},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {An empirical analysis of evolutionary computing approaches for IoT security assessment},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid LSTM-graph attention network for
cross-subject analysis on thinking and speaking state using EEG signals.
<em>JIFS</em>, <em>48</em>(5), 767–778. (<a
href="https://doi.org/10.3233/JIFS-233143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, the rapid advancement of deep learning has led to increased interest in utilizing Electroencephalogram (EEG) signals for automatic speech recognition. However, due to the significant variation observed in EEG signals from different individuals, the field of EEG-based speech recognition faces challenges related to individual differences across subjects, which ultimately impact recognition performance. In this investigation, a novel approach is proposed for EEG-based speech recognition that combines the capabilities of Long Short Term Memory (LSTM) and Graph Attention Network (GAT). The LSTM component of the model is designed to process sequential patterns within the data, enabling it to capture temporal dependencies and extract pertinent features. On the other hand, the GAT component exploits the interconnections among data points, which may represent channels, nodes, or features, in the form of a graph. This innovative model not only delves deeper into the connection between connectivity features and thinking as well as speaking states, but also addresses the challenge of individual disparities across subjects. The experimental results showcase the effectiveness of the proposed approach. When considering the thinking state, the average accuracy for single subjects and cross-subject are 65.7% and 67.3% respectively. Similarly, for the speaking state, the average accuracies were 65.4% for single subjects and 67.4% for cross-subject conditions, all based on the KaraOne dataset. These outcomes highlight the model’s positive impact on the task of cross-subject EEG speech recognition. The motivations for conducting cross subject are real world applicability, Generalization, Adaptation and personalization and performance evaluation.},
  archive      = {J_JIFS},
  author       = {Ramkumar, N. and Karthika Renuka, D.},
  doi          = {10.3233/JIFS-233143},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {767-778},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A novel hybrid LSTM-graph attention network for cross-subject analysis on thinking and speaking state using EEG signals},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMF-MF: Interactive moment localization with adaptive
multimodal fusion and self-attention. <em>JIFS</em>, <em>48</em>(5),
755–766. (<a href="https://doi.org/10.3233/JIFS-233071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise video moment retrieval is crucial for enabling users to locate specific moments within a large video corpus. This paper presents Interactive Moment Localization with Multimodal Fusion (IMF-MF), a novel interactive moment localization with multimodal fusion model that leverages the power of self-attention to achieve state-of-the-art performance. IMF-MF effectively integrates query context and multimodal features, including visual and audio information, to accurately localize moments of interest. The model operates in two distinct phases: feature fusion and joint representation learning. The first phase dynamically calculates fusion weights for adapting the combination of multimodal video content, ensuring that the most relevant features are prioritized. The second phase employs bi-directional attention to tightly couple video and query features into a unified joint representation for moment localization. This joint representation captures long-range dependencies and complex patterns, enabling the model to effectively distinguish between relevant and irrelevant video segments. The effectiveness of IMF-MF is demonstrated through comprehensive evaluations on three benchmark datasets: TVR for closed-world TV episodes and Charades for open-world user-generated videos, DiDeMo dataset, Open-world, diverse video moment retrieval dataset. The empirical results indicate that the proposed approach surpasses existing state-of-the-art methods in terms of retrieval accuracy, as evaluated by metrics like Recall (R1, R5, R10, and R100) and Intersection-of-Union (IoU). The results consistently demonstrate IMF-MF’s superior performance compared to existing state-of-the-art methods, highlighting the benefits of its innovative interactive moment localization approach and the use of self-attention for feature representation and attention modeling.},
  archive      = {J_JIFS},
  author       = {Singh, Pratibha and Kushwaha, Alok Kumar Singh and Varshney, Neeraj},
  doi          = {10.3233/JIFS-233071},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {755-766},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {IMF-MF: Interactive moment localization with adaptive multimodal fusion and self-attention},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Further investigation on the super classical mean labeling
of graphs obtained from paths. <em>JIFS</em>, <em>48</em>(5), 747–753.
(<a href="https://doi.org/10.3233/JIFS-232328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider the graph G , with the injection Ω from node set to the first p + q natural numbers. Let us assume that the ceiling function of the classical average of the node labels of the end nodes of each link is the induced link assignment Ω * . If the union of range of Ω of node set and the range of Ω * of link set is all the first p + q natural numbers, then Ω is called a classical mean labeling. A super classical mean graph is a graph with super classical mean labeling. In this research effort, we attempted to address the super classical meanness of graphs generated by paths and those formed by the union of two graphs.},
  archive      = {J_JIFS},
  author       = {Rajesh Kannan, A. and Thirupathi, G. and Murali Krishnan, S.},
  doi          = {10.3233/JIFS-232328},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {747-753},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Further investigation on the super classical mean labeling of graphs obtained from paths},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-task TSK fuzzy system modeling method based on
multi-task fuzzy clustering. <em>JIFS</em>, <em>48</em>(5), 731–746. (<a
href="https://doi.org/10.3233/JIFS-232312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional multi-task Takagi-Sugeno-Kang (TSK) fuzzy system modeling methods pay more attention to utilizing the inter-task correlation to learn the consequent parameters but ignore the importance of the antecedent parameters of the model. To this end, we propose a novel multi-task TSK fuzzy system modeling method based on multi-task fuzzy clustering. This method first proposes a novel multi-task fuzzy c-means clustering method that learns multiple specific clustering centers for each task and some common clustering centers for all tasks. Secondly, for the consequent parameters of the fuzzy system, the novel low-rank and row-sparse constraints are proposed to better implement multi-task learning. The experimental results demonstrate that the proposed model shows better performance compared with other existing methods.},
  archive      = {J_JIFS},
  author       = {Yao, Ziyang},
  doi          = {10.3233/JIFS-232312},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {731-746},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A novel multi-task TSK fuzzy system modeling method based on multi-task fuzzy clustering},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive feature reduction with varied missing data and
feature selection for arthritis disease prediction. <em>JIFS</em>,
<em>48</em>(5), 715–729. (<a
href="https://doi.org/10.3233/JIFS-231537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the expansive domain of data-driven research, the curse of dimensionality poses challenges such as increased computational complexity, noise sensitivity, and the risk of overfitting models. Dimensionality reduction is vital to handle high-dimensional datasets effectively. The pilot study disease dataset (PSD) with 53 features contains patients with Rheumatoid Arthritis (RA) and Osteoarthritis (OA). Our work aims to reduce the dimension of the features in the PSD dataset, identify a suitable feature selection technique for the reduced-dimensional dataset, analyze an appropriate Machine Learning (ML) model, select significant features to predict the RA and OA disease and reveal significant features that predict the arthritis disease. The proposed study, Progressive Feature Reduction with Varied Missing Data (PFRVMD), was employed to reduce the dimension of features by using PCA loading scores in the random value imputed PSD dataset. Subsequently, notable feature selection methods, such as backward feature selection, the Boruta algorithm, the extra tree classifier, and forward feature selection, were implemented on the reduced-dimensional feature set. The significant features/biomarkers are obtained from the best feature selection technique. ML models such as the K-Nearest Neighbour Classifier (KNNC), Linear Discriminant Analysis (LDA), Logistic Regression (LR), Naïve Bayes Classifier (NBC), Random Forest Classifier (RFC) and Support Vector Classifier (SVC) are used to determine the best feature selection method. The results indicated that the Extra Tree Classifier (ETC) is the promising feature selection method for the PSD dataset because the significant features obtained from ETC depicted the highest accuracy on SVC.},
  archive      = {J_JIFS},
  author       = {Ramasamy, Uma and Santhoshkumar, Sundar},
  doi          = {10.3233/JIFS-231537},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {715-729},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Progressive feature reduction with varied missing data and feature selection for arthritis disease prediction},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive evaluation measures of nonlinear estimation
algorithm performance. <em>JIFS</em>, <em>48</em>(5), 705–714. (<a
href="https://doi.org/10.3233/JIFS-231376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many scholars say that their algorithms are better than others in the state estimation problem, only a fewer convincing algorithms were applied to engineering practices. The reason is that their algorithms outperform others only in some aspects such as the estimation accuracy or the computation load. To solve the problem of performance evaluation of state estimation algorithms, in this paper, the comprehensive evaluation measures (CEM) for evaluating the nonlinear estimation algorithm (NEA) is proposed, which can comprehensively reflect the performance of the NEAs. First, we introduce three types of the NEAs. Second, the CEM combining the flatness, estimation accuracy and computation time of the NEAs, is designed to evaluate the above NEAs. Finally, the superiority of the CEM is verified by a numerical example, which helps decision makers of nonlinear estimation algorithms theoretically and technically.},
  archive      = {J_JIFS},
  author       = {Peng, Weishi and Fang, Yangwang and Ma, Yongzhong},
  doi          = {10.3233/JIFS-231376},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {705-714},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Comprehensive evaluation measures of nonlinear estimation algorithm performance},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-disclosure ESG rating method based on the fuzzy set
and reward mechanism of disclosure. <em>JIFS</em>, <em>48</em>(5),
691–703. (<a href="https://doi.org/10.3233/JIFS-230777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The environmental, social, and governance (ESG) rating method is a powerful tool that can help investors to judge the investment value of companies based on the information disclosure. However, mainstream ESG rating methods ignore the distinction between companies with incomplete information disclosure and companies without information disclosure, which decreases the initiative and enthusiasm of companies to disclose information. In this study, a self-disclosure ESG (SDESG) rating method is proposed to evaluate companies’ ESG performance capabilities. First, based on the fuzzy set, fuzzy data is defined and applied to the SDESG rating method. Second, analogous to the academic reward system of a university, a reward mechanism of disclosure is used in the SDESG rating method. Finally, the effectiveness and reliability of the SDESG rating method are demonstrated through Refinitiv’s case. The results show that the SDESG rating method can distinguish companies with incomplete information disclosure from companies without information disclosure and allow companies that proactively disclose information to obtain better ESG scores under each industry. The implications of the study would increase companies’ enthusiasm to disclose information and maintain transparency within a company.},
  archive      = {J_JIFS},
  author       = {Yin, Songyi and Wang, Yu and Fu, Yelin},
  doi          = {10.3233/JIFS-230777},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {691-703},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A self-disclosure ESG rating method based on the fuzzy set and reward mechanism of disclosure},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VIKOR optimization decision model based on poset.
<em>JIFS</em>, <em>48</em>(5), 673–689. (<a
href="https://doi.org/10.3233/JIFS-230680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Vlsekriterijumska Optimizacija I Komprosmisno Resenie (VIKOR) method to some extent modifies the utility function to a value function that can consider different risk preferences. However, the weight and risk attitude parameters involved in the model are difficult to determine, which limits its application. To overcome this problem, a Poset-VIKOR model is proposed. A partial order set is a non-parametric decision-making method. Through the combination of partial order set and VIKOR model, the parameters can be “eliminated”, and a robust method that can run the model is obtained. This method uses the Hasse diagram to express the evaluation results, which can not only directly display the hierarchical and clustering information, but also show the robustness characteristics of the alternative comparison.},
  archive      = {J_JIFS},
  author       = {Yue, Lizhu and Lv, Yue},
  doi          = {10.3233/JIFS-230680},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {673-689},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {VIKOR optimization decision model based on poset},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated license plate authentication framework using
multi-view vehicle images. <em>JIFS</em>, <em>48</em>(5), 645–671. (<a
href="https://doi.org/10.3233/JIFS-230607">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current framework for detecting Fake License Plates (FLP) in real-time is not robust enough for patrol teams. The objective of this paper is to develop a robust license plate authentication framework, based on the Vehicle Make and Model Recognition (VMMR) and the License Plate Recognition (LPR) algorithms that is implementable at the edge devices. The contributions of this paper are (i) Development of license plate database for 547 Indian cars, (ii) Development of an image dataset with 3173 images of 547 Indian cars in 8 classes, (iii) Development of an ensemble model to recognize vehicle make and model from frontal, rear, and side images, and (iv) Development of a framework to authenticate the license plates with frontal, rear, and side images. The proposed ensemble model is compared with the state-of-the-art networks from the literature. Among the implemented networks for VMMR, the Ensembling model with a size of 303.2 MB achieves the best accuracy of 89%. Due to the limited memory size, Easy OCR is chosen to recognize license plate. The total size of the authentication framework is 308 MB. The performance of the proposed framework is compared with the literature. According to the results, the proposed framework enhances FLP recognition due to the recognition of vehicles from side images. The dataset is made public at https://www.kaggle.com/ganeshmailecture/datasets .},
  archive      = {J_JIFS},
  author       = {Ganesh, M.A. and Saravana Perumaal, S. and Gomathi Sankar, S.M.},
  doi          = {10.3233/JIFS-230607},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {645-671},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Automated license plate authentication framework using multi-view vehicle images},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combined unet and CNN image classification model for COVID
disease detection using CXR/CT imaging. <em>JIFS</em>, <em>48</em>(5),
627–643. (<a href="https://doi.org/10.3233/JIFS-230523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate SARS-CoV-2 screening is made possible by automated Computer-Aided Diagnosis (CAD) which reduces the stress on healthcare systems. Since Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) is highly contagious, the transition chain can be broken through an early diagnosis by clinical knowledge and Artificial Intelligence (AI). Manual findings are time and labor-intensive. Even if Reverse Transcription-Polymerase Chain Reaction (RT-PCR) delivers quick findings, Chest X-ray (CXR) imaging is still a more trustworthy tool for disease classification and assessment. Several studies have been conducted using Deep Learning (DL) algorithms for COVID-19 detection. One of the biggest challenges in modernizing healthcare is extracting useful data from high-dimensional, heterogeneous, and complex biological data. Intending to introduce an automated COVID-19 diagnosis model, this paper develops a proficient optimization model that enhances the classification performance with better accuracy. The input images are initially pre-processed with an image filtering approach for noise removal and data augmentation to extend the dataset. Secondly, the images are segmented via U-Net and are given to classification using the Fused U-Net Convolutional Neural Network (FUCNN) model. Here, the performance of U-Net is enhanced through the modified Moth Flame Optimization (MFO) algorithm named Chaotic System-based MFO (CSMFO) by optimizing the weights of U-Net. The significance of the implemented model is confirmed over a comparative evaluation with the state-of-the-art models. Specifically, the proposed CSMFO-FUCNN attained 98.45% of accuracy, 98.63% of sensitivity, 98.98% of specificity, and 98.98% of precision.},
  archive      = {J_JIFS},
  author       = {Haennah, J.H. Jensha and Christopher, C. Seldev and King, G.R. Gnana},
  doi          = {10.3233/JIFS-230523},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {627-643},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Combined unet and CNN image classification model for COVID disease detection using CXR/CT imaging},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel prophet model based on gaussian linear fuzzy
information granule for long-term time series prediction 1.
<em>JIFS</em>, <em>48</em>(5), 611–625. (<a
href="https://doi.org/10.3233/JIFS-230313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper focuses on how to improve the prediction accuracy of time series and the interpretability of prediction results. First, a novel Prophet model based on Gaussian linear fuzzy approximate representation (GF-Prophet) is proposed for long-term prediction, which uniformly predicts the data with consistent trend characteristics. By taking Gaussian linear fuzzy information granules as inputs and outputs, GF-Prophet predicts with significantly smaller cumulative error. Second, noticing that trend extraction affects prediction accuracy seriously, a novel granulation modification algorithm is proposed to merge adjacent information granules that do not have significant differences. This is the first attempt to establish Prophet based on fuzzy information granules to predict trend characteristics. Experiments on public datasets show that the introduction of Gaussian linear fuzzy information granules significantly improves prediction performance of traditional Prophet model. Compared with other classical models, GF-Prophet has not only higher prediction accuracy, but also better interpretability, which can clearly give the change information, fluctuation amplitude and duration of a certain trend in the future that investors actually pay attention to.},
  archive      = {J_JIFS},
  author       = {Yang, Hong and Wang, Lina},
  doi          = {10.3233/JIFS-230313},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {611-625},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {A novel prophet model based on gaussian linear fuzzy information granule for long-term time series prediction 1},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent technique for traffic congestion prediction in
internet of vehicles using randomized machine learning. <em>JIFS</em>,
<em>48</em>(5), 597–609. (<a
href="https://doi.org/10.3233/JIFS-220929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion is a challenging issue faced by people and government traffic agencies. Traffic congestion not only increases travel time but also increases noise pollution, air pollution, and financial losses. There are many factors which affect the speed of a vehicle. Some of the factors are weather, wind speed, road conditions, and construction work. On highways, the low speed of vehicles can cause traffic congestion or delays. Machine learning can play a vital role in the detection of traffic congestion and hence in avoiding delays. When accurate parameters and correct structure are fed to the machine learning model, traffic congestion can be predicted accurately. This paper designs a technique to predict traffic congestion states with the help of the Extra Tree Classifier machine learning model. The proposed Extremely Randomized Machine Learning (ERML) system model predicts 94% accuracy for congestion state classification. It gives better results as compared to other machine learning models.},
  archive      = {J_JIFS},
  author       = {Dureja, Ajay and , Suman and Dureja, Aman and Rathore, Rajkumar Singh},
  doi          = {10.3233/JIFS-220929},
  journal      = {Journal of Intelligent &amp; Fuzzy Systems},
  month        = {3},
  number       = {5},
  pages        = {597-609},
  shortjournal = {J. Intell. Fuzzy Syst.},
  title        = {Intelligent technique for traffic congestion prediction in internet of vehicles using randomized machine learning},
  volume       = {48},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
