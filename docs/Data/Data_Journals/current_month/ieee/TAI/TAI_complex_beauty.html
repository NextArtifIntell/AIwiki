<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tai---24">TAI - 24</h2>
<ul>
<li><details>
<summary>
(2025). DDM-lag: A diffusion-based decision-making model for
autonomous vehicles with lagrangian safety enhancement. <em>TAI</em>,
<em>6</em>(3), 780–791. (<a
href="https://doi.org/10.1109/TAI.2024.3497918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making stands as a pivotal component in the realm of autonomous vehicles (AVs), playing a crucial role in navigating the intricacies of autonomous driving. Amid the evolving landscape of data-driven methodologies, enhancing decision-making performance in complex scenarios has emerged as a prominent research focus. Despite considerable advancements, current learning-based decision-making approaches exhibit potential for refinement, particularly in aspects of policy articulation and safety assurance. To address these challenges, we introduce DDM-Lag, a diffusion decision model, augmented with Lagrangian-based safety enhancements. This work conceptualizes the sequential decision-making challenge inherent in autonomous driving as a problem of generative modeling, adopting diffusion models as the medium for assimilating patterns of decision-making. We introduce a hybrid policy update strategy for diffusion models, amalgamating the principles of behavior cloning and Q-learning, alongside the formulation of an actor–critic architecture for the facilitation of updates. To augment the model&#39;s exploration process with a layer of safety, we incorporate additional safety constraints, employing a sophisticated policy optimization technique predicated on Lagrangian relaxation to refine the policy learning endeavor comprehensively. Empirical evaluation of our proposed decision-making methodology was conducted across a spectrum of driving tasks, distinguished by their varying degrees of complexity and environmental contexts. The comparative analysis with established baseline methodologies elucidates our model&#39;s superior performance, particularly in dimensions of safety and holistic efficacy.},
  archive      = {J_TAI},
  author       = {Jiaqi Liu and Peng Hang and Xiaocong Zhao and Jianqiang Wang and Jian Sun},
  doi          = {10.1109/TAI.2024.3497918},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {780-791},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {DDM-lag: A diffusion-based decision-making model for autonomous vehicles with lagrangian safety enhancement},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive neural network finite-time event triggered
intelligent control for stochastic nonlinear systems with time-varying
constraints. <em>TAI</em>, <em>6</em>(3), 773–779. (<a
href="https://doi.org/10.1109/TAI.2024.3497913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite-time command-filter event-trigger control based on adaptive neural network is presented in this article for a class of output-feedback stochastic nonlinear system (SNS) with output time-varying constraints and unmeasured states. The adaptive neural network combined with backstepping is utilized to approximate the unknown nonlinear functions of the system. The finite-time command-filter is employed to reduce the difficulty of complex calculation caused by backstepping technique. An adaptive observer is developed to estimate unmeasured states, and a controller is designed to be triggered only when the event-triggered condition is met. The time-varying barrier Lyapunov function is utilized to ensure the output time-varying constraint. The control method proposed in this article not only guarantees the finite-time stability of the system but also meets the output constraint. The effectiveness of the method is demonstrated on the ship maneuvering system with three degrees of freedom.},
  archive      = {J_TAI},
  author       = {Jia Liu and Jiapeng Liu and Qing-Guo Wang and Jinpeng Yu},
  doi          = {10.1109/TAI.2024.3497913},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {773-779},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Adaptive neural network finite-time event triggered intelligent control for stochastic nonlinear systems with time-varying constraints},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-level neural-RL-based approach for hierarchical
multiplayer systems under mismatched uncertainties. <em>TAI</em>,
<em>6</em>(3), 759–772. (<a
href="https://doi.org/10.1109/TAI.2024.3493833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI and reinforcement learning (RL) have attracted great attention in the study of multiplayer systems over the past decade. Despite the advances, most of the studies are focused on synchronized decision-making to attain Nash equilibrium, where all the players take actions simultaneously. On the other hand, however, in complex applications, certain players may have an advantage in making sequential decisions and this situation introduces a hierarchical structure and influences how other players respond. The control design for such system is challenging since it relies on solving the coupled Hamilton–Jacobi equation. The situation becomes more difficult when the learning process is exposed to complex uncertainties with unreliable data being exchanged. Therefore, in this article, we develop a new learning-based control approach for a class of nonlinear hierarchical multiplayer systems subject to mismatched uncertainties. Specifically, we first formulate this new problem as a multiplayer Stackelberg–Nash game in conjunction with the hierarchical robust–optimal transformation. Theoretical analysis confirms the equivalence of this transformation and ensures that the designed control policies can achieve stable equilibrium. Then, a two-level neural-RL-based approach is developed to automatically and adaptively learn the solutions. The stability of this online learning process is also provided. Finally, two numerical examples are presented to demonstrate the effectiveness of the developed learning-based robust control design.},
  archive      = {J_TAI},
  author       = {Xiangnan Zhong and Zhen Ni},
  doi          = {10.1109/TAI.2024.3493833},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {759-772},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A two-level neural-RL-based approach for hierarchical multiplayer systems under mismatched uncertainties},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Swin-MGNet: Swin transformer based multiview grouping
network for 3-d object recognition. <em>TAI</em>, <em>6</em>(3),
747–758. (<a href="https://doi.org/10.1109/TAI.2024.3492163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in Swin Transformer have shown its great potential in various computer vision tasks, including image classification, semantic segmentation, and object detection. However, it is challenging to achieve desired performance by directly employing the Swin Transformer in multiview 3-D object recognition since the Swin Transformer independently extracts the characteristics of each view and relies heavily on a subsequent fusion strategy to unify the multiview information. This leads to the problem of the insufficient extraction of interdependencies between the multiview images. To this end, we propose an aggregation strategy integrated into the Swin Transformer to reinforce the connections between internal features across multiple views, thus leading to a complete interpretation of isolated features extracted by the Swin Transformer. Specifically, we utilize Swin Transformer to learn view-level feature representations from multiview images and then calculate their view discrimination scores. The scores are employed to assign the view-level features to different groups. Finally, a grouping and fusion network is proposed to aggregate the features from view and group levels. The experimental results indicate that our method attains state-of-the-art performance compared with prior approaches in multiview 3-D object recognition tasks. The source code is available at https://github.com/Qishaohua94/DEST.},
  archive      = {J_TAI},
  author       = {Xin Ning and Limin Jiang and Weijun Li and Zaiyang Yu and Jinlong Xie and Lusi Li and Prayag Tiwari and Fernando Alonso-Fernandez},
  doi          = {10.1109/TAI.2024.3492163},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {747-758},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Swin-MGNet: Swin transformer based multiview grouping network for 3-D object recognition},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced LiDAR-based localization via multiresolution
iterative closest point algorithms and feature extraction. <em>TAI</em>,
<em>6</em>(3), 738–746. (<a
href="https://doi.org/10.1109/TAI.2024.3491950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle localization is a critical component in autonomous driving systems, and light detection and ranging (LiDAR)-based methods have become increasingly popular for this task. In this article, we present a novel vehicle localization approach based on the point cloud map generated from LiDAR data. In particular, our approach first uses semantic segmentation and feature point extraction techniques to create an efficient feature point map and a long-lasting map from LiDAR sequences with corresponding poses. We then introduce a map-based online localization method that achieves precise vehicle localization using both LiDAR scans and the two point cloud maps, along with a multiresolution ICP strategy. Comprehensive evaluations are conducted on the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) odometry dataset and the collected results demonstrate superior performance over the existing literature in both odometry metrics and absolute translation error. Our multiresolution iterative closest point (ICP)-based method holds significant potential for map-based vehicle localization, offering promising prospects for application in autonomous driving and associated domains.},
  archive      = {J_TAI},
  author       = {Yecheng Lyu and Xinkai Zhang and Feng Tao},
  doi          = {10.1109/TAI.2024.3491950},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {738-746},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enhanced LiDAR-based localization via multiresolution iterative closest point algorithms and feature extraction},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep feature unsupervised domain adaptation for time-series
classification. <em>TAI</em>, <em>6</em>(3), 725–737. (<a
href="https://doi.org/10.1109/TAI.2024.3491948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) for time series classification (TSC) is an important but challenging task. In the process of UDA, feature learning is most critical. Most of the existing works in this area are based on learning domain-invariant feature representation of data with help of some restriction such as MMD. However, they ignored that the mutual effects between the pretrained network and the downstream target network was also conducive to the learning of domain-invariant features. In this article, we propose a deep feature unsupervised domain adaptation (DFUDA) for time series classification. First, we pretrain a network based on consistency learning to ensure the invariant feature extraction from the source and target domains. Then, we propose an end-to-end unsupervised domain adaptation, which includes the layer matching and the unsupervised domain adaptation to promote more confident knowledge transfer. Finally, the pretrained network receives feedback of the domain adaptation&#39;s performance. To verify the effectiveness of the proposed method, we perform the comprehensive experiments on fault diagnosis datasets and human activity recognition datasets. The results show that DFUDA outperforms the state of the arts methods for both scenarios.},
  archive      = {J_TAI},
  author       = {Nannan Lu and Tong Yan and Song Zhu and Jiansheng Qian and Min Han},
  doi          = {10.1109/TAI.2024.3491948},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {725-737},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep feature unsupervised domain adaptation for time-series classification},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiattribute deep CNN-based approach for detecting
medicinal plants and their use for skin diseases. <em>TAI</em>,
<em>6</em>(3), 710–724. (<a
href="https://doi.org/10.1109/TAI.2024.3491938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin health is a critical concern for humans, especially in geographical areas where environmental conditions and lifestyle factors adversely affect their condition, leading to a prevalence of skin diseases. This issue is exacerbated in rural regions, like parts of India, where a notable dermatologist shortage exists, leading to overlooked skin diseases. In response, the use of medicinal plants for dermatological purposes has been a longstanding tradition. However, traditional plant identification often relies on a single attribute, such as leaves or flowers, which can be unreliable due to seasonal variations. This article introduces a novel approach for accurately identifying medicinal plants using a multiattribute deep convolutional neural network. This approach aims to bridge the gap in healthcare access by empowering individuals to recognize and utilize these plants effectively. Our objective is to develop a robust deep CNN model trained on a diverse dataset of images encompassing leaves, trunks, and seeds of medicinal plants associated with skin health. Our findings demonstrate that the model achieves high accuracy in plant identification, effectively addressing the limitations of single-attribute methods. This research not only contributes to the field of medicinal plant classification but also empowers individuals to make informed decisions about their skin health while preserving valuable traditional knowledge.},
  archive      = {J_TAI},
  author       = {Prachi Dalvi and Dhananjay R. Kalbande and Surendra Singh Rathod and Harshal Dalvi and Amey Agarwal},
  doi          = {10.1109/TAI.2024.3491938},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {710-724},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Multiattribute deep CNN-based approach for detecting medicinal plants and their use for skin diseases},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NL-CoWNet: A deep convolutional encoder–decoder architecture
for OCT speckle elimination using nonlocal and subband modulated DT-CWT
blocks. <em>TAI</em>, <em>6</em>(3), 700–709. (<a
href="https://doi.org/10.1109/TAI.2024.3491935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical coherence tomography (OCT), a noninvasive diagnostic technology for identifying and treating various ocular diseases, encounters a loss of image quality due to the introduction of speckles during the image creation process, compromising the precision of disease diagnosis. Researchers have proposed numerous deep convolutional networks to address speckle artifacts in OCT images. This article presents a novel deep convolutional encoder–decoder framework called NL-CoWNet for speckle elimination in OCT images. This despeckling architecture consists of an encoder network having the topology of ResNet34, whose certain feature vectors are passed through nonlocal (NL) neural network blocks and a novel subband modulated dual-tree complex wavelet (CoW) transform (DT-CWT) blocks, followed by a decoder unit with upsampling layers and channel-wise squeeze and excitation (CSE) convolutional blocks. Our network architecture has been validated after numerous ablation studies. Qualitative and quantitative assessments with contemporary and established methodologies have proven that NL-CoWNet excels conspicuously in speckle removal while preserving the structural features of the image.},
  archive      = {J_TAI},
  author       = {P. S. Arun and Bibin Francis and Varun P. Gopi},
  doi          = {10.1109/TAI.2024.3491935},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {700-709},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {NL-CoWNet: A deep convolutional Encoder–Decoder architecture for OCT speckle elimination using nonlocal and subband modulated DT-CWT blocks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semisupervised breast MRI density segmentation integrating
fine and rough annotations. <em>TAI</em>, <em>6</em>(3), 690–699. (<a
href="https://doi.org/10.1109/TAI.2024.3491693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces an enhanced teacher–student model featuring a novel Vnet architecture that integrates high-pass and low-pass filters to improve the segmentation of breast magnetic resonance imaging (MRI) images. The model effectively utilizes finely annotated, roughly annotated, and unannotated data to achieve precise breast tissue density segmentation. The teacher–student framework incorporates three specialized Vnet networks, each tailored to different types of annotations. By integrating cosine contrast loss functions between finely and roughly annotated models, and innovatively applying high-pass and low-pass filters within the Vnet architecture, the segmentation performance is significantly enhanced. This hybrid filtering approach enables the model to capture both fine-grained and coarse structural details, leading to more accurate segmentation across various MRI image datasets. Experimental results demonstrate the superiority of the proposed method, achieving Dice values of 0.833 on the finely annotated Shenzhen dataset and 0.780 on the Duke dataset, using 15 finely annotated, 15 roughly annotated, and 58 unlabeled samples provided by Shenzhen People&#39;s Hospital. These findings underscore its potential clinical application in breast density assessment.},
  archive      = {J_TAI},
  author       = {Tianyu Xie and Yue Sun and Hongxu Yang and Shuo Li and Jinhong Song and Qimin Yang and Hao Chen and Mingxiang Wu and Tao Tan},
  doi          = {10.1109/TAI.2024.3491693},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {690-699},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Semisupervised breast MRI density segmentation integrating fine and rough annotations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-heterogeneous federated graph learning with prototype
propagation. <em>TAI</em>, <em>6</em>(3), 676–689. (<a
href="https://doi.org/10.1109/TAI.2024.3490557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated graph learning (FGL) enables clients to collaboratively train a robust graph neural network (GNN) while ensuring their private graph data never leaves the local. However, existing FGL frameworks require all clients to train the identical GNN model, which limits their real-world applicability. Although many model-heterogenous frameworks have been proposed for traditional nongraph federated learning settings, directly transferring them to the FGL setting typically results in suboptimal performance. To fill the gap, this article presents federated prototype propagation network (FedPPN), a lightweight FGL framework that supports clients to train fully customized models. FedPPN only transmits prototypes between clients and the server for knowledge sharing. The core idea is propagating global prototypes on each client&#39;s local graph, generating prototype-based node representations and predictions. The prototype-based prediction can then be ensembled with the prediction of local GNN, allowing clients to achieve accurate prediction. We evaluate our FedPPN on six benchmark datasets with different heterogeneous model setups. Experimental results show that our FedPPN outperforms advanced baselines in model accuracy without adding any trainable parameters on clients or the server. Besides, FedPPN&#39;s communication cost is significantly lower than methods that rely on model parameter exchange.},
  archive      = {J_TAI},
  author       = {Zhi Liu and Hanlin Zhou and Xiaohua He and Haopeng Yuan and Jiaxin Du and Mengmeng Wang and Guojiang Shen and Xiangjie Kong and Feng Xia},
  doi          = {10.1109/TAI.2024.3490557},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {676-689},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Model-heterogeneous federated graph learning with prototype propagation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging the climate gap: Multimodel framework with
explainable decision-making for IOD and ENSO forecasting. <em>TAI</em>,
<em>6</em>(3), 661–675. (<a
href="https://doi.org/10.1109/TAI.2024.3489535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of the Indian Ocean Dipole (IOD) and El-Niño-Southern Oscillation (NINO3.4) is crucial for understanding regional weather patterns in the Indian subcontinent. Addressing the challenges associated with IOD and NINO3.4 prediction, a robust multitask autoregressive deep learning (DL) model is introduced for precise forecasting of these indices and key grid projections sea surface temperature (SST), surface-level pressure gradient (SLG), and horizontal wind velocity (U-Comp) over a short to mid-term window (20 months). Utilizing spatiotemporal (SST, SLG, U-Comp) and temporal (IOD and NINO3.4) modalities, the proposed model predicts future IOD and NINO3.4, as well as SST, SLG, and U-Comp, in an autoregressive scheme. The multitask learning component regularizes the model, effectively capturing the evolving dynamics of global patterns conditioned on IOD and NINO3.4. The comprehensive evaluation explores various task settings, including a duo-setting that predicts IOD or NINO3.4 with spatiotemporal information, showcasing notable proficiency. In a multitask environment, where both temporal IOD, NINO3.4, and spatiotemporal SST, SLG, U-Comp are predicted, the model successfully forecasts IOD and NINO3.4 indices alongside grid projections with modest accuracy in root mean square error (RMSE). To enhance the model&#39;s interpretability regarding spatiotemporal dynamics, a tailored version of Grad-CAM is employed, providing critical insights for climate prediction. This research advances climate prediction models, offering a comprehensive framework with significant implications for informed decision-making in the Indian subcontinent&#39;s climatic context.},
  archive      = {J_TAI},
  author       = {Harshit Tiwari and Prashant Kumar and Ramakant Prasad and Kamlesh Kumar Saha and Anurag Singh and Hocine Cherifi and Rajni},
  doi          = {10.1109/TAI.2024.3489535},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {661-675},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Bridging the climate gap: Multimodel framework with explainable decision-making for IOD and ENSO forecasting},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-based ensemble learning model to identify
antigenic fragments of SARS-CoV-2. <em>TAI</em>, <em>6</em>(3), 651–660.
(<a href="https://doi.org/10.1109/TAI.2024.3487149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of epitope-based vaccines (EBVs) necessitates the identification of antigenic fragments (AFs) of the target pathogen known as T-cell epitopes (TCEs). TCEs are recognized by immune system, specifically by T cells, B cells, and antibodies. Traditional wet lab methods for identifying TCEs are often costly, challenging, and time-consuming compared to computational approaches. In this study, we propose a neural network-based ensemble machine learning (ML) model trained on physicochemical properties of SARS-CoV-2 peptides sequences to predict TCE sequences. The performance of the model assessed using test dataset demonstrated an accuracy of &gt;95%, surpassing the results of other ML classifiers that were employed for comparative analysis. Through fivefold cross-validation technique, a mean accuracy of approximately 95% was reported. Additionally, when compared to other existing TCE prediction methods using a blind dataset, the proposed model was found to be more accurate and effective. The predicted epitopes may have a strong probability to act as potential vaccine candidates. Nonetheless, it is imperative to subject these epitopes to further scientific examination both in vivo and in vitro, to confirm their suitability as vaccine candidates.},
  archive      = {J_TAI},
  author       = {Syed Nisar Hussain Bukhari and Kingsley A. Ogudo},
  doi          = {10.1109/TAI.2024.3487149},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {651-660},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Neural network-based ensemble learning model to identify antigenic fragments of SARS-CoV-2},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Att2CPC: Attention-guided lossy attribute compression of
point clouds. <em>TAI</em>, <em>6</em>(3), 639–650. (<a
href="https://doi.org/10.1109/TAI.2024.3486676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the great progress of three-dimensional (3-D) sensing and acquisition technology, the volume of point cloud data has grown dramatically, which urges the development of efficient point cloud compression methods. In this article, we focus on the task of learned lossy point cloud attribute compression (PCAC). We propose an efficient attention-based method for lossy compression of point cloud attributes leveraging on an autoencoder architecture. Specifically, at the encoding side, we conduct multiple downsampling to best exploit the local attribute patterns, in which effective external cross attention (ECA) is devised to hierarchically aggregate features by intergrating attributes and geometry contexts. At the decoding side, the attributes of the point cloud are progressively reconstructed based on the multiscale representation and the zero-padding upsampling tactic. To the best of our knowledge, this is the first approach to introduce attention mechanism to point-based lossy PCAC task. We verify the compression efficiency of our model on various sequences, including human body frames, sparse objects, and large-scale point cloud scenes. Experiments show that our method achieves an average improvement of 1.15 and 2.13 dB in Bjontegaard delta (BD)-peak signal-to-noise ratio (BD-PSNR) of Y channel and YUV channel, respectively, when comparing with the state-of-the-art point-based method deep-PCAC. Codes of this article are available at https://github.com/I2-Multimedia-Lab/Att2CPC.},
  archive      = {J_TAI},
  author       = {Kai Liu and Kang You and Pan Gao and Manoranjan Paul},
  doi          = {10.1109/TAI.2024.3486676},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {639-650},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Att2CPC: Attention-guided lossy attribute compression of point clouds},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NICASU: Neurotransmitter inspired cognitive AI architecture
for surveillance underwater. <em>TAI</em>, <em>6</em>(3), 626–638. (<a
href="https://doi.org/10.1109/TAI.2024.3486675">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain is exceedingly good at learning rich narratives from highly limited experiences. One of the ways this is achieved in our brain is through neuromodulators or neurotransmitters, such as dopamine and nor-epinephrine, in cortical circuits. In terms of symbolic processing, these neuromodulators add “salience” to various emotions and experiences. A salience-based neural network (SANN) architecture was proposed in [1]. We have taken this architecture and have developed a discriminator to enable efficient change detection for underwater applications. In the context of underwater, surveillance can be elucidated as one of the processes of detecting and tracking the moving objects present in underwater videos. Several researchers working on the same tried to develop different techniques for identifying moving objects from outdoor scenes. However, while applying the same for underwater environments, it is found to be unable to preserve the minute details that are important for defining an object&#39;s boundary. This is mainly due to the complex scene dynamics of the aquatic environment. Moreover, the intricate natural properties of water and some of its characteristics, such as excessive turbidity, scattering, and low visibility, also make the task of detecting the object present in underwater videos extremely challenging. In this regard, we put forth an adversarial learning-based end-to-end deep learning architecture inspired by the way neurotransmitters work in the human brain to detect underwater moving objects. The proposed architecture uses two modules for underwater object detection. The initial module is a generator composed of a probabilistic learner which is based on multiple down- and up-sampling modules. Further, the discriminator network is composed of a multilevel feature-concatenation component, which can perpetuate specifics at distinct levels. The effectiveness of the proposed method (PM) is confirmed using the underwater change detection and Fish4Knowledge benchmark datasets by contrasting its outcomes with those of different state-of-the-art methods.},
  archive      = {J_TAI},
  author       = {Mehvish Nissar and Badri Narayan Subudhi and Amit Kumar Mishra and Vinit Jakhetiya},
  doi          = {10.1109/TAI.2024.3486675},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {626-638},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {NICASU: Neurotransmitter inspired cognitive AI architecture for surveillance underwater},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image tampering detection with frequency-aware attention and
multiview fusion. <em>TAI</em>, <em>6</em>(3), 614–625. (<a
href="https://doi.org/10.1109/TAI.2024.3486671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulated images are flooding our daily lives, which poses a threat to social security. Recently, many studies have focused on image tampering detection. However, they have poor performance on independent validation due to differences in image scenes and tampering methods. The key question is how to design a network that is able to adaptively enhance the tampering information and suppress the generalization features during training. To this end, we propose a dual-branch network with a frequency adaptation paradigm and a feature fusion module for robust tampering image detection. First, this paradigm is designed to adaptively highlight tampering features through frequency conversion and learnable weight. Second, a feature fusion module is developed to filter redundant features and dynamically fuse two-branch features. Experiments on eight typical datasets demonstrate that our model has advantages over state-of-the-art algorithms, and our paradigm can well empower semantic segmentation networks for tampering detection.},
  archive      = {J_TAI},
  author       = {Xu Xu and Junxin Chen and Wenrui Lv and Wei Wang and Yushu Zhang},
  doi          = {10.1109/TAI.2024.3486671},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {614-625},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Image tampering detection with frequency-aware attention and multiview fusion},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDA-GAN: Multiscale and dual attention generative
adversarial network for bone suppression in chest x-rays. <em>TAI</em>,
<em>6</em>(3), 604–613. (<a
href="https://doi.org/10.1109/TAI.2024.3483731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bone structure in a chest x-ray creates trouble for a radiologist to examine the organs, manifestation of disease, and hidden tiny abnormalities. Bone suppression in chest x-rays allows better examination of lung fields. This has the potential to improve diagnostic accuracy. Dual-energy subtraction imaging is a standard bone suppression technique that delivers a higher dose of radiation and requires specific hardware. This article proposes a novel multiscale and dual attention-guided generative adversarial network (MDA-GAN) to transform chest x-rays into bone-suppressed x-rays in an unsupervised manner. We incorporate a spatial attention module to generate attention maps that were further concatenated with the coarsely generated bone segmentation mask. This dual attention is introduced to the generator at multiple scales in between the skip connection of the encoder and decoder layer. The proposed dual attention multiscale mechanism helps the generator to learn that only bones need to be removed on the chest x-ray without tempering the remaining parts. The proposed MDA-GAN is trained with adversarial loss combined with deep supervised cycle consistency and structure similarity for unpaired training images. We employ supervision heads in all the decoder layers to convert the activation maps into an output comparable to the scaled-down images and minimize the cycle consistency loss in a deep supervised manner. Experiments are conducted on an unpaired dataset including the public and our in-house Indian dataset and results show that incorporating dual attention at multiple scales and deep cycle consistency in translation networks significantly improves the quality of bone-suppressed images. (https://github.com/rB080/ribsup.git.)},
  archive      = {J_TAI},
  author       = {Anushikha Singh and Rukhshanda Hussain and Rajarshi Bhattacharya and Brejesh Lall and B.K. Panigrahi and Anjali Agrawal and Anurag Agrawal and Balamugesh Thangakunam and D.J. Christopher},
  doi          = {10.1109/TAI.2024.3483731},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {604-613},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {MDA-GAN: Multiscale and dual attention generative adversarial network for bone suppression in chest X-rays},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prompt learning for few-shot question answering via
self-context data augmentation. <em>TAI</em>, <em>6</em>(3), 589–603.
(<a href="https://doi.org/10.1109/TAI.2024.3483201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pretrained language models (PLMs) have shown remarkable performance on question answering (QA) tasks, but they usually require fine-tuning (FT) that depends on a substantial quantity of QA pairs. Therefore, improving the performance of PLMs in scenarios with only a small number of training examples, also known as a few-shot setting, is of great practical significance. Current mitigation strategies for the few-shot QA task largely rely on pretraining a QA task-specific language model from scratch, overlooking the potential of foundational PLMs to generate QA pairs, particularly in the few-shot setting. To address this issue, we propose a prompt-based QA data augmentation method aimed at automating the creation of high-quality QA pairs. It employs the PFT method, adapting the question generation process of PLMs to the few-shot setting. Additionally, we introduce a dynamic text filling training strategy. This strategy simulates the progressive human learning process, thereby alleviating overfitting of PLMs in the few-shot setting and enhancing their reasoning capability to tackle complex questions. Extensive experiments demonstrate that the proposed method outperforms existing approaches across various few-shot configurations.},
  archive      = {J_TAI},
  author       = {Jian-Qiang Qiu and Chun-Yang Zhang and C. L. Philip Chen},
  doi          = {10.1109/TAI.2024.3483201},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {589-603},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Prompt learning for few-shot question answering via self-context data augmentation},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized learning path problem variations: Computational
complexity and AI approaches. <em>TAI</em>, <em>6</em>(3), 574–588. (<a
href="https://doi.org/10.1109/TAI.2024.3483190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-learning courses often suffer from high dropout rates and low student satisfaction. One way to address this issue is to use personalized learning paths (PLPs), which are sequences of learning materials that meet the individual needs of students. However, creating PLPs is difficult and often involves combining knowledge graphs (KGs), student profiles, and learning materials. Researchers typically assume that the problem of creating PLPs belong to the nondeterministic polynomial (NP)-hard class of computational problems. However, previous research in this field has neither defined the different variations of the PLP problem nor formally established their computational complexity. Without clear definitions of the PLP variations, researchers risk making invalid comparisons and conclusions when they use different metaheuristics for different PLP problems. To unify this conversation, this article formally proves the NP-completeness of two common PLP variations and their generalizations and uses them to categorize recent research in the PLP field. It then presents an instance of the PLP problem using real-world data and shows how this instance can be cast into two different NP-complete variations. This article then presents three artificial intelligence (AI) strategies, solving one of the PLP variations with back-tracking and branch and bound heuristics and also converting the PLP variation instance to XCSP${}^{3}$, an intermediate constraint satisfaction language to be resolved with a general constraint optimization solver. This article solves the other PLP variation instance using a greedy search heuristic. The article finishes by comparing the results of the two different PLP variations.},
  archive      = {J_TAI},
  author       = {Sean A. Mochocki and Mark G. Reith and Brett J. Borghetti and Gilbert L. Peterson and John D. Jasper and Laurence D. Merkle},
  doi          = {10.1109/TAI.2024.3483190},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {574-588},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Personalized learning path problem variations: Computational complexity and AI approaches},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffexplainer: A framework toward GNN-based interpretable
traffic prediction. <em>TAI</em>, <em>6</em>(3), 559–573. (<a
href="https://doi.org/10.1109/TAI.2024.3459857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing traffic congestion problems in metropolises, traffic prediction plays an essential role in intelligent traffic systems. Notably, various deep learning models, especially graph neural networks (GNNs), achieve state-of-the-art performance in traffic prediction tasks but still lack interpretability. To interpret the critical information abstracted by traffic prediction models, we proposed a flexible framework termed Traffexplainer toward GNN-based interpretable traffic prediction. Traffexplainer is applicable to a wide range of GNNs without making any modifications to the original model structure. The framework consists of the GNN-based traffic prediction model and the perturbation-based hierarchical interpretation generator. Specifically, the hierarchical spatial mask and temporal mask are introduced to perturb the prediction model by modulating the values of input data. Then the prediction losses are backward propagated to the masks, which can identify the most critical features for traffic prediction, and further improve the prediction performance. We deploy the framework with five representative GNN-based traffic prediction models and analyze their prediction and interpretation performance on three real-world traffic flow datasets. The experiment results demonstrate that our framework can generate effective and faithful interpretations for GNN-based traffic prediction models, and also improve the prediction performance. The code will be publicly available at https://github.com/lingbai-kong/Traffexplainer.},
  archive      = {J_TAI},
  author       = {Lingbai Kong and Hanchen Yang and Wengen Li and Yichao Zhang and Jihong Guan and Shuigeng Zhou},
  doi          = {10.1109/TAI.2024.3459857},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {559-573},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Traffexplainer: A framework toward GNN-based interpretable traffic prediction},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReLAQA: Reinforcement learning-based autonomous quantum
agent for quantum applications. <em>TAI</em>, <em>6</em>(3), 549–558.
(<a href="https://doi.org/10.1109/TAI.2024.3437335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a quantum reinforcement learning (QRL) approach for robotic applications, which incorporates a Grover-based autonomous quantum agent (GAQA) and a quantum environment represented as a quantum TicTacToe (QTTT) game. The QTTT environment is a quantum circuit of qubits in their superposition states, manipulated by the agent through quantum gates to establish a goal state. By utilizing amplitude estimation and Grover search techniques, the proposed reinforcement learning-based autonomous quantum agent (ReLAQA) enhances the probability amplitudes of the actions taken, which results in reducing the number of observed states required to reach a solution. Empirical results substantiate the quantum advantages of the proposed GAQA in reinforcement learning (RL) tasks by observing fewer states of 6300, outperforming classical agents. Therefore, signifying its potential to enhance complex problem-solving in robotics.},
  archive      = {J_TAI},
  author       = {Ahmad Alomari and Sathish A. P. Kumar},
  doi          = {10.1109/TAI.2024.3437335},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {549-558},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ReLAQA: Reinforcement learning-based autonomous quantum agent for quantum applications},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep-learning-based uncertainty-estimation approach for
unknown traffic identification. <em>TAI</em>, <em>6</em>(3), 533–548.
(<a href="https://doi.org/10.1109/TAI.2024.3437332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real open network environments include the traffic generated by known applications or protocols, which have been previously identified and labeled, and unknown network traffic that cannot be identified based on existing knowledge. Accurately identifying unknown traffic is critical to network management and security, not only to help managers allocate bandwidth appropriately for all types of applications and ensure quality of service but also to prevent security breaches that may result from unknown applications or protocols. Notably, the unknown network traffic has been increasing with the emergence of new applications or protocols, which further increases the difficulty in identifying them. Existing unknown traffic classification methods based on Softmax output confidence values cause bias in the prediction probability due to overconfidence of the model during the training process, thus decreasing the identification accuracy. Thus, for unknown traffic identification, this study proposes a deep-learning-based uncertainty-estimation (EUE) approach. EUE introduces the theory of evidence to the task of identifying unknown traffic by inferring traffic uncertainty directly from traffic evidence without the need for a Softmax layer, thus avoiding overconfidence in the model. Thus, the EUE can accurately identify unknown traffic while classifying known traffic at the application level. We construct two experimental scenarios simulating the real network environments with different proportions of unknown traffic to evaluate EUE. The experimental results show that the proposed approach EUE exhibits excellent classification accuracy.},
  archive      = {J_TAI},
  author       = {Siqi Le and Yingxu Lai and Yipeng Wang and Huijie He},
  doi          = {10.1109/TAI.2024.3437332},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {533-548},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep-learning-based uncertainty-estimation approach for unknown traffic identification},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evolutionary multitasking algorithm for efficient
multiobjective recommendations. <em>TAI</em>, <em>6</em>(3), 518–532.
(<a href="https://doi.org/10.1109/TAI.2024.3414289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Represented by evolutionary algorithms and swarm intelligence algorithms, nature-inspired metaheuristics have been successfully applied to recommender systems and amply demonstrated effectiveness, in particular, for multiobjective recommendation. Owing to the population-based search paradigm, these algorithms can produce a number of recommendation lists, making diverse tradeoffs between multiple metrics and meeting the requirements of accuracy, novelty, diversity, and other user preferences. However, these algorithms are criticized for the low efficiency of the optimization process, especially when the number of users is large. To address this issue, this article proposes an evolutionary multitasking-based recommendation method, where each task corresponds to a user and all the tasks are optimized simultaneously, thus highly improving the efficiency of recommendation. To enhance the convergence speed, all the users are divided into multiple populations according to the similarity between their preferences, where each population evolves with internal knowledge transfer between users, and all the populations evolve with external knowledge transfer between populations. Experimental results on various datasets verify that the proposed method can better balance between multiple metrics than classical and deep neural network-based recommendation methods and exhibits significantly higher efficiency than evolutionary multiobjective optimization-based recommendation methods.},
  archive      = {J_TAI},
  author       = {Ye Tian and Luke Ji and Yiwei Hu and Haiping Ma and Le Wu and Xingyi Zhang},
  doi          = {10.1109/TAI.2024.3414289},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {518-532},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {An evolutionary multitasking algorithm for efficient multiobjective recommendations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regret and belief complexity tradeoff in gaussian process
bandits via information thresholding. <em>TAI</em>, <em>6</em>(3),
508–517. (<a href="https://doi.org/10.1109/TAI.2023.3332023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian optimization is a powerful framework for global search, using maximum a posteriori updates instead of simulated annealing. We cast it as a multiarmed bandit problem with a Gaussian process (GP) for the payoff function. Action selections rely on upper confidence bound (UCB) or expected improvement (EI). Prior works with GPs faced challenges for large iteration horizons ($T$) due to cubic scaling in posterior computation. To address this, we propose a simple thresholding: incorporating an action into the GP posterior only when its conditional entropy surpasses $\epsilon$. Doing so permits us to precisely characterize the tradeoff between regret bounds of GP bandit algorithms and complexity of the posterior distributions depending on the compression parameter $\epsilon$ for both discrete and continuous action sets. To best of our knowledge, this is the first result which allows us to obtain sublinear regret bounds while still maintaining sublinear growth rate of the complexity of the posterior which is linear in the existing literature. Moreover, a provably finite bound on the complexity could be achieved but the algorithm would result in $\epsilon$-regret which means $\textbf{Reg}_{T}/T\rightarrow\mathcal{O}(\epsilon)$ as $T\rightarrow\infty$. Experiments demonstrate state-of-the-art accuracy and complexity tradeoffs for GP bandit algorithms in global optimization, highlighting the benefits of compressed GPs in bandit settings.},
  archive      = {J_TAI},
  author       = {Amrit Singh Bedi and Dheeraj Peddireddy and Vaneet Aggarwal and Brian M. Sadler and Alec Koppel},
  doi          = {10.1109/TAI.2023.3332023},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {508-517},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Regret and belief complexity tradeoff in gaussian process bandits via information thresholding},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair machine learning in healthcare: A survey. <em>TAI</em>,
<em>6</em>(3), 493–507. (<a
href="https://doi.org/10.1109/TAI.2024.3361836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digitization of healthcare data coupled with advances in computational capabilities has propelled the adoption of machine learning (ML) in healthcare. However, these methods can perpetuate or even exacerbate existing disparities, leading to fairness concerns such as the unequal distribution of resources and diagnostic inaccuracies among different demographic groups. Addressing these fairness problems is paramount to prevent further entrenchment of social injustices. In this survey, we analyze the intersection of fairness in ML and healthcare disparities. We adopt a framework based on the principles of distributive justice to categorize fairness concerns into two distinct classes: equal allocation and equal performance. We provide a critical review of the associated fairness metrics from a ML standpoint and examine biases and mitigation strategies across the stages of the ML lifecycle, discussing the relationship between biases and their countermeasures. The article concludes with a discussion on the pressing challenges that remain unaddressed in ensuring fairness in healthcare ML and proposes several new research directions that hold promise for developing ethical and equitable ML applications in healthcare.},
  archive      = {J_TAI},
  author       = {Qizhang Feng and Mengnan Du and Na Zou and Xia Hu},
  doi          = {10.1109/TAI.2024.3361836},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {3},
  number       = {3},
  pages        = {493-507},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Fair machine learning in healthcare: A survey},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
