<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JPDC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jpdc---5">JPDC - 5</h2>
<ul>
<li><details>
<summary>
(2025). The (t,k)-diagnosability of cayley graph generated by
2-tree. <em>JPDC</em>, <em>200</em>, 105068. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiprocessor systems, which typically use interconnection networks (or graphs) as underlying topologies, are widely utilized for big data analysis in scientific computing due to the advancements in technologies such as cloud computing, IoT, social network. With the dramatic expansion in the scale of multiprocessor systems, the pursuit and optimization of strategies for identifying faulty processors have become crucial to ensuring the normal operation of high-performance computing systems. System-level diagnosis is a process designed to distinguish between faulty processors and fault-free processors in multiprocessor systems. The ( t , k ) -diagnosis, a generalization of sequential diagnosis, proceeds to identify at least k faulty processors and repair them in each iteration under the assumption that there are at most t faulty processors whenever t ≥ k . We show that Cayley graph generated by 2-tree is ( 2 n − 3 , 2 n − 4 ) -diagnosable under the PMC model for n ≥ 5 while it is ( 2 n − 3 ( 2 n − 6 ) 2 n − 4 , 2 n − 4 ) -diagnosable under the MM ⁎ model for n ≥ 4 . As an empirical case study, the ( t , k ) -diagnosabilities of the alternating group graph A G n under the PMC model and the MM* model have been determined.},
  archive      = {J_JPDC},
  author       = {Lulu Yang and Shuming Zhou and Eddie Cheng},
  doi          = {10.1016/j.jpdc.2025.105068},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105068},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {The (t,k)-diagnosability of cayley graph generated by 2-tree},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data quality management in big data: Strategies, tools, and
educational implications. <em>JPDC</em>, <em>200</em>, 105067. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the critical need for effective Big Data Quality Management (BDQM) in education, a field where data quality has profound implications but remains underexplored. The work systematically progresses from requirement analysis and standard development to the deployment of tools for monitoring and enhancing data quality in big data workflows. The study&#39;s contributions are substantiated through five research questions that explore the impact of data quality on analytics, the establishment of evaluation standards, centralized management strategies, improvement techniques, and education-specific BDQM adaptations. By addressing these questions, the research advances both theoretical and practical frameworks, equipping stakeholders with the tools to enhance the reliability and efficiency of data-driven educational initiatives. Integrating Artificial Intelligence (AI) and distributed computing, this research introduces a novel multi-stage BDQM framework that emphasizes data quality assessment, centralized governance, and AI-enhanced improvement techniques. This work underscores the transformative potential of robust BDQM systems in supporting informed decision-making and achieving sustainable outcomes in educational projects. The survey findings highlight the potential for automated data management within big data architectures, suggesting that data quality frameworks can be significantly enhanced by leveraging AI and distributed computing. Additionally, the survey emphasizes emerging trends in big data quality management, specifically (i) automated data cleaning and cleansing and (ii) data enrichment and augmentation.},
  archive      = {J_JPDC},
  author       = {Thu Nguyen and Hong-Tri Nguyen and Tu-Anh Nguyen-Hoang},
  doi          = {10.1016/j.jpdc.2025.105067},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105067},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Data quality management in big data: Strategies, tools, and educational implications},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMI-GPU: Inverted multi-index for billion-scale approximate
nearest neighbor search with GPUs. <em>JPDC</em>, <em>200</em>, 105066.
(<a href="https://doi.org/10.1016/j.jpdc.2025.105066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity search is utilized in specialized database systems designed to handle multimedia data, often represented by high-dimensional features. In this paper, we focus on speeding up the search process with GPUs. This problem has been previously approached by accelerating the Inverted File with Asymmetric Distance Computation algorithm on GPUs (IVFADC-GPU). However, the most recent algorithm for CPU, Inverted Multi-Index (IMI), was not considered for parallelization, being found too challenging for efficient GPU deployment. Thus, we propose a novel and efficient version of IMI for GPUs called IMI-GPU. We propose a new design of the multi-sequence algorithm of IMI, enabling efficient GPU execution. We compared IMI-GPU with IVFADC-GPU using a billion-scale dataset in which IMI-GPU achieved speedups of about 3.2× and 1.9× at Recall@1 and at Recall@16 respectively. The algorithms have been compared in a variety of scenarios and our novel IMI-GPU has shown to significantly outperform IVFADC on GPUs for the majority of tested cases.},
  archive      = {J_JPDC},
  author       = {Alan Araujo and Willian Barreiros Jr. and Jun Kong and Renato Ferreira and George Teodoro},
  doi          = {10.1016/j.jpdc.2025.105066},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105066},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {IMI-GPU: Inverted multi-index for billion-scale approximate nearest neighbor search with GPUs},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed landmark labeling for social networks.
<em>JPDC</em>, <em>200</em>, 105057. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance queries are a fundamental part of many network analysis applications. They can be used to infer the closeness of two users in social networks, the relation between two sites in a web graph, or the importance of the interaction between two proteins or molecules. Being able to answer these queries rapidly has many benefits in the area of network analysis. Pruned Landmark Labeling ( Pll ) is a technique used to generate an index for a given graph that allows the shortest path queries to be completed in a fraction of the time when compared to a standard breadth-first or a depth-first search-based algorithm. Parallel Shortest-distance Labeling ( Psl ) reorganizes the steps of Pll for the multithreaded setting and is designed particularly for social networks for which the index sizes can be much larger than what a single server can store. Even for a medium-size, 5 million vertex graph, the index size can be more than 40 GB. This paper proposes a hybrid, shared- and distributed-memory algorithm, DPSL, by partitioning the input graph via a vertex separator. The proposed method improves both the parallel execution time and the maximum memory consumption by distributing both the data and the work across multiple nodes of a cluster. For instance, on a graph with 5M vertices and 150M edges, using 4 nodes, DPSL reduces the execution time and maximum memory consumption by 2.13× and 1.87×, respectively, compared to our improved implementation of Psl .},
  archive      = {J_JPDC},
  author       = {Arda Şener and Hüsnü Yenigün and Kamer Kaya},
  doi          = {10.1016/j.jpdc.2025.105057},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105057},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Distributed landmark labeling for social networks},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring data science workflows: A practice-oriented
approach to teaching processing of massive datasets. <em>JPDC</em>,
<em>200</em>, 105043. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive datasets are typically processed by a sequence of different stages, comprising data acquisition and preparation, data processing, data analysis, result validation, and visualization. In conjunction, these stages form a data science workflow, a key element enabling the solution of data-intensive problems. The complexity and heterogeneity of these stages require a diverse set of techniques and skills. This article discusses a hands-on practice-oriented approach aiming to enable and motivate graduate students to engage with realistic data science workflows. A major goal of the approach is to bridge the gap between academia and industry by integrating programming assignments that implement different data workflows with real-world data. In consecutive assignments, students are exposed to the methodology of solving problems using big data frameworks and are required to implement different data workflows of varying complexity. This practice-oriented approach is well received by students, as confirmed by different surveys.},
  archive      = {J_JPDC},
  author       = {Johannes Schoder and H. Martin Bücker},
  doi          = {10.1016/j.jpdc.2025.105043},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105043},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Exploring data science workflows: A practice-oriented approach to teaching processing of massive datasets},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
