<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOE_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="joe---18">JOE - 18</h2>
<ul>
<li><details>
<summary>
(2025). Quantile prediction with factor-augmented regression:
Structural instability and model uncertainty. <em>JOE</em>,
<em>249</em>, 105999. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantile regression is an effective tool in modeling data with heterogeneous conditional distribution. This paper considers the time-varying coefficient quantile predictive regression with factor-augmented predictors, to capture smooth structural changes and incorporate high-dimensional data information in prediction simultaneously. Uniform consistency of the local linear quantile coefficient estimators is established under misspecification. To further improve the forecast accuracy, a novel time-varying model averaging based on local forward-validation is developed. The averaging estimator is shown to be asymptotically optimal in the sense of minimizing out-of-sample forecast risk function. Furthermore, the weight selection consistency and the asymptotic distribution of the averaging coefficient estimator are established. Numerical results from simulations and a real data application to forecasting U.S. inflation demonstrate the nice performance of the averaging estimators.},
  archive      = {J_JOE},
  author       = {Yundong Tu and Siwei Wang},
  doi          = {10.1016/j.jeconom.2025.105999},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105999},
  shortjournal = {J. Econ.},
  title        = {Quantile prediction with factor-augmented regression: Structural instability and model uncertainty},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limit theory and inference in non-cointegrated functional
coefficient regression. <em>JOE</em>, <em>249</em>, 105996. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional coefficient (FC) cointegrating regressions offer empirical investigators flexibility in modeling economic relationships by introducing covariates that influence the direction and intensity of comovement among nonstationary time series. FC regression models are also useful when formal cointegration is absent, in the sense that the equation errors may themselves be nonstationary, but where the nonstationary series display well-defined FC linkages that can be meaningfully interpreted as correlation measures involving the covariates. The present paper proposes new nonparametric estimators for such FC regression models where the nonstationary series display linkages that enable consistent estimation of the correlation measures between them. Specifically, we develop n -consistent estimators for the functional coefficient and establish their asymptotic distributions, which involve mixed normal limits that facilitate inference. Two novel features that appear in the limit theory are (i) the need for non-diagonal matrix normalization due to the presence of stationary and nonstationary components in the regression; and (ii) random bias elements that appear in the asymptotic distribution of the kernel estimators, again resulting from the nonstationary regression components. Numerical studies reveal that the proposed estimators achieve significant efficiency improvements compared to the estimators suggested in earlier work by Sun et al. (2011). Easily implementable specification tests with standard chi-square asymptotics are suggested to check for constancy of the functional coefficient. These tests are shown to have faster divergence rate under local alternatives and enjoy superior performance in simulations than tests proposed in Gan et al. (2014). An empirical application based on the quantity theory of money is included, illustrating the practical use of correlated but non-cointegrated regression relations.},
  archive      = {J_JOE},
  author       = {Ying Wang and Peter C.B. Phillips and Yundong Tu},
  doi          = {10.1016/j.jeconom.2025.105996},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105996},
  shortjournal = {J. Econ.},
  title        = {Limit theory and inference in non-cointegrated functional coefficient regression},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supervised factor modeling for high-dimensional linear time
series. <em>JOE</em>, <em>249</em>, 105995. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by Tucker tensor decomposition, this paper imposes low-rank structures to the column and row spaces of coefficient matrices in a multivariate infinite-order vector autoregression (VAR), which leads to a supervised factor model with two factor modelings being conducted to responses and predictors simultaneously. Interestingly, the stationarity condition implies an intrinsic weak group sparsity mechanism of infinite-order VAR, and hence a rank-constrained group Lasso estimation is considered for high-dimensional linear time series. Its non-asymptotic properties are discussed by balancing the estimation, approximation and truncation errors. Moreover, an alternating gradient descent algorithm with hard-thresholding is designed to search for high-dimensional estimates, and its theoretical justifications, including statistical and convergence analysis, are also provided. Theoretical and computational properties of the proposed methodology are verified by simulation experiments, and the advantages over existing methods are demonstrated by analyzing US quarterly macroeconomic variables.},
  archive      = {J_JOE},
  author       = {Feiqing Huang and Kexin Lu and Yao Zheng and Guodong Li},
  doi          = {10.1016/j.jeconom.2025.105995},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105995},
  shortjournal = {J. Econ.},
  title        = {Supervised factor modeling for high-dimensional linear time series},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model averaging prediction for possibly nonstationary
autoregressions. <em>JOE</em>, <em>249</em>, 105994. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an alternative to model selection (MS), this paper considers model averaging (MA) for integrated autoregressive processes of infinite order (AR( ∞ )). We derive a uniformly asymptotic expression for the mean squared prediction error (MSPE) of the averaging prediction with fixed weights and then propose a Mallows-type criterion to select the data-driven weights that minimize the MSPE asymptotically. We show that the proposed MA estimator and its variants, Shibata and Akaike MA estimators, are asymptotically optimal in the sense of achieving the lowest possible MSPE. We further demonstrate that MA can provide significant MSPE reduction over MS in the algebraic-decay case. These theoretical findings are extended to integrated AR( ∞ ) models with deterministic time trends and are supported by Monte Carlo simulations and real data analysis.},
  archive      = {J_JOE},
  author       = {Tzu-Chi Lin and Chu-An Liu},
  doi          = {10.1016/j.jeconom.2025.105994},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105994},
  shortjournal = {J. Econ.},
  title        = {Model averaging prediction for possibly nonstationary autoregressions},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Huber principal component analysis for large-dimensional
factor models. <em>JOE</em>, <em>249</em>, 105993. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor models have been widely used in economics and finance. However, the heavy-tailed nature of macroeconomic and financial data is often neglected in statistical analysis. To address this issue, we propose a robust approach to estimate factor loadings and scores by minimizing the Huber loss function, which is motivated by the equivalence between conventional Principal Component Analysis (PCA) and the constrained least squares method in the factor model. We provide two algorithms that use different penalty forms. The first algorithm involves an element-wise-type Huber loss minimization, solved by an iterative Huber regression algorithm. The second algorithm, which we refer to as Huber PCA, minimizes the ℓ 2 -norm-type Huber loss and performs PCA on the weighted sample covariance matrix. We examine the theoretical minimizer of the element-wise Huber loss function and demonstrate that it has the same convergence rate as conventional PCA when the idiosyncratic errors have bounded second moments. We also derive their asymptotic distributions under mild conditions. Moreover, we suggest a consistent model selection criterion that relies on rank minimization to estimate the number of factors robustly. We showcase the benefits of the proposed two algorithms through extensive numerical experiments and a real macroeconomic data example. An R package named “ HDRFA ” 1 has been developed to conduct the proposed robust factor analysis.},
  archive      = {J_JOE},
  author       = {Yong He and Lingxiao Li and Dong Liu and Wen-Xin Zhou},
  doi          = {10.1016/j.jeconom.2025.105993},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105993},
  shortjournal = {J. Econ.},
  title        = {Huber principal component analysis for large-dimensional factor models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantile granger causality in the presence of instability.
<em>JOE</em>, <em>249</em>, 105992. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new framework for assessing Granger causality in quantiles in unstable environments, for a fixed quantile or over a continuum of quantile levels. Our proposed test statistics are consistent against fixed alternatives, they have nontrivial power against local alternatives, and they are pivotal in certain important special cases. In addition, we show the validity of a bootstrap procedure when asymptotic distributions depend on nuisance parameters. Monte Carlo simulations reveal that the proposed test statistics have correct empirical size and high power, even in absence of structural breaks. Moreover, a procedure providing additional insight into the timing of Granger causal regimes based on our new tests is proposed. Finally, an empirical application in energy economics highlights the applicability of our method as the new tests provide stronger evidence of Granger causality.},
  archive      = {J_JOE},
  author       = {Alexander Mayer and Dominik Wied and Victor Troster},
  doi          = {10.1016/j.jeconom.2025.105992},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105992},
  shortjournal = {J. Econ.},
  title        = {Quantile granger causality in the presence of instability},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adjustments with many regressors under covariate-adaptive
randomizations. <em>JOE</em>, <em>249</em>, 105991. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our paper discovers a new trade-off of using regression adjustments (RAs) in causal inference under covariate-adaptive randomizations (CARs). On one hand, RAs can improve the efficiency of causal estimators by incorporating information from covariates that are not used in the randomization. On the other hand, RAs can degrade estimation efficiency due to their estimation errors, which are not asymptotically negligible when the number of regressors is of the same order as the sample size. Ignoring the estimation errors of RAs may result in serious over-rejection of causal inference under the null hypothesis. To address the issue, we construct a new ATE estimator by optimally linearly combining the estimators with and without RAs. We then develop a unified inference theory for this estimator under CARs. It has two features: (1) the Wald test based on it achieves the exact asymptotic size under the null hypothesis, regardless of whether the number of covariates is fixed or diverges no faster than the sample size; and (2) it guarantees weak efficiency improvement over estimators both with and without RAs.},
  archive      = {J_JOE},
  author       = {Liang Jiang and Liyao Li and Ke Miao and Yichong Zhang},
  doi          = {10.1016/j.jeconom.2025.105991},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105991},
  shortjournal = {J. Econ.},
  title        = {Adjustments with many regressors under covariate-adaptive randomizations},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bootstrap based asymptotic refinements for high-dimensional
nonlinear models. <em>JOE</em>, <em>249</em>, 105977. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider penalized extremum estimation of a high-dimensional, possibly nonlinear model that is sparse in the sense that most of its parameters are zero but some are not. We use the SCAD penalty function, which provides model selection consistent and oracle efficient estimates under suitable conditions. However, asymptotic approximations based on the oracle model can be inaccurate with the sample sizes found in many applications. This paper gives conditions under which the bootstrap, based on estimates obtained through SCAD penalization with thresholding, provides asymptotic refinements of size O ( n − 2 ) for the error in the rejection (coverage) probability of a symmetric hypothesis test (confidence interval) and O ( n − 1 ) for the error in the rejection (coverage) probability of a one-sided or equal tailed test (confidence interval). The results of Monte Carlo experiments show that the bootstrap can provide large reductions in errors in rejection and coverage probabilities. The bootstrap is consistent, though it does not necessarily provide asymptotic refinements, if some parameters are close but not equal to zero. Random-coefficients logit and probit models and nonlinear moment models are examples of models to which the procedure applies.},
  archive      = {J_JOE},
  author       = {Joel L. Horowitz and Ahnaf Rafi},
  doi          = {10.1016/j.jeconom.2025.105977},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105977},
  shortjournal = {J. Econ.},
  title        = {Bootstrap based asymptotic refinements for high-dimensional nonlinear models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor time series imputation through tensor factor
modelling. <em>JOE</em>, <em>249</em>, 105974. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose tensor time series imputation when the missing pattern in the tensor data can be general, as long as any two data positions along a tensor fibre are both observed for enough time points. The method is based on a tensor time series factor model with Tucker decomposition of the common component. One distinguished feature of the tensor time series factor model used is that there can be weak factors in the factor loading matrix for each mode. This reflects reality better when real data can have weak factors which drive only groups of observed variables, for instance, a sector factor in a financial market driving only stocks in a particular sector. Using the data with missing entries, asymptotic normality is derived for rows of estimated factor loadings, while consistent covariance matrix estimation enables us to carry out inferences. As a first in the literature, we also propose a ratio-based estimator for the rank of the core tensor under general missing patterns. Rates of convergence are spelt out for the imputations from the estimated tensor factor models. Simulation results show that our imputation procedure works well, with asymptotic normality and corresponding inferences also demonstrated. Re-imputation performances are also gauged when we demonstrate that using slightly larger rank then estimated gives superior re-imputation performances. A Fama–French portfolio example with matrix returns and an OECD data example with matrix of economic indicators are presented and analysed, showing the efficacy of our imputation approach compared to direct vector imputation.},
  archive      = {J_JOE},
  author       = {Zetai Cen and Clifford Lam},
  doi          = {10.1016/j.jeconom.2025.105974},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105974},
  shortjournal = {J. Econ.},
  title        = {Tensor time series imputation through tensor factor modelling},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimation and uniform inference in sparse high-dimensional
additive models. <em>JOE</em>, <em>249</em>, 105973. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a novel method to construct uniformly valid confidence bands for a nonparametric component f 1 in the sparse additive model Y = f 1 ( X 1 ) + … + f p ( X p ) + ɛ in a high-dimensional setting. Our method integrates sieve estimation into a high-dimensional Z-estimation framework, facilitating the construction of uniformly valid confidence bands for the target component f 1 . To form these confidence bands, we employ a multiplier bootstrap procedure. Additionally, we provide rates for the uniform lasso estimation in high dimensions, which may be of independent interest. Through simulation studies, we demonstrate that our proposed method delivers reliable results in terms of estimation and coverage, even in small samples.},
  archive      = {J_JOE},
  author       = {Philipp Bach and Sven Klaassen and Jannis Kueck and Martin Spindler},
  doi          = {10.1016/j.jeconom.2025.105973},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105973},
  shortjournal = {J. Econ.},
  title        = {Estimation and uniform inference in sparse high-dimensional additive models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When structural break meets threshold effect: Factor
analysis under structural instabilities. <em>JOE</em>, <em>249</em>,
105972. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural instability has been one of the central research questions in economics and finance over many decades. This paper systematically investigates structural instabilities in high dimensional factor models, which portray both structural breaks and threshold effects simultaneously. The observed high dimensional time series are concatenated at an unknown number of break points, while they are described by multiple threshold factor models that are heterogeneous between any two consecutive subsamples. Both joint and sequential procedures for estimating the break points are developed based on the second moment of the pseudo factor estimates that fully ignore the structural instabilities. In each separated subsample, the group Lasso approach recently proposed by Ma and Tu (2023b) is adopted to efficiently identify the threshold factor structure. An information criterion is further proposed to determine the number of break points, which also serves the purpose to distinguish the two types of instabilities. Theoretical properties of the proposed estimators are established, and their finite sample performance is evaluated in Monte Carlo simulations. An empirical application to the U.S. financial market dataset demonstrates the consequences when structural break meets threshold effect in factor analysis.},
  archive      = {J_JOE},
  author       = {Chenchen Ma and Yundong Tu},
  doi          = {10.1016/j.jeconom.2025.105972},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105972},
  shortjournal = {J. Econ.},
  title        = {When structural break meets threshold effect: Factor analysis under structural instabilities},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large confirmatory dynamic factor model for stock market
returns in different time zones. <em>JOE</em>, <em>249</em>, 105971. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a confirmatory dynamic factor model for a large number of stocks whose returns are observed daily across multiple time zones. The model has a global factor and a continental factor that both drive the individual stock return series. We propose two estimators of the model: a quasi-maximum likelihood estimator (QML-just-identified), and an improved estimator based on an Expectation Maximization (EM) algorithm (QML-all-res). Our estimators are consistent and asymptotically normal under the large approximate factor model setting. In particular, the asymptotic distributions of QML-all-res are the same as those of the infeasible OLS estimators that treat factors as known and utilize all the restrictions on the parameters of the model. We apply the model to MSCI equity indices of 42 developed and emerging markets, and find that most markets are more integrated when the CBOE Volatility Index (VIX) is high.},
  archive      = {J_JOE},
  author       = {Oliver B. Linton and Haihan Tang and Jianbin Wu},
  doi          = {10.1016/j.jeconom.2025.105971},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105971},
  shortjournal = {J. Econ.},
  title        = {A large confirmatory dynamic factor model for stock market returns in different time zones},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On time-varying panel data models with time-varying
interactive fixed effects. <em>JOE</em>, <em>249</em>, 105960. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a time-varying (TV) panel data model with interactive fixed effects where both the coefficients and factor loadings are allowed to change smoothly over time. We propose a local version of the least squares and principal component method to estimate the TV coefficients, TV factor loadings, and common factors simultaneously. We provide a bias-corrected local least squares estimator for the TV coefficients and establish the limiting distributions and uniform convergence of the bias-corrected coefficient estimators, estimated factors, and factor loadings in the large N and large T framework. Based on the estimates, we propose three test statistics to gauge possible sources of TV features. We establish the limit null distributions and the asymptotic local power properties of our tests. Simulations are conducted to evaluate the finite sample performance of our estimates and tests. We apply our theoretical results to analyze the Phillips curve using the U.S. state-level unemployment rates and nominal wages, and document significant TV behavior in both the slope coefficient and factor loadings.},
  archive      = {J_JOE},
  author       = {Xia Wang and Sainan Jin and Yingxing Li and Junhui Qian and Liangjun Su},
  doi          = {10.1016/j.jeconom.2025.105960},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105960},
  shortjournal = {J. Econ.},
  title        = {On time-varying panel data models with time-varying interactive fixed effects},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplicative factor model for volatility. <em>JOE</em>,
<em>249</em>, 105959. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facilitated with high-frequency observations, we introduce a remarkably parsimonious one-factor volatility model that offers a novel perspective for comprehending daily volatilities of a large number of stocks. Specifically, we propose a multiplicative volatility factor (MVF) model, where stock daily variance is represented by a common variance factor and a multiplicative idiosyncratic component. We demonstrate compelling empirical evidence supporting our model and provide statistical properties for two simple estimation methods. The MVF model reflects important properties of volatilities, applies to both individual stocks and portfolios, can be easily estimated, and leads to exceptional predictive performance in both US stocks and global equity indices.},
  archive      = {J_JOE},
  author       = {Yi Ding and Robert Engle and Yingying Li and Xinghua Zheng},
  doi          = {10.1016/j.jeconom.2025.105959},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105959},
  shortjournal = {J. Econ.},
  title        = {Multiplicative factor model for volatility},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Penalized estimation of finite mixture models. <em>JOE</em>,
<em>249</em>, 105958. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economists often model unobserved heterogeneity using finite mixtures. In practice, the number of mixture components is rarely known. Model parameters lack point-identification if the estimation includes too many components, thus invalidating the classic properties of maximum likelihood estimation. I propose a penalized likelihood method to estimate finite mixtures with an unknown number of components. The resulting Order-Selection-Consistent Estimator (OSCE) consistently estimates the true number of components and achieves oracle efficiency. This paper extends penalized estimation to models without point-identification and to mixtures with growing number of components. I apply the OSCE to estimate players’ rationality levels in a coordination game.},
  archive      = {J_JOE},
  author       = {Sofya Budanova},
  doi          = {10.1016/j.jeconom.2025.105958},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105958},
  shortjournal = {J. Econ.},
  title        = {Penalized estimation of finite mixture models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional heterogeneous panel data models with
multi-level interactive fixed effects. <em>JOE</em>, <em>249</em>,
105957. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a three-dimensional (3D) panel data model with heterogeneous slope coefficients and multi-level interactive fixed effects consisting of latent global factors and two types of local factors. Our model nests many commonly used 3D panel data models. We propose an iterative estimation procedure that relies on initial consistent estimators obtained through a novel defactored approach. We study the asymptotic properties of our estimators and show that our iterative estimators of the slope coefficients are “oracle efficient” in the sense that they are asymptotically equivalent to those when the factors were known. Some specification testing issues are also considered. Monte Carlo simulations demonstrate that our estimators and tests perform well in finite samples. We apply our new method to the international trade dataset.},
  archive      = {J_JOE},
  author       = {Sainan Jin and Xun Lu and Liangjun Su},
  doi          = {10.1016/j.jeconom.2025.105957},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105957},
  shortjournal = {J. Econ.},
  title        = {Three-dimensional heterogeneous panel data models with multi-level interactive fixed effects},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification and estimation of a search model with
heterogeneous consumers and firms. <em>JOE</em>, <em>249</em>, 105956.
(<a href="https://doi.org/10.1016/j.jeconom.2025.105956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a model of nonsequential consumer search where consumers and firms differ in search and production costs respectively. We characterize the equilibrium of the game. We first show the distribution of search cost can be identified by market shares and prices. Subsequently, we identify the production cost distribution using a similar strategy to Guerre, Perrigne and Vuong (2000) as the firms’ decision problems resemble bidders’ problems in a particular procurement auction. We prove the firm’s cost density can be estimated at the same convergence rate as the optimal rate in Guerre et al. uniformly over any fixed subset on the interior of the support. The uniform convergence rate over any expanding support is slower due to a pole in the price pdf that is a feature of the equilibrium. Our simulation study confirms the theoretical features of the model. Our identification and convergence rate results also apply to two generalizations of the baseline search model that allow for: (i) vertically differentiated products; (ii) an intermediary. We apply the latter model to study loan search using UK mortgage data.},
  archive      = {J_JOE},
  author       = {Mateusz Myśliwski and May Rostom and Fabio Sanches and Daniel Silva Jr and Sorawoot Srisuma},
  doi          = {10.1016/j.jeconom.2025.105956},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105956},
  shortjournal = {J. Econ.},
  title        = {Identification and estimation of a search model with heterogeneous consumers and firms},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simple subvector inference on sharp identified set in affine
models. <em>JOE</em>, <em>249</em>, 105952. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a regularized support function estimator for bounds on components of the parameter vector in the case in which the identified set is a polygon. The proposed regularized estimator has three important properties: (i) it has a uniform asymptotic Gaussian limit in the presence of flat faces in the absence of redundant (or overidentifying) constraints (or vice versa); (ii) the bias from regularization does not enter the first-order limiting distribution; (iii) the estimator remains consistent for sharp (non-enlarged) identified set for the individual components even in the non-regular case. These properties are used to construct uniformly valid confidence sets for an element θ 1 of a parameter vector θ ∈ R d that is partially identified by affine moment equality and inequality conditions. The proposed confidence sets can be computed as a solution to a small number of linear and convex quadratic programs, leading to a substantial decrease in computation time and guarantees a global optimum. As a result, the method provides a uniformly valid inference in applications in which the dimension of the parameter space, d , and the number of inequalities, k , were previously computationally unfeasible ( d , k = 100 ). The proposed approach can be extended to construct confidence sets for intersection bounds, to construct joint polygon-shaped confidence sets for multiple components of θ , and to find the set of solutions to a linear program. Inference for coefficients in the linear IV regression model with an interval outcome is used as an illustrative example.},
  archive      = {J_JOE},
  author       = {Bulat Gafarov},
  doi          = {10.1016/j.jeconom.2025.105952},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105952},
  shortjournal = {J. Econ.},
  title        = {Simple subvector inference on sharp identified set in affine models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
