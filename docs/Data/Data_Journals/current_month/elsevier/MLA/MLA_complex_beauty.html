<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MLA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mla---14">MLA - 14</h2>
<ul>
<li><details>
<summary>
(2025). Predicting cyberbullying victimisation in emerging markets
and developing countries using the global school-based health survey.
<em>MLA</em>, <em>20</em>, 100646. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives This study aimed to identify predictors of cyberbullying victimisation among adolescents and develop predictive models to support early intervention strategies. Methods Data from the Global School-based Health Surveys (2017–2021) were analysed, focusing on emerging markets and developing countries. A simple random sampling strategy was used to ensure equal representation across countries. A multivariable logistic regression model was applied to 26 variables to identify significant predictors of cyberbullying victimisation. Subsequently, machine learning techniques were used to develop predictive models. Results This logistic regression model was statistically significant ( χ2(26)=507.96, p &lt; 0 .001 ), explaining 19.3 % of the variance with an AUROC of 0 .758 (95 % CI, 0.739 to 0.778) . Twelve variables, including being bullied on school property, female gender, peer victimisation, early sexual debut, alcohol consumption, and suicidal ideation, were identified as significant predictors. The best-performing predictive model, a randomly over-sampled random forest classifier, achieved 82 % accuracy and an AUROC of 0 .83 (95 % CI, 0.81 to 0.85) . Conclusions The study highlights key predictors of cyberbullying victimisation and demonstrates the potential of machine learning in developing accurate predictive models. However, reliance on self-reported data may introduce biases. Future research could integrate diverse data sources to enhance model accuracy and reliability.},
  archive      = {J_MLA},
  author       = {Paulo Ricardo Vieira Braga and Katie Rose Tyrrell},
  doi          = {10.1016/j.mlwa.2025.100646},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100646},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predicting cyberbullying victimisation in emerging markets and developing countries using the global school-based health survey},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning based risk analysis and predictive modeling
of structure fire related casualties. <em>MLA</em>, <em>20</em>, 100645.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analysed over 48,000 reported structure fire incidents in Oregon that occurred from January 2012 through August 2023. The dataset includes 2136 fires that led to civilian casualties including 317 confirmed fatalities. Bagged decision tree classifiers with random forest algorithm were used to quantify the importance of factors related to socioeconomic conditions, population characteristics, structural and behavioral incident details, and local infrastructure on the severity of injuries. Our results show that the age of victims, fire service response times, and availability of working smoke or fire detectors were among the most important parameters for predicting fatal outcomes of structure fires. Furthermore, a predictive Bayesian regularized neural network ensemble classifier was developed to model the severity of casualties and project a spatial risk classification on the census block level. The network model achieves a prediction accuracy of 92.5 % for the classification of structural fire-related casualty severities. With information aggregated to the census block scale and information related to specific fire incidents removed, the retrained model based solely on spatially available data reaches an 87.6 % severity classification accuracy. As the first statewide analysis of its kind, our spatial assessment provides a useful tool for resource allocation, risk factor reduction, and safety education efforts targeted to reduce the number of serious injuries or fatalities from structure fires.},
  archive      = {J_MLA},
  author       = {Andres Schmidt and Eric Gemmil and Russ Hoskins},
  doi          = {10.1016/j.mlwa.2025.100645},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100645},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning based risk analysis and predictive modeling of structure fire related casualties},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal risk mapping of statewide weather-related
traffic crashes: A machine learning approach. <em>MLA</em>, <em>20</em>,
100642. (<a href="https://doi.org/10.1016/j.mlwa.2025.100642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving transportation safety statewide is key in upholding a state&#39;s economy. However, weather-related crashes, known to be one of the most severe types of crashes, poses a threat to this as lots of money is lost to lives and property damage. The goal of this study is to employ machine learning (ML) to develop a workflow on which weather-related crash risk can be better identified, predicted, and interpreted. Central to this workflow, the effects of spatiotemporal heterogeneity of weather-related crashes are studied. To demonstrate the workflow, weather-related crash events in the state of North Carolina were used. Space-time cubes were created using an optimized 5 mi x 5mi grid size and 1-month time aggregation. Equivalent property damage only (EPDO) scores were computed for each space-time cube to create a risk metric that combines both crash frequency and severity. A two-layered technique was employed for identifying and labelling crash risk zones. Subsequently, XGBoost model was used to predict crash risk zones and identify factors associated with the different risk levels. SHapley Additive exPlanations (SHAP), an explainable AI (XAI) tool, was used to interpret the model and examine the relationship between the explanatory variables and the outcome. Per the results, there are three optimal clusters with distinct variability of the impact of weather conditions that constitute the crash risk levels in the study area. The workflow can be used by transportation safety units within state departments of transportation (DOTs) to evaluate different safety risk levels, and the potential high-risk zones can be flagged for devising countermeasures (i.e., proactive risk mitigation strategies).},
  archive      = {J_MLA},
  author       = {Abimbola Ogungbire and Srinivas S. Pulugurtha},
  doi          = {10.1016/j.mlwa.2025.100642},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100642},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Spatiotemporal risk mapping of statewide weather-related traffic crashes: A machine learning approach},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based identification of precipitation clouds
from all-sky camera data for observatory safety. <em>MLA</em>,
<em>20</em>, 100640. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For monitoring the night sky conditions, wide-angle all-sky cameras are used in most astronomical observatories to monitor the sky cloudiness. In this manuscript, we apply a deep-learning approach for automating the identification of precipitation clouds in all-sky camera data as a cloud warning system. We construct our original training and test sets using the all-sky camera image archive of the Iranian National Observatory (INO). The training and test set images are labeled manually based on their potential rainfall and their distribution in the sky. We train our model on a set of roughly 2445 images taken by the INO all-sky camera through the deep learning method based on the EfficientNet network. Our model reaches an average accuracy of 99% in determining the cloud rainfall’s potential and an accuracy of 96% for cloud coverage. To enable a comprehensive comparison and evaluate the performance of alternative architectures for the task, we additionally trained three models—LeNet, DeiT, and AlexNet. This approach can be used for early warning of incoming dangerous clouds toward telescopes and harnesses the power of deep learning to automatically analyze vast amounts of all-sky camera data and accurately identify precipitation clouds formations. Our trained model can be deployed for real-time analysis, enabling the rapid identification of potential threats, and offering a scaleable solution that can improve our ability to safeguard telescopes and instruments in observatories. This is important now that numerous small- and medium-sized telescopes are increasingly integrated with smart control systems to reduce manual operation.},
  archive      = {J_MLA},
  author       = {Mohammad H. Zhoolideh Haghighi and Alireza Ghasrimanesh and Habib Khosroshahi},
  doi          = {10.1016/j.mlwa.2025.100640},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100640},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Deep learning-based identification of precipitation clouds from all-sky camera data for observatory safety},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software engineering meets legal texts: LLMs for auto
detection of contract smells. <em>MLA</em>, <em>20</em>, 100639. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although there have been many major advances in Artificial Intelligence including its application to a wide variety of tasks, some specialized domains remain difficult to tackle. In this work, we examine parallels between software engineering and legal contract drafting and analysis. Porting well-known code smells principles to various legal contracts, we introduce ”contract smells,” text patterns that are indicative of potentially significant issues within contractual agreements. We leverage semi-auto labeling with GPT-4, prompting and expert spot checks, to create datasets for suitability testing of auto detection of these contract smells. Using transformer-based models, we explore the impact of legal domain knowledge, hyperparameters fine tuning and specific task information on detection success. We achieve high accuracy with further fine-tuning of BERT as well as LEGAL-BERT, while more consistent results were achieved using task-specific data. We further demonstrate that although multi-class detection can boost coverage of rare smells, single-class detection yields better accuracy. While this is an initial foray into the idea of contract smells, this work underscores the feasibility of applying advanced NLP techniques and LLMs to automate aspects of legal contract review, suggesting a scalable path toward standardized, machine-assisted legal drafting and analysis.},
  archive      = {J_MLA},
  author       = {Moriya Dechtiar and Daniel Martin Katz and Hongming Wang},
  doi          = {10.1016/j.mlwa.2025.100639},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100639},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Software engineering meets legal texts: LLMs for auto detection of contract smells},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-shot generative distribution matching for augmented
RF-based UAV identification. <em>MLA</em>, <em>20</em>, 100638. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the challenge of identifying Unmanned Aerial Vehicles (UAV) using radiofrequency (RF) fingerprinting in limited RF environments. The complexity and variability of RF signals, influenced by environmental interference and hardware imperfections, often render traditional RF-based identification methods ineffective. To address these complications, the study introduces the rigorous use of one-shot generative methods for augmenting transformed RF signals, offering a significant improvement in UAV identification. This approach, when utilizing a distributional distance metric, demonstrates significant promise in low-data regimes, outperforming deep generative methods such as conditional generative adversarial networks (GANs) and variational autoencoders (VAEs). The paper provides a theoretical guarantee for the effectiveness of one-shot generative models in augmenting limited data, setting a precedent for their application in limited RF environments. This research also contributes to learning techniques in low-data regime scenarios, which may include complex sequences beyond images and videos. The code and links to datasets used in this study are available at https://github.com/amir-kazemi/uav-rf-id .},
  archive      = {J_MLA},
  author       = {Amir Kazemi and Salar Basiri and Volodymyr Kindratenko and Srinivasa Salapaka},
  doi          = {10.1016/j.mlwa.2025.100638},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100638},
  shortjournal = {Mach. Learn. Appl.},
  title        = {One-shot generative distribution matching for augmented RF-based UAV identification},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid oversampling technique for imbalanced pattern
recognition: Enhancing performance with borderline synthetic minority
oversampling and generative adversarial networks. <em>MLA</em>,
<em>20</em>, 100637. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance problems (CIP) are one of the potential challenges in developing unbiased Machine Learning models for predictions. CIP occurs when data samples are not equally distributed between two or multiple classes. Several synthetic oversampling techniques have been introduced to balance the imbalanced data by oversampling the minor samples. One of the potential drawbacks of existing oversampling techniques is that they often fail to focus on the data samples that lie at the border point and give more attention to the extreme observations, ultimately limiting the creation of more diverse data after oversampling, and that is almost the scenario for most of the oversampling strategies. As an effect, marginalization occurs after oversampling. To address these issues, in this work, we propose a hybrid oversampling technique, named Borderline Synthetic Minority Oversampling and Generative Adversarial Network (BSGAN), by combining the strengths of Borderline-Synthetic Minority Oversampling Technique (SMOTE) and Generative Adversarial Networks (GANs). This approach aims to generate more diverse data that follow Gaussian distributions, marking a significant contribution to the field of Artificial Intelligence. We tested BSGAN on ten highly imbalanced datasets, demonstrating its application in engineering, where it outperformed existing oversampling techniques, creating a more diverse dataset that follows a normal distribution after oversampling.},
  archive      = {J_MLA},
  author       = {Md Manjurul Ahsan and Shivakumar Raman and Yingtao Liu and Zahed Siddique},
  doi          = {10.1016/j.mlwa.2025.100637},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100637},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Hybrid oversampling technique for imbalanced pattern recognition: Enhancing performance with borderline synthetic minority oversampling and generative adversarial networks},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced fault detection in photovoltaic panels using
enhanced u-net architectures. <em>MLA</em>, <em>20</em>, 100636. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection in photovoltaic (PV) panels using thermal images remains a significant challenge due to the complexity of thermal patterns, environmental noise, and the subtle nature of anomalies. This paper introduces an advanced deep learning framework that enhances the U-Net architecture by integrating Residual Blocks, Atrous Spatial Pyramid Pooling (ASPP), and Attention Mechanisms. These enhancements collectively improve feature extraction, contextual understanding, and fault localization, addressing the limitations of traditional segmentation approaches and reducing false positives. Extensive experiments demonstrate that the proposed method significantly outperforms all benchmarked algorithms across key segmentation metrics, including standard U-Net, U-Net with ASPP, and DeepLabV3+. Compared to standard U-Net, the proposed model achieves more than a 29% increase in F1-score and a 62% improvement in Intersection over Union (IoU) while reducing segmentation loss by 71%. Its ability to accurately detect faults under challenging conditions establishes the framework as a state-of-the-art solution for real-time PV monitoring. These results demonstrate the effectiveness of the proposed approach in addressing the challenges of PV fault detection, offering a practical and reliable solution for ensuring the operational performance of renewable energy systems.},
  archive      = {J_MLA},
  author       = {Khalfalla Awedat and Gurcan Comert and Mustafa Ayad and Abdulmajid Mrebit},
  doi          = {10.1016/j.mlwa.2025.100636},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100636},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Advanced fault detection in photovoltaic panels using enhanced U-net architectures},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pioneering precision in lumbar spine MRI segmentation with
advanced deep learning and data enhancement. <em>MLA</em>, <em>20</em>,
100635. (<a href="https://doi.org/10.1016/j.mlwa.2025.100635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an advanced approach to lumbar spine segmentation using deep learning techniques, focusing on addressing key challenges such as class imbalance and data preprocessing. Magnetic resonance imaging (MRI) scans of patients with low back pain are meticulously preprocessed to accurately represent three critical classes: vertebrae, spinal canal, and intervertebral discs (IVDs). By rectifying class inconsistencies in the data preprocessing stage, the fidelity of the training data is ensured. The modified U-Net model incorporates innovative architectural enhancements, including an upsample block with leaky Rectified Linear Units (ReLU) and Glorot uniform initializer, to mitigate common issues such as the dying ReLU problem and improve stability during training. Introducing a custom combined loss function effectively tackles class imbalance, significantly improving segmentation accuracy. Evaluation using a comprehensive suite of metrics showcases the superior performance of this approach, outperforming existing methods and advancing the current techniques in lumbar spine segmentation. These findings hold significant advancements for enhanced lumbar spine MRI and segmentation diagnostic accuracy.},
  archive      = {J_MLA},
  author       = {Istiak Ahmed and Md. Tanzim Hossain and Md. Zahirul Islam Nahid and Kazi Shahriar Sanjid and Md. Shakib Shahariar Junayed and M. Monir Uddin and Mohammad Monirujjaman Khan},
  doi          = {10.1016/j.mlwa.2025.100635},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100635},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Pioneering precision in lumbar spine MRI segmentation with advanced deep learning and data enhancement},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-driven predictive modeling of mechanical
properties in diverse steels. <em>MLA</em>, <em>20</em>, 100634. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the application of machine learning (ML) in steel design using a small dataset of various steel grades that include 13 key elements and three critical mechanical properties. Random forest (RF) models were systematically evaluated for their robustness and effectiveness in predicting the stress-strain of steel properties. Moreover, other alternative approaches, such as support vector machines, extreme gradient boosting machines, and artificial neural networks, were also evaluated to ensure that the predictions made by the RF model are as accurate as possible. To assess the bias-variance trade-off, 1-seed and random 100-seeds with 80/20 train/test split, and leave-one-out cross-validation for all datasets were conducted. The results demonstrated that the RF models are accurate and reliable, achieving low bias and variance while delivering predictions comparable to, and in some cases better than, those obtained in studies with larger datasets. The analysis revealed a trade-off between strength and ductility, with elongation negatively correlated with yield strength and ultimate tensile strength. This study highlights the feasibility of using small, realistic datasets to develop effective ML models for predicting mechanical properties in steel design. The methodology can also be readily extended to investigate processing-property relationships in other systems, offering a versatile approach for advancing materials science through data-driven techniques.},
  archive      = {J_MLA},
  author       = {Movaffaq Kateb and Sahar Safarian},
  doi          = {10.1016/j.mlwa.2025.100634},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100634},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning-driven predictive modeling of mechanical properties in diverse steels},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of machine learning for seam profile
identification in robotic welding. <em>MLA</em>, <em>20</em>, 100633.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses critical challenges in automated robotic welding, emphasizing precise weld groove profiling for pipe welding applications. By integrating advanced laser scanning technology with the Local Outlier Factor (LOF) algorithm, the research effectively mitigates outliers and compensates for incomplete data—persistent issues in dynamic manufacturing environments. To further enhance accuracy, a robust neural network model is employed to predict weld groove alignment, a crucial factor in maintaining weld structural integrity. The LOF algorithm was chosen for its ability to detect spatial anomalies, ensuring the exclusion of erroneous data that could compromise welding precision. Experimental results demonstrate that the combined use of LOF and neural networks significantly improves the operational efficiency of robotic welding, delivering consistently strong and precise welds across diverse manufacturing scenarios. The model achieved an average mean square error of 0.078 and an R² value of 0.995, accurately predicting 99.5 % of data. Therefore, neural network modeling enables accurate interpolation of missing data and real-time adjustments to varying operational conditions.},
  archive      = {J_MLA},
  author       = {Fatemeh Habibkhah and Mehrdad Moallem},
  doi          = {10.1016/j.mlwa.2025.100633},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100633},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Application of machine learning for seam profile identification in robotic welding},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification based on symbolic regression and
probabilistic programming and its application. <em>MLA</em>,
<em>20</em>, 100632. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint roughness coefficient (JRC) is critical to evaluate the strength and deformation behavior of joint rock mass in rock engineering. Various methods have been developed to estimate JRC value based on the statistical parameter of rock joints. The JRC value is uncertain due to the complex, random rock joint. Uncertainty is an essential characteristic of rock joints. However, the traditional determinative method cannot deal with uncertainty during the analysis, evaluation, and characterization of the mechanism for the rock joint. This study developed a novel JRC determination framework to estimate the JRC value and evaluate the uncertainty of rock joints based on symbolic regression and probabilistic programming. The symbolic regression was utilized to generate the general empirical equation with the unknown coefficient for the JRC determination of rock joints. The probabilistic programming was used to quantify the uncertainty of the rock joint roughness. The ten standard rock joint profiles illustrated and investigated the developed framework. And then, the developed framework was applied to the collected rock joint profile from the literature. The predicted JRC value was compared with the traditional empirical equations. The results show that the generalization performance of the developed framework is better than the traditional determinative empirical equation. It provides a scientific, reliable, and helpful to estimate the JRC value and characterize the mechanical behavior of joint rock mass.},
  archive      = {J_MLA},
  author       = {Yuyang Zhao and Hongbo Zhao},
  doi          = {10.1016/j.mlwa.2025.100632},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100632},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Uncertainty quantification based on symbolic regression and probabilistic programming and its application},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key technical indicators for stock market prediction.
<em>MLA</em>, <em>20</em>, 100631. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of technical indicators for forecasting the stock market is widespread among investors and researchers. It is crucial to determine the optimal number of input technical indicators to predict the stock market successfully. However, there is no consensus on which collection of technical indicators is most suitable. The selection of technical indicators for a given forecasting model continues to be an active area of research. To our knowledge, there is limited published work on the importance of technical indicators in various categories such as momentum, trend, volatility, and volume. To identify the key technical indicators for stock market prediction, we employed XGBoost, Random Forest, Support Vector Regression, and LSTM regression techniques using 88 technical indicators as input data. We also used the PCA method for dimension reduction. The results reveal the most significant technical indicators within the momentum, trend, volatility, and volume categories. Our findings provide evidence that the proposed model is highly effective in predicting daily prices (with and without lag in Close price) on the S&amp;P 500 stock index.},
  archive      = {J_MLA},
  author       = {Seyed Mostafa Mostafavi and Ali Reza Hooman},
  doi          = {10.1016/j.mlwa.2025.100631},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100631},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Key technical indicators for stock market prediction},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based state of charge estimation: A
comparison between CatBoost model and c-BLSTM-AE model. <em>MLA</em>,
<em>20</em>, 100629. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The State of Charge (SOC) is a key metric within a Lithium-ion battery management system (BMS). Accurate SOC estimation is essential for enhancing battery longevity and ensuring user safety, making it a critical component of an effective BMS. Although SOC estimation has become an active research area for the machine learning (ML) community, only a handful of works have considered its estimation at negative temperatures. This paper proposes the application of two machine learning-based approaches for SOC estimation that perform well at wide range of temperatures (positive and negative) and varying dynamic loads. The first one is a hybrid deep learning approach based on the Convolutional BLSTM Auto-Encoder (C-BLSTM-AE) model that relies on extracting abstract features from input data. The second one is a CatBoost model that leverages the gradient boosting technique to enhance the prediction made by its constituent trees. The performance of the models is evaluated by comparing their regression accuracy and computational resource utilization. The C-BLSTM-AE model achieves a low Mean Absolute Error (MAE) of 0.52 % under fixed ambient temperature conditions and maintains a MAE of 1.03 % for variable ambient temperatures. The CatBoost model achieves a MAE of 0.69 % with fixed temperature settings and a MAE of 1.09 % under variable temperature conditions.},
  archive      = {J_MLA},
  author       = {Abderrahim Zilali and Mehdi Adda and Khaled Ziane and Maxime Berger},
  doi          = {10.1016/j.mlwa.2025.100629},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100629},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning-based state of charge estimation: A comparison between CatBoost model and C-BLSTM-AE model},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
