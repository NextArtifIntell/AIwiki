<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CVIU_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cviu---1">CVIU - 1</h2>
<ul>
<li><details>
<summary>
(2025). Uncertainty estimation using boundary prediction for medical
image super-resolution. <em>CVIU</em>, <em>256</em>, 104349. (<a
href="https://doi.org/10.1016/j.cviu.2025.104349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image super-resolution can be performed by several deep learning frameworks. However, as the safety of each patient is of primary concern, having models with a high degree of population level accuracy is not enough. Instead of a one size fits all approach, there is a need to measure the reliability and trustworthiness of such models from the point of view of personalized healthcare and precision medicine. Hence, in this paper, we propose a novel approach to predict a range of super-resolved (SR) images that any generative super-resolution model may yield for a given low-resolution (LR) image using residual image prediction. Providing multiple images within the suggested lower and upper bound increases the probability of finding an exact match to the high-resolution (HR) image. To further compare models and provide reliability scores, we estimate the coverage and uncertainty of the models and check if coverage can be improved at the cost of increasing uncertainty. Experimental results on lung CT scans from LIDC-IDRI and Radiopedia COVID-19 CT Images Segmentation datasets show that our models, BliMSR and MoMSGAN, provide the best HR and SR coverage at different levels of residual attention with a comparatively lower uncertainty. We believe our model agnostic approach to uncertainty estimation for generative medical imaging is the first of its kind and would help clinicians decide on the trustworthiness of any super-resolution model in a generalized manner while providing alternate SR images with enhanced details for better diagnosis for each individual patient.},
  archive      = {J_CVIU},
  author       = {Samiran Dey and Partha Basuchowdhuri and Debasis Mitra and Robin Augustine and Sanjoy Kumar Saha and Tapabrata Chakraborti},
  doi          = {10.1016/j.cviu.2025.104349},
  journal      = {Computer Vision and Image Understanding},
  month        = {5},
  pages        = {104349},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Uncertainty estimation using boundary prediction for medical image super-resolution},
  volume       = {256},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
