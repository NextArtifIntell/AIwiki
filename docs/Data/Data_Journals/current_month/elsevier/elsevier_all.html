<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>elsevier_all</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h1 id="elsevier">ELSEVIER</h1>
<h2 id="aij---1">AIJ - 1</h2>
<ul>
<li><details>
<summary>
(2025). The influence of dimensions on the complexity of computing
decision trees. <em>AIJ</em>, <em>343</em>, 104322. (<a
href="https://doi.org/10.1016/j.artint.2025.104322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A decision tree recursively splits a feature space R d and then assigns class labels based on the resulting partition. Decision trees have been part of the basic machine-learning toolkit for decades. A large body of work considers heuristic algorithms that compute a decision tree from training data, usually aiming to minimize in particular the size of the resulting tree. In contrast, little is known about the complexity of the underlying computational problem of computing a minimum-size tree for the given training data. We study this problem with respect to the number d of dimensions of the feature space R d , which contains n training examples. We show that it can be solved in O ( n 2 d + 1 ) time, but under reasonable complexity-theoretic assumptions it is not possible to achieve f ( d ) ⋅ n o ( d / log ⁡ d ) running time. The problem is solvable in ( d R ) O ( d R ) ⋅ n 1 + o ( 1 ) time if there are exactly two classes and R is an upper bound on the number of tree leaves labeled with the first class.},
  archive      = {J_AIJ},
  author       = {Stephen Kobourov and Maarten Löffler and Fabrizio Montecchiani and Marcin Pilipczuk and Ignaz Rutter and Raimund Seidel and Manuel Sorge and Jules Wulms},
  doi          = {10.1016/j.artint.2025.104322},
  journal      = {Artificial Intelligence},
  month        = {6},
  pages        = {104322},
  shortjournal = {Artif. Intell.},
  title        = {The influence of dimensions on the complexity of computing decision trees},
  volume       = {343},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="amc---14">AMC - 14</h2>
<ul>
<li><details>
<summary>
(2025). Sparse image representation through multiple multiresolution
analysis. <em>AMC</em>, <em>500</em>, 129440. (<a
href="https://doi.org/10.1016/j.amc.2025.129440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a strategy for image data sparsification based on a multiple multiresolution representation obtained through a structured tree of filterbanks, where both the filters and decimation matrices may vary with the decomposition level. As an extension of standard wavelet and wavelet-like approaches, our method also captures directional anisotropic information of the image while maintaining a controlled implementation complexity due to its filterbank structure and to the possibility of expressing the employed 2-D filters in an almost separable aspect. The focus of this work is on the transformation stage of image compression, emphasizing the sparsification of the transformed data. The proposed algorithm exploits the redundancy of the transformed image by applying an efficient sparse selection strategy, retaining a minimal yet representative subset of coefficients while preserving most of the energy of the data.},
  archive      = {J_AMC},
  author       = {Mariantonia Cotronei and Dörte Rüweler and Tomas Sauer},
  doi          = {10.1016/j.amc.2025.129440},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129440},
  shortjournal = {Appl. Math. Comput.},
  title        = {Sparse image representation through multiple multiresolution analysis},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of environmental feedback in promoting cooperation
among unequal groups. <em>AMC</em>, <em>500</em>, 129436. (<a
href="https://doi.org/10.1016/j.amc.2025.129436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperation plays a crucial role in addressing social dilemmas, yet inequality complicates the achievement of cooperation. This paper explores how environmental feedback mechanisms influence the evolution of cooperation within unequal groups. We construct a public goods game model that includes productivity and endowment inequalities and introduce a dynamic environmental feedback mechanism to study individual strategy choices in different environmental states. The results indicate that appropriate environmental feedback significantly improves cooperation levels. When there is only productivity inequality, appropriate environmental feedback increases the tendency of all individuals to cooperate, especially those with low productivity. In both productivity and endowment inequality, participants maintain a high level of cooperation when the initial endowment distribution falls within a certain range. Once the initial distribution of endowments exceeds this range, cooperative behavior quickly deteriorates. Our study provides a promising approach to enhancing the propensity for cooperation in unequal populations and highlights the significant role of adequate environmental feedback in promoting cooperation.},
  archive      = {J_AMC},
  author       = {Xiaotong Yu and Haili Liang and Xiaoqiang Ren and Zhihai Rong and Xiaofan Wang and Ming Cao},
  doi          = {10.1016/j.amc.2025.129436},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129436},
  shortjournal = {Appl. Math. Comput.},
  title        = {The role of environmental feedback in promoting cooperation among unequal groups},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The reduction of block-transitive 3-(v,k,2) designs.
<em>AMC</em>, <em>500</em>, 129435. (<a
href="https://doi.org/10.1016/j.amc.2025.129435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the O&#39;Nan-Scott Theorem for classifying the primitive permutation group, the classification problem of 3-design is discussed. And the block-transitive and point-primitive automorphism groups of a 3- ( v , k , 2 ) designs is reduced to affine type and almost simple type.},
  archive      = {J_AMC},
  author       = {Luozhong Gong and Weijun Liu and Shaojun Dai},
  doi          = {10.1016/j.amc.2025.129435},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129435},
  shortjournal = {Appl. Math. Comput.},
  title        = {The reduction of block-transitive 3-(v,k,2) designs},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out-of-equilibrium inference of feeding rates through
population data from generic consumer-resource stochastic dynamics.
<em>AMC</em>, <em>500</em>, 129434. (<a
href="https://doi.org/10.1016/j.amc.2025.129434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical models are often structurally unidentifiable, because different sets of parameters can lead to equal model outcomes. To be useful for prediction and parameter inference from data, stochastic population models need to be identifiable, this meaning that model parameters can be uniquely inferred from a large number of model observations. In particular, precise estimation of feeding rates in consumer-resource dynamics is crucial, because consumer-resource processes are central in determining biomass transport across ecosystems. Model parameters are usually estimated at stationarity, because in that case model analyses are often easier. In this contribution we analyze the problem of parameter redundancy in a multi-resource consumer-resource model, showing that model identifiability depends on whether the dynamics have reached stationarity or not. To be precise, we: (i) Calculate the steady-state and out-of-equilibrium probability distributions of predator&#39;s abundances analytically using generating functions, which allow us to unveil parameter redundancy and carry out proper maximum likelihood estimation. (ii) Conduct in silico experiments by tracking the abundance of consumers that are either searching for or handling prey, data then used for maximum likelihood parameter estimation. (iii) Show that, when model observations are recorded out of equilibrium, feeding parameters are truly identifiable, whereas if sampling is done solely at stationarity, only ratios of rates can be inferred from data (i.e., parameters are redundant). We discuss the implications of our results when inferring parameters of general dynamical models.},
  archive      = {J_AMC},
  author       = {José A. Capitán and David Alonso},
  doi          = {10.1016/j.amc.2025.129434},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129434},
  shortjournal = {Appl. Math. Comput.},
  title        = {Out-of-equilibrium inference of feeding rates through population data from generic consumer-resource stochastic dynamics},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graphs with span 1 and shortest optimal walks. <em>AMC</em>,
<em>500</em>, 129433. (<a
href="https://doi.org/10.1016/j.amc.2025.129433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A span of a given graph G is the maximum distance that two players can keep at all times while visiting all vertices (edges) of G and moving according to certain rules, that produces different variants of span. We prove that the vertex and edge span of the same variant can differ by at most 1 and present a graph where the difference is exactly 1. For all variants of vertex span we present a lower bound in terms of the girth of the graph. Then we study graphs with the strong vertex span equal to 1. We present some nice properties of such graphs and show that interval graphs are contained in the class of graphs having the strong vertex span equal to 1. Finally, we present an algorithm that returns the minimum number of moves needed for both players to traverse all vertices of the given graph G such that in each move the distance between players equals at least the chosen vertex span of G .},
  archive      = {J_AMC},
  author       = {Tanja Dravec and Mirjana Mikalački and Andrej Taranenko},
  doi          = {10.1016/j.amc.2025.129433},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129433},
  shortjournal = {Appl. Math. Comput.},
  title        = {Graphs with span 1 and shortest optimal walks},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximal and maximum induced matchings in connected graphs.
<em>AMC</em>, <em>500</em>, 129432. (<a
href="https://doi.org/10.1016/j.amc.2025.129432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An induced matching is defined as a set of edges whose end-vertices induce a subgraph that is 1-regular. Building upon the work of Gupta et al. (2012) [11] and Basavaraju et al. (2016) [1] , who determined the maximum number of maximal induced matchings in general and triangle-free graphs respectively, this paper extends their findings to connected graphs with n vertices. We establish a tight upper bound on the number of maximal and maximum induced matchings, as detailed below: { ( n 2 ) if 1 ≤ n ≤ 8 ; ( ⌊ n 2 ⌋ 2 ) ⋅ ( ⌈ n 2 ⌉ 2 ) − ( ⌊ n 2 ⌋ − 1 ) ⋅ ( ⌈ n 2 ⌉ − 1 ) + 1 if 9 ≤ n ≤ 13 ; 10 n − 1 5 + n + 144 30 ⋅ 6 n − 6 5 if 14 ≤ n ≤ 30 ; 10 n − 1 5 + n − 1 5 ⋅ 6 n − 6 5 if n ≥ 31 . This result not only provides a theoretical upper bound but also implies a practical algorithmic application: enumerating all maximal induced matchings of an n -vertex connected graph in time O ( 1.5849 n ) . Additionally, our work offers an estimate for the number of maximal dissociation sets in connected graphs with n vertices.}},
  archive      = {J_AMC},
  author       = {Bo-Jun Yuan and Zhao-Yu Yang and Lu Zheng and Shi-Cai Gong},
  doi          = {10.1016/j.amc.2025.129432},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129432},
  shortjournal = {Appl. Math. Comput.},
  title        = {Maximal and maximum induced matchings in connected graphs},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parking triangles on a continuous ladder. <em>AMC</em>,
<em>500</em>, 129431. (<a
href="https://doi.org/10.1016/j.amc.2025.129431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we study a variant of the famous Rényi&#39;s car-parking problem in which we are parking isosceles triangles on a strip of height 1, and where the base of the triangle can be on either side of that strip. We find the exact value of the parking constant for this model.},
  archive      = {J_AMC},
  author       = {Stjepan Šebek},
  doi          = {10.1016/j.amc.2025.129431},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129431},
  shortjournal = {Appl. Math. Comput.},
  title        = {Parking triangles on a continuous ladder},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distance ideals of digraphs. <em>AMC</em>, <em>500</em>,
129430. (<a href="https://doi.org/10.1016/j.amc.2025.129430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on strongly connected, strong for short, digraphs since in this setting distance is defined for every pair of vertices. Distance ideals generalize the spectrum and Smith normal form of several distance matrices associated with strong digraphs. We introduce the concept of pattern which allow us to characterize the family Γ 1 of digraphs with only one trivial distance ideal over Z . This result generalizes an analogous result for undirected graphs that states that connected graphs with one trivial ideal over Z consists of either complete graphs or complete bipartite graphs. It turns out that the strong digraphs in Γ 1 consists in the circuit with 3 vertices and a family Λ of strong digraphs that contains complete graphs and complete bipartite graphs, regarded as digraphs. We also compute all distance ideals of some strong digraphs in the family Λ. Then, we explore the distance ideals of circuits, which turns out to be an infinite family of digraphs with unbounded diameter in Γ 2 , that is, digraphs with two trivial distance ideals.},
  archive      = {J_AMC},
  author       = {Carlos A. Alfaro and Teresa I. Hoekstra-Mendoza and Juan Pablo Serrano and Ralihe R. Villagrán},
  doi          = {10.1016/j.amc.2025.129430},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129430},
  shortjournal = {Appl. Math. Comput.},
  title        = {Distance ideals of digraphs},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “mathematical modeling of electro
hydrodynamic non-newtonian fluid flow through tapered arterial stenosis
with periodic body acceleration and applied magnetic field” [applied
mathematics and computation, 362(2019) 124453]]. <em>AMC</em>,
<em>500</em>, 129418. (<a
href="https://doi.org/10.1016/j.amc.2025.129418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A mathematical model is proposed to the pulsatile flow of blood in a tapered artery with mild constriction. This study considers blood as an electrically conducting, non-Newtonian fluid (Jeffrey fluid) which contains magnetic nanoparticles. As blood conducts electricity, it exerts an electric force along the flow direction due to the induced magnetic force by an applied magnetic field which produces Lorentz force and influences the fluidity. Assuming that the pulsatile fluid flow is accelerated by a body force that has in slip velocity at the wall, a set of coupled nonlinear Navier–Stokes equation governing the flow networks is obtained. By employing Laplace and Hankel transforms on the partial equations, we obtain an exact solution for the velocity of flow pattern. Further, the evaluated axial velocity of both fluid and particle are used to find the physiological quantities such as shear stress, flow resistivity and volume of fluid flow. Their dependency on the Womersley parameter, Hartmann number, shape parameter, Jeffrey number and electrokinetic number are calculated numerically and explained graphically. Furthermore, the results are compared within slip and no slip velocities.},
  archive      = {J_AMC},
  author       = {R. Padma and R. Ponalagusamy and R. Tamil Selvi},
  doi          = {10.1016/j.amc.2025.129418},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129418},
  shortjournal = {Appl. Math. Comput.},
  title        = {Corrigendum to “Mathematical modeling of electro hydrodynamic non-newtonian fluid flow through tapered arterial stenosis with periodic body acceleration and applied magnetic field” [Applied mathematics and computation, 362(2019) 124453]]},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maneuvering control of stochastic nonlinear systems with
unknown covariance noise. <em>AMC</em>, <em>500</em>, 129416. (<a
href="https://doi.org/10.1016/j.amc.2025.129416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maneuvering problem for nonlinear systems under stochastic disturbances is investigated in this paper. Firstly, the maneuvering control objectives in their stochastic version are described in the sense of moment with tunable design parameters. Then, quartic Lyapunov functions of stabilizing errors are adopted to deal with the unknown covariance noise. Based on the adaptive law and the filter-gradient update law, an adaptive maneuvering controller is designed by the backstepping technique, which makes the closed-loop system is exponentially practically stable in mean square. Furthermore, both the path tracking error and the velocity assignment error converge to neighborhoods of zero, and the radius of these neighborhoods can be adjusted arbitrarily small by tuning independent parameters. Finally, to demonstrate the controller&#39;s effectiveness in handling unknown covariance and ensuring the practical stability of the closed-loop system, simulations of the mobile robot system in stochastic environments are conducted with various design parameters and covariance settings.},
  archive      = {J_AMC},
  author       = {Ce Zhang and Likang Feng and Zhaojing Wu},
  doi          = {10.1016/j.amc.2025.129416},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129416},
  shortjournal = {Appl. Math. Comput.},
  title        = {Maneuvering control of stochastic nonlinear systems with unknown covariance noise},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reset observer-based containment protocol via
event-triggered strategy for multi-agent networks against aperiodic DoS
attacks. <em>AMC</em>, <em>500</em>, 129415. (<a
href="https://doi.org/10.1016/j.amc.2025.129415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the containment control problem for multi-agent systems (MASs) that are affected by aperiodic denial-of-service attacks using event-triggered strategies (ETSs) in a directed graph. To overcome the limitation of the Luenberger observer, which requires a trade-off between rise time and overshoot, we design a reset observer with improved error convergence performance and more reasonable reset conditions to estimate the states of the MASs. To conserve communication resources, we introduce an ETS into the reset observer-based containment controller. To avoid Zeno behavior, a trigger known as the “Zeno-free trigger” is introduced, which prevents Zeno behavior by setting a fixed triggering interval as the lower bound of the event-triggered interval. Finally, the effectiveness of the designed protocol is demonstrated through a case involving a formation of unmanned air vehicles (UAVs). By comparing the reset observer with the Luenberger observer, the superior performance of the reset observer is demonstrated.},
  archive      = {J_AMC},
  author       = {Dawei Zhao and Wenkang Xiang and Weizhao Song and Lijuan Xu and Chuan Chen and Zhen Wang},
  doi          = {10.1016/j.amc.2025.129415},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129415},
  shortjournal = {Appl. Math. Comput.},
  title        = {Reset observer-based containment protocol via event-triggered strategy for multi-agent networks against aperiodic DoS attacks},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicit forms of interpolating cubic splines and data
smoothing. <em>AMC</em>, <em>500</em>, 129411. (<a
href="https://doi.org/10.1016/j.amc.2025.129411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We express the interpolating cubic splines of class C 2 in their new, explicit forms. We construct the desired forms, the spline&#39;s Hermitian and B-spline representations for both equidistant and arbitrary nodes. During this process we demonstrate an innovative way to compute the inverse of a special class of tridiagonal matrices. Afterward, we propose the corresponding interpolating spline based linear regression models with easily interpretable coefficients suitable for smoothing data of complex structures.},
  archive      = {J_AMC},
  author       = {Csaba Török and Juraj Hudák and Viktor Pristaš and Lubomir Antoni},
  doi          = {10.1016/j.amc.2025.129411},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129411},
  shortjournal = {Appl. Math. Comput.},
  title        = {Explicit forms of interpolating cubic splines and data smoothing},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An evolutionary game-based vicsek model with a fixed number
of neighbors. <em>AMC</em>, <em>500</em>, 129403. (<a
href="https://doi.org/10.1016/j.amc.2025.129403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the face of collective motion, people often face a binary decision: they may interact with others and pay for communication, or they can choose to go alone and forgo these costs. Evolutionary game theory (EGT) emerges in this setting as a crucial paradigm to address this complex issue. In this study, an EGT-based Vicsek with a fixed number of neighbors is proposed. It assumed that the agent had a limited view and just considered a certain number of neighbors. Agents exhibit varying movement patterns depending on the strategies they choose. Each agent&#39;s payoff depends on balancing the benefits of group movement against the communication costs with selected neighbors. Using the Fermi rule, individuals adjust their strategies accordingly. The study indicates that agents achieve the highest levels of cooperation and the fastest convergence times in high-density environments. When density is constant, increasing the number of neighbors enhances the synchronization; when the number of neighbors remains unchanged, a lower density leads to better synchronization. Additionally, the results show that EGT could boost the synchronization and accelerate the convergence of self-propelled agents.},
  archive      = {J_AMC},
  author       = {Hui Zhao and Zhenyu Zhang and Igor Tchappi and Li Li},
  doi          = {10.1016/j.amc.2025.129403},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129403},
  shortjournal = {Appl. Math. Comput.},
  title        = {An evolutionary game-based vicsek model with a fixed number of neighbors},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability evaluation of conditional recursive networks
under h-conditional restriction. <em>AMC</em>, <em>500</em>, 129399. (<a
href="https://doi.org/10.1016/j.amc.2025.129399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the number of links and processors in an interconnection network increases, faulty links and processors are constantly emerging. When a network fails, how to evaluate the state of the network and optimize the reliability of the network itself is the focus of attention in recent years. Therefore, the design of network structure and network reliability evaluation are particularly significant. In recent years, connectivity, especially h -conditional restricted connectivity, has been widely discussed by scholars. In this paper, a family of composite network is constructed on the basis of complete graph K l ( l ≥ 3 is an odd integer), named conditional recursive networks (simply called CRNs). It contains the common network alternating group network ( A N m ) and some unknown networks. In order to further reflect the reliability of composite network CRNs, we determine connectivity and h -conditional restricted connectivity for 0 ≤ h ≤ l − 1 . As an application, we get the connectivity and h -conditional restricted connectivity of A N m directly.},
  archive      = {J_AMC},
  author       = {Hong Zhang and Hong Bian and Jixiang Meng},
  doi          = {10.1016/j.amc.2025.129399},
  journal      = {Applied Mathematics and Computation},
  month        = {9},
  pages        = {129399},
  shortjournal = {Appl. Math. Comput.},
  title        = {Reliability evaluation of conditional recursive networks under h-conditional restriction},
  volume       = {500},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="artmed---9">ARTMED - 9</h2>
<ul>
<li><details>
<summary>
(2025). Deep learning method for malaria parasite evaluation from
microscopic blood smear. <em>ARTMED</em>, <em>163</em>, 103114. (<a
href="https://doi.org/10.1016/j.artmed.2025.103114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective Malaria remains a leading cause of global morbidity and mortality, responsible for approximately 5,97,000 deaths according to World Malaria Report 2024. The study aims to systematically review current methodologies for automated analysis of the Plasmodium genus in malaria diagnostics. Specifically, it focuses on computer-assisted methods, examining databases, blood smear types, staining techniques, and diagnostic models used for malaria characterization while identifying the limitations and contributions of recent studies. Methods A systematic literature review was conducted following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Peer-reviewed and published studies from 2020 to 2024 were retrieved from Web of Science and Scopus. Inclusion criteria focused on studies utilizing deep learning and machine learning models for automated malaria detection from microscopic blood smears. The review considered various blood smear types, staining techniques, and diagnostic models, providing a comprehensive evaluation of the automated diagnostic landscape for malaria. Results The NIH database is the standardized and most widely tested database for malaria diagnostics. Giemsa stained-thin blood smear is the most efficient diagnostic method for the detection and observation of the plasmodium lifecycle. This study has been able to identify three categories of ML models most suitable for digital diagnostic of malaria, i.e., Most Accurate- ResNet and VGG with peak accuracy of 99.12 %, Most Popular- custom CNN-based models used by 58 % of studies, and least complex- CADx model. A few pre and post-processing techniques like Gaussian filter and auto encoder for noise reduction have also been discussed for improved accuracy of models. Conclusion Automated methods for malaria diagnostics show considerable promise in improving diagnostic accuracy and reducing human error. While deep learning models have demonstrated high performance, challenges remain in data standardization and real-world application. Addressing these gaps could lead to more reliable and scalable diagnostic tools, aiding global malaria control efforts.},
  archive      = {J_ARTMED},
  author       = {Abhinav Dahiya and Devvrat Raghuvanshi and Chhaya Sharma and Kamaldeep Joshi and Ashima Nehra and Archana Sharma and Radha Jangra and Parul Badhwar and Renu Tuteja and Sarvajeet S. Gill and Ritu Gill},
  doi          = {10.1016/j.artmed.2025.103114},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {103114},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning method for malaria parasite evaluation from microscopic blood smear},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Histopathology image classification based on semantic
correlation clustering domain adaptation. <em>ARTMED</em>, <em>163</em>,
103110. (<a href="https://doi.org/10.1016/j.artmed.2025.103110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been successfully applied to histopathology image classification tasks. However, the performance of deep models is data-driven, and the acquisition and annotation of pathological image samples are difficult, which limit the model&#39;s performance. Compared to whole slide images (WSI) of patients, histopathology image datasets of animal models are easier to acquire and annotate. Therefore, this paper proposes an unsupervised domain adaptation method based on semantic correlation clustering for histopathology image classification. The aim is to utilize Minmice model histopathology image dataset to achieve the classification and recognition of human WSIs. Firstly, the multi-scale fused features extracted from the source and target domains are normalized and mapped. In the new feature space, the cosine distance between class centers is used to measure the semantic correlation between categories. Then, the domain centers, class centers, and sample distributions are self-constrainedly aligned. Multi-granular information is applied to achieve cross-domain semantic correlation knowledge transfer between classes. Finally, the probabilistic heatmap is used to visualize the model&#39;s prediction results and annotate the cancerous regions in WSIs. Experimental results show that the proposed method has high classification accuracy for WSI, and the annotated result is close to manual annotation, indicating its potential for clinical applications.},
  archive      = {J_ARTMED},
  author       = {Pin Wang and Jinhua Zhang and Yongming Li and Yurou Guo and Pufei Li and Rui Chen},
  doi          = {10.1016/j.artmed.2025.103110},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {103110},
  shortjournal = {Artif. Intell. Med.},
  title        = {Histopathology image classification based on semantic correlation clustering domain adaptation},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Voice analysis in parkinson’s disease - a systematic
literature review. <em>ARTMED</em>, <em>163</em>, 103109. (<a
href="https://doi.org/10.1016/j.artmed.2025.103109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and aim: Parkinson’s disease is a neurodegenerative disease. It is often diagnosed at an advanced stage, which can influence the control over the illness. Therefore, the possibility of diagnosing Parkinson’s disease at an earlier stage, and possibly prognosticate it, could be an advantage. Given this, a literature review that covers current studies in the field is relevant. Methods: The aim of this study is to present a systematic literature review in which the models used for the diagnosis and prognosis of Parkinson’s disease through voice and speech assessment are elucidated. Three databases were consulted to obtain the studies between 2019 and 2023: SienceDirect, IEEE Xplore and ACM Library . Results: One hundred and six studies were considered eligible, considering the definition of inclusion and exclusion criteria. The vast majority of these studies (94.34%) focus on diagnosing the disease, while the remainder (11.32%) focus on prognosis. Conclusion: Voice analysis for the diagnosis and prognosis of Parkinson’s disease using machine learning techniques can be achieved, with very satisfactory performance results, like is demonstrated in this systematic literature review.},
  archive      = {J_ARTMED},
  author       = {Daniela Xavier and Virginie Felizardo and Beatriz Ferreira and Henriques Zacarias and Mehran Pourvahab and Leonice Souza-Pereira and Nuno M. Garcia},
  doi          = {10.1016/j.artmed.2025.103109},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {103109},
  shortjournal = {Artif. Intell. Med.},
  title        = {Voice analysis in parkinson’s disease - a systematic literature review},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparing neural language models for medical concept
representation and patient trajectory prediction. <em>ARTMED</em>,
<em>163</em>, 103108. (<a
href="https://doi.org/10.1016/j.artmed.2025.103108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective representation of medical concepts is crucial for secondary analyses of electronic health records. Neural language models have shown promise in automatically deriving medical concept representations from clinical data. However, the comparative performance of different language models for creating these empirical representations, and the extent to which they encode medical semantics, has not been extensively studied. This study aims to address this gap by evaluating the effectiveness of three popular language models - word2vec, fastText, and GloVe - in creating medical concept embeddings that capture their semantic meaning. By using a large dataset of digital health records, we created patient trajectories and used them to train the language models. We then assessed the ability of the learned embeddings to encode semantics through an explicit comparison with biomedical terminologies, and implicitly by predicting patient outcomes and trajectories with different levels of available information. Our qualitative analysis shows that empirical clusters of embeddings learned by fastText exhibit the highest similarity with theoretical clustering patterns obtained from biomedical terminologies, with a similarity score between empirical and theoretical clusters of 0.88, 0.80, and 0.92 for diagnosis, procedure, and medication codes, respectively. Conversely, for outcome prediction, word2vec and GloVe tend to outperform fastText, with the former achieving AUROC as high as 0.78, 0.62, and 0.85 for length-of-stay, readmission, and mortality prediction, respectively. In predicting medical codes in patient trajectories, GloVe achieves the highest performance for diagnosis and medication codes (AUPRC of 0.45 and of 0.81, respectively) at the highest level of the semantic hierarchy, while fastText outperforms the other models for procedure codes (AUPRC of 0.66). Our study demonstrates that subword information is crucial for learning medical concept representations, but global embedding vectors are better suited for more high-level downstream tasks, such as trajectory prediction. Thus, these models can be harnessed to learn representations that convey clinical meaning, and our insights highlight the potential of using machine learning techniques to semantically encode medical data.},
  archive      = {J_ARTMED},
  author       = {Alban Bornet and Dimitrios Proios and Anthony Yazdani and Fernando Jaume-Santero and Guy Haller and Edward Choi and Douglas Teodoro},
  doi          = {10.1016/j.artmed.2025.103108},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {103108},
  shortjournal = {Artif. Intell. Med.},
  title        = {Comparing neural language models for medical concept representation and patient trajectory prediction},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRExplainer: Quantifiable interpretability in drug response
prediction with directed graph convolutional network. <em>ARTMED</em>,
<em>163</em>, 103101. (<a
href="https://doi.org/10.1016/j.artmed.2025.103101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the response of a cancer cell line to a therapeutic drug is pivotal for personalized medicine. Despite numerous deep learning methods that have been developed for drug response prediction, integrating diverse information about biological entities and predicting the directional response remain major challenges. Here, we propose a novel interpretable predictive model, DRExplainer, which leverages a directed graph convolutional network to enhance the prediction in a directed bipartite network framework. DRExplainer constructs a directed bipartite network integrating multi-omics profiles of cell lines, the chemical structure of drugs and known drug response to achieve directed prediction. Then, DRExplainer identifies the most relevant subgraph to each prediction in this directed bipartite network by learning a mask, facilitating critical medical decision-making. Additionally, we introduce a quantifiable method for model interpretability that leverages a ground truth benchmark dataset curated from biological features. In computational experiments, DRExplainer outperforms state-of-the-art predictive methods and another graph-based explanation method under the same experimental setting. Finally, the case studies further validate the interpretability and the effectiveness of DRExplainer in predictive novel drug response. Our code is available at: https://github.com/vshy-dream/DRExplainer .},
  archive      = {J_ARTMED},
  author       = {Haoyuan Shi and Tao Xu and Xiaodi Li and Qian Gao and Zhiwei Xiong and Junfeng Xia and Zhenyu Yue},
  doi          = {10.1016/j.artmed.2025.103101},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {103101},
  shortjournal = {Artif. Intell. Med.},
  title        = {DRExplainer: Quantifiable interpretability in drug response prediction with directed graph convolutional network},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing diagnosis prediction with adaptive disease
representation learning. <em>ARTMED</em>, <em>163</em>, 103098. (<a
href="https://doi.org/10.1016/j.artmed.2025.103098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosis prediction predicts which diseases a patient is most likely to suffer from in the future based on their historical electronic health records. The time series model can better capture the temporal progression relationship of patient diseases, but ignores the semantic correlation between all diseases; in fact, multiple diseases that are often diagnosed at the same time reflect hidden patterns that are conducive to diagnosis, so predefined global disease co-occurrence graph can help the model understand disease relationships. But it may contain a lot of noise and ignore the semantic adaptation of the disease under the diagnosis target. To this end, we propose a graph-driven end-to-end framework, named A daptive D isease R epresentation L earning (ADRL), obtain disease representation after learning complex disease relationships, and then use it to improve diagnosis prediction performance. This model introduces an adaptive mechanism to dynamically adjust and optimize disease relationships by performing self-supervised perturbations on a predefined global disease co-occurrence graph, thereby learning a global disease relationship graph that contains complex semantic association information between diseases. The computational burden of adaptive global disease graph can be further alleviated by the proposed SVD-based accelerator. Finally, experimental results on two real-world EHR datasets show that the proposed model outperforms existing models in diagnosis prediction.},
  archive      = {J_ARTMED},
  author       = {Hengliang Cheng and Shibo Li and Tao Shen and Weihua Li},
  doi          = {10.1016/j.artmed.2025.103098},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {103098},
  shortjournal = {Artif. Intell. Med.},
  title        = {Enhancing diagnosis prediction with adaptive disease representation learning},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking mitosis detection: Towards diverse data and
feature representation for better domain generalization.
<em>ARTMED</em>, <em>163</em>, 103097. (<a
href="https://doi.org/10.1016/j.artmed.2025.103097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitosis detection is one of the fundamental tasks in computational pathology, which is extremely challenging due to the heterogeneity of mitotic cell. Most of the current studies solve the heterogeneity in the technical aspect by increasing the model complexity. However, lacking consideration of the biological knowledge and the complex model design may lead to the overfitting problem while limited the generalizability of the detection model. In this paper, we systematically study the morphological appearances in different mitotic phases as well as the ambiguous non-mitotic cells and identify that balancing the data and feature diversity can achieve better generalizability. Based on this observation, we propose a novel generalizable framework (MitDet) for mitosis detection. The data diversity is considered by the proposed diversity-guided sample balancing (DGSB). And the feature diversity is preserved by inter- and intra- class feature diversity-preserved module (InCDP). Stain enhancement (SE) module is introduced to enhance the domain-relevant diversity of both data and features simultaneously. Extensive experiments have demonstrated that our proposed model outperforms all the state-of-the-art (SOTA) approaches in several popular mitosis detection datasets in both internal and unseen test sets using point annotations only. Comprehensive ablation studies have also proven the effectiveness of the rethinking of data and feature diversity balancing. By analyzing the results quantitatively and qualitatively, we believe that our proposed model not only achieves SOTA performance but also might inspire the future studies in new perspectives. Code is available at https://github.com/linjiatai/MitDet .},
  archive      = {J_ARTMED},
  author       = {Jiatai Lin and Hao Wang and Danyi Li and Jing Wang and Bingchao Zhao and Zhenwei Shi and Changhong Liang and Guoqiang Han and Li Liang and Zaiyi Liu and Chu Han},
  doi          = {10.1016/j.artmed.2025.103097},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {103097},
  shortjournal = {Artif. Intell. Med.},
  title        = {Rethinking mitosis detection: Towards diverse data and feature representation for better domain generalization},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital phenotyping for mental health based on data
analytics: A systematic literature review. <em>ARTMED</em>,
<em>163</em>, 103094. (<a
href="https://doi.org/10.1016/j.artmed.2025.103094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even though mental health is a human right, mental disorders still affect millions of people worldwide. Untreated and undertreated mental health conditions may lead to suicide, which generates more than 700,000 deaths annually around the world. The broad adoption of smartphones and wearable devices allowed the recording and analysis of human behaviors in digital devices, which might reveal mental health symptoms. This analysis constitutes digital phenotyping research, referring to frequent and constant measurement of human phenotypes in situ based on data from smartphones and other personal digital devices. Therefore, this article presents a systematic literature review providing a computer science view on data analytics for digital phenotyping in mental health. This study reviewed 5,422 articles from ten academic databases published up to September 2024, generating a final list of 74 studies. The investigated databases are ACM, IEEE Xplore, PsycArticles, PsycInfo, Pubmed, Science Direct, Scopus, Springer, Web of Science, and Wiley. We investigated ten research questions, considering explored data, employed devices, and techniques for data analysis. This review also organizes the application domains and mental health conditions, data analytics techniques, and current research challenges. This study found a growing research interest in digital phenotyping for mental health in recent years. Current approaches still present a high dependence on self-reported measures of mental health status, but there is evidence of the employment of smartphones for leveraging passive data collection. Traditional machine learning techniques are the main explored strategies for analyzing the large amount of collected data. In this regard, published approaches deeply focused on data analysis, generating opportunities concerning the implementation of resources for assisting individuals suffering from mental disorders.},
  archive      = {J_ARTMED},
  author       = {Wesllei Felipe Heckler and Luan Paris Feijó and Juliano Varella de Carvalho and Jorge Luis Victória Barbosa},
  doi          = {10.1016/j.artmed.2025.103094},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {103094},
  shortjournal = {Artif. Intell. Med.},
  title        = {Digital phenotyping for mental health based on data analytics: A systematic literature review},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning based estimation of heart surface potentials.
<em>ARTMED</em>, <em>163</em>, 103093. (<a
href="https://doi.org/10.1016/j.artmed.2025.103093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiographic imaging (ECGI) aims to noninvasively estimate heart surface potentials starting from body surface potentials. This is classically based on geometric information on the torso and the heart from imaging, which complicates clinical application. In this study, we aim to develop a deep learning framework to estimate heart surface potentials solely from body surface potentials, enabling wider clinical use. The framework introduces two main components: the transformation of 3D torso and heart geometries into standard 2D representations, and the development of a customized deep learning network model. The 2D torso and heart representations maintain a consistent layout across different subjects, making the proposed framework applicable to different torso-heart geometries. With spatial information incorporated in the 2D representations, the torso-heart physiological relationship can be learnt by the network. The deep learning model is based on a Pix2Pix network, adapted to work with 2.5D data in our task, i.e., 2D body surface potential maps (BSPMs) and 2D heart surface potential maps (HSPMs) with time sequential information. We propose a new loss function tailored to this specific task, which uses a cosine similarity and different weights for different inputs. BSPMs and HSPMs from 11 healthy subjects (8 females and 3 males) and 29 idiopathic ventricular fibrillation (IVF) patients (11 females and 18 males) were used in this study. Performance was assessed on a test set by measuring the similarity and error between the output of the proposed model and the solution provided by mainstream ECGI, by comparing HSPMs, the concatenated electrograms (EGMs), and the estimated activation time (AT) and recovery time (RT). The mean of the mean absolute error (MAE) for the HSPMs was 0.012 ± 0.011, and the mean of the corresponding structural similarity index measure (SSIM) was 0.984 ± 0.026. The mean of the MAE for the EGMs was 0.004 ± 0.004, and the mean of the corresponding Pearson correlation coefficient (PCC) was 0.643 ± 0.352. Results suggest that the model is able to precisely capture the structural and temporal characteristics of the HSPMs. The mean of the absolute time differences between estimated and reference activation times was 6.048 ± 5.188 ms, and the mean of the absolute differences for recovery times was 18.768 ± 17.299 ms. Overall, results show similar performance between the proposed model and standard ECGI, exhibiting low error and consistent clinical patterns, without the need for CT/MRI. The model shows to be effective across diverse torso-heart geometries, and it successfully integrates temporal information in the input. This in turn suggests the possible use of this model in cost effective clinical scenarios like patient screening or post-operative follow-up.},
  archive      = {J_ARTMED},
  author       = {Tiantian Wang and Joël M.H. Karel and Niels Osnabrugge and Kurt Driessens and Job Stoks and Matthijs J.M. Cluitmans and Paul G.A. Volders and Pietro Bonizzi and Ralf L.M. Peeters},
  doi          = {10.1016/j.artmed.2025.103093},
  journal      = {Artificial Intelligence in Medicine},
  month        = {5},
  pages        = {103093},
  shortjournal = {Artif. Intell. Med.},
  title        = {Deep learning based estimation of heart surface potentials},
  volume       = {163},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="asoc---11">ASOC - 11</h2>
<ul>
<li><details>
<summary>
(2025). A dynamic parameters genetic algorithm for collaborative
strike task allocation of unmanned aerial vehicle clusters towards
heterogeneous targets. <em>ASOC</em>, <em>175</em>, 113075. (<a
href="https://doi.org/10.1016/j.asoc.2025.113075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative strikes by unmanned aerial vehicle clusters (UAVCs) is becoming a key focus in the future air warfare, which can significantly enhance warfare effectiveness and reduce costs. To exactly describe the real battlefield scenarios, various heterogeneous strike-targets should be embedded. However, it will significantly increase the complexity of multi-constraint combinatorial optimization problem, thus the traditional genetic algorithm (GA) is difficult to solve efficiently due to its unchanged gene operator. In this paper, a dynamic parameters genetic algorithm has been proposed for UAVCs collaborative task allocation towards heterogeneous targets. Firstly, according to the differences of type, value, combat and defense, the heterogeneous strike-targets have been abstracted into strike target points and the UAVCs have been formulated into a set. Secondly, an innovative multiple unmanned aerial vehicles duplicate tasks orienteering problem (MUDTOP) model has been built to achieve multiple strikes on certain targets. Finally, the new triple-chromosome encoding and duplicate gene segments have been designed, and a novel genetic algorithm called DPGA-TEDG has been presented through dynamic gene operator. Experimental comparison results across various battlefield scales demonstrate that the outcomes of the proposed DPGA-TEDG algorithm not only meet practical requirements, but also outperform that of the other three algorithms in both optimality and robustness. Especially, in the battlefield scale environment of 180 km* 180 km, the average objective value of DPGA-TEDG is better than that of traditional genetic algorithm (GA-TEDG), simulated annealing algorithm (SA) and particle swarm optimization algorithm (PSO) about 2.71 %, 6.58 % and 20.49 %, respectively.},
  archive      = {J_ASOC},
  author       = {Chao Zhang and Jianlu Guo and Fei Wang and Boyuan Chen and Chunshi Fan and Linghui Yu and Zhiwen Wang},
  doi          = {10.1016/j.asoc.2025.113075},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113075},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A dynamic parameters genetic algorithm for collaborative strike task allocation of unmanned aerial vehicle clusters towards heterogeneous targets},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time stabilization of fractional-order neural
networks with time-varying delays: A generalized inequality approach and
controller design. <em>ASOC</em>, <em>175</em>, 113074. (<a
href="https://doi.org/10.1016/j.asoc.2025.113074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores finite-time stabilization methods for a specific class of neural networks with fractional-order dynamics and time-varying delays. The first contribution involves introducing a generalized inequality, an extension of the existing one, to analyze the finite-time stabilization behavior of the addressed model. This extension has successfully addressed numerous limitations and challenges present in existing works. Additionally, an explicit formula for calculating the finite-time stabilization duration is provided. Subsequently, two types of controllers—delay-independent and delay-dependent feedback controllers—are developed to achieve finite-time stabilization for the neural networks under consideration. The conditions for stability, dependent on both the delay and the order, are formulated as linear matrix inequalities using inequality techniques, Lyapunov stability theory, and the newly proposed finite-time stability inequality. These conditions ensure that the fractional-order neural network model is stabilized in finite-time. The efficacy of the suggested design approach is demonstrated through two numerical case studies.},
  archive      = {J_ASOC},
  author       = {M. Shafiya and N. Padmaja},
  doi          = {10.1016/j.asoc.2025.113074},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113074},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Finite-time stabilization of fractional-order neural networks with time-varying delays: A generalized inequality approach and controller design},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thinking innovation strategy (TIS): A novel mechanism for
metaheuristic algorithm design and evolutionary update. <em>ASOC</em>,
<em>175</em>, 113071. (<a
href="https://doi.org/10.1016/j.asoc.2025.113071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metaheuristic optimization algorithm(MHS) is a global optimization method inspired by natural phenomena, demonstrating superior performance in specific application scenarios. Traditional optimization algorithms utilize two main concepts: exploration, to expand the search range, and exploitation, to enhance solution accuracy. However, as problem complexity and application scenarios increase, MHS struggles to balance exploration and exploitation to find the optimal solution. Therefore, this paper introduces innovative characteristics of individual thinking and proposes a new Thinking Innovation Strategy (TIS). TIS does not aim for an optimal solution but seeks global optimization based on successful individuals, enhancing algorithm performance through survival of the fittest. This paper applies TIS strategies to improve various MHS algorithms and evaluates their performance on 57 engineering problems and the IEEE CEC2020 benchmarks. Experimental results indicate that the TIS-enhanced algorithms outperform the original versions across 57 engineering problems, according to Friedman ranking and Wilcoxon rank-sum test results. Some algorithms show significant improvement, demonstrating the feasibility and practicality of TIS for optimization problems. The TIS (LSHADE_SPACMA) of the source code can be accessed through the following ways: https://github.com/LIANLIAN-Serendipity/TIS-},
  archive      = {J_ASOC},
  author       = {Heming Jia and Xuelian Zhou and Jinrui Zhang},
  doi          = {10.1016/j.asoc.2025.113071},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113071},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Thinking innovation strategy (TIS): A novel mechanism for metaheuristic algorithm design and evolutionary update},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A performance-driven multi-stage KNN approach for local
adaptive classification. <em>ASOC</em>, <em>175</em>, 113070. (<a
href="https://doi.org/10.1016/j.asoc.2025.113070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key issue of the K-Nearest Neighbors (KNN) algorithm is determining the optimal neighborhood size K , which limits the widespread applicability of KNN. To address this, a performance-driven multi-stage KNN (PMKNN) approach is proposed in this paper. Given a set of alternative K values, the traditional KNN algorithm is initially employed in the PMKNN approach to identify the optimal K values for all known samples. A convex optimization model is then constructed based on the least squares loss function to learn the correlation between known samples and query samples. After the learned correlation is used to evaluate the performances of all candidate K values in classifying query samples, a weighted majority voting process is designed to generate the final classification results. Unlike existing KNN approaches, the proposed PMKNN approach considers multiple optimal K values for each query sample, enhancing classification stability and reliability. The proposed approach also reduces the negative impact of inappropriate K values on classification performance. An experimental study is conducted using twenty real-world classification datasets collected from two public data repositories to assess the effectiveness of the proposed PMKNN approach. The relevant results highlight the high classification performance of the proposed PMKNN approach compared to seven state-of-the-art KNN methods and underscore its predictive stability compared to the traditional KNN algorithm using all possible K values.},
  archive      = {J_ASOC},
  author       = {Che Xu and Zhenhua Fan},
  doi          = {10.1016/j.asoc.2025.113070},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113070},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A performance-driven multi-stage KNN approach for local adaptive classification},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective cuckoo search algorithm using generalized
lèvy flight and dissimilar egg identification for multispectral image
thresholding. <em>ASOC</em>, <em>175</em>, 113054. (<a
href="https://doi.org/10.1016/j.asoc.2025.113054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cuckoo Search (CS) stands as a highly efficient meta-heuristic optimization algorithm. Existing literature showcases the ability of CS in multi-objective scenarios, delineated by the three fundamental rules. However, the first rule of the algorithm incurs the cost of a generation to update a single nest, while the third rule necessitates hit-and-trial methods for parameter adjustment. To address these concerns, a multi-objective cuckoo search algorithm is proposed in this paper. The algorithm builds upon a generalized concept of Lèvy Flight for generating new solutions. Problem-specific, constraint-based strategies for identifying the best nest and dissimilar eggs are also introduced. The algorithm is further applied to solve multispectral remote sensing image thresholding problem. Prior studies have underscored the efficiency of entropy and clustering-based thresholding methods over other techniques. Nevertheless, most entropy-based approaches entail converting color images to grayscale before segmentation, potentially sacrificing crucial spectral information and consequently degrading segmentation algorithm’s performance. To avoid these limitations, this research introduces an entropy-based thresholding method to segment a color image without converting it to grayscale. The experiments are carried out using very high resolution (VHR) and coarse resolution (CR) multispectral (MS) images from the satellite sensors Pl’eidas-1B and Sentinel-2b, respectively. The proposed methods undergo validation against four state-of-the-art techniques on benchmark functions and six clustering indexes, respectively.},
  archive      = {J_ASOC},
  author       = {Ramen Pal and Pritam Roy and Srijon Mallick and Somnath Mukhopadhyay and Sunita Sarkar and Mike Hinchey},
  doi          = {10.1016/j.asoc.2025.113054},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113054},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective cuckoo search algorithm using generalized lèvy flight and dissimilar egg identification for multispectral image thresholding},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cancelable binary biometric template generation scheme based
on partial walsh transformation and MinHash algorithm. <em>ASOC</em>,
<em>175</em>, 113049. (<a
href="https://doi.org/10.1016/j.asoc.2025.113049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of biometrics, biometric templates stored in biometric systems are at serious risk of security and privacy breaches. Cancelable biometric scheme is an effective remedy when many unprotected biometric templates are compromised. We propose a cancelable binary biometric template generation scheme based on the partial Walsh transformation and the MinHash algorithm to improve recognition accuracy and generation efficiency. Firstly, the partial Walsh matrix transforms the high-dimensional original biometric feature into a low-dimensional space. Then, protected cancelable binary biometric templates are generated based on the proposed sliding window grouping minimum hash algorithm SWG-MinHash. Our scheme demonstrates superior recognition accuracy and generation efficiency on fingerprint and face databases compared to existing schemes. Meanwhile, our scheme satisfies the properties of non-invertibility, revocability, and unlinkability, and is resistant to common security and privacy attacks. Therefore, our scheme effectively mitigates the problem of balancing recognition accuracy, security, and generation efficiency of cancelable biometric schemes and is more practical for biometric systems. The source code of our scheme is available at https://github.com/sscwrx/cbef .},
  archive      = {J_ASOC},
  author       = {Shuaichao Song and Yeming Yang and Miao Yu and Yuming Liao and Weilai Guo and Jiyuan Li and Songhui Guo},
  doi          = {10.1016/j.asoc.2025.113049},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113049},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cancelable binary biometric template generation scheme based on partial walsh transformation and MinHash algorithm},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-expression multi-label feature selection based on fuzzy
decision. <em>ASOC</em>, <em>175</em>, 113046. (<a
href="https://doi.org/10.1016/j.asoc.2025.113046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large amount of high-dimensional data poses a great challenge to multi-label learning. Feature selection is an effective method to alleviate this problem. However, many existing multi-label feature selection models either ignore the intrinsic spatial structure of samples or have no restrictions on the predicted label values. To solve the above problems, a sample self-representation multi-label feature selection method based on fuzzy decision is proposed in this paper. Firstly, a self-representation coefficient matrix of samples is proposed, which not only retains the original data structure information, but also reflects the distribution structure of data. Then, a fuzzy decision function is introduced to fuzzy prediction labels which well represents the membership of a sample to a class and is more consistent with the real label distribution. The L 2 , 1 -norm is imposed on the feature weight matrix to ensure sparsity and the F -norm is introduced into the self-expression matrix to weaken the effects of redundancy and anomalous samples. Finally, the gradient descent method is used to optimize the objective function. Experimental results on 12 multi-label datasets show that the proposed method performs better than other state-of-the-art multi-label feature selection methods, and obtain a significant increase in classification accuracy of about 2%–3% over all the compared approaches.},
  archive      = {J_ASOC},
  author       = {Shibing Pei and Minghao Chen and Changzhong Wang},
  doi          = {10.1016/j.asoc.2025.113046},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113046},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Self-expression multi-label feature selection based on fuzzy decision},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FT-GPNN: A finite-time convergence solution for multi-set
constrained optimization. <em>ASOC</em>, <em>175</em>, 113030. (<a
href="https://doi.org/10.1016/j.asoc.2025.113030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient Neural Networks (GNNs) have demonstrated remarkable progress in handling optimization problems. However, applying GNNs to multi-constrained optimization problems, particularly those with those involving multi-set constraints, poses several challenges. These challenges arise from the complexity of the derivations and the increasing number of constraints. As the number of constraints increases, the optimization problem becomes more complex, making it more challenging for GNN-based methods to effectively identify the optimal solution. Motivated by these challenges, the Finite-Time Gradient Projection Neural Network (FT-GPNN) is introduced for tackling Multi-set Constrained Optimization (MCO). This innovative solution incorporates an Enhanced Sign-Bi-Power (ESBP) activation function and simplifies the design tailored explicitly for MCO. Furthermore, within the Lyapunov stability framework, the theoretical foundation of this model is strengthened by rigorous proof of local convergence. Building upon this foundation, we further establish that our model can achieve convergence within a finite time. To validate the effectiveness of our approach, we present empirical results from numerical experiments conducted under consistent conditions. Notably, our experiments demonstrate that the model using the ESBP activation function outperforms others in terms of finite-time convergence.},
  archive      = {J_ASOC},
  author       = {Huiting He and Chengze Jiang and Zhiyuan Song and Xiuchun Xiao and Neal Xiong},
  doi          = {10.1016/j.asoc.2025.113030},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113030},
  shortjournal = {Appl. Soft. Comput.},
  title        = {FT-GPNN: A finite-time convergence solution for multi-set constrained optimization},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing a cryptocurrency trading system with deep
reinforcement learning utilizing LSTM neural networks and XGBoost
feature selection. <em>ASOC</em>, <em>175</em>, 113029. (<a
href="https://doi.org/10.1016/j.asoc.2025.113029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to present a cryptocurrency trading strategy that addresses market volatility and decision-making challenges using advanced machine learning techniques and a wide range of predictor variables. Specifically, the proposed method is designed to enhance trading decisions by improving the accuracy of market trend forecasts. The approach consists of two primary steps. First, the XGBoost algorithm is applied to identify the most relevant features from market variables, technical indicators, macroeconomic factors, and blockchain-specific data for each cryptocurrency. In the second step, these selected features are fed into a Double Deep Q-Network (DDQN) algorithm incorporating LSTM (Long Short-Term Memory), BiLSTM (Bidirectional Long Short-Term Memory), and GRU (Gated recurrent units) layers to generate trading signals (buy, hold, sell). The model’s performance, tested on Bitcoin and Ethereum data from July 2021 to March 2023, demonstrates that blockchain variables provide crucial insights for trading strategies. Furthermore, combining XGBoost for feature selection with the DDQN model improves all key trading performance metrics, highlighting the significance of feature selection in optimizing deep reinforcement learning agents.},
  archive      = {J_ASOC},
  author       = {Hamidreza Ghadiri and Ehsan Hajizadeh},
  doi          = {10.1016/j.asoc.2025.113029},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113029},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Designing a cryptocurrency trading system with deep reinforcement learning utilizing LSTM neural networks and XGBoost feature selection},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intra and inter-series pattern representations fusion
network for multiple time series forecasting. <em>ASOC</em>,
<em>175</em>, 113024. (<a
href="https://doi.org/10.1016/j.asoc.2025.113024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple time series (MTS) can comprise data collected from various wireless sensor networks in the actual application, and each source provides a distinctive pattern. Most existing neural network methods attempt to model the patterns of individual time series by training a global model using the entire dataset, suffering from insufficient ability to consider the differences among source patterns and lowering the predictability. To address this limitation, we propose the Multiple Time Series Pattern Representation Network(MTS-PRNet), a unified framework consisting of two modules to forecast multiple time series from diverse sources. The first is the intra-series correlation learning module, which explicitly learns the temporal dependencies of time series. The second is the inter-series discriminative representation learning module that learns shapelets as discriminative representations to capture shared features among series. By integrating the covariates map generated by the second module, both intra and inter-series characteristics are captured to provide transferable guidance for increasing predictability. Experiments conducted on 9 datasets verify that our model achieves state-of-the-art performance. In particular, we carry out an ablation study to validate the effectiveness of discriminative representations.},
  archive      = {J_ASOC},
  author       = {Canghong Jin and Tianyi Chen and Hao Ni and Qihao Shi},
  doi          = {10.1016/j.asoc.2025.113024},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {113024},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Intra and inter-series pattern representations fusion network for multiple time series forecasting},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive large neighborhood search incorporating
mixed-integer linear programming for electric vehicle routing problem
with mobile charging and nonlinear battery degradation. <em>ASOC</em>,
<em>175</em>, 112988. (<a
href="https://doi.org/10.1016/j.asoc.2025.112988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The limited driving range and short battery life are obstacles to the widespread adoption of electric vehicles in urban logistics. This study proposes an electric vehicle routing problem with time window, mobile charging, and nonlinear battery degradation. Mobile charging vehicles (MCVs) can be flexibly scheduled to charge the electric delivery vehicles (EDVs) at customer locations, reducing the electricity consumption caused by the detours to the charging stations. The proposed problem is formulated into an arc-based model that incorporates nonlinear battery degradation costs associated with State of Charge (SOC) and charging strategies, thereby enhancing the complexity of the spatio-temporal synchronization mechanism. Constraining a lower SOC can mitigate the battery degradation of EDVs, but it leads to increased charging demands and makes searching for feasible routing solutions more challenging due to the interdependence between MCVs and EDVs. A hybrid adaptive large neighborhood search heuristic algorithm is developed. Dynamic programming is embedded in the algorithm framework to devise charging schemes considering nonlinear battery degradation for the given EDVs’ routes. A mixed-integer linear programming model is formulated to select the combination of labels with continuous charging decisions and design MCVs’ routes. Extensive numerical experiments are conducted to verify the proposed model and algorithm. Experimental results indicate considering battery degradation in the objectives significantly improves the total system costs by optimizing the SOC and charging quantity. Mobile charging can be an alternative for constructing fixed charging facilities due to the charging flexibility of MCVs. The performance of our algorithm is demonstrated through both large-scale instances and a real-world case study on urban logistics.},
  archive      = {J_ASOC},
  author       = {Senyan Yang and Ruiyan Zhang and Ying Ma and Xingquan Zuo},
  doi          = {10.1016/j.asoc.2025.112988},
  journal      = {Applied Soft Computing},
  month        = {5},
  pages        = {112988},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive large neighborhood search incorporating mixed-integer linear programming for electric vehicle routing problem with mobile charging and nonlinear battery degradation},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="autom---37">AUTOM - 37</h2>
<ul>
<li><details>
<summary>
(2025). Cooperative spheroidal coverage control of multi-agent
systems in 3D non-convex environments. <em>AUTOM</em>, <em>176</em>,
112269. (<a
href="https://doi.org/10.1016/j.automatica.2025.112269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimal configuration of multi-agent systems (MASs) has long been a challenging task to fulfill abundant three-dimensional (3D) non-convex coverage operations. This brief proposes a spheroidal coverage control scheme, where a spheroidal partition protocol is designed with a distributed estimator to ensure an equitable workload in each sub-region. Afterwards, a distributed control law is developed to asymptotically deploy each agent to the associated optimal configuration. Significantly, the analytical challenge of the present design lies in the convergence analysis of the three-level cascading systems induced by the proposed spheroidal partition protocol. Finally, numerical simulation is conducted to verify the effectiveness of the present spheroidal coverage control method.},
  archive      = {J_AUTOM},
  author       = {Jiayu Zou and Hai-Tao Zhang and Ning Xing and Xingjian Liu},
  doi          = {10.1016/j.automatica.2025.112269},
  journal      = {Automatica},
  month        = {6},
  pages        = {112269},
  shortjournal = {Automatica},
  title        = {Cooperative spheroidal coverage control of multi-agent systems in 3D non-convex environments},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time formation tracking for heterogeneous
euler–lagrange systems with an uncertain leader. <em>AUTOM</em>,
<em>176</em>, 112268. (<a
href="https://doi.org/10.1016/j.automatica.2025.112268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the finite-time time-varying formation tracking control problem of heterogeneous Euler–Lagrange systems with an uncertain leader. Unlike most existing works, where knowledge of the system dynamics of the leader node is required for follower agents in advance, this paper presents a distributed observer-based finite-time formation tracking control framework that operates independently of the system dynamic knowledge of the leader node. Firstly, two novel classes of finite-time adaptive distributed observers are constructed to estimate both the state and unknown dynamics of the leader system. The associated adaptation parameters can converge to the true values in finite time under an initial excitation condition, rather than the existing restrictive persistently exciting or cooperative finite-time excitation condition. Then, a finite-time formation tracking controller is developed based on the presented finite-time observers; with the help of Lyapunov stability theory, the finite-time formation tracking criterion for the considered system with an uncertain leader is derived from the constructed controller. Finally, a simulation example is provided to demonstrate the effectiveness of the presented finite-time formation tracking controller.},
  archive      = {J_AUTOM},
  author       = {Qing Wang and Xiwang Dong and Zhiyong Chen and Zhi Lian and Jinhu Lü},
  doi          = {10.1016/j.automatica.2025.112268},
  journal      = {Automatica},
  month        = {6},
  pages        = {112268},
  shortjournal = {Automatica},
  title        = {Finite-time formation tracking for heterogeneous Euler–Lagrange systems with an uncertain leader},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid formation control for heterogeneous uncertain linear
two-time-scale systems. <em>AUTOM</em>, <em>176</em>, 112267. (<a
href="https://doi.org/10.1016/j.automatica.2025.112267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates time-varying output formation of interconnected heterogeneous linear two-time-scale systems with model uncertainty. Unlike previous works on the cooperation of interconnected two-time-scale systems, we consider nonidentical dynamics for each agent that may be characterized by different dimensions and time-scaling factors. Additionally, the systems are interconnected through a switching graph with a disconnected topology, rendering more challenging the analysis and the controller design. To address these challenges, a hybrid two-layer hierarchical control protocol is proposed. The upper layer utilizes an impulsive cooperative control strategy to generate local references, enabling discrete-time interactions among agents and thereby reducing the communication burden. The lower layer implements an internal model-based controller for the two-time-scale dynamics to track the generated references, demonstrating robustness against small model uncertainties. Closed-loop analysis is based on input-to-state stability (ISS) results for hybrid systems. Furthermore, the obtained result is extended to achieve the output consensus. Finally, two examples are presented to illustrate the effectiveness of the results.},
  archive      = {J_AUTOM},
  author       = {Yan Lei and Zheng Wang and Xin Wang and Hongyi Li and Irinel-Constantin Morărescu},
  doi          = {10.1016/j.automatica.2025.112267},
  journal      = {Automatica},
  month        = {6},
  pages        = {112267},
  shortjournal = {Automatica},
  title        = {Hybrid formation control for heterogeneous uncertain linear two-time-scale systems},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Output-feedback event-triggered boundary control of
reaction–diffusion PDEs with delayed actuator. <em>AUTOM</em>,
<em>176</em>, 112266. (<a
href="https://doi.org/10.1016/j.automatica.2025.112266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an output-feedback event-triggered delay-compensated boundary control scheme for a class of reaction–diffusion PDEs under a delayed actuator, where an arbitrarily long time delay exists between the PDE plant and the ODE actuator. After treating the time delay as a transport PDE, the overall plant configuration becomes ODE-PDE-PDE. Combining the PDE and ODE backstepping designs, a three-step backstepping transformation is proposed to build the continuous-in-time control law. A PDE observer is designed to track the PDE states required in the control law using a boundary measurement. Then, a dynamic event-triggering mechanism is designed, based on the evaluation of the overall ODE-PDE-PDE system, to determine the updating times of the control signal. In the resulting output-feedback event-based closed-loop system, a strictly positive lower bound of the minimal dwell time is found, which is independent of initial conditions. As a result, the absence of a Zeno behavior is guaranteed. Besides, exponential convergence to zero of all signals is proved via Lyapunov analysis, including the H 1 norm of the transport PDE state, the L 2 norm of the reaction–diffusion PDE and observer states, the actuator states, the internal dynamic variable in the event-triggering mechanism, as well as the control input. The effectiveness of the proposed method is illustrated by numerical simulation.},
  archive      = {J_AUTOM},
  author       = {Hongpeng Yuan and Ji Wang and Jianping Zeng and Weiyao Lan},
  doi          = {10.1016/j.automatica.2025.112266},
  journal      = {Automatica},
  month        = {6},
  pages        = {112266},
  shortjournal = {Automatica},
  title        = {Output-feedback event-triggered boundary control of reaction–diffusion PDEs with delayed actuator},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimistic approach to cost-aware predictive control.
<em>AUTOM</em>, <em>176</em>, 112263. (<a
href="https://doi.org/10.1016/j.automatica.2025.112263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider continuous-time systems subject to a priori unknown state-dependent disturbance inputs. Given a target goal region, our first approach consists of a control scheme that avoids unsafe regions of the state space and observes the disturbance behavior until the goal is reachable with high probability. We leverage collected observations and the mixed monotonicity property of dynamical systems to efficiently obtain high-probability overapproximations of the system’s reachable sets. These overapproximations improve as more observations are collected. For our second approach, we consider the problem of minimizing cost while navigating toward the goal region and modify our previous formulation to allow for the estimated confidence bounds on the disturbance to be adjusted based on what would reduce the overall cost. We explicitly consider the additional cost incurred through exploration and develop a formulation wherein the amount of exploration performed can be directly tuned. We show theoretical results confirming that this confidence bound modification strategy outperforms the previously developed strategy on a simplified system. We demonstrate the first approach on an example of a motorboat navigating a river, then showcase a Monte Carlo simulation comparison of both approaches on a planar multirotor navigating toward a goal region through an unknown wind field.},
  archive      = {J_AUTOM},
  author       = {Michael Enqi Cao and Matthieu Bloch and Samuel Coogan},
  doi          = {10.1016/j.automatica.2025.112263},
  journal      = {Automatica},
  month        = {6},
  pages        = {112263},
  shortjournal = {Automatica},
  title        = {An optimistic approach to cost-aware predictive control},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient and efficient safeguard mechanism design for
deploying untrusted linear controllers. <em>AUTOM</em>, <em>176</em>,
112262. (<a
href="https://doi.org/10.1016/j.automatica.2025.112262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deployment of untrusted controllers is challenging. Such an untrusted controller may be provided by a malicious third party, who claims to deliver optimal control performance but actually attempts to exploit the system. Alternatively, untrusted controllers arising from benign factors such as inaccurate modeling or human error may also destabilize the system and cause security breaches. The system operator, with limited access to the knowledge of the system, may not be able to verify the untrusted controllers offline. To mitigate this risk, we propose a “plug-and-play” modification to the untrusted controller with minimal requirement on system knowledge, which switches to a known stabilizing controller when the norm of the difference between the untrusted and fallback control inputs exceeds a certain threshold. We show that for linear stochastic systems, this safeguard mechanism is both resilient and efficient, in the sense that: 1) the linear–quadratic cost of the system is always bounded even if the original untrusted controller is destabilizing; 2) in case the untrusted controller is stabilizing, the performance loss caused by the safeguard converges super-exponentially to 0 for Gaussian noise, while converging polynomially for general heavy-tailed noise. Finally, we demonstrate the effectiveness of the proposed safeguard strategy via numerical simulation on the Tennessee Eastman Process.},
  archive      = {J_AUTOM},
  author       = {Yiwen Lu and Yilin Mo},
  doi          = {10.1016/j.automatica.2025.112262},
  journal      = {Automatica},
  month        = {6},
  pages        = {112262},
  shortjournal = {Automatica},
  title        = {Resilient and efficient safeguard mechanism design for deploying untrusted linear controllers},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controlling the occurrence sequence of reaction modules
through biochemical relaxation oscillators. <em>AUTOM</em>,
<em>176</em>, 112261. (<a
href="https://doi.org/10.1016/j.automatica.2025.112261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding sequential computations in biochemical environments is challenging because the computations are carried out through chemical reactions, which are inherently disordered. In this paper we apply modular design to specific calculations through chemical reactions and provide a design scheme of biochemical oscillator models in order to generate periodical species for the order regulation of these reaction modules. We take the case of arbitrary multi-module regulation into consideration, analyze the main errors in the regulation process under mass-action kinetics and illustrate our design scheme under existing synthetic biochemical oscillator models.},
  archive      = {J_AUTOM},
  author       = {Xiaopeng Shi and Chuanhou Gao and Denis Dochain},
  doi          = {10.1016/j.automatica.2025.112261},
  journal      = {Automatica},
  month        = {6},
  pages        = {112261},
  shortjournal = {Automatica},
  title        = {Controlling the occurrence sequence of reaction modules through biochemical relaxation oscillators},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean field hierarchical control for production output
adjustment with noisy sticky prices. <em>AUTOM</em>, <em>176</em>,
112260. (<a
href="https://doi.org/10.1016/j.automatica.2025.112260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the hierarchical decentralized solution to mean field production output adjustment. We first introduce a mean field output adjustment model for many firms in a market, where the price is sticky and regulated by a government. Under a given policy of the regulator, we first tackle a centralized game problem, and obtain a system of coupled forward–backward stochastic differential equations (FBSDEs). By decoupling the high-dimensional FBSDEs, a Nash equilibrium strategy is designed for competitive firms. After applying firms’ strategies, we construct a decentralized strategy of the regulator by solving an optimal control problem driven by FBSDEs. By perturbation analysis, the proposed decentralized strategy is shown to be an ɛ -Stackelberg equilibrium.},
  archive      = {J_AUTOM},
  author       = {Bing-Chang Wang},
  doi          = {10.1016/j.automatica.2025.112260},
  journal      = {Automatica},
  month        = {6},
  pages        = {112260},
  shortjournal = {Automatica},
  title        = {Mean field hierarchical control for production output adjustment with noisy sticky prices},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundary output feedback stabilization for 2-d and 3-d
parabolic equations. <em>AUTOM</em>, <em>176</em>, 112259. (<a
href="https://doi.org/10.1016/j.automatica.2025.112259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper addresses the topic of boundary output feedback stabilization of parabolic-type equations, governed by linear differential operators which can be diagonalized by the introduction of adequate weighting functions (by means of the Sturm–Liouville method), and which evolve in bounded spatial domains that are subsets of R d , d = 2 , 3 . Generalizing previous works for the boundary output feedback control of 1-D parabolic PDEs and for the state feedback control of multi-D parabolic PDEs, we report in this paper an output feedback boundary stabilizing control with internal Dirichlet measurements designed by means of a finite-dimensional observer. The reported control design procedure is shown to be systematic for 2-D and 3-D parabolic equations.},
  archive      = {J_AUTOM},
  author       = {Hugo Lhachemi and Ionut Munteanu and Christophe Prieur},
  doi          = {10.1016/j.automatica.2025.112259},
  journal      = {Automatica},
  month        = {6},
  pages        = {112259},
  shortjournal = {Automatica},
  title        = {Boundary output feedback stabilization for 2-D and 3-D parabolic equations},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dominance regions of pursuit-evasion games in
non-anticipative information patterns. <em>AUTOM</em>, <em>176</em>,
112258. (<a
href="https://doi.org/10.1016/j.automatica.2025.112258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evader’s dominance region is an important concept and the foundation of geometric methods for pursuit-evasion games. This article mainly reveals the relevant properties of the evader’s dominance region, especially in non-anticipative information patterns. We can use these properties to research pursuit-evasion games in non-anticipative information patterns. The core problem is under what condition the pursuer has a non-anticipative strategy to prevent the evader leaving its initial dominance region before being captured regardless of the evader’s strategy. We first define the evader’s dominance region by the shortest path distance, and we rigorously prove for the first time that the initial dominance region of the evader is the reachable region of the evader in the open-loop sense. Subsequently, we prove that there exists a non-anticipative strategy by which the pursuer can capture the evader before the evader leaves its initial dominance region’s closure in the absence of obstacles. For cases with obstacles, we provide a counter example to illustrate that such a non-anticipative strategy does not always exist, and provide a necessary condition for the existence of such strategy. Finally, we consider a scenario with a single corner obstacle and provide a sufficient condition for the existence of such a non-anticipative strategy. At the end of this article, we discuss the application of the evader’s dominance region in target defense games. This article has important reference significance for the design of non-anticipative strategies in pursuit-evasion games with obstacles.},
  archive      = {J_AUTOM},
  author       = {Weiwen Huang and Li Liang and Ningsheng Xu and Fang Deng},
  doi          = {10.1016/j.automatica.2025.112258},
  journal      = {Automatica},
  month        = {6},
  pages        = {112258},
  shortjournal = {Automatica},
  title        = {Dominance regions of pursuit-evasion games in non-anticipative information patterns},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Worst-case performance of kalman filtering against
cyber-attacks with true and contaminated information. <em>AUTOM</em>,
<em>176</em>, 112257. (<a
href="https://doi.org/10.1016/j.automatica.2025.112257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the worst-case performance of Kalman filtering under the attacks in the framework of multi-sensor with and without safe sensors. The specific setup is that a remote estimator with χ 2 detectors performs the state estimation based on data transmitted from a group of sensors via a wireless network. The transmitted data may be modified by an adversary. The previous literature mainly investigates potential impacts of several feasible stealthy integrity attacks on remote estimator in the multi-sensor setup instead of the worst-case estimation performance. It should be pointed out that the analysis of the worst-case performance of remote estimator under the attacks can provide a reference for operators to identify the vulnerability of systems and decide whether corresponding defensive measures need to be executed. Hence, such analyses play an importance role in ensuring system security. In this work, a cyber-attack pattern utilizing true and contaminated information from all sensors is developed. The worst-case estimation performance and corresponding strictly stealthy attack policies in closed-form are provided. Finally, a numerical example is given to verify the effectiveness of the given results.},
  archive      = {J_AUTOM},
  author       = {Yake Yang and Zhi Li and Xudong Zhao and Yuzhe Li},
  doi          = {10.1016/j.automatica.2025.112257},
  journal      = {Automatica},
  month        = {6},
  pages        = {112257},
  shortjournal = {Automatica},
  title        = {Worst-case performance of kalman filtering against cyber-attacks with true and contaminated information},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network combination to persistence of high-dimensional
delayed complex balanced mass-action systems. <em>AUTOM</em>,
<em>176</em>, 112256. (<a
href="https://doi.org/10.1016/j.automatica.2025.112256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex balanced mass-action systems (CBMASs) are of great importance in the field of biochemical systems. However, the increase in system dimensionality significantly amplifies the complexity of boundary cases, posing a considerable challenge for persistence analysis of CBMASs with or without time delays. To tackle this issue, we propose a method of network combination, wherein some high-dimensional delayed CBMAS (DeCBMAS) is regarded as a combination of sub-DeCBMASs that are of dimension lower than 2, according to a certain combination mode. By defining all combination modes as the intersection between semilocking sets and intersecting species sets, we further classify the complex and diverse boundaries brought about by high dimensions and resolve them by utilizing the boundaries of subsystems accordingly, which could not be resolved in previous work. This approach overcomes the bottleneck of persistence in high-dimensional DeCBMAS in some degree. The effectiveness of our proposed approach is also demonstrated through several examples, highlighting its practical applicability.},
  archive      = {J_AUTOM},
  author       = {Xiaoyu Zhang and Chuanhou Gao and Denis Dochain},
  doi          = {10.1016/j.automatica.2025.112256},
  journal      = {Automatica},
  month        = {6},
  pages        = {112256},
  shortjournal = {Automatica},
  title        = {Network combination to persistence of high-dimensional delayed complex balanced mass-action systems},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consensus of multi-agent systems under binary-valued
measurements: An event-triggered coordination approach. <em>AUTOM</em>,
<em>176</em>, 112255. (<a
href="https://doi.org/10.1016/j.automatica.2025.112255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the consensus problem of multi-agent systems. Owing to the effect of bandwidth restriction, the communication information between two adjacent agents is based on the binary-valued observation of the imprecise sender’s output, which is only 1-bit. Each agent employs the recursive projection algorithm to estimate the states of all neighbors. Then, an event-triggered coordination technique is proposed to address the consensus problem. The first characteristic of this technique is that the information data transmission between two adjacent agents is managed by an event-triggered scheduler. The second characteristic of this technique is that each agent adopts the event-triggered control protocol to achieve the ultimate target. By this technique, the estimation error and the consensus error can converge to zero in the mean square sense and in the almost sure sense with explicit convergence speeds. Moreover, the communication rate of the communication scheme between two adjacent agents does not exceed fifty percent. And the communication rate of the control scheme can almost surely converge to zero with an explicit rate. Compared with the existing results, these two communication rates can be extremely reduced when achieving the same convergence value. As a result, the communication resources can be saved in terms of quantization, communication and control. An example is presented to illustrate the advantage of the proposed technique.},
  archive      = {J_AUTOM},
  author       = {Xiaodong Lu and Ting Wang and Yanlong Zhao and Ji-Feng Zhang},
  doi          = {10.1016/j.automatica.2025.112255},
  journal      = {Automatica},
  month        = {6},
  pages        = {112255},
  shortjournal = {Automatica},
  title        = {Consensus of multi-agent systems under binary-valued measurements: An event-triggered coordination approach},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extremum seeking nonlinear regulator with concurrent
uncertainties in exosystems and control directions. <em>AUTOM</em>,
<em>176</em>, 112254. (<a
href="https://doi.org/10.1016/j.automatica.2025.112254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a non-adaptive control solution framework to the practical output regulation problem (PORP) for a class of nonlinear systems with uncertain parameters, unknown control directions and uncertain exosystem dynamics. The concurrence of the unknown control directions and uncertainties in both the system dynamics and the exosystem pose a significant challenge to the problem. In light of a nonlinear internal model approach, we first convert the robust PORP into a robust non-adaptive stabilization problem for the augmented system with integral Input-to-State Stable (iISS) inverse dynamics. By employing an extremum-seeking control (ESC) approach, the construction of our solution method avoids the use of Nussbaum-type gain techniques to address the robust PORP subject to unknown control directions with time-varying coefficients. The stability of the non-adaptive output regulation design is proven via a Lie bracket averaging technique where uniform ultimate boundedness of the closed-loop signals is guaranteed. As a result, the practical output regulation problem can be solved using the proposed non-adaptive and non-Nussbaum-type framework. Moreover, both the estimation and tracking errors uniformly asymptotically converge to zero, provided that the frequency of the dither signal goes to infinity. Finally, a simulation example with unknown coefficients is provided to exemplify the validity of the proposed control solution frameworks.},
  archive      = {J_AUTOM},
  author       = {Shimin Wang and Martin Guay and Dabo Xu and Denis Dochain},
  doi          = {10.1016/j.automatica.2025.112254},
  journal      = {Automatica},
  month        = {6},
  pages        = {112254},
  shortjournal = {Automatica},
  title        = {Extremum seeking nonlinear regulator with concurrent uncertainties in exosystems and control directions},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the contact hamiltonian functions of conservative contact
systems. <em>AUTOM</em>, <em>176</em>, 112251. (<a
href="https://doi.org/10.1016/j.automatica.2025.112251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamics of irreversible thermodynamic systems have been expressed in terms of conservative contact systems where contact vector fields are generated by contact Hamiltonian functions defined on the Thermodynamic Phase Space (TPS). In this paper, we first emphasize the importance of both the Gibbs relation and the Gibbs–Duhem relation of the entropy or energy contact form in developing a first-order invariance constraint that every contact Hamiltonian function must satisfy. This novel insight is then considered together with the zero-order invariance constraint to infer solutions, thereby yielding a generalized family of contact Hamiltonian functions generating non-strict or strict contact vector fields which are equal on the associated Legendre submanifold on which the dynamics of the thermodynamic system is living. Finally, we show sufficient conditions under which the inverse images of zero by the contact Hamiltonian functions or the Legendre submanifold are globally attractive when lifting the system dynamics to the complete TPS. A simulated example is given to support the theoretical developments and to discuss the difference of the dynamic behaviours between the generated strict and non-strict contact vector fields.},
  archive      = {J_AUTOM},
  author       = {N. Ha Hoang and Denis Dochain},
  doi          = {10.1016/j.automatica.2025.112251},
  journal      = {Automatica},
  month        = {6},
  pages        = {112251},
  shortjournal = {Automatica},
  title        = {On the contact hamiltonian functions of conservative contact systems},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On attack detection and identification for the
cyber–physical system using lifted system model. <em>AUTOM</em>,
<em>176</em>, 112243. (<a
href="https://doi.org/10.1016/j.automatica.2025.112243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the safety and security issues related to cyber–physical systems with potentially multi-rate, delayed, and nonuniformly sampled measurements, we investigate the attack detection and identification using the lifted system model in this paper. Attack detectability and identifiability based on the lifted system model are formally defined and rigorously characterized in a novel approach. The method of checking detectability is discussed, and a residual design problem for attack detection is formulated in a general way. For attack identification, we define and characterize it by generalizing the concept of mode discernibility for switched systems, and a method for identifying the attack is discussed based on the theoretical analysis. An illustrative example of an unmanned aircraft system is provided to validate the main results.},
  archive      = {J_AUTOM},
  author       = {Dawei Sun and Minhyun Cho and Inseok Hwang},
  doi          = {10.1016/j.automatica.2025.112243},
  journal      = {Automatica},
  month        = {6},
  pages        = {112243},
  shortjournal = {Automatica},
  title        = {On attack detection and identification for the cyber–physical system using lifted system model},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bearing-only solution for fermat–weber location problem:
Generalized algorithms. <em>AUTOM</em>, <em>176</em>, 112242. (<a
href="https://doi.org/10.1016/j.automatica.2025.112242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents novel algorithms for the Fermat–Weber Location Problem, guiding an autonomous agent to the point that minimizes the weighted sum of Euclidean distances to some beacons using only bearing measurements. The current results address only the simple scenario where the beacons are stationary and the agent is modeled by a single integrator. In this paper, we present a number of bearing-only algorithms that let the agent follow the Fermat–Weber point of a group of stationary or moving beacons. Exponential and finite-time stability of the Fermat–Weber point are also established. The theoretical results are rigorously proven using Lyapunov theory and supported with simulation examples.},
  archive      = {J_AUTOM},
  author       = {Nhat-Minh Le-Phan and Phuoc Doan Nguyen and Hyo-Sung Ahn and Minh Hoang Trinh},
  doi          = {10.1016/j.automatica.2025.112242},
  journal      = {Automatica},
  month        = {6},
  pages        = {112242},
  shortjournal = {Automatica},
  title        = {Bearing-only solution for Fermat–Weber location problem: Generalized algorithms},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Verification of current-state opacity and opaque time for
labeled time petri net systems. <em>AUTOM</em>, <em>176</em>, 112241.
(<a href="https://doi.org/10.1016/j.automatica.2025.112241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the verification of current-state opacity and opaque time in timed discrete event systems modeled with labeled time Petri nets (LTPNs). First, we formally conceptualize current-state opacity and opaque time for LTPN systems. Based on the solution of a set of linear programming problems (LPPs) associated with the transitions-related timing constraints in the modified state class graph (MSCG) of an LTPN system, an approach is proposed to find all the state classes and logic transition sequences that the system may generate at a given time instant. By utilizing such state classes and logic transition sequences, a method for verifying the current-state opacity of an LTPN system is presented, avoiding an exhaustive enumeration of the state classes that are consistent with all the observable label sequences at the time instant. To further acquire the current-state opaque time of the LTPN system, we propose a method for calculating the length of opaque time based on the solution of LPPs that are associated with the paths in the MSCG. Particularly, an algorithm is reported to compute the opaque time of an LTPN system with respect to a given secret. Finally, a case study is provided to illustrate the proposed algorithms to determine the current-state opacity and opaque time for an LTPN system.},
  archive      = {J_AUTOM},
  author       = {Yuting Wang and Liang Li and Zhiwu Li},
  doi          = {10.1016/j.automatica.2025.112241},
  journal      = {Automatica},
  month        = {6},
  pages        = {112241},
  shortjournal = {Automatica},
  title        = {Verification of current-state opacity and opaque time for labeled time petri net systems},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal control over markovian wireless communication
channels under generalized packet dropout compensation. <em>AUTOM</em>,
<em>176</em>, 112240. (<a
href="https://doi.org/10.1016/j.automatica.2025.112240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Control loops closed over wireless links greatly benefit from accurate estimates of the communication channel condition. To this end, the finite-state Markov channel model allows for reliable channel state estimation. This paper develops a Markov jump linear system representation for wireless networked control with persistent channel state observation, stochastic message losses, and generalized packet dropout compensation. With this model, we solve the finite- and infinite-horizon linear quadratic regulation problems and introduce an easy-to-test stability condition for any given infinite-horizon control law. We also thoroughly analyze the impact of a scalar general dropout compensation factor on the stability and closed-loop performance of a rotary inverted pendulum controlled remotely through a wireless link. Finally, we validate the results numerically via extensive Monte Carlo simulations, showing the benefits of the proposed control strategy.},
  archive      = {J_AUTOM},
  author       = {Yuriy Zacchia Lun and Francesco Smarra and Alessandro D’Innocenzo},
  doi          = {10.1016/j.automatica.2025.112240},
  journal      = {Automatica},
  month        = {6},
  pages        = {112240},
  shortjournal = {Automatica},
  title        = {Optimal control over markovian wireless communication channels under generalized packet dropout compensation},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Certified data-driven inverse reinforcement learning of
markov jump systems. <em>AUTOM</em>, <em>176</em>, 112239. (<a
href="https://doi.org/10.1016/j.automatica.2025.112239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper devises a data-driven off-policy inverse reinforcement learning algorithm for discrete-time linear Markov jump systems. Leveraging observed behaviors from multi-mode Markov jump systems optimized with respect to unknown mode-wise cost functions, our algorithm reconstructs each mode’s associated cost function and control policies. Our approach certifies mean-square asymptotic stability, unbiased convergence, and nonuniqueness. Notably, the proposed algorithm operates solely on demonstrated behavioral data, eliminating the need for system models, prior knowledge of transition probabilities, or initial control gains. The practical efficacy of our approach is validated.},
  archive      = {J_AUTOM},
  author       = {Wenqian Xue and Frank L. Lewis and Bosen Lian},
  doi          = {10.1016/j.automatica.2025.112239},
  journal      = {Automatica},
  month        = {6},
  pages        = {112239},
  shortjournal = {Automatica},
  title        = {Certified data-driven inverse reinforcement learning of markov jump systems},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximizing the smallest eigenvalue of grounded laplacian
matrices via edge addition. <em>AUTOM</em>, <em>176</em>, 112238. (<a
href="https://doi.org/10.1016/j.automatica.2025.112238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smallest eigenvalue of the grounded Laplacian matrix holds pivotal significance across various practical scenarios, particularly in characterizing the convergence rate of leader–follower networks in multi-agent systems, with a larger smallest eigenvalue indicating a faster convergence rate. This paper focuses on maximizing the smallest eigenvalue of the grounded Laplacian matrix via adding edges for both undirected and directed networks. For undirected networks, under intuitive conditions, we prove that adding one edge between two vertices that correspond to the smallest and largest eigenvector components for the smallest eigenvalue will maximize the smallest eigenvalue of the grounded Laplacian matrix. In addition, the discussion is extended to the case of multiple edge addition, where a suboptimal algorithm is proposed to maximize the eigenvalue with a low time complexity. For directed networks, when fixing a vertex i and adding an edge pointing to it, choosing the vertex, if there is any, that has the smallest eigenvector component than that of i leads to the maximal increase of the smallest eigenvalue. We apply the derived results to the distributed neighbor selection for directed networks.},
  archive      = {J_AUTOM},
  author       = {Xinfeng Ru and Weiguo Xia and Ming Cao},
  doi          = {10.1016/j.automatica.2025.112238},
  journal      = {Automatica},
  month        = {6},
  pages        = {112238},
  shortjournal = {Automatica},
  title        = {Maximizing the smallest eigenvalue of grounded laplacian matrices via edge addition},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic reachable sets of stochastic nonlinear systems
with contextual uncertainties. <em>AUTOM</em>, <em>176</em>, 112237. (<a
href="https://doi.org/10.1016/j.automatica.2025.112237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Validating and controlling safety-critical systems in uncertain environments necessitates probabilistic reachable sets of future state evolutions. The existing methods of computing probabilistic reachable sets normally assume that stochastic uncertainties are independent of system states, inputs, and other environment variables. However, this assumption falls short in many real-world applications, where the probability distribution governing uncertainties depends on these variables, referred to as contextual uncertainties . This paper addresses the challenge of computing probabilistic reachable sets of stochastic nonlinear states with contextual uncertainties by seeking minimum-volume polynomial sublevel sets with contextual chance constraints. The formulated problem cannot be solved by the existing sample-based approximation method since the existing methods do not consider conditional probability densities. To address this, we propose a consistent sample approximation of the original problem by leveraging conditional density estimation and resampling. The obtained approximate problem is a tractable optimization problem. Additionally, we prove the proposed sample-based approximation’s almost uniform convergence, showing that it gives the optimal solution almost consistently with the original ones. Through a numerical example, we evaluate the effectiveness of the proposed method against existing approaches, highlighting its capability to significantly reduce the bias inherent in sample-based approximation without considering a conditional probability density.},
  archive      = {J_AUTOM},
  author       = {Xun Shen and Ye Wang and Kazumune Hashimoto and Yuhu Wu and Sebastien Gros},
  doi          = {10.1016/j.automatica.2025.112237},
  journal      = {Automatica},
  month        = {6},
  pages        = {112237},
  shortjournal = {Automatica},
  title        = {Probabilistic reachable sets of stochastic nonlinear systems with contextual uncertainties},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rank resilience of pattern matrices against structured
perturbations with applications. <em>AUTOM</em>, <em>176</em>, 112236.
(<a href="https://doi.org/10.1016/j.automatica.2025.112236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In structured system theory, a pattern matrix is a matrix with entries either fixed to zero or free to take arbitrary numbers. The (generic) rank of a pattern matrix is the rank of almost all its realizations. The resilience of various system properties is closely tied to the rank resilience of the corresponding pattern matrices. Yet, existing literature predominantly explores the latter aspect by focusing on perturbations that change the zero–nonzero structure of pattern matrices, corresponding to link additions/deletions. In this paper, we consider the rank resilience of pattern matrices against structured perturbations that can arbitrarily alter the values of a prescribed set of entries, corresponding to link weight variations. We say a pattern matrix is structurally rank r resilient against a perturbation pattern if almost all realizations of this pattern matrix have a rank not less than r under arbitrary complex-valued realizations of the perturbation pattern. We establish a generic property in this concept. We then present combinatorial necessary and sufficient conditions for a rectangular pattern matrix to lose full rank under given perturbation patterns. We also generalize them to obtain a sufficient condition and a necessary one for losing an arbitrarily prescribed rank. We finally show our results can be applied to the resilience analysis of various properties of structured (descriptor) systems, including controllability and input-state observability, as well as characterizing zero structurally fixed modes.},
  archive      = {J_AUTOM},
  author       = {Yuan Zhang and Yuanqing Xia and Gang Wang},
  doi          = {10.1016/j.automatica.2025.112236},
  journal      = {Automatica},
  month        = {6},
  pages        = {112236},
  shortjournal = {Automatica},
  title        = {Rank resilience of pattern matrices against structured perturbations with applications},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered learning-based control for output tracking
with unknown cost functions. <em>AUTOM</em>, <em>176</em>, 112235. (<a
href="https://doi.org/10.1016/j.automatica.2025.112235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a two-layer event-triggered learning-based control framework is proposed to address extremum seeking problem in networked control systems with limited communication resources and unknown cost function. In this framework, the lower layer is an event-triggered controller to drive the output to track the given setpoints generated from the upper layer, where a learning-based optimizer is developed to approach the extremum of the unknown cost function. Specifically, in the lower layer, an event-triggered output controller, based on a high-gain extended state observer, is designed to tackle uncertainties and disturbances. In the upper layer, a nonparametric gradient model is established, and then the gradient descent method is applied to generate setpoints for the tracking control. The update of the learning and optimization process is determined by the tracking performance of the lower layer. The stability and Zeno-freeness of the proposed event-triggered controller is proved. Furthermore, the dependence of the convergence rate of the proposed learning-based extremum seeking algorithm on the designed parameters is also explicitly characterized. Finally, the effectiveness of the proposed framework is validated by numerical examples.},
  archive      = {J_AUTOM},
  author       = {Jiliang Song and Dawei Shi and Shu-Xia Tang and Hao Yu and Yang Shi},
  doi          = {10.1016/j.automatica.2025.112235},
  journal      = {Automatica},
  month        = {6},
  pages        = {112235},
  shortjournal = {Automatica},
  title        = {Event-triggered learning-based control for output tracking with unknown cost functions},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust optimal control of bi-objective non-homogeneous
stochastic linear quadratic system with random coefficients.
<em>AUTOM</em>, <em>176</em>, 112234. (<a
href="https://doi.org/10.1016/j.automatica.2025.112234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a robust stochastic linear–quadratic optimal control (RSLQ) problem with non-homogeneous terms in state, where all coefficients of state and cost function are allowed to be random and the coefficients of cost function are also uncertain. The existence of a unique robust optimal control (OC) v ̄ λ ∗ which depends on parameter λ ∗ ∈ [ 0 , 1 ] is obtained, and ( λ ∗ , v ̄ λ ∗ ) is verified to be a saddle point of a game problem. Then the solving of Problem RSLQ is proven to be equivalent to the seeking of a global maximum point λ ∗ of a value function V λ ( x ) w.r.t. λ ∈ [ 0 , 1 ] . Furthermore, for the case with one-dimensional state, we obtain the continuity of V λ ( x ) w.r.t. λ , which can also be seen as a stability property of value function of stochastic linear–quadratic (SLQ) problems w.r.t. parameter λ . The main challenge is the continuity dependency w.r.t. λ of solution of an auxiliary linear backward stochastic differential equation (BSDE), which has possibly unbounded coefficients and appears in the explicit form of V λ ( x ) . Via the estimates of bounded mean oscillation martingales (BMO martingales) and stochastic Riccati equations (SREs), along with transformation of measures, we overcome this obstacle and derive that V λ ( x ) is Lipschitz continuous w.r.t. λ . Estimates of two generalized SREs appeared in an SLQ problem with conic constraint are also obtained. Some numerical examples are given to further verify the validity of our theoretical analysis.},
  archive      = {J_AUTOM},
  author       = {Guangchen Wang and Zhuangzhuang Xing},
  doi          = {10.1016/j.automatica.2025.112234},
  journal      = {Automatica},
  month        = {6},
  pages        = {112234},
  shortjournal = {Automatica},
  title        = {Robust optimal control of bi-objective non-homogeneous stochastic linear quadratic system with random coefficients},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust fault detection method based on interval neural
networks optimized by ellipsoid bundles. <em>AUTOM</em>, <em>176</em>,
112233. (<a
href="https://doi.org/10.1016/j.automatica.2025.112233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel framework for interval prediction neural network model optimized by ellipsoid bundles is designed for data-driven systems with unknown but bounded noise and disturbances. Firstly, a point prediction neural network model is constructed with input and output data, the prediction error is assumed to be unknown but bounded. Then, a feasible set related to the output weights of the neural network model is described by ellipsoid bundles, which allows decreasing conservatism compared to other types of sets such as zonotopes or ellipsoids. To obtain a more precise description shape of the feasible set, an optimal iterative formula is theoretically derived by minimizing the Frobenius norm of ellipsoid bundles. Next, an outer bounding box is established to obtain the maximum and minimum weights that satisfy the feasible set, thereby providing the output prediction interval. This interval characterizes the systems’ disturbance and can be used as the threshold when dealing with fault diagnosis applications. Finally, the effectiveness of the proposed interval neural network model is demonstrated by using faulty data from a wastewater treatment process. Simulation results verify that the proposed method can achieve accurate prediction outputs and fault diagnosis performance.},
  archive      = {J_AUTOM},
  author       = {Meng Zhou and Yinyue Zhang and Jing Wang and Tarek Raïssi and Vicenç Puig},
  doi          = {10.1016/j.automatica.2025.112233},
  journal      = {Automatica},
  month        = {6},
  pages        = {112233},
  shortjournal = {Automatica},
  title        = {Robust fault detection method based on interval neural networks optimized by ellipsoid bundles},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generic diagonalizability, structural functional
observability and output controllability. <em>AUTOM</em>, <em>176</em>,
112232. (<a
href="https://doi.org/10.1016/j.automatica.2025.112232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the structural functional observability (SFO) and structural output controllability (SOC) of a class of systems and explores the associated minimal sensor and actuator placement problems. The verification of SOC and the corresponding sensor and actuator placement problems, i.e., the problems of determining the minimum number of outputs and inputs required to achieve SFO and SOC, respectively, are yet open for general systems. This motivates our focus on a large class of systems enabling polynomial-time solutions. In this line, we first define and characterize generically diagonalizable systems, referring to structured systems for which almost all realizations of the state matrices are diagonalizable. We then develop computationally efficient criteria for SFO and SOC within the context of generically diagonalizable systems. Our work expands the class of systems amenable to polynomial-time SOC verification. Thanks to the simplicity of the obtained criteria, we derive closed-form solutions for determining the minimal sensor placement to achieve SFO and the minimal actuator deployment to achieve SOC in such systems, along with efficient weighted maximum matching-based and weighted maximum flow-based algorithms. For more general systems to achieve SFO, we establish an upper bound on the number of required sensors by identifying a non-decreasing property of SFO with respect to a specific class of edge additions, which is proven to be optimal under certain conditions.},
  archive      = {J_AUTOM},
  author       = {Yuan Zhang and Tyrone Fernando and Mohamed Darouach},
  doi          = {10.1016/j.automatica.2025.112232},
  journal      = {Automatica},
  month        = {6},
  pages        = {112232},
  shortjournal = {Automatica},
  title        = {Generic diagonalizability, structural functional observability and output controllability},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scaling policy iteration based reinforcement learning for
unknown discrete-time linear systems. <em>AUTOM</em>, <em>176</em>,
112227. (<a
href="https://doi.org/10.1016/j.automatica.2025.112227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In optimal control problem, policy iteration (PI) is a powerful reinforcement learning (RL) tool used for designing optimal controller for the linear systems. However, the need for an initial stabilizing control policy significantly limits its applicability. To address this constraint, this paper proposes a novel scaling technique, which progressively brings a sequence of stable scaled systems closer to the original system, enabling the acquisition of stable control gain. Based on the designed scaling update law, we develop model-based and model-free scaling policy iteration (SPI) algorithms for solving the optimal control problem for discrete-time linear systems, in both known and completely unknown system dynamics scenarios. Unlike existing works on PI based RL, the SPI algorithms do not necessitate an initial stabilizing gain to initialize the algorithms, they can achieve the optimal control under any initial control gain. Finally, the numerical results validate the theoretical findings and confirm the effectiveness of the algorithms.},
  archive      = {J_AUTOM},
  author       = {Zhen Pang and Shengda Tang and Jun Cheng and Shuping He},
  doi          = {10.1016/j.automatica.2025.112227},
  journal      = {Automatica},
  month        = {6},
  pages        = {112227},
  shortjournal = {Automatica},
  title        = {Scaling policy iteration based reinforcement learning for unknown discrete-time linear systems},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Properties of immersions for systems with multiple limit
sets with implications to learning koopman embeddings. <em>AUTOM</em>,
<em>176</em>, 112226. (<a
href="https://doi.org/10.1016/j.automatica.2025.112226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear immersions (such as Koopman eigenfunctions) of a nonlinear system have wide applications in prediction and control. In this work, we study the properties of linear immersions for nonlinear systems with multiple omega-limit sets. While previous research has indicated the possibility of discontinuous one-to-one linear immersions for such systems, it has been unclear whether continuous one-to-one linear immersions are attainable. Under mild conditions, we prove that any continuous immersion to a class of systems including finite-dimensional linear systems collapses all the omega-limit sets, and thus cannot be one-to-one. Furthermore, we show that this property is also shared by approximate linear immersions learned from data as sample size increases and sampling interval decreases. Multiple examples are studied to illustrate our results.},
  archive      = {J_AUTOM},
  author       = {Zexiang Liu and Necmiye Ozay and Eduardo D. Sontag},
  doi          = {10.1016/j.automatica.2025.112226},
  journal      = {Automatica},
  month        = {6},
  pages        = {112226},
  shortjournal = {Automatica},
  title        = {Properties of immersions for systems with multiple limit sets with implications to learning koopman embeddings},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wage rigidity and retirement in optimal portfolio choice.
<em>AUTOM</em>, <em>176</em>, 112225. (<a
href="https://doi.org/10.1016/j.automatica.2025.112225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an agent’s lifecycle portfolio choice problem with stochastic labor income, borrowing constraints and a finite retirement date. Similarly to Biffis et al. (2020), wages evolve in a path-dependent way, but the presence of a finite retirement time leads to a novel, two-stage infinite dimensional stochastic optimal control problem with explicit optimal controls in feedback form. We find an explicit solution to the associated Hamilton–Jacobi–Bellman (HJB) equation, which is an infinite dimensional PDE of parabolic type. The identification of the optimal feedbacks is delicate due to the presence of time-dependent state constraints, which appear to be new in the infinite dimensional stochastic control literature. The explicit solution allows us to study the properties of optimal strategies and discuss their implications for portfolio choice. As opposed to models with Markovian dynamics, path dependency can now modulate the hedging demand arising from the implicit holding of risky assets in human capital, leading to richer asset allocation predictions consistent with wage rigidity and the agents learning about their earning potential.},
  archive      = {J_AUTOM},
  author       = {Sara Biagini and Enrico Biffis and Fausto Gozzi and Margherita Zanella},
  doi          = {10.1016/j.automatica.2025.112225},
  journal      = {Automatica},
  month        = {6},
  pages        = {112225},
  shortjournal = {Automatica},
  title        = {Wage rigidity and retirement in optimal portfolio choice},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastically constrained best arm identification with
thompson sampling. <em>AUTOM</em>, <em>176</em>, 112223. (<a
href="https://doi.org/10.1016/j.automatica.2025.112223">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of the best arm identification in the presence of stochastic constraints, where there is a finite number of arms associated with multiple performance measures. The goal is to identify the arm that optimizes the objective measure subject to constraints on the remaining measures. We will explore the popular idea of Thompson sampling (TS) as a means to solve it. To the best of our knowledge, it is the first attempt to extend TS to this problem. We will design a TS-based sampling algorithm, establish its asymptotic optimality in the rate of posterior convergence, and demonstrate its superior performance using numerical examples.},
  archive      = {J_AUTOM},
  author       = {Le Yang and Siyang Gao and Cheng Li and Yi Wang},
  doi          = {10.1016/j.automatica.2025.112223},
  journal      = {Automatica},
  month        = {6},
  pages        = {112223},
  shortjournal = {Automatica},
  title        = {Stochastically constrained best arm identification with thompson sampling},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent homeomorphic curves in swarms. <em>AUTOM</em>,
<em>176</em>, 112221. (<a
href="https://doi.org/10.1016/j.automatica.2025.112221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new decentralized approach for producing emergent curve trajectories in swarms of agents. The central innovation lies in use of a quaternion-based stabilizing embedding, which permits the application of linear control policies to produce globally-stable behaviour from local observations. Agents are modelled as particles in free space using double integrator dynamics. We stabilize an arbitrary number of agents indirectly, through virtual representations bijected onto a circle, and then produce elaborate curve trajectories through a family of topological homeomorphisms. We formulate these virtual agents as embeddings, through a combination of state feedback, rotations, and variable changes. The result is evenly-spaced swarms along the desired trajectories, with each agent only requiring information about the state of its neighbours. Simulations demonstrate the emergent qualities of the swarm as it converges to the desired geometry. The agents maintain separation and automatically compensate for loss or addition of agents in the swarm. We provide mathematical proofs of stability for the embedding, trajectories, and controller.},
  archive      = {J_AUTOM},
  author       = {Peter Travis Jardine and Sidney Givigi},
  doi          = {10.1016/j.automatica.2025.112221},
  journal      = {Automatica},
  month        = {6},
  pages        = {112221},
  shortjournal = {Automatica},
  title        = {Emergent homeomorphic curves in swarms},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust optimal density control of robotic swarms.
<em>AUTOM</em>, <em>176</em>, 112218. (<a
href="https://doi.org/10.1016/j.automatica.2025.112218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a computationally efficient, robust density control strategy for the mean-field model of a robotic swarm. We formulate a static optimal control problem (OCP) that computes a robot velocity field which drives the swarm to a target equilibrium density, and we prove the stability of the controlled system in the presence of transient perturbations and uncertainties in the initial conditions. The density dynamics are described by a linear elliptic advection–diffusion equation in which the control enters bilinearly into the advection term. The well-posedness of the state problem is ensured by an integral constraint. We prove the existence of optimal controls by embedding the state constraint into the weak formulation of the state dynamics. The resulting control field is space-dependent and does not require any communication between robots or costly density estimation algorithms. Based on the properties of the primal and dual systems, we first propose a method to accommodate the state constraint. Exploiting the properties of the state dynamics and associated controls, we then construct a modified dynamic OCP to speed up the convergence to the target equilibrium density of the associated static problem. We show that the finite-element discretization of the static and dynamic OCPs inherits the structure and several useful properties of their infinite-dimensional formulations. Finally, we demonstrate the effectiveness of our control approach through numerical simulations of scenarios with obstacles and an external velocity field.},
  archive      = {J_AUTOM},
  author       = {Carlo Sinigaglia and Andrea Manzoni and Francesco Braghin and Spring Berman},
  doi          = {10.1016/j.automatica.2025.112218},
  journal      = {Automatica},
  month        = {6},
  pages        = {112218},
  shortjournal = {Automatica},
  title        = {Robust optimal density control of robotic swarms},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed parameter estimation with gaussian observation
noises in time-varying digraphs. <em>AUTOM</em>, <em>176</em>, 112209.
(<a href="https://doi.org/10.1016/j.automatica.2025.112209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of distributed parameter estimation in sensor networks. Each sensor makes successive observations of an unknown d -dimensional parameter, which might be subject to Gaussian random noises. The sensors aim to infer the true value of the unknown parameter by cooperating with each other. To this end, we first generalize the so-called dynamic regressor extension and mixing (DREM) algorithm to stochastic systems, with which the problem of estimating a d -dimensional vector parameter is transformed to that of d scalar ones: one for each of the unknown parameters. For each of the scalar problem, both combine-then-adapt (CTA) and adapt-then-combine (ATC) diffusion-based estimation algorithms are given, where each sensor performs a combination step to fuse the local estimates in its in-neighborhood, alongside an adaptation step to process its streaming observations. Under weak conditions on network topology and excitation of regressors, we show that the proposed estimators guarantee that each sensor infers the true parameter, even if any individual of them cannot by itself. Specifically, it is required that the union of topologies over an interval with fixed length is strongly connected. Moreover, the sensors must collectively satisfy a cooperative persistent excitation (PE) condition, which relaxes the traditional PE condition. Numerical examples are finally provided to illustrate the established results.},
  archive      = {J_AUTOM},
  author       = {Jiaqi Yan and Hideaki Ishii},
  doi          = {10.1016/j.automatica.2025.112209},
  journal      = {Automatica},
  month        = {6},
  pages        = {112209},
  shortjournal = {Automatica},
  title        = {Distributed parameter estimation with gaussian observation noises in time-varying digraphs},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Securing voltage stability in power grids via holomorphic
dynamics. <em>AUTOM</em>, <em>176</em>, 112158. (<a
href="https://doi.org/10.1016/j.automatica.2025.112158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Voltage instability is a complex dynamic phenomenon in today’s electric power systems. The onset of voltage instability is usually related to the loss of proper solutions to the nonlinear power flow equations, which express the fundamental law governing electric power and voltages in a power grid. Thus, studying the solvability of the power flow equations is at the heart of the voltage stability problem. In this paper, we transform the solvability problem of the power flow equations to a stability problem of a discrete dynamical system defined by a holomorphic mapping in several complex variables. Then, we show a general result on the fixed points of holomorphic functions invariant in a polydisc. Using these analytical tools, we obtain a strong explicit condition that certifies the existence and uniqueness of a proper solution to the nonlinear power flow equations. The new condition reveals in a precise way the interplay between voltage instability, the electrical and topological structures of the power grid, and the electric load characteristics. The new condition is proven to be stronger than existing ones. Extensive computational experiments further demonstrate the strength of the proposed condition for securing real-time voltage stability of large-scale high-voltage electric transmission systems.},
  archive      = {J_AUTOM},
  author       = {Bai Cui and Xu Andy Sun},
  doi          = {10.1016/j.automatica.2025.112158},
  journal      = {Automatica},
  month        = {6},
  pages        = {112158},
  shortjournal = {Automatica},
  title        = {Securing voltage stability in power grids via holomorphic dynamics},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint opacity and opacity against
state-estimate-intersection-based intrusion of discrete-event systems.
<em>AUTOM</em>, <em>176</em>, 112136. (<a
href="https://doi.org/10.1016/j.automatica.2025.112136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a general framework for joint opacity of discrete-event systems under partial observation. It discusses a class of state-estimate-intersection-based (SEI-based) intrusions that existing opacity conditions cannot prevent. The paper provides a procedure to verify the opacity of a system against such SEI-based intrusions. The results are formally verified by Isabelle/HOL.},
  archive      = {J_AUTOM},
  author       = {K. Ritsuka and Stéphane Lafortune and Feng Lin},
  doi          = {10.1016/j.automatica.2025.112136},
  journal      = {Automatica},
  month        = {6},
  pages        = {112136},
  shortjournal = {Automatica},
  title        = {Joint opacity and opacity against state-estimate-intersection-based intrusion of discrete-event systems},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A control theoretical approach to online constrained
optimization. <em>AUTOM</em>, <em>176</em>, 112107. (<a
href="https://doi.org/10.1016/j.automatica.2024.112107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we focus on the solution of online problems with time-varying, linear equality and inequality constraints. Our approach is to design a novel online algorithm by leveraging the tools of control theory. In particular, for the case of equality constraints only, using robust control we design an online algorithm with asymptotic convergence to the optimal trajectory, differently from the alternatives that achieve non-zero tracking error. When also inequality constraints are present, we show how to modify the proposed algorithm to account for the wind-up induced by the nonnegativity constraints on the dual variables. We report numerical results that corroborate the theoretical analysis, and show how the proposed approach outperforms state-of-the-art algorithms both with equality and inequality constraints.},
  archive      = {J_AUTOM},
  author       = {Umberto Casti and Nicola Bastianello and Ruggero Carli and Sandro Zampieri},
  doi          = {10.1016/j.automatica.2024.112107},
  journal      = {Automatica},
  month        = {6},
  pages        = {112107},
  shortjournal = {Automatica},
  title        = {A control theoretical approach to online constrained optimization},
  volume       = {176},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cma---10">CMA - 10</h2>
<ul>
<li><details>
<summary>
(2025). A convective allen-cahn model for the two- and
three-dimensional shape transformations of non-contact objects.
<em>CMA</em>, <em>188</em>, 72–82. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a shape transformation model based on the Allen-Cahn equation, and its numerical scheme. The model overcomes the limitations of previous shape transformation models by introducing a convective term, realizing a smooth and stable shape transformation when the initial shape is not in contact with the target shape. To solve the problem of high-dimensions and the complexity of nonlinear terms, the numerical scheme adopts the dimension-splitting method, which can accelerate the computation by parallel algorithm, and incorporate a first-order stabilization term to mitigate numerical instability from explicit nonlinear computations. The numerical experiments explore the effect of the attracting coefficient and illustrates the effectiveness of our method in dealing with the non-contact objects through model comparison. Finally, 2D and 3D transformations validate the robustness and effectiveness of the proposed model and algorithm.},
  archive      = {J_CMA},
  author       = {Anwen Jiang and Yan Wang and Fenglian Zheng and Xufeng Xiao},
  doi          = {10.1016/j.camwa.2025.03.018},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {72-82},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A convective allen-cahn model for the two- and three-dimensional shape transformations of non-contact objects},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topology optimization of stokes eigenvalues by a level set
method. <em>CMA</em>, <em>188</em>, 50–71. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a level set method for a Stokes eigenvalue optimization problem. A relaxed approach is employed first to approximate the Stokes eigenvalue problem and transform the original shape optimization problem into a topology optimization model. Then the distributed shape gradient is used in numerical algorithms based on a level set method. Single-grid and efficient two-grid level set algorithms are developed for the relaxed optimization problem. A two-grid mixed finite element scheme that has reliable accuracy and asymptotically optimal convergence is shown to improve the efficiency of the Stokes eigenvalue solver. Thus, it can save computational efforts of the whole optimization algorithm. Two and three-dimensional numerical results are reported to show effectiveness and efficiency of the algorithms.},
  archive      = {J_CMA},
  author       = {Jiajie Li and Meizhi Qian and Shengfeng Zhu},
  doi          = {10.1016/j.camwa.2025.03.012},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {50-71},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Topology optimization of stokes eigenvalues by a level set method},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully consistent lowest-order finite element methods for
generalised stokes flows with variable viscosity. <em>CMA</em>,
<em>188</em>, 40–49. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In finite element methods for incompressible flows, the most popular approach to allow equal-order velocity-pressure pairs are residual-based stabilisations. When using first-order elements, however, the viscous part of the residual cannot be approximated, which often degrades accuracy. For constant viscosity, or by assuming a Lipschitz condition on the viscosity field, we can construct stabilisation methods that fully approximate the residual, regardless of the polynomial order of the finite element spaces. This work analyses and tests two variants of such a fully consistent approach, with the generalised Stokes system as a model problem. We prove unique solvability and derive expressions for the stabilisation parameter, generalising some classical results for constant viscosity. Numerical results illustrate how our method completely eliminates the spurious pressure boundary layers typically induced by low-order PSPG-like stabilisations.},
  archive      = {J_CMA},
  author       = {Felipe Galarce and Douglas R.Q. Pacheco},
  doi          = {10.1016/j.camwa.2025.03.013},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {40-49},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Fully consistent lowest-order finite element methods for generalised stokes flows with variable viscosity},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). H1− galerkin mixed finite element method using tensor
product of cubic b-splines for two-dimensional kuramoto-sivashinsky
equation. <em>CMA</em>, <em>188</em>, 19–39. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional ( 2 D ) Kuramoto-Sivashinsky equation offers a robust framework for studying complex, chaotic, and nonlinear dynamics in various mathematical and physical contexts. Analyzing this model also provides insights into higher-dimensional spatio-temporal chaotic systems that are relevant to many fields. This article aims to solve the scalar form of the two-dimensional Kuramoto-Sivashinsky equation using the H 1 − mixed Galerkin finite element method. By introducing an intermediate variable, the equation is transformed into a coupled system. This system is then approximated using the H 1 − mixed Galerkin finite element method, with the tensor product of the cubic B-spline in x and y directions serving as the test and trial functions in both the semi-discrete and fully discrete schemes. In this approach, triangularization is avoided, thereby reducing the size of the stiffness matrix. In the fully discrete scheme, the time derivative is approximated using the backward Euler method. The suitable linearization method is used to simplify the nonlinear term in both schemes. The theoretical analysis yields optimal order error estimates for the scalar unknown and its flux in the L 2 , L ∞ , and H 1 norms, demonstrating the accuracy, efficiency, and stability of the proposed method. Additionally, three test problems are numerically analyzed to validate these theoretical results. The chaotic behavior of the equation is analyzed, in relation to the viscosity coefficient γ , and is also numerically investigated using the proposed method.},
  archive      = {J_CMA},
  author       = {L. Jones Tarcius Doss and V. Sindhujarani},
  doi          = {10.1016/j.camwa.2025.03.009},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {19-39},
  shortjournal = {Comput. Meth. Appl.},
  title        = {H1− galerkin mixed finite element method using tensor product of cubic B-splines for two-dimensional kuramoto-sivashinsky equation},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed spectral element method combined with second-order
time stepping schemes for a two-dimensional nonlinear fourth-order
fractional diffusion equation. <em>CMA</em>, <em>188</em>, 1–18. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a mixed spectral element method combined with second-order time stepping schemes for solving a two-dimensional nonlinear fourth-order fractional diffusion equation is constructed. For formulating an efficient numerical scheme, an auxiliary function is introduced to transform the fourth-order fractional system into a low-order coupled system, then the time direction is discretized by second-order FBT- θ schemes, and the spatial direction is approximated using the Legendre mixed spectral element method (LMSEM). The stability and the optimal error estimate with O ( τ 2 + h min ⁡ { N + 1 , r } N − r ) for the fully discrete scheme are derived, where τ stands for the time step size, h denotes the space step size, N indicates the degree of the polynomial, and r represents the order of Sobolev space. Finally, some numerical tests are carried out to verify the theory results and the effectiveness of the developed algorithm.},
  archive      = {J_CMA},
  author       = {Jiarui Wang and Yining Yang and Hong Li and Yang Liu},
  doi          = {10.1016/j.camwa.2025.03.015},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {1-18},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Mixed spectral element method combined with second-order time stepping schemes for a two-dimensional nonlinear fourth-order fractional diffusion equation},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A non-convex and non-smooth weighted image denoising model.
<em>CMA</em>, <em>187</em>, 85–105. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to provide a more effective method to describe the local structure of the degraded image and to enhance the robustness of the denoising, we propose a non-convex total variational image denoising model that combines the non-convex log function with an adaptive weighted matrix within the total variation framework. In the proposed model, the weighted matrix is capable of effectively describing the primary direction of the edge structure, based on the coupling of the gradient operator of the denoising image and the diagonal matrix. As the proposed model is a non-convex and non-smooth optimisation problem, the iterative reweighted ℓ 1 algorithm and alternating direction multiplier method are employed to decompose it into a number of readily solvable sub-problems. The results obtained from numerical experiments demonstrate that the proposed model is capable of effectively suppressing the noise while maintaining the local structure of the image.},
  archive      = {J_CMA},
  author       = {Huayu Fan and Qiqi Feng and Rui Chen and Xiangyang Cao and Zhi-Feng Pang},
  doi          = {10.1016/j.camwa.2025.03.010},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {85-105},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A non-convex and non-smooth weighted image denoising model},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-implicit lax-wendroff kinetic scheme for multi-scale
phonon transport. <em>CMA</em>, <em>187</em>, 72–84. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast and accurate predictions of the spatiotemporal distributions of temperature are crucial to the multi-scale thermal management and safe operation of microelectronic devices. To realize it, an efficient semi-implicit Lax-Wendroff kinetic scheme is developed for numerically solving the transient phonon Boltzmann transport equation (BTE) from the ballistic to diffusive regime. The biggest innovation of the present scheme is that the finite difference method is used to solve the phonon BTE for the reconstruction of the interfacial distribution function at the half-time step, where the second-order numerical schemes are used for both the temporal and spatial discretization. Consequently, the phonon scattering and migration are coupled together within one time step, and the evolution process of phonon distribution function follows the actual physical law even if the time step is much longer than the relaxation time. Numerical results show that the present scheme could accurately predict the steady/unsteady heat conduction in solid materials from the ballistic to diffusive regime, and its time step or cell size is not limited by the relaxation time or phonon mean free path. The present work could provide a useful tool for the efficient predictions of the macroscopic spatiotemporal distributions in the multi-scale thermal engineering.},
  archive      = {J_CMA},
  author       = {Shuang Peng and Songze Chen and Hong Liang and Chuang Zhang},
  doi          = {10.1016/j.camwa.2025.03.019},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {72-84},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Semi-implicit lax-wendroff kinetic scheme for multi-scale phonon transport},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lattice-boltzmann inspired finite volume solver for
compressible flows. <em>CMA</em>, <em>187</em>, 50–71. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lattice Boltzmann method (LBM) for compressible flow is characterized by good numerical stability and low dissipation, while the conventional finite volume solvers have intrinsic conversation and flexibility in using unstructured meshes for complex geometries. This paper proposes a strategy to combine the advantages of the two kinds of solvers by designing a finite volume solver to mimic the LBM algorithm. It assumes an ideal LBM that can recover all desired higher-order moments. Time-discretized moment equations with second-order temporal accuracy and physically consistent dissipation terms are derived from the ideal LBM. By solving the recovered moment equations, a finite volume solver that can be applied to nonuniform meshes naturally, enabling body-fitted mass-conserving simulations, is proposed. Numerical tests show that the proposed solver can achieve good numerical stability from subsonic to hypersonic flows, and low dissipation for a long-distance entropy spot convection. For the challenging direct simulations of acoustic waves, its dissipation can be significantly reduced compared with the Lax-Wendroff solver of the same second-order spatial and temporal accuracy, while only remaining higher than that of the LBM on coarse meshes. The analysis implies that approximations of third-order temporal accuracy are required to recover the low dissipation of LBM further.},
  archive      = {J_CMA},
  author       = {Jinhua Lu and Song Zhao and Pierre Boivin},
  doi          = {10.1016/j.camwa.2025.03.007},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {50-71},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A lattice-boltzmann inspired finite volume solver for compressible flows},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal numerical simulation of breast cancer tumors
in one-dimensional nonlinear moving boundary models via temporal-spatial
spectral collocation method. <em>CMA</em>, <em>187</em>, 30–49. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research article, we have simulated the solutions of three types of (classical) moving boundary models in ductal carcinoma in situ by an efficient temporal-spatial spectral collocation method. In all of these three classical models, the associated fixed (spatial) boundary equations are localized by the numerical scheme. In the numerical scheme, Laguerre polynomials and Hermite polynomials are implemented to approximate the temporal and spatial variables (of unknown solutions), respectively. Then, as a generalization of the first classical model, we have considered a space-fractional moving boundary model and then transformed it, again, to the corresponding fixed boundary space-fractional equation for a straightforward discretization. Due to the impossibility of transforming of the time-fractional moving boundary model into its fixed boundary variant, we localized the time-fractional moving boundary model directly by the proposed method. The results in this category are also very satisfactory and the accuracy is again in a spectral rate. Moreover, (temporal) multi-step version of our method is applied for the considered models and the results are very accurate with respect to the single-step one, especially when the boundary of tumor is diverging in practice. In this regard, an adaptive strategy is connected to the temporal multi-step approach for a better simulation. Extensive test problems are provided to verify the accuracy of the method, with full consideration given to iterative tools for solving the final system of nonlinear algebraic equations.},
  archive      = {J_CMA},
  author       = {Yin Yang and Sayyed Ehsan Monabbati and Emran Tohidi and Atena Pasban},
  doi          = {10.1016/j.camwa.2025.03.006},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {30-49},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Spatiotemporal numerical simulation of breast cancer tumors in one-dimensional nonlinear moving boundary models via temporal-spatial spectral collocation method},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decoupled, convergent and fully linear algorithm for the
landau–lifshitz–gilbert equation with magnetoelastic effects.
<em>CMA</em>, <em>187</em>, 1–29. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the coupled system of the Landau–Lifshitz–Gilbert equation and the conservation of linear momentum law to describe magnetic processes in ferromagnetic materials including magnetoelastic effects in the small-strain regime. For this nonlinear system of time-dependent partial differential equations, we present a decoupled integrator based on first-order finite elements in space and an implicit one-step method in time. We prove unconditional convergence of the sequence of discrete approximations towards a weak solution of the system as the mesh size and the time-step size go to zero. Compared to previous numerical works on this problem, for our method, we prove a discrete energy law that mimics that of the continuous problem and, passing to the limit, yields an energy inequality satisfied by weak solutions. Moreover, our method does not employ a nodal projection to impose the unit length constraint on the discrete magnetisation, so that the stability of the method does not require weakly acute meshes. Furthermore, our integrator and its analysis hold for a more general setting, including body forces and traction, as well as a more general representation of the magnetostrain. Numerical experiments underpin the theory and showcase the applicability of the scheme for the simulation of the dynamical processes involving magnetoelastic materials at submicrometer length scales.},
  archive      = {J_CMA},
  author       = {Hywel Normington and Michele Ruggeri},
  doi          = {10.1016/j.camwa.2025.03.008},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {1-29},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A decoupled, convergent and fully linear algorithm for the Landau–Lifshitz–Gilbert equation with magnetoelastic effects},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cmame---59">CMAME - 59</h2>
<ul>
<li><details>
<summary>
(2025). SK-PINN: Accelerated physics-informed deep learning by
smoothing kernel gradients. <em>CMAME</em>, <em>440</em>, 117956. (<a
href="https://doi.org/10.1016/j.cma.2025.117956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic differentiation (AD) in the vanilla physics-informed neural networks (PINNs) is the computational bottleneck for the high-efficiency analysis. The concept of derivative discretization in smoothed particle hydrodynamics (SPH) can provide an accelerated training method for PINNs. In this paper, smoothing kernel physics-informed neural networks (SK-PINNs) are established, which solve differential equations using smoothing kernel discretization. It is a robust framework capable of solving problems in the computational mechanics of complex domains. When the number of collocation points gradually increases, the training speed of SK-PINNs significantly surpasses that of vanilla PINNs. In cases involving large collocation point sets or higher-order problems, SK-PINN training can be up to tens of times faster than vanilla PINN. Additionally, analysis using neural tangent kernel (NTK) theory shows that the convergence rates of SK-PINNs are consistent with those of vanilla PINNs. The superior performance of SK-PINNs is demonstrated through various examples, including regular and complex domains, as well as forward and inverse problems in fluid dynamics and solid mechanics.},
  archive      = {J_CMAME},
  author       = {Cunliang Pan and Chengxuan Li and Yu Liu and Yonggang Zheng and Hongfei Ye},
  doi          = {10.1016/j.cma.2025.117956},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117956},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {SK-PINN: Accelerated physics-informed deep learning by smoothing kernel gradients},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new paradigm for hybrid reliability-based design
optimization: From β-circle to β-cylinder. <em>CMAME</em>, <em>440</em>,
117954. (<a href="https://doi.org/10.1016/j.cma.2025.117954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new paradigm for hybrid reliability-based design optimization (HRBDO) is proposed. The key innovation lies in expanding the traditional β -circle into a β -cylinder along the interval dimensions, integrating both random and interval dimensional information. Building upon this theoretical foundation, a novel interval-based dimensional expansion β -cylinder active learning (IBAL) method is proposed, transforming the complex double-loop reliability calculation into an efficient single-loop process. The method employs Kriging models to replace expensive physical responses. Unlike traditional sampling techniques, the IBAL method focuses exclusively on predicted means and deviations on the β -cylinder to guide the Kriging models of performance functions, efficiently identifying the Most Probable Point (MPP). This approach effectively addresses challenges including interval dimensions nonlinearity, multiple extreme points, and multiple MPPs. In HRBDO, the method incorporates an active constraint screening (ACS) mechanism and an MPP objective function isosurface active learning (MIAL) method to enhance computational efficiency and avoid convergence to local optima. The effectiveness of the proposed method is validated through four mathematical examples and one engineering case study.},
  archive      = {J_CMAME},
  author       = {Peng Hao and Zehao Cui and Bingyi Du and Hao Yang and Yue Zhang},
  doi          = {10.1016/j.cma.2025.117954},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117954},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A new paradigm for hybrid reliability-based design optimization: From β-circle to β-cylinder},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Populating cellular metamaterials on the extrema of
attainable elasticity through neuroevolution. <em>CMAME</em>,
<em>440</em>, 117950. (<a
href="https://doi.org/10.1016/j.cma.2025.117950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trade-offs between different mechanical properties of materials pose fundamental challenges in engineering material design, such as balancing stiffness versus toughness, weight versus energy-absorbing capacity, and among the various elastic coefficients. Although gradient-based topology optimization approaches have been effective in finding specific designs and properties, they are not efficient tools for surveying the vast design space of metamaterials, and thus unable to reveal the attainable bound of interdependent material properties. Other common methods, such as parametric design or data-driven approaches, are limited by either the lack of diversity in geometry or the difficulty to extrapolate from known data, respectively. In this work, we formulate the simultaneous exploration of multiple competing material properties as a multi-objective optimization (MOO) problem and employ a neuroevolution algorithm to efficiently solve it. The Compositional Pattern-Producing Networks (CPPNs) is used as the generative model for unit cell designs, which provide very compact yet lossless encoding of geometry. A modified Neuroevolution of Augmenting Topologies (NEAT) algorithm is employed to evolve the CPPNs such that they create metamaterial designs on the Pareto front of the MOO problem, revealing empirical bounds of different combinations of elastic properties. Looking ahead, our method serves as a universal framework for the computational discovery of diverse metamaterials across a range of fields, including robotics, biomedicine, thermal engineering, and photonics.},
  archive      = {J_CMAME},
  author       = {Maohua Yan and Ruicheng Wang and Ke Liu},
  doi          = {10.1016/j.cma.2025.117950},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117950},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Populating cellular metamaterials on the extrema of attainable elasticity through neuroevolution},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generalized non-hourglass updated lagrangian formulation
for SPH solid dynamics. <em>CMAME</em>, <em>440</em>, 117948. (<a
href="https://doi.org/10.1016/j.cma.2025.117948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hourglass modes, characterized by zigzag particle and stress distributions, are a common numerical instability encountered when simulating solid materials with updated Lagrangian smoothed particle hydrodynamics (ULSPH). While recent solutions have effectively addressed this issue in elastic materials using an essentially non-hourglass formulation, extending these solutions to plastic materials with more complex constitutive equations has proven challenging due to the need to express shear forces in the form of a velocity Laplacian. To address this, a generalized non-hourglass formulation is proposed within the ULSPH framework, suitable for both elastic and plastic materials. Specifically, a penalty force is introduced into the momentum equation to resolve the disparity between the linearly predicted and actual velocity differences of neighboring particle pairs, thereby mitigating the hourglass issue. The stability, convergence, and accuracy of the proposed method are validated through a series of classical elastic and plastic cases, with a dual-criterion time-stepping scheme to improve computational efficiency. The results show that the present method not only matches or even surpasses the performance of the recent essentially non-hourglass formulation in elastic cases but also performs well in plastic scenarios.},
  archive      = {J_CMAME},
  author       = {Shuaihao Zhang and Dong Wu and Sérgio D.N. Lourenço and Xiangyu Hu},
  doi          = {10.1016/j.cma.2025.117948},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117948},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A generalized non-hourglass updated lagrangian formulation for SPH solid dynamics},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information entropy regularization method for structural
identification with large-scale damaged parameters. <em>CMAME</em>,
<em>440</em>, 117947. (<a
href="https://doi.org/10.1016/j.cma.2025.117947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of structural health monitoring technology, the increasing precision in modeling, scalability of model parameters, and complexity of external environments have introduced significant challenges to damage identification. Notably, the ill-posed nature of large-scale parameter identification from refined models has become a critical technical challenge. Regularization methods are widely employed to mitigate ill-posedness and control the complexity of identification problems. Traditional regularization methods often penalize imbalances in damage parameters, leading to errors and suboptimal convergence, failing to accurately reflect actual damage conditions. To address these challenges, an information entropy regularization term is introduced to capture the distribution of structural damage location and severity. By integrating regularization term with an adjoint sensitivity optimization algorithm, a refined iterative approach is developed to manage large-scale damage parameter identification from detailed finite element models. Numerical analyses on a 2D stress plate and a 3D wing, along with experimental validation on impact damage of clamped plates, demonstrate the accuracy and effectiveness of the proposed method.},
  archive      = {J_CMAME},
  author       = {Yifei Wang and Xiaojun Wang and Geyong Cao},
  doi          = {10.1016/j.cma.2025.117947},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117947},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Information entropy regularization method for structural identification with large-scale damaged parameters},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Teaching artificial intelligence to perform rapid,
resolution-invariant grain growth modeling via fourier neural operator.
<em>CMAME</em>, <em>440</em>, 117945. (<a
href="https://doi.org/10.1016/j.cma.2025.117945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microstructural evolution, particularly grain growth, plays a critical role in shaping the physical, optical, and electronic properties of materials. Traditional phase-field modeling accurately simulates these phenomena but is computationally intensive, especially for large systems and fine spatial resolutions. While machine learning approaches have been employed to accelerate simulations, they often struggle with resolution dependence and generalization across different grain scales. This study introduces a novel approach utilizing Fourier Neural Operator (FNO) to achieve resolution-invariant modeling of microstructure evolution in multi-grain systems. FNO operates in the Fourier space and can inherently handle varying resolutions by learning mappings between function spaces. By integrating FNO with the phase-field method, we developed a surrogate model that significantly reduces computational costs while maintaining high accuracy across different spatial scales. We generated a comprehensive dataset from phase-field simulations using the Fan–Chen model, capturing grain evolution over time. Data preparation involved creating input–output pairs with a time shift, allowing the model to predict future microstructures based on current and past states. The FNO-based neural network was trained using sequences of microstructures and demonstrated remarkable accuracy in predicting long-term evolution, even for unseen configurations and higher-resolution grids not encountered during training.},
  archive      = {J_CMAME},
  author       = {Iman Peivaste and Ahmed Makradi and Salim Belouettar},
  doi          = {10.1016/j.cma.2025.117945},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117945},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Teaching artificial intelligence to perform rapid, resolution-invariant grain growth modeling via fourier neural operator},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key conditional quotient of random finite element model
under measurement conditions. <em>CMAME</em>, <em>440</em>, 117943. (<a
href="https://doi.org/10.1016/j.cma.2025.117943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty and nonlinearity in real-world structures like complex connections and composite materials often impede the establishment of accurate finite element models, requiring measurement assistance to estimate the actual structural response. However, accurately and efficiently estimating the structural response in the face of random measurement errors, structural uncertainty, and nonlinear effects remains a challenge. In this study, a novel key conditional quotient (KCQ) theory has been presented to tackle this challenge. By extracting key conditions from measurement data and applying the principle of probability conservation, the KCQ theory provides an precise quotient-form expression, i.e., KCQ, for estimating the structural response considering random measurement errors, structural uncertainty, and nonlinearity. To effectively extract key measurement conditions, this study also proposes two innovative methods: the strong correlation measurement points method, and the covariance matrix of measurement errors method. To accurately and efficiently estimating the KCQ, a numerical method by combining the generalized quasi-Monte Carlo method based on the generalized center discrepancy and an offline-online coupling computational strategy is proposed. Five numerical examples are provided to verify the precision, efficiency, and robustness against measurement errors of the proposed KCQ theory and numerical method.},
  archive      = {J_CMAME},
  author       = {Yuelin Zhao and Feng Wu},
  doi          = {10.1016/j.cma.2025.117943},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117943},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Key conditional quotient of random finite element model under measurement conditions},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EM-based fast uncertainty quantification for bayesian
multi-setup operational modal analysis. <em>CMAME</em>, <em>440</em>,
117942. (<a href="https://doi.org/10.1016/j.cma.2025.117942">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current Bayesian FFT algorithm relies on direct differentiation to obtain the posterior covariance matrix (PCM), which is time-consuming, memory-intensive, and hard to code, especially for the multi-setup operational modal analysis (OMA). Aiming at accelerating the uncertainty quantification in multi-setup OMA, an expectation-maximization (EM)-based algorithm is proposed by reformulating the Hessian matrix of the negative log-likelihood function (NLLF) as a sum of simplified components corresponding to the complete-data NLLF. Matrix calculus is employed to derive these components in a compact manner, resulting in expressions similar to those in the single-setup case. This similarity allows for the reuse of existing Bayesian single-setup OMA codes, simplifying implementation. The singularity caused by mode shape norm constraints is addressed through null space projection, eliminating potential numerical errors from the conventional pseudoinverse operation. A sparse assembly strategy is further adopted, avoiding unnecessary calculations and storage of predominant zero elements in the Hessian matrix. The proposed method is then validated through a comprehensive parametric study and applied to a multi-setup OMA of a high-rise building. Results demonstrate that the proposed method efficiently calculates the PCM within seconds, even for cases with hundreds of parameters. This represents an efficiency improvement of at least one order of magnitude over the state-of-the-art method. Such performance paves the way for a real-time modal identification of large-scale structures, including those with closely-spaced modes.},
  archive      = {J_CMAME},
  author       = {Wei Zhu and Binbin Li and Zuo Zhu},
  doi          = {10.1016/j.cma.2025.117942},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117942},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {EM-based fast uncertainty quantification for bayesian multi-setup operational modal analysis},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundary settings for seismic dynamic analysis of rock
masses using the nodal-based continuous-discontinuous deformation
analysis method. <em>CMAME</em>, <em>440</em>, 117941. (<a
href="https://doi.org/10.1016/j.cma.2025.117941">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nodal-based continuous-discontinuous deformation analysis method (NCDDAM) proposed by the authors has demonstrated its potential for dynamic analysis of rock masses with discontinuities. However, the existing boundary conditions applied in NCDDAM are not suitable for seismic dynamic analysis, as they can cause fictitious reflected waves. To further apply the NCDDAM for seismic dynamic analysis, this paper introduces five boundary conditions: viscous boundary, viscoelasticity boundary, seismic input boundary, free field boundary, and static-dynamic unified boundary. Several numerical examples are conduced to validate the enriched NCDDAM. The numerical results demonstrate the capacity of the enriched NCDDAM for seismic dynamic analysis of rock masses. The nonreflecting boundaries applied in NCDDAM can effectively absorb wave energy and avoid fictitious scattered waves, while the free field boundary applied in NCDDAM effectively simulates wave propagation in a semi-infinite domain. Based on the static-dynamic unified boundary, the seamless transition of boundary condition settings between the quasi-static and dynamic stages can be achieved. The entire evolution process of earthquake-induced disasters, including initiation, movement, run-out, and deposition can be effectively simulated within a unified framework using the enriched NCDDAM.},
  archive      = {J_CMAME},
  author       = {Yang Xia and Yongtao Yang and Hong Zheng and He Liu and Shuilin Wang},
  doi          = {10.1016/j.cma.2025.117941},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117941},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Boundary settings for seismic dynamic analysis of rock masses using the nodal-based continuous-discontinuous deformation analysis method},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The shifted boundary method for contact problems.
<em>CMAME</em>, <em>440</em>, 117940. (<a
href="https://doi.org/10.1016/j.cma.2025.117940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an embedded algorithm for contact mechanics based on the Shifted Boundary Method. The contact conditions are applied on a surrogate contact surface in proximity of the true contact surface and Taylor expansions are used to change (shift) both their value and location. This approach is robust, accurate, and avoids integrating the variational formulation on cut cells and related numerical instabilities. Computational experiments in both two and three dimensions are provided to demonstrate the performance of our methodology. The proposed approach offers an advantage whenever bodies of very complex shape come into contact, especially when the shapes are not represented using standard Computer Aided Design (CAD) formats. In all these situations, body-fitted grid generation may become extremely time consuming or completely unfeasible.},
  archive      = {J_CMAME},
  author       = {Kangan Li and Andrea Gorgi and Riccardo Rossi and Guglielmo Scovazzi},
  doi          = {10.1016/j.cma.2025.117940},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117940},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {The shifted boundary method for contact problems},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven elastoplastic constitutive modelling with
physics-informed RNNs using the virtual fields method for indirect
training. <em>CMAME</em>, <em>440</em>, 117935. (<a
href="https://doi.org/10.1016/j.cma.2025.117935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing demand for accurate material behaviour data in engineering simulations has exposed the limitations of traditional constitutive models. Although recent advances in full-field measurement techniques provide more detailed material characterization, conventional approaches still heavily rely on explicit assumptions and labour-intensive experimentation. This paper revisits the indirect training methodology introduced by the authors [1] , which integrates Recurrent Neural Networks (RNNs) with Gated-Recurrent Units (GRUs) and the Virtual Fields Method (VFM) to model material behaviour without labelled data. The earlier study demonstrated the feasibility of training a GRU-based RNN using only global force and strain data through the VFM. Building on those findings, this work presents a more robust approach featuring an improved network architecture, with residual connections to enhance gradient flow and training stability, while also incorporating physics-based constraints. Extensive hyperparameter tuning was conducted to optimize the model and a sensitivity analysis was performed to assess the impact of the virtual fields on the accuracy and training dynamics. The models were validated using additional heterogeneous mechanical tests and the Reconstructed Axial Force Ratio (RAFR), as a key performance indicator, to further assess the physical correctness. The results show enhanced predictive accuracy and improved force reconstruction when larger sets of virtual fields are employed. Additionally, normalizing the VFM loss contributed to more consistent predictions and force reconstruction across all time stages. Stress contour plots further confirm the model’s ability to accurately predict stress distributions, which are in good agreement with the reference, with low median and average absolute errors.},
  archive      = {J_CMAME},
  author       = {Rúben Lourenço and Petia Georgieva and A. Andrade-Campos},
  doi          = {10.1016/j.cma.2025.117935},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117935},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Data-driven elastoplastic constitutive modelling with physics-informed RNNs using the virtual fields method for indirect training},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Customized gaussian process for representing polycrystalline
texture. <em>CMAME</em>, <em>440</em>, 117934. (<a
href="https://doi.org/10.1016/j.cma.2025.117934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A customized Gaussian Process Regression (GPR) model is developed to reconstruct Pole Density Functions in texture analysis. The model integrates spherical-periodic distance measures with conventional stationary kernels, adapting the GPR framework to capture localized texture features. A key contribution is the introduction of a log-linear data transformation, which enforces the non-negativity of both interpolated function values and stochastic intervals, ensuring physically meaningful reconstructions. To assess the model’s effectiveness, a systematic investigation examines the impact of distance measures, kernel selection, and hyperparameter optimization using synthetic texture datasets, provided as part of this work, with evaluations focusing on reconstruction accuracy, feature preservation, and uncertainty quantification in comparison to the conventional spherical harmonics approach. GPR with a log-linear transformation, geodesic distance, and a Matérn ν =5/2 kernel, shows promise in achieving higher accuracy than traditional spherical harmonics for reconstructing non-negative pole density functions, while additionally providing confidence intervals for uncertainty quantification.},
  archive      = {J_CMAME},
  author       = {Bingqian Li and Piotr Breitkopf and Ludovic Cauvin},
  doi          = {10.1016/j.cma.2025.117934},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117934},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Customized gaussian process for representing polycrystalline texture},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RoePINNs: An integration of advanced CFD solvers with
physics-informed neural networks and application in arterial flow
modeling. <em>CMAME</em>, <em>440</em>, 117933. (<a
href="https://doi.org/10.1016/j.cma.2025.117933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The characterization of forward and inverse problems describing blood flow dynamics plays a decisive role in numerous biomedical applications. These systems can be modeled using one-dimensional (1D) approaches leading to a hyperbolic system of equations with source terms. Their numerical discretization, associated to the spatial variation of mechanical and geometrical properties, requires advanced numerical solvers that ensure both stability and an accurate description of the dynamics of the system. In this work, we present RoePINNs, a hybrid framework for the embedding of advanced Computational Fluid Dynamics (CFD) solvers into Physics-Informed Neural Networks (PINNs), and give examples of application to Burgers’ equation as well as the propagation of nonlinear waves in elastic arteries, both under the presence of geometric-type source terms, for forward and inverse problems. We demonstrate that Augmented Riemann solvers can be incorporated into the PINN framework with straightforward adjustments to the hyperparameters, providing a promising alternative to automatic differentiation (AD), especially in cases where the solution exhibits strong nonlinearities and physical constraints are required. Benefits of the proposed RoePINN compared with the vanilla PINN based in AD are twofold: on the one hand, this hybrid approach employs numerical differentiation by means of support points in the surroundings of the collocation points, hence the robustness, generalization capacity and tunability of the PINNs are, in most cases, largely enhanced. On the other hand, the RoePINN incorporates the numerical solver, hence it is also capable of capturing sharp discontinuities with an order-of-magnitude improvement in accuracy compared with the vanilla version.},
  archive      = {J_CMAME},
  author       = {J. Orera and J. Ramírez and P. García-Navarro and J. Murillo},
  doi          = {10.1016/j.cma.2025.117933},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117933},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {RoePINNs: An integration of advanced CFD solvers with physics-informed neural networks and application in arterial flow modeling},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy stable and structure-preserving algorithms for the
stochastic galerkin system of 2D shallow water equations.
<em>CMAME</em>, <em>440</em>, 117932. (<a
href="https://doi.org/10.1016/j.cma.2025.117932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shallow water equations (SWE) are fundamental nonlinear hyperbolic PDE-based models in fluid dynamics that are essential for studying a wide range of geophysical and engineering phenomena. Therefore, stable and accurate numerical methods for SWE are needed. Although some algorithms are well studied for deterministic SWE, more effort should be devoted to handling the SWE with uncertainty. In this paper, we incorporate uncertainty through a stochastic Galerkin (SG) framework, and building on an existing hyperbolicity-preserving SG formulation for 2D SWE, we construct the corresponding entropy flux pair, and develop structure-preserving, well-balanced, second-order energy conservative and energy stable finite volume schemes for the SG formulation of the two-dimensional shallow water system. We demonstrate the efficacy, applicability, and robustness of these structure-preserving algorithms through several challenging numerical experiments.},
  archive      = {J_CMAME},
  author       = {Yekaterina Epshteyn and Akil Narayan and Yinqian Yu},
  doi          = {10.1016/j.cma.2025.117932},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117932},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Energy stable and structure-preserving algorithms for the stochastic galerkin system of 2D shallow water equations},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A competitive baseline for deep learning enhanced data
assimilation using conditional gaussian ensemble kalman filtering.
<em>CMAME</em>, <em>440</em>, 117931. (<a
href="https://doi.org/10.1016/j.cma.2025.117931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble Kalman Filtering (EnKF) is a popular technique for data assimilation, with far ranging applications. However, the vanilla EnKF framework is not well-defined when perturbations are nonlinear. We study two non-linear extensions of the vanilla EnKF – dubbed the conditional-Gaussian EnKF (CG-EnKF) and the normal score EnKF (NS-EnKF) – which sidestep assumptions of linearity by constructing the Kalman gain matrix with the ‘conditional Gaussian’ update formula in place of the traditional one. We then compare these models against a state-of-the-art deep learning based particle filter called the score filter (SF). This model uses an expensive score diffusion model for estimating densities and also requires a strong assumption on the perturbation operator for validity. In our comparison, we find that CG-EnKF and NS-EnKF dramatically outperform SF for two canonical systems in data assimilation: the Lorenz-96 system and a double well potential system. Our analysis also demonstrates that the CG-EnKF and NS-EnKF can handle highly non-Gaussian additive noise perturbations, with the latter typically outperforming the former.},
  archive      = {J_CMAME},
  author       = {Zachariah Malik and Romit Maulik},
  doi          = {10.1016/j.cma.2025.117931},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117931},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A competitive baseline for deep learning enhanced data assimilation using conditional gaussian ensemble kalman filtering},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PIGODE: A novel model for efficient surrogate modeling in
complex geometric structures. <em>CMAME</em>, <em>440</em>, 117930. (<a
href="https://doi.org/10.1016/j.cma.2025.117930">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Network (PINN), as a novel neural network model, is known for its strong interpretability and generalization capabilities, making it widely used in surrogate models and various engineering scenarios. While traditional PINN has achieved good results in simple geometric scenarios, there is limited research on its application to complex geometric structures. Additionally, PINN integrates boundary conditions into the loss function, requiring retraining model when boundary conditions change. To address these issues, we propose a new Physics-Informed Graph Ordinary Differential Equation (PIGODE) model for constructing surrogate models in complex geometric structures. The Peridynamic Differential Operator (PDDO) is extended to a PIGODE which is defined on graph data structure, and a PDDO-based message passing layer is developed to replace automatic differentiation (AD). This method precomputes Peridynamic weights, thereby avoiding additional computational overhead during model training. Furthermore, boundary conditions are embedded into the model input to address the need for dynamically modifying boundary conditions in surrogate models. Through comparative studies with existing PINN solvers, we validate the effectiveness of the proposed model, demonstrating its superior performance on complex geometric structures. Additionally, this model is applied to practical engineering scenarios, specifically constructing a temperature field surrogate model for the conical picks of a tunnel boring machine. The research results indicate that the proposed PIGODE model not only enhances the interpretability and efficiency of surrogate models but also extends their applicability to complex geometric structures in engineering.},
  archive      = {J_CMAME},
  author       = {Chengyu Lu and Zhaoxi Hong and Xiuju Song and Zhixin Liu and Bingtao Hu and Yixiong Feng and Jianrong Tan},
  doi          = {10.1016/j.cma.2025.117930},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117930},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {PIGODE: A novel model for efficient surrogate modeling in complex geometric structures},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frictional contact between solids: A fully eulerian
phase-field approach. <em>CMAME</em>, <em>440</em>, 117929. (<a
href="https://doi.org/10.1016/j.cma.2025.117929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements have demonstrated that fully Eulerian methods can effectively model frictionless contact between deformable solids. Unlike traditional Lagrangian approaches, which require contact detection and resolution algorithms, the Eulerian framework utilizes a single, fixed spatial mesh combined with a diffuse interface phase-field approach, simplifying contact resolution significantly. Moreover, the Eulerian method is well-suited for developing a unified framework to handle multiphysical systems involving growing bodies that interact with a constraining medium. In this work, we extend our previous methodology to incorporate frictional contact. By leveraging the intersection of the phase fields of multiple bodies, we define normal and tangential penalty force fields, which are incorporated into the linear momentum equations to capture frictional interactions. This formulation allows independent motion of each body using distinct velocity fields, coupled solely through interfacial forces arising from contact and friction. We thoroughly validate the proposed approach through several numerical examples. The method is shown to handle large sliding effortlessly, accurately capture the stick–slip transition, and preserve history-dependent energy dissipation, offering a solution for modeling frictional contact in Eulerian models.},
  archive      = {J_CMAME},
  author       = {Flavio Lorez and Mohit Pundir},
  doi          = {10.1016/j.cma.2025.117929},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117929},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Frictional contact between solids: A fully eulerian phase-field approach},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based surrogate capacity models and
multi-objective fragility estimates for reinforced concrete frames.
<em>CMAME</em>, <em>440</em>, 117928. (<a
href="https://doi.org/10.1016/j.cma.2025.117928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes surrogate capacity models for reinforced concrete frames (RCFs) using deep neural networks (DNNs) and Transformers to address the strong nonlinearity in structural deformation. After validating the finite element modeling method, an extensive stochastic finite element analysis is conducted to construct a comprehensive capacity database. The hyperparameters for the DNN architecture are initially determined, balancing accuracy with model complexity to finalize the surrogate capacity models. However, due to the strong nonlinearity in deformation-related surrogate models, lower accuracies are observed, which are further improved by applying a logarithmic transformation and the more advanced Transformer model. Despite these enhancements, the accuracy achieved by standard DNNs remains the most optimal, indicating their suitability for this task. Considering uncertainties in input features and neural network hyperparameters, fragility estimates for example RCFs are rapidly predicted using the surrogate capacity models. The fragility assessment indicates that the peak deformation is strongly influenced by structural nonlinearity among all output responses.},
  archive      = {J_CMAME},
  author       = {Lili Xing and Paolo Gardoni and Ge Song and Ying Zhou},
  doi          = {10.1016/j.cma.2025.117928},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117928},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Deep learning-based surrogate capacity models and multi-objective fragility estimates for reinforced concrete frames},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal modeling based on manifold learning for
collision dynamic prediction of thin-walled structures under oblique
load. <em>CMAME</em>, <em>440</em>, 117926. (<a
href="https://doi.org/10.1016/j.cma.2025.117926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical simulation of the collision dynamics in thin-walled structures under oblique load involves complex spatiotemporal processes, including material, geometric, and contact nonlinearities, which often require significant computational resources and time. Moreover, predicting high-dimensional spatiotemporal responses remains a challenge for most surrogate-based models. This paper proposes a deep learning framework based on manifold learning for spatiotemporal modeling of collision dynamics in thin-walled structures under oblique load. The framework leverages multiple deep learning models, including Variational Autoencoders (VAE), Radial Basis Function Interpolation (RBFI), and regression Residual Network (ResNet18), to capture the complex nonlinearities inherent in structural deformation, stress distribution, and crush force, enabling continuous prediction of multimodal spatiotemporal responses. Using a rectangular thin-walled tube under oblique load as an example, the models are validated with simulation data, yielding average prediction errors of 5.80 % for structural deformation, 6.01 % for Energy Absorption (EA), 10.66 % for Peak Crush Force (PCF), and 16.66 % for crush force. Compared to traditional finite element (FE) simulations, prediction time is reduced by 98.6 % for structural deformation and stress distribution, and 97.4 % for crush force. Additionally, the method demonstrates stability and broad applicability across different design parameters and structural configurations, including rectangular and double-cell tubes. This work underscores the potential of deep learning techniques to enhance computational efficiency and predictive accuracy in the crashworthiness design of thin-walled structures.},
  archive      = {J_CMAME},
  author       = {Jian Xie and Junyuan Zhang and Hao Zhou and Zihang Li and Zhongyu Li},
  doi          = {10.1016/j.cma.2025.117926},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117926},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Spatiotemporal modeling based on manifold learning for collision dynamic prediction of thin-walled structures under oblique load},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a canonical interface model with application to
micro-heterogeneous elastic solids. <em>CMAME</em>, <em>440</em>,
117925. (<a href="https://doi.org/10.1016/j.cma.2025.117925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finite-thickness interphases between different constituents in heterogeneous materials are often replaced by a zero-thickness interface model. Due to increasing area-to-volume ratio with decreasing size of microstructures, interfaces introduce a physical length into the effective response at the macroscale. The most commonly studied interface models are the cohesive interface model and the elastic interface model . The cohesive interface model allows for a displacement jump across the interface, in contrast to the elastic interface model that requires displacement continuity across the interface. The classical general interface model assumes that the interface displacement itself must coincide with the displacement average across the interface. The recently proposed extended general interface model defines the interface displacement kinematically via the weighted average of displacement across the interface. Here, we propose a canonical interface model based on a variationally consistent approach, which encompasses all previous interface models. We implement our model with the finite element method and illustrate its consequences through a series of numerical examples. Moreover, variationally consistent homogenization is employed to upscale an elastic composite with particles surrounded by a canonical interface and embedded in a matrix. The numerical results highlight the significance of the canonical interface model on the overall response of composites, at times leading to counter-intuitive behavior at the macroscale.},
  archive      = {J_CMAME},
  author       = {Ali Javili and Fredrik Larsson and Kenneth Runesson and Paul Steinmann},
  doi          = {10.1016/j.cma.2025.117925},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117925},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {On a canonical interface model with application to micro-heterogeneous elastic solids},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mutual-information-based dimensional learning: Objective
algorithms for identification of relevant dimensionless quantities.
<em>CMAME</em>, <em>440</em>, 117922. (<a
href="https://doi.org/10.1016/j.cma.2025.117922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical dimensional analysis provides powerful insights into underlying physical mechanisms, but has limitations in determining the uniqueness and measuring the relative importance of dimensionless quantities. To address these limitations, we propose a data-driven approach, called mutual-information-based dimensional learning, to identify unique and relevant dimensionless quantities from available data. The proposed method employs a novel information-theoretic criterion to measure the relative importance of dimensionless quantities, whereas the existing methodologies rely on sensitivity/derivative-based measures. This entropy-based measure provides two significant advantages: (1) invariance (objectivity) with respect to reparametrizations of variables, and (2) robustness against outliers. Numerical results show that our method outperforms the current state-of-the-art method in these aspects, and enables identifying dominant dimensionless quantities. Examples include the study of the friction factor in benchmark pipe flows, the eddy viscosity coefficients in turbulent channel flows and the vapor depression dynamics in laser–metal interaction.},
  archive      = {J_CMAME},
  author       = {Lei Zhang and Guowei He},
  doi          = {10.1016/j.cma.2025.117922},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117922},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Mutual-information-based dimensional learning: Objective algorithms for identification of relevant dimensionless quantities},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The junction riemann problem in 1D shallow water channels
including supercritical flow conditions. <em>CMAME</em>, <em>440</em>,
117919. (<a href="https://doi.org/10.1016/j.cma.2025.117919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents an advancement in solving the Shallow Water Equations (SWE) in one-dimensional (1D) networks of channels using the Junction Riemann Problem (JRP). The necessity for robust solvers for junctions in networks is evident from the extensive literature and the variety of proposed methods. While multidimensional coupled approaches that model junctions as two-dimensional spaces have shown success, they lack the computational efficiency of pure 1D methods that treat junctions as singular points. In this context, existing JRP-based methods have primarily been limited to subcritical flow regimes. For the first time, this paper demonstrates that the Junction Riemann Problem can be effectively used as an internal boundary condition across all flow regimes representing a junction of channels. The proposed JRP solution is both simple and robust, accommodating various flow regimes and an arbitrary number of channels without requiring additional information. Furthermore, it is shown that the JRP can be solved efficiently at internal boundaries and integrated with a standard first-order Godunov scheme to yield accurate results. The validation of this method is confirmed through a series of test cases, highlighting its effectiveness in modeling free-surface flows.},
  archive      = {J_CMAME},
  author       = {Juan Mairal and Javier Murillo and Pilar Garcia-Navarro},
  doi          = {10.1016/j.cma.2025.117919},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117919},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {The junction riemann problem in 1D shallow water channels including supercritical flow conditions},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel energy-fitted hexagonal quadrature scheme enables
low-cost and high-fidelity peridynamic computations. <em>CMAME</em>,
<em>440</em>, 117918. (<a
href="https://doi.org/10.1016/j.cma.2025.117918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this contribution, we propose a novel hexagonal quadrature scheme for one-neighbor interactions in continuum-kinematics-inspired peridynamics equivalent to bond-based peridynamics. The hexagonal quadrature scheme is fitted to correctly integrate the stored energy density within the nonlocal finite-sized neighborhood of a continuum point subject to affine expansion. Our proposed hexagonal quadrature scheme is grid-independent by relying on appropriate interpolation of pertinent quantities from collocation to quadrature points. In this contribution, we discuss linear and quadratic interpolations and compare our novel hexagonal quadrature scheme to common grid-dependent quadrature schemes. For this, we consider both, tetragonal and hexagonal discretizations of the domain. The accuracy of the presented quadrature schemes is first evaluated and compared by computing the stored energy density of various prescribed affine deformations within the nonlocal neighborhood. Furthermore, we perform three different boundary value problems, where we measure the effective Poisson’s ratio resulting from each quadrature scheme and evaluate the deformation of a unit square under extension and beam bending. Key findings of our studies are: The Poisson’s test is a good indicator for the convergence behavior of quadrature schemes with respect to the grid density. The accuracy of quadrature schemes depends, as expected, on their ability to appropriately capture the deformation within the nonlocal neighborhood. Our novel hexagonal quadrature scheme, rendering the correct effective Poisson’s ratio of 1 / 3 for small deformations, together with quadratic interpolation consequently yields the most accurate results for the studies presented in this contribution, thereby effectively reducing the computational cost.},
  archive      = {J_CMAME},
  author       = {Emely Schaller and Ali Javili and Paul Steinmann},
  doi          = {10.1016/j.cma.2025.117918},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117918},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A novel energy-fitted hexagonal quadrature scheme enables low-cost and high-fidelity peridynamic computations},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the mesh insensitivity of the edge-based smoothed finite
element method for moving-domain problems. <em>CMAME</em>, <em>440</em>,
117917. (<a href="https://doi.org/10.1016/j.cma.2025.117917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although much less sensitive to mesh distortion, the edge-based smoothed finite element method (ESFEM) can become ineffective on severely distorted elements whose Jacobians are less than or equal to zero, especially in transient cases. In this work, we first prove that the ESFEM may be unable to get over severe mesh distortion occurring even in a very simple mesh of four four-node quadrilateral (Q4) elements. We then propose a slight modification that makes the ESFEM inherently applicable to negative-Jacobian Q4 elements without requiring any ad hoc stabilization. For the ESFEM, a smoothing cell (SC) attached to negative-Jacobian Q4 element is rebuilt on the midpoint of the shorter diagonal of the damaged element. Thus, the SC has a positive area that accounts correctly for inertial effects of transient problems. Such a treatment is compatible with the regular procedure for constructing an edge-based SC in normal Q4 elements. The mesh insensitivity of the ESFEM is highlighted by solving fluid–structure interaction on negative-Jacobian Q4 elements. Importantly, the present scheme can be generalized to other linear n -sided elements which are more likely to be badly distorted in complex moving-domain problems.},
  archive      = {J_CMAME},
  author       = {Tao He},
  doi          = {10.1016/j.cma.2025.117917},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117917},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {On the mesh insensitivity of the edge-based smoothed finite element method for moving-domain problems},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Residual stress-constrained space–time topology optimization
for multi-axis additive manufacturing. <em>CMAME</em>, <em>440</em>,
117913. (<a href="https://doi.org/10.1016/j.cma.2025.117913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Residual stresses and distortions are major barriers to the broader adoption of wire arc additive manufacturing. These issues are coupled and arise due to large thermal gradients and phase transformations during the directed energy deposition process. Mitigating distortions may lead to substantial residual stresses, causing cracks in the fabricated components. In this paper, we propose a novel method to reduce both residual stresses and distortions by optimizing the fabrication sequence. This approach explores the use of non-planar layers, leveraging the increased manufacturing flexibility provided by robotic arms. Additionally, our method allows for the concurrent optimization of the structural layout and corresponding fabrication sequence. We employ the inherent strain method as a simplified process simulation model to predict residual stresses and distortions. Local residual stresses are aggregated using a p -norm function, which is integrated into distortion minimization as a constraint. Through numerical examples, we demonstrate that the optimized non-planar fabrication strategies can effectively reduce both residual stresses and distortions.},
  archive      = {J_CMAME},
  author       = {Kai Wu and Fred van Keulen and Jun Wu},
  doi          = {10.1016/j.cma.2025.117913},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117913},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Residual stress-constrained space–time topology optimization for multi-axis additive manufacturing},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-constrained discontinuous galerkin network (DGNet)
for compressible euler equations with out-of-distribution
generalization. <em>CMAME</em>, <em>440</em>, 117912. (<a
href="https://doi.org/10.1016/j.cma.2025.117912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time accurate solutions of large-scale complex dynamical systems are critically needed for control, optimization, uncertainty quantification, and decision-making in practical engineering and science applications, particularly in digital twin contexts. Recent research on hybrid approaches combining numerical methods and machine learning in end-to-end training has shown significant improvements over either approach alone. However, using neural networks as surrogate models generally exhibits limitations in generalizability over different settings and in capturing the evolution of solution discontinuities. In this work, we develop a model-constrained discontinuous Galerkin Network ( DGNet ) approach, a significant extension to our previous work (Nguyen and Bui-Thanh, 2022), for compressible Euler equations with out-of-distribution generalization. The core of DGNet is the synergy of several key strategies: (i) leveraging time integration schemes to capture temporal correlation and taking advantage of neural network speed for computation time reduction. This is the key to the temporal discretization-invariant property of DGNet ; (ii) employing a model-constrained approach to ensure the learned tangent slope satisfies governing equations; (iii) utilizing a DG-inspired architecture for GNN where edges represent Riemann solver surrogate models and nodes represent volume integration correction surrogate models, enabling capturing discontinuity capability, aliasing error reduction, and mesh discretization generalizability. Such a design allows DGNet to learn the DG spatial discretization accurately; (iv) developing an input normalization strategy that allows surrogate models to generalize across different initial conditions, geometries, meshes, boundary conditions, and solution orders. In fact, the normalization is the key to spatial discretization-invariance for DGNet ; and (v) incorporating a data randomization technique that not only implicitly promotes agreement between surrogate models and true numerical models up to second-order derivatives, ensuring long-term stability and prediction capacity, but also serves as a data generation engine during training, leading to enhanced generalization on unseen data. To validate the theoretical results, effectiveness, stability, and generalizability of our novel DGNet approach, we present comprehensive numerical results for 1D and 2D compressible Euler equation problems, including Sod Shock Tube, Lax Shock Tube, Isentropic Vortex, Forward Facing Step, Scramjet, Airfoil, Euler Benchmarks, Double Mach Reflection, and a Hypersonic Sphere Cone benchmark.},
  archive      = {J_CMAME},
  author       = {Hai Van Nguyen and Jau-Uei Chen and Tan Bui-Thanh},
  doi          = {10.1016/j.cma.2025.117912},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117912},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A model-constrained discontinuous galerkin network (DGNet) for compressible euler equations with out-of-distribution generalization},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-propelling, soft, and slender structures in fluids:
Cosserat rods immersed in the velocity–vorticity formulation of the
incompressible navier–stokes equations. <em>CMAME</em>, <em>440</em>,
117910. (<a href="https://doi.org/10.1016/j.cma.2025.117910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a hybrid Eulerian–Lagrangian method for the direct simulation of three-dimensional, heterogeneous, active, and self-propelling structures made of soft fibers and operating in incompressible viscous flows. Fiber-based organization of matter is pervasive in nature and engineering, from biological architectures made of cilia, hair, muscles or bones to polymers, composite materials or soft robots. In nature, many such structures are adapted to manipulate flows for feeding, swimming or energy harvesting, through mechanisms that are often not fully understood. While simulations can support the analysis (and subsequent translational engineering) of these systems, extreme fibers’ aspect-ratios, large elastic deformations, two-way coupling with three-dimensional flows, and self-propulsion all render the problem numerically challenging. To address this, we couple Cosserat rod theory, where fibers’ dynamics is accurately captured in one-dimensional fashion, with the velocity–vorticity formulation of the Navier–Stokes equations, through a virtual boundary technique. The favorable properties of the resultant hydroelastic solver are demonstrated against a battery of benchmarks, and further showcased in a range of multi-physics scenarios, involving magnetic actuation, viscous streaming, biomechanics, multi-body interaction, and untethered swimming.},
  archive      = {J_CMAME},
  author       = {Arman Tekinalp and Yashraj Bhosale and Songyuan Cui and Fan Kiat Chan and Mattia Gazzola},
  doi          = {10.1016/j.cma.2025.117910},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117910},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Self-propelling, soft, and slender structures in fluids: Cosserat rods immersed in the velocity–vorticity formulation of the incompressible Navier–Stokes equations},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harnessing dynamic turbulent dynamics in parrot optimization
algorithm for complex high-dimensional engineering problems.
<em>CMAME</em>, <em>440</em>, 117908. (<a
href="https://doi.org/10.1016/j.cma.2025.117908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Parrot Optimization Algorithm (PO) is a nature-inspired metaheuristic algorithm developed based on the social and adaptive behaviors of Pyrrhura molinae parrots. PO demonstrates robust optimization performance by balancing exploration and exploitation, mimicking foraging and cooperative activities. However, as the algorithm progresses through iterations, it faces critical challenges in maintaining search diversity and movement efficiency diminishes, leading to premature convergence and a reduced ability to find optimal solutions in complex search space. To address these limitations, this work introduces the Dynamic Turbulent-based Parrot Optimization Algorithm (DTPO), which represents a significant advancement over the original PO by incorporating three novel strategies: a novel Differential Mutation (DM), Dynamic Opposite Learning (DOL), and Turbulent Operator (TO). The DM Strategy enhances exploration by introducing controlled variations in the population, allowing DTPO to escape local optima. Also, the DOL Strategy dynamically generates opposite solutions to refresh stagnated populations, expanding the search space and maintaining adaptability. Finally, the TO strategy simulates chaotic movements inspired by turbulence, ensuring a thorough local search while preserving population diversity. Together, these strategies improve the algorithm&#39;s ability to explore, exploit, and converge efficiently. Furthermore, the DTPO&#39;s performance was rigorously evaluated on benchmark functions from CEC2017 and CEC2022, comparing it against 23 state-of-the-art algorithms. The results demonstrate DTPO&#39;s superior convergence speed, search efficiency, and optimization accuracy. Additionally, DTPO was tested on seven engineering design problems, achieving significant improvements over the original PO algorithm, with superior performance gains compared to other algorithms in real-world scenarios. Particularly, DTPO outperformed competing algorithms in 37 out of 41 benchmark functions, achieving an overall success rate of 90.24%. Moreover, DTPO obtained the best Friedman ranks across all comparisons, with values ranging from 3.03 to 1.18, demonstrating its superiority over classical, advanced, and recent algorithms. These results validate the proposed enhancements and highlight DTPO&#39;s robustness and effectiveness in solving complex optimization problems.},
  archive      = {J_CMAME},
  author       = {Mahmoud Abdel-Salam and Saleh Ali Alomari and Jing Yang and Sangkeum Lee and Kashif Saleem and Aseel Smerat and Vaclav Snasel and Laith Abualigah},
  doi          = {10.1016/j.cma.2025.117908},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117908},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Harnessing dynamic turbulent dynamics in parrot optimization algorithm for complex high-dimensional engineering problems},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The lagrangian-eulerian described particle flow topology
optimization (PFTO) approach with isogeometric material point method.
<em>CMAME</em>, <em>440</em>, 117892. (<a
href="https://doi.org/10.1016/j.cma.2025.117892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, several topology optimization methods in the Lagrangian or Eulerian description has accepted a wide of discussions, which have been applied to several design problems. In the current work, the primary intention is to propose the Particle Flow Topology Optimization (PFTO) approach in a Lagrangian-Eulerian description, which can sufficiently unify their unique characteristics and superiorities for the optimization with a higher effectiveness. Firstly, an Isogeometric Material Points Method (I-MPM) is applied to develop the numerical analysis framework for particles to solve the static equilibrium equation, which can maintain the consistency of geometrical model and analysis model using the same NURBS (non-uniform rational B-splines) basis functions. Secondly, a Lagrangian-Eulerian particle flow model is proposed for representing structural topology in the optimization, which consists of several critical components, namely the mappings of physical information (P2C: Particles to Control points, C2G: Control points to Gauss quadrature points), the inverse mappings of sensitivity information (G2C and C2P). Thirdly, the mathematical formulation for the maximization of structural loading-capability is developed using the PFTO approach, in which physical positions and material consumptions of particles are design variables to drive the evolvement of structural topology. The sensitivity analysis of the objective and constraint functions with respect to design variables at particles, namely physical information is derived in detail. Finally, several numerical design examples in 2D and 3D are performed to demonstrate the validity, effectiveness, and superiority of the proposed PFTO approach, and the indispensability of particles movement for the optimization is also sufficiently studied.},
  archive      = {J_CMAME},
  author       = {Daji Lin and Liang Gao and Jie Gao},
  doi          = {10.1016/j.cma.2025.117892},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117892},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {The lagrangian-eulerian described particle flow topology optimization (PFTO) approach with isogeometric material point method},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective bayesian optimisation of spinodoid cellular
structures for crush energy absorption. <em>CMAME</em>, <em>440</em>,
117890. (<a href="https://doi.org/10.1016/j.cma.2025.117890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the pursuit of designing safer and more efficient energy-absorbing structures, engineers must tackle the challenge of improving crush performance while balancing multiple conflicting objectives, such as maximising energy absorption and minimising peak impact forces. Accurately simulating real-world conditions necessitates the use of complex material models to replicate the non-linear behaviour of materials under impact, which comes at a significant computational cost. This study addresses these challenges by introducing a multi-objective Bayesian optimisation framework specifically developed to optimise spinodoid structures for crush energy absorption. Spinodoid structures, characterised by their scalable, non-periodic topologies and efficient stress distribution, offer a promising direction for advanced structural design. However, optimising design parameters to enhance crush performance is far from straightforward, particularly under realistic conditions. Conventional optimisation methods, although effective, often require a large number of costly simulations to identify suitable solutions, making the process both time-consuming and resource intensive. In this context, multi-objective Bayesian optimisation provides a clear advantage by intelligently navigating the design space, learning from each evaluation to reduce the number of simulations required, and efficiently addressing the complexities of non-linear material behaviour. By integrating finite element analysis with Bayesian optimisation, the framework developed in this study tackles the dual challenge of improving energy absorption and reducing peak force, particularly in scenarios where plastic deformation plays a critical role. Leveraging scalarisation and hypervolume-based techniques, the framework effectively identifies Pareto-optimal solutions that balance these conflicting objectives while accounting for the complexities of plastic material behaviour. Importantly, the approach also prevents problematic densification, ensuring structural integrity during impact. The results not only demonstrate the framework’s ability to outperform the NSGA-II algorithm but also highlight its potential for wider applications in structural and material optimisation. The framework’s adaptability to various design requirements underscores its capability to address complex, multi-objective optimisation challenges associated with real-world conditions.},
  archive      = {J_CMAME},
  author       = {Hirak Kansara and Siamak F. Khosroshahi and Leo Guo and Miguel A. Bessa and Wei Tan},
  doi          = {10.1016/j.cma.2025.117890},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117890},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Multi-objective bayesian optimisation of spinodoid cellular structures for crush energy absorption},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic learning from real-world observations of
systems with unknown inputs for model-form UQ and digital twinning.
<em>CMAME</em>, <em>440</em>, 117863. (<a
href="https://doi.org/10.1016/j.cma.2025.117863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In engineering systems, a digital twin serves as a digital replica encompassing both physical assets and their associated processes, such as manufacturing and certification. The implementation of digital twins offers substantial potential for various applications, including improved design, enhanced collaboration, effective energy management, risk mitigation, lifecycle management, and predictive maintenance. However, existing definitions of a “twin” are often ambiguous and lack a structured approach for developing digital twins, particularly for systems with unknown inputs. This paper addresses these shortcomings by proposing a clear definition and a robust methodology for building digital twins. Our methodology integrates projection-based model order reduction, a rapid approach for identifying unknown inputs, and a non-parametric probabilistic method for modeling and quantifying model-form uncertainty. Additionally, it incorporates a probabilistic learning approach for performing stochastic model updating. The effectiveness of this digital twinning methodology is illustrated through a case study involving an elevated truss footbridge located at the Autodesk Research facility at Pier 9 in San Francisco with unknown inputs. This case study underscores the importance of accurately modeling uncertainty to enhance the performance and reliability of digital twins in real-world engineering applications.},
  archive      = {J_CMAME},
  author       = {Zimi J. Zhang and Akmal Bakar and Adrian Humphry and Farhad Javid and Patrick Nadeau and Mehran Ebrahimi and Adrian Butscher and Alexander Tessier and Jesus Rodriguez and Charbel Farhat},
  doi          = {10.1016/j.cma.2025.117863},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117863},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Probabilistic learning from real-world observations of systems with unknown inputs for model-form UQ and digital twinning},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiscale design method using interpretable machine
learning for phononic materials with closely interacting scales.
<em>CMAME</em>, <em>440</em>, 117833. (<a
href="https://doi.org/10.1016/j.cma.2025.117833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulating the dispersive characteristics of vibrational waves is beneficial for many applications, e.g., high-precision instruments. architected hierarchical phononic materials have sparked promise tunability of elastodynamic waves and vibrations over multiple frequency ranges. In this article, hierarchical unit-cells are obtained, where features at each length scale result in a band gap within a targeted frequency range. Our novel approach, the “hierarchical unit-cell template method,” is an interpretable machine-learning approach that uncovers global unit-cell shape/topology patterns corresponding to predefined band-gap objectives. A scale-separation effect is observed where the coarse-scale band-gap objective is mostly unaffected by the fine-scale features despite the closeness of their length scales, thus enabling an efficient hierarchical algorithm. Moreover, the hierarchical patterns revealed are not predefined or self-similar hierarchies as common in current hierarchical phononic materials. Thus, our approach offers a flexible and efficient method for the exploration of new regions in the hierarchical design space, extracting minimal effective patterns for inverse design in applications targeting multiple frequency ranges.},
  archive      = {J_CMAME},
  author       = {Mary V. Bastawrous and Zhi Chen and Alexander C. Ogren and Chiara Daraio and Cynthia Rudin and L. Catherine Brinson},
  doi          = {10.1016/j.cma.2025.117833},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117833},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A multiscale design method using interpretable machine learning for phononic materials with closely interacting scales},
  volume       = {440},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-fidelity physics-informed machine learning framework
for fatigue life prediction of additive manufactured materials.
<em>CMAME</em>, <em>439</em>, 117924. (<a
href="https://doi.org/10.1016/j.cma.2025.117924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development direction of high reliability and longer serviceable life for major equipment requires accurate fatigue life predictions of additively manufactured (AM) components. However, small samples and high scatter of fatigue performance have become significant challenges in accurately modeling the fatigue failure behavior of AM components. To overcome the limitation of traditional fatigue life prediction models, a multi-fidelity physics-informed machine learning (PIML) framework is proposed. In this framework, the uncertainty quantification of fatigue performance and the fitting low-fidelity fatigue data with physical consistency are achieved through a physics-guided Wasserstein generative adversarial network with gradient penalty (WGAN-GP). The introduced concept of transfer learning allows training a physics-informed neural network (PiNN) using multi-fidelity fatigue data during the training process. Embedding the effect of manufacturing defects on fatigue performance as physical constraints can ensure the physical consistency of the overall multi-fidelity framework. Compared with traditional neural network (NN) and PiNN, the multi-fidelity framework has significant advantages in strong prediction performance, generalization ability and effectiveness. Moreover, the results of deep feature transfer demonstrate that the proposed multi-fidelity framework is expected to be a unified fatigue life prediction framework for AM materials.},
  archive      = {J_CMAME},
  author       = {Lanyi Wang and Shun-Peng Zhu and Borui Wu and Zijian Xu and Changqi Luo and Qingyuan Wang},
  doi          = {10.1016/j.cma.2025.117924},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117924},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Multi-fidelity physics-informed machine learning framework for fatigue life prediction of additive manufactured materials},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of damage evolution in CMCs considering the real
microstructures through a deep-learning scheme. <em>CMAME</em>,
<em>439</em>, 117923. (<a
href="https://doi.org/10.1016/j.cma.2025.117923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real microstructures of ceramic matrix composites (CMCs) play a crucial role in determining their damage behavior. However, considering the real microstructure within the high-fidelity numerical simulation usually leads to expensive computational costs. In this study, an end-to-end deep-learning (DL) framework is proposed to predict the evolution of damage fields for CMCs from their real microstructures, which are characterized through computed tomography (CT). Three sub-networks, including the microstructure processing network (MPN), elastic deformation prediction network (EPN), and damage sequence prediction network (DPN), are used to construct a two-stage DL model. In the first stage, the geometrical characteristics of real microstructure are precisely captured by the MPN with over 92 % precision for the yarns and matrix. In the second stage, the elastic deformation predicted by the EPN is taken as the intermediate variable to motivate the damage prediction of DPN with the MPN-predicted microstructure as input. The damage evolution of real microstructure is finally predicted with a mean relative error of 10.8 % for the primary damage variable fields. The high-damage regions in the microstructure can also be accurately captured with a mean precision of 87.9 %. The proposed model is further validated by the in-situ tensile experiment. The micro-cracks are proven to initiate and propagate in the high-damage regions. Compared with the high-fidelity numerical methods, this DL-based method can predict the damage evolution on the fly, avoiding time-consuming computation and poor convergence during the damage analysis.},
  archive      = {J_CMAME},
  author       = {Rongqi Zhu and Guohao Niu and Panding Wang and Chunwang He and Zhaoliang Qu and Daining Fang},
  doi          = {10.1016/j.cma.2025.117923},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117923},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Prediction of damage evolution in CMCs considering the real microstructures through a deep-learning scheme},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projection-based model order reduction of embedded boundary
models for CFD and nonlinear FSI. <em>CMAME</em>, <em>439</em>, 117920.
(<a href="https://doi.org/10.1016/j.cma.2025.117920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedded boundary methods (EBMs) for Computational Fluid Dynamics (CFD) and nonlinear fluid–structure interaction (FSI) – also known as immersed boundary methods, Cartesian methods, or fictitious domain methods – are the most robust methods for the solution of flow problems past obstacles that undergo large relative motions, significant deformations, large shape modifications, and/or surface topology changes. They can also introduce a high degree of automation in the task of grid generation and significant flexibility in the gridding of complex geometries. However, just like in the case of their counterpart body-fitted methods, their application to parametric flow computations at high Reynolds numbers remains today impractical in most engineering environments. For body-fitted CFD, the state of the art of projection-based model order reduction (PMOR) has significantly advanced during the last decade and demonstrated a remarkable success at reducing the dimensionality and wall-clock time of high Reynolds number models, while maintaining a desirable level of accuracy. For non-body-fitted CFD however, PMOR is still in its infancy, primarily because EBMs dynamically partition the computational fluid domain into real and ghost subdomains, which complicates the collection of solution snapshots and their compression into a reduced-order basis. In an attempt to fill this gap, this paper presents a robust computational framework for PMOR in the context of high Reynolds number flows and in the EBM setting of CFD/FSI (PMOR-EBM). The framework incorporates a hyperreduction approach based on the energy-conserving sampling and weighting (ECSW) method to accelerate the evaluation of the repeated projections arising in nonlinear implicit computations; and a piecewise-affine approach for constructing a nonlinear low-dimensional approximation of the solution to mitigate the Kolmogorov n -width barrier to the reducibility of transport models. The paper also assesses the performance of the proposed computational framework PMOR-EBM for two unsteady turbulent flow problems whose predictions necessitate or benefit from the application of an EBM; and two shape-parametric steady-state studies of the academic type but of relevance to design analysis and optimization.},
  archive      = {J_CMAME},
  author       = {Noah B. Youkilis and Charbel Farhat},
  doi          = {10.1016/j.cma.2025.117920},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117920},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Projection-based model order reduction of embedded boundary models for CFD and nonlinear FSI},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective loss balancing for physics-informed deep
learning. <em>CMAME</em>, <em>439</em>, 117914. (<a
href="https://doi.org/10.1016/j.cma.2025.117914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINN) are deep learning algorithms that leverage physical laws by including partial differential equations together with a respective set of boundary and initial conditions as penalty terms in their loss function. In this work, we observe the significant role of correctly weighting the combination of multiple competitive loss functions for training PINNs effectively. To this end, we implement and evaluate different methods aiming at balancing the contributions of multiple terms of the PINN’s loss function and their gradients. After reviewing three existing loss scaling approaches (Learning Rate Annealing, GradNorm and SoftAdapt), we propose a novel self-adaptive loss balancing scheme for PINNs named ReLoBRaLo (Relative Loss Balancing with Random Lookback). We extensively evaluate the performance of the aforementioned balancing schemes by solving both forward as well as inverse problems on three benchmark PDEs for PINNs: Burgers’ equation, Kirchhoff’s plate bending equation, Helmholtz’s equation and over 20 PDEs from the ”PINNacle” collection. The results show that ReLoBRaLo is able to consistently outperform the baseline of existing scaling methods in terms of accuracy while also inducing significantly less computational overhead for a variety of PDE classes.},
  archive      = {J_CMAME},
  author       = {Rafael Bischof and Michael A. Kraus},
  doi          = {10.1016/j.cma.2025.117914},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117914},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Multi-objective loss balancing for physics-informed deep learning},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven modeling framework for nonlinear static
aeroelasticity. <em>CMAME</em>, <em>439</em>, 117911. (<a
href="https://doi.org/10.1016/j.cma.2025.117911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the multiphysical coupling between a deformable structural body and the forces imposed on that body from a surrounding fluid can be a challenging and computationally expensive task, especially when the structure, fluid, or both exhibit nonlinear behavior. Consequently, there exists a need for novel reduced-order static aeroelasticity analysis techniques that make efficient use of high-fidelity computational models, especially for preliminary design of next-generation aerostructures with high-aspect ratio lifting surfaces exhibiting large deformations or in situ geometric reconfigurations driven by nonlinear mechanisms. This work presents the compositional static aeroelastic analysis method: an embarrassingly parallelizable data-driven modeling technique that seeks to construct a system-level aeroelastic surrogate model representing the function composition of high-fidelity structural and fluid models in terms of shape parameters characterizing a reduced-order geometric description of the deformed fluid–structure interface. By formulating the static aeroelasticity problem as a fixed point problem, the proposed reduced-order modeling framework removes the need for a reduced-order representation of the traction field acting on the structure, unlike previous data-driven methods that independently train separate fluid and structural surrogate models. Additionally, by replacing the iterative exchange of full-order aeroelastic coupling variables with a statistical exploration of a reduced-order shape parameter space, the minimum computational time for approximating a static aeroelastic response is equivalent to one set of high-fidelity fluid and structural model evaluations. The following work presents the theoretical development of the proposed compositional method and demonstrates its use in two case studies, one of which involves a cantilevered baffle comprised of linear and nonlinear material with large deformations exceeding 35%. Numerical results show close agreement with a conventional partitioned analysis scheme, where tip displacement error is less than 1% in both material cases. It is also demonstrated how traction field information can be reused when considering structural modifications to circumvent the need for additional computationally expensive fluid model evaluations.},
  archive      = {J_CMAME},
  author       = {Trent White and Darren Hartl},
  doi          = {10.1016/j.cma.2025.117911},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117911},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A data-driven modeling framework for nonlinear static aeroelasticity},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A finite element-based simulation of microstructure
evolution through a 3D finite strain cosserat phase-field model.
<em>CMAME</em>, <em>439</em>, 117900. (<a
href="https://doi.org/10.1016/j.cma.2025.117900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A computational framework for microstructure evolution in metallic polycrystals is achieved by coupling large deformation Cosserat isotropic hyperelasticity with a phase-field model to take into account grain boundary formation and motion. Each material point has an associated crystal lattice orientation described by the Cosserat microrotation, which can evolve due to deformation or grain boundary migration. The analysis is restricted to transformations in the solid state. The numerical treatment of the proposed model requires some consideration. Discretization by finite elements leads to a strongly nonlinear, coupled system. The microrotation is parametrized to facilitate the numerical treatment of incremental updates of the Cosserat degrees of freedom. In order to reduce computation time and effort, a parallel computing mechanism based on domain decomposition is adopted together with an iterative staggered scheme to avoid the ill-conditioning inherent to the monolithic coupled system of equations.},
  archive      = {J_CMAME},
  author       = {Jad Doghman and Christophe Bovet and Anna Ask},
  doi          = {10.1016/j.cma.2025.117900},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117900},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A finite element-based simulation of microstructure evolution through a 3D finite strain cosserat phase-field model},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCA method for predicting effective viscosity of particle
reinforced thermoplastic melt and a metric for measuring clusters.
<em>CMAME</em>, <em>439</em>, 117899. (<a
href="https://doi.org/10.1016/j.cma.2025.117899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective viscosity of particle reinforced thermoplastic melt shows strongly anisotropic behavior and is also shear rate-dependent. The traditional homogenization method may face challenge due to extremely expensive computational cost, when the non-linear effective viscosities on all the directions of Particle Reinforced Thermoplastics (PRT) are demanded. This paper approaches this challenge with the FEM-Cluster based reduced order Analysis (FCA) method [1]. The governing equations are solved by minimizing a cluster-based dual formulation of the dissipating energy, where the cluster-wise Admissible Shear Stress (ASS) set is obtained by FCA together with a Spectrum Analysis Algorithm (SAA). In addition, considering the fact that there is a lack of effective method for determining the proper number of clusters, a cluster metric is developed, which relates the given number of clusters and the prediction accuracy of FCA method. This metric can be easily used in the offline stage to pre-estimate the applicability of the obtained clusters on the given loading conditions with a small amount of additional computation.},
  archive      = {J_CMAME},
  author       = {Zheng Li and Yinghao Nie and Gengdong Cheng},
  doi          = {10.1016/j.cma.2025.117899},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117899},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {FCA method for predicting effective viscosity of particle reinforced thermoplastic melt and a metric for measuring clusters},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A coupled immersed boundary method and isogeometric shell
analysis for fluid–structure interaction of flexible and lightweight
shells in high-reynolds number flows. <em>CMAME</em>, <em>439</em>,
117898. (<a href="https://doi.org/10.1016/j.cma.2025.117898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an efficient numerical framework for simulating fluid–structure interactions (FSIs) involving flexible, lightweight shells subjected to high-Reynolds-number flows. By combining the immersed boundary method (IBM) and isogeometric analysis (IGA), the framework incorporates three major innovations: (1) a wall-modeling, direct-forcing, diffused-interface IBM tailored for FSI simulations with high-Reynolds-number turbulent flows, employing non-equilibrium explicit wall functions; (2) integration of the interface quasi-Newton inverse least-squares (IQN-ILS) method into the IBM/IGA framework to enhance the accuracy and efficiency of iterative Gauss–Seidel coupling in strongly coupled FSI scenarios; and (3) high-order solvers for both fluid and structural domains, featuring a sixth-order compact finite difference method (FDM) for fluid dynamics and isogeometric shell formulations for structural analysis. The framework is validated through four numerical test cases, including simulations of a hinged flag, an inverted flag, a membrane airfoil, and an air-supported membrane structure. The results demonstrate good agreement with reference data, showing the framework’s efficiency, accuracy, and applicability for solving large-scale shell-related FSI problems across diverse engineering and scientific domains.},
  archive      = {J_CMAME},
  author       = {Keye Yan and Yue Wu and Qiming Zhu and Boo Cheong Khoo},
  doi          = {10.1016/j.cma.2025.117898},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117898},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A coupled immersed boundary method and isogeometric shell analysis for fluid–structure interaction of flexible and lightweight shells in high-reynolds number flows},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient flow based phase-field modeling using separable
neural networks. <em>CMAME</em>, <em>439</em>, 117897. (<a
href="https://doi.org/10.1016/j.cma.2025.117897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Allen–Cahn equation is a reaction–diffusion equation and is widely used for modeling phase separation. Machine learning methods for solving the Allen–Cahn equation in its strong form suffer from inaccuracies in collocation techniques, errors in computing higher-order spatial derivatives, and the large system size required by the space–time approach. To overcome these challenges, we propose solving the L 2 gradient flow of the Ginzburg–Landau free energy functional, which is equivalent to the Allen–Cahn equation, thereby avoiding the second-order spatial derivatives associated with the Allen–Cahn equation. A minimizing movement scheme is employed to solve the gradient flow problem, eliminating the complexities of a space–time approach. We utilize a separable neural network that efficiently represents the phase field through low-rank tensor decomposition. As we use the minimizing movement scheme to numerically solve the gradient flow problem, we thus, refer to the proposed method as the Separable Deep Minimizing Movement (SDMM) method. The evaluation of the functional in the minimizing movement scheme using the Gauss quadrature technique bypasses the inaccuracies associated with collocation techniques traditionally used to solve partial differential equations. A hyperbolic tangent transformation is introduced on the phase field prior to the evaluation of the functional to ensure that it remains strictly bounded within the values of the two phases. For this transformation, theoretical guarantee for energy stability of the minimizing movement scheme is established. Our results suggest that this transformation helps to improve the accuracy and efficiency significantly. The proposed method resolves the challenges faced by state-of-the-art machine learning techniques, outperforming them in both accuracy and efficiency. It is also the first machine learning method to achieve an order of magnitude speed improvement over the finite element method. In addition to its formulation and computational implementation, several case studies illustrate the applicability of the proposed method. 1},
  archive      = {J_CMAME},
  author       = {Revanth Mattey and Susanta Ghosh},
  doi          = {10.1016/j.cma.2025.117897},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117897},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Gradient flow based phase-field modeling using separable neural networks},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path-following strategy with consistent jacobian for
periodic solutions in multi-DOF nonlinear dynamic systems.
<em>CMAME</em>, <em>439</em>, 117896. (<a
href="https://doi.org/10.1016/j.cma.2025.117896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an enhanced pseudo-arclength path-following technique for recovering periodic solutions in high-dimensional nonlinear dynamic systems using the Poincaré map method. The key innovation is the direct computation of the Jacobian matrix within the time-marching algorithm used to obtain periodic orbits, including both the monodromy matrix and derivatives with respect to the continuation parameter. For smooth problems, the resulting Jacobian matrix is algorithmically exact: while the equations of motion are approximated using a user-selected time-integration scheme, the differentiation of the computed solution is performed exactly. This approach eliminates the need for numerical differentiation, significantly improving both the efficiency and robustness of the path-following process. Although the theoretical framework assumes differentiability, the method effectively handles piecewise smooth problems as well. Numerical tests demonstrate the superior performance of the proposed approach compared to traditional techniques that rely on numerical differentiation. To further validate its effectiveness and versatility, we present numerical examples involving the Finite Element discretization of three-dimensional problems, including shell structures.},
  archive      = {J_CMAME},
  author       = {Domenico Magisano and Giovanni Formica},
  doi          = {10.1016/j.cma.2025.117896},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117896},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Path-following strategy with consistent jacobian for periodic solutions in multi-DOF nonlinear dynamic systems},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multi-patch isogeometric analysis for heat transfer
in three-dimensional solid. <em>CMAME</em>, <em>439</em>, 117895. (<a
href="https://doi.org/10.1016/j.cma.2025.117895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an adaptive multi-patch isogeometric framework for modeling heat conduction in isotropic/orthotropic media. The proposed adaptive scheme is a novel combination of local mesh refinement and adaptive time-stepping to improve the calculation efficiency and reduce meshing burden. The local adaptive refinement is driven by a recovery-based error estimator. Truncated hierarchical NURBS (TH-NURBS) are utilized for local adaptive mesh refinement due to their excellent properties, such as linear independence, partition-of-unity, and exact description of complex geometry. Multi-patch technique is applied to model complex structures, with Nitsche’s method as the coupling strategy. The computational accuracy of the proposed model is verified through several 3D numerical examples. The high efficiency of the adaptive scheme is demonstrated by comparing with uniform refinement method and fixed time-stepping method separately.},
  archive      = {J_CMAME},
  author       = {Lin Wang and Tiantang Yu and Sundararajan Natarajan and Weihua Fang and Zhiwei Zhou},
  doi          = {10.1016/j.cma.2025.117895},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117895},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Adaptive multi-patch isogeometric analysis for heat transfer in three-dimensional solid},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Region-optimal gaussian process surrogate model via
dirichlet process for cold-flow and combustion emulations.
<em>CMAME</em>, <em>439</em>, 117894. (<a
href="https://doi.org/10.1016/j.cma.2025.117894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate modeling plays an increasingly important role in engineering design. The present work develops a novel surrogate model, region-optimal Gaussian process (roGP), to accurately emulate cold-flow and combustion fields in a significantly short time period. The model leverages an advanced statistical approach, Dirichlet process (DP) mixture model, to partition the entire spatial domain of concern into discrete subregions in a physics-informed manner. Each subregion contains the common features embedded in the collected dataset and is modeled by a Gaussian process (GP) with shared hyperparameters. Additionally, an active learning strategy iteratively refines the training dataset by prioritizing high-uncertainty regions, further enhancing predictive accuracy. The roGP model is evaluated on three representative cases of increasing complexity, consistently outperforming conventional GP-based surrogates. Results show that roGP effectively mitigates overfitting in independent GP models and reduces information loss in proper-orthogonal-decomposition GP models. In all test cases, roGP achieves superior spatial prediction accuracy, with relative root mean square errors below 5.5 %. A unique characteristic of the roGP model is that the DP-optimized subregions of roGP connect physics-alike coordinates among sampling design points. The entire pressure field in cold-flow case is effectively described by five subregions, while physical fields in two combustion cases require the elevated number of subregions due to their increased complexity. roGP achieves substantial acceleration in prediction time, up to eight orders of magnitude faster than numerical simulations. The developed surrogate model can be implemented to emulate a range of high-dimensional engineering applications with high accuracy and efficiency.},
  archive      = {J_CMAME},
  author       = {Mingshuo Zhou and Ruiye Zuo and Chih-Li Sung and Yanjie Tong and Xingjian Wang},
  doi          = {10.1016/j.cma.2025.117894},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117894},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Region-optimal gaussian process surrogate model via dirichlet process for cold-flow and combustion emulations},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicit dual-mesh virtual element method for 2D nonlinear
dynamic problems. <em>CMAME</em>, <em>439</em>, 117893. (<a
href="https://doi.org/10.1016/j.cma.2025.117893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel explicit Dual-Mesh virtual element method (DM-VEM) for two dimensional nonlinear dynamic problems is proposed. The DM-VEM employs an Eulerian background grid to solve the momentum equation of the virtual element method (VEM), which significantly improves the spatial stability and the temporal stability of the VEM. An explicit critical time step formula is first developed for one dimensional problems and then extended to two dimensional problems, which takes the effect of vertex position and neighboring cell interaction into consideration. An efficient Lagrangian multiplier contact method based on the background grid is also proposed to deal with contact phenomena. Several numerical examples are studied to verify the proposed explicit DM-VEM in nonlinear dynamic problems.},
  archive      = {J_CMAME},
  author       = {Ruopu Zhou and Zhixin Zeng and Xiong Zhang},
  doi          = {10.1016/j.cma.2025.117893},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117893},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Explicit dual-mesh virtual element method for 2D nonlinear dynamic problems},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A coupled thermo-chemo-mechanical peridynamic model for
predicting process-induced residual stress in fiber-reinforced polymer
composites. <em>CMAME</em>, <em>439</em>, 117891. (<a
href="https://doi.org/10.1016/j.cma.2025.117891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fiber reinforced polymer (FRP) composites have extensive applications in aerospace, automobile, marine and sports industries, however, the process-induced residual stress developed during the cure process can lead to microcracks and weaken the macroscopic mechanical performance. In this work, we developed a multiscale PD framework for modeling thermo-chemo-mechanical behaviors of FRP composites for the first time. The whole cure process is modeled by a macroscale thermo-chemical coupling behavior of the FRP specimen followed by a microscale thermo-chemo-mechanical coupling process of the representative volume element (RVE) taken from the macro specimen. After the multiscale cure modeling, the resulted residual stress distribution is maintained when applying the mechanical loading. The proposed PD framework was validated by examining the temperature and degree of cure histories and the stress-strain curves against experimental data. The effects of periodic boundary condition (PBC) treatments, fiber content, fiber distribution and chemical shrinkage are explored. Cure-induced residual stress can amplify the local stress concentration and damage in the fiber‒matrix interfaces. Results show that PBC treatments have negligible influence on the final damage distribution while the fiber content and distribution can pose huge impact on the strain and stress history of the RVE. In addition, chemical shrinkage can complicate the stress state and impact the mechanical response of composites. This model can serve as a potential tool for predicting the process-induced residual stress and damage and contributes to improved composites designs.},
  archive      = {J_CMAME},
  author       = {Weikang Sun and Jiaxiang Liew and Zhifei Tan and Yang Zhang and Binbin Yin},
  doi          = {10.1016/j.cma.2025.117891},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117891},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A coupled thermo-chemo-mechanical peridynamic model for predicting process-induced residual stress in fiber-reinforced polymer composites},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compatible finite element interpolated neural networks.
<em>CMAME</em>, <em>439</em>, 117889. (<a
href="https://doi.org/10.1016/j.cma.2025.117889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the finite element interpolated neural network (FEINN) framework from partial differential equations (PDEs) with weak solutions in H 1 to PDEs with weak solutions in H ( curl ) or H ( div ) . To this end, we consider interpolation trial spaces that satisfy the de Rham Hilbert subcomplex, providing stable and structure-preserving neural network discretisations for a wide variety of PDEs. This approach, coined compatible FEINNs, has been used to accurately approximate the H ( curl ) inner product. We numerically observe that the trained network outperforms finite element solutions by several orders of magnitude for smooth analytical solutions. Furthermore, to showcase the versatility of the method, we demonstrate that compatible FEINNs achieve high accuracy in solving surface PDEs such as the Darcy equation on a sphere. Additionally, the framework can integrate adaptive mesh refinements to effectively solve problems with localised features. We use an adaptive training strategy to train the network on a sequence of progressively adapted meshes. Finally, we compare compatible FEINNs with the adjoint neural network method for solving inverse problems. We consider a one-loop algorithm that trains the neural networks for unknowns and missing parameters using a loss function that includes PDE residual and data misfit terms. The algorithm is applied to identify space-varying physical parameters for the H ( curl ) model problem from partial, noisy, or boundary observations. We find that compatible FEINNs achieve accuracy and robustness comparable to, if not exceeding, the adjoint method in these scenarios.},
  archive      = {J_CMAME},
  author       = {Santiago Badia and Wei Li and Alberto F. Martín},
  doi          = {10.1016/j.cma.2025.117889},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117889},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Compatible finite element interpolated neural networks},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kolmogorov–arnold PointNet: Deep learning for prediction of
fluid fields on irregular geometries. <em>CMAME</em>, <em>439</em>,
117888. (<a href="https://doi.org/10.1016/j.cma.2025.117888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kolmogorov–Arnold Networks (KANs) have emerged as a promising alternative to traditional Multilayer Perceptrons (MLPs) in deep learning. KANs have already been integrated into various architectures, such as convolutional neural networks, graph neural networks, and transformers, and their potential has been assessed for predicting physical quantities. However, the combination of KANs with point-cloud-based neural networks (e.g., PointNet) for computational physics has not yet been explored. To address this, we present Kolmogorov–Arnold PointNet (KA-PointNet) as a novel supervised deep learning framework for the prediction of incompressible steady-state fluid flow fields in irregular domains, where the predicted fields are a function of the geometry of the domains. In KA-PointNet, we implement shared KANs in the segmentation branch of the PointNet architecture. We utilize Jacobi polynomials to construct shared KANs. As a benchmark test case, we consider incompressible laminar steady-state flow over a cylinder, where the geometry of its cross-section varies over the data set. We investigate the performance of Jacobi polynomials with different degrees as well as special cases of Jacobi polynomials such as Legendre polynomials, Chebyshev polynomials of the first and second kinds, and Gegenbauer polynomials, in terms of the computational cost of training and accuracy of prediction of the test set. Furthermore, we examine the robustness of KA-PointNet in the presence of noisy training data and missing points in the point clouds of the test set. Additionally, we compare the performance of PointNet with shared KANs (i.e., KA-PointNet) and PointNet with shared MLPs. It is observed that when the number of trainable parameters is approximately equal, PointNet with shared KANs (i.e., KA-PointNet) outperforms PointNet with shared MLPs. Moreover, KA-PointNet predicts the pressure and velocity distributions along the surface of cylinders more accurately, resulting in more precise computations of lift and drag.},
  archive      = {J_CMAME},
  author       = {Ali Kashefi},
  doi          = {10.1016/j.cma.2025.117888},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117888},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Kolmogorov–Arnold PointNet: Deep learning for prediction of fluid fields on irregular geometries},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Output probability distribution estimation of stochastic
static and dynamic systems using laplace transform and maximum entropy.
<em>CMAME</em>, <em>439</em>, 117887. (<a
href="https://doi.org/10.1016/j.cma.2025.117887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively estimating output probability distributions in stochastic static and dynamic systems with a limited number of simulations is a significant challenge, especially for complex distributions with multi-modality and heavy tails. To address this challenge, this work explores the potential of the Laplace Transform (LT) and its inversion. First, the statistical information embedded in the derivatives of the LT is analysed, establishing the theoretical foundation for recovering output probability distributions. Subsequently, a novel analytical expression for the response probability density function (PDF) is derived by decomposing its inverse LT (ILT) using Euler’s formula. Building on the numerically estimated LT, a non-parametric numerical solution, termed the Numerical Decomposed ILT (NDILT) algorithm, is developed to flexibly estimate the main body of complex PDFs with limited samples. Second, the Taylor expansion of the real component of LT (RCLT) reveals its rich statistical content. Exploiting this property, another parametric method, the LT-based Maximum Entropy Method (LT-MEM), is proposed, incorporating estimated RCLT as constraints of the maximum entropy principle. By solving an optimization problem, LT-MEM can effectively reconstruct complex PDFs across their entire distribution domain using a small sample size. The proposed methods rediscover and harness the power of the LT and ILT to reconstruct complex-shaped probability distributions, offering a valuable alternative. Parameter selection strategies for NDILT and LT-MEM are provided, and their robust accuracy is validated through analytical and numerical examples across various challenging distributions.},
  archive      = {J_CMAME},
  author       = {Yang Zhang and Chao Dang and Jun Xu and Michael Beer},
  doi          = {10.1016/j.cma.2025.117887},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117887},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Output probability distribution estimation of stochastic static and dynamic systems using laplace transform and maximum entropy},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analytical exact, locking free element formulation for
thin-walled composite timoshenko beams. <em>CMAME</em>, <em>439</em>,
117886. (<a href="https://doi.org/10.1016/j.cma.2025.117886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial truss structures represent a robust, cost-effective, and efficient lightweight design, especially when isotropic materials are substituted with lightweight materials such as composites. During early design phases, truss structures are often subject to optimisations. In order to achieve this in an efficient manner, it is essential to employ a precise yet cost-effective computational model. The most common methodology for the analysis of spatial truss structures employs hinged joints in conjunction with struts that are only subject to tension or compression. However, this approach does not account for the bending and coupling effects inherent to struts manufactured from composite materials. In particular, when employing asymmetric laminates, these effects can no longer be ignored. In order to incorporate these effects, it is common practice to use Finite Element Analysis tools. Particularly for large spatial truss structures comprising struts with slender and thin-walled cross-sections, a large number of solid or shell elements is required, which results in time-consuming simulations. This contribution presents a fully analytical thin-walled composite beam element, applicable to an arbitrarily shaped, closed cross-section. The beam model incorporates two distinct composite material models, namely the Classical Laminate Plate Theory and the First Order Shear Deformation Theory. Moreover, it is capable of simulating asymmetric laminates and modelling the coupling effects within these laminates. Utilising the exact third-order solution of a composite Timoshenko - Ehrenfest beam enables the locking-free representation of an individual strut with a single beam element. In comparison to the conventional shell / solid Finite Element Analysis, this approach results in a substantial reduction in the number of degrees of freedom, by a factor of several orders of magnitude. As a result, the required computational time is significantly reduced. In the case of a single strut, the computational time is reduced by a factor between 160 and 430. For an exemplary truss structure comprising 64 struts, a reduction in computational time of approximately 100 000 times is reached. The numerical comparisons presented in this contribution demonstrate that the model is highly accurate, particularly for tubular and elliptical cross-sections including symmetric and asymmetric laminates.},
  archive      = {J_CMAME},
  author       = {Michael Jäger and Jacqueline Albertsen and Sandro Wartzack},
  doi          = {10.1016/j.cma.2025.117886},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117886},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {An analytical exact, locking free element formulation for thin-walled composite timoshenko beams},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locking and stabilization free hybrid virtual elements for
the coarse mesh analysis of elastic thick plates. <em>CMAME</em>,
<em>439</em>, 117883. (<a
href="https://doi.org/10.1016/j.cma.2025.117883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a Virtual Element formulation (VE) for shear-deformable elastic plates. In particular, the Hybrid Virtual Element Method (HVEM) is adopted, which assumes a self-equilibrated stress interpolation and an energy-based projection, eliminating the need for stabilization terms. This choice, together with a cubic linked interpolation for displacement and rotations, makes the approach free from locking, even for very thin plates and highly distorted element geometries. These features enable the proposed VE to achieve high accuracy even for coarse meshes, yielding low errors when compared to analytical solutions and providing a smooth reconstruction of all the stress field components. Furthermore, low error in both the displacement and stress fields are obtained in the challenging case of single element polygonal discretization. The same performance are guaranteed in presence of bulk loads, thanks to a consistent treatment within the projection operation that a-priori assumes equilibrium for the stress field interpolation. A random-based benchmark is proposed for assessing numerically the absence of spurious modes in concave and convex distorted elements. The proposed HVEM for plate is validated in classical benchmark problems, demonstrating the superior accuracy of polygonal meshes compared to the quadrilateral ones, for an equivalent number of degrees of freedom. This result is relevant in all the applications where polygonal element shapes are necessary. In addition, it opens up the way to new modeling scenarios where polygonal meshes are preferred not only for their versatility but also for their enhanced accuracy.},
  archive      = {J_CMAME},
  author       = {F. Liguori and A. Madeo and S. Marfia and G. Garcea and E. Sacco},
  doi          = {10.1016/j.cma.2025.117883},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117883},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Locking and stabilization free hybrid virtual elements for the coarse mesh analysis of elastic thick plates},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear dynamic substructuring in the frequency domain.
<em>CMAME</em>, <em>439</em>, 117882. (<a
href="https://doi.org/10.1016/j.cma.2025.117882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a nonlinear dynamic substructuring technique to efficiently evaluate nonlinear systems with localized nonlinearities in the frequency domain. A closed-form equation is derived from coupling the dynamics of substructures and nonlinear connections. The method requires the linear frequency response functions of the substructures, which can be calculated independently using reduced-order methods. Increasing the number of linear bases in the reduction method for substructures does not affect the number of nonlinear equations, unlike in component mode synthesis techniques. The performance of the method is evaluated through three case studies: a lumped parameter system with cubic nonlinearity, bars with a small gap (normal contact), and a plate with a couple of nonlinear energy sinks. The results demonstrate promising accuracy with significantly reduced computational cost.},
  archive      = {J_CMAME},
  author       = {Hossein Soleimani and Niels Aage},
  doi          = {10.1016/j.cma.2025.117882},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117882},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Nonlinear dynamic substructuring in the frequency domain},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A clustering-based multiscale topology optimization
framework for efficient design of porous composite structures.
<em>CMAME</em>, <em>439</em>, 117881. (<a
href="https://doi.org/10.1016/j.cma.2025.117881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization design of the microstructures and their macro distribution in porous composite structures (PCS) offers significant potential for achieving both lightweight and functional performance. This paper proposes a novel optimization design framework for PCS with varying densities and multiple microstructures. Initially, components topology optimization (TO-Components) using ordered SIMP interpolation is applied to determine the type and density distribution of void, solid and porous materials. Following this, element stress state analysis calculates the stress-to-density ratio ( s e ) for each porous material element. A two-level k-means++ clustering method, based on s e and density, then replaces the widely used manual partitioning, enabling optimal subregion division for the specified number of microstructure types. This approach identifies representative unit cells (RUCs) for the subsequent topology optimization of RUCs (TO-RUCs). The TO-RUCs process designs the microstructures of each RUC using homogenization theory to minimize strain energy. Three benchmark numerical examples take only 1 to 2 min to complete the full-scale design. Additionally, the scalability of the design for both uniform and variable density PCS is explored. The comparison examples demonstrate that the proposed method reduces optimization time by an order of magnitude while maintaining consistent full-scale compliance, using the same material quantity, compared to existing methods. Finally, additive manufacturing and mechanical testing of the optimized structures confirm the performance benefits.},
  archive      = {J_CMAME},
  author       = {Jinlong Liu and Zhiqiang Zou and Zeyang Li and Min Zhang and Jie Yang and Kang Gao and Zhangming Wu},
  doi          = {10.1016/j.cma.2025.117881},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117881},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A clustering-based multiscale topology optimization framework for efficient design of porous composite structures},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-stabilized virtual element modeling of 2D mixed-mode
cohesive crack propagation in isotropic elastic solids. <em>CMAME</em>,
<em>439</em>, 117880. (<a
href="https://doi.org/10.1016/j.cma.2025.117880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive strategy for the simulation of mixed-mode cohesive crack propagation in a mesh of originally self-stabilized Virtual Elements (VEs) is proposed. Exploiting the VEs substantial insensitivity to mesh distortion, the propagating cohesive crack is accommodated within existing self-stabilized first-order quadrilateral VEs by simply adding new edges separated by a cohesive interface. The added edges make however the VE unstable and a new procedure for the stabilization of initially stable VE is developed. The method is formulated within a recently proposed Hu–Washizu variational framework, allowing for a higher order, independent modeling of stresses. In this way, a more accurate estimate of the stress at the tip of the cohesive process zone can be achieved allowing for a more accurate assessment of crack propagation conditions and direction. The proposed method is validated by application to several benchmark problems.},
  archive      = {J_CMAME},
  author       = {Y. Chen and D. Sun and Q. Li and U. Perego},
  doi          = {10.1016/j.cma.2025.117880},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117880},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Self-stabilized virtual element modeling of 2D mixed-mode cohesive crack propagation in isotropic elastic solids},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On efficient simulation of self-assembling diblock
copolymers using a peridynamic-enhanced fourier spectral method.
<em>CMAME</em>, <em>439</em>, 117878. (<a
href="https://doi.org/10.1016/j.cma.2025.117878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a computational framework for simulating the self-assembly of diblock copolymers using a novel peridynamic (PD)-enhanced Fourier spectral method (FSM). Diblock copolymers, composed of two distinct polymer blocks, are capable of forming nanostructured domains with applications in nanoelectronics, photonics, and advanced membranes. Current simulation techniques face challenges in capturing the multiscale dynamics of polymer systems and are often limited by computational inefficiencies. Our approach combines a phase-field model with FSM for spatial discretization and leverages a PD-based diffusion operator to overcome the stability restrictions of explicit time-stepping schemes. This integration allows for larger time steps, ensuring both stability and computational efficiency. The method’s scalability is enhanced through parallel implementation using C++ and OpenMP, optimized for multi-core CPUs. Validation through phase diagrams of copolymer melts and simulations of evaporation-induced self-assembly (EISA) processes demonstrates the capability of the proposed method to accurately capture large-scale, dynamic morphologies. Our approach provides a versatile framework and was found in certain examples to improve computational efficiency by more than a factor of 6 compared to forward-Euler FSM approach.},
  archive      = {J_CMAME},
  author       = {Farshid Mossaiby and Gregor Häfner and Arman Shojaei and Alexander Hermann and Christian Cyron and Marcus Müller and Stewart Silling},
  doi          = {10.1016/j.cma.2025.117878},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117878},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {On efficient simulation of self-assembling diblock copolymers using a peridynamic-enhanced fourier spectral method},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Similarity equivariant graph neural networks for
homogenization of metamaterials. <em>CMAME</em>, <em>439</em>, 117867.
(<a href="https://doi.org/10.1016/j.cma.2025.117867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft, porous mechanical metamaterials exhibit pattern transformations that may have important applications in soft robotics, sound reduction and biomedicine. To design these innovative materials, it is important to be able to simulate them accurately and quickly, in order to tune their mechanical properties. Since conventional simulations using the finite element method entail a high computational cost, in this article we aim to develop a machine learning-based approach that scales favorably to serve as a surrogate model. To ensure that the model is also able to handle various microstructures, including those not encountered during training, we include the microstructure as part of the network input. Therefore, we introduce a graph neural network that predicts global quantities (energy, stress, stiffness) as well as the pattern transformations that occur (the kinematics) in hyperelastic, two-dimensional, microporous materials. Predicting these pattern transformations means predicting the displacement field. To make our model as accurate and data-efficient as possible, various symmetries are incorporated into the model. The starting point is an E ( n ) -equivariant graph neural network (which respects translation, rotation and reflection) that has periodic boundary conditions (i.e., it is in-/equivariant with respect to the choice of RVE), is scale in-/equivariant, can simulate large deformations, and can predict scalars, vectors as well as second and fourth order tensors (specifically energy, stress and stiffness). The incorporation of scale equivariance makes the model equivariant with respect to the similarities group, of which the Euclidean group E ( n ) is a subgroup. We show that this network is more accurate and data-efficient than graph neural networks with fewer symmetries. To create an efficient graph representation of the finite element discretization, we use only the internal geometrical hole boundaries from the finite element mesh to achieve a better speed-up and scaling with the mesh size.},
  archive      = {J_CMAME},
  author       = {Fleur Hendriks and Vlado Menkovski and Martin Doškář and Marc G.D. Geers and Ondřej Rokoš},
  doi          = {10.1016/j.cma.2025.117867},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117867},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Similarity equivariant graph neural networks for homogenization of metamaterials},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional varying-order NURBS discretization method
for enhanced IGA of large deformation frictional contact problems.
<em>CMAME</em>, <em>439</em>, 117853. (<a
href="https://doi.org/10.1016/j.cma.2025.117853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this contribution, we introduce a varying-order (VO) NURBS discretization method to enhance the performance of the isogeometric analysis (IGA) technique for solving three-dimensional (3D) large deformation frictional contact problems involving two deformable bodies. Building on the promising results obtained from the previous work on the 2D isogeometric contact analysis (Agrawal and Gautam, 2020), this work extends the method’s capability for tri-variate NURBS-based discretization. The proposed method allows for independent, user-defined application of higher-order NURBS functions to discretize the contact surface while employing the minimum order NURBS for the remaining volume of the elastic solid. This flexible strategy enables the possibility to refine a NURBS-constructed solid at a fixed mesh with the controllable order elevation-based approach while preserving the original volume parametrization. The advantages of the method are twofold. First, employing higher-order NURBS for contact integral evaluations considerably enhances the accuracy of the contact responses at a fixed mesh, fully exploiting the advantage of higher-order NURBS specifically for contact computations. Second, the minimum order NURBS for the computations in the remaining bulk volume substantially reduces the computational cost inherently associated with the standard uniform order NURBS-based isogeometric contact analyses. The capabilities of the proposed method are demonstrated using various contact problems between elastic solids with or without considering friction. The results with the standard uniform order of tri-variate NURBS-based discretizations are also included to provide a comprehensive comparative assessment. We show that to attain results of similar accuracy, the varying-order NURBS discretization uses a much coarser mesh resolution than the standard uniform-order NURBS-based discretization, hence leading to a major gain in computational efficiency for isogeometric contact analysis. The convergence study demonstrates the consistent performance of the method for efficient IGA of 3D frictional contact problems. Furthermore, the simplicity of the method facilitates its direct integration into the existing 3D NURBS-based IGA framework with only a few minor modifications.},
  archive      = {J_CMAME},
  author       = {Vishal Agrawal},
  doi          = {10.1016/j.cma.2025.117853},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117853},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Three-dimensional varying-order NURBS discretization method for enhanced IGA of large deformation frictional contact problems},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the capriccio method via one-dimensional systems
for coupled continuum-particle simulations in various uniaxial load
cases using a novel interdimensional comparison approach.
<em>CMAME</em>, <em>439</em>, 117817. (<a
href="https://doi.org/10.1016/j.cma.2025.117817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This contribution investigates sources of insufficiencies observed with the Capriccio method for concurrent continuum-particle coupling using a novel comparison technique. This approach maps the deformation states of three-dimensional (3D) coupled domains into a concise one-dimensional (1D) representation, which allows for a separate evaluation of the domain strains in a unified representation, enabling facile comparisons of the domain states during deformation. For the investigation, we employ both a 1D coupled system resembling the most relevant features of the full 3D Capriccio method as well as a corresponding 3D setup. Our analysis explores interactions between different material models in finite element (FE) and molecular dynamics (MD) domains. Based on various load cases studied in the 1D setup, we identify a resistance of the coupling region to spatial movement as the fundamental cause of strain convergence problems when applying the staggered solution scheme. Using the developed mapping approach, examination of the corresponding 3D setup reveals that these strain inconsistencies are even exacerbated by adverse relaxation effects in viscous MD models, particularly when coupled to a corresponding viscoelastic–viscoplastic FE model, leading to divergence from optimal strain. Our findings confirm that smaller strain increments in combination with larger load step numbers significantly improve strain convergence in all domains. Overall, this indicates the need for detailed sensitivity analysis of coupling parameter influences to reduce the identified motion resistance of the coupling region. Based on promising results in 1D, we further recommend exploring monolithic solving schemes for 3D systems to achieve optimal strain convergence for all types of Capriccio-based coupled particle and continuum material models. Moreover, our systematic approach of system definition and interdimensional comparison may serve as a model to assess other domain-decomposition coupling techniques.},
  archive      = {J_CMAME},
  author       = {Lukas Laubert and Felix Weber and Sebastian Pfaller},
  doi          = {10.1016/j.cma.2025.117817},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117817},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Assessing the capriccio method via one-dimensional systems for coupled continuum-particle simulations in various uniaxial load cases using a novel interdimensional comparison approach},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic particle packing to generate complex geometries.
<em>CMAME</em>, <em>439</em>, 117802. (<a
href="https://doi.org/10.1016/j.cma.2025.117802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the discrete nature of solid structures is crucial, particularly in situations where system behavior relies on material discontinuities, such as fracture and wear, along with their subsequent effects. It is not only essential to investigate when failure or discontinuity occurs within a material, but also how it unfolds and impacts its surroundings. While numerical methods serve as effective tools for analyzing structural behavior, continuum-based approaches may not provide a comprehensive view when dealing with discontinuities in a material. Discrete models provide the capability to simulate these discontinuities by bonding discrete elements (particles) together, thereby also simulating continuum behavior. However, the challenge lies in packing these particles within a complex-shaped structure. The dynamic packing approach excels in generating a tightly packed, randomly arranged bonded-particle structure with consistent mechanical behavior. However, it struggles when it comes to generating complex geometries. Conversely, the geometric approach is proficient at generating complex structures but lacks the reliability needed to simulate engineering materials. The method outlined in this paper represents the first attempt to dynamically pack particles within a complex geometry while maintaining all the necessary mechanical properties to accurately model isotropic engineering materials. Such precision in structure and methodology is vital for calibrating the bonds, ensuring that the bonded-particle structure behaves similarly to real materials. As an example, several bonded-particle structures are generated and tested to demonstrate the complexity of their shapes and their realistic mechanical behavior.},
  archive      = {J_CMAME},
  author       = {Muhammad Sameer and C. Fred Higgs III},
  doi          = {10.1016/j.cma.2025.117802},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117802},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Dynamic particle packing to generate complex geometries},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="comcom---5">COMCOM - 5</h2>
<ul>
<li><details>
<summary>
(2025). LFIoTDI: A lightweight and fine-grained device
identification approach for IoT security enhancement. <em>COMCOM</em>,
<em>237</em>, 108149. (<a
href="https://doi.org/10.1016/j.comcom.2025.108149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of the Internet of Things (IoT) has brought new challenges in device identification. Accurately identifying IoT devices connected to a network is vital for effective resource management, network planning, security threat detection, and handling anomalous traffic. However, existing traffic-based device identification approaches have shortcomings in terms of accuracy, stability, identification granularity, etc. In this study, we introduce LFIoTDI, a lightweight and fine-grained device identification method leveraging machine learning to enhance IoT security. Based on an innovative feature set, LFIoTDI can accomplish device identification on resources-constraint IoT devices with just a single network-layer packet. Additionally, a key feature of LFIoTDI is its use of the Message Queuing Telemetry Transport (MQTT) protocol for real-time updates to the device identification model, greatly enhancing the model’s scalability. Extensive evaluation experiments on the CIC, UNSW, and SMPS datasets demonstrate LFIoTDI’s exceptional performance, achieving accuracies of 99.08%, 98.15%, and 95.28%, respectively, while maintaining minimal system overhead. These results highlight its broad effectiveness in the IoT environment.},
  archive      = {J_COMCOM},
  author       = {Zaiting Xu and Qian Lu and Fei Chen and Hequn Xian},
  doi          = {10.1016/j.comcom.2025.108149},
  journal      = {Computer Communications},
  month        = {5},
  pages        = {108149},
  shortjournal = {Comput. Commun.},
  title        = {LFIoTDI: A lightweight and fine-grained device identification approach for IoT security enhancement},
  volume       = {237},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of attack-defense game for advanced malware
propagation control in cloud. <em>COMCOM</em>, <em>237</em>, 108148. (<a
href="https://doi.org/10.1016/j.comcom.2025.108148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern society, cloud computing has emerged as an indispensable infrastructure. Nevertheless, as the cloud ecosystem grows increasingly vast and complex, a series of novel security challenges have surfaced, among which artificial intelligence (AI)-empowered advanced malware has provided network attackers with even more stealthy and potent weapons. While existing malware detection technologies can still maintain a certain level of defense against traditional security threats, the instant detection and response to these sophisticated AI-crafted threats become exceedingly difficult, consuming substantial remediation time and security resources. To address the balance between control costs and effectiveness, recognizing the intricately intertwined and dynamically interactive nature of the offensive and defensive parties, this paper introduces the framework of differential game theory, delving into the strategies for controlling the propagation of advanced malware in cloud environments. Firstly, we construct an advanced malware propagation control model targeting each virtual machine. On this basis, we define the specific categories of strategy selection for both the offensive and defensive sides, as well as their respective cost-benefit relationships, and formulate an attack-defense game problem. Subsequently, we rigorously demonstrate, from a mathematical theoretical perspective, that the optimal solution (i.e., Nash equilibrium) to the attack-defense game problem is indeed attainable, and we devise a dedicated accelerated algorithm for its solution. Finally, we conduct comparative experiments on three real-world datasets using three distinct strategies, and the analysis results show the effectiveness of our proposed method.},
  archive      = {J_COMCOM},
  author       = {Liang Tian and Chenquan Gan and Jiabin Lin and Fengjun Shang and Qingyi Zhu},
  doi          = {10.1016/j.comcom.2025.108148},
  journal      = {Computer Communications},
  month        = {5},
  pages        = {108148},
  shortjournal = {Comput. Commun.},
  title        = {Analysis of attack-defense game for advanced malware propagation control in cloud},
  volume       = {237},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Introducing and evaluating SWI-FEED: A smart water IoT
framework designed for large-scale contexts. <em>COMCOM</em>,
<em>237</em>, 108146. (<a
href="https://doi.org/10.1016/j.comcom.2025.108146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digitalization of Water Distribution Systems (WDSs) is becoming a key objective in modern society. The increasing complexity of contemporary WDSs, driven by urbanization, fluctuating consumer demand, and limited resources, makes their management particularly challenging, especially in large-scale scenarios. This paper proposes the SWI-FEED framework designed to facilitate the widespread deployment of the Internet of Things (IoT) for enhanced monitoring and optimization of WDSs. The framework aims to investigate the utilization of massive IoT in monitoring and optimizing WDSs in different contexts, with a particular focus on four use cases such as optimal node activation, IoT gateways deployment, distributed leakage detection and water demand disaggregation. SWI-FEED has been tested with predefined network models available in the Open Water Analytics community public repository. Specifically, the four use cases are evaluated using a large network consisting of 4,419 sensor nodes, 3 tanks and 5,066 pipes. Overall, this comprehensive framework provides a holistic approach to address possible challenges of a WDS and optimize the efficiency of large-scale IoT deployments. It reduces the energy consumption of IoT devices within the WDS while enhancing leak detection and localization capabilities in real-world water networks. Our adopted theoretical methodology is based on graph theory, which allows IoT gateways to be strategically positioned to maximize network coverage and minimize infrastructure redundancy. This makes it possible to significantly reduce the number of gateways required and, consequently, the overall system energy consumption.},
  archive      = {J_COMCOM},
  author       = {Antonino Pagano and Domenico Garlisi and Fabrizio Giuliano and Tiziana Cattai and Redemptor Jr Laceda Taloma and Francesca Cuomo},
  doi          = {10.1016/j.comcom.2025.108146},
  journal      = {Computer Communications},
  month        = {5},
  pages        = {108146},
  shortjournal = {Comput. Commun.},
  title        = {Introducing and evaluating SWI-FEED: A smart water IoT framework designed for large-scale contexts},
  volume       = {237},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASAP 2.0: Autonomous &amp; proactive detection of malicious
applications for privacy quantification in 6G network services.
<em>COMCOM</em>, <em>237</em>, 108145. (<a
href="https://doi.org/10.1016/j.comcom.2025.108145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While 6G networks, reliant on software, promise significant advancements, the proliferation of diverse applications deployed closer to users poses considerable privacy challenges. To counter this, privacy-first software development, as advocated by DevPrivOps, becomes essential. While Privacy-Enhancing Technologies (PETs) are frequently used, their limitations are well-documented. DevPrivOps strives to reinforce software privacy through prioritization, compliance, transparency, optimization, and informed decision-making. A promising alternative to PETs involves quantifying privacy to guide development and pinpoint potential threats, thus enhancing application privacy before deployment on OpenSlice network services. Privacy-centric malicious application detection, amongst other features, is a key component of this privacy quantification framework, serving to inform users of potential harm from such applications. In this study, we focus on privacy-centric malicious application detection. ASAP 2.0, an autonomous system, identifies these threats by scrutinizing requested application permissions. Building on its antecedent, ASAP 2.0 employs a tuned autoencoder trained via unsupervised learning. By analyzing reconstruction errors, it differentiates between potentially harmful and benign applications. A dynamically adjusted threshold assists in the decision-making process. Our model, validated on three public datasets, achieved an average Matthews Correlation Coefficient (MCC) of 0.976, outperforming baseline models such as Logistic Regression and Decision Trees.},
  archive      = {J_COMCOM},
  author       = {Catarina Silva and João Felisberto and João Paulo Barraca and Paulo Salvador},
  doi          = {10.1016/j.comcom.2025.108145},
  journal      = {Computer Communications},
  month        = {5},
  pages        = {108145},
  shortjournal = {Comput. Commun.},
  title        = {ASAP 2.0: Autonomous &amp; proactive detection of malicious applications for privacy quantification in 6G network services},
  volume       = {237},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Protecting an entity by hiding its role in anonymity
networks. <em>COMCOM</em>, <em>237</em>, 108109. (<a
href="https://doi.org/10.1016/j.comcom.2025.108109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowing the role of entities in a network undermines anonymity and facilitates the identification of their behavioral patterns. In many existing low-latency anonymity network structures, the creation and use of tunnels for packet transmission allow adversaries to discern the roles of entities. This paper explores the impact of identifying these tunnels, specifically how such identification can expose an entity’s role in relation to a particular message, potentially reducing the level of anonymity in the network. To explore this, we first discuss two key aspects of anonymity networks: the distribution of information and the homogeneity of roles. We then analyze several low-latency anonymity structures to assess vulnerabilities related to tunnel identification, evaluating their strengths and weaknesses based on the aforementioned aspects. In addition, we propose a novel network structure that addresses these vulnerabilities by eliminating the conventional tunnel mechanism, which typically requires a tunnel establishment message. This change prevents adversaries from identifying an entity’s role. In the proposed structure, the sender and intermediate relays work together to select distinct routes for each packet, removing the need for the sender to establish a dedicated data tunnel. To provide a deeper analysis, we will describe in detail the information an attacker can obtain by tracing tunneling messages and how this compromises anonymity by exposing the roles of entities. We will also evaluate how these changes affect the degree of anonymity based on the attacker’s knowledge. Our evaluation shows that the proposed technique effectively eliminates traffic patterns that would normally reveal the roles of entities, thus neutralizing the attacker’s ability to compromise anonymity. As a result, the average level of anonymity is significantly improved compared to previous structures. Overall, our findings suggest that the proposed approach offers a more effective strategy for concealing the roles of entities compared to earlier methods.},
  archive      = {J_COMCOM},
  author       = {Reza Mirzaei and Nasser Yazdani and Mohammad Sayad Haghighi},
  doi          = {10.1016/j.comcom.2025.108109},
  journal      = {Computer Communications},
  month        = {5},
  pages        = {108109},
  shortjournal = {Comput. Commun.},
  title        = {Protecting an entity by hiding its role in anonymity networks},
  volume       = {237},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cor---12">COR - 12</h2>
<ul>
<li><details>
<summary>
(2025). Minimizing the expected cybersecurity loss in a software
supply chain through scheduling scanning jobs. <em>COR</em>,
<em>180</em>, 107064. (<a
href="https://doi.org/10.1016/j.cor.2025.107064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Third-party cybersecurity providers in a software supply chain execute scanning jobs according to business policies and government regulations, tailoring responses to each node’s unique attributes and risks. Traditionally, providers might use various tools at different times without coordination, leading to resource bottlenecks. This study introduces a novel approach to scanning job scheduling, addressing the unique challenge where the marginal benefit of scanning time varies non-linearly, unlike traditional job scheduling problems. The findings reveal that upgrading a scanning strategy by one level can quantify the reduced loss, providing a foundation for efficient resource allocation in large-scale supply chains. A branch-and-bound algorithm is developed to generate the optimal schedules, serving as a benchmark for evaluating other metaheuristic algorithms. Furthermore, this study proposes an innovative genetic algorithm incorporating dynamic crossover or mutation rates, as well as mechanisms to prevent premature convergence and improve performance. This approach demonstrates practical scalability and efficiency in scheduling scanning jobs across 300 nodes, ensuring adaptability to real-world supply chains.},
  archive      = {J_COR},
  author       = {Jen-Ya Wang},
  doi          = {10.1016/j.cor.2025.107064},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107064},
  shortjournal = {Comput. Oper. Res.},
  title        = {Minimizing the expected cybersecurity loss in a software supply chain through scheduling scanning jobs},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Periodic and aperiodic train timetabling and rolling stock
circulation planning using an efficient lagrangian relaxation
decomposition. <em>COR</em>, <em>180</em>, 107062. (<a
href="https://doi.org/10.1016/j.cor.2025.107062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Train timetabling and rolling stock circulation planning are problems of crucial importance for integrated planning. Often, these problems are separately solved in a sequential way without consideration of periodic train schedule. However, a notable drawback of this layered planning process is poor coordination and efficiency between train and rolling stock timetables, as well as lack of regularity. To this end, we explore the joint optimization problem of periodic and aperiodic train timetabling and rolling stock circulation planning in this paper. To address this comprehensive problem, an integer programming model is initially established by incorporating rolling stock circulation into optimizing periodic and aperiodic train timetabling. Due to the model-solving complexity, a three-dimensional space–time-state network is constructed to reformulate this model. Within this three-dimensional network, states are used to represent trains served by rolling stocks. Subsequently, the problem is transformed into a minimum-cost multi-commodity network flow problem with incompatible arcs based on the space–time-state network. And an efficient Lagrangian relaxation decomposition algorithm is proposed to solve this network flow problem. The effectiveness of the algorithm is verified through a series of case studies.},
  archive      = {J_COR},
  author       = {Naijie Chai and Ziyu Chen and Wenliang Zhou},
  doi          = {10.1016/j.cor.2025.107062},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107062},
  shortjournal = {Comput. Oper. Res.},
  title        = {Periodic and aperiodic train timetabling and rolling stock circulation planning using an efficient lagrangian relaxation decomposition},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing blocking and starving delays in sequential zone
order picking systems through time-decomposed workload balancing.
<em>COR</em>, <em>180</em>, 107060. (<a
href="https://doi.org/10.1016/j.cor.2025.107060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential zone order picking systems frequently encounter blocking delays when a tote cannot proceed to the next zone because it is occupied, and starving delays when a tote remains unassigned to a zone. General approaches to minimize delays include balancing the total workload across zones, grouping the orders into batches, or optimizing the order release sequences. However, the issue of temporal workload imbalances caused by instantaneous differences in processing time between zones has not been addressed. Since temporal workload imbalances result in delays, this study proposes the decomposition of workloads into time slots and develops a temporal workload balancing model (TBM) that incorporates batching and sequencing based on time slot decomposition. We also develop an adaptive large neighborhood search (ALNS) heuristic model to tackle large-scale practical problems of temporal workload imbalance. In simulation experiments, we compare the TBM model to alternative batching strategies in an order picking environment featuring consecutive batch windows. Our findings reveal that the TBM model yields an average reduction in makespan of 27.65% and 15.99% compared to random strategy and baseline method. We conclude that temporal workload balancing can minimize blocking and starving delays and maximize order picking productivity.},
  archive      = {J_COR},
  author       = {Jeongwon Park and Soondo Hong},
  doi          = {10.1016/j.cor.2025.107060},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107060},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing blocking and starving delays in sequential zone order picking systems through time-decomposed workload balancing},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel decision support framework for multi-objective
aircraft routing problem. <em>COR</em>, <em>180</em>, 107058. (<a
href="https://doi.org/10.1016/j.cor.2025.107058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aircraft routing problem has received extensive attention from researchers, prompting the utilization of diverse problem-solving approaches and the use of various metrics to inform decision-making. Despite the wealth of research, airline managers often rely heavily on their own experience when evaluating potential aircraft routing solutions. To bridge this gap and empower airline managers with a robust decision-making process, this paper proposes a novel modeling framework and decision support tool for solving the Multi-Objective Aircraft Routing Problem. Our methodological framework comprises 3 modules: (i) an efficient data handling and storage process to manage a large volume of data and ensure data tractability; (ii) a novel mixed-integer linear programming model to effectively solve the aircraft routing problem within 1 to 5 min of computation, even at large instances; (iii) a multi-objective algorithmic framework that effectively employs parallelization techniques to generate Pareto-optimal frontiers within 30 min of computation. The three components are integrated into an unified decision support tool that empowers airline managers to visualize and evaluate various aircraft routing solutions, considering multiple objectives simultaneously while leveraging the use of multi-criteria methods. To validate the proposed approach, historic data from AirAsia is used for testing. The results demonstrate the tool’s capability to generate high-quality solutions that strike a balance between conflicting objectives, affirming its practicality and effectiveness in real-world applications.},
  archive      = {J_COR},
  author       = {Francisco López-Ramos and Francisco Benita and Nuno Antunes Ribeiro},
  doi          = {10.1016/j.cor.2025.107058},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107058},
  shortjournal = {Comput. Oper. Res.},
  title        = {A novel decision support framework for multi-objective aircraft routing problem},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modelling a capacitated location problem for designing
multimodal vaccine distribution network using a novel health emergency
susceptibility index. <em>COR</em>, <em>180</em>, 107056. (<a
href="https://doi.org/10.1016/j.cor.2025.107056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health emergency due to the outbreak of a contagious virus augments the need for effective vaccine distribution strategies to control its spread. This paper suggests a two-phase strategy to solve this problem. Phase I constructs a Health Emergency Susceptibility Index for each region, considering the disease data and comorbidity situation. Phase II uses the HESI and proposes three versions of priority weights for different application scenarios. These are used as the priority weights to formulate a capacitated location problem with a multimodal network and multiple types of refrigerators. The model considers additional factors like storage capacity, locations, transportation distances (including air and ground options), costs (maintenance and transportation), and vehicle capacity. To solve the model for large networks, the paper suggests a solution approach using Benders Decomposition with extreme directions. To validate the models, we examine the case of COVID-19 vaccine distribution in India. To assess the impact of the Susceptibility Index on facility locations, proposed weightage versions are compared with a version that does not use the index. The results show that one of the three versions with weighting schemes based on the population-to-susceptibility ratio leads to the most cost-effective distribution strategy, ensuring coverage of all susceptible regions. Furthermore, the Decomposition-based solution significantly improves computational efficiency, solving the problem over fifty times faster than the commercial solver.},
  archive      = {J_COR},
  author       = {Biswajit Kar and Mamata Jenamani},
  doi          = {10.1016/j.cor.2025.107056},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107056},
  shortjournal = {Comput. Oper. Res.},
  title        = {Modelling a capacitated location problem for designing multimodal vaccine distribution network using a novel health emergency susceptibility index},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A note on “self-adaptive general variable neighborhood
search algorithm for parallel machine scheduling with unrelated
servers.” <em>COR</em>, <em>180</em>, 107055. (<a
href="https://doi.org/10.1016/j.cor.2025.107055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent paper a two-machines two-servers scheduling problem with identical machines but unrelated servers and makespan objective is studied and solved via sophisticated Variable-Neighbourhood Search procedures, for instances up to 120 jobs in size. We show that the same problem can be transformed to a pretty standard problem with unrelated machines that can be efficiently solved to optimality, up to much larger instances.},
  archive      = {J_COR},
  author       = {Andrea Grosso and Fabio Salassa},
  doi          = {10.1016/j.cor.2025.107055},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107055},
  shortjournal = {Comput. Oper. Res.},
  title        = {A note on “Self-adaptive general variable neighborhood search algorithm for parallel machine scheduling with unrelated servers”},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heuristic approach for the critical chain project
scheduling problem based on resource flows. <em>COR</em>, <em>180</em>,
107054. (<a href="https://doi.org/10.1016/j.cor.2025.107054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Critical Chain Project Scheduling Problem (CCPSP) aims to obtain robust baseline schedules by optimizing the size and insertion of buffers for projects with uncertain activity durations. To overcome the challenge of handling new resource conflicts due to insertion of buffers, we develop a novel approach based on resource flow to add additional precedence relationships that resolve resource conflicts. Our priority-rule based heuristic is easy to implement, fast, and effective. A comprehensive computational experiment is conducted to examine the performance of a large set of priority rules and their combinations, which is then estimated using regression analysis with the problem characteristics as independent variables. Our algorithm outperforms the existing benchmark method for the addressed problem in both solution quality and efficiency, and provides project managers an efficient and effective tool to handle large-scale projects under uncertainty.},
  archive      = {J_COR},
  author       = {Wuliang Peng and Ziyan Wang and Fang Xie and Haitao Li},
  doi          = {10.1016/j.cor.2025.107054},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107054},
  shortjournal = {Comput. Oper. Res.},
  title        = {A heuristic approach for the critical chain project scheduling problem based on resource flows},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing strategic and operational decisions of car
sharing systems under demand uncertainty and substitution. <em>COR</em>,
<em>180</em>, 107052. (<a
href="https://doi.org/10.1016/j.cor.2025.107052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Car sharing is an efficient way to improve mobility, reduce the use of personal vehicles, and lessen the associated carbon emissions. Due to increasing environmental awareness of customers and government regulations, car sharing providers must be careful about the composition of their vehicle fleet to meet diverse customer demand through vehicle types with different carbon emission levels. In this study, for a car sharing company, we consider the problems of determining service regions and purchasing decisions with a mixed fleet of vehicles under budget and carbon emission constraints, and the deployment of these vehicles to service regions under uncertain one-way and round-trip rental requests over a multi-period planning horizon. We further introduce the concept of “substitution” to the car sharing operations that provides customers with alternative vehicle options when their preferred type is unavailable. To address this complex problem, we propose a novel two-stage stochastic mixed-integer program leveraging spatial–temporal networks and multicommodity flows to capture these strategic and operational decisions of this system over the planning horizon while allowing substitution in operations. We further prove that the corresponding second-stage problem of the proposed program has a totally unimodular constraint matrix. Taking advantage of this result, we develop a branch-and-cut-based decomposition algorithm with various computational enhancements. We present an extensive computational study that highlights the value of the proposed models from different perspectives and demonstrates the performance of the proposed solution algorithm with significant speedups. Our case study provides insights for region opening and fleet allocation plans under demand uncertainty and demonstrates the value of introducing substitution to car sharing operations and the importance of integrating strategic and operational decisions and obtaining stochastic solutions.},
  archive      = {J_COR},
  author       = {Beste Basciftci and Esra Koca and Sinan Emre Kosunda},
  doi          = {10.1016/j.cor.2025.107052},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107052},
  shortjournal = {Comput. Oper. Res.},
  title        = {Optimizing strategic and operational decisions of car sharing systems under demand uncertainty and substitution},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A distributionally robust optimisation with joint chance
constraints approach for location-routing problem in urban search and
rescue operations. <em>COR</em>, <em>180</em>, 107051. (<a
href="https://doi.org/10.1016/j.cor.2025.107051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines a multi-period location-routing problem with uncertain demand and travel times in the context of disaster management. We propose an optimisation model that integrates strategic location decisions with multi-period routing decisions to navigate search-and-rescue teams in the aftermath of a disaster within an uncertain environment. To model this problem, we apply a distributionally robust optimisation approach with joint chance constraints. We enhance computational tractability by reformulating the problem using Bonferroni’s inequality and approximating the chance constraints. The proposed methodology is evaluated in a hypothetical case study of Santa Cruz County, California, USA, a region highly susceptible to earthquakes. We tested multiple instances of this case study to demonstrate the effectiveness of the proposed method compared to the sample average approximation approach. Numerical experiments reveal that the methodology developed in this paper aids decision-makers in strategically locating facilities to deploy search-and-rescue teams and efficiently directing them towards affected sites, achieving a maximal rescue rate.},
  archive      = {J_COR},
  author       = {Kamran Sarmadi and Mehdi Amiri-Aref},
  doi          = {10.1016/j.cor.2025.107051},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107051},
  shortjournal = {Comput. Oper. Res.},
  title        = {A distributionally robust optimisation with joint chance constraints approach for location-routing problem in urban search and rescue operations},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A causal framework for stochastic local search optimization
algorithms. <em>COR</em>, <em>180</em>, 107050. (<a
href="https://doi.org/10.1016/j.cor.2025.107050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the multitude of optimization algorithms available in the literature and the various approaches that study them, understanding the behaviour of an optimization algorithm and explaining its results are fundamental open questions in artificial intelligence and operations research. We argue that the body of available literature is already very rich, and the main obstacle to advancements towards answering those questions is its fragmentation. In this work, we focus on stochastic local search algorithms, a broad class of methods to compute good quality suboptimal solutions in a short time. We propose a causal framework that relates the entities involved in the solution of an optimization problem. We demonstrate how this conceptual framework can be used to relate many approaches aimed at understanding how stochastic local search algorithms work, and how it can be utilized to address open problems, both theoretical and practical.},
  archive      = {J_COR},
  author       = {Alberto Franzin and Thomas Stützle},
  doi          = {10.1016/j.cor.2025.107050},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107050},
  shortjournal = {Comput. Oper. Res.},
  title        = {A causal framework for stochastic local search optimization algorithms},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A supervised learning approach to rankability. <em>COR</em>,
<em>180</em>, 107049. (<a
href="https://doi.org/10.1016/j.cor.2025.107049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rankability of data is a novel problem that considers the ability of a dataset, represented as a graph, to produce a meaningful ranking of the items it contains. To study this concept, a number of rankability measures have been proposed, based on comparisons to a complete dominance graph via combinatorial and linear algebraic methods. Interest in this field has been steadily expanding, with a growing appreciation for the significance of evaluating rankability across diverse applications. Consequently, the validation of these rankability methodologies in different scenarios holds paramount importance. In this paper, we review existing measures of rankability and highlight some questions to which they give rise. We go on to introduce a new framework designed to evaluate rankability with a tailored approach, one that allows for efficient estimation in specific problem domains. Finally, we present a comparative analysis of these metrics by applying them to both synthetic and real-life sports data.},
  archive      = {J_COR},
  author       = {Nathan McJames and David Malone and Oliver Mason},
  doi          = {10.1016/j.cor.2025.107049},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107049},
  shortjournal = {Comput. Oper. Res.},
  title        = {A supervised learning approach to rankability},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interval two-stage robust stochastic programming under a
bi-level multi-objective framework toward river basin water resources
allocation. <em>COR</em>, <em>180</em>, 107045. (<a
href="https://doi.org/10.1016/j.cor.2025.107045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertainty stemming from hydrological variables and socio-economic parameters poses new challenges to river basin water resources allocation (RBWRA). Given the pressing need for efficient, environmentally friendly, and equitable solutions in RBWRA, a bi-level multi-objective interval two-stage robust stochastic programming (BLMOITRSP) model is proposed. This model aims to achieve the optimal balance among efficiency, eco-friendliness, and equity, collectively called the “3E”. A novel hierarchical mixed water allocation mechanism is introduced within this model. The basin authority pursues the “3E” objectives at the macro-control level through administrative water allocation. Conversely, sub-areas as followers prioritize economic interests, striving for economic benefit maximization through water market allocation. Furthermore, uncertain parameters (e.g., water demand) are treated as interval parameters, employing interval two-stage robust stochastic programming (ITRSP) to address uncertainty issues and control systemic risks in the model. To solve the BLMOITRSP model, we present a bi-level interactive global equilibrium optimization algorithm, fusing with the modified particle swarm optimization (PSO) algorithm. The bi-level algorithm provides solutions tailored to the preferences of different decision-makers. The proposed model and method are also applied to the Hanjiang River Basin in China to demonstrate its feasibility and effectiveness. The results indicate that the proposed model effectively ensures the “3E” balance. The introduction of the hierarchical mixed water allocation mechanism proves conducive to promoting water distribution and enhancing economic benefits. ITRSP effectively controls the systemic risks of the model’s impact on the basin’s total economic benefit. The economic performance of each sub-area varies in response to different decision preferences under RBWRA schemes. Finally, the conclusions and future research directions are provided.},
  archive      = {J_COR},
  author       = {Yan Tu and Yongzheng Lu and Benjamin Lev},
  doi          = {10.1016/j.cor.2025.107045},
  journal      = {Computers &amp; Operations Research},
  month        = {8},
  pages        = {107045},
  shortjournal = {Comput. Oper. Res.},
  title        = {An interval two-stage robust stochastic programming under a bi-level multi-objective framework toward river basin water resources allocation},
  volume       = {180},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="csda---7">CSDA - 7</h2>
<ul>
<li><details>
<summary>
(2025). A multiple imputation approach for flexible modelling of
interval-censored data with missing and censored covariates.
<em>CSDA</em>, <em>209</em>, 108177. (<a
href="https://doi.org/10.1016/j.csda.2025.108177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses regression analysis of interval-censored failure time data that commonly occur in biomedical studies among others. For the situation, the failure event of interest is known only to occur within an interval instead of being observed exactly. In addition to interval censoring on the failure time of interest, sometimes covariates may be missing or suffer censoring, which can bring extra theoretical and computational challenges for the regression analysis. To deal with such data, we propose a novel multiple imputation approach with the use of the rejection sampling under a class of semiparametric transformation models. The proposed method is flexible and can lead to more efficient estimation than the existing methods, and the resulting estimators are shown to be consistent and asymptotically normal. An extensive simulation study is conducted and demonstrates that the proposed approach works well in practice. Finally, we apply the proposed approach to a set of real data on Alzheimer&#39;s disease that motivated this study.},
  archive      = {J_CSDA},
  author       = {Yichen Lou and Yuqing Ma and Liming Xiang and Jianguo Sun},
  doi          = {10.1016/j.csda.2025.108177},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {9},
  pages        = {108177},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {A multiple imputation approach for flexible modelling of interval-censored data with missing and censored covariates},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear covariance selection model via ℓ1-penalization.
<em>CSDA</em>, <em>209</em>, 108176. (<a
href="https://doi.org/10.1016/j.csda.2025.108176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a study on an ℓ 1 -penalized covariance regression method. Conventional approaches in high-dimensional covariance estimation often lack the flexibility to integrate external information. As a remedy, we adopt the regression-based covariance modeling framework and introduce a linear covariance selection model (LCSM) to encompass a broader spectrum of covariance structures when covariate information is available. Unlike existing methods, we do not assume that the true covariance matrix can be exactly represented by a linear combination of known basis matrices. Instead, we adopt additional basis matrices for a portion of the covariance patterns not captured by the given bases. To estimate high-dimensional regression coefficients, we exploit the sparsity-inducing ℓ 1 -penalization scheme. Our theoretical analyses are based on the (symmetric) matrix regression model with additive random error matrix, which allows us to establish new non-asymptotic convergence rates of the proposed covariance estimator. The proposed method is implemented with the coordinate descent algorithm. We conduct empirical evaluation on simulated data to complement theoretical findings and underscore the efficacy of our approach. To show a practical applicability of our method, we further apply it to the co-expression analysis of liver gene expression data where the given basis corresponds to the adjacency matrix of the co-expression network.},
  archive      = {J_CSDA},
  author       = {Kwan-Young Bak and Seongoh Park},
  doi          = {10.1016/j.csda.2025.108176},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {9},
  pages        = {108176},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Linear covariance selection model via ℓ1-penalization},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selecting time-series hyperparameters with the artificial
jackknife. <em>CSDA</em>, <em>209</em>, 108173. (<a
href="https://doi.org/10.1016/j.csda.2025.108173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A generalisation of the delete- d jackknife is proposed for solving hyperparameter selection problems in time series. The method is referred to as the artificial delete- d jackknife, emphasizing that it replaces the classic removal step with a fictitious deletion, wherein observed data points are replaced with artificial missing values. This procedure preserves the data order, ensuring seamless compatibility with time series. The approach is asymptotically justified and its finite-sample properties are studied via simulations. In addition, an application based on foreign exchange rates illustrates its practical relevance.},
  archive      = {J_CSDA},
  author       = {Filippo Pellegrino},
  doi          = {10.1016/j.csda.2025.108173},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {9},
  pages        = {108173},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Selecting time-series hyperparameters with the artificial jackknife},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based edge clustering for weighted networks with a
noise component. <em>CSDA</em>, <em>209</em>, 108172. (<a
href="https://doi.org/10.1016/j.csda.2025.108172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a fundamental task in network analysis, essential for uncovering hidden structures within complex systems. Edge clustering, which focuses on relationships between nodes rather than the nodes themselves, has gained increased attention in recent years. However, existing edge clustering algorithms often overlook the significance of edge weights, which can represent the strength or capacity of connections, and fail to account for noisy edges—connections that obscure the true structure of the network. To address these challenges, the Weighted Edge Clustering Adjusting for Noise (WECAN) model is introduced. This novel algorithm integrates edge weights into the clustering process and includes a noise component that filters out spurious edges. WECAN offers a data-driven approach to distinguishing between meaningful and noisy edges, avoiding the arbitrary thresholding commonly used in network analysis. Its effectiveness is demonstrated through simulation studies and applications to real-world datasets, showing significant improvements over traditional clustering methods. Additionally, the R package “WECAN” 1 has been developed to facilitate its practical implementation.},
  archive      = {J_CSDA},
  author       = {Haomin Li and Daniel K. Sewell},
  doi          = {10.1016/j.csda.2025.108172},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {9},
  pages        = {108172},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Model-based edge clustering for weighted networks with a noise component},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hidden semi-markov models with inhomogeneous state
dwell-time distributions. <em>CSDA</em>, <em>209</em>, 108171. (<a
href="https://doi.org/10.1016/j.csda.2025.108171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The well-established methodology for the estimation of hidden semi-Markov models (HSMMs) as hidden Markov models (HMMs) with extended state spaces is further developed. Covariate influences are incorporated across all aspects of the state process model, in particular regarding the distributions governing the state dwell time. The special case of periodically varying covariate effects on the state dwell-time distributions — and possibly the conditional transition probabilities — is examined in detail. Important properties of these models are derived, including the periodically varying unconditional state distribution as well as the overall state dwell-time distribution. Simulation studies are conducted to assess key properties of these models and provide recommendations for hyperparameter settings. A case study involving an HSMM with periodically varying dwell-time distributions is presented to analyse the movement trajectory of an Arctic muskox, demonstrating the practical relevance of the developed methodology.},
  archive      = {J_CSDA},
  author       = {Jan-Ole Koslik},
  doi          = {10.1016/j.csda.2025.108171},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {9},
  pages        = {108171},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Hidden semi-markov models with inhomogeneous state dwell-time distributions},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional nonlinear principal component analysis.
<em>CSDA</em>, <em>209</em>, 108169. (<a
href="https://doi.org/10.1016/j.csda.2025.108169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widely adopted dimension reduction technique, functional principal component analysis (FPCA), typically represents functional data as a linear combination of functional principal components (FPCs) and their corresponding scores. However, this linear formulation is too restrictive to reflect reality because it fails to capture the nonlinear dependence of functional data when nonlinear features are present in the data. This study develops a novel FPCA model to uncover the nonlinear structures of functional data. The proposed method can accommodate multivariate functional data observed on different domains, and multidimensional functional data with gaps and holes. To navigate the complexities of spatial structure in multidimensional functional variables, tensor product smoothing and spline smoothing over triangulation are employed, providing precise tools for approximating nonparametric function. Furthermore, an efficient estimation approach and theory are developed when the number of FPCs diverges to infinity. To assess its performance comprehensively, extensive simulations are conducted, and the proposed method is applied to real data from the Alzheimer&#39;s Disease Neuroimaging Initiative study, affirming its practical efficacy in uncovering and interpreting nonlinear structures inherent in functional data.},
  archive      = {J_CSDA},
  author       = {Qingzhi Zhong and Xinyuan Song},
  doi          = {10.1016/j.csda.2025.108169},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {9},
  pages        = {108169},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Functional nonlinear principal component analysis},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Manifold-valued models for analysis of EEG time series data.
<em>CSDA</em>, <em>209</em>, 108168. (<a
href="https://doi.org/10.1016/j.csda.2025.108168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {EEG (electroencephalogram) records brain electrical activity and is a vital clinical tool in the diagnosis and treatment of epilepsy. Time series of covariance matrices between EEG channels for patients suffering from epilepsy, obtained from an open-source dataset, are analysed. The aim is two-fold: to develop a model with interpretable parameters for different possible modes of EEG dynamics, and to explore the extent to which modelling results are affected by the choice of geometry imposed on the space of covariance matrices. The space of full-rank covariance matrices of fixed dimension forms a smooth manifold, and any statistical analysis inherently depends on the choice of metric or Riemannian structure on this manifold. The model specifies a distribution for the tangent direction vector at any time point, combining an autoregressive term, a mean reverting term and a form of Gaussian noise. Parameter inference is performed by maximum likelihood estimation, and we compare modelling results obtained using the standard Euclidean geometry and the affine invariant geometry on covariance matrices. The findings reveal distinct dynamics between epileptic seizures and interictal periods (between seizures), with interictal series characterized by strong mean reversion and absence of autoregression, while seizures exhibit significant autoregressive components with weaker mean reversion. The fitted models are also used to measure seizure dissimilarity within and between patients.},
  archive      = {J_CSDA},
  author       = {Tao Ding and Tom M.W. Nye and Yujiang Wang},
  doi          = {10.1016/j.csda.2025.108168},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {9},
  pages        = {108168},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Manifold-valued models for analysis of EEG time series data},
  volume       = {209},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cviu---1">CVIU - 1</h2>
<ul>
<li><details>
<summary>
(2025). Uncertainty estimation using boundary prediction for medical
image super-resolution. <em>CVIU</em>, <em>256</em>, 104349. (<a
href="https://doi.org/10.1016/j.cviu.2025.104349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image super-resolution can be performed by several deep learning frameworks. However, as the safety of each patient is of primary concern, having models with a high degree of population level accuracy is not enough. Instead of a one size fits all approach, there is a need to measure the reliability and trustworthiness of such models from the point of view of personalized healthcare and precision medicine. Hence, in this paper, we propose a novel approach to predict a range of super-resolved (SR) images that any generative super-resolution model may yield for a given low-resolution (LR) image using residual image prediction. Providing multiple images within the suggested lower and upper bound increases the probability of finding an exact match to the high-resolution (HR) image. To further compare models and provide reliability scores, we estimate the coverage and uncertainty of the models and check if coverage can be improved at the cost of increasing uncertainty. Experimental results on lung CT scans from LIDC-IDRI and Radiopedia COVID-19 CT Images Segmentation datasets show that our models, BliMSR and MoMSGAN, provide the best HR and SR coverage at different levels of residual attention with a comparatively lower uncertainty. We believe our model agnostic approach to uncertainty estimation for generative medical imaging is the first of its kind and would help clinicians decide on the trustworthiness of any super-resolution model in a generalized manner while providing alternate SR images with enhanced details for better diagnosis for each individual patient.},
  archive      = {J_CVIU},
  author       = {Samiran Dey and Partha Basuchowdhuri and Debasis Mitra and Robin Augustine and Sanjoy Kumar Saha and Tapabrata Chakraborti},
  doi          = {10.1016/j.cviu.2025.104349},
  journal      = {Computer Vision and Image Understanding},
  month        = {5},
  pages        = {104349},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Uncertainty estimation using boundary prediction for medical image super-resolution},
  volume       = {256},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="dke---6">DKE - 6</h2>
<ul>
<li><details>
<summary>
(2025). Fake news detection algorithms – a systematic literature
review. <em>DKE</em>, <em>158</em>, 102441. (<a
href="https://doi.org/10.1016/j.datak.2025.102441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media and news platforms make available to their users, in real-time and simultaneously, access to a significant amount of content that may be true or false. It is remarkable that, with the evolution of Industry 4.0 technologies, the production and dissemination of fake news also increased in recent years. Some content quickly reaches considerable popularity because it is accessed and shared on a large scale, especially in social networks, thus having a potential for going viral. Thus, this study aimed to identify the algorithms and software used for fake news detection. The choice for this combination is justified because in Brazil this process is carried out manually by verification agencies and thus, based on the mapping of the algorithms identified in the literature, an architecture proposal will be developed using artificial intelligence. As a methodology, a systematic literature review (SLR) was conducted in the Science Direct and Scopus databases using the keywords &quot;fake news&quot; and &quot;machine learning&quot; to locate reviews and research articles published in Engineering fields from 2018 to 2023. A total of 24 articles were analyzed, and the results pointed out that Facebook and X 1 were the social networks most used to disseminate fake news. Moreover, the main topics addressed were the COVID-19 pandemic and the United States presidential elections of 2016 and 2020. As for the most used algorithms, a predominance of neural networks was observed. The contribution of this study is in mapping the most used algorithms and their degree of assertiveness, as well as identifying the themes, countries and related researchers that help in the evolution of the fake news theme.},
  archive      = {J_DKE},
  author       = {Ana Julia Dal Forno and Graziela Piccoli Richetti and Vinícius Heinz Knaesel},
  doi          = {10.1016/j.datak.2025.102441},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {7},
  pages        = {102441},
  shortjournal = {Data Knowl. Eng.},
  title        = {Fake news detection algorithms – a systematic literature review},
  volume       = {158},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modelling process durations with gamma mixtures for
right-censored data: Applications in customer clustering, pattern
recognition, drift detection, and rationalisation. <em>DKE</em>,
<em>158</em>, 102430. (<a
href="https://doi.org/10.1016/j.datak.2025.102430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customer modelling, particularly concerning length of stay or process duration, is vital for identifying customer patterns and optimising business processes. Recent advancements in computing and database technologies have revolutionised statistics and business process analytics by producing heterogeneous data that reflects diverse customer behaviours. Different models should be employed for distinct customer categories, culminating in an overall mixture model. Furthermore, some customers may remain “alive” at the conclusion of the observation period, meaning their journeys are incomplete, resulting in right-censored (RC) duration data. This combination of heterogeneous and right-censored data introduces complexity to process duration modelling and analysis. This paper presents a general approach to modelling process duration data using a gamma mixture model, where each gamma distribution represents a specific customer pattern. The model is adapted to account for RC data by modifying the likelihood function during model fitting. The paper explores three key application scenarios: (1) offline pattern clustering, which categorises customers who have completed their journeys; (2) online pattern tracking, which monitors and predicts customer behaviours in real-time; and (3) concept drift detection and rationalisation, which identifies shifts in customer patterns and explains their underlying causes. The proposed method has been validated using synthetically generated data and real-world data from a hospital billing process. In all instances, the fitted models effectively represented the data and demonstrated strong performance across the three application scenarios.},
  archive      = {J_DKE},
  author       = {Lingkai Yang and Sally McClean and Kevin Burke and Mark Donnelly and Kashaf Khan},
  doi          = {10.1016/j.datak.2025.102430},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {7},
  pages        = {102430},
  shortjournal = {Data Knowl. Eng.},
  title        = {Modelling process durations with gamma mixtures for right-censored data: Applications in customer clustering, pattern recognition, drift detection, and rationalisation},
  volume       = {158},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accessibility in conceptual modeling—a systematic literature
review, a keyboard-only UML modeling tool, and a research roadmap.
<em>DKE</em>, <em>158</em>, 102423. (<a
href="https://doi.org/10.1016/j.datak.2025.102423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reports on Disability by the World Health Organization show that the number of people with disabilities is increasing. Consequently, accessibility should play an essential role in information systems engineering research. While there is an increasingly rich set of available web accessibility guidelines, testing frameworks, and generally accessibility features in modern web-based software systems, software development frameworks, and Integrated Development Environments, this paper shows, based on a systematic review of the literature and current modeling tools, that accessibility is, so far, only scarcely focused in conceptual modeling research. With this paper, we assess the state of the art of accessibility in conceptual modeling, we identify current research gaps, and we delineate a vision toward more accessible conceptual modeling methods and tools. As a concrete step forward toward this vision, we present a generic concept of a keyboard-only modeling tool interaction that is implemented as a new module for the Graphical Language Server Platform (GLSP) framework. We show—using a currently developed UML modeling tool—how efficiently this module allows GLSP-based tool developers to introduce accessibility features into their modeling tools, thereby engaging physically disabled users in conceptual modeling.},
  archive      = {J_DKE},
  author       = {Aylin Sarioğlu and Haydar Metin and Dominik Bork},
  doi          = {10.1016/j.datak.2025.102423},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {7},
  pages        = {102423},
  shortjournal = {Data Knowl. Eng.},
  title        = {Accessibility in conceptual modeling—A systematic literature review, a keyboard-only UML modeling tool, and a research roadmap},
  volume       = {158},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving cross-network service recommendation via
federated learning of unified user representations. <em>DKE</em>,
<em>158</em>, 102422. (<a
href="https://doi.org/10.1016/j.datak.2025.102422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of cloud computing, the Internet of Things, and other large-scale environments, recommender systems have been faced with several issues, mainly (i) the distribution of user–item data across multiple information networks, (ii) privacy restrictions and the partial profiling of users and items caused by this distribution, (iii) the heterogeneity of user–item knowledge in different information networks. Furthermore, most approaches perform recommendations based on a single source of information, and do not handle the partial representation of users’ and items’ information in a federated way. Such isolated and non-collaborative behavior, in multi-source and cross-network information settings, often results in inaccurate and low-quality recommendations. To address these issues, we exploit the strengths of network representation learning and federated learning to propose a service recommendation approach in smart service networks. While NRL is employed to learn rich representations of entities (e.g., users, services, IoT objects), federated learning helps collaboratively infer a unified profile of users and items, based on the concept of anchor user , which are bridge entities connecting multiple information networks. These unified profiles are, finally, fed into a federated recommendation algorithm to select the top-rated services. Using a scenario from the smart healthcare context, the proposed approach was developed and validated on a multiplex information network built from real-world electronic medical records (157 diseases, 491 symptoms, 273 174 patients, treatments and anchors data). Experimental results under varied federated settings demonstrated the utility of cross-client knowledge (i.e. anchor links) and the collaborative reconstruction of composite embeddings (i.e. user representations) for improving recommendation accuracy. In terms of RMSE@K and MAE@K, our approach achieved an improvement of 54.41% compared to traditional single-network recommendation, as long as the federation and communication scale increased. Moreover, the gap with four federated approaches has reached 19.83 %, highlighting our approach’s ability to map local embeddings (i.e. user’s partial representations) into a complete view.},
  archive      = {J_DKE},
  author       = {Mohamed Gaith Ayadi and Haithem Mezni and Hela Elmannai and Reem Ibrahim Alkanhel},
  doi          = {10.1016/j.datak.2025.102422},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {7},
  pages        = {102422},
  shortjournal = {Data Knowl. Eng.},
  title        = {Privacy-preserving cross-network service recommendation via federated learning of unified user representations},
  volume       = {158},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph theoretic approach to assess quality of data for
classification task. <em>DKE</em>, <em>158</em>, 102421. (<a
href="https://doi.org/10.1016/j.datak.2025.102421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The correctness of predictions rendered by an AI/ML model is key to its acceptability. To foster researchers’ and practitioners’ confidence in the model, it is necessary to render an intuitive understanding of the workings of a model. In this work, we attempt to explain a model’s working by providing some insights into the quality of data. While doing this, it is essential to consider that revealing the training data to the users is not feasible for logistical and security reasons. However, sharing some interpretable parameters of the training data and correlating them with the model’s performance can be helpful in this regard. To this end, we propose a new measure based on Euclidean Minimum Spanning Tree (EMST) for quantifying the intrinsic separation (or overlaps) between the data classes. For experiments, we use datasets from diverse domains such as finance, medical, and marketing. We use state-of-the-art measure known as Davies Bouldin Index (DBI) to validate our approach on four different datasets from aforementioned domains. The experimental results of this study establish the viability of the proposed approach in explaining the working and efficiency of a classifier. Firstly, the proposed measure of class-overlap quantification has shown a better correlation with the classification performance as compared to DBI scores. Secondly, the results on multi-class datasets demonstrate that the proposed measure can be used to determine the feature importance so as to learn a better classification model.},
  archive      = {J_DKE},
  author       = {Payel Sadhukhan and Samrat Gupta},
  doi          = {10.1016/j.datak.2025.102421},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {7},
  pages        = {102421},
  shortjournal = {Data Knowl. Eng.},
  title        = {A graph theoretic approach to assess quality of data for classification task},
  volume       = {158},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CriMOnto: A generalized domain-specific ontology for
modeling procedural norms of the lebanese criminal law. <em>DKE</em>,
<em>158</em>, 102419. (<a
href="https://doi.org/10.1016/j.datak.2025.102419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Criminal (or penal) law regulates offenses, offenders, and legal punishments. Modeling criminal law is gaining much attention in the ontology engineering community. However, a significant aspect is neglected: the explicit representation of procedural knowledge. Procedural norms, such as regulative norms, are addressed to agents in the normative system. They govern the different interactions among these agents. In this study, we propose a formal and faithful representation of the procedural aspect of legal norms in the context of the Lebanese Criminal Code. A modular domain-specific ontology named CriMOnto is developed for this purpose. CriMOnto is grounded in the Unified Foundational Ontology (UFO) and the legal core ontology UFO-L by applying the Ontology-Driven Conceptual Modeling (ODCM) process. Conceptual Ontology Patterns (COPs) are reused from UFO and UFO-L to build the hierarchical and procedural content of the ontology. CriMOnto is validated as a formal ontology and evaluated using a dual evaluation approach. The potential use of CriMOnto for lightweight rule-based decision support is discussed in this study.},
  archive      = {J_DKE},
  author       = {Mirna El Ghosh and Hala Naja and Habib Abdulrab and Mohamad Khalil},
  doi          = {10.1016/j.datak.2025.102419},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {7},
  pages        = {102419},
  shortjournal = {Data Knowl. Eng.},
  title        = {CriMOnto: A generalized domain-specific ontology for modeling procedural norms of the lebanese criminal law},
  volume       = {158},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="dss---5">DSS - 5</h2>
<ul>
<li><details>
<summary>
(2025). Predicting stock price movement using social network
analytics: Posts are sometimes less useful. <em>DSS</em>, <em>192</em>,
114438. (<a href="https://doi.org/10.1016/j.dss.2025.114438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary research has leveraged social network data as a predictive tool for decision-making process in the capital market. Yet, its effectiveness may be compromised by social contagion. This study addresses this problem by introducing conversation-level measures that capture how interactions among investors affect market predictions. Drawing on social contagion theory, we identified three conversation conditions—argument similarity, sentiment similarity, and conversation size—and examined their association with the likelihood of abrupt stock price changes, which indicate a loss of collective wisdom. Our analysis of 18 million StockTwits posts for 859 Initial Public Offerings (2008–2017) reveals that conversations with highly similar arguments, highly similar sentiments, and larger size are significantly associated with an increased likelihood of abrupt stock price changes in the subsequent week. Moreover, out-of-sample tests confirm that monitoring conversational dynamics enhances the predictive power of social network analytics, offering valuable guidance for investors and practitioners. Our study extends the theoretical framework of social contagion by highlighting the importance of the conversation level and provides practical recommendations for refining trading strategies based on social media data.},
  archive      = {J_DSS},
  author       = {Wanyun Li and Alvin Chung Man Leung and Ka Wai Choi (Stanley) and Shuk Ying Ho},
  doi          = {10.1016/j.dss.2025.114438},
  journal      = {Decision Support Systems},
  month        = {5},
  pages        = {114438},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Predicting stock price movement using social network analytics: Posts are sometimes less useful},
  volume       = {192},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). To disclose or not? The impact of prosocial behavior
disclosure on the attainment of social capital on social networking
sites. <em>DSS</em>, <em>192</em>, 114437. (<a
href="https://doi.org/10.1016/j.dss.2025.114437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While some donors and volunteers do not publicize their prosocial behaviors because of humility, many others fear that disclosing their prosocial behaviors may be perceived as bragging. With the rise of social networking sites (SNSs), this has become an essential issue with important business implications. As more companies encourage employees to volunteer a small portion of their work time and match their charitable contributions, disclosing these prosocial acts on social media platforms has become more common. Building upon social capital theory, we apply a mixed-method approach to investigate the relationship between the disclosure of prosocial behaviors and the attainment of social capital on SNSs. Our first exploratory study applies qualitative interviews to explore the factors that moderate the relationship between the disclosure of prosocial behaviors and the attainment of social capital. Our second study utilizes a randomized online experiment in the U.S. to test the causal effect of prosocial behavior disclosure on social capital attainment online, as well as two moderators of this relationship. A post-hoc replication study of our experiment is conducted in China. We find that the disclosure of prosocial behavior increases relational and structural social capital on SNSs but find no evidence of the impact of the disclosure of prosocial behavior on cognitive social capital. The effect becomes stronger when one&#39;s prosocial behavior is disclosed by others (rather than by oneself) in the U.S. sample. Our findings inform SNSs users to make informed decisions regarding disclosing prosocial behaviors to attain structural and relational social capital. Businesses encouraging their employees to donate/volunteer and charities on the receiving end could also benefit from our findings.},
  archive      = {J_DSS},
  author       = {Jiayuan Zhang and Koray Özpolat and Gulver Karamemis and Dara Schniederjans},
  doi          = {10.1016/j.dss.2025.114437},
  journal      = {Decision Support Systems},
  month        = {5},
  pages        = {114437},
  shortjournal = {Decis. Supp. Syst.},
  title        = {To disclose or not? the impact of prosocial behavior disclosure on the attainment of social capital on social networking sites},
  volume       = {192},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Not easy to “like”: How does cognitive load influence user
engagement in online reviews? <em>DSS</em>, <em>192</em>, 114436. (<a
href="https://doi.org/10.1016/j.dss.2025.114436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User engagement (e.g., likes, shares, and comments) is widely recognized as critical to business success. Although existing studies have explored the determinants of user engagement, relatively little attention has been paid to cognitive load. This study, based on cognitive load theory, expectation confirmation theory, and the stressor-strain-outcome framework, examines the heterogeneous effects of intrinsic, extraneous, and germane cognitive load on user engagement in Study 1, the moderating effects of intrinsic, extraneous, and germane cognitive load variance (i.e., described as cognitive load changes induced by processing from one review to another review) in Study 1, and their underlying mechanisms in Study 2. Results indicate that: (1) intrinsic and extraneous cognitive load negatively influence user engagement, while germane cognitive load has a positive effect, (2) intrinsic/extraneous cognitive load variance accentuates the negative effect of intrinsic/extraneous cognitive load, while germane cognitive load variance strengthens the positive effect of germane cognitive load, and (3) perceived fatigue negatively mediates the effects of intrinsic and extraneous cognitive load but positively mediates the effect of germane cognitive load. Our findings contribute to the literature on user engagement and offer practical insights for optimizing online review systems.},
  archive      = {J_DSS},
  author       = {Yuqiu Wang and Kai Li},
  doi          = {10.1016/j.dss.2025.114436},
  journal      = {Decision Support Systems},
  month        = {5},
  pages        = {114436},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Not easy to “like”: How does cognitive load influence user engagement in online reviews?},
  volume       = {192},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Re-evaluating causal inference: Bias reduction in
confounder-effect modifier scenarios. <em>DSS</em>, <em>192</em>,
114435. (<a href="https://doi.org/10.1016/j.dss.2025.114435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Propensity Score Matching (PSM) is a widely used method for estimating causal treatment effects, but its performance can be limited in complex scenarios. This paper examines cases where a confounder also serves as an effect modifier and compares the bias-reduction performance of PSM with Inverse Probability Weighting (IPW). Using the University of California, Berkeley graduate admission data as an illustrative example, we show that PSM can produce biased estimates of the Average Treatment Effect (ATE) in such contexts. Through a simulation study, we demonstrate that PSM generally fails to adequately reduce bias for the ATE when a confounder is also an effect modifier, while IPW yields less biased estimates with lower Mean Squared Error (MSE). To validate these findings in a more real-world setting, we analyse data generated from a well-known matched-pairs experimental study of Mexico&#39;s Seguro Popular de Salud (Universal Health Insurance) Program. From this experiment we derive observational data that incorporates confounders and effect modifiers and compare the performance of PSM and IPW estimators. Our results confirm that IPW consistently provides more accurate and reliable estimates of the ATE, with smaller bias, compared to PSM.},
  archive      = {J_DSS},
  author       = {Xuan Wang and Tamer Oraby and Xi Mao and Geng Sun and Helmut Schneider},
  doi          = {10.1016/j.dss.2025.114435},
  journal      = {Decision Support Systems},
  month        = {5},
  pages        = {114435},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Re-evaluating causal inference: Bias reduction in confounder-effect modifier scenarios},
  volume       = {192},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal advertising strategy for streaming platforms:
Whether to purchase external consumer data. <em>DSS</em>, <em>192</em>,
114427. (<a href="https://doi.org/10.1016/j.dss.2025.114427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By utilizing consumer behavioral data, targeted ads can enhance the click-through rates (CTRs) but, at the same time, cause consumer privacy concerns. In this paper, we investigate whether a streaming platform should purchase external consumer data to improve ad-targeting levels, whereby it gain revenue from cost-per-mille (CPM) and cost-per-click (CPC) advertising. We explore how advertising intensity and consumer advertising fatigue interactively determine the data purchase decision and the optimal ad-targeting level of the streaming platform. Our findings indicate that the platform with low advertising intensity or high consumer advertising fatigue is more likely to purchase external consumer data because the ad-driven CTRs are low in these cases. An unexpected finding is that the amount of consumer data purchased by the platform increases with the intensity of privacy concern when advertising intensity is low or when both advertising intensity and fatigue level are high. In these scenarios, the privacy invasion effect resulting from purchasing external consumer data is low due to the low ad-driven CTRs. After purchasing consumer data, to compensate for the privacy invasion effect of targeted ads on consumers, the platform should lower the advertising intensity if and only if the advertising fatigue level is low. Furthermore, we demonstrate that if the platform simultaneously decides on advertising intensity and ad-targeting level, purchasing external consumer data results in a Pareto improvement when the organic CTR is low, benefiting both consumers and the streaming platform. Our findings highlight the importance of balancing advertising precision and consumer privacy on a streaming platform.},
  archive      = {J_DSS},
  author       = {Jiahe Wang and Nan Feng and Haiyang Feng and Minqiang Li},
  doi          = {10.1016/j.dss.2025.114427},
  journal      = {Decision Support Systems},
  month        = {5},
  pages        = {114427},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Optimal advertising strategy for streaming platforms: Whether to purchase external consumer data},
  volume       = {192},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="eaai---22">EAAI - 22</h2>
<ul>
<li><details>
<summary>
(2025). Personalised healthcare and exercise rehabilitation based on
upper-limb metrics. <em>EAAI</em>, <em>151</em>, 110673. (<a
href="https://doi.org/10.1016/j.engappai.2025.110673">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapid and accurate upper-limb motion analysis and metrics are essential for enhancing exercise medicine knowledge graph to drive personalised medicine. However, current studies face limitations in understanding multi-timescale and multi-target, compounded by discrepancies in physiological structure. This study proposes Upper-Limb Dynamic Warping (UP-Ldw), which effectively responds to motion discrepancies and adapts to the physiological characteristics. UP-Ldw constructs a geometric model by parameterizing features and incorporating physiological structure parameters to accommodate individual variations. Dynamic temporal regularization is integrated to accommodate motion sequences across multiple time scales. Ultimately, the motion similarity among various targets is outputted to facilitate comparison and metrics. Furthermore, two datasets are developed: Upper-Limb 3-Dimensional Dataset (UP-L-3D), and Upper-Limb Geometric Modeling Dataset (UP-L-GM), both utilized for validation. Comparison experiments employed convolutional neural network (CNN), principal component analysis (PCA), and random forests. Results demonstrate that UP-Ldw achieves the highest accuracy of 97.92 % using metrics 20 as the discriminant criterion, with a short running time of 1–8 ms. UP-Ldw aligned with CNN confusion matrices and the PCA downscaling, validating its precise motion analysis. The Random Forest model attained an average accuracy of 91.1 %, confirming the validity of the geometric model. A generalization experiment was conducted using the public dataset Arm-CODA, further validating UP-Ldw&#39;s ability to adapt to physiological structures and effectively metricize upper-limb motion. Overall, UP-Ldw employs artificial intelligence to metricize motion, facilitating mirror rehabilitation. This advancement contributes significantly to the engineering applications of personalised healthcare and exercise rehabilitation.},
  archive      = {J_EAAI},
  author       = {Honggang Wang and Yisu Wang and Zengmin He and Xuzhi Li and Yufeng Yao},
  doi          = {10.1016/j.engappai.2025.110673},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110673},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Personalised healthcare and exercise rehabilitation based on upper-limb metrics},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “image–text sentiment analysis based on
hierarchical interaction fusion and contrast learning enhanced” [eng.
Appl. Artific. Intellig. 146 (2025) 110262]. <em>EAAI</em>,
<em>151</em>, 110667. (<a
href="https://doi.org/10.1016/j.engappai.2025.110667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Hongbin Wang and Qifei Du and Yan Xiang},
  doi          = {10.1016/j.engappai.2025.110667},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110667},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Corrigendum to “Image–text sentiment analysis based on hierarchical interaction fusion and contrast learning enhanced” [Eng. appl. artific. intellig. 146 (2025) 110262]},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging deep reinforcement learning to optimize linear
quadratic regulator parameters for leader-follower formation control.
<em>EAAI</em>, <em>151</em>, 110666. (<a
href="https://doi.org/10.1016/j.engappai.2025.110666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of robotic formations in various fields, from exploration missions to precision agricultural operations, has highlighted the urgent need for studying and optimizing formation control techniques. This paper aims to enhance the full-process control of a leader-follower formation system, encompassing both formation establishment and maintenance. Firstly, an algorithm is designed to autonomously assign team roles to follower robots in a distributed fashion, thereby generating a virtual goal pose for each follower. Secondly, a combination of a Linear Quadratic Regulator (LQR) controller, based on the Ackermann model, and a Proportional-Derivative (PD) controller is developed for lateral and longitudinal distance control of each robot. Subsequently, an improved Asynchronous Advantage Actor-Critic (A3C) algorithm is utilized to expedite the training process and enable real-time online parameter optimization of the LQR controller. Finally, the Robot Operating System 2 (ROS2)-based formation system and experimental setup are presented, along with a detailed description of the A3C training process. According to both simulation and real-vehicle experiments, the formation control method proposed in this paper demonstrates stable operation and high accuracy in formation maintenance, surpassing other similar methods and the traditional LQR approach.},
  archive      = {J_EAAI},
  author       = {Zhi Wang and Yun Ling and Min Ma and TingTing Chen},
  doi          = {10.1016/j.engappai.2025.110666},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110666},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leveraging deep reinforcement learning to optimize linear quadratic regulator parameters for leader-follower formation control},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on multi-objective point path planning for mobile
inspection robot based on multi-informed-rapidly exploring random tree∗.
<em>EAAI</em>, <em>151</em>, 110645. (<a
href="https://doi.org/10.1016/j.engappai.2025.110645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Daily inspection as a top priority to ensure the safe production of intelligent workshops, can directly respond to the degree of intelligence of the factory workshop, which often needs robots to inspect multiple target devices. To enhance the inspection quality of intelligent workshop inspection robots, this thesis is based on the Informed-Rapidly Exploring Random Tree (RRT) algorithm and introduces the concept of simultaneous expansion of multiple trees. This paper proposes a strategy involving random tree connectivity to the Multi-Informed-RRT∗ (MI-RRT∗) global path planning algorithm, which is suitable for multi-objective point planning. It is verified through simulation that in solving the same planning problem for eight objective points, compared with the basic Informed-RRT∗ algorithm, the MI-RRT∗ algorithm&#39;s running time is reduced by 79.56 %, and the final generated path length is reduced by 25.26 %; compared with the Multi-RRT∗ algorithm, which is also used for solving the multi-objective point planning problem, the running time of the algorithm is reduced by 48.48 % and the final generated path length is reduced by 7.45 %. In conclusion, this study proposes a multi-objective point path planning algorithm tailored for the dynamic environment of intelligent workshops, achieved through the integration of MI-RRT∗ and an enhanced Dynamic Window Approach (DWA) algorithm. Experimental evidence substantiates that the path generated by the MI-RRT∗ algorithm, as presented in this paper, is superior, resulting in shorter robot running times and a substantial enhancement in inspection efficiency within the workshop. Simultaneously, it mitigates the issue of traditional inspection equipment leakage, thereby possessing tangible practical value.},
  archive      = {J_EAAI},
  author       = {Hongjuan Yang and Xu Luo and Chao Duan and Peishen Wang and Kaidi Zhu and Xingqiao Deng and Wenjuan Ren},
  doi          = {10.1016/j.engappai.2025.110645},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110645},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Research on multi-objective point path planning for mobile inspection robot based on multi-informed-rapidly exploring random tree∗},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification of power quality disturbances using residual
networks with channel attention mechanism. <em>EAAI</em>, <em>151</em>,
110641. (<a
href="https://doi.org/10.1016/j.engappai.2025.110641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection and classification of power quality disturbances (PQDs) carries significant importance for power systems. In response to this imperative, numerous intelligent diagnostic methods have been developed. However, existing identification methods usually concentrate on single-type signals or on complex signals with two types, rendering them susceptible to noisy labels and environmental effects. This study proposes a novel method for the classification of PQDs, named Stockwell transform-Grouped convolution Squeeze-and-excitation Residual Network (ST-GSResNet), which utilizes the Stockwell transform (S-Transform) and an improved residual network (ResNet) with a channel attention mechanism. The ST-GSResNet approach initially uses the S-Transform to transform a time-series signal into a two-dimensional (2D) time–frequency image for feature enhancement. Then, an improved ResNet model is introduced, which employs grouped convolution instead of the traditional convolution operation. This improvement aims to facilitate learning with a block-diagonal structured sparsity on the channel dimension, the highly-correlated filters are learned in a more structured way in the networks with filter groups. By reducing the number of parameters in the network in this significant manner, the model becomes less prone to overfitting. Furthermore, the channel attention mechanism (squeeze-and-excitation module) concentrates on primary components, which enhances the model’s robustness in recognition and immunity to noise. Experimental results demonstrate that, compared to existing deep learning models, our approach has advantages in computational efficiency and classification accuracy.},
  archive      = {J_EAAI},
  author       = {Su Pan and Xingyang Nie and Xiaoyu Zhai and Cheng He and Zhenping Ding},
  doi          = {10.1016/j.engappai.2025.110641},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110641},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Classification of power quality disturbances using residual networks with channel attention mechanism},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzification-back propagation neural network-based model
prediction for robotic arm positioning error reduction. <em>EAAI</em>,
<em>151</em>, 110639. (<a
href="https://doi.org/10.1016/j.engappai.2025.110639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic arms are pervasively used in critical manufacturing fields, but its absolute positioning accuracy cannot be controlled because of random errors. Although some researches using back propagation neural network to predict the robotic arm&#39;s absolute positioning error have been proved, they suffer from poor convergence and low prediction accuracy in that input parameters contain unavoidable measurement errors. This paper proposed an error prediction model based on fuzzification and back propagation neural network. The rotation angle and direction of robotic joints are employed as training samples for the back propagation neural network, and converted into error contributions using the fuzzification to eliminate the influence of measurement errors in the input parameters. The input parameters are simplified, which enables the training process of the back propagation neural network to be optimized. Experimental results showed that the training time of the model was reduced by two times or more, and the mean square error was decreased by roughly 2.94 %. Meanwhile, the average absolute positioning error of the robotic arm with the prediction model was reduced by 59.22 %. The model can be easily transplanted into embedded systems to provide a methodology for new design of robotic arm error compensators.},
  archive      = {J_EAAI},
  author       = {Jiang Liu and Jianwei Wu and Jiansheng Pan and Pengyue Zhao},
  doi          = {10.1016/j.engappai.2025.110639},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110639},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fuzzification-back propagation neural network-based model prediction for robotic arm positioning error reduction},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic data-augmented explainable vision transformer for
colorectal cancer diagnosis via surface tactile imaging. <em>EAAI</em>,
<em>151</em>, 110633. (<a
href="https://doi.org/10.1016/j.engappai.2025.110633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a synthetic data augmented explainable Vision Transformer (ViT) framework designed for the informed and intuitive early diagnosis of colorectal cancer (CRC) polyps. The framework uses textural images — generated by our recently developed vision-based tactile sensor (called HySenSe) and augmented by synthetically generated images from a diffusion model pipeline, to output class-based probabilities of potential CRC polyp types. Additionally, it provides local relevancy-based heatmaps to assist clinicians by highlighting key areas of interest in the tactile images representing CRC polyp textures. We benchmark each aspect of this framework through: (i) Inception Scores for the synthetic images generated by the diffusion pipeline, (ii) Performance evaluation and sensitivity analyses on the effects of synthetic data addition on model generalizability compared with other state-of-the-art architectures, (iii) Dimensionality reduction techniques to confirm the suitability of synthetically generated images, and (iv) Comparison of two independent approaches visualizing explainability.},
  archive      = {J_EAAI},
  author       = {Siddhartha Kapuria and Naruhiko Ikoma and Sandeep Chinchali and Farshid Alambeigi},
  doi          = {10.1016/j.engappai.2025.110633},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110633},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Synthetic data-augmented explainable vision transformer for colorectal cancer diagnosis via surface tactile imaging},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-based sentiment analysis for software requirements
elicitation using fine-tuned bidirectional encoder representations from
transformers and explainable artificial intelligence. <em>EAAI</em>,
<em>151</em>, 110632. (<a
href="https://doi.org/10.1016/j.engappai.2025.110632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-Based Sentiment Analysis (ABSA) of app reviews allows a better understanding of user preferences regarding specific product features and helps the development team elicit requirements effectively. The existing literature faces challenges such as limited focus on the automation of Requirement Elicitation (RE), insufficient task-specific fine-tuning of models such as Bidirectional Encoder Representations from Transformers (BERT), and lack of interpretability owing to the black-box nature of these models. Therefore, our work makes the following significant contributions to address these challenges: (1) development and evaluation of a robust method based on ABSA for the automation of the RE process; (2) optimization of ABSA using BERT fine-tuning for enhanced performance, which includes conducting a comprehensive ablation study to obtain the best hyperparameters that guarantee the best model performance and robustness; and (3) integration of Explainable Artificial Intelligence (XAI) techniques for enhanced BERT model interpretability. Our work was evaluated on the ABSA Warehouse of Apps REviews (AWARE) dataset, a specifically tailored dataset for the RE process. Our study outperformed baseline models such as the Support Vector Machine (SVM), Convolutional Neural Network (CNN), and BERT, and achieved an average F1-Score of 0.83 for the Aspect Category Detection (ACD) task and 0.94 for the Aspect Category Polarity (ACP) task. In addition, we employed XAI using Locally Interpretable Model-Agnostic Explanations (LIME) to explain the BERT model prediction results, which aids in the improved visualization and interpretability of the app review analysis for the automated RE process.},
  archive      = {J_EAAI},
  author       = {Soonh Taj and Sher Muhammad Daudpota and Ali Shariq Imran and Zenun Kastrati},
  doi          = {10.1016/j.engappai.2025.110632},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110632},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Aspect-based sentiment analysis for software requirements elicitation using fine-tuned bidirectional encoder representations from transformers and explainable artificial intelligence},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced code time complexity prediction approach using
contrastive learning. <em>EAAI</em>, <em>151</em>, 110631. (<a
href="https://doi.org/10.1016/j.engappai.2025.110631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a crucial task to predict the algorithmic time complexity for estimating the efficiency of a software code. Since the problem is known to be undecidable in theory, there is no 100% accurate tools to solve the problem. Even humans often make mistakes when analyzing the time complexity of code, and this process requires considerable effort and time to thoroughly examine the code. Therefore, we aim to develop an automated method for analyzing code time complexity. We observe that solution codes submitted for coding problems in competitive programming contests tend to have similar time complexities due to constraints such as time limits and functional requirements of the problems. Based on this observation, we propose a contrastive learning-based training strategy that aligns solution codes for the same competitive programming problem. Our training strategy clusters codes with similar time complexities by using both natural language problem descriptions and a single reference code per problem as anchors. This design enables the model to capture core algorithmic features such as loops and recursion more accurately. Experiments in three scenarios – in-dataset, cross-dataset, and cross-language – demonstrate substantial gains on pre-trained code models, consistently surpassing existing methods in both accuracy and generalizability. Our proposed training strategy yields an average 12.54% improvement over cross-entropy-based training, and an 8.01% improvement over data augmentation-based contrastive learning.},
  archive      = {J_EAAI},
  author       = {Shinwoo Park and Joonghyuk Hahn and Elizabeth Orwig and Sang-Ki Ko and Yo-Sub Han},
  doi          = {10.1016/j.engappai.2025.110631},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110631},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advanced code time complexity prediction approach using contrastive learning},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating cumulative binomial probability into artificial
bee colony algorithm for global optimization in mechanical engineering
design. <em>EAAI</em>, <em>151</em>, 110628. (<a
href="https://doi.org/10.1016/j.engappai.2025.110628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The artificial bee colony (ABC) algorithm has gained significant attention in engineering design optimization for its simplicity and robustness. However, it suffers from low convergence accuracy and imbalanced exploration and exploitation, particularly in non-convex and multi-modal problems. To alleviate these shortcomings, we present a novel ABC algorithm that combines cumulative binomial probability (CBABC), which contains two versions, single-dimensional evolution (CBACB_S) and multi-dimensional evolution (CBABC_M). According to the success and failure evolution experience, we first introduce a scaling factor based on cumulative binomial probability. Sequentially new movement equations with different characteristics are designed in the onlooker bee phase to balance local and global search capabilities. Then, a novel abandoned solution update mechanism is defined during scout bee phase to partly improve the solution accuracy. Finally, our approaches achieve a minimum winning rate of 68.19% and a maximum winning rate of 95.45% against its 9 outstanding ABC variants across the 22 functions. In addition, the proposed algorithms maintain a winning rate within [57.89%, 100%] compared to several state-of-the-art evolutionary algorithms for tackling 19 real-world mechanical engineering problems from Congress on Evolutionary Computation 2020 (CEC2020) suite.},
  archive      = {J_EAAI},
  author       = {Xiangyu Kong and Pengpeng Shang and Chunfeng Wang and Lixia Liu},
  doi          = {10.1016/j.engappai.2025.110628},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110628},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrating cumulative binomial probability into artificial bee colony algorithm for global optimization in mechanical engineering design},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing greenhouse gas emission reduction strategies:
Integrating multi-criteria decision-making with complex q-rung picture
fuzzy sugeno–weber operators. <em>EAAI</em>, <em>151</em>, 110621. (<a
href="https://doi.org/10.1016/j.engappai.2025.110621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The urgent need to mitigate greenhouse gas emissions amidst escalating global climate change demands innovative and comprehensive strategies. This paper addresses this challenge by proposing a novel Multi-Criteria Decision-Making (MCDM) framework that integrates Sugeno–Weber t-norm and t-conorm within the Complex q-Rung Picture Fuzzy Set (Cq-RPFS) paradigm. Our approach introduces three new aggregation operators: Sugeno–Weber Weighted Average, Sugeno–Weber Ordered Weighted Average, and Sugeno–Weber Hybrid Weighted Average under the environment of Cq-RPFS. These operators enhance fuzzy information aggregation by addressing complex criterion interrelationships, offering a more nuanced evaluation of emission reduction strategies. We validate our framework through a detailed case study on emissions in India, focusing on aligning reduction strategies with sustainable development goals. The proposed method demonstrates superior effectiveness in managing multidimensional data compared to traditional aggregation techniques. Comprehensive sensitivity analysis and comparative studies further reveal the robustness and adaptability of our approach, showcasing its potential to provide more accurate and balanced assessments in real-world scenarios. This research fills a critical gap in decision-making methodologies and offers valuable insights for policymakers and researchers engaged in sustainable climate action.},
  archive      = {J_EAAI},
  author       = {Subramanian Petchimuthu and Fathima Banu M. and S. Thiruvazhimarba Pillai and Tapan Senapati},
  doi          = {10.1016/j.engappai.2025.110621},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110621},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Advancing greenhouse gas emission reduction strategies: Integrating multi-criteria decision-making with complex q-rung picture fuzzy Sugeno–Weber operators},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-based metamodel of synthetic seismograms:
Application for uncertainty quantification. <em>EAAI</em>, <em>151</em>,
110613. (<a
href="https://doi.org/10.1016/j.engappai.2025.110613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We developed time and frequency domains neural network surrogate models of synthetic seismograms stemming from the resolution of the three-dimensional equation of motion. The surrogates predict the time or frequency-series knowing the input variables of the physical model. The surrogate models are used to quantify epistemic uncertainty in ground motion prediction through global sensitivity analysis. We first generate a dataset of time domain synthetic seismograms in a seven-dimensions uncertain space using the spectral-element method. To validate the surrogate model, we evaluate its ability to reproduce at least 80% of the bootstrap resamples. Additionally, the R 2 regression coefficient between the simulations generated by the spectral-element method code and those predicted by the neural network is 0.94 for the validation set, confirming the accuracy of the surrogate model. These surrogates allow fast predictions of velocity time-series or Fourier amplitude spectra where spectral-element simulations are not done (neural networks compute about 100,000 surrogates per second, while a single spectral-element simulation longs approximately 7 h on 48 cores). To quantify the uncertainty of the physical system under study, a global sensitivity analysis is undertaken to better understand how uncertain parameters affect the predicted state of the system. We present two sampling-based estimation methods, the so-called “pick-freeze” Sobol method and the Li and Mahadevan method, to quantify this uncertainty. The Sobol method requires approximately 500,000 simulations to achieve stability, whereas the Li and Mahadevan method requires only 30,000 simulations. Using the metamodel, both methods require only a few seconds to produce results, although the Li and Mahadevan method analyzes 10,000 simulations per second, compared to 3,000 for the Sobol method. The results indicate that the shear wave velocity in the physical system’s layer is the most influential parameter affecting the ground speed on the physical system. In contrast, at a reference station (without considering the geological properties of the physical system), the results show that the shear wave velocity in the first and third deep layers are the most influential parameters.},
  archive      = {J_EAAI},
  author       = {Mohamad Ali Noureddine and Florent De Martin and Rani El Meouche and Muhammad Ali Sammuneh and Fakhreddine Ababsa and Mickael Beaufils},
  doi          = {10.1016/j.engappai.2025.110613},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110613},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural network-based metamodel of synthetic seismograms: Application for uncertainty quantification},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic momentum contrastive learning network for diabetic
retinopathy grading. <em>EAAI</em>, <em>151</em>, 110604. (<a
href="https://doi.org/10.1016/j.engappai.2025.110604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy is the leading cause of blindness among the global working population. Automated and accurate grading of diabetic retinopathy is crucial for the diagnosis and treatment of retinal diseases. However, challenges arise in grading due to class imbalance, inter-class similarity, intra-class variability, and the small scale of lesions in different stages of diabetic retinopathy. To address the issues of class imbalance and small lesion scales, the dynamic momentum contrastive learning network (DMCLNet) for diabetic retinopathy grading is proposed in this paper. Firstly, a new strategy is introduced for constructing positive and negative samples to enhance individual differences. Then, an encoder and a momentum encoder are used to extract features from the main image, the positive and negative samples, respectively. The dynamic balancing strategy is presented to update the multi-class feature queue and calculate the similarity matrix between the main image and each positive and negative sample for contrastive learning. A dual dimensional loss function guides the training of the proposed model to fully capture the subtle differences between images of different classes, which improves inter-class discrimination ability. Finally, channel attention and spatial attention mechanisms are applied to enhance disease-related fine-grained features and suppress irrelevant redundant information, which accurately identifies small-scale lesions and improves the precision of severity grading. Extensive comparative experiments and ablation studies on three public datasets demonstrate that DMCLNet outperforms other state-of-the-art methods. It can achieve superior diabetic retinopathy grading performance across multiple datasets without relying on pixel-level lesion annotation, with high accuracy and generalization.},
  archive      = {J_EAAI},
  author       = {Yanfei Guo and Chenglong Yang and Hangli Du and Yuanke Zhang and Fei Ma and Shasha Yuan},
  doi          = {10.1016/j.engappai.2025.110604},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110604},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic momentum contrastive learning network for diabetic retinopathy grading},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active learning of optical path classification.
<em>EAAI</em>, <em>151</em>, 110582. (<a
href="https://doi.org/10.1016/j.engappai.2025.110582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating classification models to predict whether an optical channel can provide a required level of transmission quality is a promising approach to automated path quality assessment in optical network design. The applicability of machine learning algorithms in this domain is limited, however, by the cost, effort, and time needed to collect sufficient labeled data for model creation. The necessary amount of labeled data may be substantially reduced by active learning. This is an iterative process, creating a sequence of models, where each model is used to select the most useful paths for a class labeling query which are then added to the training set for the next model. Such a learning scenario poses different challenges for machine learning algorithms than standard “passive” learning, since they have to deal with very small and often imbalanced data. This work examines how these challenges are handled by algorithms that have been found particularly useful for optical path classification by prior studies. The random forest and extreme gradient boosting algorithms are applied to active learning from a real dataset provided by a network operator, starting only from a handful of training instances. Uncertainty sampling and diversity sampling are used for query selection. Confidence-based and stability-based stopping criteria are used to determine when the process can be safely terminated. The results confirm that active learning is a useful approach to creating optical path classification models, making it possible to save more than a half of the cost needed to provide class labels for model creation.},
  archive      = {J_EAAI},
  author       = {Paweł Cichosz},
  doi          = {10.1016/j.engappai.2025.110582},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110582},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Active learning of optical path classification},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic-demand vulnerability analysis of water networks
using a two-index neural network algorithm. <em>EAAI</em>, <em>151</em>,
110581. (<a
href="https://doi.org/10.1016/j.engappai.2025.110581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User demand changes periodically throughout the day, and the water distribution network is multi-terminal, so a vulnerability assessment based on a static network cannot accurately describe the network. In view of the above two reasons, we first establish two indicators in this paper, path centrality index and node importance index, and the proposed indicators accurately quantify the importance of paths and nodes in the water distribution network. The dynamic demand water distribution network vulnerability is assessed through the proposed two-index neural network algorithm. Firstly, a novel feedforward neural network is proposed to obtain path and flow information, and the neural network structure is established according to the topology of the water distribution network. Then, based on this information, the path centrality index and node importance index are calculated, and the important node and path sets are found. Finally, according to the dynamic demand of each user, the supply–demand ratio in the faulty network is solved. Theoretical analysis proves that the time complexity of the algorithm is o ( 6 n 2 ) . Administrators can further optimize maintenance schedules based on the supply–demand ratio over time. Taking the widely studied North Marin Water District Network in California as an example, it is proved that the proposed two-index neural network algorithm has increased accuracy, faster computation than static methods. However, the proposed algorithm relies on the complete network topology, and the uncertainty of the network topology can be further explored in future research.},
  archive      = {J_EAAI},
  author       = {Baowen Zhang},
  doi          = {10.1016/j.engappai.2025.110581},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110581},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic-demand vulnerability analysis of water networks using a two-index neural network algorithm},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised learning of monocular depth estimators in
autonomous vehicles with federated learning. <em>EAAI</em>,
<em>151</em>, 110572. (<a
href="https://doi.org/10.1016/j.engappai.2025.110572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence has been applied to improve intelligent transportation systems, with a special focus on developing autonomous vehicles. Monocular depth estimation is a crucial task in autonomous driving, offering a cost-effective alternative to binocular methods. While existing approaches for this task leverage self-supervised learning of deep neural networks, they have not taken into account key requirements for their use in autonomous vehicles, such as the need to preserve the privacy of samples collected by multiple vehicles, reduce network consumption during training, and optimize the computation cost distribution. In recent studies, the use of federated learning has shown notable benefits when addressing these requirements. Thus, we propose a novel method combining federated learning and deep self-supervision to enable training of monocular depth estimators with comparable efficacy and superior efficiency to current methods. Our evaluation experiments, using two public benchmarks of images captured by moving vehicles, show that our proposed method achieves near state-of-the-art performance, with test losses of 0.115 and 0.169 on each dataset requiring, on average, only 1k to 1.25k training steps and about 65.1% to 87.4% less data transfer per vehicle in each round than our baseline.},
  archive      = {J_EAAI},
  author       = {Elton F. de S. Soares and Carlos Alberto V. Campos},
  doi          = {10.1016/j.engappai.2025.110572},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110572},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised learning of monocular depth estimators in autonomous vehicles with federated learning},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph convolutional network for traffic incidents duration
classification. <em>EAAI</em>, <em>151</em>, 110570. (<a
href="https://doi.org/10.1016/j.engappai.2025.110570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic incidents are a primary cause of severe congestion in urban areas, making accurate forecasting of incident duration essential for effective traffic management systems. However, the inherent uncertainty associated with incidents presents significant challenges in predicting their durations. In this paper, we propose a novel deep neural network model for predicting and classifying traffic incident durations. To capture the dynamic nature of incidents, the model learns from time series data on traffic flow, speed, and occupancy. Additionally, it employs a graph neural network architecture to model the spatial relationships between sensors, while also accounting for factors such as time and incident type. By training the model with cross-entropy loss, we enable it to predict whether an incident’s duration will be long or short. Experimental results demonstrate that our model outperforms existing baselines, demonstrating the effectiveness of our proposed approach. Furthermore, we conduct a case study to visualize the impact of incidents and further validate the model’s predictive capability.},
  archive      = {J_EAAI},
  author       = {Lyuyi Zhu and Qixin Zhang and Xiangru Jian and Yu Yang},
  doi          = {10.1016/j.engappai.2025.110570},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110570},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph convolutional network for traffic incidents duration classification},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction of medical image segmentation errors through
contrast learning with multi-branch. <em>EAAI</em>, <em>151</em>,
110564. (<a
href="https://doi.org/10.1016/j.engappai.2025.110564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation plays a pivotal role in computer-aided diagnosis. Despite the considerable advancements achieved by convolutional neural networks, segmentation errors such as under-segmentation and mis-segmentation remain significant obstacles, particularly in complex medical images where target regions often share similar features with the background. In this paper, we propose a generalized network called Correction of Medical Image Segmentation Errors through Contrast Learning with Multi-Branch Network (MEC) to address these biases and ultimately improve segmentation accuracy. MEC leverages a multi-branch architecture, where each branch is specifically designed to tackle distinct segmentation issues. The negative branch focuses on encoding mis-segmented regions, the positive branch captures accurately labeled regions, and the anchor branch refines the segmentation output from the base network. To effectively integrate the complementary information from these branches, we employ a contrastive learning strategy that aligns the semantic features of the anchor branch with those of the positive branch, while maintaining a clear distinction from the negative branch. This methodology enhances segmentation performance by capitalizing on the unique strengths of each branch. Experimental results on several medical image datasets demonstrate significant improvements in segmentation accuracy, thereby validating the effectiveness of our proposed approach.},
  archive      = {J_EAAI},
  author       = {Tianlei Gao and Lei Lyu and Nuo Wei and Tongze Liu and Minglei Shu and Yushui Geng},
  doi          = {10.1016/j.engappai.2025.110564},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110564},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Correction of medical image segmentation errors through contrast learning with multi-branch},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient object detection for autonomous vehicles:
Integrating deep learning and sensor fusion in adverse conditions.
<em>EAAI</em>, <em>151</em>, 110563. (<a
href="https://doi.org/10.1016/j.engappai.2025.110563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles (AVs) rely on advanced object detection systems to ensure safe navigation, especially under adverse weather conditions that can impair sensor visibility and introduce detection challenges. This manuscript provides a comprehensive analysis of state-of-the-art methodologies, focusing on deep learning frameworks, multi-sensor fusion techniques, and specialized datasets designed for AV object detection across various environmental conditions. We categorize approaches based on accuracy, computational efficiency, and resilience to challenging weather scenarios, offering insights into the strengths and limitations of each technique. Additionally, widely used datasets, such as KITTI and Waymo, along with synthetic and real-time datasets, are evaluated to assess their impact on detection accuracy in complex scenarios. While deep learning models demonstrate high accuracy, the integration of sensor fusion and transfer learning techniques further enhances robustness and adaptability. Our findings emphasize the importance of developing weather-resilient AV perception systems and provide recommendations for advancing object detection frameworks in autonomous driving applications.},
  archive      = {J_EAAI},
  author       = {Pardhu Thottempudi and Asral Bin Bahari Jambek and Vijay Kumar and Biswaranjan Acharya and Fernando Moreira},
  doi          = {10.1016/j.engappai.2025.110563},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110563},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Resilient object detection for autonomous vehicles: Integrating deep learning and sensor fusion in adverse conditions},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing quadratic programming problems with
intuitionistic fuzzy parameters using a neural network. <em>EAAI</em>,
<em>151</em>, 110562. (<a
href="https://doi.org/10.1016/j.engappai.2025.110562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of intuitionistic fuzzy theory in optimization problems has significantly enhanced the ability to handle complex, uncertain and imprecise scenarios. Despite these advancements, existing models have not adequately addressed the specific challenges of intuitionistic fuzzy quadratic programming problems (IFQPPs). This study fills this gap by proposing a novel recurrent neural network for IFQPPs. First of all, IFQPP is transformed into a multi-objective optimization problem using α , β -cuts. This technique allows to explore a wide range of possible solutions using various combinations of α , β -cuts. Next, the multi-objective problem is converted into a weighted problem coupled with duality theory to remodel into a single-layer recurrent neural network. To validate the proposed approach, theorems as well as lemmas have been constructed and proved at appropriate places. The proposed neural network model is illustrated using numerical examples to explain the methodology. Later, it is applied to a small-scale electrical power grid to demonstrate the practical utility and impact of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Pooja Rani and Sumati Mahajan},
  doi          = {10.1016/j.engappai.2025.110562},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110562},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing quadratic programming problems with intuitionistic fuzzy parameters using a neural network},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention guided class activation maps for boosting weakly
supervised semantic segmentation. <em>EAAI</em>, <em>151</em>, 110556.
(<a href="https://doi.org/10.1016/j.engappai.2025.110556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly Supervised Semantic Segmentation (WSSS) has garnered significant attention for its ability to utilize weaker labels in place of expensive pixel-level annotations while maintaining commendable performance. Class Activation Maps (CAM) can still possess target localization capabilities without pixel-level annotations, and are thus widely used as pseudo labels to supervise subsequent segmentation tasks. With the continuous advancement of artificial intelligence, generating high-quality CAM by combining the strengths of Convolutional Neural Networks (CNN) and Transformer architectures has received widespread attention. As a classic architecture, Conformer adopts a parallel structure and has been applied in multiple WSSS models. We observed that the attention matrices of different levels of Transformer blocks in Conformer exhibit significant characteristic differences, and these matrices effectively capture the correlations between different regions. Based on this observation, we propose a method called Attention-Guided Class Activation Map (AG-CAM), which selectively utilizes attention matrices at different levels to enhance features for various purposes. Detailed experiments on common datasets have shown that the proposed AG-CAM method significantly improves the quality of class activation maps. Our work provides a more precise solution for WSSS, thereby demonstrating immense potential and value in real-world applications where data annotation is scarce.},
  archive      = {J_EAAI},
  author       = {Junhui Li and Lei Zhu and Wenwu Wang and Yin Gong},
  doi          = {10.1016/j.engappai.2025.110556},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110556},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attention guided class activation maps for boosting weakly supervised semantic segmentation},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel koopman-based assistant features network for long
and short-term carbon emission prediction. <em>EAAI</em>, <em>151</em>,
110366. (<a
href="https://doi.org/10.1016/j.engappai.2025.110366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing threat of global warming has heightened the importance of accurately predicting carbon dioxide emissions, a key factor in climate change mitigation. Previous studies have developed carbon emission prediction models using aggregated yearbook statistics, which are limited by spatiotemporal constraints and data scarcity. These models often assume data stationarity, overlooking the dynamic nature of carbon dioxide emission, leading to less reliable predictions that fall short of informing effective urban emission reduction strategies. This paper presents a novel approach by introducing two first daily, city-specific, multi-source carbon dioxide emissions datasets. It integrates global carbon dioxide emissions grid data from CarbonMonitor-graced with concentration measurements from the global carbon column total observation network. To make better use of these data features, we introduce a novel deep learning model, the K oopman A ssistant F eature Net work (KAFNet). By incorporating carbon dioxide concentration and calendar features as additional inputs, we apply the Koopman Operator theory, which is adept at analyzing the time-varying dynamics of complex systems. This approach allows for a comprehensive consideration of the underlying dynamics within carbon emissions data, enabling end-to-end optimization of predictive targets. Our empirical analysis reveals that our model significantly outperforms the sub-optimal models it was compared against, with an average reduction of 34.5% in Mean Absolute Error and 18.8% in Mean Squared Error. This enhancement in predictive accuracy provides a robust tool for capturing the evolving trends in carbon dioxide emissions, thereby offering a solid quantitative foundation to support data-driven decision-making in urban carbon reduction policies.},
  archive      = {J_EAAI},
  author       = {Daishun Cui and Qin Jiwei and Dezhi Sun and Xizhong Qin and Fei Shi},
  doi          = {10.1016/j.engappai.2025.110366},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {7},
  pages        = {110366},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel koopman-based assistant features network for long and short-term carbon emission prediction},
  volume       = {151},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ejor---44">EJOR - 44</h2>
<ul>
<li><details>
<summary>
(2025). Investigating the research and development performance of
chinese industry: A two-stage prospect data envelopment analysis
approach. <em>EJOR</em>, <em>323</em>(3), 1040–1059. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With growing investments inindustry research and development (R&amp;D) innovation in China, evaluating whether R&amp;D resources assigned to industries areeffectively used is essential. However, limited research has been conducted on the assessment of R&amp;D effectiveness in Chinese industries that encompasses both the internal process of R&amp;D production and the psychological risks encountered by decision-makers (DMs).Hence, this study puts forward a two-stage prospect data envelopment analysis approach that can characterise the risk attitude of DM in evaluation. By employing this approach, we assess the R&amp;D activities of 28 industries in China from an overall perspective and explore the actual influence of DMs’ risk psychology on the evaluation results through sensitivity and comparative analyses. Furthermore, we categorise the R&amp;D performance of 28 Chinese industries into four quadrants for analysis and focus on the R&amp;D performance of key industries such as extraction of petroleum and natural gas, mining of ferrous metal ores and manufacture of tobacco. Based on the findings, we provide a range of policy recommendations regarding the R&amp;D activities of Chinese industries.},
  archive      = {J_EJOR},
  author       = {Hui-hui Liu and Guo-liang Yang and Jian-wei Gao and Ya-ping Wang and Guo-hua Ni},
  doi          = {10.1016/j.ejor.2025.01.002},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1040-1059},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Investigating the research and development performance of chinese industry: A two-stage prospect data envelopment analysis approach},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Business cycle and realized losses in the consumer credit
industry. <em>EJOR</em>, <em>323</em>(3), 1024–1039. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the determinants of losses given default (LGD) in consumer credit. Utilizing a unique dataset encompassing over 6 million observations of Italian consumer credit over a long time span, we find that macroeconomic and social (MS) variables significantly enhance the forecasting performance at both individual and portfolio levels, improving R 2 by up to 10 percentage points. Our findings are robust across various model specifications. Non-linear forecast combination schemes employing neural networks consistently rank among the top performers in terms of mean absolute error, RMSE, R 2 , and model confidence sets in every tested scenario. Notably, every model that belongs to the superior set systematically includes MS variables. The relationship between expected LGD and macro predictors, as revealed by accumulated local effects plots and Shapley values, supports the intuition that lower real activity, a rising cost-of-debt to GDP ratio, and heightened economic uncertainty are associated with higher LGD for consumer credit. Our results on the influence of MS variables complement and slightly differ from those of related papers. These discrepancies can be attributed to the comprehensive nature of our database – spanning broader dimensions in space, time, sectors, and types of consumer credit – the variety of models utilized, and the analyses conducted.},
  archive      = {J_EJOR},
  author       = {Walter Distaso and Francesco Roccazzella and Frédéric Vrins},
  doi          = {10.1016/j.ejor.2024.12.026},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1024-1039},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Business cycle and realized losses in the consumer credit industry},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expected information of noisy attribute forecasts for
probabilistic forecasts. <em>EJOR</em>, <em>323</em>(3), 1013–1023. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper extends the maximum entropy (ME) model to include uncertainty about noisy moment forecasts. In this framework the noise propagates to the ME model through the constrained optimization’s Lagrange multipliers. The mutual information and expected Fisher information are included for assessing effects of the noisy moment forecasts on the ME model and its parameters. A new mean–variance decomposition of the mutual information is derived for the normal distribution when the mean and variance are both noisy. A simulation estimator is used to estimate the expected information for noisy ME models on finite support. A family of ensemble of individual level noisy ME forecast models is introduced which includes individual level versions of the conditional logit and multiplicative competitive interaction models as specific cases. To illustrate the implementation and merits of the proposed noisy ME framework, the classic loaded dice problem and discrete choice analysis are examined.},
  archive      = {J_EJOR},
  author       = {Omid M. Ardakani and Robert F. Bordley and Ehsan S. Soofi},
  doi          = {10.1016/j.ejor.2024.12.024},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {1013-1023},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Expected information of noisy attribute forecasts for probabilistic forecasts},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Does the quantity discount mechanism offer a loophole for
retailer collusion? Impacts and responses. <em>EJOR</em>,
<em>323</em>(3), 999–1012. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantity discount mechanism is an effective and widely used tool by manufacturers to encourage downstream retailers to increase their order volumes. As wholesale prices decrease with larger order quantities, retailers have an incentive to collude and achieve joint procurement. Two joint procurement modes—group buying (GB) and agency procurement (AP)—are considered to characterize the phenomenon of retailer collusion. In GB mode, retailers purchase as a group and enjoy the same per-unit wholesale price. In contrast, in the AP mode, a leading retailer assumes responsibility for aggregating orders and submitting the total order to the manufacturer while having the authority to set the resale price. A dual-channel model is developed to investigate joint procurement among competing retailers, aiming to identify its underlying driving forces and impacts. Our findings indicate that, compared to individual purchasing (IP), GB is always attainable for retailers, whereas AP is only attainable under intense competition when retailers are symmetric. We reveal that retailers engaging in joint procurement do not always aim to achieve lower wholesale prices. In some cases, the objective may be to mitigate price competition. This finding suggests that joint procurement by retailers results in a reduction in total order quantity, which significantly diminishes the manufacturer’s profit. In response to the challenges of retailer collusion, we explore the feasibility and potential value of offering a coordinated quantity discount mechanism, wherein the manufacturer gives up the pursuit of maximizing its own profit in favor of optimizing the profits of the entire supply chain, making concessions to the retailers. We identify the scenarios in which a coordinated quantity discount contract can eliminate the loophole for retailer collusion and highlight both the value and necessity of achieving contract coordination.},
  archive      = {J_EJOR},
  author       = {Shaofu Du and Xiahui Sun and Li Hu and Tsan-Ming Choi},
  doi          = {10.1016/j.ejor.2024.12.007},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {999-1012},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Does the quantity discount mechanism offer a loophole for retailer collusion? impacts and responses},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-activity shift scheduling under uncertainty: The value
of shift flexibility. <em>EJOR</em>, <em>323</em>(3), 988–998. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a multi-activity shift scheduling problem under demand uncertainty, exploring various levels of flexibility in adapting aspects of the shift schedule (e.g., activity assignment, break assignment, selection of shift type and shift end time) to late-arriving demand information. To address the resulting complex two-stage stochastic combinatorial optimisation problems, we propose a novel two-stage stochastic mixed-integer programming formulation leveraging state-expanded networks and a clustering-based sequential sampling approach for efficiently solving large-scale problem instances. In computational experiments on stochastic problems derived from well-known multi-activity shift scheduling instances, we show that this method effectively solves instances with up to 10 activities and 100 demand scenarios, approaching near-optimality within an average time of less than one hour. From a managerial standpoint, our study provides insights into the structure of good first-stage scheduling decisions as well as into the impact of different flexibility levels on expected costs of the solutions, thereby offering valuable support for decisions such as adjusting employees’ salaries in exchange for increased shift flexibility.},
  archive      = {J_EJOR},
  author       = {Felix Hagemann and Till Frederik Porrmann and Michael Römer},
  doi          = {10.1016/j.ejor.2024.12.028},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {988-998},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Multi-activity shift scheduling under uncertainty: The value of shift flexibility},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Measuring technical efficiency under variable returns to
scale using debreu’s loss function. <em>EJOR</em>, <em>323</em>(3),
975–987. (<a href="https://doi.org/10.1016/j.ejor.2024.12.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a model that makes two contributions to the measurement of technical efficiency under a technology with variable returns to scale. First, the criteria for identifying an optimal benchmark are not limited to technical dominance and Pareto efficiency, but also include maximum average productivity, defined as the ratio between a weighted linear aggregate of outputs and inputs. Second, the paper contributes a conceptual basis for correcting the shadow prices of inputs and outputs to reflect the influence of returns to scale. Debreu&#39;s loss function is used to value inefficiency as the difference between the virtual input and output using the shadow prices of the supporting hyperplane at the optimal reference. The efficiency score is a virtual profitability index with endogenous shadow prices that reflect the valuation of inputs and outputs with a microeconomic rationale, i.e., it is not a distance measure based on aggregation with exogenous weights of the difference between observed and optimal quantities. Two further results follow from these contributions. First, the radial input-output orientation to maximise productivity is endogenous. It is conditioned by the nature of the returns to scale. Second, the efficiency measure based on the loss function exhibits the desirable properties in a radial context, including the indication property, because the efficiency score incorporates non-radial slack.},
  archive      = {J_EJOR},
  author       = {Juan José Díaz-Hernández and David-José Cova-Alonso and Eduardo Martínez-Budría},
  doi          = {10.1016/j.ejor.2024.12.050},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {975-987},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Measuring technical efficiency under variable returns to scale using debreu&#39;s loss function},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The copeland ratio ranking method for abstract decision
problems. <em>EJOR</em>, <em>323</em>(3), 966–974. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of ranking a finite number of alternatives on the basis of a dominance relation. We firstly investigate some disadvantages of the Copeland ranking method, of the degree ratio ranking method and of the modified degree ratio ranking method which were characterized by using clone properties and classical axiomatic properties. Then, we introduce some alternative axiomatic properties and propose a new ranking method which is defined by the Copeland ratio of alternatives (i.e., the Copeland score of an alternative divided by its total degree). We show that this proposed ranking method coincides with the Copeland ranking method, the degree ratio ranking method and the modified degree ratio ranking method for abstract decision problems with complete and asymmetric dominance relations. Subsequently, we prove that this new ranking method is able to overcome the mentioned disadvantages of these ranking methods. After that, we provide a characterization for the Copeland ratio ranking method using the introduced axiomatic properties.},
  archive      = {J_EJOR},
  author       = {Weibin Han and Adrian Van Deemen},
  doi          = {10.1016/j.ejor.2024.12.042},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {966-974},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The copeland ratio ranking method for abstract decision problems},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective evolutionary algorithm with
mutual-information-guided improvement phase for feature selection in
complex manufacturing processes. <em>EJOR</em>, <em>323</em>(3),
952–965. (<a href="https://doi.org/10.1016/j.ejor.2024.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex manufacturing processes (CMP) involve numerous features that impact product quality. Therefore, selecting key process features (KPF) is crucial for effective quality prediction and control in CMPs. This paper proposes a KPF (feature) selection method for the high-dimensional CMP data. The KPF selection problem is formulated as a bi-objective combinatorial optimization task of maximizing the geometric mean measure and minimizing the number of selected features. To solve this challenging high-dimensional KPF selection problem, we propose a novel multi-objective evolutionary algorithm (MOEA) called NSGAII-MIIP. NSGAII-MIIP applies an improvement phase (called MIIP) to purify the non-dominated solutions obtained by genetic operators during the iteration process to improve the FS performance. The improvement phase is guided by a mutual-information-based feature importance measure considering both a feature’s relevance degree to class (product quality level) and its redundancy degree to selected features. This allows MIIP to efficiently update non-dominated solutions by selecting relevant features and eliminating redundant features. Moreover, MIIP is seamlessly integrated into the solution ranking process of NSGAII-MIIP so that solutions from the improvement phase can be ranked together with original solutions in the population efficiently. Experiments on eight datasets show that NSGAII-MIIP has better KPF selection performance than eight state-of-the-art multi-objective FS methods. Moreover, NSGAII-MIIP exhibits superior search performance compared to eight typical multi-objective optimization algorithms.},
  archive      = {J_EJOR},
  author       = {An-Da Li and Zhen He and Qing Wang and Yang Zhang and Yanhui Ma},
  doi          = {10.1016/j.ejor.2024.12.036},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {952-965},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A multi-objective evolutionary algorithm with mutual-information-guided improvement phase for feature selection in complex manufacturing processes},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Opinion convergence and management: Opinion dynamics in
interactive group decision-making. <em>EJOR</em>, <em>323</em>(3),
938–951. (<a href="https://doi.org/10.1016/j.ejor.2024.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making processes are significantly influenced by internal social network interactions and external information inputs. While previous research has highlighted the role of social networks in opinion evolution, the dynamics of information dissemination and its interaction with these networks are less understood. To bridge this gap, we introduce the Social-Information-Opinion Dynamic Supernetwork (SIO-DS) model, which integrates critical factors such as the impact of external information and opinion propagation, alongside the influence of internal social network structures and individual willingness to adjust opinions. This model takes into account the varied levels of confidence and individualized dynamic influence among decision makers, recognizing both their asymmetry and diversity. It performs opinion dynamics using bounded confidence models and parameters that govern information dissemination. We found that scale-free networks, which feature influential leaders, are more effective at reaching consensus compared to small-world networks, which are hindered by limited inter-group connections. The speed of information dissemination is critical; moderate speeds help in maintaining a stable consensus by balancing social influence, while very fast or slow speeds risk exacerbating polarization based on how social influence is managed. The SIO-DS model has broad implications for enhancing decision-making in corporate management by optimizing network structures, in public policy by managing public opinion, and in crisis management by developing effective communication strategies. Ultimately, this model not only deepens our understanding of opinion dynamics but also provides practical tools for improving decision-making quality and efficiency in various contexts.},
  archive      = {J_EJOR},
  author       = {Yuan Xu and Shifeng Liu and T.C.E. Cheng and Xue Feng and Jun Wang and Xiaopu Shang},
  doi          = {10.1016/j.ejor.2024.12.046},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {938-951},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Opinion convergence and management: Opinion dynamics in interactive group decision-making},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven preference learning methods for sorting problems
with multiple temporal criteria. <em>EJOR</em>, <em>323</em>(3),
918–937. (<a href="https://doi.org/10.1016/j.ejor.2024.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present novel preference learning approaches for sorting problems with multiple temporal criteria. They leverage an additive value function as the basic preference model, adapted for accommodating time series data. Given assignment examples concerning reference alternatives, we learn such a model using convex quadratic programming. It is characterized by fixed-time discount factors and operates within a regularization framework. This approach enables the consideration of temporal interdependencies between timestamps while mitigating the risk of overfitting. To enhance scalability and accommodate learnable time discount factors, we introduce a novel monotonic Recurrent Neural Network (mRNN). It captures the evolving dynamics of preferences over time, while upholding critical properties inherent to multiple criteria sorting problems. These include criteria monotonicity, preference independence, and the natural ordering of classes. The proposed mRNN can describe the preference dynamics by depicting piecewise linear marginal value functions and personalized time discount factors along with time. Thus, it effectively combines the interpretability of traditional sorting methods with the predictive potential offered by deep preference learning models. We comprehensively assess the proposed models on synthetic data scenarios and a real-case study centered on classifying valuable users within a mobile gaming app based on their historical in-game behavioral sequences. Empirical findings underscore the notable performance improvements achieved by the proposed models when compared to a spectrum of baseline methods, spanning machine learning, deep learning, and conventional multiple criteria sorting approaches.},
  archive      = {J_EJOR},
  author       = {Yijun Li and Mengzhuo Guo and Miłosz Kadziński and Qingpeng Zhang and Chenxi Xu},
  doi          = {10.1016/j.ejor.2024.12.020},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {918-937},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Data-driven preference learning methods for sorting problems with multiple temporal criteria},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conical free disposal hull estimators of directional
distances and luenberger productivity indices for general technologies.
<em>EJOR</em>, <em>323</em>(3), 907–917. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directional distances are a popular tool in productivity and efficiency analysis due to their versatility in evaluating the distance of Decision Making Units (DMU) to the efficient frontier of the production set. The theoretical and statistical properties of these measures are well-established in various contexts. However, the measurement of directional distances to the cone spanned by the attainable set has not yet been explored. This cone is necessary to define the Luenberger indices for general technologies. This paper aims to fill this gap by presenting a method for defining and estimating directional distances to this cone, applicable to general technologies without imposing convexity. We also discuss the statistical properties of these measures, enabling us to measure distances to non-convex attainable sets under Constant Returns to Scale (CRS), as well as measure and estimate Luenberger productivity indices and their decompositions for general technologies. In addition, we provide a detailed description of how to make inferences on these indices. Finally, we offer simulated data and a practical example of inference on Luenberger productivity indices and their decompositions using a well-known real data set.},
  archive      = {J_EJOR},
  author       = {Cinzia Daraio and Simone Di Leo and Léopold Simar},
  doi          = {10.1016/j.ejor.2024.12.025},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {907-917},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Conical free disposal hull estimators of directional distances and luenberger productivity indices for general technologies},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The collaborative berth allocation problem with
row-generation algorithms for stable cost allocations. <em>EJOR</em>,
<em>323</em>(3), 888–906. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent supply chain disruptions and crisis response policies (e.g., the COVID-19 pandemic and the Red Sea crisis) have highlighted the role of container terminals as crucial and scarce resources in the global economy. To tackle these challenges, the industry increasingly aims for advanced operational collaboration among multiple stakeholders, as demonstrated by the ambitions of the recently founded Gemini alliance. Nonetheless, collaborative planning models often disregard the requirements and incentives of stakeholders or simply solve idealized small instances. Motivated by the above, we design novel and effective collaboration mechanisms among terminal operators that share the resources (berths and quay cranes). We first define the collaborative berth allocation problem and propose a mixed integer linear programming (MILP) model to minimize the total cost of all terminals, referred to as the coalitional costs. We adopt the core and the nucleolus concepts from cooperative game theory to allocate the coalitional costs such that stakeholders have stable incentives to collaborate. To obtain solutions for realistic instance sizes, we propose two exact row-generation-based core and nucleolus algorithms that are versatile and can be used for various combinatorial optimization problems. To the best of our knowledge, the proposed row-generation approach for the nucleolus is the first of its kind for combinatorial optimization problems. Extensive experiments demonstrate that the collaborative berth allocation approach achieves up to 28.44% of cost savings, increasing the solution space in disruptive situations, while the proposed core and nucleolus solutions guarantee the collaboration incentives for individual terminals.},
  archive      = {J_EJOR},
  author       = {Xiaohuan Lyu and Eduardo Lalla-Ruiz and Frederik Schulte},
  doi          = {10.1016/j.ejor.2024.12.048},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {888-906},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The collaborative berth allocation problem with row-generation algorithms for stable cost allocations},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategic decentralization of self-branded and contract
manufacturing businesses. <em>EJOR</em>, <em>323</em>(3), 868–887. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the incentive of a competitive contract manufacturer (CCM) to adopt a decentralized structure by segregating contract manufacturing from its self-branded business. We consider an original equipment manufacturer (OEM) with the option to outsource production either to a CCM producing its self-branded product, or to a non-competitive contract manufacturer (NCM) also serving another OEM. The CCM has the option to centralize or decentralize its two businesses and competes in quantity with both OEMs in the end-user market. Our analysis of the strategic interactions between the OEM&#39;s outsourcing decision and the CCM&#39;s organizational structure choice shows that the likelihood of the OEM outsourcing to the CCM increases when the CCM adopts a decentralized structure compared to a centralized one. Under decentralization, a sufficiently low wholesale price offered by the contract manufacturing division provides the OEM with a competitive advantage. Consequently, the CCM is motivated to strategically deploy a decentralized structure to attract contract manufacturing business from the OEM, even though decentralization yields a lower profit than centralization. However, the CCM must be cautious when implementing a decentralized structure to secure orders from the OEM. The resulting intensified market competition undermines its profit from self-branded business and potentially makes it worse off from producing for the OEM. In such case, the CCM should maintain a centralized structure and uphold a purely competitive relationship with the OEM. Moreover, we demonstrate how the profitability of another OEM supplied by the NCM is influenced by the interplay between the CCM and the OEM.},
  archive      = {J_EJOR},
  author       = {Wei Li and Yanglei Li and Jing Chen and Bintong Chen},
  doi          = {10.1016/j.ejor.2025.01.017},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {868-887},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Strategic decentralization of self-branded and contract manufacturing businesses},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Managing social responsibility efforts with the
consideration of violation probability. <em>EJOR</em>, <em>323</em>(3),
852–867. (<a href="https://doi.org/10.1016/j.ejor.2025.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Corporate social responsibility (CSR) has a strong impact on the external image of the enterprise. The violation of CSR not only harms the enterprise but also negatively affects other firms in the supply chain. This paper establishes a game-theoretical model to study the management of social responsibility efforts with considerations of violation probability. The upstream manufacturer and downstream retailer can reduce the violation probability by exerting CSR efforts. Specifically, we study the following four models, including both participants exerting efforts, only the manufacturer exerting effort, only the retailer exerting effort, and neither participant exerting effort. Our analysis shows that as the effort cost of the manufacturer increases, the retailer may increase or decrease his effort level under both participants exerting efforts, due to the complementary and substitution effects between the efforts of the manufacturer and retailer. We also find that compared with both participants exerting efforts, the retailer may increase or decrease his effort level under only the retailer exerting effort, and the effort level of the manufacturer may grow or shrink under only the manufacturer exerting effort. In addition, we study the decision matrix for the manufacturer and retailer, and find that in equilibrium the manufacturer always has incentives to exert CSR effort, while the retailer may prefer a free ride and sometimes chooses not to exert effort. Interestingly, we find that the total supply chain profit may not be the highest under both participants exerting efforts, but it is the lowest under neither participant exerting effort.},
  archive      = {J_EJOR},
  author       = {Jiayan Xu and Housheng Duan and Sijing Deng},
  doi          = {10.1016/j.ejor.2025.01.016},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {852-867},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Managing social responsibility efforts with the consideration of violation probability},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact algorithms for routing electric autonomous mobile
robots in intralogistics. <em>EJOR</em>, <em>323</em>(3), 830–851. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In intralogistics and manufacturing, autonomous mobile robots (AMRs) are usually electrically powered and recharged by battery swapping or induction. We investigate AMR route planning in these settings by studying different variants of the electric vehicle routing problem with due dates (EVRPD). We consider three common recharging strategies: battery swapping, inductive recharging with full recharges, and inductive recharging with partial recharges. Moreover, we consider two different objective functions: the standard objective of minimizing the total distance traveled and the minimization of the total completion times of transport jobs. The latter is of particular interest in intralogistics, where time aspects are of crucial importance and the earliest possible completion of jobs often has priority. In this context, recharging decisions also play an essential role. For solving the EVRPD variants, we propose exact branch-price-and-cut algorithms that rely on ad-hoc labeling algorithms tailored to the respective variants. We perform an extensive computational study to generate managerial insights on the AMR route planning problem and to assess the performance of our solution approach. The experiments are based on newly introduced instances featuring typical characteristics of AMR applications in intralogistics and manufacturing and on standard benchmark instances from the literature. The detailed analysis of our results reveals that inductive recharging with partial recharges is competitive with battery swapping, while using a full-recharges strategy has considerable drawbacks in an AMR setup.},
  archive      = {J_EJOR},
  author       = {Anne Meyer and Timo Gschwind and Boris Amberg and Dominik Colling},
  doi          = {10.1016/j.ejor.2024.12.041},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {830-851},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exact algorithms for routing electric autonomous mobile robots in intralogistics},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexibility-based price discrimination in a competitive
context considering consumers’ socioeconomic status. <em>EJOR</em>,
<em>323</em>(3), 810–829. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study examines the impact of flexibility-based price discrimination (FBPD) on the pricing and quality strategy of the adopting firm and its competitor, as well as the impact on the welfare of consumers. We assume that the inflexible consumers being targeted for price discrimination can be either high-income consumers or low-income consumers, and the high-income consumers are more sensitive to product quality. We show that depending on who the targeted inflexible consumers are, the impact of FBPD on all firms and consumers can be either negative or positive. If an FBPD is to exploit the inflexibility of low-income consumers, it will not only make the vulnerable group even more disadvantaged but also lower the firms’ incentive to produce high-quality products. On the contrary, if an FBPD is to exploit the inflexibility of high-income consumers, it will increase the firms’ incentive to produce high-quality products, and the targeted consumers will be compensated by having higher quality products. However, the firms might engage in excessive quality enhancement, leading to a situation where the competition between the firms falls into a prisoner’s dilemma. Our research results suggest that the application of FBPD could necessitate a comprehensive regulatory framework to ensure ethical implementation while safeguarding consumer welfare, particularly that of vulnerable groups.},
  archive      = {J_EJOR},
  author       = {Jian Zhang and Emily B. Laidlaw and Raymond A. Patterson},
  doi          = {10.1016/j.ejor.2025.01.005},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {810-829},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flexibility-based price discrimination in a competitive context considering consumers’ socioeconomic status},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coordinate or collaborate? Reducing food waste in
perishable-product supply chains. <em>EJOR</em>, <em>323</em>(3),
795–809. (<a href="https://doi.org/10.1016/j.ejor.2024.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reducing food waste in supply chains (SCs) with multiple decision-makers is challenging. A common approach grocery retailers use to reduce waste is requiring manufacturers to only send products with a long remaining shelf life (“minimum life on receipt”-MLOR). However, its impact on manufacturers remains unclear. To evaluate the effectiveness of MLOR agreements on food waste, we investigate two strategies: (1) collaborating on setting the MLOR level and (2) coordinating the SC via contract. Through collaboration, we analytically show that if the MLOR agreement does not demand solely fresh products, it raises manufacturer profits, enabling potential wholesale price reduction. This might incentivize retailers to collaborate to reduce the MLOR level. We demonstrate that the coordinating strategy can reduce waste in the SC and is most beneficial when the wholesale price is high, and the issuing policy is FIFO. We introduce possible coordination contracts and show that in coordinated SCs, manufacturers always provide the highest MLOR level without requiring any restrictive MLOR agreements. Governments mainly focus on reducing retail waste and promoting retailers to request higher MLOR. However, these efforts can backfire by creating more waste for manufacturers. Reducing the MLOR allows retailers to negotiate lower wholesale prices, increasing profitability while reducing waste. Although SC coordination is known for reducing inefficiency, it may not be the best strategy for reducing waste, especially when the issuing policy is more LIFO than FIFO. Specifically, while coordination might be a better strategy for online retailers, collaboration can be a better strategy for brick-and-mortar retailers.},
  archive      = {J_EJOR},
  author       = {Navid Mohamadi and Sandra Transchel and Jan C. Fransoo},
  doi          = {10.1016/j.ejor.2024.12.039},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {795-809},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Coordinate or collaborate? reducing food waste in perishable-product supply chains},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Judgmental selection of parameters for simple forecasting
models. <em>EJOR</em>, <em>323</em>(3), 780–794. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In an era dominated by big data and machine and deep learning solutions, judgment has still an important role to play in decision making. Behavioural operations are on the rise as judgment complements automated algorithms in many practical settings. Over the years, new and exciting uses of judgment have emerged, with some providing fresh and innovative insights on algorithmic approaches. The forecasting field, in particular, has seen judgment infiltrating in several stages of the forecasting process, such as the production of purely judgmental forecasts, judgmental revisions of formal (statistical) forecasts, and as an alternative to statistical selection between forecasting models. In this paper, we take the first steps towards exploring a neglected use of judgment in forecasting: the manual selection of the parameters for forecasting models. We focus on a simple but widely-used forecasting model, the Simple Exponential Smoothing, and, through a behavioural experiment, we investigate the performance of individuals versus algorithms in selecting optimal modelling parameters under different conditions. Our results suggest that the use of judgment on the task of parameter selection could improve forecasting accuracy. However, individuals also suffer from anchoring biases.},
  archive      = {J_EJOR},
  author       = {Fotios Petropoulos and Evangelos Spiliotis},
  doi          = {10.1016/j.ejor.2024.12.034},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {780-794},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Judgmental selection of parameters for simple forecasting models},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trade-off between utility and fairness in two-agent
single-machine scheduling. <em>EJOR</em>, <em>323</em>(3), 767–779. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem arising when two agents, each owning a set of jobs, compete to schedule their jobs on a common processing resource. Each schedule implies a certain utility for each agent and an overall system utility. We are interested in solutions that incorporate some criterion of fairness for the agents and, at the same time, are satisfactory from the viewpoint of system utility. More precisely, we investigate the trade-off between fairness and system utility when both agents want to minimize the total completion time of their respective jobs. We analyze the structure of the set of such trade-off solutions, and propose an exact algorithm for their computation, based on the Lagrangian relaxation of a MILP formulation of the problem. A large set of computational experiments has been carried out to show the viability of the approach. Moreover, the results show that in most cases a solution having a high degree of fairness can be obtained by sacrificing a very limited amount of system utility.},
  archive      = {J_EJOR},
  author       = {Alessandro Agnetis and Mario Benini and Gaia Nicosia and Andrea Pacifici},
  doi          = {10.1016/j.ejor.2025.01.025},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {767-779},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Trade-off between utility and fairness in two-agent single-machine scheduling},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new effective heuristic for the prisoner transportation
problem. <em>EJOR</em>, <em>323</em>(3), 753–766. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Prisoner Transportation Problem is an NP-hard combinatorial problem and a complex variant of the Dial-a-Ride Problem. Given a set of requests for pick-up and delivery and a homogeneous fleet, it consists of assigning requests to vehicles to serve all requests, respecting the problem constraints such as route duration, capacity, ride time, time windows, multi-compartment assignment of conflicting prisoners and simultaneous services in order to optimize a given objective function. In this paper, we present a new solution framework to address this problem that leads to an efficient heuristic. A comparison with computational results from previous papers shows that the heuristic is very competitive for some classes of benchmark instances from the literature and clearly superior in the remaining cases. Finally, suggestions for future studies are presented.},
  archive      = {J_EJOR},
  author       = {Luciano Ferreira and Marcos Vinicius Milan Maciel and José Valério de Carvalho and Elsa Silva and Filipe Pereira Alvelos},
  doi          = {10.1016/j.ejor.2025.01.029},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {753-766},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A new effective heuristic for the prisoner transportation problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Formulations and branch-and-cut algorithms for the period
travelling salesman problem. <em>EJOR</em>, <em>323</em>(3), 739–752.
(<a href="https://doi.org/10.1016/j.ejor.2025.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we address two variants of the Period Travelling Salesman Problem: one where some nodes cannot be visited consecutively over the time horizon, and another one where this restriction is not imposed. A new flow-based formulation that uses specific information about the visit patterns of nodes is studied and empirical tests show that it is able to solve test instances where a flow-based formulation based on the Single Commodity Flow formulation for the Travelling Salesman Problem reached the time limit. Non-compact formulations are studied in this work as well. We propose two new sets of exponentially-sized valid inequalities that have not been studied yet in the literature. A formulation which is based on connectivity cuts per period enhanced with these sets of valid inequalities proved to be the most efficient and it was able to solve several instances.},
  archive      = {J_EJOR},
  author       = {Sofia Henriques and Ana Paias},
  doi          = {10.1016/j.ejor.2025.01.015},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {739-752},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Formulations and branch-and-cut algorithms for the period travelling salesman problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness in repetitive scheduling. <em>EJOR</em>,
<em>323</em>(3), 724–738. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research found that fairness plays a key role in customer satisfaction. Therefore, many manufacturing and services industries have become aware of the need to treat customers fairly. Still, there is a huge lack of models that enable industries to make operational decisions fairly, such as a fair scheduling of the customers’ jobs. Our main aim in this research is to provide a unified framework to enable schedulers to make fair decisions in repetitive scheduling environments. For doing so, we consider a set of repetitive scheduling problems involving a set of n clients. In each out of q consecutive operational periods ( e.g. days), each one of the customers submits a job for processing by an operational system. The scheduler’s aim is to provide a schedule for each of the q periods such that the quality of service (QoS) received by each of the clients will meet a certain predefined threshold. The QoS of a client may take several different forms, e.g. , the number of days that the customer receives its job later than a given due date, the number of times the customer receives his preferred time slot for service, or the sum of waiting times for service. We analyze the single machine variant of the problem for several different definitions of QoS, and classify the complexity of the corresponding problems using the theories of classical and parameterized complexity. We also study the price of fairness, i.e., the loss in the system’s efficiency that results from the need to provide fair solutions.},
  archive      = {J_EJOR},
  author       = {Danny Hermelin and Hendrik Molter and Rolf Niedermeier and Michael Pinedo and Dvir Shabtay},
  doi          = {10.1016/j.ejor.2024.12.052},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {724-738},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fairness in repetitive scheduling},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the parallel processor scheduling and bin packing
problems with contiguity constraints: Mathematical models and
computational studies. <em>EJOR</em>, <em>323</em>(3), 701–723. (<a
href="https://doi.org/10.1016/j.ejor.2024.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The parallel processor scheduling and bin packing problems with contiguity constraints are important in the field of combinatorial optimization because both problems can be used as components of effective exact decomposition approaches for several two-dimensional packing problems. In this study, we provide an extensive review of existing mathematical formulations for the two problems, together with some model enhancements and lower bounding techniques, and we empirically evaluate the computational behavior of each of these elements using a state-of-the-art solver on a large set of literature instances. We also assess whether recent developments such as meet-in-the middle patterns and the reflect formulation can be used to solve the two problems more effectively. Our experiments demonstrate that some features, such as the mathematical model used, have a major impact on whether an approach is able to solve an instance, whereas other features, such as the use of symmetry-breaking constraints, do not bring any empirical advantage despite being useful in theory. Overall, our goal is to help the research community design more effective yet simpler algorithms to solve the parallel processor scheduling and bin packing problems with contiguity constraints and closely related extensions so that, eventually, those can be integrated into a larger number of exact methods for two-dimensional packing problems.},
  archive      = {J_EJOR},
  author       = {Fatih Burak Akçay and Maxence Delorme},
  doi          = {10.1016/j.ejor.2024.09.013},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {3},
  pages        = {701-723},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving the parallel processor scheduling and bin packing problems with contiguity constraints: Mathematical models and computational studies},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Milk adulteration testing and impact of farmers efficiency
heterogeneity: A strategic analysis. <em>EJOR</em>, <em>323</em>(2),
686–700. (<a href="https://doi.org/10.1016/j.ejor.2024.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by economic motives, dairy farmers adulterate milk to increase its perceived quality, posing a serious risk to consumer health. We analyse a milk supply chain in which smallholder dairy farmers can adulterate milk and explore the feasibility of selling it to end consumers through an aggregator. Using a non-cooperative sequential game between the aggregator and farmers, we examine the impact of two testing strategies offered by the aggregator to curb adulteration - (i) individual (testing milk procured from each farmer individually) and (ii) composite (testing the milk after aggregating the portions procured from all the farmers). Our analyses reveal that the aggregator can control milk adulteration by judiciously using testing and penalty mechanisms. We find that a higher market price (aggregation effect) , fetched by the aggregator because of its bargaining power owing to the consolidation of milk supplies, is essential for its operation. It leads to higher revenue for the aggregator and expands the zone in which it is profitable for the aggregator to operate. However, our results show that the efficiency heterogeneity among farmers, which leads to the less efficient farmers free-riding on the more efficient ones, has a detrimental effect on the aggregator operation. We also explore the impact of external uncertainties on the supply chain and observe that the composite testing strategy becomes more profitable for the aggregator when external uncertainties increase. Our results provide important policy recommendations for aggregators adopting optimal testing strategies.},
  archive      = {J_EJOR},
  author       = {Samir Biswas and Preetam Basu and Balram Avittathur},
  doi          = {10.1016/j.ejor.2024.12.001},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {686-700},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Milk adulteration testing and impact of farmers efficiency heterogeneity: A strategic analysis},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from the aggregated optimum: Managing port wine
inventory in the face of climate risks. <em>EJOR</em>, <em>323</em>(2),
671–685. (<a href="https://doi.org/10.1016/j.ejor.2024.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Port wine stocks ameliorate during storage, facilitating product differentiation according to age. This induces a trade-off between immediate revenues and further maturation. Varying climate conditions in the limited supply region lead to stochastic purchase prices for wine grapes. Decision makers must integrate recurring purchasing, production, and issuance decisions. Because stocks from different age classes can be blended to create final products, the solution space increases exponentially in the number of age classes. We model the problem of managing port wine inventory as a Markov decision process, considering decay as an additional source of uncertainty. For small problems, we derive general management strategies from the long-run behavior of the optimal policy. Our solution approach for otherwise intractable large problems, therefore, first aggregates age classes to create a tractable problem representation. We then use machine learning to train tree-based decision rules that reproduce the optimal aggregated policy and the enclosed management strategies. The derived rules are scaled back to solve the original problem. Learning from the aggregated optimum outperforms benchmark rules by 21.4% in annual profits (while leaving a 2.8%-gap to an upper bound). For an industry case, we obtain a 17.4%-improvement over current practices. Our research provides distinct strategies for how producers can mitigate climate risks. The purchasing policy dynamically adapts to climate-dependent price fluctuations. Uncertainties are met with lower production of younger products, whereas strategic surpluses of older stocks ensure high production of older products. Moreover, a wide spread in the age classes used for blending reduces decay risk exposure.},
  archive      = {J_EJOR},
  author       = {Alexander Pahr and Martin Grunow and Pedro Amorim},
  doi          = {10.1016/j.ejor.2024.11.046},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {671-685},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Learning from the aggregated optimum: Managing port wine inventory in the face of climate risks},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible enhanced indexation models through stochastic
dominance and ordered weighted average optimization. <em>EJOR</em>,
<em>323</em>(2), 657–670. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss portfolio selection strategies for Enhanced Indexation (EI), which are based on stochastic dominance relations. The goal is to select portfolios that stochastically dominate a given benchmark but that, at the same time, must generate some excess return with respect to a benchmark index. To achieve this goal, we propose a new methodology that selects portfolios using the ordered weighted average (OWA) operator, which generalizes previous approaches based on minimax selection rules and still leads to solving linear programming models. We also introduce a new type of approximate stochastic dominance rule and show that it implies the almost Second-order Stochastic Dominance (SSD) criterion proposed by Lizyayev and Ruszczyński (2012). We prove that our EI model based on OWA selects portfolios that dominate a given benchmark through this new form of stochastic dominance criterion. We test the performance of the obtained portfolios in an extensive empirical analysis based on real-world datasets. The computational results show that our proposed approach outperforms several SSD-based strategies widely used in the literature, as well as the global minimum variance portfolio.},
  archive      = {J_EJOR},
  author       = {Francesco Cesarone and Justo Puerto},
  doi          = {10.1016/j.ejor.2024.11.050},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {657-670},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flexible enhanced indexation models through stochastic dominance and ordered weighted average optimization},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal fulfillment and replenishment for omnichannel
retailers with standard shipping contracts. <em>EJOR</em>,
<em>323</em>(2), 642–656. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce sales rise exponentially and represent an increasing proportion of global retail. To benefit from this, traditional brick-and-mortar stores enter the e-commerce market and become omnichannel retailers. However, the profitability of omnichannel retailers remains questionable due to high shipment and fulfillment costs. This paper addresses this challenge, focusing on using standard shipping contracts as a potential solution. Such contracts promise delivery within a given number of periods. Once a customer orders, the retailer should set a delivery period. In this way, retailers are flexible in setting exact delivery days, providing an opportunity for jointly optimizing product replenishment and customer fulfillment. We provide a generic model for the use of standard shipping contracts and formulate it as a Markov decision process. We provide optimal solutions using a modified policy iteration algorithm. Our results show that using standard shipping contracts creates a win-win situation: It increases profits and customer service. The observed profit increase is directly linked to maintaining less on-hand inventory. This effect is more pronounced for higher valued products and longer replenishment lead times. Additionally, we propose a heuristic policy that performs within 4% of the optimal policy.},
  archive      = {J_EJOR},
  author       = {Bartu Arslan and Albert H. Schrotenboer and Zümbül Atan},
  doi          = {10.1016/j.ejor.2024.11.051},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {642-656},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal fulfillment and replenishment for omnichannel retailers with standard shipping contracts},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank matrix estimation via nonconvex spectral
regularized methods in errors-in-variables matrix regression.
<em>EJOR</em>, <em>323</em>(2), 626–641. (<a
href="https://doi.org/10.1016/j.ejor.2025.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional matrix regression has been studied in various aspects, such as statistical properties, computational efficiency and application to specific instances including multivariate regression, system identification and matrix compressed sensing. Current studies mainly consider the idealized case that the covariate matrix is obtained without noise, while the more realistic scenario that the covariates may always be corrupted with noise or missing data has received little attention. We consider the general errors-in-variables matrix regression model and proposed a unified framework for low-rank estimation based on nonconvex spectral regularization. Then from the statistical aspect, recovery bounds for any stationary points are provided to achieve statistical consistency. From the computational aspect, the proximal gradient method is applied to solve the nonconvex optimization problem and is proved to converge to a small neighborhood of the global solution in polynomial time. Consequences for concrete models such as matrix compressed sensing models with additive noise and missing data are obtained via verifying corresponding regularity conditions. Finally, the performance of the proposed nonconvex estimation method is illustrated by numerical experiments on both synthetic and real neuroimaging data.},
  archive      = {J_EJOR},
  author       = {Xin Li and Dongya Wu},
  doi          = {10.1016/j.ejor.2025.02.005},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {626-641},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Low-rank matrix estimation via nonconvex spectral regularized methods in errors-in-variables matrix regression},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From collaborative filtering to deep learning: Advancing
recommender systems with longitudinal data in the financial services
industry. <em>EJOR</em>, <em>323</em>(2), 609–625. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RS) are highly relevant for multiple domains, allowing to construct personalized suggestions for consumers. Previous studies have strongly focused on collaborative filtering approaches, but the inclusion of longitudinal data (LD) has received limited attention. To address this gap, we investigate the impact of incorporating LD for recommendations, comparing traditional collaborative filtering approaches, multi-label classifier (MLC) algorithms, and a deep learning model (DL) in the form of gated recurrent units (GRU). Additional analysis for the best performing model is provided through SHapley Additive exPlanations (SHAP), to uncover relations between the different recommended products and features. Thus, this article contributes to operational research literature by (1) comparing several MLC techniques and RS, including state-of-the-art DL models in a real-life scenario, (2) the comparison of various featurization techniques to assess the impact of incorporating LD on MLC performance, (3) the evaluation of LD as sequential input through the use of DL models, (4) offering interpretable model insights to improve the understanding of RS with LD. The results uncover that DL models are capable of extracting information from longitudinal features for overall higher and statistically significant performance. Further, SHAP values reveal that LD has the higher impact on model output and managerial relevant temporal patterns emerge across product categories.},
  archive      = {J_EJOR},
  author       = {Stephanie Beyer Díaz and Kristof Coussement and Arno De Caigny},
  doi          = {10.1016/j.ejor.2025.01.022},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {609-625},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {From collaborative filtering to deep learning: Advancing recommender systems with longitudinal data in the financial services industry},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On enhancing the explainability and fairness of tree
ensembles. <em>EJOR</em>, <em>323</em>(2), 599–608. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree ensembles are one of the most powerful methodologies in Machine Learning. In this paper, we investigate how to make tree ensembles more flexible to incorporate explainability and fairness in the training process, possibly at the expense of a decrease in accuracy. While explainability helps the user understand the key features that play a role in the classification task, with fairness we ensure that the ensemble does not discriminate against a group of observations that share a sensitive attribute. We propose a Mixed Integer Linear Optimization formulation to train an ensemble of trees that, apart from minimizing the misclassification cost, controls for sparsity as well as the accuracy in the sensitive group. Our formulation is scalable in the number of observations since its number of binary decision variables is independent of the number of observations. In our numerical results, we show that for standard datasets used in the fairness literature, we can dramatically enhance the fairness of the benchmark, namely the popular Random Forest, while using only a few features, all without damaging the misclassification cost.},
  archive      = {J_EJOR},
  author       = {Emilio Carrizosa and Kseniia Kurishchenko and Dolores Romero Morales},
  doi          = {10.1016/j.ejor.2025.01.008},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {599-608},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On enhancing the explainability and fairness of tree ensembles},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The manufacturer’s resale strategy for trade-ins.
<em>EJOR</em>, <em>323</em>(2), 583–598. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To cope with the ever-increasing number of used cars, many automobile manufacturers now offer trade-in programs whereby they resell used cars to generate revenue. Consumers have the alternative of selling their used cars via an online peer-to-peer (P2P) resale platform, which charges a commission on each transaction. This paper studies a manufacturer’s traded-in resale strategy and assess how the manufacturer’s resale strategy and profits are affected by the presence of online P2P platforms. We find that in the absence of P2P platforms, the manufacturer may opt against implementing a resale program, whereas it will always do so in the presence of P2P platforms. This suggests a notable shift in manufacturers’ optimal choice of trade-in resale strategies due to the emergence of P2P platforms. Furthermore, the study reveals that the introduction of P2P platforms may diminishes the profits of manufacturers who have implemented a resale program. Importantly, the study underscores that manufacturers are not necessarily obliged to adopt a planned obsolescence strategy. When P2P platforms are absent, implementing a resale program allows manufacturers to increase profits by producing products that are either less or more durable. However, in the face of competition from P2P platforms, profitability can only be enhanced by making products more durable. This suggests that a platform’s emergence can alter how the depreciation rate affects a manufacturer’s profit and hence its optimal product design strategies. Understanding these dynamics is crucial for effectively navigating the growing used car market.},
  archive      = {J_EJOR},
  author       = {Shu Hu and Stuart X. Zhu and Ke Fu},
  doi          = {10.1016/j.ejor.2024.12.017},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {583-598},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The manufacturer’s resale strategy for trade-ins},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Connections between multiple-objective programming and
weight restricted data envelopment analysis: The role of the ordering
cone. <em>EJOR</em>, <em>323</em>(2), 571–582. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores some new, important and interesting connections between Multiple-Objective Programming (MOP) and Data Envelopment Analysis (DEA). We show that imposing weight restrictions in DEA corresponds to changing the ordering cone in MOP in a specific way. The new ordering cone is constructed and its properties are proved, providing useful insights about the connections between MOP and DEA. After providing several theoretical results, we illustrate them on a real-world data set. In addition to their theoretical appeal, our results hold significant practical importance for several reasons which are addressed in the paper.},
  archive      = {J_EJOR},
  author       = {Pekka Korhonen and Majid Soleimani-damaneh and Jyrki Wallenius},
  doi          = {10.1016/j.ejor.2024.12.002},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {571-582},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Connections between multiple-objective programming and weight restricted data envelopment analysis: The role of the ordering cone},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An incremental preference elicitation-based approach to
learning potentially non-monotonic preferences in multi-criteria
sorting. <em>EJOR</em>, <em>323</em>(2), 553–570. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging assignment example preference information, to determine the shape of marginal utility functions and category thresholds of the threshold-based multi-criteria sorting (MCS) model, has emerged as a focal point of current research within the realm of MCS. Most studies assume decision makers can provide all assignment example preference information in batch and that their preferences over criteria are monotonic, which may not align with practical MCS problems. This paper introduces a novel incremental preference elicitation-based approach to learning potentially non-monotonic preferences in MCS problems, enabling decision makers to progressively provide assignment example preference information. Specifically, we first construct a max-margin optimization-based model to model potentially non-monotonic preferences and inconsistent assignment example preference information in each iteration of the incremental preference elicitation process. Using the optimal objective function value of the max-margin optimization-based model, we devise information amount measurement methods and question selection strategies to pinpoint the most informative alternative in each iteration within the framework of uncertainty sampling in active learning. Once the termination criterion is satisfied, the sorting result for non-reference alternatives can be determined through the use of two optimization models, i.e., the max-margin optimization-based model and the complexity controlling optimization model. Subsequently, two incremental preference elicitation-based algorithms are developed to learn potentially non-monotonic preferences, considering different termination criteria. Ultimately, we apply the proposed approach to a firm financial state rating problem to elucidate the detailed implementation steps, and perform computational experiments on both artificial and real-world data sets to compare the proposed question selection strategies with several benchmark strategies.},
  archive      = {J_EJOR},
  author       = {Zhuolin Li and Zhen Zhang and Witold Pedrycz},
  doi          = {10.1016/j.ejor.2024.11.047},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {553-570},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An incremental preference elicitation-based approach to learning potentially non-monotonic preferences in multi-criteria sorting},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A coevolutionary algorithm for exploiting a large fuzzy
outranking relation. <em>EJOR</em>, <em>323</em>(2), 540–552. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outranking approach in Multiple Criteria Decision Analysis (MCDA) uses ranking procedures to exploit a fuzzy outranking relation, which captures the decision maker&#39;s notion of a ranking. However, as decision problems become more complex and computer performance improves, new ranking procedures are needed to rank complex data sets that decision-makers may not interpret. This paper discusses recent efforts and potential directions for developing ranking procedures that use multiobjective evolutionary algorithms (MOEAs) to exploit a fuzzy outranking relation. After that, based on the cooperative coevolutionary algorithms (CCEA) approach, we suggest some fundamental modifications to extend the RP 2 -NSGA-II+H algorithm that improve the scalability of this MOEA to exploit large-sized fuzzy outranking relations. Empirical results indicate that adjustments improve the RP 2 -NSGA-II+H algorithm for the addressed problem. The proposed ranking procedure outperforms RP 2 -NSGA-II+H in terms of ranking error rates based on the experiments conducted. Our experimental results also demonstrate that the proposed approach can be scaled for instances of the ranking problem of up to one thousand alternatives.},
  archive      = {J_EJOR},
  author       = {Jesús Jaime Solano Noriega and Juan Carlos Leyva López and Carlos Andrés Oñate Ochoa and José Rui Figueira},
  doi          = {10.1016/j.ejor.2024.12.012},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {540-552},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A coevolutionary algorithm for exploiting a large fuzzy outranking relation},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain adoption and coordination strategies for green
supply chains considering consumer privacy concern. <em>EJOR</em>,
<em>323</em>(2), 525–539. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumers’ uncertainty about the value of green products will reduce their willingness to pay, thereby obstructing green product promotion. Blockchain can eliminate this uncertainty but bring privacy concerns. We develop a game theoretical model to study a green supply chain composed of one manufacturer and one retailer, aiming to explore the implications of partial or full blockchain adoption on green product manufacturing. Subsequently, we consider the use of revenue-sharing and cost-sharing contracts as mechanisms to coordinate the supply chain that adopts blockchain technologies. We show that adopting blockchain for some products benefits the manufacturer and the retailer, and consumers’ privacy concerns make it impossible for blockchain to be adopted for all products. Interestingly, partial or full blockchain adoption does not affect the green investment level. Furthermore, we find that revenue-sharing and cost-sharing contracts are always beneficial for the manufacturer. However, it can be beneficial for the retailer only when the revenue-sharing or cost-sharing ratio is small. Surprisingly, the effectiveness of the coordinating contract is not affected by consumers’ privacy concerns. Finally, when comparing the wholesale price contract with two coordination mechanisms, we find that the manufacturer and the retailer can agree on adopting a cost-sharing contract when both revenue- and cost-sharing ratios are low. When the revenue-sharing ratio is moderate and the cost-sharing ratio is low, a revenue-sharing contract is adopted. In all other cases, trading is conducted according to the wholesale price contract. These insights can contribute to optimize the application of blockchain in green supply chains.},
  archive      = {J_EJOR},
  author       = {Changhua Liao and Qihui Lu and Salar Ghamat and Helen Huifen Cai},
  doi          = {10.1016/j.ejor.2024.12.022},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {525-539},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Blockchain adoption and coordination strategies for green supply chains considering consumer privacy concern},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An operation-agnostic stochastic user equilibrium model for
mobility-on-demand networks with congestible capacities. <em>EJOR</em>,
<em>323</em>(2), 504–524. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the impact of privately-owned Mobility-on-Demand (MoD) services is important from a regulatory perspective. There is a need to model multimodal equilibria with MoD to support policymaking. While there exists a large body of literature on MoD services focusing on service design under equilibrium modeling, these studies commonly adopt assumptions of MoD operational policies. However, such policies might not be shared with regulatory agencies due to commercial privacy concerns of private operators. We model multimodal equilibrium with MoD systems in an operation-agnostic manner based on empirical observations of flow and capacity. This is done with a Flow-Capacity Interaction (FC) matrix that captures systematic effect of congestible capacities, a phenomenon in MoD systems where capacities are affected by flows. The FC matrix encapsulates the operation and demand patterns by capturing the empirical equilibrium relationship between flows and capacities. An operation-agnostic logit-based stochastic user equilibrium (SUE) formulation is proposed and proof of equivalence of the SUE formulation is derived. The proof shows that, unlike static capacities, path delays are not just the sum of the Lagrange multipliers of the links on the paths, but dependent on the whole network. We name this phenomenon as “non-separable link delays”. A solution algorithm that finds SUE with a bounded path set is proposed, with a custom Frank-Wolfe algorithm to solve the non-linear SUE formulation. Since the FC matrix cannot be directly observed, an inverse optimization problem is introduced to estimate it with observed flow and capacity data. Two numerical examples are provided with sensitivity tests. An empirical example with yellow taxi data of downtown Manhattan, NY is provided to demonstrate effectiveness of estimating the FC matrix from real data, and for determining the equilibrium that captures the underlying flow-capacity dynamics.},
  archive      = {J_EJOR},
  author       = {Bingqing Liu and David Watling and Joseph Y.J. Chow},
  doi          = {10.1016/j.ejor.2024.12.038},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {504-524},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An operation-agnostic stochastic user equilibrium model for mobility-on-demand networks with congestible capacities},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Product line extensions and distribution channels in
pharmaceutical supply chain. <em>EJOR</em>, <em>323</em>(2), 490–503.
(<a href="https://doi.org/10.1016/j.ejor.2024.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to aggressive generic competition after the original drug’s patent expires, various original firms extend their product lines by introducing an authorized generic drug with both lower quality and cost, either via internal distribution or third-party distribution. In this paper, we develop a game-theoretic model to investigate the product line extension and distribution channel decisions for an original firm that has already sold an original drug and considers introducing an authorized generic drug to compete against the generic firm. We show that product line extension enables the original firm to leverage the value of drug differentiation by price discriminating the patients with heterogeneous preferences for quality, but it also leads to original drug’s profit loss caused by the internal cannibalization. Given an internal distribution channel, when the cost gap is not small for the internal cannibalization to be less aggressive, the original firm will extend the product line, which could surprisingly benefit the generic firm but harm the patients. In contrast, under a third-party distribution channel, the original firm always prefers to extend the product line by setting a low wholesale price, which always reduces the generic firm’s profit but increases the patient surplus. Finally, contrary to the conventional wisdom that a decentralized channel always harms the original firm compared with a centralized one due to the double marginalization, our results suggest that when the original drug has a small cost gap or a large quality gap relative to the generic drug, the original firm is better off with using the third-party distribution to introduce the authorized generic drug than the internal distribution, as it permits higher original drug’s profit due to alleviated internal cannibalization, although at the expense of lower authorized generic drug’s profit.},
  archive      = {J_EJOR},
  author       = {Ran Tao and Yanfei Lan and Ruiqing Zhao and Rong Gao},
  doi          = {10.1016/j.ejor.2024.12.013},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {490-503},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Product line extensions and distribution channels in pharmaceutical supply chain},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated differentiated time slot pricing and order
dispatching with uncertain customer demand in on-demand food delivery.
<em>EJOR</em>, <em>323</em>(2), 471–489. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentiated time slot pricing (DTSP) is a promising approach to enhance the efficiency and cost-effectiveness of food delivery platforms by influencing customers’ choices regarding delivery time slots. In this paper, we investigate the integrated problem of DTSP at the tactical level and order dispatching at the operational level, formulating it as a two-stage stochastic programming model. The first-stage model determines the delivery price for each time slot to maximize the system’s expected profit. The second-stage model generates the optimal order dispatching plan to minimize the generalized system cost under each stochastic scenario. To efficiently estimate the order dispatching cost for each scenario, we develop an order consolidation dispatching algorithm (OCDA) to solve the second-stage order dispatching subproblem under each demand scenario. Building on OCDA, we propose a hybrid adaptive large neighborhood search (HALNS) heuristic to solve the integrated problem. Extensive case studies based on real-world data verify the effectiveness of the proposed approach and demonstrate the benefits of DTSP strategy. Our numerical analysis provides important managerial insights for operating food delivery platforms.},
  archive      = {J_EJOR},
  author       = {Bo Zhang and Elkafi Hassini and Yun Zhou and Meng Zhao and Xiangpei Hu},
  doi          = {10.1016/j.ejor.2024.12.011},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {471-489},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated differentiated time slot pricing and order dispatching with uncertain customer demand in on-demand food delivery},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal forecast reconciliation with time series selection.
<em>EJOR</em>, <em>323</em>(2), 455–470. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecast reconciliation ensures forecasts of time series in a hierarchy adhere to aggregation constraints, enabling aligned decision making. While forecast reconciliation can enhance overall accuracy in a hierarchical or grouped structure, it can lead to worse forecasts for certain series, with the greatest gains typically seen in series that originally have poorly performing base forecasts. In practical applications, some series in a structure often produce poor base forecasts due to model misspecification or low forecastability. To mitigate their negative impact, we propose two categories of forecast reconciliation methods that incorporate automatic time series selection based on out-of-sample and in-sample information, respectively. These methods keep “poor” base forecasts unused in forming reconciled forecasts, while adjusting the weights assigned to the remaining series accordingly when generating bottom-level reconciled forecasts. Additionally, our methods ameliorate disparities stemming from varied estimators of the base forecast error covariance matrix, alleviating challenges associated with estimator selection. Empirical evaluations through two simulation studies and applications using Australian labour force and domestic tourism data demonstrate the potential of the proposed methods to exclude series with high scaled forecast errors and show promising results.},
  archive      = {J_EJOR},
  author       = {Xiaoqian Wang and Rob J. Hyndman and Shanika L. Wickramasuriya},
  doi          = {10.1016/j.ejor.2024.12.004},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {455-470},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal forecast reconciliation with time series selection},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the discrete and continuous edge improvement
problems: Models and algorithms. <em>EJOR</em>, <em>323</em>(2),
441–454. (<a href="https://doi.org/10.1016/j.ejor.2024.12.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the edge improvement problem where the fixed edge traversal time assumption of the traditional network flow problems is relaxed. We consider two variants of the problem: one where improvement decisions are restricted to a discrete set (discrete edge improvement problem), and the other where they can take any value within a specified range (continuous edge improvement problem). We first analyze both problem variants on a tree-shaped network and discuss their computational complexities. For the general case, where the underlying network has no special structure, we provide mixed-integer programming (MIP) formulations for both versions of the problem. To the best of our knowledge, this study is the first to propose and compare different formulations for the discrete edge improvement problem and to present a formulation for the continuous edge improvement problem. Since the developed models do not perform well for medium and large problem instances, we introduce a Benders decomposition algorithm to solve the discrete edge improvement problem. Additionally, we employ it heuristically to find high-quality solution for the continuous edge improvement problem within reasonable times. We also devise an MIP formulation to find lower bounds for the continuous edge improvement problem, leveraging the McCormick envelopes and optimal solution properties. Our experiments demonstrate that the Benders decomposition algorithm outperforms the other formulations for the discrete edge improvement problem, while the heuristic method proposed for the continuous edge improvement problem provides quite well results even for large problem instances.},
  archive      = {J_EJOR},
  author       = {Esra Koca and A. Burak Paç},
  doi          = {10.1016/j.ejor.2024.12.051},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {441-454},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exploring the discrete and continuous edge improvement problems: Models and algorithms},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and effective breakpoints heuristic algorithm for the
quadratic knapsack problem. <em>EJOR</em>, <em>323</em>(2), 425–440. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Quadratic Knapsack Problem (QKP) involves selecting a subset of elements that maximizes the sum of pairwise and singleton utilities without exceeding a given budget. The pairwise utilities are nonnegative, the singleton utilities may be positive, negative, or zero, and the node costs are nonnegative. We introduce a Breakpoints Algorithm for QKP, named QKBP, which is based on a technique proposed in Hochbaum (2009) for efficiently generating the concave envelope of the solutions to the relaxation of the problem for all values of the budget. Our approach utilizes the fact that breakpoints in the concave envelopes are optimal solutions for their respective budgets. For budgets between breakpoints, a fast greedy heuristic derives high-quality solutions from the optimal solutions of adjacent breakpoints. The QKBP algorithm is a heuristic which is highly scalable due to an efficient parametric cut procedure used to generate the concave envelope. This efficiency is further improved by a newly developed compact problem formulation. Our extensive computational study on both existing and new benchmark instances, with up to 10,000 elements, shows that while some leading algorithms perform well on a few instances, QKBP consistently delivers high-quality solutions regardless of instance size, density, or budget. Moreover, QKBP achieves these results in significantly faster running times than all leading algorithms. The source code of the QKBP algorithm, the benchmark instances, and the detailed results are publicly available on GitHub.},
  archive      = {J_EJOR},
  author       = {D.S. Hochbaum and P. Baumann and O. Goldschmidt and Y. Zhang},
  doi          = {10.1016/j.ejor.2024.12.019},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {425-440},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A fast and effective breakpoints heuristic algorithm for the quadratic knapsack problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the multiobjective quasi-clique problem.
<em>EJOR</em>, <em>323</em>(2), 409–424. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a simple undirected graph G , a quasi-clique is a subgraph of G whose density is at least γ ( 0 &lt; γ ≤ 1 ) . Finding a maximum quasi-clique has been addressed from two different perspectives: ( i ) maximizing vertex cardinality for a given edge density; and ( i i ) maximizing edge density for a given vertex cardinality. However, when no a priori preference information about cardinality and density is available, a more natural approach is to consider the problem from a multiobjective perspective. We introduce the Multiobjective Quasi-clique (MOQC) problem, which aims to find a quasi-clique by simultaneously maximizing both vertex cardinality and edge density. To efficiently address this problem, we explore the relationship among MOQC, its single-objective counterpart problems, and a bi-objective optimization problem, along with several properties of the MOQC problem and quasi-cliques. We propose a baseline approach using ɛ -constraint scalarization and introduce a Two-phase strategy, which applies a dichotomic search based on weighted sum scalarization in the first phase and an ɛ -constraint methodology in the second phase. Additionally, we present a Three-phase strategy that combines the dichotomic search used in Two-phase with a vertex-degree-based local search employing novel sufficient conditions to assess quasi-clique efficiency, followed by an ɛ -constraint in a final stage. Experimental results on synthetic and real-world sparse graphs indicate that the integrated use of dichotomic search and local search, together with mechanisms to assess quasi-clique efficiency, makes the Three-phase strategy an effective approach for solving the MOQC problem in sparse graphs in terms of running time and ability to produce new efficient quasi-cliques.},
  archive      = {J_EJOR},
  author       = {Daniela Scherer dos Santos and Kathrin Klamroth and Pedro Martins and Luís Paquete},
  doi          = {10.1016/j.ejor.2024.12.018},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {409-424},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving the multiobjective quasi-clique problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete optimization: A quantum revolution? <em>EJOR</em>,
<em>323</em>(2), 378–408. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop several quantum procedures and investigate their potential to solve discrete optimization problems. First, we introduce a binary search procedure and illustrate how it can be used to effectively solve the binary knapsack problem. Next, we introduce two other procedures: a hybrid branch-and-bound procedure that allows to exploit the structure of the problem and a random-ascent procedure that can be used to solve problems that have no clear structure and/or are difficult to solve using traditional methods. We explain how to assess the performance of these procedures and perform an elaborate computational experiment. Our results show that we can match the worst-case performance of the best classical algorithms when solving the binary knapsack problem. After improving and generalizing our procedures, we show that they can be used to solve any discrete optimization problem. To illustrate, we show how to solve the quadratic binary knapsack problem. For this problem, our procedures outperform the best classical algorithms. In addition, we demonstrate that our procedures can be used as heuristics to find (near-) optimal solutions in limited time Not only does our work provide the tools required to explore a myriad of future research directions, it also shows that quantum computing has the potential to revolutionize the field of discrete optimization.},
  archive      = {J_EJOR},
  author       = {Stefan Creemers and Luis Fernando Pérez Armas},
  doi          = {10.1016/j.ejor.2024.12.016},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {378-408},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Discrete optimization: A quantum revolution?},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fifty years of multiple criteria decision analysis: From
classical methods to robust ordinal regression. <em>EJOR</em>,
<em>323</em>(2), 351–377. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple Criteria Decision Analysis (MCDA) is a subfield of Operational Research that aims to support Decision-Makers (DMs) in the decision-making process through mathematical models and computational procedures. In this perspective, MCDA employs structured and traceable protocols to identify potential actions and the criteria for evaluating them. MCDA procedures aim to define recommendations consistent with the preferences of DMs for the specific decision problem at hand. These problems are generally formulated in terms of either choosing the best action, classifying actions into pre-defined and ordered decision classes, or ranking actions from best to worst. As the evaluation criteria are generally conflicting, the main challenge is to aggregate them into a mathematical preference model representing the DM value system. We review the development of MCDA over the past fifty years and describe its evolution with examples of distinctive methods. They are distinguished by the type of preference information elicited by DMs, the type of the preference model (criteria aggregation), and the way of converting the preference relation induced by the preference model in the set of potential actions into a decision recommendation. We focus on MCDA methods with a finite set of actions. References to specific application areas will be given. In the conclusion section, some prospective avenues of research will be outlined.},
  archive      = {J_EJOR},
  author       = {Salvatore Greco and Roman Słowiński and Jyrki Wallenius},
  doi          = {10.1016/j.ejor.2024.07.038},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {351-377},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of multiple criteria decision analysis: From classical methods to robust ordinal regression},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="iandc---11">IANDC - 11</h2>
<ul>
<li><details>
<summary>
(2025). On the data persistency of replicated erasure codes in
distributed storage systems. <em>IANDC</em>, <em>304</em>, 105297. (<a
href="https://doi.org/10.1016/j.ic.2025.105297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fundamental problem of data persistency for a general family of redundancy schemes, called replicated erasure codes . In replicated erasure codes each document is divided into p chunks and then encoded into p + q chunks. Then, each of the p + q chunks is replicated into r replicas. We analyze two strategies of replicated erasure codes distribution: random (all chunks are spread randomly among storage nodes) and sequential (the chunks are sequentially placed into storage nodes). For both strategies we derive closed-form expression and asymptotic bounds for expected data persistency of replicated erasure codes when the storage nodes leave the storage system and erase their locally stored data. We observe that the maximal expected data persistency of replicated erasure codes for both placement strategies is attained for parameter p = 1 and give formulas in terms of the beta function in this case.},
  archive      = {J_IANDC},
  author       = {Roy Friedman and Rafał Kapelko and Karol Marchwicki},
  doi          = {10.1016/j.ic.2025.105297},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105297},
  shortjournal = {Inf. Comput.},
  title        = {On the data persistency of replicated erasure codes in distributed storage systems},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Elastic-degenerate string comparison. <em>IANDC</em>,
<em>304</em>, 105296. (<a
href="https://doi.org/10.1016/j.ic.2025.105296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An elastic-degenerate (ED) string T is a sequence of n sets T [ 1 ] , … , T [ n ] containing m strings in total whose cumulative length is N . We call n , m , and N the length, the cardinality and the size of T , respectively. The language of T is defined as L ( T ) = { S 1 ⋯ S n : S i ∈ T [ i ] for all i ∈ [ 1 , n ] } . Given two ED strings, how fast can we check whether the two languages they represent have a nonempty intersection? We call this problem the ED String Intersection (EDSI) problem. For two ED strings T 1 and T 2 of lengths n 1 and n 2 , cardinalities m 1 and m 2 , and sizes N 1 and N 2 , respectively, we show the following: • There is no O ( ( N 1 N 2 ) 1 − ϵ ) -time algorithm, for any ϵ &gt; 0 , for EDSI even if T 1 and T 2 are over a binary alphabet, unless the Strong Exponential-Time Hypothesis is false. • There is no combinatorial O ( ( N 1 + N 2 ) 1.2 − ϵ f ( n 1 , n 2 ) ) -time algorithm, for any ϵ &gt; 0 and any function f , for EDSI even if T 1 and T 2 are over a binary alphabet, unless the Boolean Matrix Multiplication conjecture is false. • An O ( N 1 log ⁡ N 1 log ⁡ n 1 + N 2 log ⁡ N 2 log ⁡ n 2 ) -time algorithm for outputting a compact representation of the intersection language of two unary ED strings. When T 1 and T 2 are given in a compact representation, we show that the problem is NP-complete. • An O ( N 1 m 2 + N 2 m 1 ) -time algorithm for EDSI. • An O ˜ ( N 1 ω − 1 n 2 + N 2 ω − 1 n 1 ) -time algorithm for EDSI, where ω is the matrix multiplication exponent; the O ˜ notation suppresses factors that are polylogarithmic in the input size.},
  archive      = {J_IANDC},
  author       = {Estéban Gabory and Moses Njagi Mwaniki and Nadia Pisanti and Solon P. Pissis and Jakub Radoszewski and Michelle Sweering and Wiktor Zuba},
  doi          = {10.1016/j.ic.2025.105296},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105296},
  shortjournal = {Inf. Comput.},
  title        = {Elastic-degenerate string comparison},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Derandomization of quantum algorithm for triangle finding.
<em>IANDC</em>, <em>304</em>, 105295. (<a
href="https://doi.org/10.1016/j.ic.2025.105295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Derandomization is the process of taking a randomized algorithm and turning it into a deterministic algorithm, which has attracted great attention in classical computing. In quantum computing, it is challenging and intriguing to derandomize quantum algorithms, due to the inherent randomness of quantum mechanics. The significance of derandomizing quantum algorithms lies not only in theoretically proving that the success probability can essentially be 1 without sacrificing quantum speedups, but also in experimentally improving the success rate when the algorithm is implemented on a real quantum computer. In this paper, we focus on derandomizing quantum algorithms for the triangle sum problem (including the famous triangle finding problem as a special case), which asks to find a triangle in an edge-weighted graph with n vertices, such that its edges sum up to a given weight. We show that when the graph is promised to contain at most one target triangle, there exists a deterministic quantum algorithm that either finds the triangle if it exists or outputs “no triangle” if none exists. It makes O ( n 9 / 7 ) queries to the edge weight matrix oracle, and thus has the same complexity as the state-of-the-art bounded-error quantum algorithm. To achieve this derandomization, we make full use of several techniques: nested quantum walk with quantum data structure, deterministic quantum search with adjustable parameters, and dimensional reduction of quantum walk search on Johnson graph.},
  archive      = {J_IANDC},
  author       = {Guanzhong Li and Lvzhou Li},
  doi          = {10.1016/j.ic.2025.105295},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105295},
  shortjournal = {Inf. Comput.},
  title        = {Derandomization of quantum algorithm for triangle finding},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collision-free robot scheduling. <em>IANDC</em>,
<em>304</em>, 105294. (<a
href="https://doi.org/10.1016/j.ic.2025.105294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the problem of designing schedules for completing a set of tasks at fixed locations with multiple robots in a laboratory. We represent the laboratory as a graph with tasks placed on fixed vertices and robots represented as agents, with the constraint that no two robots may occupy the same vertex at any given timestep. Each schedule is partitioned into a set of timesteps, corresponding to a walk through the graph (allowing for a robot to wait at a vertex to complete a task), with each timestep taking time equal to the time for a robot to move from one vertex to another and each task taking some given number of timesteps during the completion of which a robot must stay at the vertex containing the task. The goal is to determine a set of schedules, with one schedule for each robot, minimising the number of timesteps taken by the schedule taking the greatest number of timesteps within the set of schedules. We show that this problem is NP-complete for both star graphs (for k ≥ 2 robots), and planar graphs (for any number of robots). Finally, we provide positive results for path, cycle, and tadpole graphs, showing that we can find an optimal set of schedules for k robots completing m tasks of equal duration of a path of length n in O ( k m n ) , O ( k m n 2 ) time, and O ( k 3 m 4 n ) time respectively.},
  archive      = {J_IANDC},
  author       = {Duncan Adamson and Nathan Flaherty and Igor Potapov and Paul G. Spirakis},
  doi          = {10.1016/j.ic.2025.105294},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105294},
  shortjournal = {Inf. Comput.},
  title        = {Collision-free robot scheduling},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dichotomy result for countably based sober spaces.
<em>IANDC</em>, <em>304</em>, 105293. (<a
href="https://doi.org/10.1016/j.ic.2025.105293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cartesian closed categories have been playing fundamental roles in providing denotational semantic for higher-order programming languages. In this paper we try to identify Cartesian closed subcategories of the category C S ⊥ of pointed countably based sober spaces, and we present a conclusion known as the dichotomy result in the category C S ⊥ . This result explains that any Cartesian closed full subcategory of C S ⊥ is contained within either the category of weakly compact open connected spaces or that of principally connected spaces. To prove our dichotomy theorem, we first deduce that every pointed countably based sober space X is locally connected, if the space of all continuous functions from X to X is locally compact. Next, we demonstrate that a function space in C S ⊥ is locally connected only if its input space is either weakly compact open connected or its output space is principally connected.},
  archive      = {J_IANDC},
  author       = {Hualin Miao and Qingguo Li},
  doi          = {10.1016/j.ic.2025.105293},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105293},
  shortjournal = {Inf. Comput.},
  title        = {A dichotomy result for countably based sober spaces},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multivariate convertible undeniable signature scheme.
<em>IANDC</em>, <em>304</em>, 105286. (<a
href="https://doi.org/10.1016/j.ic.2025.105286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital signature is an important cryptographic primitive which can be universally verified. However, this universal verifiability can be ominous in case of e-auction, e-voting, and e-cash, where the verifiability must be restricted. Undeniable signature is a type of digital signature that is mainly used to achieve the goal of access control. In this article, we propose the first multivariate-based quantum secure undeniable signature scheme, which can also be converted into an ordinary signature. The security of this scheme relies on the hardness of multivariate quadratic problem which is computationally hard to solve when defined over any finite field. We deploy Monteiro et al.&#39;s improvement on Sakumoto et al.&#39;s zero-knowledge protocol for the verification process. We discuss the security properties of undeniable signature, viz., completeness, soundness, unforgeability, invisibility, and non-impersonation. Additionally, we show that the proposed undeniable signature has the smallest signature and key sizes among all the existing quantum-resistant undeniable signatures.},
  archive      = {J_IANDC},
  author       = {Satyam Omar and Sahadeo Padhye and Dhananjoy Dey and Devansh Mehrotra},
  doi          = {10.1016/j.ic.2025.105286},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105286},
  shortjournal = {Inf. Comput.},
  title        = {A multivariate convertible undeniable signature scheme},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Composing bridges. <em>IANDC</em>, <em>304</em>, 105285. (<a
href="https://doi.org/10.1016/j.ic.2025.105285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work builds on previous investigations of the authors (and their collaborators) regarding bridges, a certain type of morphisms between encryption schemes, making a step forward in developing a (category theory) language for studying relations between encryption schemes. Here we analyse the conditions under which bridges can be performed sequentially, formalizing the notion of composability. One of our results gives a sufficient condition for a pair of bridges to be composable. We illustrate that composing two bridges, each independently satisfying a previously established IND-CPA security definition, can actually lead to an insecure bridge. Our main result gives a sufficient condition that a pair of secure composable bridges should satisfy in order for their composition to be a secure bridge. We also introduce the concept of a complete bridge and show that it is connected to the notion of Fully composable Homomorphic Encryption (FcHE), recently considered by Micciancio. Moreover, we show that a result of Micciancio which gives a construction of FcHE schemes can be phrased in the language of complete bridges, where his insights can be formalized in a greater generality.},
  archive      = {J_IANDC},
  author       = {Mugurel Barcau and Vicenţiu Paşol and George C. Ţurcaş},
  doi          = {10.1016/j.ic.2025.105285},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105285},
  shortjournal = {Inf. Comput.},
  title        = {Composing bridges},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identity based proxy blind signature scheme using NTRU
lattices. <em>IANDC</em>, <em>304</em>, 105284. (<a
href="https://doi.org/10.1016/j.ic.2025.105284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proxy blind signatures represent a specific type of blind signature that allows a proxy signer to sign documents on behalf of the original signer without having access to the content they are signing. Currently, most of the existing proxy blind signature schemes rely on complex number-theoretic hard problems like bilinear pairing and the discrete logarithm problem or on general lattices&#39; hardness. Unfortunately, the security of number-theoretic hard problems-based systems is struggling due to vulnerability to Shor&#39;s algorithm, which jeopardizes the security of cryptographic schemes based on them, and general lattices suffer from large key sizes. Thus, we are looking for a new scheme that is efficient in time and storage, has short key and signature sizes, and is crucially secure against threats posed by quantum computers. Recently, NTRU lattice-based schemes have gained significant popularity due to their ease of implementation and proven security reductions. In 2018, Zhu et al. presented an identity-based proxy blind signature scheme over NTRU lattices, which is not secure. Therefore, by explaining the security breach of Zhu et al.&#39;s scheme, we present a novel, secure, and improved identity-based proxy blind signature system resistant to quantum threats and utilizing NTRU lattices. Based on the standard hardness assumptions related to the approximate shortest vector problem ( γ -SVP) and the shortest integer solution problem (SIS), it is demonstrated that the proposed method is secure against quantum forgery.},
  archive      = {J_IANDC},
  author       = {Sonika Singh and Swati Rawal and Sahadeo Padhye and Namita Tiwari},
  doi          = {10.1016/j.ic.2025.105284},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105284},
  shortjournal = {Inf. Comput.},
  title        = {Identity based proxy blind signature scheme using NTRU lattices},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computing maximal palindromes in non-standard matching
models. <em>IANDC</em>, <em>304</em>, 105283. (<a
href="https://doi.org/10.1016/j.ic.2025.105283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palindromes are popular and important objects in textual data processing, bioinformatics, and combinatorics on words. Let S = X a Y be a string where X and Y are of the same length, and a is either a single character or the empty string. Then, there exist two alternative definitions for palindromes: S is said to be a palindrome if S is equal to its reversal S R (Reversal-based definition); or if its right-arm Y is equal to the reversal of its left-arm X R (Symmetry-based definition). It is clear that if the “equality” (≈) used in both definitions is exact character matching (=), then the two definitions are the same. However, if we apply other string-equality criteria ≈, including the complementary-matching model for biological sequences, the Cartesian-tree model [Park et al., TCS 2020], the parameterized model [Baker, JCSS 1996], the order-preserving model [Kim et al., TCS 2014], and the palindromic-structure model [I et al., TCS 2013], then are the reversal-based palindromes and the symmetry-based palindromes the same? To the best of our knowledge, no previous work has considered or answered this natural question. In this paper, we first provide answers to this question, and then present efficient algorithms for computing all maximal palindromes under the non-standard matching models in a given string. After confirming that Gusfield&#39;s offline suffix-tree-based algorithm for computing maximal symmetry-based palindromes can be readily extended to the aforementioned matching models, we show how to extend Manacher&#39;s online algorithm for computing maximal reversal-based palindromes in linear time for all the aforementioned matching models.},
  archive      = {J_IANDC},
  author       = {Takuya Mieno and Mitsuru Funakoshi and Yuto Nakashima and Shunsuke Inenaga and Hideo Bannai and Masayuki Takeda},
  doi          = {10.1016/j.ic.2025.105283},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105283},
  shortjournal = {Inf. Comput.},
  title        = {Computing maximal palindromes in non-standard matching models},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polynomial-delay enumeration of large maximal common
independent sets in two matroids and beyond. <em>IANDC</em>,
<em>304</em>, 105282. (<a
href="https://doi.org/10.1016/j.ic.2025.105282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a maximum cardinality common independent set in two matroids (also known as Matroid Intersection ) is a classical combinatorial optimization problem, which generalizes several well-known problems, such as finding a maximum bipartite matching, a maximum colorful forest, and an arborescence in directed graphs. Enumerating all maximal common independent sets in two (or more) matroids is a classical enumeration problem. In this paper, we address an “intersection” of these problems: Given two matroids and a threshold τ , the goal is to enumerate all maximal common independent sets in the matroids with cardinality at least τ . We show that this problem can be solved in polynomial delay and polynomial space. Moreover, our technique can be extended to a more general problem, which is relevant to Matroid Matching . We give a polynomial-delay and polynomial-space algorithm for enumerating all maximal “matchings” with cardinality at least τ , assuming that the optimization counterpart is “tractable” in a certain sense. This extension allows us to enumerate small minimal connected vertex covers in subcubic graphs. We also discuss a framework to convert enumeration with cardinality constraints into ranked enumeration.},
  archive      = {J_IANDC},
  author       = {Yasuaki Kobayashi and Kazuhiro Kurita and Kunihiro Wasa},
  doi          = {10.1016/j.ic.2025.105282},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105282},
  shortjournal = {Inf. Comput.},
  title        = {Polynomial-delay enumeration of large maximal common independent sets in two matroids and beyond},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Homogeneous spiking neural p systems with synaptic failure.
<em>IANDC</em>, <em>304</em>, 105281. (<a
href="https://doi.org/10.1016/j.ic.2025.105281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural P (SN P) systems are a class of neural-like computational models, inspired by the way biological neurons process information through electrical impulses known as spikes. Homogeneous spiking neural P (HSN P) systems are a specialized variant of SN P systems, where all neurons share the same set of rules. In this work, with the biological inspiration that excessive synaptic transmission can lead to short-term failures in signal delivery between neurons in neural systems, the notion of synaptic failure is considered in HSN P systems, termed HSN P systems with synaptic failure (HSNPSF systems). Specifically, synaptic failure is referred to a family of sets of failure-prone synapses: if spikes simultaneously pass along all the synapses in such a set, the transmitted spikes across the synapses are suppressed; if a synapse in the set does not transmit any spike, the spikes pass along the synapses at that time, ultimately reaching the destination neurons. The computational power of HSNPSF systems is investigated by proving that they can achieve computational completeness both in generating and accepting modes. Furthermore, the computational efficiency of HSNPSF systems is examined, and it is demonstrated that with the help of non-deterministic feature, these systems are capable of solving NP -complete (the Subset Sum) problem in a semi-uniform way and within constant time.},
  archive      = {J_IANDC},
  author       = {Luping Zhang and Tingfang Wu},
  doi          = {10.1016/j.ic.2025.105281},
  journal      = {Information and Computation},
  month        = {5},
  pages        = {105281},
  shortjournal = {Inf. Comput.},
  title        = {Homogeneous spiking neural p systems with synaptic failure},
  volume       = {304},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="icv---18">ICV - 18</h2>
<ul>
<li><details>
<summary>
(2025). Image–text feature learning for unsupervised
visible–infrared person re-identification. <em>ICV</em>, <em>158</em>,
105520. (<a href="https://doi.org/10.1016/j.imavis.2025.105520">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible–infrared person re-identification (VI-ReID) focuses on matching infrared and visible images of the same person. To reduce labeling costs, unsupervised VI-ReID (UVI-ReID) methods typically use clustering algorithms to generate pseudo-labels and iteratively optimize the model based on these pseudo-labels. Although existing UVI-ReID methods have achieved promising performance, they often overlook the effectiveness of text semantics in inter-modality matching and modality-invariant feature learning. In this paper, we propose an image–text feature learning (ITFL) method, which not only leverages text semantics to enhance intra-modality identity-related learning but also incorporates text semantics into inter-modality matching and modality-invariant feature learning. Specifically, ITFL first performs modality-aware feature learning to generate pseudo-labels within each modality. Then, ITFL employs modality-invariant text modeling (MTM) to learn a text feature for each cluster in the visible modality, and utilizes inter-modality dual-semantics matching (IDM) to match inter-modality positive clusters. To obtain modality-invariant and identity-related image features, we not only introduce a cross-modality contrastive loss in ITFL to mitigate the impact of modality gaps, but also develop a text semantic consistency loss to further promote modality-invariant feature learning. Extensive experimental results on VI-ReID datasets demonstrate that ITFL not only outperforms existing unsupervised methods but also competes with some supervised approaches.},
  archive      = {J_ICV},
  author       = {Jifeng Guo and Zhiqi Pang},
  doi          = {10.1016/j.imavis.2025.105520},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105520},
  shortjournal = {Image Vis. Comput.},
  title        = {Image–text feature learning for unsupervised visible–infrared person re-identification},
  volume       = {158},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MrgaNet: Multi-scale recursive gated aggregation network for
tracheoscopy images. <em>ICV</em>, <em>158</em>, 105503. (<a
href="https://doi.org/10.1016/j.imavis.2025.105503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is a potentially fatal disease worldwide, and improving the accuracy of diagnosis plays a key role in enhancing patient outcomes. In this study, we extended computer-aided work to the task of assisting tracheoscopy in predicting lung cancer subtypes. To solve the problem of information fusion in different spatial scales and channels, we proposed MrgaNet. The network enhances classification performance by expanding interactions from low to high orders, dynamically adjusting feature weights, and incorporating a channel competition operator for efficient feature selection. Our network achieved a precision of 0.87 in the endobronchial dataset. In addition, the accuracy of 89.25% and 96.76% was achieved in the Kvasir-v2 dataset and the Kvasir-Capsule dataset, respectively. The results demonstrate that MrgaNet achieves superior performance compared to existing excellent methods.},
  archive      = {J_ICV},
  author       = {Ying Wang and Yun Tie and Dalong Zhang and Fenghui Liu and Lin Qi},
  doi          = {10.1016/j.imavis.2025.105503},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105503},
  shortjournal = {Image Vis. Comput.},
  title        = {MrgaNet: Multi-scale recursive gated aggregation network for tracheoscopy images},
  volume       = {158},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatio-temporal information mining and fusion feature-guided
modal alignment for video-based visible-infrared person
re-identification. <em>ICV</em>, <em>157</em>, 105518. (<a
href="https://doi.org/10.1016/j.imavis.2025.105518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The video-based visible-infrared person re-identification (Re-ID) aims to recognize the same person across modalities through video sequences. The core challenges of this task lie in narrowing the modal differences and deeply mining the rich spatio-temporal information contained in video to enhance model performance. However, existing research primarily focuses on addressing the modality gap, with insufficient utilization of the spatio-temporal information in video sequences. To address this, this paper proposes a novel spatio-temporal information mining and fusion feature-guided modal alignment framework for video-based visible-infrared person Re-ID. Specifically, we propose a spatio-temporal information mining method. This method employs the proposed feature correlation mechanism to enhance the discriminative features of person across different frames, while utilizing a temporal Transformer to mine person motion features. The advantage of this method lies in its ability to alleviate issues such as occlusion and frame misalignment, improving the discriminability of person features. Additionally, we introduce a fusion modality-guided modal alignment strategy, which reduces modality differences between infrared and visible video frames by aligning single-modality features with fusion features. The advantage of this strategy is that each modality not only learns its specific features but also absorbs person information from the other modality, thereby alleviating modality differences and further enhancing the discriminability of person features. Extensive comparative and ablation experiments conducted on the HITSZ-VCM and BUPTCampus datasets confirm the effectiveness and superiority of the proposed framework. The source code is available at https://github.com/lhf12278/SIMFGA .},
  archive      = {J_ICV},
  author       = {Zhigang Zuo and Huafeng Li and Yafei Zhang and Minghong Xie},
  doi          = {10.1016/j.imavis.2025.105518},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105518},
  shortjournal = {Image Vis. Comput.},
  title        = {Spatio-temporal information mining and fusion feature-guided modal alignment for video-based visible-infrared person re-identification},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stealth sight: A multi perspective approach for camouflaged
object detection. <em>ICV</em>, <em>157</em>, 105517. (<a
href="https://doi.org/10.1016/j.imavis.2025.105517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) is a challenging task due to the inherent similarity between objects and their surroundings. This paper introduces Stealth Sight , a novel framework integrating multi-view feature fusion and depth-based refinement to enhance segmentation accuracy. Our approach incorporates a pretrained multi-view CLIP encoder and a depth extraction network, facilitating robust feature representation. Additionally, we introduce a cross-attention transformer decoder and a post-training pruning mechanism to improve efficiency. Extensive evaluations on benchmark datasets demonstrate that Stealth Sight outperforms state-of-the-art methods in camouflaged object segmentation. Our method significantly enhances detection in complex environments, making it applicable to medical imaging, security, and wildlife monitoring.},
  archive      = {J_ICV},
  author       = {Domnic S. and Jayanthan K.S.},
  doi          = {10.1016/j.imavis.2025.105517},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105517},
  shortjournal = {Image Vis. Comput.},
  title        = {Stealth sight: A multi perspective approach for camouflaged object detection},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFKD: Multi-dimensional feature alignment for knowledge
distillation. <em>ICV</em>, <em>157</em>, 105514. (<a
href="https://doi.org/10.1016/j.imavis.2025.105514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation is a popular technique for compressing and transferring models in the field of deep learning. However, existing distillation methods often focus on optimizing a single dimension and overlook the importance of aligning and transforming knowledge across multiple dimensions, leading to suboptimal results. In this article, we introduce a novel approach called multi-dimensional feature alignment for knowledge distillation (MFKD) to address this limitation. The MFKD framework is built on the observation that knowledge from different dimensions can complement each other effectively. We extract knowledge from features in the spatcial, sample and channel dimensions separately. Our spatial-level part separates the foreground and background information, guiding the student to focus on crucial image regions by mimicking the teacher’s spatial and channel attention maps. Our sample-level part distills knowledge encoded in semantic correlations between sample activations by aligning the student’s activations to emulate the teacher’s clustering patterns using the Spearman correlation coefficient. Furthermore, our channel-level part encourages the student to learn standardized feature representations aligned with the teacher’s channel-wise interdependencies. Finally, we dynamically balance the loss factors of the different dimensions to optimize the overall performance of the distillation process. To validate the effectiveness of our methodology, we conduct experiments on benchmark datasets such as CIFAR-100, ImageNet and COCO. The experimental results demonstrate substantial performance improvements compared to baseline and recent state-of-the-art methods, confirming the efficacy of our MFKD framework. Furthermore, we provide a comprehensive analysis of the experimental results, offering deeper insight into the benefits and effectiveness of our approach. Through this analysis, we reinforce the significance of aligning and leveraging knowledge across multiple dimensions in knowledge distillation.},
  archive      = {J_ICV},
  author       = {Zhen Guo and Pengzhou Zhang and Peng Liang},
  doi          = {10.1016/j.imavis.2025.105514},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105514},
  shortjournal = {Image Vis. Comput.},
  title        = {MFKD: Multi-dimensional feature alignment for knowledge distillation},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing grid and adaptive region features for image
captioning. <em>ICV</em>, <em>157</em>, 105513. (<a
href="https://doi.org/10.1016/j.imavis.2025.105513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning aims to automatically generate grammatically correct and reasonable description sentences for given images. Improving feature optimization and processing is crucial for enhancing performance in this task. A common approach is to leverage the complementary advantages of grid features and region features. However, incorporating region features in most current methods may lead to incorrect guidance during training, along with high acquisition costs and the requirement of pre-caching. These factors impact the effectiveness and practical application of image captioning. To address these limitations, this paper proposes a method called fusing grid and adaptive region features for image captioning (FGAR). FGAR dynamically explores pseudo-region information within a given image based on the extracted grid features. Subsequently, it utilizes a combination of computational layers with varying permissions to fuse features, enabling comprehensive interaction between information from different modalities while preserving the unique characteristics of each modality. The resulting enhanced visual features provide improved support to the decoder for autoregressively generating sentences describing the content of a given image. All processes are integrated within a fully end-to-end framework, facilitating both training and inference processes while achieving satisfactory performance. Extensive experiments validate the effectiveness of the proposed FGAR method.},
  archive      = {J_ICV},
  author       = {Jiahui Wei and Zhixin Li and Canlong Zhang and Huifang Ma},
  doi          = {10.1016/j.imavis.2025.105513},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105513},
  shortjournal = {Image Vis. Comput.},
  title        = {Fusing grid and adaptive region features for image captioning},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention head purification: A new perspective to harness
CLIP for domain generalization. <em>ICV</em>, <em>157</em>, 105511. (<a
href="https://doi.org/10.1016/j.imavis.2025.105511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain Generalization (DG) aims to learn a model from multiple source domains to achieve satisfactory performance on unseen target domains. Recent works introduce CLIP to DG tasks due to its superior image-text alignment and zeros-shot performance. Previous methods either utilize full fine-tuning or prompt-learning paradigms to harness CLIP for DG tasks. Those works focus on avoiding catastrophic forgetting of the original knowledge encoded in CLIP but ignore that the knowledge encoded in CLIP in nature may contain domain-specific cues that constrain its domain generalization performance. In this paper, we propose a new perspective to harness CLIP for DG, i.e., attention head purification. We observe that different attention heads may encode different properties of an image and selecting heads appropriately may yield remarkable performance improvement across domains. Based on such observations, we purify the attention heads of CLIP from two levels, including task-level purification and domain-level purification . For task-level purification, we design head-aware LoRA to make each head more adapted to the task we considered. For domain-level purification, we perform head selection via a simple gating strategy. We utilize MMD loss to encourage masked head features to be more domain-invariant to emphasize more generalizable properties/heads. During training, we jointly perform task-level purification and domain-level purification. We conduct experiments on various representative DG benchmarks. Though simple, extensive experiments demonstrate that our method performs favorably against previous state-of-the-arts.},
  archive      = {J_ICV},
  author       = {Yingfan Wang and Guoliang Kang},
  doi          = {10.1016/j.imavis.2025.105511},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105511},
  shortjournal = {Image Vis. Comput.},
  title        = {Attention head purification: A new perspective to harness CLIP for domain generalization},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDMCB: Open-world object detection empowered by denoising
diffusion models and calibration balance. <em>ICV</em>, <em>157</em>,
105508. (<a href="https://doi.org/10.1016/j.imavis.2025.105508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-world object detection (OWOD) differs from traditional object detection by being more suited to real-world, dynamic scenarios. It aims to recognize unseen objects and have the skill to learn incrementally based on newly introduced knowledge. However, the current OWOD usually relies on supervising of known objects in identifying unknown objects, using high objectness scores as critical indicators of potential unknown objects. While these methods can detect unknown objects with features similar to known objects, they also classify regions dissimilar to known objects as background, leading to label bias issues. To address this problem, we leverage the knowledge from large visual models to provide auxiliary supervision for unknown objects. Additionally, we apply the Denoising Diffusion Probabilistic Model (DDPM) in OWOD scenarios. We propose an unsupervised modeling approach based on DDPM, which significantly improves the accuracy of unknown object detection. Despite this, the classifier trained during the model training process only encounters known classes, resulting in higher confidence for known classes during inference; thus, bias issues again occur. Therefore, we propose a probability calibration technique for post-processing predictions during inference. The calibration aims to reduce the probabilities of known objects and increase the probabilities of unknown objects, thereby balancing the final probability predictions. Our experiments demonstrate that the proposed method achieves significant improvements on OWOD benchmarks, with an unknown objects detection recall rate of 54.7 U-Recall , surpassing the current state-of-the-art (SOTA) methods by 44.3% . In terms of real-time performance, Our model uses a few parameters, and pure convolutional neural networks instead of intensive attention mechanisms, achieving an inference speed of 35.04 FPS , exceeding the SOTA OWOD methods based on Faster R-CNN and Deformable DETR by 2.79 and 10.95 FPS , respectively.},
  archive      = {J_ICV},
  author       = {Yangyang Huang and Xing Xi and Ronghua Luo},
  doi          = {10.1016/j.imavis.2025.105508},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105508},
  shortjournal = {Image Vis. Comput.},
  title        = {DDMCB: Open-world object detection empowered by denoising diffusion models and calibration balance},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised monocular depth learning from unknown
cameras: Leveraging the power of raw data. <em>ICV</em>, <em>157</em>,
105505. (<a href="https://doi.org/10.1016/j.imavis.2025.105505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised monocular depth estimation from wild videos with unknown camera intrinsics is a practical and challenging task in computer vision. Most of the existing methods in literature employed a camera decoder and a pose decoder to estimate camera intrinsics and poses respectively, however, their performances would be degraded significantly in many complex scenarios with severe noise and large camera rotations. To address this problem, we propose a novel self-supervised monocular depth estimation method, which could be trained from wild videos with a joint optimization strategy for simultaneously estimating camera intrinsics and poses. In the proposed method, a depth encoder is employed to learn scene depth features, and then by taking these features as inputs, a Neighborhood Influence Module (NIM) is designed for predicting each pixel’s depth by fusing the depths of its neighboring pixels, which could explicitly enforce the depth accuracy. In addition, a knowledge distillation mechanism is introduced to learn a lightweight depth encoder from a large-scale depth encoder, for achieving a balance between computational speed and accuracy. Experimental results on four public datasets demonstrate that the proposed method outperforms some state-of-the-art methods in most cases. Moreover, once the proposed method is trained with a mixed set of different datasets, its performance would be further boosted in comparison to the proposed method trained with each involved single dataset. Codes are available at: https://github.com/ZhuYongChaoUSST/IntrLessMonoDepth .},
  archive      = {J_ICV},
  author       = {Xiaofei Qin and Yongchao Zhu and Lin Wang and Xuedian Zhang and Changxiang He and Qiulei Dong},
  doi          = {10.1016/j.imavis.2025.105505},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105505},
  shortjournal = {Image Vis. Comput.},
  title        = {Self-supervised monocular depth learning from unknown cameras: Leveraging the power of raw data},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced deep learning and large language models:
Comprehensive insights for cancer detection. <em>ICV</em>, <em>157</em>,
105495. (<a href="https://doi.org/10.1016/j.imavis.2025.105495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the rapid advancement of machine learning (ML), particularly deep learning (DL), has revolutionized various fields, with healthcare being one of the most notable beneficiaries. DL has demonstrated exceptional capabilities in addressing complex medical challenges, including the early detection and diagnosis of cancer. Its superior performance, surpassing both traditional ML methods and human accuracy, has made it a critical tool in identifying and diagnosing diseases such as cancer. Despite the availability of numerous reviews on DL applications in healthcare, a comprehensive and detailed understanding of DL’s role in cancer detection remains lacking. Most existing studies focus on specific aspects of DL, leaving significant gaps in the broader knowledge base. This paper aims to bridge these gaps by offering a thorough review of advanced DL techniques, namely transfer learning (TL), reinforcement learning (RL), federated learning (FL), Transformers, and large language models (LLMs). These cutting-edge approaches are pushing the boundaries of cancer detection by enhancing model accuracy, addressing data scarcity, and enabling decentralized learning across institutions while maintaining data privacy. TL enables the adaptation of pre-trained models to new cancer datasets, significantly improving performance with limited labeled data. RL is emerging as a promising method for optimizing diagnostic pathways and treatment strategies, while FL ensures collaborative model development without sharing sensitive patient data. Furthermore, Transformers and LLMs, traditionally utilized in natural language processing (NLP), are now being applied to medical data for enhanced interpretability and context-based predictions. In addition, this review explores the efficiency of the aforementioned techniques in cancer diagnosis, it addresses key challenges such as data imbalance, and proposes potential solutions. It aims to be a valuable resource for researchers and practitioners, offering insights into current trends and guiding future research in the application of advanced DL techniques for cancer detection.},
  archive      = {J_ICV},
  author       = {Yassine Habchi and Hamza Kheddar and Yassine Himeur and Adel Belouchrani and Erchin Serpedin and Fouad Khelifi and Muhammad E.H. Chowdhury},
  doi          = {10.1016/j.imavis.2025.105495},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105495},
  shortjournal = {Image Vis. Comput.},
  title        = {Advanced deep learning and large language models: Comprehensive insights for cancer detection},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rif-diff: Improving image fusion based on diffusion model
via residual prediction. <em>ICV</em>, <em>157</em>, 105494. (<a
href="https://doi.org/10.1016/j.imavis.2025.105494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an image fusion framework Rif-Diff, which adopts several strategies and approaches to improve current fusion methods based on diffusion model. Rif-Diff employs residual images as the generation target of the diffusion model to optimize the model’s convergence process and enhance the fusion performance. For fusion tasks lacking ground truth, image fusion prior is utilized to facilitate the production of residual images. Simultaneously, to overcome the limitations of the model’s learning capacity imposed by training with image fusion prior, Rif-Diff introduces the idea of image restoration to enable the initial fused images to incorporate more expected information. Additionally, a dual-step decision module is designed to address the blurriness issue of fused images in existing multi-focus image fusion methods that do not rely on decision maps. Extensive experiments demonstrate the effectiveness of Rif-Diff across multiple fusion tasks including multi-focus image fusion, multi-exposure image fusion, and infrared-visible image fusion. The code is available at: https://github.com/peixuanWu/Rif-Diff .},
  archive      = {J_ICV},
  author       = {Peixuan Wu and Shen Yang and Jin Wu and Qian Li},
  doi          = {10.1016/j.imavis.2025.105494},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105494},
  shortjournal = {Image Vis. Comput.},
  title        = {Rif-diff: Improving image fusion based on diffusion model via residual prediction},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strengthening incomplete multi-view clustering: An attention
contrastive learning method. <em>ICV</em>, <em>157</em>, 105493. (<a
href="https://doi.org/10.1016/j.imavis.2025.105493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multi-view clustering presents greater challenges than traditional multi-view clustering. In recent years, significant progress has been made in this field, multi-view clustering relies on the consistency and integrity of views to ensure the accurate transmission of data information. However, during the process of data collection and transmission, data loss is inevitable, leading to partial view loss and increasing the difficulty of joint learning on incomplete multi-view data. To address this issue, we propose a multi-view contrastive learning framework based on the attention mechanism. Previous contrastive learning mainly focused on the relationships between isolated sample pairs, which limited the robustness of the method. Our method selects positive samples from both global and local perspectives by utilizing the nearest neighbor graph to maximize the correlation between local features and latent features of each view. Additionally, we use a cross-view encoder network with self-attention structure to fuse the low dimensional representations of each view into a joint representation, and guide the learning of the joint representation through a high confidence structure. Furthermore, we introduce graph constraint learning to explore potential neighbor relationships among instances to facilitate data reconstruction. The experimental results on six multi-view datasets demonstrate that our method exhibits significant effectiveness and superiority compared to existing methods.},
  archive      = {J_ICV},
  author       = {Shudong Hou and Lanlan Guo and Xu Wei},
  doi          = {10.1016/j.imavis.2025.105493},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105493},
  shortjournal = {Image Vis. Comput.},
  title        = {Strengthening incomplete multi-view clustering: An attention contrastive learning method},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early progression detection from MCI to AD using multi-view
MRI for enhanced assisted living. <em>ICV</em>, <em>157</em>, 105491.
(<a href="https://doi.org/10.1016/j.imavis.2025.105491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s disease (AD) is a progressive neurodegenerative disorder. Early detection is crucial for timely intervention and treatment to improve assisted living. Although magnetic resonance imaging (MRI) is a widely used neuroimaging modality for the diagnosis of AD, most studies focus on a single MRI plane, missing comprehensive spatial information. In this study, we proposed a novel approach that leverages multiple MRI planes (axial, coronal, and sagittal) from 3D MRI volumes to predict progression from stable mild cognitive impairment (sMCI) to progressive MCI (pMCI) and AD. We employed a list of convolutional neural networks, including EfficientNet-B7, ConvNext, and DenseNet-121, to extract deep features from each MRI plane, followed by a feature enhancement step through an attention module. The optimized feature set was then passed through a Bayesian-optimized pool of classification heads (i.e., multilayer perceptron (MLP), long short-term memory (LSTM), and multi-head attention (MHA)) to obtain the most effective model for each MRI plane. The optimal model for each MRI plane was then integrated into homogeneous and heterogeneous ensembles to further enhance the performance of the model. Using the ADNI dataset, the proposed model achieved 91% accuracy, 87% sensitivity, 88% specificity, and 92% AUC. To enhance the interpretability of the model, we used the Grad-CAM explainability technique to generate attention maps for each MRI plane, which identified critical brain regions affected by disease progression. These attention maps revealed consistent patterns of tissue damage across the MRI scans. The results demonstrate the effectiveness of combining multiplane MRI data with ensemble learning and attention mechanisms to improve the early detection and tracking of AD progression in patients with MCI, offering a more comprehensive diagnostic tool and enhanced clinical decision-making. The datasets, results, and code used to conduct the comprehensive analysis are made available to the research community through the following link: https://github.com/nasir3843/Early_Progression_detection_MCI-to_AD},
  archive      = {J_ICV},
  author       = {Nasir Rahim and Naveed Ahmad and Waseem Ullah and Jatin Bedi and Younhyun Jung},
  doi          = {10.1016/j.imavis.2025.105491},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105491},
  shortjournal = {Image Vis. Comput.},
  title        = {Early progression detection from MCI to AD using multi-view MRI for enhanced assisted living},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal few-shot image recognition with enhanced
semantic and visual integration. <em>ICV</em>, <em>157</em>, 105490. (<a
href="https://doi.org/10.1016/j.imavis.2025.105490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Learning (FSL) enables models to recognize new classes with only a few examples by leveraging knowledge from known classes. Although some methods incorporate class names as prior knowledge, effectively integrating visual and semantic information remains challenging. Additionally, conventional similarity measurement techniques often result in information loss, obscure distinctions between samples, and fail to capture intra-sample diversity. To address these issues, this paper presents a Multi-modal Few-shot Image Recognition (MFSIR) approach. We first introduce the Multi-Scale Interaction Module (MSIM), which facilitates multi-scale interactions between semantic and visual features, significantly enhancing the representation of visual features. We also propose the Hybrid Similarity Measurement Module (HSMM), which integrates information from multiple dimensions to evaluate the similarity between samples by dynamically adjusting the weights of various similarity measurement methods, thereby improving the accuracy and robustness of similarity assessments. Experimental results demonstrate that our approach significantly outperforms existing methods on four FSL benchmarks, with marked improvements in FSL accuracy under 1-shot and 5-shot scenarios.},
  archive      = {J_ICV},
  author       = {Chunru Dong and Lizhen Wang and Feng Zhang and Qiang Hua},
  doi          = {10.1016/j.imavis.2025.105490},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105490},
  shortjournal = {Image Vis. Comput.},
  title        = {Multi-modal few-shot image recognition with enhanced semantic and visual integration},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Object tracking based on temporal and spatial context
information. <em>ICV</em>, <em>157</em>, 105488. (<a
href="https://doi.org/10.1016/j.imavis.2025.105488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, numerous advanced trackers improve stability by optimizing the target visual appearance models or by improving interactions between templates and search areas. Despite these advancements, appearance-based trackers still primarily depend on the visual information of targets without adequately integrating spatio-temporal context information, thus limiting their effectiveness in handling similar objects around the target. To address this challenge, a novel object tracking method, TSCTrack, which leverages spatio-temporal context information, has been introduced. TSCTrack overcomes the shortcomings of traditional center-cropping preprocessing techniques by introducing Global Spatial Position Embedding, effectively preserving spatial information and capturing motion data of targets. Additionally, TSCTrack incorporates a Spatial Relationship Aggregation module and a Temporal Relationship Aggregation module—the former captures static spatial context information per frame, while the latter integrates dynamic temporal context information. This sophisticated integration allows the Dynamic Tracking Prediction module to generate precise target coordinates effectively, greatly reducing the impact of target deformations and scale changes on tracking performance. Demonstrated across multiple public tracking datasets including LaSOT, TrackingNet, UAV123, GOT-10k, and OTB, TSCTrack showcases superior performance and validates its exceptional tracking capabilities in diverse scenarios.},
  archive      = {J_ICV},
  author       = {Yan Chen and Tao Lin and Jixiang Du and Hongbo Zhang},
  doi          = {10.1016/j.imavis.2025.105488},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105488},
  shortjournal = {Image Vis. Comput.},
  title        = {Object tracking based on temporal and spatial context information},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An edge-aware high-resolution framework for camouflaged
object detection. <em>ICV</em>, <em>157</em>, 105487. (<a
href="https://doi.org/10.1016/j.imavis.2025.105487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged objects are often seamlessly assimilated into their surroundings and exhibit indistinct boundaries. The complex environmental conditions and the high intrinsic similarity between camouflaged targets and their backgrounds present significant challenges in accurately locating and fully segmenting these objects. Although existing methods have achieved remarkable performance across various real-world scenarios, they still struggle with challenging cases such as small targets, thin structures, and blurred boundaries. To address these issues, we propose a novel edge-aware high-resolution network. Specifically, we design a High-Resolution Feature Enhancement Module to exploit multi-scale features while preserving local details. Furthermore, we introduce an Edge Prediction Module to generate high-quality edge prediction maps. Subsequently, we develop an Attention-Guided Fusion Module to effectively leverage the edge prediction maps. With these key modules, the proposed model achieves real-time performance at 58 FPS and surpasses 21 state-of-the-art algorithms across six standard evaluation metrics. Source code will be publicly available at https://github.com/clelouch/EHNet .},
  archive      = {J_ICV},
  author       = {Jingyuan Ma and Tianyou Chen and Jin Xiao and Xiaoguang Hu and Yingxun Wang},
  doi          = {10.1016/j.imavis.2025.105487},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105487},
  shortjournal = {Image Vis. Comput.},
  title        = {An edge-aware high-resolution framework for camouflaged object detection},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive scale matching for remote sensing object detection
based on aerial images. <em>ICV</em>, <em>157</em>, 105482. (<a
href="https://doi.org/10.1016/j.imavis.2025.105482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing object detection based on aerial images presents challenges due to their complex backgrounds, and the utilization of specific a contextual information can enhance detection accuracy. Inadequate long-range background information may lead to erroneous detection of small remotely sensed objects, with variations in background complexity observed across different object types. In this paper, we propose a new YOLO -based real-time object detector. The detector aims to S cale- M atch the proportions of various objects in remote sensing images using the model named YOLO-SM . Specifically, this paper proposes a straightforward yet highly efficient building block that dynamically adjusts the necessary receptive field for each object, minimizing the loss of feature information caused by consecutive convolutions. Additionally, a supplementary bottom-up pathway is incorporated to improve the representation of smaller objects. Empirical evaluations conducted on DOTA-v1.0, DOTA-v1.5, DIOR-R, and HRSC2016 datasets confirm the efficacy of the proposed methodology. On DOTA-v1.0, compared to RTMDet-R-L, YOLO-SM-S achieved competitive accuracy while significantly reducing parameters by 74.8% and FLOPs by 78.5%. Compared to LSKNet on HRSC2016, YOLO-SM-Tiny dramatically reduces 76% of parameters and 90% of FLOPs and improves FPS by about three times while maintaining stable accuracy.},
  archive      = {J_ICV},
  author       = {Lu Han and Nan Li and Zeyuan Zhong and Dong Niu and Bingbing Gao},
  doi          = {10.1016/j.imavis.2025.105482},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105482},
  shortjournal = {Image Vis. Comput.},
  title        = {Adaptive scale matching for remote sensing object detection based on aerial images},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video wire inpainting via hierarchical feature mixture.
<em>ICV</em>, <em>157</em>, 105460. (<a
href="https://doi.org/10.1016/j.imavis.2025.105460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video wire inpainting aims at automatically eliminating visible wires from film footage, significantly streamlining post-production workflows. Previous models address redundancy in wire removal by eliminating redundant blocks to enhance focus on crucial wire details for more accurate reconstruction. However, once redundancy is removed, the disorganized non-redundant blocks disrupt temporal and spatial coherence, making seamless inpainting challenging. The absence of multi-scale feature fusion further limits the model’s ability to handle different wire scales and blend inpainted regions with complex backgrounds. To address these challenges, we propose a Hierarchical Feature Mixture Network (HFM-Net) that integrates two novel modules: a Hierarchical Transformer Module (HTM) and a Spatio-temporal Feature Mixture Module (SFM). Specifically, the HTM employs redundancy-aware attention modules and lightweight transformers to reorganize and fuse key high- and low-dimensional patches. The lightweight transformers are sufficient due to the reduced number of non-redundant blocks processing. By aggregating similar features, these transformers guide the alignment of non-redundant blocks and achieve effective spatio-temporal synchronization. Building on this, the SFM incorporates gated convolutions and GRU to enhance spatial and temporal integration further. Gated convolutions fuse low- and high-dimensional features, while the GRU captures temporal dependencies, enabling seamless inpainting of dynamic wire patterns. Additionally, we introduce a lightweight 3D separable convolution discriminator to improve video quality during the inpainting process while reducing computational costs. Experimental results demonstrate that HFM-Net achieves state-of-the-art performance on the video wire removal task.},
  archive      = {J_ICV},
  author       = {Zhong Ji and Yimu Su and Yan Zhang and Shuangming Yang and Yanwei Pang},
  doi          = {10.1016/j.imavis.2025.105460},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105460},
  shortjournal = {Image Vis. Comput.},
  title        = {Video wire inpainting via hierarchical feature mixture},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijar---10">IJAR - 10</h2>
<ul>
<li><details>
<summary>
(2025). Modeling and updating uncertain evidence within belief
function theory. <em>IJAR</em>, <em>182</em>, 109428. (<a
href="https://doi.org/10.1016/j.ijar.2025.109428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a framework that enhances the expressiveness of the evidential and credal interpretations of Belief Function Theory while remaining within its scope. It allows uncertain evidence to be represented “as is” by associating meaningful intervals of N or R to focal elements, providing an intrinsic justification for belief values. This improves the modeling and manipulation of knowledge. From a credal perspective, the framework enables the accurate representation of non-maximal credal sets, when their extrema are belief and plausibility functions. We introduce three update operations that extend Dempster&#39;s, geometric, and Bayesian conditioning to uncertain evidence. These updates are expressed in terms of transfer of evidence, ensuring linear complexity relative to the number of focal elements. This approach provides clear evidential semantics to Bayesian conditioning, resolves several of its anomalies by making it tractable and commutative, and explains its apparent dilation effect. Most importantly, it accurately yields the updated credal set, rather than merely providing its bounds.},
  archive      = {J_IJAR},
  author       = {Pierre Pomeret-Coquot},
  doi          = {10.1016/j.ijar.2025.109428},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109428},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Modeling and updating uncertain evidence within belief function theory},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel active learning approach to label one million
unknown malware variants. <em>IJAR</em>, <em>182</em>, 109426. (<a
href="https://doi.org/10.1016/j.ijar.2025.109426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning for classification seeks to reduce the cost of labeling samples by finding unlabeled examples about which the current model is least certain and sending them to an annotator/expert to label. Bayesian theory can provide a probabilistic view of deep neural network models by asserting a prior distribution over model parameters and estimating the uncertainties by posterior distribution over these parameters. This paper proposes two novel active learning approaches to label one million malware examples belonging to different unknown modern malware families. The first model is Inception-V4+PCA combined with several support vector machine (SVM) algorithms (UTSVM, PSVM, SVM-GSU, TBSVM). The second model is Vision Transformer based Bayesian Neural Networks ViT-BNN. Our proposed ViT-BNN is a state-of-the-art active learning approach that differs from current methods and can apply to any particular task. The experiments demonstrate that the ViT-BNN is more stable and robust in handling uncertainty.},
  archive      = {J_IJAR},
  author       = {Ahmed Bensaoud and Jugal Kalita},
  doi          = {10.1016/j.ijar.2025.109426},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109426},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel active learning approach to label one million unknown malware variants},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strong consistency and robustness of fuzzy medoids.
<em>IJAR</em>, <em>182</em>, 109425. (<a
href="https://doi.org/10.1016/j.ijar.2025.109425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Central tendency of fuzzy number-valued data can be robustly summarized with different proposals from the literature, namely, fuzzy-valued medians, trimmed means and M-estimators of location. In many applications, fuzzy numbers of a specific shape, such as trapezoidal or triangular, are considered, since the chosen shape scarcely affects the value of these summary measures, whenever the ‘meaning’ is basically preserved. Whereas, irrespective of the considered data shape, M-estimators of location under the conditions of the representer theorem and trimmed means would share the same shape, fuzzy medians do not have to. Fuzzy medians must be frequently approximated through the computation of some of their α -levels, whence methods based on them become more complex computationally. All this might discourage users from choosing these measures to describe central tendency. Fuzzy medoids have been recently introduced as an alternative that keeps both the shape of the data and the idea inspiring fuzzy medians, by focusing on the minimization of the mean distance to sample observations, but constrained to the set of fuzzy-valued data. Consequently, it is guaranteed that they always coincide with a sample observation, like it happens (or can be assumed, by convention, to happen) with the median in real-valued scenarios. This work shows the strong consistency of fuzzy medoids as estimators of the corresponding population median (with respect to the same distance) and their robustness in terms of the finite sample breakdown point. Furthermore, some simulation studies have been developed to compare the finite-sample behaviour of fuzzy medoids and other robust central tendency measures.},
  archive      = {J_IJAR},
  author       = {Beatriz Sinova and Sergio Palacio-Vega and María Ángeles Gil},
  doi          = {10.1016/j.ijar.2025.109425},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109425},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Strong consistency and robustness of fuzzy medoids},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval three-way decision model based on data envelopment
analysis and prospect theory. <em>IJAR</em>, <em>182</em>, 109424. (<a
href="https://doi.org/10.1016/j.ijar.2025.109424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the three-way decision theory was proposed, two paradigms, “narrow sense” and “broad sense”, have gradually evolved, each demonstrating unique advantages in handling multi-granularity information and uncertainty analysis. These approaches provide a systematic theoretical framework for solving complex decision-making problems. However, the traditional three-way decision model has limitations in multi-input-output scenarios, and the current method is still insufficient in characterizing the risk attitudes and psychological characteristics of decision-makers. To address these challenges, this paper proposes an interval three-way decision model based on Data Envelopment Analysis (DEA) and Prospect theory for multi-input-output decision problems. First, we define a many-valued decision information system based on DEA, using benefit scores from various orientations as decision attributes to formulate decision strategies. Second, to mitigate the subjective bias introduced by reference points in Prospect theory, we introduce triangular fuzzy reference points that account for interval uncertainty. Additionally, we propose a calculation method for the multi-input-output interval membership function of Decision-Making Units (DMUs) and a construction method for the value function. Comprehensive decision rules are derived by calculating the overall prospect value. Finally, the effectiveness of the proposed model is validated using a series of experiments across multiple datasets, with comparisons to over ten existing methods. The results indicate that the model achieves competitive performance in terms of classification accuracy and decision-making efficiency, demonstrating its strengths in addressing uncertain multi-input-output decision problems while incorporating decision-makers&#39; risk preferences in an interval environment.},
  archive      = {J_IJAR},
  author       = {Xianwei Xin and Xiao Yu and Tao Li and Zhanao Xue},
  doi          = {10.1016/j.ijar.2025.109424},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109424},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Interval three-way decision model based on data envelopment analysis and prospect theory},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification in regression neural networks
using evidential likelihood-based inference. <em>IJAR</em>,
<em>182</em>, 109423. (<a
href="https://doi.org/10.1016/j.ijar.2025.109423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a new method for quantifying prediction uncertainty in regression neural networks using evidential likelihood-based inference. The method is based on the Gaussian approximation of the likelihood function and the linearization of the network output with respect to the weights. Prediction uncertainty is described by a random fuzzy set inducing a predictive belief function. Two models are considered: a simple one with constant conditional variance and a more complex one in which the conditional variance is predicted by an auxiliary neural network. Both models are trained by regularized log-likelihood maximization using a standard optimization algorithm. The postprocessing required for uncertainty quantification only consists of one computation and inversion of the Hessian matrix after convergence. Numerical experiments show that the approximations are quite accurate and that the method allows for conservative uncertainty-aware predictions.},
  archive      = {J_IJAR},
  author       = {Thierry Denœux},
  doi          = {10.1016/j.ijar.2025.109423},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109423},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Uncertainty quantification in regression neural networks using evidential likelihood-based inference},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way clustering based on the graph of local density
trend. <em>IJAR</em>, <em>182</em>, 109422. (<a
href="https://doi.org/10.1016/j.ijar.2025.109422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way clustering demonstrates its unique advantages in dealing with the issues of information ambiguity and unclear boundaries present in real-world datasets. The core and boundary region in the data are identified as key features of cluster analysis. Typically, data is segmented into three regions based on a set of predetermined global thresholds, a common practice in three-way clustering. However, this method, which relies on global thresholds, often overlooks the intrinsic distribution patterns within the dataset and determining these thresholds a priori can be quite challenging. In this paper, we propose a three-way clustering method based on the graph of local density trend (3W-GLDT). Specifically, the algorithm first uses a density-decreasing strategy to build subgraphs and divide the core region data. Then, the unreasonable connection is corrected by using isolated forest, which increases the number of core points and enlarges the distribution range of core points. Next, a three-way allocation strategy is proposed, which fully considers the degree of local aggregation of subgraphs and the natural domain information of each data object to ensure the correct allocation. Finally, the proposed algorithm is compared with 8 different clustering methods on 8 synthetic datasets and 10 UCI real datasets. The experimental results show that the 3W-GLDT algorithm has good performance and clustering results.},
  archive      = {J_IJAR},
  author       = {Haifeng Yang and Weiqi Wang and Jianghui Cai and Jie Wang and Yating Li and Yaling Xun and Xujun Zhao},
  doi          = {10.1016/j.ijar.2025.109422},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109422},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Three-way clustering based on the graph of local density trend},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Superior scoring rules for probabilistic evaluation of
single-label multi-class classification tasks. <em>IJAR</em>,
<em>182</em>, 109421. (<a
href="https://doi.org/10.1016/j.ijar.2025.109421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces novel superior scoring rules called Penalized Brier Score ( PBS ) and Penalized Logarithmic Loss ( PLL ) to improve model evaluation for probabilistic classification. Traditional scoring rules like Brier Score and Logarithmic Loss sometimes assign better scores to misclassifications in comparison with correct classifications. This discrepancy from the actual preference for rewarding correct classifications can lead to suboptimal model selection. By integrating penalties for misclassifications, PBS and PLL modify traditional proper scoring rules to consistently assign better scores to correct predictions. Formal proofs demonstrate that PBS and PLL satisfy strictly proper scoring rule properties while also preferentially rewarding accurate classifications. Experiments showcase the benefits of using PBS and PLL for model selection, model checkpointing, and early stopping. PBS exhibits a higher negative correlation with the F1 score compared to the Brier Score during training. Thus, PBS more effectively identifies optimal checkpoints and early stopping points, leading to improved F1 scores. Comparative analysis verifies models selected by PBS and PLL achieve superior F1 scores. Therefore, PBS and PLL address the gap between uncertainty quantification and accuracy maximization by encapsulating both proper scoring principles and explicit preference for true classifications. The proposed metrics can enhance model evaluation and selection for reliable probabilistic classification.},
  archive      = {J_IJAR},
  author       = {Rouhollah Ahmadian and Mehdi Ghatee and Johan Wahlström},
  doi          = {10.1016/j.ijar.2025.109421},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109421},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Superior scoring rules for probabilistic evaluation of single-label multi-class classification tasks},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel covering rough set model based on granular-ball
computing for data with label noise. <em>IJAR</em>, <em>182</em>,
109420. (<a href="https://doi.org/10.1016/j.ijar.2025.109420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a novel granular computing model, granular-ball computing (GBC) has a notable advantage of robustness. Inspired by GBC, a granular-ball covering rough set (GBCRS) model whose covering is made up of granular-balls (GBs) is proposed. GBCRS is the first covering rough set that fits the data distribution well. Inheriting the robustness of GBC, GBCRS can work in label noise environments. First, the optimization objective function of GBs in GBCRS is given. In order to ensure the quality of generated GBs, this function is subject to three constraints. Second, the GBCRS model is proposed. The purity threshold is used to relax the related notions so that GBCRS can be used in label noise environments. Subsequently, GBCRS is applied to the covering granular reduction and attribute reduction in label noise environments. In covering granular reduction, we propose an intuitive, understandable and anti-noise GBCRS-based granular reduction (GBCRS-GR) algorithm, which also solves the optimization objective function of GBs. Based on GBCRS-GR, a GBCRS-based attribute reduction (GBCRS-AR) algorithm is proposed with the classification ability of the attribute subset as the evaluation. The experiments on UCI datasets illustrate that proposed algorithm is more robust against label noise than the comparison ones.},
  archive      = {J_IJAR},
  author       = {Xiaoli Peng and Yuanlin Gong and Xiang Hou and Zhan Tang and Yabin Shao},
  doi          = {10.1016/j.ijar.2025.109420},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109420},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel covering rough set model based on granular-ball computing for data with label noise},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surprisingly popular-based multivariate conceptual knowledge
acquisition method. <em>IJAR</em>, <em>182</em>, 109419. (<a
href="https://doi.org/10.1016/j.ijar.2025.109419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal Concept Analysis (FCA) plays a crucial role in uncertain artificial intelligence by revealing specialization and generalization relationships among concepts. Unlike artificial neural network methods, concepts are fundamental to human cognition and learning, making knowledge acquisition and decision-making methods highly significant, especially when influenced by data and cognition. However, existing FCA models and extensions predominantly emphasize data-driven approaches, often disregarding the cognitive attributes of individual learners. This paper introduces a novel method for acquiring diverse conceptual knowledge and a cognition-enhanced decision-making approach based on the Surprisingly Popular (SP) method. Initially, it defines a new multivariate relational formal context and its corresponding decision-making method to facilitate a more sophisticated exploration of uncertain information. Additionally, it presents a method for quantifying the similarity of multivariate concepts. The SP approach is then integrated to identify the core and peripheral multivariate concepts within the multivariate concept lattice. Furthermore, the paper develops a multivariate cognitive decision-making method and presents the corresponding algorithm. Finally, instance analysis is conducted on the UCI dataset to compare the proposed method with state-of-the-art models. The results indicate that the proposed model effectively uncovers core and peripheral concepts within uncertain information by incorporating human cognitive decision processes.},
  archive      = {J_IJAR},
  author       = {Xianwei Xin and Shiting Yuan and Tao Li and Zhanao Xue and Chenyang Wang},
  doi          = {10.1016/j.ijar.2025.109419},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109419},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Surprisingly popular-based multivariate conceptual knowledge acquisition method},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weightedness measures from inequality systems.
<em>IJAR</em>, <em>182</em>, 109418. (<a
href="https://doi.org/10.1016/j.ijar.2025.109418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A simple game is a cooperative game where some coalitions among players or voters became the (monotonic) set of winning coalitions, and the other ones form the set of losing coalitions. It is well-known that weighted voting games form a strict subclass of simple games, where each player has a voting weight so that a coalition wins if and only if the sum of weights of their members exceeds a given quota, otherwise it loses. This work studies how far away a simple game is for being representable as a weighted voting game, which allows for a more compact representation. There are several measures that determine the weightedness of a simple game, such as the dimension, the trade-robustness, the critical threshold value associated with the α -roughly weightedness property, etc. In this work we propose some new weightedness measures, all based on linear programming. In general terms, for a given simple game, a linear program is used to identify its weightedness: (i) the ϵ -roughly value ( μ ϵ ), (ii) the Z + -roughly value ( μ Z + ), (iii) the Δ-roughly value ( μ Δ ), and (iv) the outlier value ( Ψ M ). We show a close relation between the known critical threshold value of weightedness and the new measure μ Δ . Finally, we also present an exhaustive comparison of weightedness measures for simple games with up to six players.},
  archive      = {J_IJAR},
  author       = {Maria Albareda-Sambola and Xavier Molinero and Salvador Roura},
  doi          = {10.1016/j.ijar.2025.109418},
  journal      = {International Journal of Approximate Reasoning},
  month        = {7},
  pages        = {109418},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Weightedness measures from inequality systems},
  volume       = {182},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ipl---8">IPL - 8</h2>
<ul>
<li><details>
<summary>
(2025). A note on the method of equal shares. <em>IPL</em>,
<em>190</em>, 106576. (<a
href="https://doi.org/10.1016/j.ipl.2025.106576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Method of Equal Shares (ES) is a popular approval-based multi-winner voting rule, which was originally proposed by Peters and Skowron. It satisfies several well-known representation axioms, like extended justified representation (EJR) and priceability, and it can be computed in polynomial time. Further, it has already been employed in several real participatory budgeting elections. In this note, we prove that ES is an instance of the EJR-Exact family of voting rules that also satisfy EJR and were proposed by Aziz et al. 2018 before the work of Peters and Skowron.},
  archive      = {J_IPL},
  author       = {Luis Sánchez-Fernández},
  doi          = {10.1016/j.ipl.2025.106576},
  journal      = {Information Processing Letters},
  month        = {8},
  pages        = {106576},
  shortjournal = {Inf. Process. Lett.},
  title        = {A note on the method of equal shares},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A note on the complexity of one-sided crossing minimization
of trees. <em>IPL</em>, <em>190</em>, 106575. (<a
href="https://doi.org/10.1016/j.ipl.2025.106575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2011, Harrigan and Healy claimed that one-sided crossing minimization can be solved in polynomial time on trees [1] . We point out a counterexample to their claims, and show that one-sided crossing minimization is -hard for trees.},
  archive      = {J_IPL},
  author       = {Alexander Dobler},
  doi          = {10.1016/j.ipl.2025.106575},
  journal      = {Information Processing Letters},
  month        = {8},
  pages        = {106575},
  shortjournal = {Inf. Process. Lett.},
  title        = {A note on the complexity of one-sided crossing minimization of trees},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the complexity of some restricted variants of quotient
pigeon and a weak variant of kőnig. <em>IPL</em>, <em>190</em>, 106574.
(<a href="https://doi.org/10.1016/j.ipl.2025.106574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most famous TFNP subclasses is PPP , which is the set of all search problems whose totality is guaranteed by the pigeonhole principle. The author&#39;s recent preprint [1] has introduced a TFNP problem related to the pigeonhole principle over a quotient set, called Quotient Pigeon , and shown that the problem Quotient Pigeon is not only PPP -hard but also PLS -hard. In this paper, we formulate other computational problems related to the pigeonhole principle over a quotient set via an explicit representation of the equivalence classes. Our new formulation introduces a non-trivial PPP ∩ PPA k -complete problem for every k ≥ 2 . Furthermore, we consider the computational complexity of a computational problem related to Kőnig&#39;s lemma, which is a weaker variant of the problem formulated by Pasarkar et al. [2] . We show that our weaker variant is PPAD -hard and is in PPP ∩ PPA .},
  archive      = {J_IPL},
  author       = {Takashi Ishizuka},
  doi          = {10.1016/j.ipl.2025.106574},
  journal      = {Information Processing Letters},
  month        = {8},
  pages        = {106574},
  shortjournal = {Inf. Process. Lett.},
  title        = {On the complexity of some restricted variants of quotient pigeon and a weak variant of kőnig},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Friends-and-strangers is PSPACE-complete. <em>IPL</em>,
<em>190</em>, 106573. (<a
href="https://doi.org/10.1016/j.ipl.2025.106573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The friends-and-strangers problem is defined on two graphs X and Y of the same order n , where X is the location graph on a set of locations V ( X ) and Y is the friendship graph on a set of people V ( Y ) . A configuration is a bijection from V ( X ) to V ( Y ) , representing an arrangement of n people at n locations. The friends-and-stranger problem investigates the connectivity of two arbitrary configurations by a sequence of swaps of two people that are neighbors (i.e., adjacent in X ) and friends (i.e., adjacent in Y ). In this paper, we show that the friends-and-strangers problem with subcubic planar location graphs X is PSPACE -complete by a reduction from the Ncl (non-deterministic constraint logic) problem.},
  archive      = {J_IPL},
  author       = {Chao Yang and Zhujun Zhang},
  doi          = {10.1016/j.ipl.2025.106573},
  journal      = {Information Processing Letters},
  month        = {8},
  pages        = {106573},
  shortjournal = {Inf. Process. Lett.},
  title        = {Friends-and-strangers is PSPACE-complete},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple 4-approximation algorithm for maximum agreement
forests on multiple unrooted binary trees. <em>IPL</em>, <em>190</em>,
106572. (<a href="https://doi.org/10.1016/j.ipl.2025.106572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximum agreement forests have been used as a measure of dissimilarity of two or more phylogenetic trees on a given set of taxa. An agreement forest is a set of trees that can be obtained from each of the input trees by deleting edges and suppressing degree-2 vertices. A maximum agreement forest is such a forest with the minimum number of components. We present a simple 4-approximation algorithm for computing a maximum agreement forest of multiple unrooted binary trees. This algorithm applies LP rounding to an extension of a recent ILP formulation of the maximum agreement forest problem on two trees by Van Wersch et al. [13] . We achieve the same approximation ratio as the algorithm by Chen et al. [3] , but our algorithm is extremely simple. We also prove that no algorithm based on the ILP formulation by Van Wersch et al. can achieve an approximation ratio of 4 − ε , for any ε &gt; 0 , even on two trees. To this end, we prove that the integrality gap of the ILP approaches 4 as the size of the two input trees grows.},
  archive      = {J_IPL},
  author       = {Jordan Dempsey and Leo van Iersel and Mark Jones and Norbert Zeh},
  doi          = {10.1016/j.ipl.2025.106572},
  journal      = {Information Processing Letters},
  month        = {8},
  pages        = {106572},
  shortjournal = {Inf. Process. Lett.},
  title        = {A simple 4-approximation algorithm for maximum agreement forests on multiple unrooted binary trees},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lower bound proof for the size of BDDs representing a
shifted addition. <em>IPL</em>, <em>190</em>, 106571. (<a
href="https://doi.org/10.1016/j.ipl.2025.106571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision Diagrams (DDs) are among the most popular representations for Boolean functions. They are widely used in the synthesis and verification of digital circuits. The size (i.e., number of nodes) and computation time (required time for performing operations) are two important parameters that determine the efficiency of a DD in different applications. It has been proven that some DDs can represent specific functions in polynomial space or perform certain operations in polynomial time. For example, Binary Decision Diagrams (BDDs) are capable of representing a wide variety of functions (e.g. integer addition) in polynomial space with respect to the input size. However, there are also some functions (e.g., integer multiplication) for which the exponential lower-bounds have been proven for the BDD sizes. In this paper, we investigate the space complexity of representing an integer addition, where one of the operands is shifted to the right by an arbitrary value. We call this function the shifted addition. This function is widely used in many digital circuits, e.g., floating point adders. We prove that the size of the BDD representing a shifted addition has exponential space complexity with respect to the input size. It is an important step towards clarifying the reasons behind the failure of BDD-based verification and synthesis when they are applied to the circuits containing shifted addition, e.g., floating point adders.},
  archive      = {J_IPL},
  author       = {Jan Kleinekathöfer and Alireza Mahzoon and Rolf Drechsler},
  doi          = {10.1016/j.ipl.2025.106571},
  journal      = {Information Processing Letters},
  month        = {8},
  pages        = {106571},
  shortjournal = {Inf. Process. Lett.},
  title        = {Lower bound proof for the size of BDDs representing a shifted addition},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Faster algorithms and a smaller kernel for cliques or trees
vertex deletion. <em>IPL</em>, <em>190</em>, 106570. (<a
href="https://doi.org/10.1016/j.ipl.2025.106570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the Cliques or Trees Vertex Deletion problem, the input is a graph G and an integer k , and the goal is to decide whether there is a set of at most k vertices whose removal from G result in a graph in which every connected component is either a clique or a tree. In this paper we give an O ⁎ ( 3.46 k ) -time deterministic algorithm, an O ⁎ ( 3.103 k ) -time randomized algorithm, and a kernel with O ( k 4 ) vertices for Cliques or Trees Vertex Deletion .},
  archive      = {J_IPL},
  author       = {Dekel Tsur},
  doi          = {10.1016/j.ipl.2025.106570},
  journal      = {Information Processing Letters},
  month        = {8},
  pages        = {106570},
  shortjournal = {Inf. Process. Lett.},
  title        = {Faster algorithms and a smaller kernel for cliques or trees vertex deletion},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online delay management on a single train line with
predictions. <em>IPL</em>, <em>190</em>, 106569. (<a
href="https://doi.org/10.1016/j.ipl.2025.106569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Online Delay Management on a Single Train Line (ODMP) deals with the question at which station a train should wait for delayed passengers, instead of forcing them to take the next train. Waiting at a station increases the delay of all passengers that are already on board, and the goal is to minimize the total passenger delay. An online algorithm learns about the number of delayed passengers at a station only when reaching this station. We study the ODMP with an additional prediction on the future input data, which an online algorithm can utilize. Two desired qualities for online algorithms with prediction are called consistency and robustness, denoting the competitive ratio in case of best and worst prediction respectively. We present a family of algorithms, which uses a hyperparameter λ ∈ ( 0 , 1 ) measuring the “doubt” about the given prediction. This allows to achieve ( 1 + λ ) -consistency and ( 1 + 1 / λ ) -robustness. Moreover, we provide a lower bound for the trade-off between consistency and robustness for two variously detailed prediction models, showing that our algorithm achieves an asymptotically optimal trade-off for small values of λ .},
  archive      = {J_IPL},
  author       = {Daniel Eichhorn and Sven O. Krumke},
  doi          = {10.1016/j.ipl.2025.106569},
  journal      = {Information Processing Letters},
  month        = {8},
  pages        = {106569},
  shortjournal = {Inf. Process. Lett.},
  title        = {Online delay management on a single train line with predictions},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="isci---20">ISCI - 20</h2>
<ul>
<li><details>
<summary>
(2025). A stable framework-based modeling of the complex dynamical
system using a double context layered with self-weighted output feedback
loop elman recurrent neural network. <em>ISCI</em>, <em>712</em>,
122132. (<a href="https://doi.org/10.1016/j.ins.2025.122132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a modified structure of the classical Elman recurrent neural network (ERNN) named Double context layered with output self-weighted feedback loop Elman recurrent neural network (DCLOSWFLERNN) is proposed. It consists of two additional components (as compared to the ERNN model): one extra context layer and an adjustable weighted feedback loop in the output layer. This has resulted in the model&#39;s ability to approximate the underlying unknown mathematical relationship relating to the input-output data (obtained from any complex dynamical plant). The second emphasis of this paper pertains to the stability component, wherein the Lyapunov stability is utilized to develop a stable Back-propagation (BP) based weight update rule. Lastly, an adjustable learning rate is also suggested, which contributes to improving the learning algorithm&#39;s overall performance. The simulation results reveal that the proposed model has given better modeling accuracy as compared to the other considered neural models. This can be observed from the values obtained of the error-based indicators such as Root Mean Square Error (RMSE) and Mean Average Error (MSE). The values of RMSE and MAE obtained from the proposed model during the modeling procedure are 0.0028 and 0.0035 which are the least among the obtained with other neural models.},
  archive      = {J_ISCI},
  author       = {Rajesh Kumar},
  doi          = {10.1016/j.ins.2025.122132},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122132},
  shortjournal = {Inf. Sci.},
  title        = {A stable framework-based modeling of the complex dynamical system using a double context layered with self-weighted output feedback loop elman recurrent neural network},
  volume       = {712},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-aware differential equation discovery with
automated background knowledge extraction. <em>ISCI</em>, <em>712</em>,
122131. (<a href="https://doi.org/10.1016/j.ins.2025.122131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In differential equation discovery algorithms, a priori expert knowledge is mainly used to constrain the form of the expected equation, making it impossible for the algorithm to truly discover equations. As a result, most differential equation discovery algorithms try to recover the coefficients for a known fixed form of the equation. In this paper, we, using the initial guess obtained automatically, modify the structure space instead of imposing rigid constraints so that specific terms appear more likely within the cross-over and mutation operators. In this way, we mimic expertly chosen terms while preserving the possibility of obtaining any form of differential equation. The paper shows that the extraction and use of knowledge allow it to outperform the SINDy algorithm in terms of search stability and robustness. Synthetic examples are given for Burgers, wave, and Korteweg–de Vries equations.},
  archive      = {J_ISCI},
  author       = {Elizaveta Ivanchik and Alexander Hvatov},
  doi          = {10.1016/j.ins.2025.122131},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122131},
  shortjournal = {Inf. Sci.},
  title        = {Knowledge-aware differential equation discovery with automated background knowledge extraction},
  volume       = {712},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic enhanced bi-syntactic graph convolutional network
for aspect-based sentiment analysis. <em>ISCI</em>, <em>712</em>,
122130. (<a href="https://doi.org/10.1016/j.ins.2025.122130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous work on fine-grained sentiment analysis focuses on establishing the semantic correlations between words by means of attention mechanisms. More recently, effects of syntax-based models, applying graph convolution operation over dependency trees, are highlighted due to their superiority. However, these methods still have deficiencies. For one thing, little aspect-specific information is considered during semantic modeling of contextual words, which introduces irrelevant noise toward the aspect. For another, current syntax-based approaches either ignore the syntactic constituent knowledge, or fail to maintain the syntactic information from the reconstructed constituent tree. As such, no relation among words, phrases and clauses is built. In this work, a Semantic Enhanced Bi-Syntax Graph Convolutional Network (SEBS-GCN) is proposed to enhance semantics of context to the aspect, and capture the sentiment relevance among words, phrases and clauses. Specifically, we devise an aspect-aware gated mechanism to obtain the aspect-aware feature, based on the semantic correlations between the specific aspect and its contexts. Furthermore, the syntax information of the constituent tree is sufficiently exploited to analyze the hierarchical structure and the logical relation among words, phrases and clauses, based on which to capture the sentiment clues of the aspect.},
  archive      = {J_ISCI},
  author       = {Junyang Xiao and Yun Xue and Fenghuan Li},
  doi          = {10.1016/j.ins.2025.122130},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122130},
  shortjournal = {Inf. Sci.},
  title        = {Semantic enhanced bi-syntactic graph convolutional network for aspect-based sentiment analysis},
  volume       = {712},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fuzzy funnel control of nonlinear multi-agent
systems via dual-channel event-triggered strategy. <em>ISCI</em>,
<em>712</em>, 122129. (<a
href="https://doi.org/10.1016/j.ins.2025.122129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the constraint control problem of nonlinear multi-agent systems (MASs). An adjustable funnel control is proposed by designing a new transformation variable, which ensures the consensus errors converge within the funnel. By utilizing adaptive fuzzy logic systems, the unknown dynamics of agents are approximated. A novel dual-channel event-triggered strategy is designed by employing the concept of two channels, to save the communication resources and controller resources at the same time. Meanwhile, the Zeno behavior is avoided as well. Two simulation results demonstrate the effectiveness of the proposed control approach.},
  archive      = {J_ISCI},
  author       = {Xiaoyang Liu and Minghao Hui and Lu Fan and Wenwu Yu and Jinde Cao},
  doi          = {10.1016/j.ins.2025.122129},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122129},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy funnel control of nonlinear multi-agent systems via dual-channel event-triggered strategy},
  volume       = {712},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPSN-STHA: A dynamic perception model of similar nodes with
spatial-temporal heterogeneity attention for traffic flow forecasting.
<em>ISCI</em>, <em>712</em>, 122126. (<a
href="https://doi.org/10.1016/j.ins.2025.122126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precisely capturing spatial-temporal feature correlations represents an effective approach for improving the traffic flow prediction performance. However, accurate capturing of spatial-temporal features in traffic systems faces certain challenges, such as long-range correlations and node heterogeneity. To overcome these issues, this paper introduces a novel traffic flow prediction model that incorporates spatial-temporal heterogeneous attention, allowing for dynamic perception of similar nodes. In the proposed model, a filter network dynamic parameter memory generator is used for real-time parameter adjustment, which assigns greater weights to nodes with higher similarity to mitigate spatial-temporal heterogeneity. In addition, a similarity-based node computation method, which uses the Wasserstein distance, is introduced to construct a spatial-temporal association matrix, allowing for the dynamic capturing of long-range correlations between nodes. The model&#39;s efficacy is validated through experiments on four publicly available traffic datasets. Results show that the proposed model consistently outperforms the best baselines in predictive accuracy. Furthermore, this study examines factors such as training data size, dimensionality, the number of attention heads, and the threshold of the spatial-temporal association matrix, and includes an ablation study to evaluate the model&#39;s overall performance.},
  archive      = {J_ISCI},
  author       = {Jinnan Yang and Wentian Cui and Qing Shen and Jungang Lou},
  doi          = {10.1016/j.ins.2025.122126},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122126},
  shortjournal = {Inf. Sci.},
  title        = {DPSN-STHA: A dynamic perception model of similar nodes with spatial-temporal heterogeneity attention for traffic flow forecasting},
  volume       = {712},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time safe reinforcement learning control of
multi-player nonzero-sum game for quadcopter systems. <em>ISCI</em>,
<em>712</em>, 122117. (<a
href="https://doi.org/10.1016/j.ins.2025.122117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a finite-time safe reinforcement learning control algorithm for multi-player nonzero-sum games (FT-SRL-NZS). In addressing the finite-time safe optimal control issue, value functions incorporating designated barrier functions for the involved players are established within the transformed finite-time stable space. The finite-time safe optimal controller is derived from the solution to the transformed Nash equilibrium condition. An actor-critic structure is proposed for solving the Hamilton-Jacobi-Bellman (HJB) equation in the finite-time stable space, aimed at approximating the finite-time optimal value and its corresponded controller using a novel finite-time concurrent learning update law. A dynamic event-trigger rule adjusts the trigger condition in real time, thereby minimizing the computational and communicative demands associated with calculating Nash equilibrium. Lyapunov stability analysis is employed to examine the finite-time equilibrium of the closed-loop system. Numerical simulations and unmanned aerial vehicle (UAV) hardware tests are carried out to illustrate the efficacy of the proposed finite-time safe control algorithm.},
  archive      = {J_ISCI},
  author       = {Junkai Tan and Shuangsi Xue and Qingshu Guan and Kai Qu and Hui Cao},
  doi          = {10.1016/j.ins.2025.122117},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122117},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time safe reinforcement learning control of multi-player nonzero-sum game for quadcopter systems},
  volume       = {712},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational graph autoencoder-driven balancing strategy for
multimodal multi-objective optimization. <em>ISCI</em>, <em>712</em>,
122116. (<a href="https://doi.org/10.1016/j.ins.2025.122116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization aims to balance the diversity and the convergence to obtain multiple complete and uniform Pareto optimal solution sets. In recent years, using machine learning models to improve the performance of evolutionary algorithms has become a hot topic. However, few studies utilize machine learning models to solve the imbalance problem between the diversity and the convergence in multimodal multi-objective optimization. Therefore, this paper proposes a multimodal multi-objective evolutionary algorithm driven by variational graph autoencoder (VGAE), which can reproduce diversified offspring with good convergence by reconstructing the parent population. In reproduction, the parent population is constructed into graph data, and the VGAE is adopted to map the graph data to the latent space, obtaining the distribution information represented by the low-dimensional vector. By sampling the distribution, the VGAE can generate the offspring with the similar distribution to the parent, which can fill the less dense regions in the decision space and improve the exploitation ability. In archive updating, the convergence state based on the inverted generation distance between the non-dominated solutions and the worst dominated solutions is defined, and the state information of the convergence archive is transferred to the diversity archive to determine the dynamic niche. This niche comprehensively considers the distribution state and convergence degree of solutions in the diversity and convergence archives, which is employed to calculate the local convergence quality, retaining more promising solutions. The results of 48 benchmark problems and a practical application show that the proposed algorithm outperforms eight competitive algorithms.},
  archive      = {J_ISCI},
  author       = {Lei Yang and Erlei Zhang and Qianlong Dang},
  doi          = {10.1016/j.ins.2025.122116},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122116},
  shortjournal = {Inf. Sci.},
  title        = {Variational graph autoencoder-driven balancing strategy for multimodal multi-objective optimization},
  volume       = {712},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial multi-label learning with label and classifier
correlations. <em>ISCI</em>, <em>712</em>, 122101. (<a
href="https://doi.org/10.1016/j.ins.2025.122101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In partial multi-label learning (PML), each instance is associated with a set of candidate labels, which contains multiple relevant labels and noisy labels. The disambiguation-based strategy has been widely adopted by most existing PML methods, i.e., recovering the information of real labels from the set of candidate labels. To achieve this goal, these methods usually assume that global label correlations among different categories are applicable to all the instances, but local label correlations are seldom considered. In this paper, we propose a novel PML method to address this issue, termed Partial Multi-Label Learning with Label and Classifier Correlations (PML-LC), where both global and local label correlations are taken into consideration. Specifically, the Minimum Spanning Tree (MST) technique is employed to obtain the global manifold structure information of the feature space, which is then transformed into the label space, acting as global label correlations. Moreover, a local label manifold regularizer is introduced to capture local label correlations. Besides, a covariance regularizer is also adopted to model classifier correlations when learning the mapping matrix. Experimental results on thirteen PML datasets demonstrate its superior performance over several state-of-the-art PML approaches.},
  archive      = {J_ISCI},
  author       = {Ke Wang and Yahu Guan and Yunyu Xie and Zhaohong Jia and Hong Ye and Zhangling Duan and Dong Liang},
  doi          = {10.1016/j.ins.2025.122101},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122101},
  shortjournal = {Inf. Sci.},
  title        = {Partial multi-label learning with label and classifier correlations},
  volume       = {712},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Herbal ingredient-target interaction prediction via
multi-modal learning. <em>ISCI</em>, <em>711</em>, 122115. (<a
href="https://doi.org/10.1016/j.ins.2025.122115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational prediction of herbal ingredient-target interactions (ITIs) is essential for understanding the mechanisms of action (MoA) of herbal medicine. However, many existing computational methods have yet to fully utilize the multi-modal knowledge of herbs, and the potential noise in literature-mined ITI data has been overlooked. To address these challenges, we propose Multi-ITI, a multi-modal learning framework to learn molecular biological and network topological features for ingredients and targets from multi-modal herbal data, including ingredient SMILES sequences, target protein sequences, ingredient SMILES sequence similarity, target protein sequence similarity, and ingredient-target interactions. Multi-ITI consists of a biological feature learning module and a heterogeneous graph learning module. The biological feature learning module integrates pre-trained models to build deep feature representations for ingredients and targets, while the heterogeneous graph learning module leverages a heterogeneous graph neural network with dynamic attention mechanisms to capture ingredient-target network interactions and mitigate the impact of noisy connections. Experimental results on three public datasets demonstrate that Multi-ITI outperforms six state-of-the-art methods. Additionally, we validate the effectiveness of Multi-ITI through molecular docking simulations and comparisons with recent studies, further highlighting its superior predictive performance and practical applicability.},
  archive      = {J_ISCI},
  author       = {Xudong Liang and Guichuan Lai and Jintong Yu and Tao Lin and Chaochao Wang and Wei Wang},
  doi          = {10.1016/j.ins.2025.122115},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122115},
  shortjournal = {Inf. Sci.},
  title        = {Herbal ingredient-target interaction prediction via multi-modal learning},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive stochastic configuration network based on online
active learning for evolving data streams. <em>ISCI</em>, <em>711</em>,
122113. (<a href="https://doi.org/10.1016/j.ins.2025.122113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Configuration Networks (SCNs) have exhibited significant potential in data mining, owing to their advantages in fast incremental construction and universal approximation capabilities. However, less researches were done on SCNs-based classification models for concept-drifting data streams. The so-called drifts refer to data distributions changing over time that may degrade the classification performance of SCNs trained on historical data. The previous drift adaptation approach is to discard all the hidden nodes of SCNs, and then learn a new model with new instances, in which the valuable historical information cannot be fully utilized. In addition, labeling all newly-arrived instances is time-consuming and impractical. To address these issues, an adaptive stochastic configuration network embedding online active learning is proposed. Crucially, a query strategy is developed to select representative instances for labeling based on the change degree of instances density and their uncertainty. An online update mechanism is employed to incrementally update the network&#39;s output parameters instance by instance. To rationally forget the outdated information and learn new concepts, a dynamic adjustment mechanism adaptively adds or prunes nodes in the SCN model. Experimental results for nine datasets confirm that our algorithm outperforms six popular ones on classification accuracy.},
  archive      = {J_ISCI},
  author       = {Yinan Guo and Jiayang Pu and Jiale He and Botao Jiao and Jianjiao Ji and Shengxiang Yang},
  doi          = {10.1016/j.ins.2025.122113},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122113},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive stochastic configuration network based on online active learning for evolving data streams},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised manifold regularized multi-task learning
with privileged information. <em>ISCI</em>, <em>711</em>, 122112. (<a
href="https://doi.org/10.1016/j.ins.2025.122112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) represents an advanced learning paradigm that improves the generalization ability and learning efficiency of a model by learning multiple related tasks simultaneously. The fundamental principle of multi-task learning is the transfer of information between tasks. Nevertheless where data is limited in quantity, effectively modeling inter-task correlations is a significant challenge. We propose a novel method, semi-supervised manifold regularized multi-task learning with privileged information (MSMTL-PI), that effectively leverages the intrinsic geometric structure of data by enforcing manifold regularization and subspace learning techniques. Specifically, a similarity graph is constructed over both labeled and unlabeled samples, ensuring the preservation of local geometric relationships between data points, and manifold regularization is applied as a constraint. Concurrently, information sharing on low-dimensional subspace makes the relationship modeling between tasks more reasonable. Furthermore, a significant amount of privileged information is incorporated into the training phase, thereby optimizing the decision boundary and reducing the impact of insufficient labeled samples on the model. There is substantial experimental evidence that MSMTL-PI markedly enhances the performance of image and text classification tasks, achieving superior classification accuracy with minimal labeled data. Across 15 benchmark datasets, MSMTL-PI consistently outperforms existing methods, achieving an average F1-scores improvement of 1.92% compared to the best baseline, with a maximum gain of 4.17%.},
  archive      = {J_ISCI},
  author       = {Bo Liu and Baoqing Li and Yanshan Xiao and Zhitong Wang and Boxu Zhou and Shengxin He and Chenlong Ye and Fan Cao},
  doi          = {10.1016/j.ins.2025.122112},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122112},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised manifold regularized multi-task learning with privileged information},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-fragile fuzzy control of input-saturated systems with
global prescribed performance via an error-triggered mechanism.
<em>ISCI</em>, <em>711</em>, 122111. (<a
href="https://doi.org/10.1016/j.ins.2025.122111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An error-triggered mechanism-based non-fragile prescribed performance control (PPC) scheme is proposed for input-saturated systems in this paper. Unlike existing non-fragile PPC schemes, the proposed scheme only acts on the single prescribed performance boundary (PPB) and automatically relaxes only when the tracking error is about to contact the PPB. Moreover, through the redesign of the PPC, the scheme eliminates the initial feasibility condition and concurrently addresses settling time specifications, asymmetric regulation, and steady-state error correction. Additionally, the scheme incorporates a fuzzy logic system to approximate unknown smooth functions. The effectiveness and superiority of the proposed scheme are substantiated through simulation results.},
  archive      = {J_ISCI},
  author       = {Yu Xia and Jun He and Hak-Keung Lam and Leszek Rutkowski and Radu-Emil Precup},
  doi          = {10.1016/j.ins.2025.122111},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122111},
  shortjournal = {Inf. Sci.},
  title        = {Non-fragile fuzzy control of input-saturated systems with global prescribed performance via an error-triggered mechanism},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Batch active learning for time-series classification with
multi-mode exploration. <em>ISCI</em>, <em>711</em>, 122109. (<a
href="https://doi.org/10.1016/j.ins.2025.122109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting a sufficient amount of labeled data is challenging in practice. To deal with this challenge, active learning, which selects informative instances for annotation, has been studied. However, for time series, the dataset quality is often quite poor, and its multi-modality makes it unsuited to conventional active learning methods. Existing time series active learning methods have limitations, such as redundancy among selected instances, unrealistic assumptions on datasets, and inefficient calculations. We propose a batch active learning method for time series (BALT), which efficiently selects a batch of informative samples. BALT performs efficient clustering and picks one instance with the maximum informativeness score from each cluster. Using this score, we consider in-batch diversity explicitly so as to effectively handle multi-modality by exploring unknown regions, even under an extreme lack of labeled data. We also apply an adaptive weighting strategy to emphasize exploration in the early stage of the algorithm but shift to exploitation as the algorithm proceeds. Through experiments on several time-series datasets under various scenarios, we demonstrate the efficacy of BALT in achieving superior classification performance with less computation time under a predetermined budget, compared to existing time-series active learning methods.},
  archive      = {J_ISCI},
  author       = {Sangho Lee and Chihyeon Choi and Hyungrok Do and Youngdoo Son},
  doi          = {10.1016/j.ins.2025.122109},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122109},
  shortjournal = {Inf. Sci.},
  title        = {Batch active learning for time-series classification with multi-mode exploration},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffic forecasting using spatio-temporal dynamics and
attention with graph attention PDEs. <em>ISCI</em>, <em>711</em>,
122108. (<a href="https://doi.org/10.1016/j.ins.2025.122108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic forecasting is vital for optimizing intelligent transportation systems (ITS), yet existing models often struggle to capture the complex spatio-temporal patterns of urban traffic. We present GAPDE (Graph Attention Partial Differential Equation), a novel framework that integrates Partial Differential Equations (PDEs), Graph Convolutional Networks (GCNs), and advanced attention mechanisms. GAPDE enables continuous-time spatio-temporal modeling and dynamically prioritizes critical features through attention-driven traffic forecasting. Experiments on benchmark datasets, including PEMS-BAY, METR-LA, and various PeMS collections (PeMS03, PeMS04, PeMS07, PeMS08, PeMSD7M, and PeMSD7L), demonstrate GAPDE&#39;s superior performance over state-of-the-art models such as RGDAN, SGODE-RNN, and STD-MAE. GAPDE achieves up to 9.2 percent lower RMSE and 10.4 percent lower MAE, outperforming baselines in both short- and long-term prediction tasks. It demonstrates strong robustness to missing data, high scalability for large-scale networks, and enhanced interpretability through spatial and temporal attention visualizations. Comprehensive comparative evaluations and an in-depth ablation study further validate the effectiveness of GAPDE&#39;s components, including the GPDE block and spatio-temporal attention mechanisms. By combining PDEs, GCNs, and attention mechanisms in a scalable and efficient design, GAPDE offers a robust solution for real-time traffic forecasting in complex urban environments.},
  archive      = {J_ISCI},
  author       = {Ghadah Almousa and Yugyung Lee},
  doi          = {10.1016/j.ins.2025.122108},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122108},
  shortjournal = {Inf. Sci.},
  title        = {Traffic forecasting using spatio-temporal dynamics and attention with graph attention PDEs},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using AIE-d algorithm to recognize the node importance of
weighted urban rail transit network considering passenger flow.
<em>ISCI</em>, <em>711</em>, 122106. (<a
href="https://doi.org/10.1016/j.ins.2025.122106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The AIE-D algorithm (Adjacent Information Entropy-D algorithm) is proposed to recognize the importance of nodes in the urban rail transit network (URTN) weighted by passenger flow, which considers passenger flow, topological characteristics of nodes in the URTN, and the influence of neighboring nodes. The travel impedance is determined by using travel time, the D algorithm is used to search the k-short paths, and the weight value of each edge is the passenger flow cross-section of the corresponding line. Then, the detail AIE calculation steps are introduced. Next, a numerical study and comparison study are conducted by using the weighted topology of network. Compared with other commonly used algorithms, AIE-D has lower time complexity with faster calculation speed, and higher recognition accuracy. Finally, a real-world case study is conducted by using URTN of Chengdu Metro Network as the background. Weighted by passenger flow has greater impact on the operation of urban rail transit. The nodes are categorized into three classes according to the ranking of node importance, which includes Classification VI, Classification I and Classification GI. We conduct random attacks and deliberate attacks on the network, and analyze the network efficiency and maximum connectivity subgraph rate after the attacks.},
  archive      = {J_ISCI},
  author       = {Wencheng Huang and Xingyu Chen and Hongbing Pu and Yanhui Yin},
  doi          = {10.1016/j.ins.2025.122106},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122106},
  shortjournal = {Inf. Sci.},
  title        = {Using AIE-D algorithm to recognize the node importance of weighted urban rail transit network considering passenger flow},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A forward k-means algorithm for regression clustering.
<em>ISCI</em>, <em>711</em>, 122105. (<a
href="https://doi.org/10.1016/j.ins.2025.122105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel forward k -means algorithm for regression clustering, where the “forward” strategy progressively partitions samples from a single cluster into multiple ones, using the current optimal clustering solutions as initialization for subsequent iterations, thereby ensuring a deterministic result without any initialization requirements. We employ the mean squared error from the fitted clustering results as a criterion to guide partition optimization, which not only ensures rapid convergence of the algorithm to a stable solution but also yields desirable theoretical results. Meanwhile, we also suggest a difference-based threshold ridge ratio criterion to consistently determine the number of clusters. Comprehensive numerical studies are further conducted to demonstrate the algorithm&#39;s efficacy.},
  archive      = {J_ISCI},
  author       = {Jun Lu and Tingjin Luo and Kai Li},
  doi          = {10.1016/j.ins.2025.122105},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122105},
  shortjournal = {Inf. Sci.},
  title        = {A forward k-means algorithm for regression clustering},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refined kolmogorov complexity of analog, evolving and
stochastic recurrent neural networks. <em>ISCI</em>, <em>711</em>,
122104. (<a href="https://doi.org/10.1016/j.ins.2025.122104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kolmogorov complexity measures the compressibility of real numbers. We provide a refined characterization of the hypercomputational power of analog, evolving, and stochastic neural networks based on the Kolmogorov complexity of their real weights, evolving weights, and real probabilities, respectively. First, we retrieve the infinite hierarchy of complexity classes of analog networks, defined in terms of the Kolmogorov complexity of their real weights. This hierarchy lies between the complexity classes P and P / poly . Next, using a natural identification between real numbers and infinite sequences of bits, we generalize this result to evolving networks, obtaining a similar hierarchy of complexity classes within the same bounds. Finally, we extend these results to stochastic networks that employ real probabilities as randomness, deriving a new infinite hierarchy of complexity classes situated between BPP and BPP / lo g ⁎ . Beyond providing examples of such hierarchies, we describe a generic method for constructing them based on classes of functions of increasing complexity. As a practical application, we show that the predictive capabilities of recurrent neural networks are strongly impacted by the quantization applied to their weights. Overall, these results highlight the relationship between the computational power of neural networks and the intrinsic information contained by their parameters.},
  archive      = {J_ISCI},
  author       = {Jérémie Cabessa and Yann Strozecki},
  doi          = {10.1016/j.ins.2025.122104},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122104},
  shortjournal = {Inf. Sci.},
  title        = {Refined kolmogorov complexity of analog, evolving and stochastic recurrent neural networks},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The incremental SMOTE: A new approach based on the
incremental k-means algorithm for solving imbalanced data set problem.
<em>ISCI</em>, <em>711</em>, 122103. (<a
href="https://doi.org/10.1016/j.ins.2025.122103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is one of the very important areas in data mining. In real-life problems, developed methods for modeling with the classification problem generally perform well on datasets where the class distribution is balanced. On the other hand, the data sets are often imbalanced and it is important to develop algorithms to solve the classification problem on imbalanced data sets. Imbalanced datasets are more difficult to classify than balanced datasets because learning a class with underrepresentation is difficult. Most real life problems are imbalanced. The class with the least number of data usually corresponds to rare cases and is more important. Learning these classes is critical accordingly. One of the most commonly used solution methods to solve this problem is to oversample the minor class. When oversampling, too many repetitions in the dataset can cause overfitting. For this reason, it is very important to ensure data diversity when oversampling. Therefore, this paper proposes a new oversampling methods (the incremental SMOTE) combining the incremental k-means algorithm and Synthetic minority oversampling technique (SMOTE). The original dataset is clustered with the incremental k-means algorithm and the clusters are filtered to determine the safe clusters. The number of points to be produced from the safe clusters is determined, and then new instances are produced with the improved SMOTE algorithm. In the incremental SMOTE, diversity in the dataset is achieved by generating with incremental rate. In order to evaluate the performance of the incremental SMOTE algorithm, classification was performed on imbalanced datasets, balanced datasets obtained by the random oversampling, SMOTE, Borderline-SMOTE and SVM SMOTE methods. Comparisons for 10 datasets showed that the performance of the proposed method improves as the imbalance ratio of the dataset increases.},
  archive      = {J_ISCI},
  author       = {Duygu Selin Turan and Burak Ordin},
  doi          = {10.1016/j.ins.2025.122103},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122103},
  shortjournal = {Inf. Sci.},
  title        = {The incremental SMOTE: A new approach based on the incremental k-means algorithm for solving imbalanced data set problem},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel modelling method for rolling force prediction based
on deep stochastic configuration networks fused with physical knowledge.
<em>ISCI</em>, <em>711</em>, 122097. (<a
href="https://doi.org/10.1016/j.ins.2025.122097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the production of hot-rolled strip steal, the use of physical models frequently leads to inaccurate predictions of rolling force because some parameters are determined empirically. Further, purely data-driven models may not necessarily conform to the rolling principles, significantly restricting the applicability of machine learning in practical scenarios. Consequently, this study proposes an innovative modelling approach for predicting rolling force, utilizing a deep stochastic configuration network (DeepSCN) integrated with physical knowledge. Considering the many empirical parameters in existing physical models, an improved dung beetle optimizer (IDBO) is developed to optimize these parameters, thereby enhancing the accuracy of the physical models and acquiring more reasonable physical features. Subsequently, those physical features are utilized as deep inputs for the DeepSCN model to achieve the fusion of physical knowledge and data-driven approaches. The results suggest that the proposed model outperforms both physical and pure data-driven models. This work is able to demonstrate that the proposed fusion model conforms to the existing rolling theories and is suitable for various working conditions.},
  archive      = {J_ISCI},
  author       = {LingMing Meng and JingGuo Ding and ZiShuo Dong and Chuang Zhang and Wen Peng and DianHua Zhang},
  doi          = {10.1016/j.ins.2025.122097},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122097},
  shortjournal = {Inf. Sci.},
  title        = {A novel modelling method for rolling force prediction based on deep stochastic configuration networks fused with physical knowledge},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative recommendation-driven friendship path
selection strategy utilizing multi-agent collaborative edge caching for
social IoT networks. <em>ISCI</em>, <em>711</em>, 121914. (<a
href="https://doi.org/10.1016/j.ins.2025.121914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing complexity of the Social Internet of Things (SIoT) networks necessitates more efficient and intelligent methods for managing social interactions and service recommendations. This paper introduces a novel approach to improving the process of selecting SIoT friendship paths based on real-time recommendations leveraging a collaborative caching Multi-Agent Federated Deep Reinforcement Learning (MAFDRL) framework. This process involves using recommendation algorithms to predict and select optimal friendship connections, enhancing navigability and interaction efficiency within SIoT environments. The proposed model incorporates both the social relationships and resource-sharing dynamics of Internet of Things (IoT) devices to optimize recommendation accuracy and network performance. By combining Federated Learning (FL) principles with Deep Reinforcement Learning (DRL), the MAFDRL framework allows multiple agents to collaboratively train models without compromising privacy, ensuring scalability across distributed networks. Additionally, the integration of cache-driven techniques enhances computational efficiency, reducing latency and cost in friendship path discovery and improving real-time decision-making. Our experiments, conducted with the Waze and MovieLens-1 M datasets, reveal that the introduced framework achieves an average 30 % reduction in system and delay expenses. It also improves cache hit efficiency, with expenses reduced by approximately 25 % and around a 35 % increase in the accuracy of personalized recommendations.},
  archive      = {J_ISCI},
  author       = {Babak Farhadi and Parvaneh Asghari and Azadeh Zamanifar and Hamid Haj Seyyed Javadi},
  doi          = {10.1016/j.ins.2025.121914},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121914},
  shortjournal = {Inf. Sci.},
  title        = {An innovative recommendation-driven friendship path selection strategy utilizing multi-agent collaborative edge caching for social IoT networks},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jat---4">JAT - 4</h2>
<ul>
<li><details>
<summary>
(2025). Rearrangement-invariant norm inequalities for convolution
operators. <em>JAT</em>, <em>310</em>, 106173. (<a
href="https://doi.org/10.1016/j.jat.2025.106173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let k ∈ ( L 1 + L ∞ ) ( R n ) , where, as usual, L 1 ( R n ) denotes the class of Lebesgue-integrable functions on R n and L ∞ ( R n ) denotes the class of functions on R n that are Lebesgue-measurable and bounded almost everywhere. Given f ∈ ( L 1 ∩ L ∞ ) ( R n ) , set ( T k f ) ( x ) = ∫ R n k ( x − y ) f ( y ) d y , x ∈ R n . We study inequalities of the form ρ ( T k f ) ≤ C σ ( f ) , in which C &gt; 0 is independent of f ∈ ( L 1 ∩ L ∞ ) ( R n ) . The functionals ρ and σ are so-called rearrangement-invariant (r.i.) norms on M + ( R n ) , the class of nonnegative measurable functions on R n . Results first proved in the general context of r.i. norms are both specialized and expanded upon in the special case of Orlicz norms.},
  archive      = {J_JAT},
  author       = {Ron Kerman and S. Spektor},
  doi          = {10.1016/j.jat.2025.106173},
  journal      = {Journal of Approximation Theory},
  month        = {9},
  pages        = {106173},
  shortjournal = {J. Approx. Theory},
  title        = {Rearrangement-invariant norm inequalities for convolution operators},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact asymptotic order for generalised adaptive
approximations. <em>JAT</em>, <em>310</em>, 106171. (<a
href="https://doi.org/10.1016/j.jat.2025.106171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note, we present an abstract approach to study asymptotic orders for adaptive approximations with respect to a monotone set function J defined on dyadic cubes. We determine the exact upper order in terms of the critical value of the corresponding J -partition function, and we are able to provide upper and lower bounds in terms of fractal-geometric quantities. With properly chosen J , our new approach has applications in many different areas of mathematics, including the spectral theory of Kreĭn–Feller operators, quantisation dimensions of compactly supported probability measures, and the exact asymptotic order for Kolmogorov, Gel&#39;fand and linear widths for Sobolev embeddings into the Lebesgue space L ν p .},
  archive      = {J_JAT},
  author       = {Marc Kesseböhmer and Aljoscha Niemann},
  doi          = {10.1016/j.jat.2025.106171},
  journal      = {Journal of Approximation Theory},
  month        = {9},
  pages        = {106171},
  shortjournal = {J. Approx. Theory},
  title        = {Exact asymptotic order for generalised adaptive approximations},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relations between kondratiev spaces and refined localization
triebel–lizorkin spaces. <em>JAT</em>, <em>310</em>, 106162. (<a
href="https://doi.org/10.1016/j.jat.2025.106162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the close relation between certain weighted Sobolev spaces (Kondratiev spaces) and refined localization spaces from Triebel (2006), Triebel (2008). In particular, using a characterization for refined localization spaces from Scharf (2014), we considerably improve an embedding from Hansen (2013). This embedding is of special interest in connection with convergence rates for adaptive approximation schemes.},
  archive      = {J_JAT},
  author       = {Markus Hansen and Benjamin Scharf and Cornelia Schneider},
  doi          = {10.1016/j.jat.2025.106162},
  journal      = {Journal of Approximation Theory},
  month        = {9},
  pages        = {106162},
  shortjournal = {J. Approx. Theory},
  title        = {Relations between kondratiev spaces and refined localization Triebel–Lizorkin spaces},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A point process on the unit circle with antipodal
interactions. <em>JAT</em>, <em>310</em>, 106161. (<a
href="https://doi.org/10.1016/j.jat.2025.106161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the point process 1 Z n ∏ 1 ≤ j &lt; k ≤ n | e i θ j + e i θ k | β ∏ j = 1 n d θ j , θ 1 , … , θ n ∈ ( − π , π ] , β &gt; 0 , where Z n is the normalization constant. This point process is attractive : it involves n dependent, uniformly distributed random variables on the unit circle that attract each other. (For comparison, the well-studied C β E involves n uniformly distributed random variables on the unit circle that repel each other.) We consider linear statistics of the form ∑ j = 1 n g ( θ j ) as n → ∞ , where g ∈ C 1 , q and 2 π -periodic. We prove that the leading order fluctuations around the mean are of order n and given by ( g ( U ) − ∫ − π π g ( θ ) d θ 2 π ) n , where U ∼ Uniform ( − π , π ] . We also prove that the subleading fluctuations around the mean are of order n and of the form N R ( 0 , 4 g ′ ( U ) 2 / β ) n , i.e. that the subleading fluctuations are given by a Gaussian random variable that itself has a random variance. Our proof uses techniques developed by McKay and Isaev (McKay, 1990; Isaev and McKay, 2018) to obtain asymptotics of related n -fold integrals.},
  archive      = {J_JAT},
  author       = {Christophe Charlier},
  doi          = {10.1016/j.jat.2025.106161},
  journal      = {Journal of Approximation Theory},
  month        = {9},
  pages        = {106161},
  shortjournal = {J. Approx. Theory},
  title        = {A point process on the unit circle with antipodal interactions},
  volume       = {310},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jde---17">JDE - 17</h2>
<ul>
<li><details>
<summary>
(2025). Fractional mean field equations: Theory and application on
finite graphs. <em>JDE</em>, <em>436</em>, 113264. (<a
href="https://doi.org/10.1016/j.jde.2025.113264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the author introduces a nonlocal perspective by incorporating the fractional Laplacian ( − Δ ) s , and considers the fractional mean field equation on a finite graph G = ( V , E ) , say ( − Δ ) s u = ρ ( h e u ∫ V h e u d μ − 1 | V | ) , ∀ x ∈ V , where s ∈ ( 0 , 1 ) , ρ ∈ ( − ∞ , 0 ) ∪ ( 0 , + ∞ ) are some fixed parameters, h denotes a given real value function on V . Based on the sign of the prescribed function h , using various methods such as variational method, topological degree and two mean field type heat flows, the author obtains the existence of solutions for the above problem in three cases respectively. These results extend the relevant research of Lin-Yang (Calc. Var., 2021), Sun-Wang (Adv. Math., 2022) and Liu-Zhang (J. Math. Anal. Appl., 2023) in the case of s = 1 , and potentially broaden the understanding and application of fractional operators in discrete mathematical structures, emphasizing connections to both continuous and discrete theories.},
  archive      = {J_JDE},
  author       = {Yang Liu},
  doi          = {10.1016/j.jde.2025.113264},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113264},
  shortjournal = {J. Diff. Equ.},
  title        = {Fractional mean field equations: Theory and application on finite graphs},
  volume       = {436},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple solutions to an elliptic problem driven by a
singular nonlinearity. <em>JDE</em>, <em>436</em>, 113263. (<a
href="https://doi.org/10.1016/j.jde.2025.113263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We will prove the existence of multiple solutions to an elliptic problem driven by a singular nonlinearity. Further we studied the singular problem and analyzed the regularity of the solutions.},
  archive      = {J_JDE},
  author       = {Debajyoti Choudhuri and Ratan Kr. Giri and K. Saoudi},
  doi          = {10.1016/j.jde.2025.113263},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113263},
  shortjournal = {J. Diff. Equ.},
  title        = {Multiple solutions to an elliptic problem driven by a singular nonlinearity},
  volume       = {436},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effects of fast diffusion in the logistic equation with
refuge. <em>JDE</em>, <em>436</em>, 113261. (<a
href="https://doi.org/10.1016/j.jde.2025.113261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the behaviour of the positive solution of a logistic equation with respect to a space dependent diffusion rate. The equation also includes a refuge, a zone where the species grows freely. In contrast to the case of homogeneous diffusion coefficient, where the species dies for large diffusion regardless of the birth rate, we show that the species may die, persist or growth indefinitely, depending on the size of the birth rate, for a large increasing of this diffusion rate in a certain region of the space, even more, this growth causes blow up in this region as well as in the refuge.},
  archive      = {J_JDE},
  author       = {V.K. Ramos and C.A. Santos and A. Suárez},
  doi          = {10.1016/j.jde.2025.113261},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113261},
  shortjournal = {J. Diff. Equ.},
  title        = {Effects of fast diffusion in the logistic equation with refuge},
  volume       = {436},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global well-posedness of non-resistive quantum MHD system.
<em>JDE</em>, <em>436</em>, 113255. (<a
href="https://doi.org/10.1016/j.jde.2025.113255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are concerned with the global well-posedness of viscous non-resistive compressible quantum magnetohydrodynamic (QMHD) system in Lagrangian coordinates. By using a two-tier energy method, we study an initial-boundary value problem of compressible QMHD system in an infinite flat layer. We prove the global existence, uniqueness and decay estimate of smooth solution to the system around a suitably small uniform magnetic field which is non-parallel to the layer.},
  archive      = {J_JDE},
  author       = {Sinan Wang and Jianfeng Zhou},
  doi          = {10.1016/j.jde.2025.113255},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113255},
  shortjournal = {J. Diff. Equ.},
  title        = {Global well-posedness of non-resistive quantum MHD system},
  volume       = {436},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global long time uniform well-posedness of 3D incompressible
navier-stokes equations under time-independent uniqueness condition.
<em>JDE</em>, <em>436</em>, 113254. (<a
href="https://doi.org/10.1016/j.jde.2025.113254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, inspired by the uniqueness condition of the 3D steady incompressible Navier-Stokes equations, we present a time-independent uniqueness condition depending on ( ν , u 0 , f ∞ , Ω ) with f ∞ = sup t ≥ 0 ⁡ ‖ f ( t ) ‖ 0 , Ω and consider the fully discrete Galerkin method for the 3D time-dependent incompressible Navier-Stokes equations in the infinite time interval [ 0 , ∞ ) . Furthermore, we provide the long time uniform stability and convergence of the fully discrete Galerkin solution and obtain the global uniform well-posedness (or the existence, uniqueness and long time stability of the solution) of the 3D time-dependent incompressible Navier-Stokes equations under the time-independent uniqueness condition by use of the compact theorem and a new a priori estimate of the fully discrete Galerkin solution.},
  archive      = {J_JDE},
  author       = {Xinglong Feng and Yinnian He},
  doi          = {10.1016/j.jde.2025.113254},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113254},
  shortjournal = {J. Diff. Equ.},
  title        = {Global long time uniform well-posedness of 3D incompressible navier-stokes equations under time-independent uniqueness condition},
  volume       = {436},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chaoticity of generic points for ergodic measures in
hyperbolic systems and beyond. <em>JDE</em>, <em>436</em>, 113236. (<a
href="https://doi.org/10.1016/j.jde.2025.113236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we search the chaotic behavior in the set of generic points of ergodic measures (called the Birkhoff basin) and find several types of chaoticity stronger than Li-Yorke chaos. More precisely, we consider nonuniformly hyperbolic systems first. On one hand, the Birkhoff basin of every ergodic hyperbolic measure with positive metric entropy exhibits a type of distributional chaos property between DC1 and Li-Yorke chaos, called Banach DC1. On the other hand, the Birkhoff basin of every totally ergodic hyperbolic measure with nondegenerate support exhibits a type of distributional chaos property between DC1 and DC2, called almost DC1. For hyperbolic systems, the Birkhoff basin of every ergodic measure with nondegenerate support from an elementary part of an Axiom A system exhibits both almost DC1 and Banach DC1, and the Birkhoff basin of any trivial ergodic measure supported on some fixed point exhibits Banach DC1 but no almost DC1. In this process, Katok&#39;s shadowing and horseshoe approximation motivate us to obtain two types of weak specification property as useful techniques to reach our results. Such weak specifications are also valid to symbolic systems like sofic subshifts and β -shifts, so we put them as abstract frameworks in the proof part. Compared with Chen-Tian&#39;s result [1] considering the ergodic measures whose Birkhoff basin has a distal pair, we need to overcome general ergodic measures without the assumption of a distal pair and overcome the nonuniform difficulties from the weak specification property.},
  archive      = {J_JDE},
  author       = {Xiaobo Hou and Xueting Tian and Xutong Zhao},
  doi          = {10.1016/j.jde.2025.113236},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113236},
  shortjournal = {J. Diff. Equ.},
  title        = {Chaoticity of generic points for ergodic measures in hyperbolic systems and beyond},
  volume       = {436},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bounded and periodic solutions of quasilinear parabolic
equations in time-dependent domains. <em>JDE</em>, <em>436</em>, 113177.
(<a href="https://doi.org/10.1016/j.jde.2025.02.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show the existence and uniqueness of the bounded or periodic solution for the quasilinear parabolic equation of the form (1.1) u t − div ( σ ( | ∇ u | 2 ) ∇ u ) = f ( x , t ) in Q ( − ∞ , ∞ ) with the boundary condition u ( t ) | ∂ Ω ( t ) = 0 , where Ω ( t ) is a bounded domain in R N for each t ∈ R and Q ( − ∞ , ∞ ) = ∪ − ∞ &lt; t &lt; ∞ Ω ( t ) × { t } . Typical examples of σ are σ ( v 2 ) = | v | m , m ≥ 0 , σ ( v 2 ) = log ( 1 + v 2 ) and σ ( v 2 ) = | v | m / 1 + v 2 , m ≥ 1 . We derive a precise estimate for sup − ∞ &lt; t &lt; ∞ ⁡ ‖ ∇ u ( t ) ‖ Ω ( t ) , ∞ depending on sup − ∞ &lt; t &lt; ∞ ⁡ ‖ f ( t ) ‖ Ω ( t ) , ∞ and the movement of ∂ Ω ( t ) .},
  archive      = {J_JDE},
  author       = {Mitsuhiro Nakao},
  doi          = {10.1016/j.jde.2025.02.048},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113177},
  shortjournal = {J. Diff. Equ.},
  title        = {Bounded and periodic solutions of quasilinear parabolic equations in time-dependent domains},
  volume       = {436},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local well-posedness of the minimum energy estimator for a
defocusing cubic wave equation. <em>JDE</em>, <em>435</em>, 113258. (<a
href="https://doi.org/10.1016/j.jde.2025.113258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is concerned with the minimum energy estimator for a nonlinear hyperbolic partial differential equation. The Mortensen observer – originally introduced for the energy-optimal reconstruction of the state of nonlinear finite-dimensional systems – is formulated for a disturbed cubic wave equation and the associated observer equation is derived. An in depth study of the associated optimal control problem and sensitivity analysis of the corresponding value function reveals that the energy optimal state estimator is well-defined. Deploying a classical fixed point argument we proceed to show that the observer equation is locally well-posed.},
  archive      = {J_JDE},
  author       = {Jesper Schröder},
  doi          = {10.1016/j.jde.2025.113258},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113258},
  shortjournal = {J. Diff. Equ.},
  title        = {Local well-posedness of the minimum energy estimator for a defocusing cubic wave equation},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics and integrability of polynomial vector fields on
the n-dimensional sphere. <em>JDE</em>, <em>435</em>, 113253. (<a
href="https://doi.org/10.1016/j.jde.2025.113253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we characterize arbitrary polynomial vector fields on S n . We establish a necessary and sufficient condition for a degree one vector field on the odd-dimensional sphere S 2 n − 1 to be Hamiltonian. Additionally, we classify polynomial vector fields on S n up to degree two that possess an invariant great ( n − 1 ) -sphere. We present a class of completely integrable vector fields on S n . We found a sharp bound for the number of invariant meridian hyperplanes for a polynomial vector field on S 2 . Furthermore, we compute the sharp bound for the number of invariant parallel hyperplanes for any polynomial vector field on S n . Finally, we study homogeneous polynomial vector fields on S n , providing a characterization of their invariant ( n − 1 ) -spheres.},
  archive      = {J_JDE},
  author       = {Supriyo Jana and Soumen Sarkar},
  doi          = {10.1016/j.jde.2025.113253},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113253},
  shortjournal = {J. Diff. Equ.},
  title        = {Dynamics and integrability of polynomial vector fields on the n-dimensional sphere},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics of a periodic predator-prey reaction-diffusion
system in heterogeneous environments. <em>JDE</em>, <em>435</em>,
113252. (<a href="https://doi.org/10.1016/j.jde.2025.113252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is dedicated to investigating a predator-prey reaction-diffusion model with time-periodic, where all coefficient functions are both spatially and temporally heterogeneous. We rigorously characterize the properties of the principal eigenvalue and establish a precise relationship between the coefficient functions and the dynamics. Our results indicate that slow predator movement and short frequency of environmental periodic variations promote successful predator invasion. Conversely, reducing the predator mortality rate facilitates long-term coexistence of both populations. Additionally, we explore the asymptotic behaviors of positive periodic solutions when the diffusion coefficients are large or small, revealing the effects of diffusion on the invasion dynamics.},
  archive      = {J_JDE},
  author       = {Zhenrui Zhang and Jinfeng Wang},
  doi          = {10.1016/j.jde.2025.113252},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113252},
  shortjournal = {J. Diff. Equ.},
  title        = {Dynamics of a periodic predator-prey reaction-diffusion system in heterogeneous environments},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Second order regularity for solutions to anisotropic
degenerate elliptic equations. <em>JDE</em>, <em>435</em>, 113250. (<a
href="https://doi.org/10.1016/j.jde.2025.113250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider solutions to degenerate anisotropic elliptic equations in order to study their regularity. In particular we establish second-order estimates and enclose regularity results for the stress field. All our results are new even in the euclidean case.},
  archive      = {J_JDE},
  author       = {Daniel Baratta and Luigi Muglia and Domenico Vuono},
  doi          = {10.1016/j.jde.2025.113250},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113250},
  shortjournal = {J. Diff. Equ.},
  title        = {Second order regularity for solutions to anisotropic degenerate elliptic equations},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On li-lin’s open problem. <em>JDE</em>, <em>435</em>,
113244. (<a href="https://doi.org/10.1016/j.jde.2025.113244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we give a first negative answer to a question proposed by Li and Lin (2012) [5] . Meanwhile, we also give a second positive answer to the Li-Lin&#39;s open problem. The first positive answer was given by G. Cerami, X. Zhong and W. Zou (2015) [2] .},
  archive      = {J_JDE},
  author       = {Zhi-Yun Tang and Xianhua Tang},
  doi          = {10.1016/j.jde.2025.113244},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113244},
  shortjournal = {J. Diff. Equ.},
  title        = {On li-lin&#39;s open problem},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple way to well-posedness in h1 of a delay differential
equation from cell biology. <em>JDE</em>, <em>435</em>, 113241. (<a
href="https://doi.org/10.1016/j.jde.2025.113241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an application of recent well-posedness results in the theory of delay differential equations for ordinary differential equations [10] to a generalized population model for stem cell maturation. The weak approach using Sobolev-spaces we take allows for a larger class of initial prehistories and makes checking the requirements for well-posedness of such a model considerably easier compared to previous approaches. In fact the present approach is a possible means to guarantee that the solution manifold is not empty, which is a necessary requirement for a C 1 -approach to work.},
  archive      = {J_JDE},
  author       = {Bernhard Aigner and Marcus Waurick},
  doi          = {10.1016/j.jde.2025.113241},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113241},
  shortjournal = {J. Diff. Equ.},
  title        = {A simple way to well-posedness in h1 of a delay differential equation from cell biology},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Backward stochastic volterra integral equations with jumps
and some related problems. <em>JDE</em>, <em>435</em>, 113240. (<a
href="https://doi.org/10.1016/j.jde.2025.113240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we deal with backward stochastic Volterra integral equations with jumps. Firstly, we present the well-posedness of backward stochastic Volterra integral equations with jumps in the sense of adapted M-solution. Secondly, we give some properties of backward stochastic Volterra integral equations with jumps, which contain the duality principle, comparison theorem and the regularity of adapted M-solution. Thirdly, dynamic risk measure by means of backward stochastic Volterra integral equations with jumps is established. Fourthly, a maximum principle of Pontryagin type is obtained for an optimal control problem of stochastic Volterra integral equations with jumps. Finally, we investigate the well-posedness of linear fractional backward stochastic Volterra integral equations.},
  archive      = {J_JDE},
  author       = {Zongkui Fu and Shasha Shen and Jinbiao Wu},
  doi          = {10.1016/j.jde.2025.113240},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113240},
  shortjournal = {J. Diff. Equ.},
  title        = {Backward stochastic volterra integral equations with jumps and some related problems},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-time-scale stochastic functional differential equations:
Inclusion of infinite delay and coupled segment processes. <em>JDE</em>,
<em>435</em>, 113238. (<a
href="https://doi.org/10.1016/j.jde.2025.113238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on two-time-scale stochastic functional differential equations (SFDEs). It features in inclusion of infinite delay and coupling of slow and fast components. The coupling is through the segment processes of the slow and fast processes. The main difficulties include infinite delay and the coupling of segment processes involving fast and slow motions. Concentrating on weak convergence, the tightness of the segment process is established on a space of continuous functions. In addition, the Hölder continuity and boundedness for the segment process of the slow component, uniform boundedness for the segment process of a fixed- x SFDE, exponential ergodicity, and continuous dependence on parameters are obtained to carry out the desired asymptotic analysis, and also as byproducts, which are interesting in their own right. Then using the martingale problem formulation, an average principle is established by a direct averaging, which involves detailed computations and subtle estimates. Finally, two classes of special SFDEs, stochastic integro-differential equations and stochastic delay differential equations with two-time scales are investigated.},
  archive      = {J_JDE},
  author       = {Fuke Wu and George Yin},
  doi          = {10.1016/j.jde.2025.113238},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113238},
  shortjournal = {J. Diff. Equ.},
  title        = {Two-time-scale stochastic functional differential equations: Inclusion of infinite delay and coupled segment processes},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local controllability of the korteweg-de vries equation with
the right dirichlet control. <em>JDE</em>, <em>435</em>, 113235. (<a
href="https://doi.org/10.1016/j.jde.2025.113235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Korteweg-de Vries (KdV) equation with the right Dirichlet control is small time, locally, exactly controllable for all non-critical lengths and its linearized system is not controllable for all critical lengths. In this paper, we give a definitive picture of the local controllability properties of this control problem for all critical lengths. In particular, we show that the unreachable space of the linearized system is always of dimension 1 and the KdV system with the right Dirichlet control is not locally null controllable in small time for any critical length. We also give a criterion to determine whether the system is locally exactly controllable in finite time or not locally null controllable in any positive time for all critical lengths. Consequently, we show that there exist critical lengths such that the system is not locally null controllable in small time but is locally exactly controllable in finite time.},
  archive      = {J_JDE},
  author       = {Hoai-Minh Nguyen},
  doi          = {10.1016/j.jde.2025.113235},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113235},
  shortjournal = {J. Diff. Equ.},
  title        = {Local controllability of the korteweg-de vries equation with the right dirichlet control},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global boundedness of solutions to a class of partial
differential equations with time delay. <em>JDE</em>, <em>435</em>,
113232. (<a href="https://doi.org/10.1016/j.jde.2025.113232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of diffusive partial differential equations with strongly coupled time delays and diffusion is considered. The global boundedness of weak solutions of the equation is proved by an entropy method that was initially proposed for studying the global boundedness of reaction-diffusion equations with cross-diffusion. The presence of the time delays in the equation prevents the entropy method to be directly applied, and here we extend the entropy method to this class of diffusive partial differential equations with time delays by proving some key entropy inequalities, which further allows us to obtain the estimates of gradient of the solutions. The results can be used to show the global boundedness of solutions of population models with memory effect, which were recently proposed for describing the movement of highly-developed animal species. In addition, we show that the results are also applicable for the classic partial functional differential equations, where the time delays only appear in the reaction terms.},
  archive      = {J_JDE},
  author       = {Xuanyu Liu and Junping Shi and Chuncheng Wang and Dejun Fan},
  doi          = {10.1016/j.jde.2025.113232},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113232},
  shortjournal = {J. Diff. Equ.},
  title        = {Global boundedness of solutions to a class of partial differential equations with time delay},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jmaa---11">JMAA - 11</h2>
<ul>
<li><details>
<summary>
(2025). Unique solutions to power-transformed affine systems.
<em>JMAA</em>, <em>550</em>(1), 129515. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Systems of the form x = ( A x s ) 1 / s + b arise in a range of economic and financial applications, where A is a linear operator acting on a space of real-valued functions (or vectors) and s is a nonzero real value. In these applications, attention is focused on positive solutions. We provide a simple characterization of existence and uniqueness of positive solutions when b is positive and A is irreducible.},
  archive      = {J_JMAA},
  author       = {John Stachurski and Ole Wilms and Junnan Zhang},
  doi          = {10.1016/j.jmaa.2025.129515},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129515},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Unique solutions to power-transformed affine systems},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Connections and finsler geometry of the structure group of a
JB-algebra. <em>JMAA</em>, <em>550</em>(1), 129506. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We endow the Banach-Lie structure group S t r ( V ) of an infinite dimensional JB-algebra V with a left-invariant connection and Finsler metric, and we compute all the quantities of its connection. We show how this connection reduces to G ( Ω ) , the group of transformations that preserve the positive cone Ω of the algebra V , and to A u t ( V ) , the group of Jordan automorphisms of the algebra. We present the cone Ω as a homogeneous space for the action of G ( Ω ) , therefore inducing a quotient Finsler metric and distance. With the techniques introduced, we prove the minimality of the one-parameter groups in Ω for any symmetric gauge norm in V . We establish that the two presentations of the Finsler metric in Ω give the same distance there, which helps us prove the minimality of certain paths in G ( Ω ) for its left-invariant Finsler metric.},
  archive      = {J_JMAA},
  author       = {Gabriel Larotonda and José Luna},
  doi          = {10.1016/j.jmaa.2025.129506},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129506},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Connections and finsler geometry of the structure group of a JB-algebra},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Formulas involving moment and interpolation functions for
apostol type polynomials via nörlund sum and laplace transform.
<em>JMAA</em>, <em>550</em>(1), 129504. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of this paper is to define a new approach when constructing generating functions for the generalization and unification of the Apostol type Bernoulli polynomials. We apply the Nörlund sum, the Euler operator for derivative, ad the (inverse) Laplace transform to reach this aim. We also aim to prove a functional equation involving the Nörlund sum and the (inverse) Laplace transform. Moreover, by combining these operators with functional equations of the generating functions, we derive some new formulas for the Apostol type polynomials and k th moment of the geometric distribution. Finally, applying these operators, we not only find new the Riemann integral formulas, but also construct interpolation functions related to the Lerch zeta and the Hurwitz zeta functions for these polynomials.},
  archive      = {J_JMAA},
  author       = {Elif Sükrüoglu and Yilmaz Simsek},
  doi          = {10.1016/j.jmaa.2025.129504},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129504},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Formulas involving moment and interpolation functions for apostol type polynomials via nörlund sum and laplace transform},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global dynamics of liénard systems with arbitrary degrees.
<em>JMAA</em>, <em>550</em>(1), 129503. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to study global dynamics of Liénard systems with arbitrary degrees x ˙ = y , y ˙ = a 1 x + a 2 x 2 m + 1 + ( a 3 + a 4 x 2 n − 1 ) y . The complex and rich dynamics are presented, in particular, including double limit cycle bifurcation, Hopf bifurcation, homoclinic bifurcation and heteroclinic bifurcation. We illustrate theoretical results by numerical simulations.},
  archive      = {J_JMAA},
  author       = {Hebai Chen and Zhijie Li and Yu Xiao and Xin Yang},
  doi          = {10.1016/j.jmaa.2025.129503},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129503},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Global dynamics of liénard systems with arbitrary degrees},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On fractional p(⋅)-schrödinger-kirchhoff equations with the
critical exponent in RN. <em>JMAA</em>, <em>550</em>(1), 129502. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present paper, we discuss a class of critical Schrödinger-Kirchhoff type problem involving the fractional p ( ⋅ ) -Laplacian. Firstly, for the critical case, we analyze the loss of compactness of the problem using the famous concentration-compactness principles. Next, the existence of nontrivial solutions is derived by utilizing the Nehari manifold approach. Finally, a simple example is given to show the validity of our main theorem&#39;s conditions. Our study improves and extends some recent work in the literature.},
  archive      = {J_JMAA},
  author       = {Shuai Li and Tianqing An and Weichun Bu},
  doi          = {10.1016/j.jmaa.2025.129502},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129502},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On fractional p(⋅)-schrödinger-kirchhoff equations with the critical exponent in RN},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the planar weakly coupled nonlinear logarithmic choquard
systems. <em>JMAA</em>, <em>550</em>(1), 129501. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the following class of coupled nonlinear logarithmic Choquard equations { − Δ u + λ 1 u = ( log ⁡ 1 | ⋅ | ⁎ u 2 ) u + ( log ⁡ 1 | ⋅ | ⁎ v 2 ) u , in R 2 , − Δ v + λ 2 v = ( log ⁡ 1 | ⋅ | ⁎ v 2 ) v + ( log ⁡ 1 | ⋅ | ⁎ u 2 ) v , in R 2 . We prove the existence of a nonnegative vector solution when λ 1 = λ 2 . Moreover, we prove that if λ 1 ≠ λ 2 , then the system admits only the semi-trivial solution. Our approach is based on minimization over Nehari manifold and a version of the Principle of Symmetric Criticality due to Palais.}},
  archive      = {J_JMAA},
  author       = {J.C. de Albuquerque and J. Carvalho and E. Medeiros},
  doi          = {10.1016/j.jmaa.2025.129501},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129501},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On the planar weakly coupled nonlinear logarithmic choquard systems},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random periodic solutions of non-uniform dissipative
stochastic differential equations driven by multiplicative pure jump
lévy noises. <em>JMAA</em>, <em>550</em>(1), 129500. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to investigate random periodic solutions in distribution of non-autonomous stochastic differential equations (SDEs) driven by multiplicative pure jump Lévy noises. Inspired by the refined basic coupling method for autonomous systems, we establish exponential contractivity of solutions of non-autonomous SDEs, where the coefficients are non-uniformly dissipative, and the requirements of Lévy measure corresponding to the Lévy process are not harsh (only with a truncated α -stable component). Based on this, we obtain the existence and uniqueness of the random periodic solutions in distribution by the criterion of the existence and uniqueness of the periodic Markov process. Meanwhile, two examples are provided to illustrate our results.},
  archive      = {J_JMAA},
  author       = {Shan Huang and Xiaoyue Li and Li Yang},
  doi          = {10.1016/j.jmaa.2025.129500},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129500},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Random periodic solutions of non-uniform dissipative stochastic differential equations driven by multiplicative pure jump lévy noises},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transport multi-paths with capacity constraints.
<em>JMAA</em>, <em>550</em>(1), 129499. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article generalizes the study of branched/ramified optimal transportation to those with capacity constraints. Each admissible transport network studied here is represented by a transport multi-path between measures, with a capacity constraint on each of its components. The associated transport cost is given by the sum of the M α -cost of each component. Using this new formulation, we prove the existence of an optimal solution and provide an upper bound on the number of components for the solution. Additionally, we conduct analytical examinations of the properties (e.g. “map-compatibility”, and “simple common-source property”) of each solution component and explore the interplay among components, particularly in the discrete case.},
  archive      = {J_JMAA},
  author       = {Qinglan Xia and Haotian Sun},
  doi          = {10.1016/j.jmaa.2025.129499},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129499},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Transport multi-paths with capacity constraints},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adjointable maps between linear orthosets. <em>JMAA</em>,
<em>550</em>(1), 129494. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an (anisotropic) Hermitian space H , the collection P ( H ) of at most one-dimensional subspaces of H , equipped with the orthogonal relation ⊥ and the zero linear subspace {0}, is a linear orthoset and up to orthoisomorphism any linear orthoset of rank ⩾4 arises in this way. We investigate in this paper the correspondence of structure-preserving maps between Hermitian spaces on the one hand and between the associated linear orthosets on the other hand. Our particular focus is on adjointable maps. We show that, under a mild assumption, adjointable maps between linear orthosets are induced by quasilinear maps between Hermitian spaces and if the latter are linear, they are adjointable as well. Specialised versions of this correlation lead to Wigner-type theorems; we see, for instance, that orthoisomorphisms between the orthosets associated with at least 3-dimensional Hermitian spaces are induced by quasiunitary maps. In addition, we point out that orthomodular spaces of dimension ⩾4 can be characterised as irreducible Fréchet orthosets such that the inclusion map of any subspace is adjointable. Together with a transitivity condition, we may in this way describe the infinite-dimensional classical Hilbert spaces.},
  archive      = {J_JMAA},
  author       = {Jan Paseka and Thomas Vetterlein},
  doi          = {10.1016/j.jmaa.2025.129494},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129494},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Adjointable maps between linear orthosets},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bicomplex generalized hypergeometric functions and their
applications. <em>JMAA</em>, <em>550</em>(1), 129490. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, generalized hypergeometric functions for a bicomplex argument are introduced and the convergence criteria are derived. Furthermore, an integral representation of these functions is established. Moreover, quadratic transformation, a differential relation, analyticity, and contiguous relations of these functions are derived. Additionally, applications in quantum information systems and quantum optics are provided as a consequence.},
  archive      = {J_JMAA},
  author       = {Snehasis Bera and Sourav Das and Abhijit Banerjee},
  doi          = {10.1016/j.jmaa.2025.129490},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129490},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Bicomplex generalized hypergeometric functions and their applications},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical properties of derivative polynomials.
<em>JMAA</em>, <em>550</em>(1), 129442. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study analytical properties of derivative polynomials for tangent and secant, including recurrence relations, explicit formulas and expansion formulas. Firstly, we discuss the connections between central binomial coefficients and trigonometric functions. Secondly, we explore the similarity of derivative polynomials and Chebyshev polynomials. The idea is to choose the derivative polynomials as basis sets of a polynomial space. From this viewpoint, we give an expansion of the derivative polynomials for tangent in terms of the derivative polynomials for secant as well as a result in the reverse direction. Moreover, we get the Frobenius-type formulas for exterior peak and left peak polynomials. Finally, we discuss the connections between derivative polynomials and Eulerian polynomials.},
  archive      = {J_JMAA},
  author       = {Guo-Niu Han and Hailing Li and Shi-Mei Ma and Jean Yeh and Yeong-Nan Yeh},
  doi          = {10.1016/j.jmaa.2025.129442},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {10},
  number       = {1},
  pages        = {129442},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Analytical properties of derivative polynomials},
  volume       = {550},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jocs---18">JOCS - 18</h2>
<ul>
<li><details>
<summary>
(2025). Impact of inlet velocity waveform shape on hemodynamics.
<em>JOCS</em>, <em>87</em>, 102579. (<a
href="https://doi.org/10.1016/j.jocs.2025.102579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monitoring disease development in arteries, which supply oxygen and nutrients to the body, is crucial and can be assessed using hemodynamic metrics. Hemodynamic metrics can be calculated via computational fluid dynamic simulation of patient-specific geometries. These simulations are known to be heavily influenced by boundary conditions, such as time-dependent inlet flow. However, the effects of inlet flow profiles have not previously been quantified or understood. Here we quantify the effects of modulating temporal arterial waveforms on hemodynamic metrics. Building on our previous work that identified the minimum number of points of interest needed to characterize a left coronary artery inlet waveform, here, we extend this approach to pulmonary and carotid artery waveforms, pinpointing critical points of interest on these waveforms. Using a systematic variation of these points, we quantify the effects on hemodynamic metrics such as wall shear stress, oscillatory shear index, and relative residence time. We simulate using 1D Navier–Stokes and 3D lattice Boltzmann simulation approaches conducted on high performance compute clusters. The results pinpoint parts of the waveform that are most susceptible to perturbations and measurement error. The impacts of this work include the construction of a method that can be applied to other fluid simulations with pulsatile inlet conditions and the ability to distinguish the vital parts of a pulsatile inlet condition for computational fluid dynamic simulations and clinical metrics. This work is an extension of work published at the International Conference on Computational Science (ICCS-2024), (Geddes et al., 2024).},
  archive      = {J_JOCS},
  author       = {Justen R. Geddes and Timothy D. King and Cyrus Tanade and William Ladd and Nusrat Sadia Khan and Amanda Randles},
  doi          = {10.1016/j.jocs.2025.102579},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102579},
  shortjournal = {J. Comput. Sci.},
  title        = {Impact of inlet velocity waveform shape on hemodynamics},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A numerical investigation of convection-dominated convection
diffusion problems using characteristic stabilized mixed finite element
method. <em>JOCS</em>, <em>87</em>, 102578. (<a
href="https://doi.org/10.1016/j.jocs.2025.102578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a characteristic stabilized mixed finite element method based on the lower regularity of the flux for convection dominated convection diffusion problems. The method combines the characteristic method with a stabilized mixed finite element method that uses the lowest equal-order pair for the velocity and pressure. The stabilization term is based on two local Gauss integrations for the velocity. Moreover, we obtain that the approximation of the pressure u is optimal in the L 2 -norm and H 1 -norm, the approximation of the velocity p is suboptimal in the L 2 -norm. Finally, numerical experiments in 2D and 3D are presented to verify the theoretical results.},
  archive      = {J_JOCS},
  author       = {Baowei Lai and Lanxin Sun and Wenhuan Yang and Lixiang Yu and Zelian Ni and Zhifeng Weng},
  doi          = {10.1016/j.jocs.2025.102578},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102578},
  shortjournal = {J. Comput. Sci.},
  title        = {A numerical investigation of convection-dominated convection diffusion problems using characteristic stabilized mixed finite element method},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy dissipation preserving physics informed neural
network for allen–cahn equations. <em>JOCS</em>, <em>87</em>, 102577.
(<a href="https://doi.org/10.1016/j.jocs.2025.102577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a numerical solution of Allen–Cahn equation with constant and degenerate mobility, with polynomial and logarithmic energy functionals, with deterministic and random initial functions, and with advective term in one, two, and three spatial dimensions, based on the physics-informed neural network (PINN). To improve the learning capacity of the PINN, we incorporate the energy dissipation property of the Allen–Cahn equation as a penalty term into the loss function of the network. To facilitate the learning process of random initials, we employ a continuous analogue of the initial random condition by utilizing the Fourier series expansion. Adaptive methods from traditional numerical analysis are also integrated to enhance the effectiveness of the proposed PINN. Numerical results indicate a consistent decrease in the discrete energy, while also revealing phenomena such as phase separation and metastability.},
  archive      = {J_JOCS},
  author       = {Mustafa Kütük and Hamdullah Yücel},
  doi          = {10.1016/j.jocs.2025.102577},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102577},
  shortjournal = {J. Comput. Sci.},
  title        = {Energy dissipation preserving physics informed neural network for Allen–Cahn equations},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of the properties of the elasticity modulus in the
nasopharynx on the hydrodynamic characteristics of the flow in the upper
respiratory tract. <em>JOCS</em>, <em>87</em>, 102576. (<a
href="https://doi.org/10.1016/j.jocs.2025.102576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the influence of the elasticity modulus (5–25 kPa) and inlet boundary conditions on the distribution of velocity, pressure, shear stress and strain in the upper airways was investigated using computational fluid dynamics (CFD) and fluid-structure interaction (FSI) models. Sinusoidal velocity profiles at the entrance to the nasal sinuses with oscillation amplitudes of 1.2 m/s, 2.4 m/s, 3.6 m/s were considered. The results show that the maximum value of deformation in the nasopharyngeal region occurred at a value of Young&#39;s modulus of 5 kPa, and values from 15 to 25 kPa gave deformation values lower by more than 20 % and had insignificant differences. In addition, the CFD model showed higher pressure and shear stress values than the FSI model, and the maximum velocity of the FSI models was higher than that of the CFD model. This study provides new data on the effect of modulus and inlet boundary conditions on velocity, pressure, shear stress, and strain distributions in the upper airways.},
  archive      = {J_JOCS},
  author       = {Alibek Issakhov and Aidana Sabyrkulova and Aizhan Abylkassymova},
  doi          = {10.1016/j.jocs.2025.102576},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102576},
  shortjournal = {J. Comput. Sci.},
  title        = {Influence of the properties of the elasticity modulus in the nasopharynx on the hydrodynamic characteristics of the flow in the upper respiratory tract},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed neural networks for microflows: Rarefied
gas dynamics in cylinder arrays. <em>JOCS</em>, <em>87</em>, 102575. (<a
href="https://doi.org/10.1016/j.jocs.2025.102575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate prediction of rarefied gas dynamics is crucial for optimizing flows through microelectromechanical systems, air filtration devices, and shale gas extraction. Traditional methods, such as discrete velocity and direct simulation Monte Carlo (DSMC), demand intensive memory and computation, especially for microflows in non-convex domains. Recently, physics-informed neural networks (PINNs) emerged as a meshless and adaptable alternative for solving non-linear partial differential equations. We trained a PINN using a limited number of DSMC-generated rarefied gas microflows in the transition regime ( 0.1 &lt; Kn &lt; 3 ) , incorporating continuity and Cauchy momentum exchange equations in the loss function. The PINN achieved under 2 % error on these residuals and effectively filtered DSMC’s intrinsic statistical noise. Predictions remained strong for a tested flow field with Kn = 0.7 , and showed limited extrapolation performance on a flow field with Kn = 5 with a local overshoot of about 20 %, while maintaining physical consistency. Notably, each DSMC field required ∼ 20 hours on 4 graphics processing units (GPU), while the PINN training took &lt; 2 hours on one GPU, with evaluations under 2 seconds.},
  archive      = {J_JOCS},
  author       = {Jean-Michel Tucny and Marco Lauricella and Mihir Durve and Gianmarco Guglielmo and Andrea Montessori and Sauro Succi},
  doi          = {10.1016/j.jocs.2025.102575},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102575},
  shortjournal = {J. Comput. Sci.},
  title        = {Physics-informed neural networks for microflows: Rarefied gas dynamics in cylinder arrays},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bearing-distance flocking with zone-based interactions in
constrained dynamic environments. <em>JOCS</em>, <em>87</em>, 102574.
(<a href="https://doi.org/10.1016/j.jocs.2025.102574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel zone-based flocking control approach suitable for dynamic multi-agent systems (MAS). Inspired by Reynolds behavioral rules for boids , flocking behavioral rules with the zones of repulsion, conflict, attraction, and surveillance are introduced. For each agent, using only bearing and distance measurements, behavioral contribution vectors quantify the local separation, local and global flock velocity alignment, local cohesion, obstacle avoidance and boundary conditions, and strategic separation for avoiding alien agents. The control strategy uses the local perception-based behavioral contribution vectors to guide each agent’s motion. Additionally, the control strategy incorporates a directionally aware obstacle avoidance mechanism that prioritizes obstacles in the agent’s forward path. Simulation results validate the effectiveness of the model in creating flexible, adaptable, and scalable flocking behavior. Asymptotic stability and convergence to a stable flocking configuration for any initial conditions provided the interaction graph is a spanning tree are demonstrated. The flocking model’s reliance on locally sensed bearing and distance measurements ensures scalability and robustness, particularly in scenarios where communication is unreliable or resource-intensive. This makes it well-suited for real-world applications demanding seamless operation in highly dynamic and distributed environments.},
  archive      = {J_JOCS},
  author       = {Hossein B. Jond},
  doi          = {10.1016/j.jocs.2025.102574},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102574},
  shortjournal = {J. Comput. Sci.},
  title        = {Bearing-distance flocking with zone-based interactions in constrained dynamic environments},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cutting voxel projector a new approach to construct 3D cone
beam CT operator. <em>JOCS</em>, <em>87</em>, 102573. (<a
href="https://doi.org/10.1016/j.jocs.2025.102573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel class of projectors for 3D cone beam tomographic reconstruction. Analytical formulas are derived to compute the relationship between the volume of a voxel projected onto a detector pixel and its contribution to the line integral of attenuation recorded by that pixel. Based on these formulas, we construct a near-exact projector and backprojector, particularly suited for algebraic reconstruction techniques and hierarchical reconstruction approaches with nonuniform voxel grids. Unlike traditional projectors, which assume a uniform grid with fixed voxel sizes, our method enables local refinement of voxels, allowing for adaptive grid resolution and improved reconstruction quality in regions of interest. We have implemented this cutting voxel projector along with a relaxed, speed-optimized version and compared them to two established projectors: a ray-tracing projector based on Siddon’s algorithm and a TT footprint projector. Our results demonstrate that the cutting voxel projector achieves higher accuracy than the TT projector, especially for large cone beam angles. Furthermore, the relaxed version of the cutting voxel projector offers a significant speed advantage, while maintaining comparable accuracy. In contrast, Siddon’s algorithm, tuned to achieve the same accuracy, is considerably slower than the cutting voxel projector. All algorithms are implemented in a GPU optimized open-source framework for algebraic reconstruction.},
  archive      = {J_JOCS},
  author       = {Vojtěch Kulvait and Julian Moosmann and Georg Rose},
  doi          = {10.1016/j.jocs.2025.102573},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102573},
  shortjournal = {J. Comput. Sci.},
  title        = {Cutting voxel projector a new approach to construct 3D cone beam CT operator},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification of ship motion model based on
IPPSA-MTCN-MHSA. <em>JOCS</em>, <em>87</em>, 102572. (<a
href="https://doi.org/10.1016/j.jocs.2025.102572">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An accurate ship motion model is crucial for predicting ship attitude, preventing accidents, and facilitating autonomous navigation systems. This paper treats ship motion modeling as a sequence modeling task and introduces a hybrid prediction model, termed MTCN-MHSA. The model integrates a Multi-Channel Temporal Convolutional Network (MTCN) and a Multi-Head Self-Attention Mechanism (MHSA). The MTCN, comprised of parallel TCN channels and a Bi-LSTM, extracts and fuses multi-dimensional features from the sequence. The MHSA mechanism is incorporated to minimize feature loss during information transmission, capture dependencies within the sequence, and enhance the model’s expressiveness and generalization capability. To optimize the hyperparameters of the MTCN-MHSA model, an Improved Positional PID-based Search Algorithm (IPPSA) is proposed, which builds upon the PID-based Search Algorithm (PSA). IPPSA exhibits superior global optimization capabilities and convergence speed, effectively identifying the optimal hyperparameters. Extensive comparative modeling experiments utilizing KVLCC2 and KCS ship maneuvering data validate the notable effectiveness and superiority of the proposed IPPSA-MTCN-MHSA model in ship motion prediction.},
  archive      = {J_JOCS},
  author       = {Zhibo Yang and Haozhe Zhang and Xuguo Jiao and Chengxing Lv and Jiyi Sun},
  doi          = {10.1016/j.jocs.2025.102572},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102572},
  shortjournal = {J. Comput. Sci.},
  title        = {Identification of ship motion model based on IPPSA-MTCN-MHSA},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the effectiveness of ROUGE as unbiased metric in
extractive vs. Abstractive summarization techniques. <em>JOCS</em>,
<em>87</em>, 102571. (<a
href="https://doi.org/10.1016/j.jocs.2025.102571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approaches to Automatic Text Summarization try to extract key information from one or more input texts and generate summaries whilst preserving content meaning. These strategies are separated into two groups, Extractive and Abstractive, which differ in their work. The extractive summarization extracts sentences from the document text directly, whereas the abstractive summarization creates a summary by interpreting the text and rewriting sentences, often with new words. It is important to assess and confirm how similar a summary is to the original text independently of the particular TS algorithm adopted. The literature proposes various metrics and scores for evaluating text summarization results, and ROUGE (Recall-Oriented Understudy of Gisting Evaluation) is the most used. In this study, our main objective is to evaluate how the ROUGE metric performs when applied to both Extractive and Abstractive summarization algorithms. We aim to understand its effectiveness and reliability as an independent and unbiased metric in assessing the quality of summaries generated by these different approaches. We conducted a first experiment to compare the metric efficiency (ROUGE-1, ROUGE-2 and ROUGE-L) for evaluating Abstractive (word2vec, doc2vec, and glove) v e r s u s Extractive Text Summarization algorithms (textRank, lsa, luhn, lexRank), and a second one to compare the obtained score for two different summary approaches: a simple execution of a summarization algorithm v e r s u s a multiple execution of different algorithms on the same text. Based on our study, evaluating the ROUGE metric for Abstractive and Extractive algorithms revealed that it reaches similar results for the Abstractive and Extractive algorithms. Moreover, our findings indicate that multiple executions, based on the running of two text summarization algorithms sequentially on the same text, generally outperform single executions of a single text summarization algorithm.},
  archive      = {J_JOCS},
  author       = {Alessia Auriemma Citarella and Marcello Barbella and Madalina G. Ciobanu and Fabiola De Marco and Luigi Di Biasi and Genoveffa Tortora},
  doi          = {10.1016/j.jocs.2025.102571},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102571},
  shortjournal = {J. Comput. Sci.},
  title        = {Assessing the effectiveness of ROUGE as unbiased metric in extractive vs. abstractive summarization techniques},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time virtual intervention for simple and serial
coronary artery disease using the HarVI framework. <em>JOCS</em>,
<em>87</em>, 102570. (<a
href="https://doi.org/10.1016/j.jocs.2025.102570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual planning tools that provide intuitive user interaction and immediate hemodynamic feedback are crucial for cardiologists to effectively treat coronary artery disease. Current FDA-approved tools for coronary intervention planning require days of preliminary processing and rely on conventional 2D displays for hemodynamic evaluation. Immersion offered by extended reality (XR) has been found to benefit intervention planning over traditional 2D displays. Building on our previous work (Tanade and Randles, 2024), we introduce HarVI, a coronary intervention planner that leverages machine learning for real-time hemodynamic analysis and extended reality for intuitive 3D user interaction. The framework uses a predefined set of 1D steady state computational fluid dynamics (CFD) simulations to perform one-shot training for our machine learning-based blood flow model. In a two-center cohort of 73 patients, 70 with focal lesions and 3 with serial lesions, we calculated fractional flow reserve — the gold standard biomarker of ischemia in coronary disease, flow rate, and wall shear stress using HarVI and 1D CFD models. HarVI was shown to almost perfectly recapitulate the results of 1D CFD simulations through continuous validation scores. In this study, we establish a machine learning-based process for virtual coronary treatment planning with an average turnaround time of just 62 min — around an order of magnitude improvement over literature standards, thus reducing the required time for one-shot training to less than one working day.},
  archive      = {J_JOCS},
  author       = {Cyrus Tanade and Amanda Randles},
  doi          = {10.1016/j.jocs.2025.102570},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102570},
  shortjournal = {J. Comput. Sci.},
  title        = {Real-time virtual intervention for simple and serial coronary artery disease using the HarVI framework},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State, parameters and hidden dynamics estimation with the
deep kalman filter: Regularization strategies. <em>JOCS</em>,
<em>87</em>, 102569. (<a
href="https://doi.org/10.1016/j.jocs.2025.102569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present in detail the various regularization strategies adopted for a novel scientific machine learning extension of the well known Kalman Filter (KF) that we call the Deep Kalman Filter (DKF), briefly presented in the conference paper (Chinellato and Marcuzzi 2024) . It is based on a recent scientific machine learning paradigm, called algorithm unfolding/unrolling, that allows to create a neural network from the algebraic structure dictated by an analytical method of scientific computing. We show the interpretable consistency of DKF with the classic KF when this is optimal, and its improvements against the KF with both linear and nonlinear models in general. Indeed, the DKF learns parameters of a quite general reference model, comprising: corrector gains, predictor model parameters and eventual unmodeled dynamics. This goes well beyond the ability of the KF and its known extensions.},
  archive      = {J_JOCS},
  author       = {Erik Chinellato and Fabio Marcuzzi},
  doi          = {10.1016/j.jocs.2025.102569},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102569},
  shortjournal = {J. Comput. Sci.},
  title        = {State, parameters and hidden dynamics estimation with the deep kalman filter: Regularization strategies},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of a high-performance tensor–matrix multiplication
with BLAS. <em>JOCS</em>, <em>87</em>, 102568. (<a
href="https://doi.org/10.1016/j.jocs.2025.102568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tensor–matrix multiplication (TTM) is a basic tensor operation required by various tensor methods such as the HOSVD. This paper presents flexible high-performance algorithms that compute the tensor–matrix product according to the Loops-over-GEMM (LOG) approach. The proposed algorithms can process dense tensors with any linear tensor layout, arbitrary tensor order and dimensions all of which can be runtime variable. The paper discusses two slicing methods with orthogonal parallelization strategies and propose four algorithms that call BLAS with subtensors or tensor slices. It also provides a simple heuristic which selects one of the four proposed algorithms at runtime. All algorithms have been evaluated on a large set of tensors with various tensor shapes and linear tensor layouts. In case of large tensor slices, our best-performing algorithm achieves a median performance of 2.47 TFLOPS on an Intel Xeon Gold 5318Y and 2.93 TFLOPS an AMD EPYC 9354. Furthermore, it outperforms batched GEMM implementation of Intel MKL by a factor of 2.57 with large tensor slices. Our runtime tests show that our best-performing algorithm is, on average, at least 6.21% and up to 334.31% faster than frameworks implementing state-of-the-art approaches, including actively developed libraries such as Libtorch and Eigen. For the majority of tensor shapes, it is on par with TBLIS which uses optimized kernels for the TTM computation. Our algorithm performs better than all other competing implementations for the majority of real world tensors from the SDRBench, reaching a speedup of 2x or more for some tensor instances. This work is an extended version of ”Fast and Layout-Oblivious Tensor–Matrix Multiplication with BLAS” (Başsoy 2024).},
  archive      = {J_JOCS},
  author       = {Cem Savaş Başsoy},
  doi          = {10.1016/j.jocs.2025.102568},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102568},
  shortjournal = {J. Comput. Sci.},
  title        = {Design of a high-performance tensor–matrix multiplication with BLAS},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of new CORDIC algorithms implemented on FPGA for
the givens rotator. <em>JOCS</em>, <em>87</em>, 102567. (<a
href="https://doi.org/10.1016/j.jocs.2025.102567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is an extended version of our conference paper ”Modified CORDIC Algorithm for Givens Rotator” (Poczekajlo et al., 2024) published at the International Conference on Computational Science (ICCS-2024). The CORDIC algorithm is an iterative method of computing trigonometric functions and rotating vectors without using complex calculations. This paper presents two modified CORDIC algorithms for implementing a Givens rotator on FPGA, improving upon classic CORDIC methods. The first approach introduces a selective iteration scheme with an optimized scaling factor, while the second, not published in the original ICCS-2024 paper, leverages a scaling-free methodology for improved precision. Implemented on an Altera Cyclone V FPGA, these algorithms demonstrate a 50% accuracy improvement and a 15% reduction in latency compared to standard methods. These findings contribute to enhanced FPGA-based trigonometric computations, particularly benefiting real-time signal processing and numerical linear algebra applications.},
  archive      = {J_JOCS},
  author       = {Pawel Poczekajlo and Leonid Moroz and Ewa Deelman and Pawel Gepner},
  doi          = {10.1016/j.jocs.2025.102567},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102567},
  shortjournal = {J. Comput. Sci.},
  title        = {Evaluation of new CORDIC algorithms implemented on FPGA for the givens rotator},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast temporal second-order compact finite difference
method for two-dimensional parabolic integro-differential equations with
weakly singular kernel. <em>JOCS</em>, <em>87</em>, 102558. (<a
href="https://doi.org/10.1016/j.jocs.2025.102558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a fast temporal second-order compact finite difference method for solving a class of two-dimensional parabolic integro-differential equations with weakly singular kernel. The sum-of-exponentials approximation of the kernel function is combined with the product averaged integration rule to approximate the weakly singular integral term, and the fourth-order compact finite difference method is employed to discretize the spatial derivative operator. We use the discrete energy technique to rigorously prove that the proposed fast method is almost unconditionally stable and convergent. Compared with the direct method, the fast method significantly reduces storage and computational costs while maintaining the temporal second-order convergence and spatial fourth-order convergence for weakly singular solutions. Some comparisons with the fast method using the exponential-sum-approximation technique, the fast Runge–Kutta convolution quadrature method and the explicit fast method based on the sum-of-exponentials approximation are discussed. The numerical results confirm the results of theoretical analysis and demonstrate the computational efficiency of the fast method.},
  archive      = {J_JOCS},
  author       = {Zi-Yun Zheng and Yuan-Ming Wang},
  doi          = {10.1016/j.jocs.2025.102558},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102558},
  shortjournal = {J. Comput. Sci.},
  title        = {A fast temporal second-order compact finite difference method for two-dimensional parabolic integro-differential equations with weakly singular kernel},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards universal MPI bindings for enhanced new language
support. <em>JOCS</em>, <em>87</em>, 102557. (<a
href="https://doi.org/10.1016/j.jocs.2025.102557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of High Performance Computing (HPC), Message Passing Interface (MPI) is the most widely used and prevalent programming model. Only the low-level programming languages C, C++, and Fortran have bindings available in the standard. Although there are attempts to provide MPI bindings for other programming languages, these may be limited, which could lead to incompatibilities, performance overhead, and functional gaps. To address those problems, we present MPI4All, a brand-new tool designed to make the process of developing effective MPI bindings for any programming language more straightforward. Support for additional languages can be added with little difficulty, and MPI4All is independent of the MPI implementation. Programming language binding generators for Go and Java are included in the most recent version of MPI4All. We demonstrate their good performance results with respect to other state-of-the-art approaches. This work is an extended version of the ICCS-2024 conference paper (Piñeiro et al., 2024).},
  archive      = {J_JOCS},
  author       = {César Piñeiro and Álvaro Vázquez and Juan C. Pichel},
  doi          = {10.1016/j.jocs.2025.102557},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102557},
  shortjournal = {J. Comput. Sci.},
  title        = {Towards universal MPI bindings for enhanced new language support},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of blood-related parameters for hyperthermia-based
treatments for cancer. <em>JOCS</em>, <em>87</em>, 102556. (<a
href="https://doi.org/10.1016/j.jocs.2025.102556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperthermia is a cancer treatment method that uses controlled heat to induce tumor necrosis while preserving healthy tissue. This study uses computational simulations to investigate the effects of capillary network variability and blood flow dynamics on the thermal response during hyperthermia. A porous media bioheat model, coupled with uncertainty quantification (UQ) techniques using Monte Carlo simulations, was developed to analyze the influence of capillary angles, blood velocity, and capillary density on temperature distribution in biological tissues. The model demonstrates that under a range of physiological uncertainties, tumor tissues consistently reach the critical damage threshold temperature of 4 3 ∘ C , while healthy tissues remain below 3 8 ∘ C , minimizing collateral damage. To address the computational intensity of solving three-dimensional heat transfer equations with UQ analysis, high-performance computing methods were employed. A parallel implementation using CUDA achieved a speedup exceeding 114 × compared to serial processing, while OpenMP achieved a 16 × speedup.},
  archive      = {J_JOCS},
  author       = {Gustavo Resende Fatigate and Gustavo Coelho Martins and Marcelo Lobosco and Ruy Freitas Reis},
  doi          = {10.1016/j.jocs.2025.102556},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102556},
  shortjournal = {J. Comput. Sci.},
  title        = {Influence of blood-related parameters for hyperthermia-based treatments for cancer},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Establishing a massively parallel computational model of the
adaptive immune response. <em>JOCS</em>, <em>87</em>, 102555. (<a
href="https://doi.org/10.1016/j.jocs.2025.102555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel agent-based models of the adaptive immune response can efficiently recapitulate emerging spatiotemporal properties of T-cell motility during clonal selection across multiple length and time scales. Here, we present a distributed, three-dimensional (3D) computational model of T-cell priming, and associated parallel data structures and algorithms that enable fully deterministic cell simulations at scale. We demonstrate performant usage of modern clusters with over 350x speedup, and explore trade-offs between simulation accuracy, code complexity, and communication overhead. This study highlights the potential for parallel 3D models to explore immunological research questions and guides implementation and performance considerations for this class of biology-inspired agent-based models.},
  archive      = {J_JOCS},
  author       = {Aristotle Martin and Max Nezdyur and Cyrus Tanade and Amanda Randles},
  doi          = {10.1016/j.jocs.2025.102555},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102555},
  shortjournal = {J. Comput. Sci.},
  title        = {Establishing a massively parallel computational model of the adaptive immune response},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AJAS: A high performance direct solver for advancing high
precision astrometry. <em>JOCS</em>, <em>87</em>, 102554. (<a
href="https://doi.org/10.1016/j.jocs.2025.102554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In astrometry, the determination of three-dimensional positions and velocities of stars based on observations from a space telescope suffers from the uncertainty of random and systematic errors. The systematic errors are introduced by imperfections of the telescope’s optics and detectors as well as in the pointing accuracy of the satellite. The fine art of astrometry consists of heuristically finding the best possible calibration model that will account for and remove these systematic errors. Since this is a process based on trial and error, appropriate software is needed that is efficient enough to solve the system of astrometric equations and reveal the astrometric parameters of stars for the given calibration model within a reasonable time. This paper is an extended version of the conference paper published and discussed at the International Conference on Computational Science 2024. In this work, we propose a novel software architecture and corresponding prototype of a direct solver optimized for running on supercomputers. The main advantages expected from this direct method over an iterative one are the numerical robustness, accuracy of the method, and the explicit calculation of the variance–covariance matrix for the estimation of the accuracy and correlation of the unknown parameters. This solver can handle astrometric systems with billions of equations within several hours. To reach the desired performance, we use state-of-the-art libraries and methods for hybrid parallel and vectorized computing. The calibration model based on Legendre polynomials is tested by generating synthetic observations on grid-shaped constellation with specified distortions. For these small-sized test data, the solver can recover perfectly the correct physical solution under the condition that the correct amount of eigenvalues is zeroed out. During the space mission, the calibration model should be carefully fine-tuned according to the real operating conditions. The developed solver is furthermore tested using mock science data related to the Japan Astrometry Satellite Mission for Infrared Exploration. Up to 9.2 billion observations of 115 thousand stars can be processed in 8.5 h utilizing 5000 CPUs. A linear scaling with the number of CPUs and a quadratic scaling with the number of observations is demonstrated.},
  archive      = {J_JOCS},
  author       = {Konstantin Ryabinin and Gerasimos Sarras and Wolfgang Löffler and Olga Erokhina and Michael Biermann},
  doi          = {10.1016/j.jocs.2025.102554},
  journal      = {Journal of Computational Science},
  month        = {5},
  pages        = {102554},
  shortjournal = {J. Comput. Sci.},
  title        = {AJAS: A high performance direct solver for advancing high precision astrometry},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="joe---18">JOE - 18</h2>
<ul>
<li><details>
<summary>
(2025). Quantile prediction with factor-augmented regression:
Structural instability and model uncertainty. <em>JOE</em>,
<em>249</em>, 105999. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105999">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantile regression is an effective tool in modeling data with heterogeneous conditional distribution. This paper considers the time-varying coefficient quantile predictive regression with factor-augmented predictors, to capture smooth structural changes and incorporate high-dimensional data information in prediction simultaneously. Uniform consistency of the local linear quantile coefficient estimators is established under misspecification. To further improve the forecast accuracy, a novel time-varying model averaging based on local forward-validation is developed. The averaging estimator is shown to be asymptotically optimal in the sense of minimizing out-of-sample forecast risk function. Furthermore, the weight selection consistency and the asymptotic distribution of the averaging coefficient estimator are established. Numerical results from simulations and a real data application to forecasting U.S. inflation demonstrate the nice performance of the averaging estimators.},
  archive      = {J_JOE},
  author       = {Yundong Tu and Siwei Wang},
  doi          = {10.1016/j.jeconom.2025.105999},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105999},
  shortjournal = {J. Econ.},
  title        = {Quantile prediction with factor-augmented regression: Structural instability and model uncertainty},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limit theory and inference in non-cointegrated functional
coefficient regression. <em>JOE</em>, <em>249</em>, 105996. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional coefficient (FC) cointegrating regressions offer empirical investigators flexibility in modeling economic relationships by introducing covariates that influence the direction and intensity of comovement among nonstationary time series. FC regression models are also useful when formal cointegration is absent, in the sense that the equation errors may themselves be nonstationary, but where the nonstationary series display well-defined FC linkages that can be meaningfully interpreted as correlation measures involving the covariates. The present paper proposes new nonparametric estimators for such FC regression models where the nonstationary series display linkages that enable consistent estimation of the correlation measures between them. Specifically, we develop n -consistent estimators for the functional coefficient and establish their asymptotic distributions, which involve mixed normal limits that facilitate inference. Two novel features that appear in the limit theory are (i) the need for non-diagonal matrix normalization due to the presence of stationary and nonstationary components in the regression; and (ii) random bias elements that appear in the asymptotic distribution of the kernel estimators, again resulting from the nonstationary regression components. Numerical studies reveal that the proposed estimators achieve significant efficiency improvements compared to the estimators suggested in earlier work by Sun et al. (2011). Easily implementable specification tests with standard chi-square asymptotics are suggested to check for constancy of the functional coefficient. These tests are shown to have faster divergence rate under local alternatives and enjoy superior performance in simulations than tests proposed in Gan et al. (2014). An empirical application based on the quantity theory of money is included, illustrating the practical use of correlated but non-cointegrated regression relations.},
  archive      = {J_JOE},
  author       = {Ying Wang and Peter C.B. Phillips and Yundong Tu},
  doi          = {10.1016/j.jeconom.2025.105996},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105996},
  shortjournal = {J. Econ.},
  title        = {Limit theory and inference in non-cointegrated functional coefficient regression},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supervised factor modeling for high-dimensional linear time
series. <em>JOE</em>, <em>249</em>, 105995. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by Tucker tensor decomposition, this paper imposes low-rank structures to the column and row spaces of coefficient matrices in a multivariate infinite-order vector autoregression (VAR), which leads to a supervised factor model with two factor modelings being conducted to responses and predictors simultaneously. Interestingly, the stationarity condition implies an intrinsic weak group sparsity mechanism of infinite-order VAR, and hence a rank-constrained group Lasso estimation is considered for high-dimensional linear time series. Its non-asymptotic properties are discussed by balancing the estimation, approximation and truncation errors. Moreover, an alternating gradient descent algorithm with hard-thresholding is designed to search for high-dimensional estimates, and its theoretical justifications, including statistical and convergence analysis, are also provided. Theoretical and computational properties of the proposed methodology are verified by simulation experiments, and the advantages over existing methods are demonstrated by analyzing US quarterly macroeconomic variables.},
  archive      = {J_JOE},
  author       = {Feiqing Huang and Kexin Lu and Yao Zheng and Guodong Li},
  doi          = {10.1016/j.jeconom.2025.105995},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105995},
  shortjournal = {J. Econ.},
  title        = {Supervised factor modeling for high-dimensional linear time series},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model averaging prediction for possibly nonstationary
autoregressions. <em>JOE</em>, <em>249</em>, 105994. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an alternative to model selection (MS), this paper considers model averaging (MA) for integrated autoregressive processes of infinite order (AR( ∞ )). We derive a uniformly asymptotic expression for the mean squared prediction error (MSPE) of the averaging prediction with fixed weights and then propose a Mallows-type criterion to select the data-driven weights that minimize the MSPE asymptotically. We show that the proposed MA estimator and its variants, Shibata and Akaike MA estimators, are asymptotically optimal in the sense of achieving the lowest possible MSPE. We further demonstrate that MA can provide significant MSPE reduction over MS in the algebraic-decay case. These theoretical findings are extended to integrated AR( ∞ ) models with deterministic time trends and are supported by Monte Carlo simulations and real data analysis.},
  archive      = {J_JOE},
  author       = {Tzu-Chi Lin and Chu-An Liu},
  doi          = {10.1016/j.jeconom.2025.105994},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105994},
  shortjournal = {J. Econ.},
  title        = {Model averaging prediction for possibly nonstationary autoregressions},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Huber principal component analysis for large-dimensional
factor models. <em>JOE</em>, <em>249</em>, 105993. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105993">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor models have been widely used in economics and finance. However, the heavy-tailed nature of macroeconomic and financial data is often neglected in statistical analysis. To address this issue, we propose a robust approach to estimate factor loadings and scores by minimizing the Huber loss function, which is motivated by the equivalence between conventional Principal Component Analysis (PCA) and the constrained least squares method in the factor model. We provide two algorithms that use different penalty forms. The first algorithm involves an element-wise-type Huber loss minimization, solved by an iterative Huber regression algorithm. The second algorithm, which we refer to as Huber PCA, minimizes the ℓ 2 -norm-type Huber loss and performs PCA on the weighted sample covariance matrix. We examine the theoretical minimizer of the element-wise Huber loss function and demonstrate that it has the same convergence rate as conventional PCA when the idiosyncratic errors have bounded second moments. We also derive their asymptotic distributions under mild conditions. Moreover, we suggest a consistent model selection criterion that relies on rank minimization to estimate the number of factors robustly. We showcase the benefits of the proposed two algorithms through extensive numerical experiments and a real macroeconomic data example. An R package named “ HDRFA ” 1 has been developed to conduct the proposed robust factor analysis.},
  archive      = {J_JOE},
  author       = {Yong He and Lingxiao Li and Dong Liu and Wen-Xin Zhou},
  doi          = {10.1016/j.jeconom.2025.105993},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105993},
  shortjournal = {J. Econ.},
  title        = {Huber principal component analysis for large-dimensional factor models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantile granger causality in the presence of instability.
<em>JOE</em>, <em>249</em>, 105992. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new framework for assessing Granger causality in quantiles in unstable environments, for a fixed quantile or over a continuum of quantile levels. Our proposed test statistics are consistent against fixed alternatives, they have nontrivial power against local alternatives, and they are pivotal in certain important special cases. In addition, we show the validity of a bootstrap procedure when asymptotic distributions depend on nuisance parameters. Monte Carlo simulations reveal that the proposed test statistics have correct empirical size and high power, even in absence of structural breaks. Moreover, a procedure providing additional insight into the timing of Granger causal regimes based on our new tests is proposed. Finally, an empirical application in energy economics highlights the applicability of our method as the new tests provide stronger evidence of Granger causality.},
  archive      = {J_JOE},
  author       = {Alexander Mayer and Dominik Wied and Victor Troster},
  doi          = {10.1016/j.jeconom.2025.105992},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105992},
  shortjournal = {J. Econ.},
  title        = {Quantile granger causality in the presence of instability},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adjustments with many regressors under covariate-adaptive
randomizations. <em>JOE</em>, <em>249</em>, 105991. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our paper discovers a new trade-off of using regression adjustments (RAs) in causal inference under covariate-adaptive randomizations (CARs). On one hand, RAs can improve the efficiency of causal estimators by incorporating information from covariates that are not used in the randomization. On the other hand, RAs can degrade estimation efficiency due to their estimation errors, which are not asymptotically negligible when the number of regressors is of the same order as the sample size. Ignoring the estimation errors of RAs may result in serious over-rejection of causal inference under the null hypothesis. To address the issue, we construct a new ATE estimator by optimally linearly combining the estimators with and without RAs. We then develop a unified inference theory for this estimator under CARs. It has two features: (1) the Wald test based on it achieves the exact asymptotic size under the null hypothesis, regardless of whether the number of covariates is fixed or diverges no faster than the sample size; and (2) it guarantees weak efficiency improvement over estimators both with and without RAs.},
  archive      = {J_JOE},
  author       = {Liang Jiang and Liyao Li and Ke Miao and Yichong Zhang},
  doi          = {10.1016/j.jeconom.2025.105991},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105991},
  shortjournal = {J. Econ.},
  title        = {Adjustments with many regressors under covariate-adaptive randomizations},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bootstrap based asymptotic refinements for high-dimensional
nonlinear models. <em>JOE</em>, <em>249</em>, 105977. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider penalized extremum estimation of a high-dimensional, possibly nonlinear model that is sparse in the sense that most of its parameters are zero but some are not. We use the SCAD penalty function, which provides model selection consistent and oracle efficient estimates under suitable conditions. However, asymptotic approximations based on the oracle model can be inaccurate with the sample sizes found in many applications. This paper gives conditions under which the bootstrap, based on estimates obtained through SCAD penalization with thresholding, provides asymptotic refinements of size O ( n − 2 ) for the error in the rejection (coverage) probability of a symmetric hypothesis test (confidence interval) and O ( n − 1 ) for the error in the rejection (coverage) probability of a one-sided or equal tailed test (confidence interval). The results of Monte Carlo experiments show that the bootstrap can provide large reductions in errors in rejection and coverage probabilities. The bootstrap is consistent, though it does not necessarily provide asymptotic refinements, if some parameters are close but not equal to zero. Random-coefficients logit and probit models and nonlinear moment models are examples of models to which the procedure applies.},
  archive      = {J_JOE},
  author       = {Joel L. Horowitz and Ahnaf Rafi},
  doi          = {10.1016/j.jeconom.2025.105977},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105977},
  shortjournal = {J. Econ.},
  title        = {Bootstrap based asymptotic refinements for high-dimensional nonlinear models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor time series imputation through tensor factor
modelling. <em>JOE</em>, <em>249</em>, 105974. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose tensor time series imputation when the missing pattern in the tensor data can be general, as long as any two data positions along a tensor fibre are both observed for enough time points. The method is based on a tensor time series factor model with Tucker decomposition of the common component. One distinguished feature of the tensor time series factor model used is that there can be weak factors in the factor loading matrix for each mode. This reflects reality better when real data can have weak factors which drive only groups of observed variables, for instance, a sector factor in a financial market driving only stocks in a particular sector. Using the data with missing entries, asymptotic normality is derived for rows of estimated factor loadings, while consistent covariance matrix estimation enables us to carry out inferences. As a first in the literature, we also propose a ratio-based estimator for the rank of the core tensor under general missing patterns. Rates of convergence are spelt out for the imputations from the estimated tensor factor models. Simulation results show that our imputation procedure works well, with asymptotic normality and corresponding inferences also demonstrated. Re-imputation performances are also gauged when we demonstrate that using slightly larger rank then estimated gives superior re-imputation performances. A Fama–French portfolio example with matrix returns and an OECD data example with matrix of economic indicators are presented and analysed, showing the efficacy of our imputation approach compared to direct vector imputation.},
  archive      = {J_JOE},
  author       = {Zetai Cen and Clifford Lam},
  doi          = {10.1016/j.jeconom.2025.105974},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105974},
  shortjournal = {J. Econ.},
  title        = {Tensor time series imputation through tensor factor modelling},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimation and uniform inference in sparse high-dimensional
additive models. <em>JOE</em>, <em>249</em>, 105973. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a novel method to construct uniformly valid confidence bands for a nonparametric component f 1 in the sparse additive model Y = f 1 ( X 1 ) + … + f p ( X p ) + ɛ in a high-dimensional setting. Our method integrates sieve estimation into a high-dimensional Z-estimation framework, facilitating the construction of uniformly valid confidence bands for the target component f 1 . To form these confidence bands, we employ a multiplier bootstrap procedure. Additionally, we provide rates for the uniform lasso estimation in high dimensions, which may be of independent interest. Through simulation studies, we demonstrate that our proposed method delivers reliable results in terms of estimation and coverage, even in small samples.},
  archive      = {J_JOE},
  author       = {Philipp Bach and Sven Klaassen and Jannis Kueck and Martin Spindler},
  doi          = {10.1016/j.jeconom.2025.105973},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105973},
  shortjournal = {J. Econ.},
  title        = {Estimation and uniform inference in sparse high-dimensional additive models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When structural break meets threshold effect: Factor
analysis under structural instabilities. <em>JOE</em>, <em>249</em>,
105972. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural instability has been one of the central research questions in economics and finance over many decades. This paper systematically investigates structural instabilities in high dimensional factor models, which portray both structural breaks and threshold effects simultaneously. The observed high dimensional time series are concatenated at an unknown number of break points, while they are described by multiple threshold factor models that are heterogeneous between any two consecutive subsamples. Both joint and sequential procedures for estimating the break points are developed based on the second moment of the pseudo factor estimates that fully ignore the structural instabilities. In each separated subsample, the group Lasso approach recently proposed by Ma and Tu (2023b) is adopted to efficiently identify the threshold factor structure. An information criterion is further proposed to determine the number of break points, which also serves the purpose to distinguish the two types of instabilities. Theoretical properties of the proposed estimators are established, and their finite sample performance is evaluated in Monte Carlo simulations. An empirical application to the U.S. financial market dataset demonstrates the consequences when structural break meets threshold effect in factor analysis.},
  archive      = {J_JOE},
  author       = {Chenchen Ma and Yundong Tu},
  doi          = {10.1016/j.jeconom.2025.105972},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105972},
  shortjournal = {J. Econ.},
  title        = {When structural break meets threshold effect: Factor analysis under structural instabilities},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large confirmatory dynamic factor model for stock market
returns in different time zones. <em>JOE</em>, <em>249</em>, 105971. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a confirmatory dynamic factor model for a large number of stocks whose returns are observed daily across multiple time zones. The model has a global factor and a continental factor that both drive the individual stock return series. We propose two estimators of the model: a quasi-maximum likelihood estimator (QML-just-identified), and an improved estimator based on an Expectation Maximization (EM) algorithm (QML-all-res). Our estimators are consistent and asymptotically normal under the large approximate factor model setting. In particular, the asymptotic distributions of QML-all-res are the same as those of the infeasible OLS estimators that treat factors as known and utilize all the restrictions on the parameters of the model. We apply the model to MSCI equity indices of 42 developed and emerging markets, and find that most markets are more integrated when the CBOE Volatility Index (VIX) is high.},
  archive      = {J_JOE},
  author       = {Oliver B. Linton and Haihan Tang and Jianbin Wu},
  doi          = {10.1016/j.jeconom.2025.105971},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105971},
  shortjournal = {J. Econ.},
  title        = {A large confirmatory dynamic factor model for stock market returns in different time zones},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On time-varying panel data models with time-varying
interactive fixed effects. <em>JOE</em>, <em>249</em>, 105960. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a time-varying (TV) panel data model with interactive fixed effects where both the coefficients and factor loadings are allowed to change smoothly over time. We propose a local version of the least squares and principal component method to estimate the TV coefficients, TV factor loadings, and common factors simultaneously. We provide a bias-corrected local least squares estimator for the TV coefficients and establish the limiting distributions and uniform convergence of the bias-corrected coefficient estimators, estimated factors, and factor loadings in the large N and large T framework. Based on the estimates, we propose three test statistics to gauge possible sources of TV features. We establish the limit null distributions and the asymptotic local power properties of our tests. Simulations are conducted to evaluate the finite sample performance of our estimates and tests. We apply our theoretical results to analyze the Phillips curve using the U.S. state-level unemployment rates and nominal wages, and document significant TV behavior in both the slope coefficient and factor loadings.},
  archive      = {J_JOE},
  author       = {Xia Wang and Sainan Jin and Yingxing Li and Junhui Qian and Liangjun Su},
  doi          = {10.1016/j.jeconom.2025.105960},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105960},
  shortjournal = {J. Econ.},
  title        = {On time-varying panel data models with time-varying interactive fixed effects},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplicative factor model for volatility. <em>JOE</em>,
<em>249</em>, 105959. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facilitated with high-frequency observations, we introduce a remarkably parsimonious one-factor volatility model that offers a novel perspective for comprehending daily volatilities of a large number of stocks. Specifically, we propose a multiplicative volatility factor (MVF) model, where stock daily variance is represented by a common variance factor and a multiplicative idiosyncratic component. We demonstrate compelling empirical evidence supporting our model and provide statistical properties for two simple estimation methods. The MVF model reflects important properties of volatilities, applies to both individual stocks and portfolios, can be easily estimated, and leads to exceptional predictive performance in both US stocks and global equity indices.},
  archive      = {J_JOE},
  author       = {Yi Ding and Robert Engle and Yingying Li and Xinghua Zheng},
  doi          = {10.1016/j.jeconom.2025.105959},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105959},
  shortjournal = {J. Econ.},
  title        = {Multiplicative factor model for volatility},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Penalized estimation of finite mixture models. <em>JOE</em>,
<em>249</em>, 105958. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Economists often model unobserved heterogeneity using finite mixtures. In practice, the number of mixture components is rarely known. Model parameters lack point-identification if the estimation includes too many components, thus invalidating the classic properties of maximum likelihood estimation. I propose a penalized likelihood method to estimate finite mixtures with an unknown number of components. The resulting Order-Selection-Consistent Estimator (OSCE) consistently estimates the true number of components and achieves oracle efficiency. This paper extends penalized estimation to models without point-identification and to mixtures with growing number of components. I apply the OSCE to estimate players’ rationality levels in a coordination game.},
  archive      = {J_JOE},
  author       = {Sofya Budanova},
  doi          = {10.1016/j.jeconom.2025.105958},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105958},
  shortjournal = {J. Econ.},
  title        = {Penalized estimation of finite mixture models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional heterogeneous panel data models with
multi-level interactive fixed effects. <em>JOE</em>, <em>249</em>,
105957. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a three-dimensional (3D) panel data model with heterogeneous slope coefficients and multi-level interactive fixed effects consisting of latent global factors and two types of local factors. Our model nests many commonly used 3D panel data models. We propose an iterative estimation procedure that relies on initial consistent estimators obtained through a novel defactored approach. We study the asymptotic properties of our estimators and show that our iterative estimators of the slope coefficients are “oracle efficient” in the sense that they are asymptotically equivalent to those when the factors were known. Some specification testing issues are also considered. Monte Carlo simulations demonstrate that our estimators and tests perform well in finite samples. We apply our new method to the international trade dataset.},
  archive      = {J_JOE},
  author       = {Sainan Jin and Xun Lu and Liangjun Su},
  doi          = {10.1016/j.jeconom.2025.105957},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105957},
  shortjournal = {J. Econ.},
  title        = {Three-dimensional heterogeneous panel data models with multi-level interactive fixed effects},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification and estimation of a search model with
heterogeneous consumers and firms. <em>JOE</em>, <em>249</em>, 105956.
(<a href="https://doi.org/10.1016/j.jeconom.2025.105956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a model of nonsequential consumer search where consumers and firms differ in search and production costs respectively. We characterize the equilibrium of the game. We first show the distribution of search cost can be identified by market shares and prices. Subsequently, we identify the production cost distribution using a similar strategy to Guerre, Perrigne and Vuong (2000) as the firms’ decision problems resemble bidders’ problems in a particular procurement auction. We prove the firm’s cost density can be estimated at the same convergence rate as the optimal rate in Guerre et al. uniformly over any fixed subset on the interior of the support. The uniform convergence rate over any expanding support is slower due to a pole in the price pdf that is a feature of the equilibrium. Our simulation study confirms the theoretical features of the model. Our identification and convergence rate results also apply to two generalizations of the baseline search model that allow for: (i) vertically differentiated products; (ii) an intermediary. We apply the latter model to study loan search using UK mortgage data.},
  archive      = {J_JOE},
  author       = {Mateusz Myśliwski and May Rostom and Fabio Sanches and Daniel Silva Jr and Sorawoot Srisuma},
  doi          = {10.1016/j.jeconom.2025.105956},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105956},
  shortjournal = {J. Econ.},
  title        = {Identification and estimation of a search model with heterogeneous consumers and firms},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simple subvector inference on sharp identified set in affine
models. <em>JOE</em>, <em>249</em>, 105952. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105952">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a regularized support function estimator for bounds on components of the parameter vector in the case in which the identified set is a polygon. The proposed regularized estimator has three important properties: (i) it has a uniform asymptotic Gaussian limit in the presence of flat faces in the absence of redundant (or overidentifying) constraints (or vice versa); (ii) the bias from regularization does not enter the first-order limiting distribution; (iii) the estimator remains consistent for sharp (non-enlarged) identified set for the individual components even in the non-regular case. These properties are used to construct uniformly valid confidence sets for an element θ 1 of a parameter vector θ ∈ R d that is partially identified by affine moment equality and inequality conditions. The proposed confidence sets can be computed as a solution to a small number of linear and convex quadratic programs, leading to a substantial decrease in computation time and guarantees a global optimum. As a result, the method provides a uniformly valid inference in applications in which the dimension of the parameter space, d , and the number of inequalities, k , were previously computationally unfeasible ( d , k = 100 ). The proposed approach can be extended to construct confidence sets for intersection bounds, to construct joint polygon-shaped confidence sets for multiple components of θ , and to find the set of solutions to a linear program. Inference for coefficients in the linear IV regression model with an interval outcome is used as an illustrative example.},
  archive      = {J_JOE},
  author       = {Bulat Gafarov},
  doi          = {10.1016/j.jeconom.2025.105952},
  journal      = {Journal of Econometrics},
  month        = {5},
  pages        = {105952},
  shortjournal = {J. Econ.},
  title        = {Simple subvector inference on sharp identified set in affine models},
  volume       = {249},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="joma---11">JOMA - 11</h2>
<ul>
<li><details>
<summary>
(2025). Asymptotics of estimators for structured covariance
matrices. <em>JOMA</em>, <em>208</em>, 105443. (<a
href="https://doi.org/10.1016/j.jmva.2025.105443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that the limiting variance of a sequence of estimators for a structured covariance matrix has a general form, that for linear covariance structures appears as the variance of a scaled projection of a random matrix that is of radial type, and a similar result is obtained for the corresponding sequence of estimators for the vector of variance components. These results are illustrated by the limiting behavior of estimators for a differentiable covariance structure in a variety of multivariate statistical models. We also derive a characterization for the influence function of corresponding functionals. Furthermore, we derive the limiting distribution and influence function of scale invariant mappings of such estimators and their corresponding functionals. As a consequence, the asymptotic relative efficiency of different estimators for the shape component of a structured covariance matrix can be compared by means of a single scalar and the gross error sensitivity of the corresponding influence functions can be compared by means of a single index. Similar results are obtained for estimators of the normalized vector of variance components. We apply our results to investigate how the efficiency, gross error sensitivity, and breakdown point of S-estimators for the normalized variance components are affected simultaneously by varying their cutoff value.},
  archive      = {J_JOMA},
  author       = {Hendrik Paul Lopuhaä},
  doi          = {10.1016/j.jmva.2025.105443},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105443},
  shortjournal = {J. Multi. Anal.},
  title        = {Asymptotics of estimators for structured covariance matrices},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum spacing estimation for multivariate observations
under a general class of information-type measures. <em>JOMA</em>,
<em>208</em>, 105433. (<a
href="https://doi.org/10.1016/j.jmva.2025.105433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the maximum spacing (MSP) method for multivariate observations, nearest neighbour balls are used as a multidimensional analogue to univariate spacings. Compared to the previous studies, a broader class of MSP estimators corresponding to different information-type measures is studied. The studied class of estimators includes also the estimator corresponding to the Kullback–Leibler information measure obtained with the logarithmic function. Consistency of the MSP estimators is proved when the assigned model class is correct, that is the true density belongs to the assigned class. The behaviour of the MSP estimator under different divergence measures is studied and the advantage of using MSP estimators corresponding to different information measures in the context of model validation is illustrated in simulation examples.},
  archive      = {J_JOMA},
  author       = {Kristi Kuljus and Han Bao and Bo Ranneby},
  doi          = {10.1016/j.jmva.2025.105433},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105433},
  shortjournal = {J. Multi. Anal.},
  title        = {Maximum spacing estimation for multivariate observations under a general class of information-type measures},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimaxity under the half-cauchy prior. <em>JOMA</em>,
<em>208</em>, 105431. (<a
href="https://doi.org/10.1016/j.jmva.2025.105431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This is a follow-up paper of Polson and Scott (2012, Bayesian Analysis), which claimed that the half-Cauchy prior is a sensible default prior for a scale parameter in hierarchical models. For estimation of a p -variate normal mean under the quadratic loss, they demonstrated that the Bayes estimator with respect to the half-Cauchy prior seems to be minimax through numerical experiments. In this paper, we theoretically establish the minimaxity of the corresponding Bayes estimator using the interval arithmetic.},
  archive      = {J_JOMA},
  author       = {Yuzo Maruyama and Takeru Matsuda},
  doi          = {10.1016/j.jmva.2025.105431},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105431},
  shortjournal = {J. Multi. Anal.},
  title        = {Minimaxity under the half-cauchy prior},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric scale mixtures of normal distributions.
<em>JOMA</em>, <em>208</em>, 105430. (<a
href="https://doi.org/10.1016/j.jmva.2025.105430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Kundu (2017) proposed a multivariate skewed distribution, termed the Geometric-Normal (GN) distribution, by compounding the multivariate normal distribution with the geometric distribution. This distribution is a viable alternative to Azzalini’s multivariate skew-normal distribution and possesses several desirable properties. This paper introduces a novel class of asymmetric distributions by compounding the geometric distribution with scale mixtures of normal distributions. This class constitutes a special case of the continuous mixtures of multivariate normal distributions introduced by Arellano-Valle and Azzalini (2021). The proposed multivariate distributions exhibit high flexibility, featuring heavy tails, multi-modality, and the ability to model skewness. We have also derived several properties of this class and discussed specific examples to illustrate its applications. The expectation–maximization algorithm was employed to calculate the maximum likelihood estimates of the unknown parameters. Simulation experiments have been performed to show the effectiveness of the proposed algorithm. For illustrative purposes, we have provided one multivariate data set where it has been observed that there exist members in the proposed class of models that can provide better fit compared to skew-normal, skew-t, and generalized hyperbolic distribution. In another example, it was demonstrated that when data generated from a heavy-tailed skew-t distribution is contaminated with noise, the proposed distributions offer a better fit compared to the skew-t distribution.},
  archive      = {J_JOMA},
  author       = {Deepak Prajapati and Sobhan Shafiei and Debasis Kundu and Ahad Jamalizadeh},
  doi          = {10.1016/j.jmva.2025.105430},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105430},
  shortjournal = {J. Multi. Anal.},
  title        = {Geometric scale mixtures of normal distributions},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ledoit-wolf linear shrinkage with unknown mean.
<em>JOMA</em>, <em>208</em>, 105429. (<a
href="https://doi.org/10.1016/j.jmva.2025.105429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses large dimensional covariance matrix estimation with unknown mean. The empirical covariance estimator fails when dimension and number of samples are proportional and tend to infinity, settings known as Kolmogorov asymptotics. When the mean is known, Ledoit and Wolf (2004) proposed a linear shrinkage estimator and proved its convergence under those asymptotics. To the best of our knowledge, no formal proof has been proposed when the mean is unknown. To address this issue, we propose to extend the linear shrinkage and its convergence properties to translation-invariant estimators. We expose four estimators respecting those conditions, proving their properties. Finally, we show empirically that a new estimator we propose outperforms other standard estimators.},
  archive      = {J_JOMA},
  author       = {Benoît Oriol and Alexandre Miot},
  doi          = {10.1016/j.jmva.2025.105429},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105429},
  shortjournal = {J. Multi. Anal.},
  title        = {Ledoit-wolf linear shrinkage with unknown mean},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Markov switching multiple-equation tensor regressions.
<em>JOMA</em>, <em>208</em>, 105427. (<a
href="https://doi.org/10.1016/j.jmva.2025.105427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new flexible tensor model for multiple-equation regressions that accounts for latent regime changes is proposed. The model allows for dynamic coefficients and multi-dimensional covariates that vary across equations. The coefficients are driven by a common hidden Markov process that addresses structural breaks to enhance the model flexibility and preserve parsimony. A new soft PARAFAC hierarchical prior is introduced to achieve dimensionality reduction while preserving the structural information of the covariate tensor. The proposed prior includes a new multi-way shrinking effect to address over-parametrization issues while preserving interpretability and model tractability. Theoretical results are derived to help with the choice of the hyperparameters. An efficient Markov chain Monte Carlo (MCMC) algorithm based on random scan Gibbs and back-fitting strategy is designed with priority placed on computational scalability of the posterior sampling. The validity of the MCMC algorithm is demonstrated theoretically, and its computational efficiency is studied using numerical experiments in different parameter settings. The effectiveness of the model framework is illustrated using two original real data analyses. The proposed model exhibits superior performance compared to the current benchmark, Lasso regression.},
  archive      = {J_JOMA},
  author       = {Roberto Casarin and Radu V. Craiu and Qing Wang},
  doi          = {10.1016/j.jmva.2025.105427},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105427},
  shortjournal = {J. Multi. Anal.},
  title        = {Markov switching multiple-equation tensor regressions},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On estimation and order selection for multivariate extremes
via clustering. <em>JOMA</em>, <em>208</em>, 105426. (<a
href="https://doi.org/10.1016/j.jmva.2025.105426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the estimation of multivariate extreme models with a discrete spectral measure using spherical clustering techniques. The primary contribution involves devising a method for selecting the order, that is, the number of clusters. The method consistently identifies the true order, i.e., the number of spectral atoms, and enjoys intuitive implementation in practice. Specifically, we introduce an extra penalty term to the well-known simplified average silhouette width, which penalizes small cluster sizes and small dissimilarities between cluster centers. Consequently, we provide a consistent method for determining the order of a max-linear factor model, where a typical information-based approach is not viable. Our second contribution is a large-deviation-type analysis for estimating the discrete spectral measure through clustering methods, which serves as an assessment of the convergence quality of clustering-based estimation for multivariate extremes. Additionally, as a third contribution, we discuss how estimating the discrete measure can lead to parameter estimations of heavy-tailed factor models. We also present simulations and real-data studies that demonstrate order selection and factor model estimation.},
  archive      = {J_JOMA},
  author       = {Shiyuan Deng and He Tang and Shuyang Bai},
  doi          = {10.1016/j.jmva.2025.105426},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105426},
  shortjournal = {J. Multi. Anal.},
  title        = {On estimation and order selection for multivariate extremes via clustering},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Set-valued expectiles for ordered data analysis.
<em>JOMA</em>, <em>208</em>, 105425. (<a
href="https://doi.org/10.1016/j.jmva.2025.105425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expectile regions–like depth regions in general–capture the idea of centrality of multivariate distributions. If an order relation is present for the values of random vectors and a decision maker is interested in dominant/best points with respect to this order, centrality is not a useful concept. Therefore, cone expectile sets are introduced which depend on a vector preorder generated by a convex cone. This provides a way of describing and clustering a multivariate distribution/data cloud with respect to an order relation. Fundamental properties of cone expectiles are established including dual representations of both expectile regions and cone expectile sets. It is shown that set-valued sublinear risk measures can be constructed from cone expectile sets in the same way as in the univariate case. Inverse functions of cone expectiles are defined which should be considered as ranking functions related to the initial order relation rather than as depth functions. Finally, expectile orders for random vectors are introduced and characterized via expectile ranking functions.},
  archive      = {J_JOMA},
  author       = {Andreas H. Hamel and Thi Khanh Linh Ha},
  doi          = {10.1016/j.jmva.2025.105425},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105425},
  shortjournal = {J. Multi. Anal.},
  title        = {Set-valued expectiles for ordered data analysis},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a class of finite mixture models that includes hidden
markov models. <em>JOMA</em>, <em>208</em>, 105423. (<a
href="https://doi.org/10.1016/j.jmva.2025.105423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of longitudinal data, we introduce a class of finite mixture (FM) models that generalizes that of hidden Markov (HM) models, and derive conditions under which the two classes are equivalent. On the basis of this result, we develop a likelihood ratio (LR) misspecification test for assessing the latent structure of an HM model, along with a multiple version of this test that may be used in the presence of many latent states or time occasions. This testing procedure requires the maximum likelihood estimation of the two models under comparison, that is, the assumed HM model and the more general FM model, which is performed by suitable versions of the Expectation–Maximization algorithm. The approach is validated through a simulation study, aimed at assessing the performance of the proposed tests under different circumstances, and by an application using data derived from the SCImago Journal &amp; Country Rank database.},
  archive      = {J_JOMA},
  author       = {Francesco Bartolucci and Silvia Pandolfi and Fulvia Pennoni},
  doi          = {10.1016/j.jmva.2025.105423},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105423},
  shortjournal = {J. Multi. Anal.},
  title        = {On a class of finite mixture models that includes hidden markov models},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical analysis of parsimonious high-order multivariate
finite markov chains based on sufficient statistics. <em>JOMA</em>,
<em>208</em>, 105422. (<a
href="https://doi.org/10.1016/j.jmva.2025.105422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new parsimonious MCSS ( s ) (which stands for “Markov Chain of order s based on Sufficient Statistics”) model for multivariate discrete-valued time series is constructed. The MCSS ( s ) model has sufficient statistics of a simple form based on multivariate frequencies of ( s + 1 ) -tuples for observed time series. Special cases of the MCSS ( s ) model and their relations to the results known in the literature are discussed. The strong concavity property of the loglikelihood function and the uniqueness of the maximum likelihood estimator under mild regularity conditions are proven for the MCSS ( s ) model. Forecasting statistics for the multivariate discrete-valued time series derived with the MCSS ( s ) model are constructed. The developed theory is illustrated with computer experiments on simulated and real data.},
  archive      = {J_JOMA},
  author       = {Yuriy Kharin and Valeriy Voloshko},
  doi          = {10.1016/j.jmva.2025.105422},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105422},
  shortjournal = {J. Multi. Anal.},
  title        = {Statistical analysis of parsimonious high-order multivariate finite markov chains based on sufficient statistics},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New results for drift estimation in inhomogeneous stochastic
differential equations. <em>JOMA</em>, <em>208</em>, 105415. (<a
href="https://doi.org/10.1016/j.jmva.2025.105415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider N independent and identically distributed ( i.i.d. ) stochastic processes ( X j ( t ) , t ∈ [ 0 , T ] ) , j ∈ { 1 , … , N } , defined by a one-dimensional stochastic differential equation (SDE) with time-dependent drift and diffusion coefficient. In this context, the nonparametric estimation of a general drift function b ( t , x ) from a continuous observation of the N sample paths on [ 0 , T ] has never been investigated. Considering a set I ϵ = [ ϵ , T ] × A , with ϵ ≥ 0 and A ⊂ R , we build by a projection method an estimator of b on I ϵ . As the function is bivariate, this amounts to estimating a matrix of projection coefficients instead of a vector for univariate functions. We make use of Kronecker products, which simplifies the mathematical treatment of the problem. We study the risk of the estimator and distinguish the case where ϵ = 0 and the case ϵ &gt; 0 and A = [ a , b ] compact. In the latter case, we investigate rates of convergence and prove a lower bound showing that our estimator is minimax. We propose a data-driven choice of the projection space dimension leading to an adaptive estimator. Examples of models and numerical simulation results are proposed. The method is easy to implement and works well, although computationally slower than for the estimation of a univariate function.},
  archive      = {J_JOMA},
  author       = {Fabienne Comte and Valentine Genon-Catalot},
  doi          = {10.1016/j.jmva.2025.105415},
  journal      = {Journal of Multivariate Analysis},
  month        = {7},
  pages        = {105415},
  shortjournal = {J. Multi. Anal.},
  title        = {New results for drift estimation in inhomogeneous stochastic differential equations},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jomp---4">JOMP - 4</h2>
<ul>
<li><details>
<summary>
(2025). An entropy model of decision uncertainty. <em>JOMP</em>,
<em>125</em>, 102919. (<a
href="https://doi.org/10.1016/j.jmp.2025.102919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studying metacognition, the introspection of one&#39;s own decisions, can provide insights into the mechanisms underlying the decisions. Here we show that observers’ uncertainty about their decisions incorporates both the entropy of the stimuli and the entropy of their response probabilities across the psychometric function. Describing uncertainty data with a functional form permits the measurement of internal parameters not measurable from the decision responses alone. To test and demonstrate the utility of this novel model, we measured uncertainty in 11 participants as they judged the relative contrast appearance of two stimuli in several experiments employing implicit bias or attentional cues. The entropy model enabled an otherwise intractable quantitative analysis of participants’ uncertainty, which in one case distinguished two comparative judgments that produced nearly identical psychometric functions. In contrast, comparative and equality judgments with different behavioral reports yielded uncertainty reports that were not significantly different. The entropy model was able to successfully account for uncertainty in these two different types of decisions that resulted in differently shaped psychometric functions, and the entropy contribution from the stimuli, which were identical across experiments, was consistent. An observer&#39;s uncertainty could therefore be measured as the total entropy of the inputs and outputs of the stimulus-response system, i.e. the entropy of the stimuli plus the entropy of the observer&#39;s responses.},
  archive      = {J_JOMP},
  author       = {Keith A. Schneider},
  doi          = {10.1016/j.jmp.2025.102919},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102919},
  shortjournal = {J. Math. Psychol.},
  title        = {An entropy model of decision uncertainty},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The assessment of global optimization skills in procedural
knowledge space theory. <em>JOMP</em>, <em>125</em>, 102907. (<a
href="https://doi.org/10.1016/j.jmp.2025.102907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Procedural knowledge space theory aims to evaluate problem-solving skills using a formal representation of a problem space. Stefanutti et al. (2021) introduced the concept of the “shortest path space” to characterize optimal problem spaces when a task requires reaching a solution in the minimum number of moves. This paper takes that idea further. It expands the shortest-path space concept to include a wider range of optimization problems, where each move can be weighted by a real number representing its “value”. Depending on the application, the “value” could be a cost, waiting time, route length, etc. This new model, named the optimizing path space, comprises all the globally best solutions. Additionally, it sets the stage for evaluating human problem-solving skills in various areas, like cognitive and neuropsychological tests, experimental studies, and puzzles, where globally optimal solutions are required.},
  archive      = {J_JOMP},
  author       = {Luca Stefanutti and Andrea Brancaccio},
  doi          = {10.1016/j.jmp.2025.102907},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102907},
  shortjournal = {J. Math. Psychol.},
  title        = {The assessment of global optimization skills in procedural knowledge space theory},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Models of human probability judgment errors. <em>JOMP</em>,
<em>125</em>, 102906. (<a
href="https://doi.org/10.1016/j.jmp.2025.102906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of cognitive science’s core challenges is reconciling the success of probabilistic models in explaining human cognition with the observed fallacies in human probability judgments. This tutorial delves into models that address this discrepancy, shedding light on probabilistic fallacies. It encompasses earlier accounts like heuristics and averaging models, as well as contemporary, comprehensive models like quantum probability, the Probability Plus Noise model, and the Bayesian Sampler. The tutorial concludes by introducing the most recent accounts that integrate probability judgments with choice and response time, and highlighting ongoing challenges in the field.},
  archive      = {J_JOMP},
  author       = {Jiaqi Huang and Jerome Busemeyer},
  doi          = {10.1016/j.jmp.2025.102906},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102906},
  shortjournal = {J. Math. Psychol.},
  title        = {Models of human probability judgment errors},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two formal notions of higher-order invariance detection in
humans (a proof of the invariance equivalence principle in generalized
invariance structure theory and ramifications for related computations).
<em>JOMP</em>, <em>125</em>, 102905. (<a
href="https://doi.org/10.1016/j.jmp.2025.102905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invariance and symmetry principles have played a fundamental if not essential role in the theoretical development of the physical and mathematical sciences. More recently, Generalized Invariance Structure Theory (GIST; Vigo, 2013, 2015; Vigo et al., 2022) has extended this methodological trajectory with respect to the study and formal modeling of human cognition. Indeed, GIST is the first systematic and extensively tested mathematical and computational theory of concept learning and categorization behavior (i.e., human generalization) based on such principles. The theory introduces an original mathematical and computational framework, with novel, more appropriate, and more natural characterizations, constructs, and measures of invariance and symmetry with respect to cognition than existing ones in the mathematical sciences and physics. These have proven effective in predicting and explaining empirically tested behavior in the domains of perception, concept learning, categorization, similarity assessment, aesthetic judgments, and decision making, among others. GIST has its roots in a precursor theory known as Categorical Invariance Theory (CIT; Vigo, 2009). This paper gives a basic introduction to two different notions of human invariance detection proposed by GIST and its precursor CIT: namely, a notion based on a cognitive mechanism of dimensional suppression, rapid attention shifting, and partial similarity assessment referred to as binding ( s -invariance) and a perturbation notion based on perturbations of the values of the dimensions on which categories of object stimuli are defined ( p -invariance). This is followed by the first simple formal proof of the invariance equivalence principle from GIST which asserts that the two notions are equivalent under a set of strict conditions on categories. The paper ends with a brief discussion of how GIST, unlike CIT, may be used to model probabilistic process accounts of categorization, and how it naturally and directly applies to the learning of sequential categories and to multiset-based concept learning.},
  archive      = {J_JOMP},
  author       = {Ronaldo Vigo},
  doi          = {10.1016/j.jmp.2025.102905},
  journal      = {Journal of Mathematical Psychology},
  month        = {5},
  pages        = {102905},
  shortjournal = {J. Math. Psychol.},
  title        = {Two formal notions of higher-order invariance detection in humans (A proof of the invariance equivalence principle in generalized invariance structure theory and ramifications for related computations)},
  volume       = {125},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jpdc---5">JPDC - 5</h2>
<ul>
<li><details>
<summary>
(2025). The (t,k)-diagnosability of cayley graph generated by
2-tree. <em>JPDC</em>, <em>200</em>, 105068. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiprocessor systems, which typically use interconnection networks (or graphs) as underlying topologies, are widely utilized for big data analysis in scientific computing due to the advancements in technologies such as cloud computing, IoT, social network. With the dramatic expansion in the scale of multiprocessor systems, the pursuit and optimization of strategies for identifying faulty processors have become crucial to ensuring the normal operation of high-performance computing systems. System-level diagnosis is a process designed to distinguish between faulty processors and fault-free processors in multiprocessor systems. The ( t , k ) -diagnosis, a generalization of sequential diagnosis, proceeds to identify at least k faulty processors and repair them in each iteration under the assumption that there are at most t faulty processors whenever t ≥ k . We show that Cayley graph generated by 2-tree is ( 2 n − 3 , 2 n − 4 ) -diagnosable under the PMC model for n ≥ 5 while it is ( 2 n − 3 ( 2 n − 6 ) 2 n − 4 , 2 n − 4 ) -diagnosable under the MM ⁎ model for n ≥ 4 . As an empirical case study, the ( t , k ) -diagnosabilities of the alternating group graph A G n under the PMC model and the MM* model have been determined.},
  archive      = {J_JPDC},
  author       = {Lulu Yang and Shuming Zhou and Eddie Cheng},
  doi          = {10.1016/j.jpdc.2025.105068},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105068},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {The (t,k)-diagnosability of cayley graph generated by 2-tree},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data quality management in big data: Strategies, tools, and
educational implications. <em>JPDC</em>, <em>200</em>, 105067. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the critical need for effective Big Data Quality Management (BDQM) in education, a field where data quality has profound implications but remains underexplored. The work systematically progresses from requirement analysis and standard development to the deployment of tools for monitoring and enhancing data quality in big data workflows. The study&#39;s contributions are substantiated through five research questions that explore the impact of data quality on analytics, the establishment of evaluation standards, centralized management strategies, improvement techniques, and education-specific BDQM adaptations. By addressing these questions, the research advances both theoretical and practical frameworks, equipping stakeholders with the tools to enhance the reliability and efficiency of data-driven educational initiatives. Integrating Artificial Intelligence (AI) and distributed computing, this research introduces a novel multi-stage BDQM framework that emphasizes data quality assessment, centralized governance, and AI-enhanced improvement techniques. This work underscores the transformative potential of robust BDQM systems in supporting informed decision-making and achieving sustainable outcomes in educational projects. The survey findings highlight the potential for automated data management within big data architectures, suggesting that data quality frameworks can be significantly enhanced by leveraging AI and distributed computing. Additionally, the survey emphasizes emerging trends in big data quality management, specifically (i) automated data cleaning and cleansing and (ii) data enrichment and augmentation.},
  archive      = {J_JPDC},
  author       = {Thu Nguyen and Hong-Tri Nguyen and Tu-Anh Nguyen-Hoang},
  doi          = {10.1016/j.jpdc.2025.105067},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105067},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Data quality management in big data: Strategies, tools, and educational implications},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMI-GPU: Inverted multi-index for billion-scale approximate
nearest neighbor search with GPUs. <em>JPDC</em>, <em>200</em>, 105066.
(<a href="https://doi.org/10.1016/j.jpdc.2025.105066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similarity search is utilized in specialized database systems designed to handle multimedia data, often represented by high-dimensional features. In this paper, we focus on speeding up the search process with GPUs. This problem has been previously approached by accelerating the Inverted File with Asymmetric Distance Computation algorithm on GPUs (IVFADC-GPU). However, the most recent algorithm for CPU, Inverted Multi-Index (IMI), was not considered for parallelization, being found too challenging for efficient GPU deployment. Thus, we propose a novel and efficient version of IMI for GPUs called IMI-GPU. We propose a new design of the multi-sequence algorithm of IMI, enabling efficient GPU execution. We compared IMI-GPU with IVFADC-GPU using a billion-scale dataset in which IMI-GPU achieved speedups of about 3.2× and 1.9× at Recall@1 and at Recall@16 respectively. The algorithms have been compared in a variety of scenarios and our novel IMI-GPU has shown to significantly outperform IVFADC on GPUs for the majority of tested cases.},
  archive      = {J_JPDC},
  author       = {Alan Araujo and Willian Barreiros Jr. and Jun Kong and Renato Ferreira and George Teodoro},
  doi          = {10.1016/j.jpdc.2025.105066},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105066},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {IMI-GPU: Inverted multi-index for billion-scale approximate nearest neighbor search with GPUs},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed landmark labeling for social networks.
<em>JPDC</em>, <em>200</em>, 105057. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance queries are a fundamental part of many network analysis applications. They can be used to infer the closeness of two users in social networks, the relation between two sites in a web graph, or the importance of the interaction between two proteins or molecules. Being able to answer these queries rapidly has many benefits in the area of network analysis. Pruned Landmark Labeling ( Pll ) is a technique used to generate an index for a given graph that allows the shortest path queries to be completed in a fraction of the time when compared to a standard breadth-first or a depth-first search-based algorithm. Parallel Shortest-distance Labeling ( Psl ) reorganizes the steps of Pll for the multithreaded setting and is designed particularly for social networks for which the index sizes can be much larger than what a single server can store. Even for a medium-size, 5 million vertex graph, the index size can be more than 40 GB. This paper proposes a hybrid, shared- and distributed-memory algorithm, DPSL, by partitioning the input graph via a vertex separator. The proposed method improves both the parallel execution time and the maximum memory consumption by distributing both the data and the work across multiple nodes of a cluster. For instance, on a graph with 5M vertices and 150M edges, using 4 nodes, DPSL reduces the execution time and maximum memory consumption by 2.13× and 1.87×, respectively, compared to our improved implementation of Psl .},
  archive      = {J_JPDC},
  author       = {Arda Şener and Hüsnü Yenigün and Kamer Kaya},
  doi          = {10.1016/j.jpdc.2025.105057},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105057},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Distributed landmark labeling for social networks},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring data science workflows: A practice-oriented
approach to teaching processing of massive datasets. <em>JPDC</em>,
<em>200</em>, 105043. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive datasets are typically processed by a sequence of different stages, comprising data acquisition and preparation, data processing, data analysis, result validation, and visualization. In conjunction, these stages form a data science workflow, a key element enabling the solution of data-intensive problems. The complexity and heterogeneity of these stages require a diverse set of techniques and skills. This article discusses a hands-on practice-oriented approach aiming to enable and motivate graduate students to engage with realistic data science workflows. A major goal of the approach is to bridge the gap between academia and industry by integrating programming assignments that implement different data workflows with real-world data. In consecutive assignments, students are exposed to the methodology of solving problems using big data frameworks and are required to implement different data workflows of varying complexity. This practice-oriented approach is well received by students, as confirmed by different surveys.},
  archive      = {J_JPDC},
  author       = {Johannes Schoder and H. Martin Bücker},
  doi          = {10.1016/j.jpdc.2025.105043},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {6},
  pages        = {105043},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Exploring data science workflows: A practice-oriented approach to teaching processing of massive datasets},
  volume       = {200},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jtb---21">JTB - 21</h2>
<ul>
<li><details>
<summary>
(2025). Developing cholera outbreak forecasting through qualitative
dynamics: Insights into malawi case study. <em>JTB</em>, <em>605</em>,
112097. (<a href="https://doi.org/10.1016/j.jtbi.2025.112097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cholera, an acute diarrheal disease, is a serious concern in developing and underdeveloped areas. A qualitative understanding of cholera epidemics aims to foresee transmission patterns based on reported data and mechanistic models. The mechanistic model is a crucial tool for capturing the dynamics of disease transmission and population spread. However, using real-time cholera cases is essential for forecasting the transmission trend. This prospective study seeks to furnish insights into transmission trends through qualitative dynamics followed by machine learning-based forecasting. The Monte Carlo Markov Chain approach is employed to calibrate the proposed mechanistic model. We identify critical parameters that illustrate the disease’s dynamics using partial rank correlation coefficient-based sensitivity analysis. The basic reproduction number as a crucial threshold measures asymptotic dynamics. Furthermore, forward bifurcation directs the stability of the infection state, and Hopf bifurcation suggests that trends in transmission may become unpredictable as societal disinfection rates rise. Further, we develop epidemic-informed machine learning models by incorporating mechanistic cholera dynamics into autoregressive integrated moving averages and autoregressive neural networks. We forecast short-term future cholera cases in Malawi by implementing the proposed epidemic-informed machine learning models to support this. We assert that integrating temporal dynamics into the machine learning models can enhance the capabilities of cholera forecasting models. The execution of this mechanism can significantly influence future trends in cholera transmission. This evolving approach can also be beneficial for policymakers to interpret and respond to potential disease systems. Moreover, our methodology is replicable and adaptable, encouraging future research on disease dynamics.},
  archive      = {J_JTB},
  author       = {Adrita Ghosh and Parthasakha Das and Tanujit Chakraborty and Pritha Das and Dibakar Ghosh},
  doi          = {10.1016/j.jtbi.2025.112097},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112097},
  shortjournal = {J. Theor. Biol},
  title        = {Developing cholera outbreak forecasting through qualitative dynamics: Insights into malawi case study},
  volume       = {605},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An optimal network that promotes the spread of an
advantageous variant in an SIR epidemic. <em>JTB</em>, <em>605</em>,
112095. (<a href="https://doi.org/10.1016/j.jtbi.2025.112095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the course of epidemics, the pathogen may mutate to acquire a higher fitness. At the same time, such a mutant is automatically in an unfavorable position because the resident virus has a head start in accessing the pool of susceptible individuals. We considered a class of tunable small-world networks, where a parameter, p (the rewiring probability), characterizes the prevalence of non-local connections, and we asked, whether the underlying network can influence the fate of a mutant virus. Under an SIR model, we considered two measures of mutant success: the expected height of the peak of mutant infected individuals, and the total number of recovered from mutant individuals at the end of the epidemic. Using these measures, we have found the existence of an optimal (for an advantageous mutant virus) rewiring probability that promotes a larger infected maximum and a larger total recovered population corresponding to the advantageous pathogen strain. This optimal rewiring probability decreases as mean degree and the infectivity of the wild type are increased, and it increases with the mutant advantage. The non-monotonic behavior of the advantageous mutant as a function of rewiring probability may shed light into some of the complex patterns in the size of mutant peaks experienced by different countries during the COVID-19 pandemic.},
  archive      = {J_JTB},
  author       = {Samuel Lopez and Natalia L. Komarova},
  doi          = {10.1016/j.jtbi.2025.112095},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112095},
  shortjournal = {J. Theor. Biol},
  title        = {An optimal network that promotes the spread of an advantageous variant in an SIR epidemic},
  volume       = {605},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The spatial aggregation of phytophagous insects driven by
the evolution of preference for plant chemicals. <em>JTB</em>,
<em>605</em>, 112094. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ecologists have shown considerable interest in the spatial patterns of organism distribution and the processes responsible for their formation and maintenance. The phytophagous insects typically use chemicals in plants as host-finding cues. Because nonvolatile chemicals remain near the source, the spatial structure of plant community determines the local distribution of insects. In addition, the plant chemical accumulation due to plant–plant interaction also influences the distribution of insects. In Rumex obtusifolius , for example, the production of phenolics is mediated by conspecific interaction. Rumex plants with high phenolic concentrations are preferred by the leaf beetle Gastrophysa atrocyanea , resulting in its spatial aggregation. Although this preference of beetles for nonvolatile chemicals should be beneficial in finding host plants, there is also a cost in terms of intraspecific competition among the beetles due to aggregation on certain chemical-rich hosts. To investigate the evolutionary significance of preference for nonvolatile chemicals and the ecological consequence of spatial distribution in leaf beetles, we constructed a mathematical model for the joint evolution of two preferences for plant size and chemical condition. In the model, beetles choose a resource based on the size and chemical concentrations of plants and are exposed to resource competition. Host plants accumulate the chemicals when they interact with neighboring conspecifics, and hence the level of chemical accumulation varies depending on the species composition and spatial distribution of the plant community. As a result, beetles became more sensitive to chemicals when the host species was rare and sparsely distributed in the community. The evolution of high chemical preference caused the aggregation of beetles and hence population size declined. We proposed a potential mechanism that underlies aggregated distribution in phytophagous insects, driven by the evolution of chemical preferences in response to plant community structure.},
  archive      = {J_JTB},
  author       = {Haruna Ohsaki and Akira Yamawo and Yuuya Tachiki},
  doi          = {10.1016/j.jtbi.2025.112094},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112094},
  shortjournal = {J. Theor. Biol},
  title        = {The spatial aggregation of phytophagous insects driven by the evolution of preference for plant chemicals},
  volume       = {605},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Branching architecture affects genetic diversity within an
individual tree. <em>JTB</em>, <em>605</em>, 112093. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While a tree grows over many years, somatic mutations accumulate and form genetic variation among branches within an individual. Trees can transmit such mutations to subsequent generations, potentially enhancing the genetic diversity of the population. We study a mathematical model to understand the relationship between within-individual genetic variation and branching architecture. We generate branching architecture by repeatedly adding two new branches (main and lateral daughter branches) to each terminal branch (mother branch). The architecture is characterized by two key parameters: main-lateral ratio (ML) and daughter-mother ratio (DM). During branch elongation, somatic mutations accumulate in the stem cells of a shoot apical meristem (SAM) at the tip of each branch. In branching, all the stem cells are passed on from the mother to the main daughter branch, but only one stem cell is chosen for the lateral daughter branch. We evaluate genetic variation by Z ¯ , the mean genetic differences between all pairs of branches of a tree, and examine how Z ¯ varies with DM and ML while keeping the total branch length constant. As a result, (1) Z ¯ increases monotonically with ML; (2) Z ¯ attains the maximum for an intermediate DM, when stem cells in a SAM are genetically homogeneous; (3) Z ¯ decreases monotonically with DM when stem cells are heterogeneous. The effect of branching architecture varies significantly depending on the genetic heterogeneity within a SAM, which results from the behavior of stem cells during growth. Our study sheds light on the overlooked role of branching architecture in storing genetic diversity.},
  archive      = {J_JTB},
  author       = {Sou Tomimoto and Yoh Iwasa and Akiko Satake},
  doi          = {10.1016/j.jtbi.2025.112093},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112093},
  shortjournal = {J. Theor. Biol},
  title        = {Branching architecture affects genetic diversity within an individual tree},
  volume       = {605},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergence of food webs with a multi-trophic hierarchical
structure driven by nonlinear trait-matching. <em>JTB</em>,
<em>605</em>, 112091. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Food webs are a central subject in community ecology, because consumption supports the flow of matter through the system, which is at the base of many of its functions. Identifying the mechanisms that are at the origin of food web structure is useful, e.g., for restoration purposes. We investigated the extent to which trait-matching, which contributes to defining the strength of trophic interactions, can cause the emergence of food webs with a non-trivial, multi-trophic, hierarchical structure. We compared for that purpose the structural properties of food webs simulated by four food web model variants, depending whether trait-matching was linear or nonlinear and whether population dynamics and evolution were accounted for (dynamical model) or not (static model). Nonlinear trait-matching can restrict interactions in phenotypic space so as to obtain localized interactions (i.e., each species interact with a small subset of species), which is a key element for food web formation. In the static case, nonlinear trait-matching allowed for the emergence of food webs, at a relatively low connectance as with random graphs. In the dynamical case, nonlinear trait-matching combined with population dynamics and evolution allowed for the formation of groups of phenotypically close species, resulting in food webs with a multi-trophic, hierarchical structure.},
  archive      = {J_JTB},
  author       = {Christophe Laplanche and Benjamin Pey and Robin Aguilée},
  doi          = {10.1016/j.jtbi.2025.112091},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112091},
  shortjournal = {J. Theor. Biol},
  title        = {Emergence of food webs with a multi-trophic hierarchical structure driven by nonlinear trait-matching},
  volume       = {605},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditions for the establishment of creole languages from an
evolutionary game theoretic perspective. <em>JTB</em>, <em>605</em>,
112090. (<a href="https://doi.org/10.1016/j.jtbi.2025.112090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language contact refers to a situation in which speakers of different languages meet and interact. There are three consequences of language contact. The first one is language shift, where one language is replaced by another. The second one is language maintenance, where languages coexist without any language change. The question of how language shift takes place and under what conditions coexistence of languages is possible has drawn wide attention of linguists as well as of theoretical researchers in other disciplines. Most of the previous mathematical studies of language dynamics have shown that there is majority advantage in the competition and that the population eventually becomes dominated by a single language that was spoken by a majority when the competition started. However, it is known that the contact of different languages could lead to the third consequence: the emergence of a new language, such as creole languages. Our study aims to model the spread of creole languages by using evolutionary game theory and determine the factors that drive the spread of creoles in the population. We consider an evolutionary game with individuals who speak either one of two ancestral languages or the creole that resulted from language contact between those two ancestral languages. Due to the formation process of creole, the creole speakers can communicate with speakers of other languages to some, but not full, extent. We assume that their frequencies change according to their payoffs that reflect how well they can communicate with others. Under this basic assumption, we varied (i) the population size and (ii) the difficulty of language change, to see their effects on the spread of the creole. Results show that the creole is more likely to spread if the population size is small enough for random drift to work well and/or if two ancestral languages are linguistically distant. We also find that finiteness of the population can either favor or disfavor the spread of creole depending on detailed conditions. Our results suggest that the contact between two distant languages and random drift drive the spread of creoles. It is known that many creole languages appeared in plantations where European owners brought labor forces from Africa as slaves. Our results match the homestead phase of these plantations, where European languages are distant from African ones, and where the population size was small.},
  archive      = {J_JTB},
  author       = {Raiki Nakano and Hisashi Ohtsuki},
  doi          = {10.1016/j.jtbi.2025.112090},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112090},
  shortjournal = {J. Theor. Biol},
  title        = {Conditions for the establishment of creole languages from an evolutionary game theoretic perspective},
  volume       = {605},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Many-strategy games in groups with relatives and the
evolution of coordinated cooperation. <em>JTB</em>, <em>605</em>,
112089. (<a href="https://doi.org/10.1016/j.jtbi.2025.112089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans often cooperate in groups with friends and family members with varying degrees of genetic relatedness. Past kin selection can also be relevant to interactions between strangers, explaining how the cooperation first arose in the ancestral population. However, modelling the effects of relatedness is difficult when the benefits of cooperation scale nonlinearly with the number of cooperators (e.g., economies of scale). Here, we present a direct fitness method for rigorously accounting for kin selection in n -player interactions with m discrete strategies, where a genetically homophilic group-formation model is used to calculate the necessary higher-order relatedness coefficients. Our approach allows us to properly account for non-additive fitness effects between relatives (synergy). Analytical expressions for dynamics are obtained, and they can be solved numerically for modestly sized groups and numbers of strategies. We illustrate with an example where group members can verbally agree (cheap talk) to contribute to a public good with a sigmoidal benefit function, and we find that such coordinated cooperation is favoured by kin selection. As interactions switched from family to strangers, in order for coordinated cooperation to persist and for the population to resist invasion by liars, either some level of homophily must be maintained or following through on the agreement must be in the self-interests of contributors. Our approach is useful for scenarios where fitness effects are non-additive and the strategies are best modelled in a discrete way, such as behaviours that require a cognitive ‘leap’ of insight into the situation (e.g., shared intentionality, punishment).},
  archive      = {J_JTB},
  author       = {Nadiah P. Kristensen and Ryan A. Chisholm and Hisashi Ohtsuki},
  doi          = {10.1016/j.jtbi.2025.112089},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112089},
  shortjournal = {J. Theor. Biol},
  title        = {Many-strategy games in groups with relatives and the evolution of coordinated cooperation},
  volume       = {605},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model of tubulin removal and exchange caused by kinesin
motor walking on microtubule lattices. <em>JTB</em>, <em>605</em>,
112088. (<a href="https://doi.org/10.1016/j.jtbi.2025.112088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The kinesin motor walking on microtubule lattices can cause disassembly of GDP-tubulins, generating defects, and repair the defects by incorporating GTP-tubulins. To explore the underlying mechanism, a model is proposed here. On the basis of the model, the dynamics of the defect generation, defect repair and tubulin exchange induced by the kinesin motor is studied theoretically. The theoretical results explain well the available experimental data. Moreover, predicted results are provided.},
  archive      = {J_JTB},
  author       = {Ping Xie},
  doi          = {10.1016/j.jtbi.2025.112088},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112088},
  shortjournal = {J. Theor. Biol},
  title        = {A model of tubulin removal and exchange caused by kinesin motor walking on microtubule lattices},
  volume       = {605},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The short comment on the individual response to ionizing
radiation. <em>JTB</em>, <em>604</em>, 112092. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JTB},
  author       = {Krzysztof Wojciech Fornalski},
  doi          = {10.1016/j.jtbi.2025.112092},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112092},
  shortjournal = {J. Theor. Biol},
  title        = {The short comment on the individual response to ionizing radiation},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effects of trade-off shape and dimensionality on
eco-evolutionary dynamics in resource competition. <em>JTB</em>,
<em>604</em>, 112087. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organisms invariably experience trade-offs in their capacities for interacting with their environments. In resource competition, this often means that an organism’s ability to acquire one resource can only come at the cost of less ability with others. If the traits governing resource acquisition are under selection and heritable, this will induce eco-evolutionary dynamics along the trade-off. For Lotka–Volterra models derived from MacArthur resource competition models and for explicit resource models with two resources, the shape and dimensionality of trade-offs has seen substantial study. However, how the joint effects of trade-off shapes and the number of resources under competition affect eco-evolutionary outcomes has seen relatively little. For example, is diversification through evolutionary branching more or less likely when the number of resources increases? Here, we will present techniques complementary to existing ones for recasting trade-offs in an implicit form. Combining adaptive dynamics and resource-competition theory, we derive expressions for directional and stabilizing/disruptive selection. We apply our techniques to two models of resource competition and investigate how the number of resources and trade-off shapes affect the stability characteristics of the generalist strategy, and how diverse a community of consumers can be assembled through successive evolutionary branching. We find that even for these simple and highly symmetric models, outcomes are surprisingly complex and idiosyncratic. Taken together, our results deepen our understanding of the eco-evolutionary dynamics of resource competition for multiple resources.},
  archive      = {J_JTB},
  author       = {Jonas Wickman and Christopher A. Klausmeier},
  doi          = {10.1016/j.jtbi.2025.112087},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112087},
  shortjournal = {J. Theor. Biol},
  title        = {The effects of trade-off shape and dimensionality on eco-evolutionary dynamics in resource competition},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Absorbing markov chain model of PrEP drug adherence to
estimate adherence decay rate and probability distribution in clinical
trials. <em>JTB</em>, <em>604</em>, 112086. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-exposure prophylaxis (PrEP) is increasingly used to prevent the transmission of H.I.V. in at-risk populations. However, PrEP users may discontinue use of the medicine due to side effects, lower perceived risk, or other reasons. The usage metrics of 594 individuals was tracked over 350 days using the Wisepill electronic monitoring system. We model the PrEP drug adherence level using an absorbing Markov chain with a unique absorbing state. The transition matrix T obtained from the Wisepill data will have a trivial eigenvector (eigendistribution) associated with the first (i.e., largest) eigenvalue 1. The 2nd eigenvalue(s) then become important in determining the asymptotic behavior of the Markov chain, dictating how fast the Markov chain decays to the absorbing state. Under a fairly general assumption, we prove that the second positive eigenvalue is unique and the corresponding eigenvector will have nonnegative entries with exceptions at absorbing states. In addition, we define the asymptotic half life of the absorbing Markov chain directly from the 2nd eigenvalue. We then determine the 2nd eigenvalue of T and the asymptotic half life of the Markov chain, which turns out to be very close to the real half life of the Markov chain. Finally, we interpret the 2nd eigenvector as the relative probability distribution of X ∞ with respect to the decay rate of the 2nd eigenvalue. By applying these methods to the Wisepill data, we estimate the half-life of population adherence to be 46 weeks. The bi-weekly decay rate observed in these data from 90 to 100 % adherence is 3 %. This work produces an estimate at which adherence falls over time, given no external intervention is applied. These results suggest an eigenvector-based approach to estimate adherence trends, as well as the timing of interventions to improve adherence.},
  archive      = {J_JTB},
  author       = {Renee Dale and Hongyu He and Yingqing Chen},
  doi          = {10.1016/j.jtbi.2025.112086},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112086},
  shortjournal = {J. Theor. Biol},
  title        = {Absorbing markov chain model of PrEP drug adherence to estimate adherence decay rate and probability distribution in clinical trials},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometrically balanced model of cell growth. <em>JTB</em>,
<em>604</em>, 112085. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proteome balance constraint in metabolic flux balance analysis asserts that the proteome is constructed by ribosomes, which themselves contain many proteins. This leads to a fundamental question of optimal allocation of limited proteome among different pools of enzymes, which include ribosomes themselves. However, recent work points to additional constraints imposed by the cell geometry. In this paper we deduce the proteogeometric constraint π ¯ A = π A + θ π L / π P , where π A , π P and π L are the proteomic fractions allocated to the cell surface area, protein synthesis and cell membrane phospholipids synthesis and π ¯ A and θ are constants imposed by geometry of the cell. We illustrate the relevance of this constraint using a reduced model of cell metabolism, illuminating the interplay between cell metabolism and cell geometry.},
  archive      = {J_JTB},
  author       = {Alexei Vazquez and Tomáš Gedeon},
  doi          = {10.1016/j.jtbi.2025.112085},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112085},
  shortjournal = {J. Theor. Biol},
  title        = {Geometrically balanced model of cell growth},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incorporating adult age into mosquito population models:
Implications for predicting abundances in changing climates.
<em>JTB</em>, <em>604</em>, 112084. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mosquito-borne diseases (MBDs) pose increasing threats under future climate change scenarios and an understanding of mosquito population dynamics is pivotal to predicting future risk of MBDs. Most models that describe mosquito population dynamics often assume that adult life-history is independent of adult age and yet mosquito senescence is known to affect mosquito mortality, fecundity and other key biological traits. Despite this, little is known about the effects of adult age at the level of the mosquito population, especially under varying temperature scenarios. We develop a stage-structured delayed differential equations (DDEs) model incorporating the effects of the abiotic environment and adult age to shed light on the complex interactions between age, temperature, and mosquito population dynamics. Taking Culex pipiens , a major vector of West Nile Virus, as our study species our results show that failing to consider mosquito senescence can lead to underestimates of future mosquito abundances predicted under climate change scenarios. We also find that the age-dependent mechanisms combined with the effects of density-dependent mortality on the immature stages can result in mosquito abundances decreasing at extreme temperatures. With our work, we underscore the need for more studies to consider the effects of mosquito age. Not accounting for senescence can compromise the accuracy of abundance estimates and has implications for predicting the risk of future MBD outbreaks.},
  archive      = {J_JTB},
  author       = {Renato Andrade and Steven M. White and Christina A. Cobbold},
  doi          = {10.1016/j.jtbi.2025.112084},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112084},
  shortjournal = {J. Theor. Biol},
  title        = {Incorporating adult age into mosquito population models: Implications for predicting abundances in changing climates},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the regulation of chronic wounds by tissue
inhibitors of matrix metalloproteinases through mathematical modelling.
<em>JTB</em>, <em>604</em>, 112083. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the biochemistry and pharmacodynamics of chronic wounds is of key importance, due to the millions of people in the UK affected and the significant cost to the NHS. Chronic wounds are characterised by elevated concentrations of matrix metalloproteinases (MMPs) that destroy the surrounding extracellular matrix (ECM). However, fibroblasts can produce tissue inhibitors of MMPs (TIMPs) in order to regulate wound healing. Therefore, the role of TIMPs in both acute and chronic wounds needs to be properly understood in order to develop therapeutic treatments. In this work, we propose a reaction-diffusion system of four partial differential equations that describe the interaction of the ECM, fibroblasts, MMPs, and TIMPs in a wound. We observe that, subject to parameter sets corresponding to both acute and chronic wound healing, this mathematical model gives rise to travelling wave solutions. Using bifurcation analysis, we demonstrate that excessive degradation of the ECM results in the emergence of chronic wounds, and the reversal of these chronic wounds is prohibited for lower TIMP production values. These results are replicated within a simplified model obtained via a parameter sensitivity analysis. This model is further extended to more realistic spatial domains where we demonstrate the effectiveness of a therapeutic hydrogel containing TIMPs as a treatment for chronic wounds.},
  archive      = {J_JTB},
  author       = {Sonia Dari and Reuben D. O’dea and Nabil T. Fadai},
  doi          = {10.1016/j.jtbi.2025.112083},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112083},
  shortjournal = {J. Theor. Biol},
  title        = {Understanding the regulation of chronic wounds by tissue inhibitors of matrix metalloproteinases through mathematical modelling},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kir4.1 channel and voltage-gated calcium channel of
astrocyte account for the transition dynamics of seizures. <em>JTB</em>,
<em>604</em>, 112082. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Astrocytes have an important role in the indirect regulation of neuronal excitability. The abnormalities of their ion channels cause neurons to discharge abnormally, which may induce seizures. The inwardly rectifying potassium channel 4.1 (Kir4.1 channel) and the voltage-gated calcium channel (VGCC) of an astrocyte play important roles in maintaining the homeostasis of these potassium and calcium ions, and have been found to be associated with seizures. However, the underlying mechanisms by which they induce seizures remain unclear. This paper established a neuron-astrocyte network model, which is a model consisting of a neuron and an astrocyte, to explore some mechanisms of epileptic seizures. Through a series of simulations based on this model, the results showed that low conductance of Kir4.1 channel can induce spontaneous periodic epileptic activity (SPEA) whereas higher conductance results in spontaneous periodic bursting event (SPBE) and high-frequency tonic discharges (HFTD). The abnormalities of VGCC also lead to the generation of SPEA and SPBE. As the changes of potassium concentration in the largest nearby reservoir which is analogous to a bath solution that contains a specific concentration of potassium, SPEA can undergo a process from appearance to disappearance. Thus, the research findings showed that the transitions of seizure-like discharges provide further theoretical analyses to clarify the complex mechanism of seizures.},
  archive      = {J_JTB},
  author       = {Yu Rui and Shu Liu and Suyu Liu},
  doi          = {10.1016/j.jtbi.2025.112082},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112082},
  shortjournal = {J. Theor. Biol},
  title        = {Kir4.1 channel and voltage-gated calcium channel of astrocyte account for the transition dynamics of seizures},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PD-based ADRC using time-varying gains: An application to
microalgal-based bioprocess. <em>JTB</em>, <em>604</em>, 112074. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microalgae cultivation has gained significant attention in recent years due to its potential applications in various fields. However, achieving high productivity in these bioprocesses requires efficient process control. The dynamics of growth models typically comprise both known and unknown components due to mismatches between the nonlinear dynamics and their mathematical representations. Additionally, microalgal culture is subject to external disturbances. To address these issues, a classical proportional-derivative (PD) providing the feedback error, assisted by a time-varying gain extended state observer (ESO), maintaining the structure of an Active Disturbance Rejection Control (ADRC), was implemented. The formulation is aided by a time-varying gain extended state observer to avoid high-peaking estimation values. The optimal operating conditions were identified using the GEKKO Python package. The proposed controller was applied to the growth model of the microalga Isochrysis galbana , and numerical results demonstrated the effectiveness of the control strategy in eliminating steady-state error and ensuring asymptotic convergence to the optimal equilibrium despite unknown disturbances. A detailed analysis of the photobioreactor model, including stability under steady-state conditions, was also conducted. The results indicated that the model exhibits one, two, or no stable steady-state solutions when the dilution rate ( D ( t ) ) is manipulated.},
  archive      = {J_JTB},
  author       = {Viyils Sangregorio-Soto and Edgar Yesid Mayorga Lancheros and Gianfranco Mazzanti and Claudia L. Garzón-Castro},
  doi          = {10.1016/j.jtbi.2025.112074},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112074},
  shortjournal = {J. Theor. Biol},
  title        = {PD-based ADRC using time-varying gains: An application to microalgal-based bioprocess},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Co-evolution of pathogen–host interactions with vertical
transmission can produce bistable outcomes. <em>JTB</em>, <em>604</em>,
112073. (<a href="https://doi.org/10.1016/j.jtbi.2025.112073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vertical transmission is widely predicted to select for reduced virulence of pathogens. Recent theory cast doubt on this prediction by showing that the evolutionary response of the host to vertical transmission can lead to severe disease outcomes. That theory, however, takes a simplified view of host population dynamics by assuming pathogen-induced mortality alone inhibits host population growth. The assumption limits our ability to uncover benign co-evolutionary outcomes characterized by low levels of pathogen-induced mortality. Here, we revisit the role of vertical transmission using a model that assumes host population growth is self-regulated. Our model tracks the co-evolution of pathogen-induced mortality and host recovery until both have reached an evolutionarily stable level. For any given set of model conditions, we could identify as many as two distinct pairs of stable mortality-recovery traits. Mortality and recovery were higher for one of the pairs (the ‘escalated’ one) and lower for the other of the pairs (the ‘de-escalated’ one). As the rate of vertical transmission rose, stable expression of the pathogen-induced mortality trait always decreased, while stable expression of the host-recovery trait increased for ‘escalated’ pairs and decreased for ‘de-escalated’ ones. In addition, (i) increasing the intrinsic rate of host population growth, (ii) increasing the cost of host recovery, and (iii) decreasing the efficiency of horizontal disease transmission all led to lower levels of stable trait expression for both pathogen and host. Factors (i)-(iii) also led to lower virulence, more frequent occurrence of the de-escalated (almost commensal) stable outcome, and greater disease prevalence. We conclude that (i)-(iii) promote the co-evolution of more benign interactions in keeping with previous findings. However, our new insight is that the benign nature of the host-pathogen interaction can now be understood as the more frequent occurrence of the de-escalated outcome. We discuss our findings in light of previous theory and experimental work.},
  archive      = {J_JTB},
  author       = {Samantha Brotman and Geoff Wild},
  doi          = {10.1016/j.jtbi.2025.112073},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112073},
  shortjournal = {J. Theor. Biol},
  title        = {Co-evolution of pathogen–host interactions with vertical transmission can produce bistable outcomes},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal social distancing in pandemic preparedness and
lessons from COVID-19: Intervention intensity and infective travelers.
<em>JTB</em>, <em>604</em>, 112072. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our analysis seeks best social distancing strategies optimally balancing the direct costs of a threatening outbreak with its societal-level costs by investigating the effects of different levels of restrictions’ intensity and of the continued importation of infective travellers, while controlling for the key dimensions of the response, such as early action, adherence and the relative weight of societal costs. We identify two primary degrees of freedom in epidemic control, namely the maximum intensity of control measures and their duration. In the absence of travellers, a lower (higher) maximum intensity requires a longer (shorter) duration to achieve similar control outcomes. However, uncontrollable external factors, like the importation of undetected infectives, significantly constrain these degrees of freedom so that the optimal strategy results to be one with low/moderate intensity but prolonged in time. These findings underscore the necessity for resilient health systems and coordinated global responses in preparedness plans.},
  archive      = {J_JTB},
  author       = {Alberto Landi and Giulio Pisaneschi and Marco Laurino and Piero Manfredi},
  doi          = {10.1016/j.jtbi.2025.112072},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112072},
  shortjournal = {J. Theor. Biol},
  title        = {Optimal social distancing in pandemic preparedness and lessons from COVID-19: Intervention intensity and infective travelers},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An in-depth study of the dynamics of thornley’s mathematical
model in plant biology with a view to an improved model. <em>JTB</em>,
<em>604</em>, 112071. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plants are essential for life on Earth, serving as a major source of food supply and contributing to the planet’s carbon balance. Mathematical modelling is an important mechanism for predicting and optimising plant growth in agriculture, and Thornley’s mathematical model (Thornley, 1997) is one of the most widely used models describing carbon and nitrogen allocation in plants. However, a formal mathematical analysis of the model’s behaviour has not been performed. Our analysis of the model provides new insights into how and why the model can be inappropriate. By varying the values of some model parameters, we identify non-physical and even quite chaotic behaviour. In response, we modify Thornley’s model by including additional litter terms, resulting in the elimination of these non-physical behaviours.},
  archive      = {J_JTB},
  author       = {Ati Rostami and Brodie A.J. Lawson and Kevin Burrage},
  doi          = {10.1016/j.jtbi.2025.112071},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112071},
  shortjournal = {J. Theor. Biol},
  title        = {An in-depth study of the dynamics of thornley’s mathematical model in plant biology with a view to an improved model},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cell position-based evaluation of mechanical features of
cells in multicellular systems. <em>JTB</em>, <em>604</em>, 112070. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measurement of mechanical forces of cell–cell interactions is important for studying the emergence of diverse three-dimensional morphologies of multicellular organisms. We previously reported an image-based statistical method for inferring effective pairwise forces of cell–cell interactions (i.e., attractive/repulsive forces), where a cell particle model was fitted to cell tracking data acquired by live imaging. However, because the particle model is a coarse-grained model, it remains unclear how the pairwise forces relates to sub-cellular mechanical components including cell–cell adhesive forces. Here we applied our inference method to cell tracking data generated by vertex models that assumed sub-cellular components. Through this approach, we investigated the relationship between the effective pairwise forces and various sub-cellular components: cell–cell adhesion forces, cell surface tensions, cell–extracellular matrix (ECM) adhesion, traction forces between cells and ECM, cell growth, etc. We found that the cell–cell adhesion forces were attractive, and both the cell surface tensions and cell–ECM adhesive forces were repulsive, etc. These results indicate that sub-cellular mechanical components can contribute to the effective attractive/repulsive forces of cell–cell interactions. This comprehensive analysis provides theoretical bases for linking the pairwise forces to the sub-cellular mechanical components: this showcase is useful for speculating the sub-cellular mechanical components from the information of cell positions, and for interpreting simulation results based on particle models.},
  archive      = {J_JTB},
  author       = {Hiroshi Koyama and Atsushi M. Ito and Hisashi Okumura and Tetsuhisa Otani and Kazuyuki Nakamura and Toshihiko Fujimori},
  doi          = {10.1016/j.jtbi.2025.112070},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112070},
  shortjournal = {J. Theor. Biol},
  title        = {Cell position-based evaluation of mechanical features of cells in multicellular systems},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tradeoffs in the energetic value of neuromodulation in a
closed-loop neuromechanical system. <em>JTB</em>, <em>604</em>, 112050.
(<a href="https://doi.org/10.1016/j.jtbi.2025.112050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rhythmic motor behaviors controlled by neuromechanical systems, consisting of central neural circuitry, biomechanics, and sensory feedback, show efficiency in energy expenditure. The biomechanical elements (e.g., muscles) are modulated by peripheral neuromodulation which may improve their strength and speed properties. However, there are relatively few studies on neuromodulatory control of muscle function and metabolic mechanical efficiency in neuromechanical systems. To investigate the role of neuromodulation on the system’s mechanical efficiency, we consider a neuromuscular model of motor patterns for feeding in the marine mollusk Aplysia californica . By incorporating muscle energetics and neuromodulatory effects into the model, we demonstrate tradeoffs in the energy efficiency of Aplysia ’s rhythmic swallowing behavior as a function of the level of neuromodulation. A robust efficiency optimum arises from an intermediate level of neuromodulation, and excessive neuromodulation may be inefficient and disadvantageous to an animal’s metabolism. This optimum emerges from physiological constraints imposed upon serotonergic modulation trajectories on the energy efficiency landscape. Our results may lead to experimentally testable hypotheses of the role of neuromodulation in rhythmic motor control.},
  archive      = {J_JTB},
  author       = {Zhuojun Yu and Yangyang Wang and Peter J. Thomas and Hillel J. Chiel},
  doi          = {10.1016/j.jtbi.2025.112050},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112050},
  shortjournal = {J. Theor. Biol},
  title        = {Tradeoffs in the energetic value of neuromodulation in a closed-loop neuromechanical system},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="matdes---57">MATDES - 57</h2>
<ul>
<li><details>
<summary>
(2025). Understanding the effect of annealing temperature on
hot-rolled pure mo sheet: Investigations from texture, deformation
behavior, and mechanical properties. <em>MATDES</em>, <em>253</em>,
113889. (<a href="https://doi.org/10.1016/j.matdes.2025.113889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the effects of annealing temperature on the microstructural evolution, texture development, deformation behavior, and mechanical properties of hot-rolled pure Molybdenum (Mo) sheets. A comprehensive analysis was conducted through the combination of experimental techniques and molecular dynamics (MD) simulations to examine specimens annealed at temperatures ranging from 1000 K to 1600 K. The microstructural characterization revealed a progressive transformation from elongated grains to more equiaxed structures with increasing annealing temperature. The electron backscatter diffraction (EBSD) analysis demonstrated significant texture evolution, with the &lt; 100&gt;//ND and &lt; 110&gt;//RD fiber texture showing remarkable temperature dependence. The MD simulations provided atomic-level insights into the orientation-dependent deformation mechanisms and dislocation evolution. Annealing at 1300 K optimized the mechanical properties, achieving a desirable synergy between strength (900 MPa) and ductility (22 %). This study provides valuable insights into the processing-structure–property relationships in hot-rolled Mo sheets, offering guidance for tailoring their properties for nuclear reactor applications.},
  archive      = {J_MATDES},
  author       = {Wenbin Liu and Yanchao Li and Wen Zhang and Xuanqiao Gao and Baojian Wang and Xin Zhang and Yichao Yang and Xiaohui Lin and Jianfeng Li and Hailong Xu},
  doi          = {10.1016/j.matdes.2025.113889},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113889},
  shortjournal = {Mater. Des.},
  title        = {Understanding the effect of annealing temperature on hot-rolled pure mo sheet: Investigations from texture, deformation behavior, and mechanical properties},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Experimental and mechanistic investigation of the residual
stress in SiCP/al composites at the multi scale. <em>MATDES</em>,
<em>253</em>, 113888. (<a
href="https://doi.org/10.1016/j.matdes.2025.113888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Silicon carbide particle-reinforced aluminum matrix composites (SiC P /Al) represent a novel structural material. The performance differences between the SiC particles and the Al matrix result in a non-uniform distribution of residual stresses within the composite, which significantly affecting its mechanical properties. This study characterizes the residual stress distribution patterns within the SiC particles at the micron-scale using micro-Raman spectroscopy and transmission electron microscopy (TEM). It also analyzes the fracture behavior of these particles, considering the influence of residual stresses, through a combination of geometric phase analysis (GPA) and the Yoffe model. The interior of SiC particle experiences residual tensile stress, whereas the interface region is under compressive stress. Additionally, irregular SiC particle shapes contribute to fluctuations in residual stress. The fracture behavior is primarily influenced by a combination of factors, including residual stresses arising from thermal mismatch and externally induced loads. TEM observations confirm the presence of Mg-Si IMC at the interface of the composite material. These compounds form a coherent interface with both the Al matrix and SiC phase enhancing interfacial properties. A high dislocation density in the microstrain regions adjacent to the coherent interface is identified as the main contributor to residual stress at the interface of composite material.},
  archive      = {J_MATDES},
  author       = {Jiaqi Li and Weiguang Zhang and Xueping Zhao and Fengchao Lang and Yongming Xing},
  doi          = {10.1016/j.matdes.2025.113888},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113888},
  shortjournal = {Mater. Des.},
  title        = {Experimental and mechanistic investigation of the residual stress in SiCP/Al composites at the multi scale},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Experimental investigation of cavitation erosion-induced
surface damage and particle shedding from PTFE. <em>MATDES</em>,
<em>253</em>, 113886. (<a
href="https://doi.org/10.1016/j.matdes.2025.113886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under ultra-clean operating conditions, cavitation, combined with shear forces and fluctuating pressures, can cause surface damage and generate wear particles. Polytetrafluoroethylene (PTFE), widely used in ultra-clean flow control due to its excellent corrosion resistance, is also susceptible to erosion under cavitation. This study investigates cavitation-induced erosion of PTFE using an ultrasonic cavitation test bench. A comprehensive characterization and analysis of the eroded surfaces and released particles were performed. Results revealed that PTFE particles exhibit two distinct morphologies—brittle and ductile—on the micrometer scale, corresponding to cavitation sites. Moreover, cavitation was found to decrease PTFE crystallinity, with evidence suggesting that particle release may be accompanied by chemical reactions. These findings provide valuable insights into PTFE behavior under cavitation conditions.},
  archive      = {J_MATDES},
  author       = {Rui Su and Yiming Liu and Liang Hu and Yingnan Shen and Jing Wang and Xiaodong Ruan and Xin Fu},
  doi          = {10.1016/j.matdes.2025.113886},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113886},
  shortjournal = {Mater. Des.},
  title        = {Experimental investigation of cavitation erosion-induced surface damage and particle shedding from PTFE},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural optimized mechanical metamaterial for multi
transient high-g impact suppression and self-monitoring.
<em>MATDES</em>, <em>253</em>, 113884. (<a
href="https://doi.org/10.1016/j.matdes.2025.113884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For extreme high-g mechanical impact of vehicle personnel and penetrating munition fuze, specific protections in terms of simultaneous high energy absorption performance, high recoverability and real-time alarming are urgent demands. Currently, Bistable symmetric curved beam structure (BCBS) mechanical metamaterial is promising route that can balance energy absorption performance and recoverability, but still remain the threat of excessive negative stiffness. Here, beyond BCBS metamaterial, we propose a novel mechanical metamaterial of elliptical sandwich curved beam structure (ESCBS), which utilize the stiffness complementarity of elliptical rings and curved beams. Besides, the ESCBS metamaterial has a self-filtering effect on the violently destructive high-frequency components of mechanical impacts due to its low natural frequency. Thus, the ESCBS metamaterial enhances the energy absorption performance (above 50 % decrease in impact peak) and recoverability(above 90 % structural integrity) under extreme strong mechanical impacts (up to 25000 g ). Further, to realize self-monitoring and alarming, an endogenous triboelectric self-powered sensor is constituted inside the ESCBS metamaterial via polyurethane foam penetration without any space or energy cost. Thus, the proposed ESCBS metamaterial can serve as a representative metamaterial for safe and intelligent vehicle personnel helmets and fuze systems, and is expected to have a broad commercial application in future.},
  archive      = {J_MATDES},
  author       = {Kejia Zhang and Benqiang Yang and Zhisen Zhu and Juteng Fu and Xiangyu Han and Wenling Zhang and Keren Dai},
  doi          = {10.1016/j.matdes.2025.113884},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113884},
  shortjournal = {Mater. Des.},
  title        = {Structural optimized mechanical metamaterial for multi transient high-g impact suppression and self-monitoring},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Silver nanoparticle-assembled guided bone regeneration
membranes showcase dual functions: Initial bacterial elimination and
subsequent immune regulation. <em>MATDES</em>, <em>253</em>, 113882. (<a
href="https://doi.org/10.1016/j.matdes.2025.113882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Silver nanoparticles (AgNPs) exhibit excellent antibacterial effects at higher concentrations, and exert proper immunoregulatory effects in bone regeneration at lower concentrations. An ideal guided bone regeneration (GBR) membrane should inhibit bacterial infection initially and regulate immune cells subsequently to achieve desired bone repair. In this study, the polycaprolactone (PCL) membranes were coated with AgNPs via triple layer-by-layer (LbL) self-assembly (hereafter referred as “PCL-3Ag”). The fabrication process successfully endowed the PCL-3Ag membranes with excellent antibacterial activities and anti-inflammatory effects due to the abundant release of Ag initially, and promoted lipopolysaccharide stimulated macrophages polarization to M2 phenotype due to the slower and steady release of Ag in the subsequent stage. The regulation of PCL-3Ag on macrophages promoted the osteogenic differentiation of rat bone mesenchymal stem cells in vitro . In vivo , superior bone regeneration with decreased number of CD86-positive cells and increased number of CD163-positive cells was observed in rat calvaria defects covered with PCL-3Ag membranes compared with defects covered with PCL membranes or uncovered defects. Overall, the LbL self-assembled antibacterial, anti-inflammatory, and immunoregulatory PCL-3Ag membrane presented here enhances tissue repair and shows excellent potential for application to bone tissue engineering.},
  archive      = {J_MATDES},
  author       = {Yu Guo and Xin Li and Qian Zhang and Yanjun Yu and Zihan Shi and Zheng Zheng and Siyang Yu and Zhirui Guo and Yang Xia and Yan Xu},
  doi          = {10.1016/j.matdes.2025.113882},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113882},
  shortjournal = {Mater. Des.},
  title        = {Silver nanoparticle-assembled guided bone regeneration membranes showcase dual functions: Initial bacterial elimination and subsequent immune regulation},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating phase regimes via combinatorial synthesis: A
pathway to tailored materials libraries. <em>MATDES</em>, <em>253</em>,
113881. (<a href="https://doi.org/10.1016/j.matdes.2025.113881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combinatorial magnetron sputtering has been implemented to synthesize compositionally graded thin film material libraries, enabling rapid exploration of structure–property trends via high-throughput characterization techniques. In this study, an Fe-W material library with 169 unique samples is sputter-deposited to investigate the amorphous-crystalline transition across the Fe – 9.4 to 45.5 at.% W range. X-ray diffraction and electron microscopy techniques reveal trends in film microstructure and morphology that are intrinsically connected to alloy composition but further shown to be dependent on synthesis conditions by decoupling composition and thickness/deposition rate effects. Samples are classified into three distinct regimes: crystalline, mixed-mode, or X-ray amorphous. By deconvoluting and analyzing the interplay between composition and deposition rate, it is shown that growth kinetics can sufficiently alter phase formation to dominate compositionally driven mechanisms within a single material library. This observation is verified after heat-treatment to 750 °C on selected samples. Particularly within the mixed-mode regime, the relationship between solute content and deposition rate is quantified, thereby enabling the tailoring of materials libraries investigations of composition and growth rate effects. Overall, this work combines the expansive compositional space in a combinatorial library with sputtering science to identify microstructural and phase regime boundaries in the Fe-W system.},
  archive      = {J_MATDES},
  author       = {K. Russell and C.A. Kohnke and J.R. Trelewicz and A.M. Hodge},
  doi          = {10.1016/j.matdes.2025.113881},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113881},
  shortjournal = {Mater. Des.},
  title        = {Investigating phase regimes via combinatorial synthesis: A pathway to tailored materials libraries},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal compensation strategy in selective electron beam
melting: Tailoring the microstructure and mechanical properties of h13
tool steel. <em>MATDES</em>, <em>253</em>, 113880. (<a
href="https://doi.org/10.1016/j.matdes.2025.113880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {H13 tool steel has extensive application in the mold manufacturing industry due to its excellent thermal strength and wear resistance. However, additively manufactured H13 exhibits inferior mechanical properties, high residual stress, and high volume fraction of retained austenite, which limits its application. To solve this problem, our work aims to optimize the microstructure and mechanical properties of H13 steel using Selective Electron Beam Melting (SEBM) with different thermal compensation strategies. The microstructural evolution and mechanical property strengthening mechanism of SEBM-fabricated H13 steels were discussed. The results indicated that the microstructure of H13 steel is a mixture of bainite and martensite, achieving an optimal balance between strength of 1809 ± 11 MPa and plasticity of 10.48 % when the thermal compensation current was 40 mA. This can be attributed to adjustments in grain size, dislocation density, and precipitate phases during thermal compensation strategies. The synergistic strengthening effects of high density of dislocations, numerous fine V 8 C 7 precipitates, and refined grains result in mechanical properties that surpass those of other additive manufacturing and conventional methods. Therefore, controlled thermal compensation was an effective tool for regulating the microstructure and mechanical properties of materials, providing a valuable reference for the fabrication of high-performance H13 steel components.},
  archive      = {J_MATDES},
  author       = {Jiaqi Deng and Gengjie Wang and Hongjun Qi and Yi Liu and Zhifu Huang},
  doi          = {10.1016/j.matdes.2025.113880},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113880},
  shortjournal = {Mater. Des.},
  title        = {Thermal compensation strategy in selective electron beam melting: Tailoring the microstructure and mechanical properties of h13 tool steel},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Determination and quantitative representation of three-level
dispersion system in asphalt mixture interface area. <em>MATDES</em>,
<em>253</em>, 113879. (<a
href="https://doi.org/10.1016/j.matdes.2025.113879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To establish a theoretical foundation for the quantitative design of asphalt mixtures based on mastic theory, this study investigates the interfacial zone of OGFC-13 asphalt mixtures. A three-dimensional digital twin model of the interfacial zone in OGFC-13 was developed using X-ray computed tomography (CT) and an enhanced U-Net deep learning algorithm. The model delineated a three-level dispersion system (TDS) within the interfacial zone, outlining the distribution ranges of each system. Furthermore, the distribution of each zone within the interfacial zone’s three-level dispersion system was validated through micro-mechanical, morphological analyses, elemental analyses, and theoretical calculations. The reliability of the enhanced U-Net deep learning algorithm in processing mesoscopic images was confirmed by segmenting asphalt mixture images. The digital twin model reveals that within the three-level dispersion system of the interfacial zone in OGFC-13, the pure asphalt area spans 8–25 µm, the asphalt mastic area ranges from 30 to 108 µm, and the asphalt mortar area extends from 300 to 1360 µm. These distribution ranges agree with the results obtained from nanoindentation, energy-dispersive spectroscopy (EDS), and washing tests, thereby confirming the consistency of the digital twin model with experimental evidence.},
  archive      = {J_MATDES},
  author       = {Xiangbing Gong and Jintao Ma and Guoping Qian and Huanan Yu and Cheng Zhong},
  doi          = {10.1016/j.matdes.2025.113879},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113879},
  shortjournal = {Mater. Des.},
  title        = {Determination and quantitative representation of three-level dispersion system in asphalt mixture interface area},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification of thermal barrier coatings
lifetime on rotating turbine blades considering
chemo-thermo-mechanically coupling failure. <em>MATDES</em>,
<em>253</em>, 113878. (<a
href="https://doi.org/10.1016/j.matdes.2025.113878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lifetime prediction of thermal barrier coatings (TBCs) on rotating turbine blades remains a significant challenge due to the complex service environment and multi-physics failure mechanisms. A computationally efficient multiscale uncertainty quantification model based on an adaptive Gaussian Process was developed. The model accounts for the coupled effects of thermal mismatch, interface oxidation, and creep at the microscale, while considering the interaction of gas thermal shock and high-speed rotation at the macroscale. The model was applied to quantify the uncertainty in damage evolution and service lifetime of TBCs on rotating turbine blades. Meantime, the key factors influencing TBCs failure are also analyzed. The prediction results revealed that after 600 cycles, the failure probability of TBCs on the suction side tip and the pressure side middle region of the rotating blade reached 80 %. This indicates that the spallation of TBCs has occurred in these regions, with an area of about 9 %. The spallation position and area of the experimental results are relatively consistent with the predicted results. The thermal expansion coefficient of the thermally grown oxide and temperature were identified as the most critical factors influencing TBCs lifetime.},
  archive      = {J_MATDES},
  author       = {Weiliang Yan and Cong Li and Qianqian Zhou and Yuqi Xie and Yu Sun and Li Yang and Yichun Zhou},
  doi          = {10.1016/j.matdes.2025.113878},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113878},
  shortjournal = {Mater. Des.},
  title        = {Uncertainty quantification of thermal barrier coatings lifetime on rotating turbine blades considering chemo-thermo-mechanically coupling failure},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanisms governing the enhanced strain tolerance of
segmented APS-TBCs. <em>MATDES</em>, <em>253</em>, 113877. (<a
href="https://doi.org/10.1016/j.matdes.2025.113877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface cracks are recognized as an effective approach for enhancing the strain tolerance of air plasma sprayed thermal barrier coating system (APS-TBCs). Therefore, segmented APS-TBCs with channeled surface cracks is considered a superior coating system for improving the combustion efficiency of advanced engines. However, the underlying mechanism responsible for its enhanced strain tolerance and service durability compared to conventional ones have not yet been fully elucidated. This article reveals this mechanism by investigating the residual stress evolutions in segmented and conventional APS-TBCs. We fabricate both types of APS-TBC samples and conduct isothermal cyclic oxidation service on them. Then, we measure the residual stresses of YSZ TC and TGO using Raman spectroscopy (RS) method and Photoluminescence piezo-spectroscopy (PLPS) method, respectively. Experimental results indicate that the segmented sample exhibited 2.5 times of service durability compared to the conventional sample. Through detailed analysis, we find that the macro-compliance mechanisms played a crucial role in governing the enhanced service performance of segmented samples. This macro-compliance effect is achieved by lowering the residual stress at given stain level through surface cracks, and thus results in improved interfacial integrity compared to conventional ones. The discoveries in this study contribute towards comprehending microstructure design and selection of APS-TBCs.},
  archive      = {J_MATDES},
  author       = {Liuyu Yang and Yiwen Chen and Dingjun Li and Peng Jiang},
  doi          = {10.1016/j.matdes.2025.113877},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113877},
  shortjournal = {Mater. Des.},
  title        = {Mechanisms governing the enhanced strain tolerance of segmented APS-TBCs},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Liposomal structure tuned j-aggregated ICG as enhanced
NIR-II imaging nanoprobe. <em>MATDES</em>, <em>253</em>, 113875. (<a
href="https://doi.org/10.1016/j.matdes.2025.113875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although near-infrared II (NIR-II) fluorescence imaging (FI) for accurate and noninvasive diagnosis of solid cancer has been developed as one of the crucial methods for formulating appropriate clinical treatment strategies, it is still hindered by the limited availability of NIR-II nanoprobes. In this study, we aim to develop high performance and biocompatible NIR-II probes based on novel mechanism of the aggregation of NIR fluorephores. Using domain effect of liposomal nanostructures, the J-aggregated state of indocyanine (ICG) NIR-II nanoprobes were elaborately fabricated. Combined with molecular dynamics simulation, the molecular mechanism of the formation of J-aggregated state of ICG molecules was discovered. Results show that the engineered J-aggregated state of ICG with a concentration below 50 μg/mL can fine tune ICG interactions instead of ICG-intermolecular interactions within liposomal structure. The rational designed ICG cationic liposomes (IJA-CLPs) show 3-fold enhancement in NIR-II intensity compared to the conventional ICG liposomes (ICG-CLPs). Furthermore, for a mouse model of mammary tumors with lymph node metastasis, IF7 peptide-modified IJA-CLPs (IF7-IJA-CLPs) can successfully discriminate tumor cell-metastasized lymph nodes with more than 4-fold fluorescence signal improvement. Thus, it is expected to provide a new avenue for designing NIR-II fluorescent probes for enriching the clinical NIR imaging applications.},
  archive      = {J_MATDES},
  author       = {Haoli Yu and Yuesong Wang and Yan Chen and Mengyuan Cui and Huiting Xu and Yang Liu and Mingxi Li and Min ji and Fang Yang},
  doi          = {10.1016/j.matdes.2025.113875},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113875},
  shortjournal = {Mater. Des.},
  title        = {Liposomal structure tuned J-aggregated ICG as enhanced NIR-II imaging nanoprobe},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tannic acid coated core-shell fibers with antibacterial and
antioxidant properties for diabetic wound healing. <em>MATDES</em>,
<em>253</em>, 113874. (<a
href="https://doi.org/10.1016/j.matdes.2025.113874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic wounds are exacerbated by a local high-sugar environment, leading to vascular and nerve damage, impaired angiogenesis, reduced collagen deposition, and increased inflammation and oxidative stress, ultimately halting the healing process. With the rising prevalence of diabetes, the number of patients with diabetic wounds is also increasing. In this context, a novel fiber dressing for diabetic wounds has been developed using coaxial electrospinning combined with self-assembly coating technology. The uniform distribution of the TA (tannic acid) coating enhances the mechanical properties, hydrophilicity, and cell adhesion of PLGA-PCL core–shell fibers while imparting anti-inflammatory, antibacterial, and antioxidant capabilities. The drug Cur (curcumin), loaded in the core layer of the coaxial electrospun fibers, promotes angiogenesis, collagen deposition, and cellular anti-senescence capacity, while the shell layer facilitates drug encapsulation and sustained release. In vivo experiments, the electrospun fibers serve as an active skin substitute, creating a favorable microenvironment for diabetic wound healing. Overall, TA-coated PLGA-PCL core–shell fibers show great potential as wound dressings for diabetic wound repair.},
  archive      = {J_MATDES},
  author       = {Zouwei Li and Qi Guo and Renxin Chen and Yan E and Yezheng Wang and Mengyue Zhu and Guang Shi and Zhuowen Hao and Jingfeng Li and Shaobo Zhu},
  doi          = {10.1016/j.matdes.2025.113874},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113874},
  shortjournal = {Mater. Des.},
  title        = {Tannic acid coated core-shell fibers with antibacterial and antioxidant properties for diabetic wound healing},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantifying delamination energy in tungsten on silicon thin
films through nanoindentation and nanoscratch. <em>MATDES</em>,
<em>253</em>, 113873. (<a
href="https://doi.org/10.1016/j.matdes.2025.113873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying delamination energy is crucial for the reliability and longevity of thin films. In this work, the delamination energy in tungsten-silicon thin films is investigated through nanoindentation and nanoscratching. Nanoindentation was also employed to assess the mechanical properties of the coating through the use of substrate corrections. Energy methods were used to analyse the nanoindentation load displacement curves to quantify the delamination energy. Finite element modelling was used to further improve the accuracy of the calculated delamination energy. Nanoscratching was found to be highly sensitive to the scratch parameters used, and the effect of scratch parameters on the critical load and delamination energy was investigated. It was found that the presence of fragmentation event in nanoscratching led to higher delamination energy values as compared to nanoindentation. Nanoindentation was found to output values closer to that of literature and were additionally not parameter sensitive, making it a reliable method of evaluating thin film adhesion.},
  archive      = {J_MATDES},
  author       = {Shatha Almarri and Matthew Lloyd and Ed Darnbrough and David Armstrong},
  doi          = {10.1016/j.matdes.2025.113873},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113873},
  shortjournal = {Mater. Des.},
  title        = {Quantifying delamination energy in tungsten on silicon thin films through nanoindentation and nanoscratch},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Separation of humidity, strain rate and temperature effect
on the orientation dependent micromechanical properties of cortical
ovine bone. <em>MATDES</em>, <em>253</em>, 113872. (<a
href="https://doi.org/10.1016/j.matdes.2025.113872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone is a hierarchically structured composite material, the basic building blocks are type I collagen, hydroxyapatite and water. Water has a major influence on load transfer by facilitating interface sliding. This has a considerable effect on the quasi-static mechanical properties. For this reason, bone must be characterized at quasi physiological conditions, in order to understand the mechanisms allowing inelastic deformation and causing fracture. In the current work, compression tests were performed on 419 ovine cortical bone micropillars at the lamellar length scale in axial and transverse fibril orientation. Experiments were carried out at varying strain rates (0.1 s −1 - 100s −1 ), temperatures (24°C − 60°C) and tissue water contents (3.1 – 8.3 wt%), allowing to study the influence of these crucial factors. The effect of temperature and water on the mechanical properties could be separated by applying a linear modeling approach. This results in a temperature related softening of 1.2 MPa/K and 33–111 MPa/wt.% water. The results of this study highlight the significance of temperature and tissue water content on the compressive strength of bone and are of value for future multiscale simulations of patient fracture risk allowing to take into account age and disease related decrease in bone water content.},
  archive      = {J_MATDES},
  author       = {Christian Minnert and Cinzia Peruzzi and Tatiana Kochetkova and Jérémie Bérard and Christopher Dreimol and Stefan Remund and Beat Neuenschwander and Johann Michler and Jakob Schwiedrzik},
  doi          = {10.1016/j.matdes.2025.113872},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113872},
  shortjournal = {Mater. Des.},
  title        = {Separation of humidity, strain rate and temperature effect on the orientation dependent micromechanical properties of cortical ovine bone},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural network-assisted design and validation
of terahertz metamaterial sensor. <em>MATDES</em>, <em>253</em>, 113871.
(<a href="https://doi.org/10.1016/j.matdes.2025.113871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a convolutional neural network (CNN)-assisted method for both forward optimization and inverse design of terahertz metamaterial sensors (TMSs), addressing the limitations imposed by reliance on manual trial-and-error processes. A hollow n-shaped TMS based on copper foil was developed, exhibiting two distinct resonance peaks between 0.3 and 1.4 THz. The formation mechanisms of resonance peaks were analyzed based on electric field and current distribution, while the sensing performance of the TMS was investigated. In the forward optimization stage, the n-shaped unit of TMS was converted into a data matrix, and the CNN was developed to predict the resonance frequency. In the inverse design stage, a predictive model for estimating the size of the TMS was developed by applying one-dimensional convolution to the transmission coefficients. The training dataset employed for forward optimization and inverse design achieved coefficients of determination (R 2 ) of 0.99 and 0.99, respectively, with corresponding mean absolute error (MAE) values of 3.90 and 1.04. The efficacy of the proposed method was validated through terahertz time-domain spectroscopy (THz-TDS) measurements of TMS. Experimental assessments were conducted on glucose solutions of varying concentrations to ascertain the sensing capabilities. The proposed method contributes to the efficient design and optimization of TMS.},
  archive      = {J_MATDES},
  author       = {Shunrong Chen and Chunyue Zhao and Wei Wang and Songyuan Yang and Chengjiang Zhou},
  doi          = {10.1016/j.matdes.2025.113871},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113871},
  shortjournal = {Mater. Des.},
  title        = {Convolutional neural network-assisted design and validation of terahertz metamaterial sensor},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pressure-driven grain fusion and mechanical properties
improvement of high-entropy (Ti0.2Zr0.2Nb0.2Hf0.2Ta0.2)c ceramics.
<em>MATDES</em>, <em>253</em>, 113870. (<a
href="https://doi.org/10.1016/j.matdes.2025.113870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense and fine-grained high entropy transition metal carbides are considered as one of the most promising materials with superior hardness, fracture toughness and electrical conductivity. However, the difficulty in preparing high-quality fine-grained samples limits their wide applications. In this work, fully dense and fine-grained (Ti 0.2 Zr 0.2 Nb 0.2 Hf 0.2 Ta 0.2 )C ceramics were prepared by high temperature and high pressure technique. Ultra-high pressure significantly accelerates the densification process and significantly lowers the sintering temperature due to the pressure-induced grain fusion and grain growth suppression effect. The monolith sintered at 1200 ℃ and 15 GPa exhibits a Vickers hardness of 27.9 GPa (9.8 N), and a high fracture toughness of 8.9 MPa·m 1/2 , both of which are the highest values for the reported high-entropy carbide ceramics. Advanced characterization demonstrates that high hardness and toughness are closely related to the high dislocation density, fine grain size, and the high relative density. Additionally, the sintering temperature is significantly reduced by applying pressure, which provides a general route for preparing advanced polycrystalline high-entropy carbide ceramics for more superior mechanical properties.},
  archive      = {J_MATDES},
  author       = {Wang Chen and Pengfei Shen and Wei Li and Shuailing Ma and Min Lian and Xinmiao Wei and Yaqian Dan and Xingbin Zhao and Mengyao Qi and Tian Cui and Ralf Riedel},
  doi          = {10.1016/j.matdes.2025.113870},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113870},
  shortjournal = {Mater. Des.},
  title        = {Pressure-driven grain fusion and mechanical properties improvement of high-entropy (Ti0.2Zr0.2Nb0.2Hf0.2Ta0.2)C ceramics},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser cladding ni-based WC/MoS2 composite coatings: Particle
competition mechanism and tribological performance. <em>MATDES</em>,
<em>253</em>, 113868. (<a
href="https://doi.org/10.1016/j.matdes.2025.113868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To develop a highly wear-resistant coating with self-lubricating characteristics, this study reports the use of laser cladding to fabricate WC/MoS 2 composite coatings on the surface of 65Mn steel plates. Here, we investigated the effects of different laser powers and MoS 2 contents on the phase composition, phase distribution, microstructure, and friction/wear properties of the coatings, focusing on heat and element competition mechanisms, as well as the wear mechanism of the Ni-based WC/MoS 2 composite coatings. The results show that compared with MoS 2 , WC remains disadvantaged in terms of heat competition in the molten pool. However, during MoS 2 thermal decomposition, the free Cr atoms in the pool are also captured, not only changing the type and morphology of the M x C y carbides and inhibiting WC heat damage but also resulting in a decreased content of M x C y carbides within the coating. When a significant amount of Cr x S y gathers on the coating surface, a stable and continuous lubricating film is formed, allowing the coating to balance the wear resistance with lubrication.},
  archive      = {J_MATDES},
  author       = {Kepeng Huang and Changjiang Zheng and Zexi Chen and Dayou Wu and Xuemei Yi},
  doi          = {10.1016/j.matdes.2025.113868},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113868},
  shortjournal = {Mater. Des.},
  title        = {Laser cladding ni-based WC/MoS2 composite coatings: Particle competition mechanism and tribological performance},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TPMS-based metamaterials with tuneable elastic anisotropy
and mechanical coupling. <em>MATDES</em>, <em>253</em>, 113866. (<a
href="https://doi.org/10.1016/j.matdes.2025.113866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Architectured metamaterials typically comprise of unit cells with cubic stiffness tensors and this cubic symmetry greatly restricts the available design space of mechanical properties than can be attained. In this paper, this conventional design approach is challenged by creating metamaterials that have monoclinic, orthorhombic, and tetragonal symmetries, to provide additional design freedoms. The building block to these symmetry classes is a novel monoclinic unit cell, which is generated via the shape transformation of triply periodic minimal surfaces (TPMS). The monoclinic TPMS-based unit cell exhibits the most extreme stiffness anisotropy of the four symmetry classes in addition to possessing normal−shear and shear−shear mechanical coupling. Although the monoclinic cells only have one internal plane of symmetry, the faces of the unit cells remain periodic, which enables periodic boundary conditions to be applied in finite element analysis (FEA) and the characterisation of the unit cell homogenised stiffness tensors. Next, a wide range of these TPMS-based metamaterials were additively manufactured in polylactic acid and tested under quasi-static compression. Both the FEA and experimental test results confirm that stiffness anisotropy and mechanical coupling can be controlled, revealing an expanded design space for the stiffness tailoring of additively manufactured metamaterials.},
  archive      = {J_MATDES},
  author       = {Stephen Daynes},
  doi          = {10.1016/j.matdes.2025.113866},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113866},
  shortjournal = {Mater. Des.},
  title        = {TPMS-based metamaterials with tuneable elastic anisotropy and mechanical coupling},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning interatomic potential for the low-modulus
ti-nb-zr alloys in the vicinity of dynamical instability.
<em>MATDES</em>, <em>253</em>, 113865. (<a
href="https://doi.org/10.1016/j.matdes.2025.113865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning-augmented first-principles simulations facilitate the exploration of alloying and thermal treatments for tailoring material properties in industrial applications. However, addressing challenges near dynamical instabilities requires rigorous validation of machine-learned interatomic potentials (MLIP) to ensure their reliable applicability. In this study we have trained MLIP using moment tensor potentials to simulate finite temperature elastic properties of multicomponent β-Ti 94-x Nb x Zr 6 alloys. Our simulations predict the presence of the elinvar effect for the wide range of temperatures. Importantly, we predict that in a vicinity of dynamical and mechanical instability, the β-Ti 94-x Nb x Zr 6 alloys demonstrate strongly non-linear concentration-dependence of elastic moduli, which leads to low values of moduli comparable to that of human bone. Moreover, these alloys demonstrate a strong anisotropy of directional Young’s modulus which can be helpful for microstructure tailoring and design of materials with desired elastic properties.},
  archive      = {J_MATDES},
  author       = {Boburjon Mukhamedov and Ferenc Tasnádi and Igor A. Abrikosov},
  doi          = {10.1016/j.matdes.2025.113865},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113865},
  shortjournal = {Mater. Des.},
  title        = {Machine learning interatomic potential for the low-modulus ti-nb-zr alloys in the vicinity of dynamical instability},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Highly toughening of PLLA-based micropart via stretching
induced stereocomplex crystal microstructure evolution. <em>MATDES</em>,
<em>253</em>, 113862. (<a
href="https://doi.org/10.1016/j.matdes.2025.113862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polylactic acid (PLA) holds great potentials in biomedical applications, but its inherent brittleness restricts its versatility to a considerable degree. This study proposed a novel and heterogeneous modifier-free approach to enhance PLA’s toughness by leveraging the stretching induced evolution of stereocomplex crystal (SC) microstructures in situ formed during microinjection molding. By incorporating 10 wt% poly(D-lactic acid) (PDLA) into poly(L-lactic acid) (PLLA) through combining melt compounding and microinjection molding featuring extremely intense shear, we achieved a remarkable 10-fold increase in elongation at break (from 8.7 % to 87.2 %) while maintaining tensile strength (∼67 MPa). The structural analyses revealed a transition from phase-separated sea-island morphologies to deformable stereocomplex crystal PLA phase domains, which could serve as the physical crosslinking points facilitating stress transfer, and can be transformed into microfibril and shish-kebab structures upon drawing. Such the phase structure evolution could efficiently distribute stress and hence enhance toughness without sacrificing biodegradability or biocompatibility. This work develops a streamlined approach in simplifying conventional stereocomplex reinforcement strategies and thus offers a scalable method for developing fully biodegradable, and high-performance PLA-based materials suitable for diverse biomedical applications, such as bone tissue reconstruction.},
  archive      = {J_MATDES},
  author       = {Yeping Xie and Jiayu Tan and Shijian Fang and Zhuo Zheng and Lei Yao and Yang Xu and Jian Li and Yinghong Chen and Ning Chen and Li Li},
  doi          = {10.1016/j.matdes.2025.113862},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113862},
  shortjournal = {Mater. Des.},
  title        = {Highly toughening of PLLA-based micropart via stretching induced stereocomplex crystal microstructure evolution},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 2H-MoS2 lubrication-enhanced MWCNT nanocomposite for subtle
bio-motion piezoresistive detection with deep learning integration.
<em>MATDES</em>, <em>253</em>, 113861. (<a
href="https://doi.org/10.1016/j.matdes.2025.113861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent piezoresistive health monitoring systems integrate advanced nanocomposite architectures with precise algorithmic analysis for real-time physiological assessment. However, existing works often prioritize high sensitivity at the expense of strain tolerance and require complex fabrication procedures. Herein, we present an environmentally friendly, low-cost, and nonionic fabrication approach for a 2H-phase molybdenum disulfide (2H-MoS 2 )-enhanced multi-walled carbon nanotube (MWCNT) strain sensor, developed via a systematically optimized vacuum-assisted filtration process. This study is the first to validate the dual enhancement effect of MoS 2 , leveraging its shear-exfoliation properties to simultaneously improve strain gauge performance and mechanical robustness. The resulting nacre-like layered hybrid nanocomposite achieves a remarkable gauge factor of 675.7 (R 2 ∼0.993) at low strain (∼0–4.5 %), representing a 3881.5 % improvement over pure MWCNT systems, alongside enhanced toughness (∼89.17 %) and strain tolerance (∼53.93 %). Meanwhile, the optimized composition ensures low rest-state resistance (∼13.1 Ω), minimal hysteresis (∼5.7 %), and robust durability over 5000 cycles at 10 % strain. As a result, the proposed sensor enables highly consistent, high-fidelity monitoring of various subtle-to-moderate biomotions. Integrated with a fine-tuned InceptionTime deep learning model, it achieves an F1-score of 98 % in classifying Dysphagia Diet Standardization Initiative (IDDSI)-standard swallowing activities, demonstrating its potential for AI-driven health monitoring applications.},
  archive      = {J_MATDES},
  author       = {Ke-Yu Yao and Derek Ka-Hei Lai and Hyo-Jung Lim and Bryan Pak-Hei So and Andy Chi-Ho Chan and Patrick Yiu-Man Yip and Duo Wai-Chi Wong and Bingyang Dai and Xin Zhao and Siu Hong Dexter Wong and James Chung-Wai Cheung},
  doi          = {10.1016/j.matdes.2025.113861},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113861},
  shortjournal = {Mater. Des.},
  title        = {2H-MoS2 lubrication-enhanced MWCNT nanocomposite for subtle bio-motion piezoresistive detection with deep learning integration},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable tensile stiffness pneumatic actuators with
adjustable stick-slip friction of soft-tooth structures.
<em>MATDES</em>, <em>253</em>, 113860. (<a
href="https://doi.org/10.1016/j.matdes.2025.113860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients with hemiplegia, neurologic injuries, and sports trauma require muscle strength rehabilitation training, the existing rigid equipment is uncomfortable and bulky, and wearable training devices are not suitable for the whole-stage of passive, assistant, active and resistance rehabilitation training, and are difficult to provide comprehensive and real-time feedback on the current rehabilitation level. This paper proposes a multi-layer cylindric soft actuator with axial tensile stiffness variation, and pneumatic control is utilized to achieve axial elongation and resistance adjustment. The resistance is changed through the stick–slip friction of soft structure during tooth structures engagement and sliding, and the tensile stiffness of the soft actuator can be changed by 7.2 times with air pressure increased by only 20 kPa. Capacitive strain sensing is used to obtain elongation and stiffness feedback, and the closed-loop control errors for axial elongation and stiffness variation are only 2.02 % and 1.20 %, respectively. Finally, an application of elbow joint rehabilitation training demonstrates that the proposed variable stiffness actuator is feasible for whole-stage training and providing feedback on joint angle amplitude and strength.},
  archive      = {J_MATDES},
  author       = {Yaqing Feng and Pengyuan Wang and Chenghao Wu},
  doi          = {10.1016/j.matdes.2025.113860},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113860},
  shortjournal = {Mater. Des.},
  title        = {Variable tensile stiffness pneumatic actuators with adjustable stick-slip friction of soft-tooth structures},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resistance spot welded NiTi shape memory alloy to Ti6Al4V:
Correlation between joint microstructure, cracking and mechanical
properties. <em>MATDES</em>, <em>253</em>, 113859. (<a
href="https://doi.org/10.1016/j.matdes.2025.113859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the popularity of joining NiTi and Ti6Al4V in aerospace and biomedical applications, effective solutions for their dissimilar joining are limited due to brittle intermetallic compounds. In this work, we successfully joined NiTi/Ti6Al4V using resistance spot welding. Results indicate that the number of cracks is the primary factor determining the lap-shear load. The extensive accumulation of brittle Ti 2 Ni at the bottom of the weld pool leads to stress concentration and is the main cause of crack initiation. X-ray diffraction and phase diagrams revealed the solidification sequence of liquid metal in the joint, including L → N i T i , L + N i T i → Ti 2 N i , L → β T i + Ti 2 N i . Electron backscatter diffraction analysis showed that weld nugget grains exhibited random orientation, with stress concentration mainly within the Ti 2 Ni phase on the Ti6Al4V side and at the boundary between the NiTi and Ti 2 Ni phases, contributing to high susceptibility to deformation and cracking in these regions. Nanoindentation analysis further demonstrated that the welding process diminished the superelastic performance of NiTi, attributable to Ti 2 Ni phase, grain coarsening and the orientation deviation of B2 NiTi.},
  archive      = {J_MATDES},
  author       = {Yihu Zang and Jilin Xie and Yuhua Chen and Min Zheng and Xiaofang Liu and Jiajia Shen and J.P. Oliveira},
  doi          = {10.1016/j.matdes.2025.113859},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113859},
  shortjournal = {Mater. Des.},
  title        = {Resistance spot welded NiTi shape memory alloy to Ti6Al4V: Correlation between joint microstructure, cracking and mechanical properties},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties and microstructure analysis of laser
welded hybrid parts made of additively and conventionally manufactured
1.4313 soft martensitic steel. <em>MATDES</em>, <em>253</em>, 113858.
(<a href="https://doi.org/10.1016/j.matdes.2025.113858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates laser welding of additively (AM) and conventionally manufactured (CM) parts, aiming to enhance cost and energy efficiency for a diverse product range. In this context, hybrid specimens combining AM/CM subparts were produced, where AM subparts were created using DED, CM parts by hot forming, and the two were joined using laser welding. The material analysed is soft martensitic stainless steel. Mechanical characterisation was performed through tensile testing and hardness measurements and microstructure characterisation through EBSD, SEM, EDS, and light microscopy. The study reveals the presence of ultra-fine grains in the heat treated laser weld segments which suggests grain subdivision due to martensite deformation. As built hybrid specimens exhibited lower toughness due to the laser welds and lower strength due to the CM segments. The weakest point after the heat treatment was the HAZ of the CM segment. The best mechanical performance was observed in homogeneously heat-treated AM specimens. Moreover, the variability in grain size were examined but did not conform grain boundary strengthening, particularly after the heat treatment. This study highlights the critical influence of microstructural variations on the mechanical properties of hybrid welds, emphasizing the need for further investigation into strengthening mechanisms and individual heat treatments.},
  archive      = {J_MATDES},
  author       = {Indira Dey and Raphael Floeder and Karsten Kunze and Christian Roth and Konrad Wegener},
  doi          = {10.1016/j.matdes.2025.113858},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113858},
  shortjournal = {Mater. Des.},
  title        = {Mechanical properties and microstructure analysis of laser welded hybrid parts made of additively and conventionally manufactured 1.4313 soft martensitic steel},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-depth investigation of microstructural evolution induced
by sc, v, and ni microalloying in al-zn-mg-cu alloy during hot
compression. <em>MATDES</em>, <em>253</em>, 113857. (<a
href="https://doi.org/10.1016/j.matdes.2025.113857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the microstructural changes and mechanical behavior of an Al-Zn-Mg-Cu-Sc-(V-Ni) alloy during hot compression, conducted at temperatures ranging from 340 to 460°C and strain rates from 0.01 to 10 s −1 . Molecular dynamics simulations were employed to examine dislocation evolution and mechanical behavior. The peak power dissipation values (ν) for the Al-Zn-Mg-Cu-Sc and Al-Zn-Mg-Cu-Sc-V-Ni alloys were 35 % and 41 %, respectively, reflecting enhanced energy dissipation with V and Ni additions. The second-phase strengthening effects of Al 7 Cu 4 Ni (HCP-type) and Al 21 V 2 (FCC-type) significantly increased the high-temperature flow stress of alloy. During hot compression of the Al-Zn-Mg-Cu-Sc-V-Ni alloy, typical (111)[110] and (111)[001] perfect dislocations were observed. The accumulation of dislocations facilitated diffusion pathways, accelerating the precipitation of the η-MgZn 2 phase. The addition of Sc, V, and Ni increased the number of 1/6 &lt; 112 &gt; Shockley partial dislocations and 1/2 &lt; 110 &gt; Perfect dislocations at elevated temperatures, thereby enhancing the alloy’s compression resistance.},
  archive      = {J_MATDES},
  author       = {Yuxin Dai and Liangming Yan and Song Sun and Jingyu Zhang and Xinhao Li and Juncheng Liu and Xuefang Liu},
  doi          = {10.1016/j.matdes.2025.113857},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113857},
  shortjournal = {Mater. Des.},
  title        = {In-depth investigation of microstructural evolution induced by sc, v, and ni microalloying in al-zn-mg-cu alloy during hot compression},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SLICES-PLUS: A crystal representation leveraging spatial
symmetry. <em>MATDES</em>, <em>253</em>, 113856. (<a
href="https://doi.org/10.1016/j.matdes.2025.113856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the realm of crystalline materials has witnessed a surge in the development of generative models, predominantly aimed at the inverse design of crystals with tailored physical properties. However, spatial symmetry, which serves as a significant inductive bias, is often not optimally harnessed in the design process. This oversight tends to result in crystals with lower symmetry, potentially limiting the practical applications of certain functional materials. To bridge this gap, we introduce SLICES-PLUS, an enhanced variant of SLICES that emphasizes spatial symmetry. Our experiments in classification and generation have shown that SLICES-PLUS exhibits greater sensitivity and robustness in learning crystal symmetries compared to the original SLICES. Furthermore, by integrating SLICES-PLUS with a customized MatterGPT model, we have demonstrated its exceptional capability to target the specific physical properties and crystal systems with precision. Finally, we explore autoregressive generation towards multiple elastic properties in few-shot learning. Our research represents a significant step forward in the realm of computational materials discovery.},
  archive      = {J_MATDES},
  author       = {Baoning Wang and Zhiyuan Xu and Zhiyu Han and Qiwen Nie and Xi Chen and Hang Xiao and Gang Yan},
  doi          = {10.1016/j.matdes.2025.113856},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113856},
  shortjournal = {Mater. Des.},
  title        = {SLICES-PLUS: A crystal representation leveraging spatial symmetry},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Process optimization for improving anti-oxidation
performance of silver-coated copper powders by response surface
methodology and artificial neural network. <em>MATDES</em>,
<em>253</em>, 113855. (<a
href="https://doi.org/10.1016/j.matdes.2025.113855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of silver-coated copper powders (SCCPs) is a promising approach to reduce costs in the photovoltaic industry. However, the anti-oxidation performance of SCCPs directly determines their reliability in practical applications. This study aims to design an efficient approach for optimizing process parameters to enhance anti-oxidation performance of SCCPs. An innovative co-optimization strategy integrating response surface methodology (RSM) and artificial neural network (ANN) is proposed to optimize process parameters. The effects of interactions between process parameters on the anti-oxidation performance of SCCPs were investigated using RSM. The optimal parameter combination (ascorbic acid concentration: 0.05 mol/L, pH: 7, and feeding rate: 15 mL/min) was determined, and the results were predicted using ANN. The strategy achieves superior optimization efficiency and predictive accuracy compared to individual methods by reducing experimental requirements, lowering error functions, and enhancing fitting precision. Experimental results demonstrated that the co-optimization strategy reduced the oxidation weight gain of SCCPs by 60 % under dynamic heating conditions in an atmospheric environment, with a prediction error of 2.45 %. The co-optimization strategy successfully enhanced both the antioxidant properties and powder quality of SCCPs. This work offers an innovative design approach for enhancing the properties of silver-coated copper powders.},
  archive      = {J_MATDES},
  author       = {Hongbin Yin and Shiwei Fan and Kun Peng and Xiao Li and Zizhen Wang and Yuxin Chen and Ming Zhou},
  doi          = {10.1016/j.matdes.2025.113855},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113855},
  shortjournal = {Mater. Des.},
  title        = {Process optimization for improving anti-oxidation performance of silver-coated copper powders by response surface methodology and artificial neural network},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal gradient-index phononic crystal lenses: Design,
theory, and application on non-planar structures. <em>MATDES</em>,
<em>253</em>, 113854. (<a
href="https://doi.org/10.1016/j.matdes.2025.113854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient index phononic crystal (GRIN-PC) lenses have been widely recognized for their effectiveness in focusing or localizing elastic waves at specific target locations. This wave-focusing capability enhances the energy-harvesting performance of piezoelectric transducers and improves defect detection sensitivity in non-destructive evaluation (NDE) applications. While GRIN-PC lenses have been extensively studied for planar structures, their application to curved geometries remains limited, primarily due to the lack of a comprehensive theoretical framework for understanding wave behavior in non-planar phononic crystal structures. In this work, we develop a conformal GRIN-PC theory to analyze elastic wave focusing in curved structures and propose a systematic design framework for implementing GRIN-PC lenses on non-planar surfaces. The proposed theory models wave propagation within conformal GRIN-PC lenses using ray trajectory analysis, accurately predicting the focal region. We validate this framework through numerical simulations of a conformal GRIN-PC lens applied to a steel pipe and demonstrate its accuracy in predicting focal points. Furthermore, the design framework is applied to fabricate a 3D-printed conical GRIN-PC lens, with numerical simulations and experimental results confirming its wave-focusing performance. This work establishes a foundation for expanding GRIN-PC applications to non-planar structural components widely found in mechanical, aerospace, and civil engineering structures.},
  archive      = {J_MATDES},
  author       = {Hrishikesh Danawe and Serife Tol},
  doi          = {10.1016/j.matdes.2025.113854},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113854},
  shortjournal = {Mater. Des.},
  title        = {Conformal gradient-index phononic crystal lenses: Design, theory, and application on non-planar structures},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and test of a quasi-zero stiffness metastructure
based on the preshaped beams for low-frequency vibration isolation.
<em>MATDES</em>, <em>253</em>, 113853. (<a
href="https://doi.org/10.1016/j.matdes.2025.113853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study introduces a novel QZS metastructure, which is based on monolithic preshaped beams that draw inspiration from the snap-through behavior of cosine beams. The QZS feature is achieved by incorporating an additional arc segment, which serves as an elastic boundary, extending from the end of the cosine beam to the rigid walls. The matching mechanism between the arc segment and the cosine-shaped segment is analyzed through a static mechanical parametric analysis using the finite element method, while metastructures fabricated using 3D printing techniques are employed to experimentally validate the conceptual design. The relationships between the QZS features and the design parameters are established through a parametric analysis. A QZS isolator consisting of metastructures is designed, and its dynamic performances are verified by the experimental tests and an analytical model. The QZS isolator demonstrated a 70% reduction in peak transmissibility and a 25% lower beginning frequency of vibration compared to the nonlinear isolator lacking the QZS feature, highlighting the advantageous low-frequency vibration isolation capability of the QZS isolator. Moreover, the proposed QZS metastructure demonstrates a programmable capability by adjusting the number of units and beams. This programmable feature enables multi-step vibration isolation, which has been experimentally validated.},
  archive      = {J_MATDES},
  author       = {Zhimin Zhang and Zhuoyuan Qi and Diankun Pan},
  doi          = {10.1016/j.matdes.2025.113853},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113853},
  shortjournal = {Mater. Des.},
  title        = {Design and test of a quasi-zero stiffness metastructure based on the preshaped beams for low-frequency vibration isolation},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of graded porous acoustic absorbers based on
triply periodic minimal surfaces. <em>MATDES</em>, <em>253</em>, 113852.
(<a href="https://doi.org/10.1016/j.matdes.2025.113852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acoustic absorption of a porous structure within a specific frequency range can be tuned by varying its porosity along its thickness. In this work, triply periodic minimal surfaces (TPMS) are employed to generate graded porous structures, where the continuous porosity gradient is controlled by a mathematical function involving geometric parameters. A hybrid homogenization technique, combined with the transfer matrix method (TMM), is used to predict the normal incidence absorption coefficient of the graded TPMS structure. The porosity distribution along the thickness is then optimized using a global search method combined with a local gradient-based solver to maximize acoustic absorption within a target frequency range. The optimization results suggest that a combination of high- and low-porosity layers achieves broadband impedance matching conditions by shifting the so-called quarter-wavelength resonance frequencies. The design of the TPMS absorbers is validated through impedance tube measurements of 3D-printed samples.},
  archive      = {J_MATDES},
  author       = {Xueying Guan and Elke Deckers and Hao Dong and Maarten Hornikx and Jieun Yang},
  doi          = {10.1016/j.matdes.2025.113852},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113852},
  shortjournal = {Mater. Des.},
  title        = {Optimization of graded porous acoustic absorbers based on triply periodic minimal surfaces},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical and numerical evaluation of the relationship
between elongation calibration function and cyber standard tensile tests
for ductile materials. <em>MATDES</em>, <em>253</em>, 113851. (<a
href="https://doi.org/10.1016/j.matdes.2025.113851">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cylindrical tensile testing is critically reviewed focusing on the gage length per diameter (GLPD) and its effect on the elongation. Flow behaviors and patterns of representative cold forging materials of SCM435, SWCH45F, S25C, SWCH10A, SUS304, A6061, and ESW105 are revealed focusing on accurately predicting their tensile tests with various GLPDs using the combined elastoplastic FEM and tensile test method (EP_CFTM). A GLPD-elongation curve, called numerical elongation calibration curve, is numerically constructed, revealing that the elongation of ESW105 changes around 22.1% when the GLPD changes from 3.98 to 5. A concept of cyber standard tensile test (CSTT) of the numerical specimen with a fixed GLPD of five, based on finite element method (FEM) with accurate flow functions, is proposed to improve the objectivity of tensile testing of circular specimens. The CSTT removes the effect of the gage length of the cylindrical tensile test on the tensile testing results. A novel analytical elongation calibration function is presented and numerically validated. This function simply maps an experimental tensile test to the analytical tensile test of the specimen with arbitrary GLPD.},
  archive      = {J_MATDES},
  author       = {N.Y. Kim and N.H. Kim and M.K. Razali and H.M. Lee and M.S. Joun},
  doi          = {10.1016/j.matdes.2025.113851},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113851},
  shortjournal = {Mater. Des.},
  title        = {Analytical and numerical evaluation of the relationship between elongation calibration function and cyber standard tensile tests for ductile materials},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 2D robust intrinsic ferromagnetic half-metals Cr2XP with
high curie temperature. <em>MATDES</em>, <em>253</em>, 113850. (<a
href="https://doi.org/10.1016/j.matdes.2025.113850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {2D intrinsic ferromagnetic half-metals have received extensive attention for their promising application in spintronic devices. However, according to the Mermin-Wagner theorem, their Curie temperature hardly exceeds room temperature. Furthermore, a small half-metallic gap also limits their application in room-temperature environments. Through the first-principles and Monte Carlo calculations, we design a family of 2D room-temperature intrinsic ferromagnetic half-metals Cr 2 X P ( X =S, Se, Te) with large magnetization, high Curie temperatures (&gt;660 K), sizable half-metallic gap and good structural stability. Their large magnetic moments ∼ 7µ B arise from the exchange splitting of Cr- d orbital in the D 4h crystal field, and the ferromagnetic coupling is derived from the Cr-P-Cr super-exchange interaction mediated by P atom, the origin of wide half-metallic gap (&gt;1.24 eV) is briefly from the exchange splitting of d xy and d xz / d yz orbitals. In addition, the Cr 2 SP and Cr 2 SeP show the out-of-plane magnetocrystalline anisotropy energies (MAEs) of 188.25 and 46.57 µeV/f.u., and the Cr 2 TeP possess an in-plane MAE of 329.01 µeV/f.u. These intriguing advantages make the Cr 2 X P as an attractive candidate for spintronic devices.},
  archive      = {J_MATDES},
  author       = {Xiao-Ping Wei and Jiao-Yang Zhang and Hao-Kai Sun and Jiang-Liu Meng and Ya-Ling Zhang and Xiaoma Tao},
  doi          = {10.1016/j.matdes.2025.113850},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113850},
  shortjournal = {Mater. Des.},
  title        = {2D robust intrinsic ferromagnetic half-metals Cr2XP with high curie temperature},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical model of effective elastic moduli of composites
considering the inclusion features. <em>MATDES</em>, <em>253</em>,
113849. (<a href="https://doi.org/10.1016/j.matdes.2025.113849">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantifying the effect of composition on the two-phase composite’s mechanical properties is crucial for the life prediction and durability design of the whole structure. Features of inclusions, especially shape and size, affect the two-phase composites’ effective elastic moduli significantly. However, previous studies have not considered the coupling effects of the inclusion shape, size, and volume fraction. To address this problem, a new normalized theoretical model (modified three-point approximation TPA) is proposed to predict the coupling effects of these factors by introducing two parameters: sphericity and skewness. Then, this work considers the two-phase composite containing inclusions (non-spherical particles of different shapes) and the matrix. The non-spherical particle packing structures are created by the discrete element method. Based on the particulate structures, the reliability of the proposed modified TPA can be verified by the numerical simulation using the lattice model. The correction parameters for sphericity and skewness are 1.21 and −0.58, respectively. The new modified TPA demonstrates that the elastic moduli increase when the number of smaller particles decreases and the particle shape approaches the sphere. The newly proposed modified TPA is significant for designing and applying particulate composites.},
  archive      = {J_MATDES},
  author       = {Xuqian Liu and Zhangyu Wu and Shuohui Chen},
  doi          = {10.1016/j.matdes.2025.113849},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113849},
  shortjournal = {Mater. Des.},
  title        = {Theoretical model of effective elastic moduli of composites considering the inclusion features},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlation between nanomechanical properties and
microstructural design concepts of bivalve muscle attachment sites.
<em>MATDES</em>, <em>253</em>, 113845. (<a
href="https://doi.org/10.1016/j.matdes.2025.113845">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bivalves populate various marine environments and follow diverse lifestyles: attaching to substrates, burrowing into sediments or swimming in water. Their shells play a crucial role in the survival of organisms as they shield the soft tissue from external attacks and facilitate their respective lifestyles. Valve movement is controlled by one or two adductor muscles and the hinge. While the function and structure of adductor muscles can vary, the shell-muscle attachment develops the myostracum, a unique microstructural design. Sectioned parallel and perpendicular to the inner shell surface, we investigated myostracal and non-myostracal microstructures, textures and nanomechanical properties for three bivalve species: The burrowing Glycymeris pilosa , the sessile Chama arcana and the swimming Placopecten magellanicus . Analyses were conducted using electron backscatter diffraction measurements, laser confocal and backscatter electron imaging, nanoindentation testing and thermogravimetric analysis. We find that the myostracal microstructure is generated mainly through physical determinants, regardless of the bivalve lifestyle and adductor muscle structure. If aragonitic, we show that adjacent shell layers are used as templates for the formation of the myostracal microstructure and highlight how bivalves use the adjacent crystal arrangement to predetermine myostracal microstructure up to inner shell surfaces. Furthermore, this study demonstrates how myostracal layers exceed the hardness of the non-myostracal valves and that of geological aragonite, irrespective of grain size and morphology. Due to the anisotropy of aragonite, we show that aragonite c-axis orientation notably affects the hardness of crystals. The highest hardness is measured when indentation is normal to the shell surface in aragonite c-axes direction.},
  archive      = {J_MATDES},
  author       = {S. Hoerl and C. Micheletti and S. Amini and E. Griesshaber and K.-U. Hess and A.G. Checa and M. Peharda and W.W. Schmahl},
  doi          = {10.1016/j.matdes.2025.113845},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113845},
  shortjournal = {Mater. Des.},
  title        = {Correlation between nanomechanical properties and microstructural design concepts of bivalve muscle attachment sites},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Innovative approach for designing topological interlocking
bricks with precise morphological representation and controlled
interface curvature. <em>MATDES</em>, <em>253</em>, 113844. (<a
href="https://doi.org/10.1016/j.matdes.2025.113844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological interlocking systems present an innovative approach to structural design, offering promising solutions for the development of structures with enhanced mechanical performance. However, current research exhibits limited diversity in topological interlocking designs, with many studies lacking detailed descriptions of the geometric profiles of the interlocking bricks and the resultant interlocking effects. This paper introduces a novel design methodology for generating planar and non-planar topological interlocking bricks with curved interfaces. The proposed approach focuses on designing flexible key curved interfaces, allowing for precise control over curvature and adaptability to various base polygon patterns. The method for planar bricks is firstly developed by selecting a base polygon and designing curved interfaces to shape the interlocking brick. This approach is then further developed for non-planar bricks by creating rotated curved interfaces in the circumferential direction, and trapezoidal curved interfaces in the longitudinal direction. Additionally, a parameter FlexiCurve is introduced to control the rate of curvature and the profile of interface. The effectiveness and adaptability of the proposed approach are validated through the demonstration of both planar and non-planar interlocking bricks with square, hexagonal, and octagonal base patterns, along with the investigation of the effect of FlexiCurve on the interface curvature.},
  archive      = {J_MATDES},
  author       = {Maliheh Tavoosi Gazkoh and Xiaoshan Lin and Annan Zhou},
  doi          = {10.1016/j.matdes.2025.113844},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113844},
  shortjournal = {Mater. Des.},
  title        = {Innovative approach for designing topological interlocking bricks with precise morphological representation and controlled interface curvature},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nanospikes combined with liquid-like polymer coating
deliverable microparticles to improve dispersion and biofouling
resistance. <em>MATDES</em>, <em>253</em>, 113843. (<a
href="https://doi.org/10.1016/j.matdes.2025.113843">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A wide range of implantable microparticles has been developed for the detection, diagnosis, and treatment of various diseases. However, the risk of complications, such as inflammation, is significantly heightened by undesirable biofouling caused by biological substances, including protein adsorption, bacterial colonization, and cell adhesion. Although slippery lubricant-infused porous substrates (SLIPS) have demonstrated remarkable resistance to biofouling, concerns regarding the safety of their degradation by-products and the stability of lubricants in fluid environments limit their applicability. In this study, we present a novel ‘liquid-like’ coating polydimethylsiloxane (PDMS) brush-modified implantable microparticles that exhibit enhanced stability and durability against biofouling. Our design incorporates both physical nanospikes and chemical PDMS brushes on the surface of microparticles. This modification results in an increased hydrophobicity of the particles while promoting attractive interactions between the ‘liquid-like’ coated surfaces across different microparticle types. The presence of nanospikes facilitates a specific dispersion pattern among PDMS-modified spiky microparticles (PMSMP). The ‘liquid-like’ coating demonstrates reliable biocompatibility and significantly reduces adhesion rates for proteins (1/60), bacteria (1/56), and cells (1/20), maintaining its efficacy over extended periods (&gt;7 days). Our research introduces a groundbreaking anti-biofouling modification technology for deliverable microparticles, offering promising potential implications for developing devices or materials aimed at mitigating inflammation.},
  archive      = {J_MATDES},
  author       = {Chengduan Yang and Baoming Liang and Shu Zhang and Yao Shen and Cheng Yang and Ziqi Liu and Xiangling Li and Xi Xie and Fanmao Liu and Guozhi Huang and Ji Wang and Hui-jiuan Chen},
  doi          = {10.1016/j.matdes.2025.113843},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113843},
  shortjournal = {Mater. Des.},
  title        = {Nanospikes combined with liquid-like polymer coating deliverable microparticles to improve dispersion and biofouling resistance},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultrasound-driven piezoelectric hydrogel enhances
schwann/neural stem cells co-transplantation for spinal cord injury
repair. <em>MATDES</em>, <em>253</em>, 113842. (<a
href="https://doi.org/10.1016/j.matdes.2025.113842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spinal cord injury (SCI) remains a formidable clinical challenge due to the central nervous system’s limited regenerative capacity and the hostile microenvironment characterized by impaired axonal regeneration. Emerging therapeutic strategies employing co-transplantation of neural stem cells (NSCs) and Schwann cells (SCs) have shown promise through dual mechanisms of cellular replacement and neurotrophic factor delivery. However, suboptimal cell survival, incomplete neuronal differentiation, and the lack of endogenous electrophysiological cues persistently undermine therapeutic outcomes. To address these limitations, we developed an innovative piezoelectric hydrogel-based platform integrating ultrasound-driven bioelectrical stimulation with three-dimensional cellular co-delivery. This system leverages the unique properties of piezoelectric hydrogels to generate localized electrical fields under non-invasive ultrasound actuation, while simultaneously serving as a biomimetic scaffold for NSCs/SCs co-culture. In vitro analyses revealed that the piezoelectric stimulation significantly enhanced neuronal differentiation efficiency and promoted robust remyelination. In murine models of complete spinal cord transection, the synergistic system demonstrated multifaceted therapeutic effects: 1) enhanced NSCs-derived neuron survival, 2) increased synaptic density, and 3) accelerated motor function recovery. These findings establish a paradigm-shifting approach that orchestrates biophysical (electrical) and biochemical (cellular) regulatory cues to reconstruct spinal cord circuitry, offering new insights into developing multimodal neuroregenerative therapies for SCI.},
  archive      = {J_MATDES},
  author       = {Haifeng Wang and Wencan Zhang and Yiming Ren and Jincheng Lu and Shen Liu and Liang Liu and Peng Zhang and Zhijian Wei and Dachuan Wang and Liang Chen},
  doi          = {10.1016/j.matdes.2025.113842},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113842},
  shortjournal = {Mater. Des.},
  title        = {Ultrasound-driven piezoelectric hydrogel enhances schwann/neural stem cells co-transplantation for spinal cord injury repair},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exosome coated with prussian blue mediated microglial
polarization for spinal cord injury. <em>MATDES</em>, <em>253</em>,
113841. (<a href="https://doi.org/10.1016/j.matdes.2025.113841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The surge in reactive oxygen species (ROS) and inflammation after acute spinal cord injury (SCI) is a key factor in making this injury irreversible. How to intervene effectively is the basis of therapeutic strategy design. In our study, we explored the potential of Prussian blue nanase, which has catalase and superoxide dismutase-like activity. However, given their high immunogenicity, we chose to leverage the low immunogenicity and biosafety of exosomes to enhance the delivery of these nanase. Recognizing the prevalence of M1 microglia in local inflammation, we used exosomes derived from bone marrow mesenchymal stem cells (BMSCs) as vectors. These exosomes are further modified with hyaluronic acid (HA) to form nanoplatforms (EXO/PB) that specifically target inflammation. HA binding enables EXO/PB to locate on M1 microglia, promoting ROS clearance and facilitating the transition from M1 phenotype to M2 phenotype. Our results show that EXO/PB not only targets M1 microglia, but also leverages the ROS clearance capabilities of Prussian blue nanozymes to influence this phenotypic transition. Finally, EXO/PB provides a new therapeutic strategy for the treatment of acute spinal cord injury.},
  archive      = {J_MATDES},
  author       = {Jinpeng Gao and Chuanjie Zhang and Jiyu Zhao and Qingbo Guo and Dake Wang and Zhenkun Fu and Sen Lin and Xifan Mei and Shurui Chen},
  doi          = {10.1016/j.matdes.2025.113841},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113841},
  shortjournal = {Mater. Des.},
  title        = {Exosome coated with prussian blue mediated microglial polarization for spinal cord injury},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prussian blue nanohybrid hydrogel combined with specific
far-infrared based on graphene devices for promoting diabetic wound
healing. <em>MATDES</em>, <em>253</em>, 113839. (<a
href="https://doi.org/10.1016/j.matdes.2025.113839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic wounds are difficult to treat in nature due to their distinct pathophysiological characteristics, such as inflammation and/or oxidative stress, which offers an opportunity to employ nanozymes. However, nanozymes may cause safety concerns regarding the balance between enzymatic activity and cytotoxicity, as well as unclear metabolic pathways when used as free nanoparticles. To address this issue, we developed a Prussian blue nanohybrid hydrogel by pre-coupling of polymer materials and inorganic nanomaterials via covalent bond, improving the stability of the organic–inorganic interface as well as nanozymes within the nanohybrid hydrogel. The nanohybrid hydrogel retained the enzymatic activities of Prussian blue nanoparticles, and its enzymatic activities displayed temperature-dependent characteristics when in proximity to physiological temperature. In light of this, we combined graphene-based far-infrared photothermal therapy with nanohybrid hydrogel materials, in order to promote wound healing by thermal effects and improved enzymatic activity. Animal experiments demonstrated that this combination significantly accelerates diabetes wound healing, alleviating wound inflammatory responses, and promote collagen deposition and neovascularization. This innovative approach holds considerable promise for advancing the therapeutic potential of diabetic wound healing and offers new avenues for the development of next generation wound healing treatments.},
  archive      = {J_MATDES},
  author       = {Tingting Yu and Jiamin Zhang and Junwei Lai and Manjiao Deng and Ziying Zhou and Zhanbin Xia and Caiying Zhong and Xinyue Feng and Yimin Hu and XuRan Guo and Wei Wei and Weichen Gao and Yi Zhang and Zhaobin Guo and Ke Hu},
  doi          = {10.1016/j.matdes.2025.113839},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113839},
  shortjournal = {Mater. Des.},
  title        = {Prussian blue nanohybrid hydrogel combined with specific far-infrared based on graphene devices for promoting diabetic wound healing},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiscale investigation of hardening behavior in
dispersoid-modified AlZnMg alloys. <em>MATDES</em>, <em>253</em>,
113838. (<a href="https://doi.org/10.1016/j.matdes.2025.113838">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While dispersoid-modified Al–Zn–Mg alloys have improved thermal stability compared to their unmodified variants, they generally exhibit a reduced age-hardening potential. In the current work, Al–Zn–Mg alloys with Hf and Zr additions below 1 wt% were systematically studied with respect to the influence of the induced Hf–Zr-rich Al 3 X dispersoids on the Mg–Zn precipitation hardening response. A multiscale analysis was applied using correlative instrumented indentation, electron microscopy and atom probe tomography to derive the microstructure-property relationships in these alloys, with a focus on the precipitation behavior during the aging process. The results are compared to a reference dispersoid-free Al–Zn–Mg alloy subjected to the same aging treatment. A heterogeneous microstructure consisting of dispersoid-rich dendritic regions surrounded by dispersoid-free interdendritic regions was identified, with coarser Mg–Zn precipitation in the former. Via indentation mapping, we show that these local composition gradients correlate with spatial fluctuations in hardness. Related quantitative analysis indicates that the observed reduced macroscopic hardening potential during a 140 °C aging treatment of the dispersoid-modified alloys results from the coarser precipitates in the dispersoid-rich regions.},
  archive      = {J_MATDES},
  author       = {Viktor Wessely and Indranil Basu and Jeffrey M. Wheeler and Robin E. Schäublin and Ueli Töpfer and Stephan S.A. Gerstl and Stefan Pogatscher and Peter J. Uggowitzer and Jörg F. Löffler},
  doi          = {10.1016/j.matdes.2025.113838},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113838},
  shortjournal = {Mater. Des.},
  title        = {A multiscale investigation of hardening behavior in dispersoid-modified AlZnMg alloys},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the effect of scan strategies on the
structure-property relationship in electron beam powder bed fusion
processed 316L stainless steel. <em>MATDES</em>, <em>253</em>, 113837.
(<a href="https://doi.org/10.1016/j.matdes.2025.113837">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different electron beam path patterns realized in eight varying scanning strategies were adopted in an electron beam powder bed fusion machine to understand the effect of scan patterns on the microstructure and mechanical properties of 316L austenitic stainless steel. Results showed that variation in localized microstructure is principally determined by the beam path length and the extent of melting-remelting cycles. Sporadic dislocation sub-structures were observed in scan strategies where thermal conditions were more turbulent than the reference raster scan, eventually leading to a different mechanical response despite their lower measured densities. Average yield strength and ultimate tensile strength surpassed the conventionally produced and subsequently annealed 316L; and were very close to the standards set forward for nuclear applications. This therefore opens up the possibility of using different scan strategies in an electron beam powder bed fusion system that can exploit the scan path design freedom and achieve localized microstructural and property differences. A proof-of-concept scaled-down version of an industrial component was fabricated with varying scan patterns at different areas and mechanically tested to showcase the feasibility of the presented approach.},
  archive      = {J_MATDES},
  author       = {Prithwish Tarafder and Jinghao Xu and Anton Wiberg and Johan Moverare},
  doi          = {10.1016/j.matdes.2025.113837},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113837},
  shortjournal = {Mater. Des.},
  title        = {Assessing the effect of scan strategies on the structure-property relationship in electron beam powder bed fusion processed 316L stainless steel},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electric pulse improving the plasticity of the HAl66-6-3-2
alloy by promoting the formation of specific oriented texture.
<em>MATDES</em>, <em>253</em>, 113836. (<a
href="https://doi.org/10.1016/j.matdes.2025.113836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric pulse treatment (EPT) effectively enhances material plasticity but typically compromises strength, and the combined mechanisms of pulsed current on dislocation evolution and grain rotation remain unclear. Here, HAl66-6–3-2 alloy was subjected to EPT, and the results revealed that the EPT sample achieved an increase in plasticity without compromising the strength, with an elongation rate enhancement of 69.89 %. The changes in performance are mainly attributed to three aspects: grain refinement, slight decrease in dislocation density, and the formation of strong {632}&lt;223&gt; texture during the EPT. Unlike the untreated (UT) samples with entangled dislocations, under the coupling effect of Joule heating and non-thermal effect, the dislocations in EPT samples exhibited directionality, primarily composed of a series of parallel dislocation pairs. The formation of the strong {632}&lt;223&gt; texture primarily relied on grain boundary migration and grain rotation, with both Joule heating and non-thermal effect facilitating rapid grain boundary migration. At low-angle grain boundaries, the pulsed current facilitated grain rotation, transforming low-angle grain boundaries in the β phase into high-angle grain boundaries. The study demonstrates EPT can promote the movement of atoms and regulate the microstructure, which is of great significance for the subsequent control of alloy properties.},
  archive      = {J_MATDES},
  author       = {Bobo Lu and Kai Tang and Mingxia Wu and Yi Yang and Gang Yang},
  doi          = {10.1016/j.matdes.2025.113836},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113836},
  shortjournal = {Mater. Des.},
  title        = {Electric pulse improving the plasticity of the HAl66-6-3-2 alloy by promoting the formation of specific oriented texture},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing nanoscale coherent double-solid-solution
interfaces between non-reactive mg and steel alloys. <em>MATDES</em>,
<em>253</em>, 113834. (<a
href="https://doi.org/10.1016/j.matdes.2025.113834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving coherent interface matching between immiscible Mg and Fe alloys is a significant challenge due to significant differences in their lattice constants and structures. Although the introduction of a third element into the interfacial metallurgical reaction has been explored before, it has been difficult to avoid the formation of brittle intermetallic compounds with poor mechanical properties. This study presents a groundbreaking method that, for the first time in published literature, leverages in-situ Ni alloying with a flexible laser-arc hybrid heat source to create an exceptionally high-performing nanoscale double solid solution interface between immiscible Mg and Fe alloys. This processing approach enables the high metallurgical reaction temperatures required for immiscible and nonreactive systems. The resulting lattice formation, driven by localized elemental diffusion at elevated interfacial temperatures, fosters adaptive coherent matching across the entire Mg-Fe interface. This process successfully transforms the non-coherent lattice that is generally observed at the Mg/Fe interface into a coherent double solid solution interface with the bulk matrix on both sides, significantly enhancing bonding efficiency and performance. This study provides detailed advanced characterization of the nanoscale double solid solution structures observed at the interfaces of these immiscible dissimilar metals which has been previously unexplored in the literature.},
  archive      = {J_MATDES},
  author       = {Qiang Lang and Taotao Li and Muhammad Shehryar Khan and Gang Song and Liming Liu},
  doi          = {10.1016/j.matdes.2025.113834},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113834},
  shortjournal = {Mater. Des.},
  title        = {Characterizing nanoscale coherent double-solid-solution interfaces between non-reactive mg and steel alloys},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of carbon on the rheology and additive
manufacturability of ti-6Al-4V powders. <em>MATDES</em>, <em>253</em>,
113833. (<a href="https://doi.org/10.1016/j.matdes.2025.113833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of this work was to determine the effect of carbon blending on powder-part properties of titanium alloy Ti-6Al-4V. To assess this, carbon blends of both grade 5 and grade 23 from 0.1-1.0 wt% C were prepared. Part printability using laser powder bed fusion (LPBF) was assessed by measuring the segregation, flowability, rheology, and spreadability of the powder. Blend quality was assessed chemically and visually via computed tomography and scanning electron microscopy. Carbon blends above 0.25 wt% C produced significant segregation of carbon particles. Agglomerated carbon segregates acted as barriers to flow causing the reduction in dynamic flow by 40–60% compared to the virgin powders. High carbon contents also limited powder spreadability by promoting large streaks during powder spreading. Below 0.25 wt% C, the deleterious effects of segregation, flowability, and spreadability were reduced and the powder characteristics were comparable to the processable virgin powders. Printed parts exhibited very small effect of carbon blending on the density and micro-hardness of the material. The grade 23 powder is more suitable for carbon blending and offers the highest part densities and lowest variation in material hardness. This is attributed to lesser carbon agglomeration, better powder flow, and fewer interstitial elements.},
  archive      = {J_MATDES},
  author       = {Apratim Chakraborty and Manvinder Lalh and Étienne Martin and Heidar Karimialavijeh and Adam Bejarano and Andrew Wessman and Yu Zou and Mahdi Habibnejad-Korayem},
  doi          = {10.1016/j.matdes.2025.113833},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113833},
  shortjournal = {Mater. Des.},
  title        = {Influence of carbon on the rheology and additive manufacturability of ti-6Al-4V powders},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intravitreal injection of TA-III with sustained release to
simultaneously impart anti-inflammatory, antioxidative, and vascular
remodeling activities in diabetic retinopathy. <em>MATDES</em>,
<em>253</em>, 113832. (<a
href="https://doi.org/10.1016/j.matdes.2025.113832">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes negatively impacts vision and retinal function. However, current therapeutic options for diabetic retinopathy (DR) often present limitations, including targeting specific pathways, short duration of action, and need for frequent injections. Timosaponin AIII (TA-III) exhibited the potential of anti-inflammation, anti-oxidative stress and promoting vascular remodeling abilities from bioinformatics analysis tool. Additionally, polyethylene glycol succinimide succinate [PEG-(SS) 2 ]-human serum albumin (HSA) (Hp) hydrogel, known for its excellent biocompatibility and sustained drug release properties, was employed to encapsulate TA-III to exhibit a long-acting, sustained release profile. In vitro results demonstrated that the TA-III/Hp hydrogel upregulated the expression of vascular endothelial growth factor receptor 2 and zonula occludens-1, while reducing the level of vascular endothelial growth factor A. We further observed a significant reduction in the levels of reactive oxygen species, malondialdehyde, interleukin-1β, interleukin-6, and tumor necrosis factor-α under high glucose conditions by using the TA-III/Hp hydrogel in retinal pigment epithelium cells. Notably, intravitreal delivery of TA-III/Hp hydrogel in the DR mouse model effectively increased retinal thickness and numbers of mature blood vessels, while inhibiting oxidative stress and inflammatory factor levels. In conclusion, intravitreal injection of TA-III/Hp hydrogel facilitates sustained release of TA-III, simultaneously providing anti-inflammatory, antioxidative, and vascular remodeling effects in DR.},
  archive      = {J_MATDES},
  author       = {Jie Zhang and Yu Liu and Yu Gong and Yanyu Shangguan and Pengli Wang and Yanlong Bi and Yong Xu and Bo Tao and Bing Li},
  doi          = {10.1016/j.matdes.2025.113832},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113832},
  shortjournal = {Mater. Des.},
  title        = {Intravitreal injection of TA-III with sustained release to simultaneously impart anti-inflammatory, antioxidative, and vascular remodeling activities in diabetic retinopathy},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-performing TiAl alloy with lamellar-network two-scale
structure via semi-solid forging and its non-equilibrium solidification
mechanism. <em>MATDES</em>, <em>253</em>, 113828. (<a
href="https://doi.org/10.1016/j.matdes.2025.113828">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {TiAl alloys are lightweight, high-strength, and have good mechanical properties at elevated temperatures, rendering them appealing for high-temperature applications. However, their difficult processing, and limited ductility at ambient temperatures have hindered their widespread application. Here, we report fabrication of a Ti-43Al-9 V-0.3Y alloy with a novel lamellar-network two-scale structure comprising an inner α 2 /γ lamellar colony + outer β 0 /γ phases via semi-solid forging process. The formation of this lamellar-network two-scale structure is elucidated from the perspective of the solute diffusion and redistribution occurring, and occurs due to liquid segregation and a non-equilibrium transition of L → β(β 0 ) + α at late solidification. Compared to the as-cast alloy, the semi-solid forged alloy exhibits significant increases in elongation and tensile strength at room temperature and 800°C. The high density of dislocations and mechanical twins in the β 0 /γ phases and special α 2 /γ lamellae during tensile deformation effectively release the plastic deformation potential of the TiAl alloy at room temperature. Moreover, the abundant nano-twins in the β 0 /γ phase and γ dynamic recrystallization behavior at 800 ℃ significantly enhance the high-temperature plasticity. This approach and microstructure offer a promising solution to the engineering challenges posed by the low room-temperature ductility and limited hot-working ability of TiAl alloys.},
  archive      = {J_MATDES},
  author       = {Yuan Ye and Yuyong Chen and Yu Zhang and Shuzhi Zhang and Jianfei Sun},
  doi          = {10.1016/j.matdes.2025.113828},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113828},
  shortjournal = {Mater. Des.},
  title        = {High-performing TiAl alloy with lamellar-network two-scale structure via semi-solid forging and its non-equilibrium solidification mechanism},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design, optimization, and validation of a magnetic
mother-child robot system for targeted drug delivery. <em>MATDES</em>,
<em>253</em>, 113827. (<a
href="https://doi.org/10.1016/j.matdes.2025.113827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional untethered magnetic microrobots utilized for in vivo targeted drug delivery face challenges related to poor maneuverability and limited kinematic performance. In this study, we harness the strengths of both magnetic continuum robots (acting as “mother” units) and untethered microrobots (functioning as “child” units), refining the motion model to develop a magnetically driven mother–child robotic system. We have also enhanced the structural design of the magnetic continuum and optimized the batch fabrication process of pH-responsive hydrogel integrated with the microrobots. This design allows the child robots to be deployed by the mother unit and subsequently retrieved upon task completion. Our strategy, which aims to minimize foreign body presence and reduce side effects, was validated using an in vitro gastric model, demonstrating the feasibility and enhanced operability of this system.},
  archive      = {J_MATDES},
  author       = {Bentao Zou and Huibin Liu and Xuehao Fen and Zhizheng Gao and Zhixing Ge and Wenguang Yang},
  doi          = {10.1016/j.matdes.2025.113827},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113827},
  shortjournal = {Mater. Des.},
  title        = {Design, optimization, and validation of a magnetic mother-child robot system for targeted drug delivery},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the microstructure and dynamic mechanical behavior of
cu–cr–zr alloy manufactured by high-power laser powder bed fusion.
<em>MATDES</em>, <em>253</em>, 113826. (<a
href="https://doi.org/10.1016/j.matdes.2025.113826">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores high-power laser powder bed fusion (LPBF) processing of Cu–Cr–Zr alloy, focusing on its high strain rate dynamic mechanical response and microstructural evolution. The alloy undergoes significant strain hardening during dynamic impact loading, primarily attributed to intensified dislocation interactions and multiplication. This is accompanied by thermal softening induced by adiabatic heating, therefore improving strain accommodation. As the strain rate increases from 4400 s −1 to 11300 s −1 , the ultimate compressive strength (UCS) enhances from 173 ± 8 MPa to 489 ± 14 MPa, demonstrating a high strain rate sensitivity (SRS) of ∼ 1. Microstructural examinations reveal that higher strain rates intensify the occurrence of adiabatic shear bands (ASBs), leading to severe localized plastic deformation. These ASBs generate localized stress concentrations, which in turn accelerate crack initiation and propagation through pore formation and coalescence within the ASBs. Despite this severe plastic deformation, texture analysis indicates that the crystallographic texture remains largely stable which suggests that the deformation mechanism is primarily governed by dislocation motion and interaction, rather than by crystal structure reorientation. Overall, the alloy balances strain hardening and strain accommodation at high strain rates, making it well-suited for applications requiring strength and resilience under dynamic impacts.},
  archive      = {J_MATDES},
  author       = {Nadia Azizi and Hamed Asgari and Mahyar Hasanabadi and Akindele Odeshi and Ehsan Toyserkani},
  doi          = {10.1016/j.matdes.2025.113826},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113826},
  shortjournal = {Mater. Des.},
  title        = {On the microstructure and dynamic mechanical behavior of Cu–Cr–Zr alloy manufactured by high-power laser powder bed fusion},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermophysical and microstructural characterization of
ti-6Al-4V in powder and laser powder bed fusion-processed state within
the global temperature field range. <em>MATDES</em>, <em>253</em>,
113823. (<a href="https://doi.org/10.1016/j.matdes.2025.113823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To pave the way for thermophysical modeling and further PBF-LB/M process optimization, the thermophysical properties of Ti-6Al-4V in powder and processed states were investigated using thermo-mechanical analysis, laser flash analysis, and differential scanning calorimetry. Microstructural characterization using SEM, Vickers hardness testing, and XRD facilitated a novel interpretation of the results. The macroscopic density exhibited a linear relationship up to 880 C ∘ , showing only a minor impact from microstructural effects. The evolution of α ′ martensitic microstructure was analyzed by examining linear thermal expansion coefficients indicating direction dependency. During heating, the precipitation and stabilization of β provoke the formation and decomposition of the intermetallic phase, accompanied by a significant increase in hardness and an exothermic event. Additionally, the relaxation of residual stresses and transformation into the β phase determines the microstructural evolution. Thermal diffusivity of as-built Ti-6Al-4V propagates linearly up to 950 C ∘ . For powder, HotDisk measurements corroborate laser flash data obtained up to 850 C ∘ . Based on the LFA, the start of sintering is identified and attributed to a change in the heat transfer mechanism in AM powders. Specific heat capacity and effective thermal conductivity of AM Ti-6Al-4V are determined, highlighting the shortcomings of predicting AM powders&#39; conductivity based on solid materials.},
  archive      = {J_MATDES},
  author       = {J. Rottler and T.K. Tetzlaff and A. Wohninsland and A. Lion and M. Johlitz},
  doi          = {10.1016/j.matdes.2025.113823},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113823},
  shortjournal = {Mater. Des.},
  title        = {Thermophysical and microstructural characterization of ti-6Al-4V in powder and laser powder bed fusion-processed state within the global temperature field range},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient design of voronoi energy-absorbing foams using
bayesian optimization. <em>MATDES</em>, <em>253</em>, 113822. (<a
href="https://doi.org/10.1016/j.matdes.2025.113822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many studies have increasingly focused on developing bio-inspired structures, leveraging their lightweight and high-energy absorption properties, which are crucial across many engineering fields. Structural optimization aiming for bio-inspired structures having superior energy absorption capability, however, has been considered a challenging problem. One of these challenges is that nonlinear material behaviors induced by external forces, such as buckling and self-contact of constituting ligaments, intervene in the energy absorption process. Such nonlinearities not only make the relationship between design changes and energy absorption nonlinear, but also exacerbate the difficulties of design, given the complexity of the ligament configurations. To address this, a novel design optimization method for bio-inspired cellular structures with high energy absorption is proposed. First, Voronoi tessellation is used to capture configurations of bio-inspired material, parameterized by geometric variables. Then, Bayesian optimization with Kriging efficiently updates the design, exploring the complex design space through high-fidelity nonlinear finite element analysis. The proposed design method is efficient in structural optimization as it combines a strategy to reduce the number of samples required for surrogate modeling of structural response and optimal search, but it also generates multiple design outcomes with similar advantages due to the intrinsic variance of the Voronoi structures.},
  archive      = {J_MATDES},
  author       = {Youngtaek Oh and Byungjo Kim and Hayoung Chung},
  doi          = {10.1016/j.matdes.2025.113822},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113822},
  shortjournal = {Mater. Des.},
  title        = {Efficient design of voronoi energy-absorbing foams using bayesian optimization},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computational design of mechanical metamaterials through
misaligned periodic microstructure. <em>MATDES</em>, <em>253</em>,
113819. (<a href="https://doi.org/10.1016/j.matdes.2025.113819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical metamaterials, with their intricately designed microstructures, exhibit properties that are superior to those of natural materials. Computational optimization, which uses finite element analysis of periodic microstructures, enables the design of architected microstructures to achieve desired macroscopic properties. Traditionally, unit cells are defined within cuboidal domains; however, this study extends the design to parallelepiped domains, significantly expanding design possibilities. This study investigates the influence of geometric design domains on the topology optimization of negative Poisson&#39;s ratio (NPR) metamaterials. Using the mathematical homogenization method, unit cells within parallelogram or parallelepiped domains are represented within square or cubic domains under misaligned periodic boundary conditions. This approach enables the manipulation of macroscopic elastic stiffness components while maintaining the solid volume fraction. A comparative analysis was performed to examine the geometric characteristics of optimized microstructures and the resulting macroscopic anisotropy under both standard and misaligned periodic boundary conditions. 3D-printed NPR metamaterials were tested to validate the design. The results demonstrate the effectiveness of the computational design method in generating diverse microstructures with misalignment, opening new avenues for designing NPR metamaterials with enhanced properties.},
  archive      = {J_MATDES},
  author       = {Jiaxin Zhou and Ikumu Watanabe and Keita Kambayashi},
  doi          = {10.1016/j.matdes.2025.113819},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113819},
  shortjournal = {Mater. Des.},
  title        = {Computational design of mechanical metamaterials through misaligned periodic microstructure},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence of continuous annealing on the interfacial
compound evolution and mechanical behavior of hot-rolled titanium/steel
composite plates. <em>MATDES</em>, <em>253</em>, 113818. (<a
href="https://doi.org/10.1016/j.matdes.2025.113818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To investigate the effect of continuous annealing on the interfacial compound evolution and mechanical properties of hot-rolled TA1/St12 composite plates, the hot-rolled composites underwent heat treatments at 850 °C–950 °C for 10 min. The influence of the pre-existing TiC interlayer on interfacial reaction behavior and compound evolution was analyzed, revealing the interfacial bonding and failure mechanisms of the Ti/steel composites. Results show that at annealing temperatures ≤900 °C, the pre-existing TiC layer effectively suppressed the interdiffusion between Fe and Ti, thereby preventing the formation of Fe-Ti phases. The interfacial layer consisted of nanoscale and submicron-scale TiC. During deformation and failure, microcracks were prone to initiate at the nanoscale TiC/steel interface and subsequently propagate towards the nanoscale TiC/submicron-scale TiC interface. At 950 °C, the pre-existing TiC layer at the interface dissolved, and the interfacial compound layer evolved into a mixture of nanoscale TiC, FeTi, and Fe 2 Ti. The FeTi/TiC + Fe 2 Ti and FeTi/Fe 2 Ti interfaces became the primary crack propagation paths, severely degrading the bonding quality of the Ti/steel composite. After annealing at 850 °C, the ductility and deformation compatibility of the Ti/steel composite plate were significantly enhanced, resulting in optimal overall mechanical properties. The ultimate tensile strength, shear strength, and elongation were 286 MPa, 127 MPa, and 44 %, respectively.},
  archive      = {J_MATDES},
  author       = {Zhenxiong Wei and Peng Huang and Qiang Gao and Xixi Su and Zhanhao Feng and Lin Peng and Jun Li and Yonghui Sun and Guoyin Zu},
  doi          = {10.1016/j.matdes.2025.113818},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113818},
  shortjournal = {Mater. Des.},
  title        = {Influence of continuous annealing on the interfacial compound evolution and mechanical behavior of hot-rolled titanium/steel composite plates},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Insight into the nanoscale strengthening mechanism of
polycrystalline iron implanted by cr ions. <em>MATDES</em>,
<em>253</em>, 113814. (<a
href="https://doi.org/10.1016/j.matdes.2025.113814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The strengthening mechanisms of ion implantation remain a challenge for the application on high-performance precision mechanical manufacturing. Based on the molecular dynamics (MD) method, the paper aims to explore the nanoscale mechanisms of the polycrystalline iron implanted by Cr ions. The microstructural evolution under implantation is analyzed, and the mechanical properties of different models under nanoindentation are studied. The results show that the ion implantation reduces surface roughness while enhancing both Young’s modulus and hardness. The increase in hardness arises from Cr atoms and interstitials obstructing dislocation propagation and the inverse Hall-Petch effect, which works by transforming the deformation from being grain boundary-dominated to dislocation-dominated. The role of grain boundaries (GBs) in ion implantation and deformation are analyzed by the molecular statics method and atomic displacement field. It is found that GB sites have lower point defect formation energy than the bulk and GB atoms first participate in plastic deformation. Additionally, the interactions between dislocations and GBs are investigated. This article provides an innovative research approach for exploring the nanoscale strengthening mechanisms of ion implantation by MD method.},
  archive      = {J_MATDES},
  author       = {Tingting Jiang and Jinyuan Tang and Jiuyue Zhao and Yihao Ling and Yelin Zeng},
  doi          = {10.1016/j.matdes.2025.113814},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113814},
  shortjournal = {Mater. Des.},
  title        = {Insight into the nanoscale strengthening mechanism of polycrystalline iron implanted by cr ions},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stackable 3D-printed core-shell nozzle system for
multi-shell fiber and microdroplet generation. <em>MATDES</em>,
<em>253</em>, 113807. (<a
href="https://doi.org/10.1016/j.matdes.2025.113807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microfluidics is increasingly utilized in biofabrication to create more complex fiber and droplet structures, including those that involve multiple materials. Layered and core-multiple shell structures are of particular interest as templates for biofabrication and cell growth. Traditional fabrication methods often rely on fixed coaxial, triaxial or quadaxial needles, which are costly and prone to clogging, particularly for smaller inner diameters. Here, we introduce a versatile system based on a 3D printed nozzle which combines two flows: an inner core- and an outer shell-flow. The outlet is fitted with a glass capillary, allowing control of the fiber diameter by adjusting the capillary. The design facilitates the modular “LEGO®-Brick” stacking of multiple nozzles, enabling the efficient fabrication of complex fibers. We demonstrate the production of alginate (Alg)-methyl cellulose (MC) composite fibers with variable diameters. Additionally, when the shell was filled with an oil phase and the core with a water phase, microdroplets with controlled diameters were effectively generated. The two-flow system also enables the extrusion of graphene oxide (GO)-based fibers and microbeads, which are widely-used structures in various applications. To demonstrate the capability of the designed nozzle for biofabrication, C2C12 cell-laden GO-based fibers and microbeads were fabricated, exhibiting excellent post-fabrication cell viability.},
  archive      = {J_MATDES},
  author       = {Jianfeng Li and Peer Fischer},
  doi          = {10.1016/j.matdes.2025.113807},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113807},
  shortjournal = {Mater. Des.},
  title        = {Stackable 3D-printed core-shell nozzle system for multi-shell fiber and microdroplet generation},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Elucidating structure-property relationships for
optimization of plate lattice sound absorbers. <em>MATDES</em>,
<em>253</em>, 113801. (<a
href="https://doi.org/10.1016/j.matdes.2025.113801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To be compatible with mainstream additive manufacturing techniques, plate lattices must be designed with embedded pores to eliminate closed cells and facilitate material removal. Interestingly, these pores also transform the plate lattices into effective acoustic absorbers, with structures resembling Helmholtz resonators. In this work, the sound absorption performance of plate lattices inspired by crystal structures was investigated, with small perforations at nodes introduced as a design feature to facilitate feedstock material removal and allow acoustic energy to penetrate the structure. Calibrated through numerous additively manufactured samples, a high-fidelity mathematical model, grounded in Helmholtz resonance principles and the Transfer Matrix Method, was developed to accurately predict the acoustic properties of plate lattices across a broad range of frequencies from 450 to 6300 Hz. The model not only effectively predicts sound absorption coefficient curves based on geometric parameters but also provides valuable insights into how these parameters influence acoustic performance. It is found that smaller cell sizes, higher relative densities, and reduced perforation sizes generally result in higher mean sound absorption coefficients. The frequency bands of peak absorption regions are then strongly affected by the perforation size relative to the cell size. Furthermore, an optimization framework leveraging the model generated heterogeneous plate lattice designs with superior broadband sound absorption at targeted frequency ranges. This work introduces a robust mathematical approach for predicting and optimizing the acoustic properties of perforated plate lattices while uncovering key structural-property relationships that drive their performance.},
  archive      = {J_MATDES},
  author       = {Jun Wei Chua and Wei Zhai and Xinwei Li},
  doi          = {10.1016/j.matdes.2025.113801},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113801},
  shortjournal = {Mater. Des.},
  title        = {Elucidating structure-property relationships for optimization of plate lattice sound absorbers},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantification and evaluation of strain reduction from
small-bubble gas injection in spallation neutron source target vessels.
<em>MATDES</em>, <em>253</em>, 113797. (<a
href="https://doi.org/10.1016/j.matdes.2025.113797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small-bubble gas injection has been routinely utilized in the operation of Spallation Neutron Source (SNS) mercury targets since 2017 to mitigate cavitation-induced erosion damage to target vessels. Strain measurements of target vessels collected in-situ during initial operation with gas injection were used to study the gas injection effect on the structural response of targets to proton pulses. A significant strain reduction owing to gas injection was found by comparing the strain measurement data during operation with and without gas injection. The research presented here focuses on quantifying strain reductions in SNS targets and evaluating the effect of small-bubble gas injection by comparing different bubbler types and target designs. The strain measurement results show the gas injection significantly reduced strain in SNS target vessels; strain values decreased by 30% to 80% for targets operating with gas injection. Stress and strain responses of SNS targets were simulated to numerically evaluate the gas injection effect. Based on the predicted stresses with and without gas injection, the fatigue lifetimes of SNS jet-flow design target were estimated using fe-safe fatigue analysis software. The simulations show these reductions should improve the fatigue life of target vessels and allow SNS targets to meet their fatigue design goal.},
  archive      = {J_MATDES},
  author       = {Hao Jiang and Drew E. Winder and David A. McClintock},
  doi          = {10.1016/j.matdes.2025.113797},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113797},
  shortjournal = {Mater. Des.},
  title        = {Quantification and evaluation of strain reduction from small-bubble gas injection in spallation neutron source target vessels},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Property optimized energy absorber for automotive bumpers
utilizing multi-material and structural design strategies.
<em>MATDES</em>, <em>253</em>, 113724. (<a
href="https://doi.org/10.1016/j.matdes.2025.113724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel design for automotive bumper using optimized lattice structures and multi-materials to balance low-speed collision and high-speed pedestrian impact performance. Different blends of 20 % carbon fiber-reinforced acrylonitrile butadiene styrene with thermoplastic polyurethane were used to tailor material properties. The energy absorber features lattice structures with customized mechanical responses, created by varying the incline angle θ from 0 to 180°. We conducted 576 finite element simulations on a half-scale model to optimize energy absorption and stiffness, leading to 66 optimized designs that met both low-speed and high-speed impact criteria. Two sub-scale optimized energy absorbers with different peak forces—both meeting low-speed impact requirements—were 3D printed and validated through drop-weight testing. The one with lower peak stress demonstrated a more compliant response, exhibiting approximately 90 % lower initial peak force and an increase in energy absorption of around 33 % (from 24 J to 32 J). Compared to the baseline triangular lattice, the optimized absorber increased energy absorption by 68 % from (19 J to 32 J) and reduced peak stress by 70 %. It also showed near-complete recovery with minimal fractures, making it suitable for repeated use. This design improves safety while offering a lightweight, durable, and cost-effective bumper system.},
  archive      = {J_MATDES},
  author       = {Komal Chawla and Ahmed Arabi Hassen and Nikhil Garg and Deepak Kumar Pokkalla and Desheng Yao and Tyler Smith and Brittany Rodriguez and Brandon White and X.Rayne Zheng and Ellen C. Lee and H.Felix Wu and Seokpum Kim},
  doi          = {10.1016/j.matdes.2025.113724},
  journal      = {Materials &amp; Design},
  month        = {5},
  pages        = {113724},
  shortjournal = {Mater. Des.},
  title        = {Property optimized energy absorber for automotive bumpers utilizing multi-material and structural design strategies},
  volume       = {253},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="mla---14">MLA - 14</h2>
<ul>
<li><details>
<summary>
(2025). Predicting cyberbullying victimisation in emerging markets
and developing countries using the global school-based health survey.
<em>MLA</em>, <em>20</em>, 100646. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives This study aimed to identify predictors of cyberbullying victimisation among adolescents and develop predictive models to support early intervention strategies. Methods Data from the Global School-based Health Surveys (2017–2021) were analysed, focusing on emerging markets and developing countries. A simple random sampling strategy was used to ensure equal representation across countries. A multivariable logistic regression model was applied to 26 variables to identify significant predictors of cyberbullying victimisation. Subsequently, machine learning techniques were used to develop predictive models. Results This logistic regression model was statistically significant ( χ2(26)=507.96, p &lt; 0 .001 ), explaining 19.3 % of the variance with an AUROC of 0 .758 (95 % CI, 0.739 to 0.778) . Twelve variables, including being bullied on school property, female gender, peer victimisation, early sexual debut, alcohol consumption, and suicidal ideation, were identified as significant predictors. The best-performing predictive model, a randomly over-sampled random forest classifier, achieved 82 % accuracy and an AUROC of 0 .83 (95 % CI, 0.81 to 0.85) . Conclusions The study highlights key predictors of cyberbullying victimisation and demonstrates the potential of machine learning in developing accurate predictive models. However, reliance on self-reported data may introduce biases. Future research could integrate diverse data sources to enhance model accuracy and reliability.},
  archive      = {J_MLA},
  author       = {Paulo Ricardo Vieira Braga and Katie Rose Tyrrell},
  doi          = {10.1016/j.mlwa.2025.100646},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100646},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predicting cyberbullying victimisation in emerging markets and developing countries using the global school-based health survey},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning based risk analysis and predictive modeling
of structure fire related casualties. <em>MLA</em>, <em>20</em>, 100645.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analysed over 48,000 reported structure fire incidents in Oregon that occurred from January 2012 through August 2023. The dataset includes 2136 fires that led to civilian casualties including 317 confirmed fatalities. Bagged decision tree classifiers with random forest algorithm were used to quantify the importance of factors related to socioeconomic conditions, population characteristics, structural and behavioral incident details, and local infrastructure on the severity of injuries. Our results show that the age of victims, fire service response times, and availability of working smoke or fire detectors were among the most important parameters for predicting fatal outcomes of structure fires. Furthermore, a predictive Bayesian regularized neural network ensemble classifier was developed to model the severity of casualties and project a spatial risk classification on the census block level. The network model achieves a prediction accuracy of 92.5 % for the classification of structural fire-related casualty severities. With information aggregated to the census block scale and information related to specific fire incidents removed, the retrained model based solely on spatially available data reaches an 87.6 % severity classification accuracy. As the first statewide analysis of its kind, our spatial assessment provides a useful tool for resource allocation, risk factor reduction, and safety education efforts targeted to reduce the number of serious injuries or fatalities from structure fires.},
  archive      = {J_MLA},
  author       = {Andres Schmidt and Eric Gemmil and Russ Hoskins},
  doi          = {10.1016/j.mlwa.2025.100645},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100645},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning based risk analysis and predictive modeling of structure fire related casualties},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal risk mapping of statewide weather-related
traffic crashes: A machine learning approach. <em>MLA</em>, <em>20</em>,
100642. (<a href="https://doi.org/10.1016/j.mlwa.2025.100642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving transportation safety statewide is key in upholding a state&#39;s economy. However, weather-related crashes, known to be one of the most severe types of crashes, poses a threat to this as lots of money is lost to lives and property damage. The goal of this study is to employ machine learning (ML) to develop a workflow on which weather-related crash risk can be better identified, predicted, and interpreted. Central to this workflow, the effects of spatiotemporal heterogeneity of weather-related crashes are studied. To demonstrate the workflow, weather-related crash events in the state of North Carolina were used. Space-time cubes were created using an optimized 5 mi x 5mi grid size and 1-month time aggregation. Equivalent property damage only (EPDO) scores were computed for each space-time cube to create a risk metric that combines both crash frequency and severity. A two-layered technique was employed for identifying and labelling crash risk zones. Subsequently, XGBoost model was used to predict crash risk zones and identify factors associated with the different risk levels. SHapley Additive exPlanations (SHAP), an explainable AI (XAI) tool, was used to interpret the model and examine the relationship between the explanatory variables and the outcome. Per the results, there are three optimal clusters with distinct variability of the impact of weather conditions that constitute the crash risk levels in the study area. The workflow can be used by transportation safety units within state departments of transportation (DOTs) to evaluate different safety risk levels, and the potential high-risk zones can be flagged for devising countermeasures (i.e., proactive risk mitigation strategies).},
  archive      = {J_MLA},
  author       = {Abimbola Ogungbire and Srinivas S. Pulugurtha},
  doi          = {10.1016/j.mlwa.2025.100642},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100642},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Spatiotemporal risk mapping of statewide weather-related traffic crashes: A machine learning approach},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based identification of precipitation clouds
from all-sky camera data for observatory safety. <em>MLA</em>,
<em>20</em>, 100640. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For monitoring the night sky conditions, wide-angle all-sky cameras are used in most astronomical observatories to monitor the sky cloudiness. In this manuscript, we apply a deep-learning approach for automating the identification of precipitation clouds in all-sky camera data as a cloud warning system. We construct our original training and test sets using the all-sky camera image archive of the Iranian National Observatory (INO). The training and test set images are labeled manually based on their potential rainfall and their distribution in the sky. We train our model on a set of roughly 2445 images taken by the INO all-sky camera through the deep learning method based on the EfficientNet network. Our model reaches an average accuracy of 99% in determining the cloud rainfall’s potential and an accuracy of 96% for cloud coverage. To enable a comprehensive comparison and evaluate the performance of alternative architectures for the task, we additionally trained three models—LeNet, DeiT, and AlexNet. This approach can be used for early warning of incoming dangerous clouds toward telescopes and harnesses the power of deep learning to automatically analyze vast amounts of all-sky camera data and accurately identify precipitation clouds formations. Our trained model can be deployed for real-time analysis, enabling the rapid identification of potential threats, and offering a scaleable solution that can improve our ability to safeguard telescopes and instruments in observatories. This is important now that numerous small- and medium-sized telescopes are increasingly integrated with smart control systems to reduce manual operation.},
  archive      = {J_MLA},
  author       = {Mohammad H. Zhoolideh Haghighi and Alireza Ghasrimanesh and Habib Khosroshahi},
  doi          = {10.1016/j.mlwa.2025.100640},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100640},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Deep learning-based identification of precipitation clouds from all-sky camera data for observatory safety},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software engineering meets legal texts: LLMs for auto
detection of contract smells. <em>MLA</em>, <em>20</em>, 100639. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although there have been many major advances in Artificial Intelligence including its application to a wide variety of tasks, some specialized domains remain difficult to tackle. In this work, we examine parallels between software engineering and legal contract drafting and analysis. Porting well-known code smells principles to various legal contracts, we introduce ”contract smells,” text patterns that are indicative of potentially significant issues within contractual agreements. We leverage semi-auto labeling with GPT-4, prompting and expert spot checks, to create datasets for suitability testing of auto detection of these contract smells. Using transformer-based models, we explore the impact of legal domain knowledge, hyperparameters fine tuning and specific task information on detection success. We achieve high accuracy with further fine-tuning of BERT as well as LEGAL-BERT, while more consistent results were achieved using task-specific data. We further demonstrate that although multi-class detection can boost coverage of rare smells, single-class detection yields better accuracy. While this is an initial foray into the idea of contract smells, this work underscores the feasibility of applying advanced NLP techniques and LLMs to automate aspects of legal contract review, suggesting a scalable path toward standardized, machine-assisted legal drafting and analysis.},
  archive      = {J_MLA},
  author       = {Moriya Dechtiar and Daniel Martin Katz and Hongming Wang},
  doi          = {10.1016/j.mlwa.2025.100639},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100639},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Software engineering meets legal texts: LLMs for auto detection of contract smells},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-shot generative distribution matching for augmented
RF-based UAV identification. <em>MLA</em>, <em>20</em>, 100638. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the challenge of identifying Unmanned Aerial Vehicles (UAV) using radiofrequency (RF) fingerprinting in limited RF environments. The complexity and variability of RF signals, influenced by environmental interference and hardware imperfections, often render traditional RF-based identification methods ineffective. To address these complications, the study introduces the rigorous use of one-shot generative methods for augmenting transformed RF signals, offering a significant improvement in UAV identification. This approach, when utilizing a distributional distance metric, demonstrates significant promise in low-data regimes, outperforming deep generative methods such as conditional generative adversarial networks (GANs) and variational autoencoders (VAEs). The paper provides a theoretical guarantee for the effectiveness of one-shot generative models in augmenting limited data, setting a precedent for their application in limited RF environments. This research also contributes to learning techniques in low-data regime scenarios, which may include complex sequences beyond images and videos. The code and links to datasets used in this study are available at https://github.com/amir-kazemi/uav-rf-id .},
  archive      = {J_MLA},
  author       = {Amir Kazemi and Salar Basiri and Volodymyr Kindratenko and Srinivasa Salapaka},
  doi          = {10.1016/j.mlwa.2025.100638},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100638},
  shortjournal = {Mach. Learn. Appl.},
  title        = {One-shot generative distribution matching for augmented RF-based UAV identification},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid oversampling technique for imbalanced pattern
recognition: Enhancing performance with borderline synthetic minority
oversampling and generative adversarial networks. <em>MLA</em>,
<em>20</em>, 100637. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance problems (CIP) are one of the potential challenges in developing unbiased Machine Learning models for predictions. CIP occurs when data samples are not equally distributed between two or multiple classes. Several synthetic oversampling techniques have been introduced to balance the imbalanced data by oversampling the minor samples. One of the potential drawbacks of existing oversampling techniques is that they often fail to focus on the data samples that lie at the border point and give more attention to the extreme observations, ultimately limiting the creation of more diverse data after oversampling, and that is almost the scenario for most of the oversampling strategies. As an effect, marginalization occurs after oversampling. To address these issues, in this work, we propose a hybrid oversampling technique, named Borderline Synthetic Minority Oversampling and Generative Adversarial Network (BSGAN), by combining the strengths of Borderline-Synthetic Minority Oversampling Technique (SMOTE) and Generative Adversarial Networks (GANs). This approach aims to generate more diverse data that follow Gaussian distributions, marking a significant contribution to the field of Artificial Intelligence. We tested BSGAN on ten highly imbalanced datasets, demonstrating its application in engineering, where it outperformed existing oversampling techniques, creating a more diverse dataset that follows a normal distribution after oversampling.},
  archive      = {J_MLA},
  author       = {Md Manjurul Ahsan and Shivakumar Raman and Yingtao Liu and Zahed Siddique},
  doi          = {10.1016/j.mlwa.2025.100637},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100637},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Hybrid oversampling technique for imbalanced pattern recognition: Enhancing performance with borderline synthetic minority oversampling and generative adversarial networks},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced fault detection in photovoltaic panels using
enhanced u-net architectures. <em>MLA</em>, <em>20</em>, 100636. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault detection in photovoltaic (PV) panels using thermal images remains a significant challenge due to the complexity of thermal patterns, environmental noise, and the subtle nature of anomalies. This paper introduces an advanced deep learning framework that enhances the U-Net architecture by integrating Residual Blocks, Atrous Spatial Pyramid Pooling (ASPP), and Attention Mechanisms. These enhancements collectively improve feature extraction, contextual understanding, and fault localization, addressing the limitations of traditional segmentation approaches and reducing false positives. Extensive experiments demonstrate that the proposed method significantly outperforms all benchmarked algorithms across key segmentation metrics, including standard U-Net, U-Net with ASPP, and DeepLabV3+. Compared to standard U-Net, the proposed model achieves more than a 29% increase in F1-score and a 62% improvement in Intersection over Union (IoU) while reducing segmentation loss by 71%. Its ability to accurately detect faults under challenging conditions establishes the framework as a state-of-the-art solution for real-time PV monitoring. These results demonstrate the effectiveness of the proposed approach in addressing the challenges of PV fault detection, offering a practical and reliable solution for ensuring the operational performance of renewable energy systems.},
  archive      = {J_MLA},
  author       = {Khalfalla Awedat and Gurcan Comert and Mustafa Ayad and Abdulmajid Mrebit},
  doi          = {10.1016/j.mlwa.2025.100636},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100636},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Advanced fault detection in photovoltaic panels using enhanced U-net architectures},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pioneering precision in lumbar spine MRI segmentation with
advanced deep learning and data enhancement. <em>MLA</em>, <em>20</em>,
100635. (<a href="https://doi.org/10.1016/j.mlwa.2025.100635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an advanced approach to lumbar spine segmentation using deep learning techniques, focusing on addressing key challenges such as class imbalance and data preprocessing. Magnetic resonance imaging (MRI) scans of patients with low back pain are meticulously preprocessed to accurately represent three critical classes: vertebrae, spinal canal, and intervertebral discs (IVDs). By rectifying class inconsistencies in the data preprocessing stage, the fidelity of the training data is ensured. The modified U-Net model incorporates innovative architectural enhancements, including an upsample block with leaky Rectified Linear Units (ReLU) and Glorot uniform initializer, to mitigate common issues such as the dying ReLU problem and improve stability during training. Introducing a custom combined loss function effectively tackles class imbalance, significantly improving segmentation accuracy. Evaluation using a comprehensive suite of metrics showcases the superior performance of this approach, outperforming existing methods and advancing the current techniques in lumbar spine segmentation. These findings hold significant advancements for enhanced lumbar spine MRI and segmentation diagnostic accuracy.},
  archive      = {J_MLA},
  author       = {Istiak Ahmed and Md. Tanzim Hossain and Md. Zahirul Islam Nahid and Kazi Shahriar Sanjid and Md. Shakib Shahariar Junayed and M. Monir Uddin and Mohammad Monirujjaman Khan},
  doi          = {10.1016/j.mlwa.2025.100635},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100635},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Pioneering precision in lumbar spine MRI segmentation with advanced deep learning and data enhancement},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-driven predictive modeling of mechanical
properties in diverse steels. <em>MLA</em>, <em>20</em>, 100634. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the application of machine learning (ML) in steel design using a small dataset of various steel grades that include 13 key elements and three critical mechanical properties. Random forest (RF) models were systematically evaluated for their robustness and effectiveness in predicting the stress-strain of steel properties. Moreover, other alternative approaches, such as support vector machines, extreme gradient boosting machines, and artificial neural networks, were also evaluated to ensure that the predictions made by the RF model are as accurate as possible. To assess the bias-variance trade-off, 1-seed and random 100-seeds with 80/20 train/test split, and leave-one-out cross-validation for all datasets were conducted. The results demonstrated that the RF models are accurate and reliable, achieving low bias and variance while delivering predictions comparable to, and in some cases better than, those obtained in studies with larger datasets. The analysis revealed a trade-off between strength and ductility, with elongation negatively correlated with yield strength and ultimate tensile strength. This study highlights the feasibility of using small, realistic datasets to develop effective ML models for predicting mechanical properties in steel design. The methodology can also be readily extended to investigate processing-property relationships in other systems, offering a versatile approach for advancing materials science through data-driven techniques.},
  archive      = {J_MLA},
  author       = {Movaffaq Kateb and Sahar Safarian},
  doi          = {10.1016/j.mlwa.2025.100634},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100634},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning-driven predictive modeling of mechanical properties in diverse steels},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of machine learning for seam profile
identification in robotic welding. <em>MLA</em>, <em>20</em>, 100633.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses critical challenges in automated robotic welding, emphasizing precise weld groove profiling for pipe welding applications. By integrating advanced laser scanning technology with the Local Outlier Factor (LOF) algorithm, the research effectively mitigates outliers and compensates for incomplete data—persistent issues in dynamic manufacturing environments. To further enhance accuracy, a robust neural network model is employed to predict weld groove alignment, a crucial factor in maintaining weld structural integrity. The LOF algorithm was chosen for its ability to detect spatial anomalies, ensuring the exclusion of erroneous data that could compromise welding precision. Experimental results demonstrate that the combined use of LOF and neural networks significantly improves the operational efficiency of robotic welding, delivering consistently strong and precise welds across diverse manufacturing scenarios. The model achieved an average mean square error of 0.078 and an R² value of 0.995, accurately predicting 99.5 % of data. Therefore, neural network modeling enables accurate interpolation of missing data and real-time adjustments to varying operational conditions.},
  archive      = {J_MLA},
  author       = {Fatemeh Habibkhah and Mehrdad Moallem},
  doi          = {10.1016/j.mlwa.2025.100633},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100633},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Application of machine learning for seam profile identification in robotic welding},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification based on symbolic regression and
probabilistic programming and its application. <em>MLA</em>,
<em>20</em>, 100632. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint roughness coefficient (JRC) is critical to evaluate the strength and deformation behavior of joint rock mass in rock engineering. Various methods have been developed to estimate JRC value based on the statistical parameter of rock joints. The JRC value is uncertain due to the complex, random rock joint. Uncertainty is an essential characteristic of rock joints. However, the traditional determinative method cannot deal with uncertainty during the analysis, evaluation, and characterization of the mechanism for the rock joint. This study developed a novel JRC determination framework to estimate the JRC value and evaluate the uncertainty of rock joints based on symbolic regression and probabilistic programming. The symbolic regression was utilized to generate the general empirical equation with the unknown coefficient for the JRC determination of rock joints. The probabilistic programming was used to quantify the uncertainty of the rock joint roughness. The ten standard rock joint profiles illustrated and investigated the developed framework. And then, the developed framework was applied to the collected rock joint profile from the literature. The predicted JRC value was compared with the traditional empirical equations. The results show that the generalization performance of the developed framework is better than the traditional determinative empirical equation. It provides a scientific, reliable, and helpful to estimate the JRC value and characterize the mechanical behavior of joint rock mass.},
  archive      = {J_MLA},
  author       = {Yuyang Zhao and Hongbo Zhao},
  doi          = {10.1016/j.mlwa.2025.100632},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100632},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Uncertainty quantification based on symbolic regression and probabilistic programming and its application},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Key technical indicators for stock market prediction.
<em>MLA</em>, <em>20</em>, 100631. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of technical indicators for forecasting the stock market is widespread among investors and researchers. It is crucial to determine the optimal number of input technical indicators to predict the stock market successfully. However, there is no consensus on which collection of technical indicators is most suitable. The selection of technical indicators for a given forecasting model continues to be an active area of research. To our knowledge, there is limited published work on the importance of technical indicators in various categories such as momentum, trend, volatility, and volume. To identify the key technical indicators for stock market prediction, we employed XGBoost, Random Forest, Support Vector Regression, and LSTM regression techniques using 88 technical indicators as input data. We also used the PCA method for dimension reduction. The results reveal the most significant technical indicators within the momentum, trend, volatility, and volume categories. Our findings provide evidence that the proposed model is highly effective in predicting daily prices (with and without lag in Close price) on the S&amp;P 500 stock index.},
  archive      = {J_MLA},
  author       = {Seyed Mostafa Mostafavi and Ali Reza Hooman},
  doi          = {10.1016/j.mlwa.2025.100631},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100631},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Key technical indicators for stock market prediction},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based state of charge estimation: A
comparison between CatBoost model and c-BLSTM-AE model. <em>MLA</em>,
<em>20</em>, 100629. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The State of Charge (SOC) is a key metric within a Lithium-ion battery management system (BMS). Accurate SOC estimation is essential for enhancing battery longevity and ensuring user safety, making it a critical component of an effective BMS. Although SOC estimation has become an active research area for the machine learning (ML) community, only a handful of works have considered its estimation at negative temperatures. This paper proposes the application of two machine learning-based approaches for SOC estimation that perform well at wide range of temperatures (positive and negative) and varying dynamic loads. The first one is a hybrid deep learning approach based on the Convolutional BLSTM Auto-Encoder (C-BLSTM-AE) model that relies on extracting abstract features from input data. The second one is a CatBoost model that leverages the gradient boosting technique to enhance the prediction made by its constituent trees. The performance of the models is evaluated by comparing their regression accuracy and computational resource utilization. The C-BLSTM-AE model achieves a low Mean Absolute Error (MAE) of 0.52 % under fixed ambient temperature conditions and maintains a MAE of 1.03 % for variable ambient temperatures. The CatBoost model achieves a MAE of 0.69 % with fixed temperature settings and a MAE of 1.09 % under variable temperature conditions.},
  archive      = {J_MLA},
  author       = {Abderrahim Zilali and Mehdi Adda and Khaled Ziane and Maxime Berger},
  doi          = {10.1016/j.mlwa.2025.100629},
  journal      = {Machine Learning with Applications},
  month        = {6},
  pages        = {100629},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning-based state of charge estimation: A comparison between CatBoost model and C-BLSTM-AE model},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="neucom---79">NEUCOM - 79</h2>
<ul>
<li><details>
<summary>
(2025). Echo state network with a non-convex penalty for nonlinear
time series prediction. <em>NEUCOM</em>, <em>637</em>, 130084. (<a
href="https://doi.org/10.1016/j.neucom.2025.130084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo state networks (ESNs) with large reservoirs have been widely used in nonlinear time series prediction. However, over-large reservoirs will lead to ill-conditioned solutions when the output weights of ESNs are calculated by solving a linear regression problem. To address this issue, we propose an improved ESN with a non-convex penalty (NCP-ESN) for nonlinear time series prediction. The main idea of NCP-ESN is that an adjustable log penalty with nonconvex characteristics is introduced to the loss function for generating unbiased and sparse solutions when optimizing the output weights of the network. Meanwhile, a learning method with two-stage optimization is developed for the optimal output weights by combining the coordinate descent algorithm with the generalized inverse method. Finally, two simulation sequences and two real sequences are used to test the performance of the proposed NCP-ESN on time series prediction. Experimental results have shown the better performance of the proposed NCP-ESN compared with some regularized ESNs.},
  archive      = {J_NEUCOM},
  author       = {Wenting Wang and Fanjun Li and Qianwen Liu},
  doi          = {10.1016/j.neucom.2025.130084},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130084},
  shortjournal = {Neurocomputing},
  title        = {Echo state network with a non-convex penalty for nonlinear time series prediction},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PUAL: A classifier on trifurcate positive-unlabelled data.
<em>NEUCOM</em>, <em>637</em>, 130080. (<a
href="https://doi.org/10.1016/j.neucom.2025.130080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positive-unlabelled (PU) learning aims to train a classifier using the data containing only labelled-positive instances and unlabelled instances. However, existing PU learning methods are generally hard to achieve satisfactory performance on trifurcate data, where the positive instances distribute on both sides of the negative instances. To address this issue, firstly we propose a PU classifier with asymmetric loss (PUAL), by introducing a structure of asymmetric loss on positive instances into the objective function of the global and local learning classifier. Then we develop a kernel-based algorithm to enable PUAL to obtain non-linear decision boundary. We show that, through experiments on both simulated and real-world datasets, PUAL can achieve satisfactory classification on trifurcate data.},
  archive      = {J_NEUCOM},
  author       = {Xiaoke Wang and Xiaochen Yang and Rui Zhu and Jing-Hao Xue},
  doi          = {10.1016/j.neucom.2025.130080},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130080},
  shortjournal = {Neurocomputing},
  title        = {PUAL: A classifier on trifurcate positive-unlabelled data},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HB-net: Holistic bursting cell cluster integrated network
for occluded multi-objects recognition. <em>NEUCOM</em>, <em>637</em>,
130071. (<a href="https://doi.org/10.1016/j.neucom.2025.130071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the realm of image recognition, a specific category of multi-label classification (MLC) challenges arises when objects within the visual field may occlude one another, demanding simultaneous identification of both occluded and occluding objects. While traditional convolutional neural networks (CNNs) address these tasks, they are often bulky and achieve only moderate accuracy. To overcome this limitation, this paper introduces HB-net, a novel integrated network framework inspired by the Holistic Bursting (HB) cell from cutting-edge neural science research. Built upon the foundation of HB cell clusters, HB-net is designed to address the intricate task of simultaneously recognizing multiple occluded objects within images. The framework incorporates various Bursting cell cluster structures along with an evidence accumulation mechanism to enhance performance. Testing on multiple datasets, including digits and letters, shows that models incorporating the HB framework achieve a significant 2.98% improvement in recognition accuracy compared to models without the HB framework (1.0298 times, p=0.0499). Although in high-noise settings, standard CNNs exhibit slightly greater robustness when compared to HB-net models, the models that combine the HB framework and EA mechanism achieve a comparable level of accuracy and resilience to ResNet50, despite having only three convolutional layers and approximately 1 / 30 of the parameters. These findings of this study offer valuable insights for improving computer vision algorithms. The essential code is provided at https://github.com/d-lab438/hb-net.git .},
  archive      = {J_NEUCOM},
  author       = {Xudong Gao and Xiaoguang Gao and Jia Rong and Xiaowei Chen and Xiang Liao and Jun Chen},
  doi          = {10.1016/j.neucom.2025.130071},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130071},
  shortjournal = {Neurocomputing},
  title        = {HB-net: Holistic bursting cell cluster integrated network for occluded multi-objects recognition},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adversarial contrastive learning based cross-modality
zero-watermarking scheme for DIBR 3D video copyright protection.
<em>NEUCOM</em>, <em>637</em>, 130068. (<a
href="https://doi.org/10.1016/j.neucom.2025.130068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Copyright protection of depth image-based rendering (DIBR) videos has raised significant concerns due to their increasing popularity. Zero-watermarking, emerging as a powerful tool to protect the copyright of DIBR 3D videos, mainly relies on traditional feature extraction methods, thus necessitating improvements in robustness against complex geometric attacks and its ability to strike a balance between robustness and distinguishability. This paper presents a novel zero-watermarking scheme based on cross-modality feature fusion within a contrastive learning framework. Our approach integrates complementary information from 2D frames and depth maps using a cross-modality attention feature fusion mechanism to obtain discriminative features. Moreover, our features achieve a better trade-off between robustness and distinguishability by leveraging a designed contrastive learning strategy with an adversarial distortion simulator. Experimental results demonstrate our remarkable performance by reducing the false negative rates to around 0.2% when the false positive rate is equal to 0.5%, which is superior to the state-of-the-art zero-watermarking methods.},
  archive      = {J_NEUCOM},
  author       = {Xiyao Liu and Qingyu Dang and Huiyi Wang and Xiaoheng Deng and Xunli Fan and Cundian Yang and Zhihong Chen and Hui Fang},
  doi          = {10.1016/j.neucom.2025.130068},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130068},
  shortjournal = {Neurocomputing},
  title        = {An adversarial contrastive learning based cross-modality zero-watermarking scheme for DIBR 3D video copyright protection},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dstsa-gcn: Advancing skeleton-based gesture recognition with
semantic-aware spatio-temporal topology modeling. <em>NEUCOM</em>,
<em>637</em>, 130066. (<a
href="https://doi.org/10.1016/j.neucom.2025.130066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) have emerged as a powerful tool for skeleton-based action and gesture recognition, thanks to their ability to model spatial and temporal dependencies in skeleton data. However, existing GCN-based methods face critical limitations: (1) they lack effective spatio-temporal topology modeling that captures dynamic variations in skeletal motion, and (2) they struggle to model multiscale structural relationships beyond local joint connectivity. To address these issues, we propose a novel framework called Dynamic Spatial-Temporal Semantic Awareness Graph Convolutional Network (DSTSA-GCN). DSTSA-GCN introduces three key modules: Group Channel-wise Graph Convolution (GC-GC), Group Temporal-wise Graph Convolution (GT-GC), and Multi-Scale Temporal Convolution (MS-TCN). GC-GC and GT-GC operate in parallel to independently model channel-specific and frame-specific correlations, enabling robust topology learning that accounts for temporal variations. Additionally, both modules employ a grouping strategy to adaptively capture multiscale structural relationships. Complementing this, MS-TCN enhances temporal modeling through group-wise temporal convolutions with diverse receptive fields. Extensive experiments demonstrate that DSTSA-GCN significantly improves the topology modeling capabilities of GCNs, achieving state-of-the-art performance on benchmark datasets for gesture and action recognition, including SHREC’17 Track, DHG-14/28, NTU-RGB+D, NTU-RGB+D-120 and NW-ULCA. The code will be publicly available https://hucui2022.github.io/dstsa_gcn/ .},
  archive      = {J_NEUCOM},
  author       = {Hu Cui and Renjing Huang and Ruoyu Zhang and Tessai Hayama},
  doi          = {10.1016/j.neucom.2025.130066},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130066},
  shortjournal = {Neurocomputing},
  title        = {Dstsa-gcn: Advancing skeleton-based gesture recognition with semantic-aware spatio-temporal topology modeling},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GlobalLight: Exploring global influence in multi-agent deep
reinforcement learning for large-scale traffic signal control.
<em>NEUCOM</em>, <em>637</em>, 130065. (<a
href="https://doi.org/10.1016/j.neucom.2025.130065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By treating each intersection as an intelligent agent, multi-agent deep reinforcement learning (MADRL) offers a promising solution to adaptive traffic signal control (ATSC) in complex urban environments. However, existing approaches often emphasize the interactions between adjacent intersections while overlooking the global influence of distant relationships. This oversight limits their scalability to small-scale traffic networks, reducing their effectiveness in real-world urban transportation systems. In this paper, we propose GlobalLight , a novel MADRL-based traffic signal control method that addresses these challenges by exploring and exploiting global influence in traffic networks. We first propose a multidimensional feature extraction module via a multi-head graph attention network, which captures the mutual influence among locally adjacent intersections. Then we design a similarity mining module with two loss functions to analyze node embeddings in the representation space, uncovering latent relationships across distant intersections in the global traffic network. Finally, GlobalLight enables similar intersections to share policy parameters for decision-making within an effective MADRL framework. Our method simultaneously considers local dependencies between adjacent intersections and global traffic flow influence, enhancing scalability and decision efficiency for ATSC in city-level larger-scale traffic systems. Experimental evaluations on both synthetic and real-world traffic networks, encompassing up to 1000 of intersections, demonstrate that our method significantly outperforms SOTA approaches across multiple performance metrics, particularly in large-scale traffic scenarios.},
  archive      = {J_NEUCOM},
  author       = {Yilin Liu and Jintao Liang and Yifeng Zhang and Ping Gong and Guiyang Luo and Quan Yuan and Jinglin Li},
  doi          = {10.1016/j.neucom.2025.130065},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130065},
  shortjournal = {Neurocomputing},
  title        = {GlobalLight: Exploring global influence in multi-agent deep reinforcement learning for large-scale traffic signal control},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fraud detection in multi-relation graph: Contrastive
learning on feature and structural levels. <em>NEUCOM</em>,
<em>637</em>, 130063. (<a
href="https://doi.org/10.1016/j.neucom.2025.130063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fraud detection has emerged as a significant area of study, primarily due to its considerable impact on real-world applications. Despite the effectiveness of existing methods for fraud detection, they have not adequately addressed two key challenges: fraudulent camouflage and class imbalance. To tackle these challenges, we propose a novel model called Contrastive Learning on Feature and Structural Levels in Graph Neural Networks (CLFS-GNN) to effectively tackle these challenges. Our model incorporates an innovative neighbor nodes selection module that considers both feature and structural similarity between central nodes and their neighbor nodes, effectively reducing interference from fraudulent nodes by selecting highly similar neighbor nodes. Additionally, it employs an intra- and inter-graph message aggregation module with attention mechanisms to enhance the value of aggregated neighbor node information, thereby improving fraud detection performance. Furthermore, the algorithm incorporates contrastive learning to pull similar nodes closer and push dissimilar nodes further apart, mitigating class imbalance effects and achieving superior performance. Extensive experimental results show that this model outperforms the state-of-the-art GNN-based fraud detection on the Yelp and Amazon benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Jiangnan Tang and Huanhuan Gu and Darko B. Vuković and Guandong Xu and Youquan Wang and Haicheng Tao and Jie Cao},
  doi          = {10.1016/j.neucom.2025.130063},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130063},
  shortjournal = {Neurocomputing},
  title        = {Fraud detection in multi-relation graph: Contrastive learning on feature and structural levels},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AGQB-ViT: Adaptive granularity quantizer with bias for
post-training quantization of vision transformers. <em>NEUCOM</em>,
<em>637</em>, 130061. (<a
href="https://doi.org/10.1016/j.neucom.2025.130061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the significant achievements of Vision Transformers (ViTs) in various computer vision tasks, these models are often large and computationally complex, making them unsuitable for resource-constrained devices. Quantizing ViTs converts model parameters from high-precision to low-precision formats, which significantly reduces computational complexity and memory requirements, thereby enhancing the performance and efficiency of ViTs in limited-resource environments. In the post-training quantization (PTQ) process of ViTs, the logarithmic quantizer is an effective method for components with power-law distribution characteristics, such as Softmax and GELU. However, when further exploring quantization scenarios at 4 bits or lower, the traditional log-based quantizer suffers from significant accuracy loss due to inflexibility in base selection and suboptimal quantization efficiency. To address this issue, we propose an adaptive granularity quantizer with bias, termed AGQB. It conducts adaptive granularity optimization for both the logarithmic base and bias according to different activation distributions and quantization bit-width requirements. Furthermore, we implemented a three-stage optimization process, setting block reconstruction as the learning objective to minimize the error before and after quantization. Extensive experimental results show that AGQB-ViT can effectively quantize various ViT models and outperforms previous methods on multiple computer vision tasks. In particular, when the ViTs model is quantized to 3 bits, we achieve an average accuracy improvement of 2.13% in image classification tasks relative to existing state-of-the-art PTQ methods. The related code is available at https://github.com/kkkyq/AGQB-ViT .},
  archive      = {J_NEUCOM},
  author       = {Ying Huo and Yongqiang Kang and Dawei Yang and Jiahao Zhu},
  doi          = {10.1016/j.neucom.2025.130061},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130061},
  shortjournal = {Neurocomputing},
  title        = {AGQB-ViT: Adaptive granularity quantizer with bias for post-training quantization of vision transformers},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure modeling activation free fourier network for
spacecraft image denoising. <em>NEUCOM</em>, <em>637</em>, 130058. (<a
href="https://doi.org/10.1016/j.neucom.2025.130058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spacecraft image denoising is a crucial fundamental technology closely related to aerospace research. However, the existing deep learning-based image denoising methods are primarily designed for natural image and fail to adequately consider the characteristics of spacecraft image (e.g. low-light conditions, repetitive periodic structures), resulting in suboptimal performance in the spacecraft image denoising task. To address the aforementioned problems, we propose a Structure modeling Activation Free Fourier Network (SAFFN), which is an efficient spacecraft image denoising method including Structure Modeling Block (SMB) and Activation Free Fourier Block (AFFB). We present SMB to effectively extract edge information and model the structure for better identification of spacecraft components from dark regions in spacecraft noise image. We present AFFB and utilize an improved Fast Fourier block to extract repetitive periodic features and long-range information in noisy spacecraft image. Extensive experimental results demonstrate that our SAFFN performs competitively compared to the state-of-the-art methods on spacecraft noise image datasets. The codes are available at: https://github.com/shenduke/SAFFN .},
  archive      = {J_NEUCOM},
  author       = {Jingfan Yang and Hu Gao and Ying Zhang and Bowen Ma and Depeng Dang},
  doi          = {10.1016/j.neucom.2025.130058},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130058},
  shortjournal = {Neurocomputing},
  title        = {Structure modeling activation free fourier network for spacecraft image denoising},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAC: Collaborative learning of structure and content
features for android malware detection framework. <em>NEUCOM</em>,
<em>637</em>, 130053. (<a
href="https://doi.org/10.1016/j.neucom.2025.130053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of Internet of Things (IoT) technology, Android devices have increasingly become primary targets for malware attacks. Although significant research has been conducted in the field of malware detection, existing methods still face challenges when dealing with complex samples. In particular, a more comprehensive analysis is required in the domain of feature extraction. To enhance the accuracy of malware detection, we propose the SAC framework. This method utilizes Dalvik Executable (DEX) files as the data source and achieves deep integration of multi-view features by collaboratively modeling image and graph data types. Specifically, to accurately capture the local features of malware and improve the identification of critical behavioral patterns, we designed a task-oriented convolutional neural network (CNN) named IFNeXt, which integrates visualization analysis with an inverted bottleneck structure. Furthermore, we introduced a dual-channel graph convolutional network (GCN) that models the hierarchical structure of bytecode as a directed graph, capturing the co-occurrence relationships and semantic similarities between method calls. This approach enables a deeper exploration of the global structural features of malware. The SAC framework fully leverages the complementary advantages of image and graph data structures, providing a more comprehensive characterization of malware features from both content and structural perspectives. Experimental results demonstrate that our method achieves a detection accuracy of 99.43% on multiple real-world public datasets, significantly outperforming existing state-of-the-art detection techniques. This indicates the potential and innovation of our approach in enhancing the security of the Android platform.},
  archive      = {J_NEUCOM},
  author       = {Jin Yang and Huijia Liang and Hang Ren and Dongqing Jia and Xin Wang},
  doi          = {10.1016/j.neucom.2025.130053},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130053},
  shortjournal = {Neurocomputing},
  title        = {SAC: Collaborative learning of structure and content features for android malware detection framework},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DASC: Learning discriminative latent space for video
clustering. <em>NEUCOM</em>, <em>637</em>, 130050. (<a
href="https://doi.org/10.1016/j.neucom.2025.130050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, significant advancements have been made in video analysis technologies. However, most existing methods are primarily designed for supervised learning, particularly in video classification. Accurately labeling video data is often time-consuming and labor-intensive, making large-scale annotation challenging. As a result, most of the available video data remain in an unsupervised or weakly supervised state. This situation underscores the urgent need to develop efficient methods for unsupervised video data analysis, with a particular emphasis on video clustering techniques, which can effectively alleviate the high cost and labor intensity of video data annotation by automatically grouping similar videos, thus reducing the reliance on manual labeling. This significantly enhances the efficiency and scalability of video analysis. In this paper, we propose a deep aggregation subspace clustering (DASC) network, designed to learn a video-level self-representation matrix in an end-to-end manner, without the need for any labeled data, thus operating in an unsupervised learning environment. Specifically, DASC consists of four main components: auto-encoder backbone, video modeling module (VMM), self-representation module (SrM) and feature recovered module (FRM). A frame-level latent space is first established by utilizing the auto-encoder backbone. Then, a video-level latent space is established by constructing the VMM. Next, the video-level self-representation matrix is learned in the latent space by using the SrM. Finally, the video-level latent feature will be restored to frame-level features using the FRM. Experimental results on multiple benchmark datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Lin and Xizhan Gao and Zhihan Zhang and Haotian Deng},
  doi          = {10.1016/j.neucom.2025.130050},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130050},
  shortjournal = {Neurocomputing},
  title        = {DASC: Learning discriminative latent space for video clustering},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive symbiotic graph convolutional network.
<em>NEUCOM</em>, <em>637</em>, 130049. (<a
href="https://doi.org/10.1016/j.neucom.2025.130049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Within the intrinsic fabric of graph and network data, the latent reciprocity between network nodes forms a profound symbiotic relationship. Traditional graph neural networks struggle to adaptively parse and integrate multi-source features when learning these symbiotic relationships. To address this challenge, we propose a novel Adaptive Symbiotic Graph Convolutional Network (ASGCN) for semi-supervised node classification tasks. First, The initial contribution of this investigation is the introduction of a multi-scale feature convolution module, which enables the extraction of hierarchical features at varying scales and the construction of k-nearest neighbor graphs. This facilitates the deepening of the symbiotic features of nodes. Second, a symbiotic co-convolution module is put forth as a means of reinforcing the profound interdependence inherent to symbiotic relationships. Finally, an adaptive dynamic feature selection mechanism is introduced to flexibly respond to data characteristics, effectively identifying and fusing the most influential features in the processing information flow. Experimental results demonstrate that ASGCN exhibits significant advantages in deeply analyzing and integrating the intrinsic attributes of nodes with graph structural relationships, thereby improving performance in node classification tasks.},
  archive      = {J_NEUCOM},
  author       = {Lin Zhou and Yuzhi Xiao and Zhonglin Ye and Haixing Zhao and Zhen Liu},
  doi          = {10.1016/j.neucom.2025.130049},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130049},
  shortjournal = {Neurocomputing},
  title        = {Adaptive symbiotic graph convolutional network},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MetaGen: A framework for metaheuristic development and
hyperparameter optimization in machine and deep learning.
<em>NEUCOM</em>, <em>637</em>, 130046. (<a
href="https://doi.org/10.1016/j.neucom.2025.130046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperparameter optimization is a pivotal step in enhancing model performance within machine learning. Traditionally, this challenge is addressed through metaheuristics, which efficiently explore large search spaces to uncover optimal solutions. However, implementing these techniques can be complex without adequate development tools, which is the primary focus of this paper. Hence, we introduce MetaGen , a novel Python package designed to provide a comprehensive framework for developing and evaluating metaheuristic algorithms. MetaGen follows best practices in Python design, ensuring minimalistic code implementation, intuitive comprehension, and full flexibility in solution representation. The package defines two distinct user roles: Developers, responsible for algorithm implementation for hyperparameter optimization, and Solvers, who leverage pre-implemented metaheuristics to address optimization problems. Beyond algorithm implementation, MetaGen facilitates benchmarking through built-in test functions, ensuring standardized performance comparisons. It also provides automated reporting and visualization tools to analyze optimization progress and outcomes effectively. Furthermore, its modular design allows distribution and integration into existing machine learning workflows. Several illustrative use cases are presented to demonstrate its adaptability and efficacy. The package, along with code, a user manual, and supplementary materials, is available at: https://github.com/Data-Science-Big-Data-Research-Lab/MetaGen .},
  archive      = {J_NEUCOM},
  author       = {David Gutiérrez-Avilés and Manuel Jesús Jiménez-Navarro and José Francisco Torres and Francisco Martínez-Álvarez},
  doi          = {10.1016/j.neucom.2025.130046},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130046},
  shortjournal = {Neurocomputing},
  title        = {MetaGen: A framework for metaheuristic development and hyperparameter optimization in machine and deep learning},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prescribed performance event-triggered optimal control of
nonlinear multi-input systems. <em>NEUCOM</em>, <em>637</em>, 130044.
(<a href="https://doi.org/10.1016/j.neucom.2025.130044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a prescribed performance reinforcement learning control (PPRLC) based on event-triggered mechanism for nonlinear multi-input systems, where target error is constrained to a bounded set. Firstly, the constrained optimal control problem is reformulated as an unconstrained stationary optimal problem by using prescribed performance function. Then, the event-triggered mechanism (ETM) is integrated to save communication resources and reduce data transmission volume. In order to study the solution of the Hamilton-Jacobi-Bellman equation (HJB), we use a reinforcement learning (RL) algorithm based on the single-critic neural network (NN) and introduce a new adaptive law to update the NN weights. Based on the Lyapunov function, the convergence of weights and the closed-loop stability of the system are confirmed. Finally, the correctness and effectiveness of the method are proved by a numerical simulation example.},
  archive      = {J_NEUCOM},
  author       = {Yu Tang and Yongfeng Lv and Jun Zhao and Long Jian and Linwei Li},
  doi          = {10.1016/j.neucom.2025.130044},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130044},
  shortjournal = {Neurocomputing},
  title        = {Prescribed performance event-triggered optimal control of nonlinear multi-input systems},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trend-aware spatio-temporal fusion graph convolutional
network with self-attention for traffic prediction. <em>NEUCOM</em>,
<em>637</em>, 130040. (<a
href="https://doi.org/10.1016/j.neucom.2025.130040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current traffic prediction methods often extract insufficient road network information, have difficulty in mining long-term temporal dependencies, and cause model performance decline due to uneven data distribution. To address the issues above, we propose a novel Spatio-Temporal Fusion Graph Convolutional Network with Trend-Aware(STFTGCN) for traffic prediction. It consists of Spatio Temporal Embedding, Spatio-Temporal Synchronous Graph Convolution, Temporal-Attention Module, and Trend-Aware Forecasting. By constructing and thus aggregating Spatial Distance Graph, Road Connection Graph, Geographic Correlation Graph, and the proposed Lagged Correlation Graph, the hidden information in the road network is fully extracted. Then, Multi-layer Spatio-Temporal Synchronous Graph Convolution captures local spatio-temporal correlations, while a sandwich structure combined Temporal Self-Attention and Temporal Trend-Aware Multi-Head Self-Attention effectively extracts long-term dependencies and responds to local traffic fluctuations. The Trend-Aware transformations method overcome uneven data distribution, improving node relationship matching and capturing dynamic traffic changes. Experiments results on real-world datasets (PEMS03, PEMS04, PEMS07, PEMS08, PEMS-BAY and METR-LA) demonstrate that the proposed STFTGCN outperforms baseline models, validating its effectiveness and practicality.},
  archive      = {J_NEUCOM},
  author       = {Xiongtao Zhang and Lijie Pan and Qing Shen and Zhenfang Liu and Jungang Lou and Yunliang Jiang},
  doi          = {10.1016/j.neucom.2025.130040},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130040},
  shortjournal = {Neurocomputing},
  title        = {Trend-aware spatio-temporal fusion graph convolutional network with self-attention for traffic prediction},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class-view graph knowledge distillation: A new idea for
learning MLPs on graphs. <em>NEUCOM</em>, <em>637</em>, 130035. (<a
href="https://doi.org/10.1016/j.neucom.2025.130035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs), while effective for processing non-Euclidean structured data, suffer from computationally intensive neighbor fetching, which hinders their deployment in low-latency applications. Cross-architecture graph knowledge distillation (KD), which trains high-performance Multi-layer Perceptrons (MLPs) to emulate teacher GNNs, offers a promising solution. However, existing GNN-MLP distillation methods rely on the sample-view KD paradigm, where student models directly mimic the teacher’s parameter space. Given the fundamentally different architectures and parameter spaces of GNNs and MLPs, this direct mimicry approach limits effective knowledge transfer. Inspired by the inherent properties of MLPs, we propose a novel class-view KD paradigm for GNN-MLP distillation. Unlike sample-view KD, our method guides student MLPs to generate more discriminative parameter configurations within their own parameter space while preserving the similarity of prediction distributions with the teacher, rather than directly imitating the teacher’s parameter configurations. Extensive experiments on public benchmark datasets demonstrate that class-view KD outperforms sample-view KD across various evaluation metrics and can be seamlessly integrated into existing GNN-MLP distillation methods to improve performance without additional computational cost. The code is available at https://github.com/xsk160/Class-View-Graph-KD .},
  archive      = {J_NEUCOM},
  author       = {Yingjie Tian and Shaokai Xu and Muyang Li},
  doi          = {10.1016/j.neucom.2025.130035},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130035},
  shortjournal = {Neurocomputing},
  title        = {Class-view graph knowledge distillation: A new idea for learning MLPs on graphs},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counterfactual experience augmented off-policy reinforcement
learning. <em>NEUCOM</em>, <em>637</em>, 130017. (<a
href="https://doi.org/10.1016/j.neucom.2025.130017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning control algorithms face significant challenges due to out-of-distribution and inefficient exploration problems. While model-based reinforcement learning enhances the agent’s reasoning and planning capabilities by constructing virtual environments, training such virtual environments can be very complex. In order to build an efficient inference model and enhance the representativeness of learning data, we propose the Counterfactual Experience Augmentation (CEA) algorithm. CEA leverages variational autoencoders to model the dynamic patterns of state transitions and introduces randomness to model non-stationarity. This approach focuses on expanding the learning data in the experience pool through counterfactual inference and performs exceptionally well in environments that follow the bisimulation assumption. Environments with bisimulation properties are usually represented by discrete observation and action spaces, we propose a sampling method based on maximum kernel density estimation entropy to extend CEA to various environments. By providing reward signals for counterfactual state transitions based on real information, CEA constructs a complete counterfactual experience to alleviate the out-of-distribution problem of the learning data, and outperforms general SOTA algorithms in environments with difference properties. Finally, we discuss the similarities, differences and properties of generated counterfactual experiences and real experiences. The code is available at https://github.com/Aegis1863/CEA .},
  archive      = {J_NEUCOM},
  author       = {Sunbowen Lee and Yicheng Gong and Chao Deng},
  doi          = {10.1016/j.neucom.2025.130017},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130017},
  shortjournal = {Neurocomputing},
  title        = {Counterfactual experience augmented off-policy reinforcement learning},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Centroid-based contrastive consistency learning for
transferable deepfake detection. <em>NEUCOM</em>, <em>637</em>, 130009.
(<a href="https://doi.org/10.1016/j.neucom.2025.130009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous research efforts in deepfake detection mainly concentrated on identifying and differentiating artifacts discernible to humans. Those methods have left a bias in learned models, as they tend to concentrate on the disparities between forged and natural regions from the perspective of a single sample while overlooking consistency within categories from the perspective of the entire sample set, which remains crucial across various real-world applications. Therefore, inspired by contrastive learning, we tackle the deepfake detection problem by learning the invariant representations of both categories. Our proposed method, termed Centroid-based Contrastive Consistency Learning (C3L) method, integrates constraints on representations at both the data preprocessing and feature extraction stages. Specifically, during data preprocessing, we consider both temporal relationships within videos and the latent relationships within synthesis data. We introduce a novel Positive Enhancement Module (PEM) designed to characterize natural and forged samples in a facial semantically irrelevant way, thereby guiding a task-oriented positive pair contrasting strategy. In addition, at the feature extraction stage, we introduce the Margin Feature Simulation Module (MFSM), which leverages the centroid of the natural category to simulate marginal features for both categories. Subsequently, we employ the Supervised Contrastive Margin Loss (SCML), utilizing simulated features to emphasize differences at decision boundaries and optimize the learning process. The effectiveness and robustness of the proposed method have been demonstrated through extensive experiments.},
  archive      = {J_NEUCOM},
  author       = {Ruiqi Zha and Zhichao Lian and Qianmu Li},
  doi          = {10.1016/j.neucom.2025.130009},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130009},
  shortjournal = {Neurocomputing},
  title        = {Centroid-based contrastive consistency learning for transferable deepfake detection},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CITAL: Counterfactual intervention for temporal action
localization with point-level annotation. <em>NEUCOM</em>, <em>637</em>,
130006. (<a href="https://doi.org/10.1016/j.neucom.2025.130006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-supervised temporal action localization (PTAL) requires only a timestamp annotated on each action instance for training. Most existing PTAL methods use multiple instances learning (MIL) paradigm that localize actions according to contributions of the snippets to the classification results. The gap between classification and localization tasks causes the models to focus more on clues than pure actions. And the models are prone to localize fake actions when there are biased clues between training and test datasets. Inspired by earlier efforts on causal inference, we propose a counterfactual intervention framework for PTAL, CITAL for short. Counterfactual intervention simulates how models respond to counterfactual inputs that contains the same clues without action instances. Intuitively, we can obtain the real response to the pure actions by comparing responses to the inputs before and after counterfactual intervention. Specifically, we propose a background suppression (BS) block to suppresses the background response by guiding the model pay more attention to action instances rather than clues. To fuse the output scores of the various inputs, we propose a fusing by imitation (FI) strategy that further modifies the scores to have a high response to actions and low response to the background segments, generating more accurate proposals. Besides, we propose a counterfactual example generation (CEG) block to generate counterfactual examples with only clues and background contents based on the point labels and snippet-level action scores. Our approach achieves significant mAP gains on THUMOS14, BEOID and GTEA benchmarks comparing to various CAS-based methods without introducing additional parameters.},
  archive      = {J_NEUCOM},
  author       = {Yongxiang Hu and Ziying Xia and Zichong Chen and Thupten Tsering and Jian Cheng and Tashi Nyima},
  doi          = {10.1016/j.neucom.2025.130006},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130006},
  shortjournal = {Neurocomputing},
  title        = {CITAL: Counterfactual intervention for temporal action localization with point-level annotation},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting accuracy of student models via masked adaptive
self-distillation. <em>NEUCOM</em>, <em>637</em>, 129988. (<a
href="https://doi.org/10.1016/j.neucom.2025.129988">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) has achieved impressive success, yet conventional KD approaches are time-consuming and computationally costly. In contrast, self-distillation methods provide an efficient alternative. However, existing self-distillation methods mostly suffer from information redundancy due to the same network architecture from the teacher and student models. Additionally, they simultaneously face the inherent limitation of lacking a high-capacity teacher model. To cope with the above challenges, we propose a novel and efficient method named Masked Adaptive Self-Distillation (MASD). Specifically, we first introduce the Mask Generation Module, which masks random pixels of the feature maps and force it to reconstruct and refine more valuable features on different layers. Moreover, the Adaptive Weighting Mechanism is designed to dynamically adjust and optimize the weights of supervisory signals utilizing the probabilities from the mutual masked supervisory signals, thereby compensating the absence of high-capacity teacher model. We demonstrate the effectiveness of our MASD method on conventional image classification datasets and fine-grained datasets using state-of-the-art CNN architectures, and show that MASD significantly enhances the generalization of various backbone networks. For instance, on the CIFAR-100 classification benchmark, the proposed MASD method achieves an accuracy of 80.40% with the ResNet-18 architecture, surpassing the baseline with a 4.16% margin in Top-1 accuracy.},
  archive      = {J_NEUCOM},
  author       = {Haoran Zhao and Shuwen Tian and Jinlong Wang and Zhaopeng Deng and Xin Sun and Junyu Dong},
  doi          = {10.1016/j.neucom.2025.129988},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129988},
  shortjournal = {Neurocomputing},
  title        = {Boosting accuracy of student models via masked adaptive self-distillation},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature calibration and feature separation for long-tailed
visual recognition. <em>NEUCOM</em>, <em>637</em>, 129983. (<a
href="https://doi.org/10.1016/j.neucom.2025.129983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-tailed data classification is prevalent in real-world scenarios, but training on such datasets can lead to biased classifications and poor performance. We address this challenge by focusing on improving feature representation for tail classes, which is often lower in quality due to their closer proximity to other distinct classes. Inspired by the similarity between head and tail classes, we propose Class-wise Knowledge Distillation (CKD) to help tail classes learn prediction distributions from head classes, thus calibrating their features. Additionally, we introduce Hard Negative Samples Sampling (HNSS) to enhance feature separation by selecting challenging negative examples for contrastive learning. Our Feature Calibration and Feature Separation (FCFS) method achieves competitive results on CIFAR10-LT, CIFAR100-LT, and ImageNet-LT benchmarks, demonstrating effective feature learning for long-tailed classification problems. This approach leverages both knowledge distillation and hard negative sampling to improve model performance.},
  archive      = {J_NEUCOM},
  author       = {Qianqian Wang and Fangyu Zhou and Xiangge Zhao and Yangtao Lin and Haibo Ye},
  doi          = {10.1016/j.neucom.2025.129983},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129983},
  shortjournal = {Neurocomputing},
  title        = {Feature calibration and feature separation for long-tailed visual recognition},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPEC: Dual-path error compensation for low-light image
enhancement. <em>NEUCOM</em>, <em>637</em>, 129980. (<a
href="https://doi.org/10.1016/j.neucom.2025.129980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the task of low-light image enhancement, deep learning-based algorithms have demonstrated superiority and effectiveness compared to traditional methods. However, these methods, primarily based on Retinex theory, tend to overlook the noise and color distortions in input images, leading to significant noise amplification and local color distortions in enhanced results. To address these issues, we propose the Dual-Path Error Compensation (DPEC) method, designed to improve image quality under low-light conditions by preserving local texture details while restoring global image brightness without amplifying noise. DPEC incorporates precise pixel-level error estimation to capture subtle differences and an independent denoising mechanism to prevent noise amplification. We introduce the HIS-Retinex loss to guide DPEC’s training, ensuring the brightness distribution of enhanced images closely aligns with real-world conditions. To balance computational speed and resource efficiency while training DPEC for a comprehensive understanding of the global context, we integrated the VMamba architecture into its backbone. Comprehensive quantitative and qualitative experimental results demonstrate that our algorithm significantly outperforms state-of-the-art methods in low-light image enhancement. The code is publicly available online at https://github.com/wangshuang233/DPEC .},
  archive      = {J_NEUCOM},
  author       = {Shuang Wang and Qianwen Lu and Boxing Peng and Yihe Nie and Qingchuan Tao},
  doi          = {10.1016/j.neucom.2025.129980},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129980},
  shortjournal = {Neurocomputing},
  title        = {DPEC: Dual-path error compensation for low-light image enhancement},
  volume       = {637},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time stereo matching with enhanced geometric
comprehension through cross-attention integration. <em>NEUCOM</em>,
<em>636</em>, 130069. (<a
href="https://doi.org/10.1016/j.neucom.2025.130069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate disparity estimation through stereo matching remains a critical challenge, especially for real-time applications. This work introduces a novel and computationally efficient framework that achieves high accuracy and real-time performance in stereo-based disparity estimation. The proposed approach introduces three key innovations. This work proposes a context cross-attention (CCA) module, which enhances the cost volume aggregation process by leveraging localized cross-attention for improved geometric understanding. Guided concatenation volume (GCV) is also implemented, which optimizes feature matching by effectively combining correlation clues with contextual information, reducing computational redundancy while maintaining crucial spatial details. Also, this paper proposes an uncertainty-based refinement (UR) module, which improves accuracy in challenging scenarios by utilizing an uncertainty map, a context feature map, and a geometry feature map to correct errors in challenging areas such as textureless regions and occlusions. Comprehensive experiments on multiple benchmark datasets, including KITTI, Sceneflow, Middlebury, and ETH3D, demonstrate that the proposed model performs better than existing state-of-the-art real-time approaches in accuracy metrics while maintaining comparable computational efficiency. These results establish the framework as a viable solution for demanding real-world applications, particularly in autonomous driving and robotics systems where real-time performance is crucial. The source code is available at https://github.com/kayhan-hashemi/CCAStereo .},
  archive      = {J_NEUCOM},
  author       = {Hosein Hashemi and Yasser Baleghi and Mohamad Reza Hassanzadeh},
  doi          = {10.1016/j.neucom.2025.130069},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130069},
  shortjournal = {Neurocomputing},
  title        = {Real-time stereo matching with enhanced geometric comprehension through cross-attention integration},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Drop inherent biases: Multi-level attention calibration for
robust cross-domain few-shot classification. <em>NEUCOM</em>,
<em>636</em>, 130056. (<a
href="https://doi.org/10.1016/j.neucom.2025.130056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning (FSL) is a promising approach for addressing the challenge of classifying novel classes with only limited labeled data. Many few-shot studies have elaborated various task-shared inductive biases (meta-knowledge) to solve such tasks and have achieved impressive performance. However, when there is a domain shift between the training and testing tasks, the learned inductive biases fail to generalize across domains. In this paper, we attempt to suppress and correct inherent discriminative inductive biases from the source domain through source domain attention release and target domain attention reaggregation. We propose a few-shot learning framework, which systematically addresses the large domain shift between base and novel classes. Specifically, the framework consists of three parts: prototype-level attention calibration, feature-level attention calibration for attention release and reaggregation, and loss attention calibration. First, the prototype-level attention calibration module highlights key instances via prototype calibration, reducing the influence of noisy instances in few-shot settings. Second, the feature-level attention calibration module suppresses and corrects erroneous discriminative inductive biases from the source domain through base class attention release and novel class attention reaggregation, respectively. Finally, we incorporate the loss attention calibration module into the loss function to balance the discriminability and diversity of the classification matrix, mitigating the decline in generalization ability caused by erroneous discriminative features during domain shift. We conduct experiments on eight classic few-shot cross-domain datasets. The results demonstrate that, under varying domain shifts, our method improves performance, with average accuracy gains of 0.82% and 1.31% in the 5-way 1-shot and 5-way 5-shot settings, respectively, compared to the existing state-of-the-art (SOTA) method.},
  archive      = {J_NEUCOM},
  author       = {Minghui Li and Jing Jiang and Hongxun Yao},
  doi          = {10.1016/j.neucom.2025.130056},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130056},
  shortjournal = {Neurocomputing},
  title        = {Drop inherent biases: Multi-level attention calibration for robust cross-domain few-shot classification},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HDCPAA: A few-shot class-incremental learning model for
remote sensing image recognition. <em>NEUCOM</em>, <em>636</em>, 130043.
(<a href="https://doi.org/10.1016/j.neucom.2025.130043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the scene of remote sensing image (RSI) recognition, it is difficult to obtain a sufficient number of samples for training all categories at once. A more realistic situation is that the recognition task occurs in an open environment, with categories gradually increasing. Additionally, due to the difficulty of collecting certain data, there are only a few samples for each new category. This leads to the problem of few-shot class-incremental learning (FSCIL), where the model learns incrementally and the number of samples for incremental classes is very small, generally only a few, while the number of samples for base classes is relatively large. To address this, this paper proposes a model framework for FSCIL of RSIs, called HDCPAA. The model is mainly divided into three parts. The first part is the feature extraction network, which is pre-trained on the base classes and then its parameters are frozen in subsequent incremental learning to alleviate catastrophic forgetting of the base classes. The second part is a fully connected layer, which transforms the prototypes of each category into quasi-orthogonal prototypes to increase the distance between the prototypes. The third part is the prototype adaptation attention module, which adaptively updates prototypes and query vectors using attention mechanisms. The training process of this module is based on the meta-learning of pseudo-incremental classes. Experiments on two popular benchmark RSI datasets, MSTAR and NWPU-RESISC45, show that our model significantly outperforms the baseline models and sets new state-of-the-art results with remarkable advantages. Our code will be uploaded at: https://github.com/lipeng144/HDCPAA .},
  archive      = {J_NEUCOM},
  author       = {Peng Li and Cunqian Feng and Xiaowei Hu and Weike Feng},
  doi          = {10.1016/j.neucom.2025.130043},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130043},
  shortjournal = {Neurocomputing},
  title        = {HDCPAA: A few-shot class-incremental learning model for remote sensing image recognition},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unifying the syntax and semantics for math word problem
solving. <em>NEUCOM</em>, <em>636</em>, 130042. (<a
href="https://doi.org/10.1016/j.neucom.2025.130042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Math word problem solving is a complex task for natural language processing systems, requiring both comprehension of problem descriptions and deduction of accurate solutions. Existing studies have shown that graph-based approaches can achieve competitive results by applying multilayer graph neural networks to syntactic structure graphs. However, challenges such as incorrect parsing of syntactic dependency trees and insensitivity to numerical information may lead to misinterpretations in the representation. In this paper, we introduce a novel synthetic graph, the N umber- C entered S ynthetic S emantic G raph (NC-SSG), to address these challenges by reorganizing the dependency tree layout around numerical elements. We propose a double-channel graph transformer to enhance the connections between numbers and their contextual elements, thereby improving the understanding of problem descriptions. Additionally, we present a question-driven tree decoder to generate more accurate solutions, aiming to overcome shallow heuristics. Our approach mitigates the impact of parsing errors in syntactic dependency trees, yielding more precise representations and solutions. Experimental evaluations on two benchmark datasets demonstrate that our solver outperforms previous methods and achieves competitive performance compared to large language models.},
  archive      = {J_NEUCOM},
  author       = {Xingyu Tao and Yi Zhang and Zhiwen Xie and Zhuo Zhao and Guangyou Zhou and Yongchun Lu},
  doi          = {10.1016/j.neucom.2025.130042},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130042},
  shortjournal = {Neurocomputing},
  title        = {Unifying the syntax and semantics for math word problem solving},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CS4TE: A novel coded self-attention and semantic synergy
network for triple extraction. <em>NEUCOM</em>, <em>636</em>, 130034.
(<a href="https://doi.org/10.1016/j.neucom.2025.130034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint entity relation extraction approach holds great potential for extracting triples from unstructured text. However, in current research, two prevalent shortcomings significantly impact the efficacy of triple extraction task. Firstly, since entities constitute only a small proportion of sentences and token embedding contain a substantial amount of irrelevant information, these factors present significant challenges to the performance of classification models. Secondly, the typical process of predicting triples begins with identifying entities and then predicting triples solely based on the obtained entity representation, this process often overlooks the contextual semantic information associated with the entities. In this work, we propose CS4TE: A Novel Coded Self-Attention and Semantic Synergy Network for Triple Extraction. Specifically, we propose a novel Coded Self-Attention Mechanism designed to refine text representation by effectively masking irrelevant information and enhancing entity representation. Additionally, we propose a Semantic Synergy Network, which innovatively integrates semantic information with token pairs to predict triples, addressing the limitations of previous research that often overlooked semantic information. Finally, our model outperforms state-of-the-art baseline models on two public datasets in the joint entity-relation extraction task, and extensive experiments have been conducted to demonstrate the effectiveness of our method from multiple perspectives.},
  archive      = {J_NEUCOM},
  author       = {Huiyong Lv and Yurong Qian and Jiaying Chen and Shuxiang Hou and Hongyong Leng and Mengnan Ma},
  doi          = {10.1016/j.neucom.2025.130034},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130034},
  shortjournal = {Neurocomputing},
  title        = {CS4TE: A novel coded self-attention and semantic synergy network for triple extraction},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-morphing attack detection using few-shot learning and
triplet-loss. <em>NEUCOM</em>, <em>636</em>, 130033. (<a
href="https://doi.org/10.1016/j.neucom.2025.130033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face morphing attack detection is challenging and presents a concrete and severe threat to face verification systems. A reliable detection mechanism for such attacks, tested with a robust cross-dataset protocol and unknown morphing tools, is still a research challenge. This paper proposes a framework based on the Few-Shot-Learning approach that shares image information based on the Siamese network using triplet-semi-hard-loss to tackle the morphing attack detection and boost the learning classification process. This network compares a bona fide or potentially morphed image with triplets of morphing face images. Our results show that this new network clusters the morphed images and assigns them to the right classes to obtain a lower equal error rate in a cross-dataset scenario. Few-shot learning helps to boost the learning process by sharing only small image numbers from an unknown dataset. Experimental results using cross-datasets trained with FRGCv2 and tested with FERET datasets reduced the BPCER 10 from 43% to 4.91% using ResNet50. For the AMSL open-access dataset is reduced for MobileNetV2 from BPCER 10 of 31.50% to 2.02%. For the SDD open-access synthetic dataset, the BPCER 10 is reduced for MobileNetV2 from 21.37% to 1.96%.},
  archive      = {J_NEUCOM},
  author       = {Juan E. Tapia and Daniel Schulz and Christoph Busch},
  doi          = {10.1016/j.neucom.2025.130033},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130033},
  shortjournal = {Neurocomputing},
  title        = {Single-morphing attack detection using few-shot learning and triplet-loss},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Broad hashing for image retrieval. <em>NEUCOM</em>,
<em>636</em>, 130031. (<a
href="https://doi.org/10.1016/j.neucom.2025.130031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of deep learning, deep hashing methods have become mainstream of hashing methods which adopt deep networks to learn better feature representation of images and simultaneously generate compact binary hash codes. Deep hashing methods have a bottleneck in training efficiency due to the complex structure of deep networks. In this work, we propose a broad hashing (BH) method with high retrieval performance and very short learning time. In BH, uncorrelated and balanced binary codes are assigned to each category through a Hadamard matrix. Then, a broad hashing network is constructed to learn hash functions which maps images to binary hash codes with high efficiency. Our method yields higher retrieval precision while its training time is 200 to 700 times faster than that of deep hashing methods. At the same time, more compact hash codes are obtained compared with conventional supervised learning methods. In addition, three incremental algorithms for BH are developed for dynamic environments, which enable the hash network to be remodeled without retraining. Experiments on three benchmark datasets validate the effectiveness and efficiency of BH.},
  archive      = {J_NEUCOM},
  author       = {Wing W.Y. Ng and Xuyu Liu and Xing Tian and Ting Wang and Jianjun Zhang and C.L. Philip Chen},
  doi          = {10.1016/j.neucom.2025.130031},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130031},
  shortjournal = {Neurocomputing},
  title        = {Broad hashing for image retrieval},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial erasure network based on multi-instance learning
for weakly supervised video anomaly detection. <em>NEUCOM</em>,
<em>636</em>, 130030. (<a
href="https://doi.org/10.1016/j.neucom.2025.130030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised video anomaly detection (WSVAD) aims to precisely locate temporal windows of abnormal events in untrimmed videos using only video-level labels. By accurately locating anomalies, WSVAD has great application potential in the security domain and contributes to the progress of smart city development. However, the lack of frame-level annotations during training makes it highly challenging to infer the status of each frame. Multiple-Instance Learning (MIL) is the dominant method in WSVAD. Due to the limitation of video-level annotations, most MIL-based methods detect obvious abnormal segments to represent the overall anomaly level of the video while overlooking weak abnormal segments. To focus on the discrimination of weak anomalies, we propose a novel WSVAD framework named Adversarial Erasure Network (AE-Net). AE-Net consists of two key components: (1) a dual-branch architecture that highlights weak anomalies by erasing the most obvious abnormal features and combining the erased features with the original ones. (2) a novel triplet loss function that improves weak anomaly representation by separating abnormal and normal features in the erased feature space. Through the above design, AE-Net can reduce false negatives in real-world anomaly detection. Extensive experiments on three WSVAD benchmarks demonstrate that our method outperforms most existing state-of-the-art methods. Specifically, AE-Net achieves an AUC of 88.40% on the UCF-Crime dataset and 98.27% on the ShanghaiTech dataset, which demonstrates that AE-Net can effectively distinguish between normal and abnormal events. Moreover, AE-Net achieves an AP of 85.13% on the XD-Violence dataset, which highlights that AE-Net can accurately detect abnormal events.},
  archive      = {J_NEUCOM},
  author       = {Xin Song and Penghui Liu and Suyuan Li and Siyang Xu and Ke Wang},
  doi          = {10.1016/j.neucom.2025.130030},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130030},
  shortjournal = {Neurocomputing},
  title        = {Adversarial erasure network based on multi-instance learning for weakly supervised video anomaly detection},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attributed network community detection based on graph
contrastive learning and multi-objective evolutionary algorithm.
<em>NEUCOM</em>, <em>636</em>, 130029. (<a
href="https://doi.org/10.1016/j.neucom.2025.130029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed network community detection holds significant research value for network structure analysis and practical applications. However, existing methods still face significant challenges in addressing the conflicts between topological structure and attribute features, as well as balancing structural tightness and attribute similarity in community detection. In light of this, we propose a community detection method based on graph contrastive learning and multi-objective evolutionary algorithm (GCL-MOEA) for attributed networks. Specifically, GCL-MOEA contains two core parts: node embedding and community detection. Considering the conflict between topological structure and attribute features, the node embedding part constructs topology-augmented and attribute-augmented views, which are utilized in a cross-view graph contrastive learning model. This model comprehensively extracts node features to obtain node embedding vectors, effectively preserving the consistency and complementarity between the structure and attributes. The community detection part utilizes clustering results of node embeddings to construct high-quality initial populations. A multi-objective evolutionary algorithm is subsequently employed to obtain community structures where nodes are tightly connected and have similar attributes. The effectiveness of the proposed method is validated on five real-world networks. Experimental results demonstrate that GCL-MOEA outperforms baselines in terms of ACC, NMI, ARI, and F1, obtaining better community detection results.},
  archive      = {J_NEUCOM},
  author       = {Yao Liang and Jian Shu and Linlan Liu},
  doi          = {10.1016/j.neucom.2025.130029},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130029},
  shortjournal = {Neurocomputing},
  title        = {Attributed network community detection based on graph contrastive learning and multi-objective evolutionary algorithm},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained multi-modal prompt learning for vision–language
models. <em>NEUCOM</em>, <em>636</em>, 130028. (<a
href="https://doi.org/10.1016/j.neucom.2025.130028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently advanced pre-trained vision language models have demonstrated outstanding performance in many downstream tasks via prompt learning. Prompt learning provides task-specific prompt information to exploit beneficial knowledge stored in pre-trained models to promote generalization ability for downstream tasks. However, previous work mainly focused on single modal prompt tuning (with only one prompt per modality) and salient distinguished features, which unable to flexibly adjust the two representation spaces on downstream tasks dynamically, yet makes it hard to capture subtle discriminative knowledge, which resulting in suboptimal solutions. In this work, we propose a novel F ine- G rained M ulti-modal P rompt L earning framework, denoted as FGMPL , based on the contrastive language–image pre-trained model (CLIP). To facilitate the pre-trained CLIP model to learn and represent more effective features, we design a dual-grained visual prompt scheme to learn global discrepancies as well as specify the subtle discriminative details among visual classes, and transform random vectors with class names in class-aware text prompt into class-specific discrepancy representation. Moreover, in contrast to the previous prompt approaches, we use shared latent semantic space to generate visual and text prompts to encourage cross-modal interaction. Furthermore, a multimodal prompt tuning evaluator is proposed, which can make the vision and text prompts semantically aligned and enhance each other to promote cross-modal collaborative reasoning to further improve FGMPL. Comprehensive experiments on popular image recognition benchmarks show that our approach has superior generalization and few-shot capabilities.},
  archive      = {J_NEUCOM},
  author       = {Yunfei Liu and Yunziwei Deng and Anqi Liu and Yanan Liu and Shengyang Li},
  doi          = {10.1016/j.neucom.2025.130028},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130028},
  shortjournal = {Neurocomputing},
  title        = {Fine-grained multi-modal prompt learning for vision–language models},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event denoising for dynamic vision sensor using residual
graph neural network with density-based spatial clustering.
<em>NEUCOM</em>, <em>636</em>, 130026. (<a
href="https://doi.org/10.1016/j.neucom.2025.130026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bio-inspired emerging dynamic vision sensor (DVS), characterized by its exceptional high temporal resolution and immediate response, possesses an innate advantage in capturing rapidly changing scenes. Nevertheless, it is also susceptible to severe noise interference, especially in challenging conditions like low illumination and high exposure. Notably, the existing noise processing approaches tend to oversimplify data into 2-dimensional (2D) patterns, disregarding the sparse and irregular crucial event structure information that the DVS intrinsically provides via its asynchronous output. Aiming at these problems, we propose a residual graph neural network (RGNN) framework based on density spatial clustering for event denoising, called DBRGNN. Leveraging the temporal window rule, we extract non-overlapping event segments from the DVS event stream and adopt a density-based spatial clustering algorithm to obtain event groups with spatial correlations. To fully exploit the inherent sparsity and plentiful spatiotemporal information of the raw event stream, we transform each event group as compact graph representations via directed edges and feed them into a graph coding module composed of a series of graph convolutional and pooling layers to learn robust geometric features from event sequences. Importantly, our approach effectively reduces noise levels without compromising the spatial structure and temporal coherence of spike events. Compared with other baseline methods, our DBRGNN achieves competitive performance by quantitative and qualitative evaluations on publicly available datasets under varying lighting conditions and noise ratios.},
  archive      = {J_NEUCOM},
  author       = {Weibin Feng and Xiaoping Wang and Xin Zhan and Hongzhi Huang},
  doi          = {10.1016/j.neucom.2025.130026},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130026},
  shortjournal = {Neurocomputing},
  title        = {Event denoising for dynamic vision sensor using residual graph neural network with density-based spatial clustering},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGCDiff: Sketch-guided cross-modal diffusion model for 3D
shape completion. <em>NEUCOM</em>, <em>636</em>, 130025. (<a
href="https://doi.org/10.1016/j.neucom.2025.130025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape completion aims to generate complete shapes based on partial observations. Most recent methods utilize existing information on 3D shapes for shape completion tasks, such as inputting a partial 3D shape into an encoder–decoder structure to obtain a complete 3D shape. Despite the recent rapid evolution of neural networks greatly improving the completion performance of 3D shapes, they usually generate deterministic results. However, the completed shape is inherently diverse, leading to the concept of multimodal shape completion, in which a single partial shape can correspond to multiple plausible complete shapes. Existing multimodal shape completion methods are typically unpredictable, which results in the generated complete shapes exhibiting randomness. To address the challenge of achieving a guided generation process for multimodal shape completion, we propose a novel sketch-based diffusion model. Our key designs encompass the following. We propose a novel diffusion-based framework that employs sketches as guidance to generate complete 3D shapes. Within the framework, we introduce a dual cross-modal attention module that ensures the generated results retain sufficient geometric detail. Experimental results indicate that our approach not only facilitates multimodal shape completion based on sketches but also achieves competitive performance in deterministic shape completion.},
  archive      = {J_NEUCOM},
  author       = {Zhenjiang Du and Yan Zhang and Zhitao Liu and Guan Wang and Zeyu Ma and Ning Xie and Yang Yang},
  doi          = {10.1016/j.neucom.2025.130025},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130025},
  shortjournal = {Neurocomputing},
  title        = {SGCDiff: Sketch-guided cross-modal diffusion model for 3D shape completion},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging diffusion and flow matching models for
demographic bias mitigation of facial attribute classifiers.
<em>NEUCOM</em>, <em>636</em>, 130024. (<a
href="https://doi.org/10.1016/j.neucom.2025.130024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Published research highlights the presence of demographic bias in automated facial attribute classification algorithms, notably impacting women and individuals with darker skin tones. Proposed bias mitigation techniques are not generalizable, need demographic annotations, are application-specific, and often obtain fairness by reducing overall classification accuracy. In response to these challenges, this paper proposes a novel bias mitigation technique that systematically integrates diffusion and flow-matching models with a base classifier with minimal additional computational overhead. These generative models are chosen for their extreme success in capturing diverse data distributions and their inherent stochasticity. Our proposed approach augments the base classifier’s accuracy across all demographic sub-groups with enhanced fairness. Further, the stochastic nature of these generative models is harnessed to quantify prediction uncertainty, allowing for test-time rejection, which further enhances fairness. Additionally, novel solvers are proposed to significantly reduce the computational overhead of generative model inference. An exhaustive evaluation carried out on facial attribute annotated datasets substantiates the efficacy of our approach in enhancing the accuracy and fairness of facial attribute classifiers by 0 . 5 % − 3 % and 0 . 5 % − 5 % across datasets over SOTA mitigation techniques. Thus, obtaining state-of-the-art performance. Further, our proposal does not need a demographically annotated training set and is generalizable to any downstream classification task.},
  archive      = {J_NEUCOM},
  author       = {Sreeraj Ramachandran and Ajita Rattani},
  doi          = {10.1016/j.neucom.2025.130024},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130024},
  shortjournal = {Neurocomputing},
  title        = {Leveraging diffusion and flow matching models for demographic bias mitigation of facial attribute classifiers},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level semantic-assisted prototype learning for
few-shot action recognition. <em>NEUCOM</em>, <em>636</em>, 130022. (<a
href="https://doi.org/10.1016/j.neucom.2025.130022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Few-Shot Action Recognition (FSAR) task involves recognizing new categories with limited labeled data. The conventional fine-tuning-based adaptation approach is often prone to overfitting and lacks temporal modeling for video data. Moreover, the discrepancy in distribution between meta-training and meta-test sets can also lead to suboptimal performance in few-shot scenarios. This paper introduces a simple yet effective multi-level semantic-assisted prototype learning framework to tackle these challenges. Initially, we leverage CLIP to achieve multimodal adaptation learning and present a multi-level semantic-assisted learning module to enhance the prototypes of different action classes based on semantic information. Additionally, we integrate the lightweight adapters into the CLIP visual encoder to support parameter-efficient transfer learning and improve temporal modeling in videos. Especially, a bias compensation block is employed for feature rectification to mitigate the distribution bias in FSAR stemming from data scarcity. Extensive experiments conducted on five standard benchmark datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Dan Liu and Qing Xia and Fanrong Meng and Mao Ye and Jianwei Zhang},
  doi          = {10.1016/j.neucom.2025.130022},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130022},
  shortjournal = {Neurocomputing},
  title        = {Multi-level semantic-assisted prototype learning for few-shot action recognition},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant and attack-tolerant cooperative
event-triggered sampled-data security control for synchronization of
RDNNs with stochastic actuator failures and random deception attacks.
<em>NEUCOM</em>, <em>636</em>, 130021. (<a
href="https://doi.org/10.1016/j.neucom.2025.130021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the fault-tolerant and attack-tolerant cooperative event-triggered sampled-data security (FACETSDS) synchronization problem of space-varying reaction–diffusion neural networks (SVRDNNs) under spatially point measurements (SPMs) with stochastic actuator failures and random deception attacks is investigated. First, to save more communication resources and adapt to the variation of system dynamics subject to stochastic actuator failures and random deception attacks, a FACETSDS control scheme is proposed under SPMs. Second, by constructing a Lyapunov functional and utilizing inequality techniques, some synchronization criteria based on spatial linear matrix inequalities (SLMIs) are derived for SVRDNNs. Then, to solve SLMIs, the FETSDS control for synchronization problem of SVRDNNs under SPMs with stochastic actuator failures and random deception attacks is formulated as an linear matrix inequality feasibility problem. Lastly, the designed FACETSDS synchronization strategy is verified by one numerical example.},
  archive      = {J_NEUCOM},
  author       = {Feng-Liang Zhao and Zi-Peng Wang and Junfei Qiao and Huai-Ning Wu and Tingwen Huang},
  doi          = {10.1016/j.neucom.2025.130021},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130021},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant and attack-tolerant cooperative event-triggered sampled-data security control for synchronization of RDNNs with stochastic actuator failures and random deception attacks},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic facial expression recognition in the wild via
multi-snippet spatiotemporal learning. <em>NEUCOM</em>, <em>636</em>,
130020. (<a href="https://doi.org/10.1016/j.neucom.2025.130020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Facial Expression Recognition (DFER) in-the-wild poses a significant challenge in emotion recognition research. Many studies have focused on extracting finer facial features while overlooking the effect of noisy frames on the entire sequence. In addition, the imbalance between short- and long-term temporal relationships remains inadequately addressed. To tackle these issues, we propose the Multi-Snippet Spatiotemporal Learning (MSSL) framework that uses distinct temporal and spatial modeling for snippet feature extraction, enabling more accurate simulation of subtle facial expression changes while capturing finer details. We also introduced a dual-branch hierarchical module, BiTemporal Multi-Snippet Enhancement (BTMSE), which is designed to capture spatiotemporal dependencies and model subtle visual changes across snippets effectively. The Temporal-Transformer further enhances the learning of long-term dependencies, whereas learnable temporal position embeddings ensure consistency between snippet and fused features over time. By leveraging (2+1)D multi-snippet spatiotemporal modeling, BTMSE, and the Temporal-Transformer, MSSL hierarchically explores the complex interrelationships between temporal dynamics and facial expressions. Comparative experiments and ablation studies confirmed the effectiveness of our method on three large-scale in-the-wild datasets: DFEW, FERV39K, and MAFW.},
  archive      = {J_NEUCOM},
  author       = {Yang Lü and Fuchun Zhang and Zongnan Ma and Bo Zheng and Zhixiong Nan},
  doi          = {10.1016/j.neucom.2025.130020},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130020},
  shortjournal = {Neurocomputing},
  title        = {Dynamic facial expression recognition in the wild via multi-snippet spatiotemporal learning},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation for object detection with diffusion
model. <em>NEUCOM</em>, <em>636</em>, 130019. (<a
href="https://doi.org/10.1016/j.neucom.2025.130019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation is a method that transfers information from a larger network (i.e. the teacher) to a smaller network (i.e. the student), so that the student network can inherit the strong performance of the teacher network while maintaining its computational complexity within a relatively lower range. Currently, knowledge distillation has been widely applied to object detection field to mitigate the rapid expansion of the model size. In this paper, we propose an object detector based on knowledge distillation method. Meanwhile, directly mimicking the features of the teacher often fails to achieve the desired results due to the extra noise in the feature extracted by the student, which causes significant inconsistency and may even weaken the capability of the student. To address this issue, we utilize diffusion model to remove the noise so as to narrow the gap between the features extracted by the teacher and the student, improving the performance of the student. Furthermore, we develop a noise matching module that matches noise level in the student feature during the denoising process. Extensive experiments have been conducted on COCO and Pascal VOC to validate the effectiveness of the proposed method, in which our method achieves 40.0% mAP and 81.63% mAP respectively, while maintaining a frame rate of 27.3FPS, exhibiting the superiority of our model in both accuracy and speed.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Junzong Long and Chunrui Li},
  doi          = {10.1016/j.neucom.2025.130019},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130019},
  shortjournal = {Neurocomputing},
  title        = {Knowledge distillation for object detection with diffusion model},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal multitask similarity learning for vision language
model on radiological images and reports. <em>NEUCOM</em>, <em>636</em>,
130018. (<a href="https://doi.org/10.1016/j.neucom.2025.130018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, large-scale Vision-Language Models (VLM) have shown promise in learning general representations for various medical image analysis tasks. However, current medical VLM methods typically employ contrastive learning approaches that have limited ability to capture nuanced yet crucial medical knowledge, particularly within similar medical images, and do not explicitly consider the uneven and complementary semantic information contained in different modalities. To address these challenges, we propose a novel Multimodal Multitask Similarity Learning (M2SL) method that learns joint representations of image–text pairs and captures the relational similarity between different modalities via a coupling network. Our method also notably leverages the rich information in the text inputs to construct a knowledge-driven semantic similarity matrix as the supervision signal. We conduct extensive experiments for cross-modal retrieval and zero-shot classification tasks on radiological images and reports and demonstrate substantial performance gains over existing methods. Our method also accommodates low-resource settings with limited training data availability and has significant implications for enhancing VLM development.},
  archive      = {J_NEUCOM},
  author       = {Yang Yu and Jiahao Wang and Weide Liu and Ivan Ho Mien and Pavitra Krishnaswamy and Xulei Yang and Jun Cheng},
  doi          = {10.1016/j.neucom.2025.130018},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130018},
  shortjournal = {Neurocomputing},
  title        = {Multimodal multitask similarity learning for vision language model on radiological images and reports},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pinning synchronization of higher-order nonlinear networks
with time delays. <em>NEUCOM</em>, <em>636</em>, 130010. (<a
href="https://doi.org/10.1016/j.neucom.2025.130010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the pinning synchronization problem for a class of nonlinear higher-order time-delay networks. In contrast to previous works, the networks studied possess two distinguishing features: (i) the coupling functions governing the higher-order interactions are nonlinear, and (ii) the networks account for time delays, which include intra-node delays and higher-order interaction delays. The above two features are the key factors influencing the synchronization of the networks. By employing Lyapunov stability theory and algebraic graph theory, we derive sufficient conditions for achieving pinning synchronization in the nonlinear higher-order time-delay networks. Two key challenges in deriving the sufficient conditions arise from the two aforementioned features, which introduce: (i) complex tensor computations and (ii) difficulties in decoupling multi-node interactions. In order to address the challenges, we present a pivotal lemma. This lemma serves as a bridge to transform the complex higher-order problem into a first-order one, reducing the complexity of the derivations. Finally, the validity of the theoretical results is demonstrated through two application examples.},
  archive      = {J_NEUCOM},
  author       = {Weibin Li and Kaixin Lu and Zhichao Liang and Zhongye Xia and Bo Liu and Yanshan Xiao and Quanying Liu},
  doi          = {10.1016/j.neucom.2025.130010},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130010},
  shortjournal = {Neurocomputing},
  title        = {Pinning synchronization of higher-order nonlinear networks with time delays},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M-MDD: A multi-task deep learning framework for major
depressive disorder diagnosis using EEG. <em>NEUCOM</em>, <em>636</em>,
130008. (<a href="https://doi.org/10.1016/j.neucom.2025.130008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Major depressive disorder (MDD) is a common and destructive psychiatric disorder worldwide. Traditional MDD diagnosis relies heavily on subjective observation and questionnaires. Recently, a non-invasive method of recording the brain’s spontaneous activity called Electroencephalogram (EEG) has been a useful tool of MDD diagnosis. However, there are still some challenges to be addressed: (1) The model’s robustness to common EEG noise has to be improved, (2) The temporal, spectral and spatial features of EEG need to be extracted and fused appropriately. Learning both robust and powerful features for MDD diagnosis can improve the overall performance, and multi-task learning is a powerful solution. In this paper, we propose M-MDD, a multi-task deep learning framework for MDD diagnosis using EEG. First, we design the Contrastive Noise Robustness Task to learn noise-independent features. Then, we design the Supervised Feature Extraction Task to extract temporal, spectral and spatial features of EEG respectively, and then effectively combine them together. Finally, the above two modules share the same feature space and are trained jointly with the Multi-task Learning Module, improving the overall performance. Validated on two public MDD diagnosis datasets with subject-independent cross-validation, our model achieves the state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Yilin Wang and Sha Zhao and Haiteng Jiang and Shijian Li and Tao Li and Gang Pan},
  doi          = {10.1016/j.neucom.2025.130008},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130008},
  shortjournal = {Neurocomputing},
  title        = {M-MDD: A multi-task deep learning framework for major depressive disorder diagnosis using EEG},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring interaction: Inner-outer spatial–temporal
transformer for skeleton-based mutual action recognition.
<em>NEUCOM</em>, <em>636</em>, 130007. (<a
href="https://doi.org/10.1016/j.neucom.2025.130007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based methods have achieved significant results in the field of skeleton-based action recognition. However, when dealing with two-person interaction, existing approaches normally embed the skeleton of each person separately and then introduce an additional module to learn their interactions. This risks losing the spatial and semantic connection information between the two entities, which is crucial for interaction identification. To address this issue, a unified interactive spatial–temporal transformer is proposed in this paper. First, a Two-Person Embedding (TPE) is performed to provide a holistic interactive relationship representation, which can effectively avoid the information gap caused by the division of interacting entities. Second, an innovative Inner-Outer Transformer (IOformer) combining with a new spatio-temporal partition strategy is proposed to simultaneously learn the interactions between intra-partition joints and inter-partition skeletal parts. By comprehensively capturing the key spatio-temporal interactive feature, the accuracy and robustness of interaction recognition can be significantly improved. Extensive experiments on three challenging benchmark datasets validate that our method achieves better performance in comprehensive evaluation methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaotian Wang and Xiang Jiang and Zhifu Zhao and Kexin Wang and Yifan Yang},
  doi          = {10.1016/j.neucom.2025.130007},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130007},
  shortjournal = {Neurocomputing},
  title        = {Exploring interaction: Inner-outer spatial–temporal transformer for skeleton-based mutual action recognition},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Texture dominated no-reference quality assessment for high
resolution image by multi-scale mechanism. <em>NEUCOM</em>,
<em>636</em>, 130003. (<a
href="https://doi.org/10.1016/j.neucom.2025.130003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of new media formats, various high-definition display devices are ubiquitous, and high-resolution (HR) images are essential for high-quality visual experiences. Quality assessment of HR images has become an urgent challenge. However, conventional image quality assessment (IQA) methods with good performance are designed for low-resolution (LR) images, which lacks the perceptual characteristics of HR images, resulting in difficult to achieve satisfactory subjective consistency. Moreover, huge computational costs would have to be consumed when applying those deep neural networks in LR-IQA directly to HR images. Inspired by the fact that regions with rich textures are more sensitive to distortion than others, texture dominated no-reference image quality assessment for HR images are proposed in this paper. Specifically, a dual branch network based on multi-scale technology was designed to extract texture and semantic features separately, and cross scale and dual dimensional attention were introduced to ensure the dominance of texture features. Then, multi-layer perception network is used to map the extracted quality perception feature vectors to the predicted quality score. Worthy of note is that local entropy has been calculated and representative blocks are cropped as inputs to the feature extraction network, greatly reducing computational complexity. Overall, the texture dominated high-resolution IQA network (TD-HRNet) proposed utilizes a reference free method, while could perform excellently on HR datasets of different sizes, image types, and distortion types, accurately predicting the quality of different types of HR images.},
  archive      = {J_NEUCOM},
  author       = {Ziqing Huang and Hao Liu and Zhihao Jia and Shuo Zhang and Yonghua Zhang and Shiguang Liu},
  doi          = {10.1016/j.neucom.2025.130003},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130003},
  shortjournal = {Neurocomputing},
  title        = {Texture dominated no-reference quality assessment for high resolution image by multi-scale mechanism},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time synchronization in p-th moment for stochastic
multi-layer neural networks: An adaptive graph-theoretic lyapunov
functional approach. <em>NEUCOM</em>, <em>636</em>, 130002. (<a
href="https://doi.org/10.1016/j.neucom.2025.130002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the p-th moment synchronization problem for a class of stochastic multi-layer neural networks with intra-layer and inter-layer connections is investigated. Due to the multiple connections with delays and stochastic noise, the typical methodologies that build a canonical linear or expanded matrix model to analyze its stability by constraining eigenvalues in the left-half plane, such as the Kronecker product method, linear matrix inequality and M -matrix approach are tough to tackle the problem. Consequently, a graph-theory-based Lyapunov functional is constructed by combining multiplicative principles and a graph-theoretic approach to help examine the effect of inter- and intra-layer connectivity on a unified framework. With the proposed adaptive fixed-time controller, sufficient conditions for the p-th moment synchronization in a fixed time are derived in terms of algebraic inequality. A corollary, together with a constant-gain fixed-time controller, is presented in case there is no delay. Finally, a confirmatory and two comparative simulations show the effectiveness and convenient implementation of the proposed control strategy.},
  archive      = {J_NEUCOM},
  author       = {Guan-Nan Yu and Xiao-Kang Liu and Yan Lei and Yan-Wu Wang},
  doi          = {10.1016/j.neucom.2025.130002},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130002},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time synchronization in p-th moment for stochastic multi-layer neural networks: An adaptive graph-theoretic lyapunov functional approach},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lag-bipartite consensus control of nonlinear multi-agent
systems with exogenous disturbances via dynamic event-triggered
strategy. <em>NEUCOM</em>, <em>636</em>, 130001. (<a
href="https://doi.org/10.1016/j.neucom.2025.130001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the lag-bipartite consensus issue for nonlinear multi-agent systems with external disturbances via event-triggered mechanisms. Firstly, a disturbance observer is devised to offset disturbances induced from ambient noise or parameter uncertainties. To save needless communication among neighbor agents and enhance the system’s anti-disturbance abilities, the centralized event-based approach and a distributed dynamic event-triggered control scheme with internal dynamic parameters are raised via combining the disturbance compensation strategy, respectively. Unlike existent static triggering approaches, this dynamic triggering scheme widens interval duration between two successive triggering instants. On the basis of both control schemes, a few sufficient conditions are provided to reach lag-bipartite consensus for nonlinear multi-agent systems, while Zeno behavior cannot arise via developed triggering rules. Finally, the validity of presented schemes is illustrated under numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Junsheng Yu and Huizhi Xu and Zhongjun Ma},
  doi          = {10.1016/j.neucom.2025.130001},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130001},
  shortjournal = {Neurocomputing},
  title        = {Lag-bipartite consensus control of nonlinear multi-agent systems with exogenous disturbances via dynamic event-triggered strategy},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed approximate aggregative optimization of multiple
euler–lagrange systems using only sampling measurements.
<em>NEUCOM</em>, <em>636</em>, 130000. (<a
href="https://doi.org/10.1016/j.neucom.2025.130000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the distributed aggregative optimization for multiple Euler–Lagrange systems over directed networks. First, a new class of auxiliary aggregative variables is proposed that only utilize sampling measurements of adjacent outputs. Then, by selecting a smoothing function, we can gradually integrate the sampling information into new variables within the sampling period. Given the proposed variables, a key theorem is derived to transform the approximate aggregative optimization problem into a regulation problem, such that classical control methods can be utilized to regulate the aggregative variables for more complex dynamics. In addition, an adaptive fuzzy distributed control law is constructed based on aggregative variables, deadzone function and fuzzy system to solve the aggregative optimization for fully actuated Lagrangian agents with bounded disturbance. Finally, a numerical experiment is conducted to demonstrate the validity and effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Cong Li and Qingling Wang},
  doi          = {10.1016/j.neucom.2025.130000},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130000},
  shortjournal = {Neurocomputing},
  title        = {Distributed approximate aggregative optimization of multiple Euler–Lagrange systems using only sampling measurements},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial–spectral morphological mamba for hyperspectral image
classification. <em>NEUCOM</em>, <em>636</em>, 129995. (<a
href="https://doi.org/10.1016/j.neucom.2025.129995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in transformers, specifically self-attention mechanisms, have significantly improved hyperspectral image (HSI) classification. However, these models often have inefficiencies, as their computational complexity scales quadratically with sequence length. To address these challenges, we propose the morphological spatial mamba (SMM) and morphological spatial–spectral Mamba (SSMM) model (MorpMamba), which combines the strengths of morphological operations and the state space model framework, offering a more computationally efficient alternative to transformers. In MorpMamba, a novel token generation module first converts HSI patches into spatial–spectral tokens. These tokens are then processed through morphological operations such as erosion and dilation, utilizing depthwise separable convolutions to capture structural and shape information. A token enhancement module refines these features by dynamically adjusting the spatial and spectral tokens based on central HSI regions, ensuring effective feature fusion within each block. Subsequently, multi-head self-attention is applied to enrich the feature representations further, allowing the model to capture complex relationships and dependencies within the data. Finally, the enhanced tokens are fed into a state space module, which efficiently models the temporal evolution of the features for classification. Experimental results on widely used HSI datasets demonstrate that MorpMamba achieves superior parametric efficiency compared to traditional CNN and transformer models while maintaining high accuracy. The source code is available at https://github.com/mahmad000/MorpMamba .},
  archive      = {J_NEUCOM},
  author       = {Muhammad Ahmad and Muhammad Hassaan Farooq Butt and Adil Mehmood Khan and Manuel Mazzara and Salvatore Distefano and Muhammad Usama and Swalpa Kumar Roy and Jocelyn Chanussot and Danfeng Hong},
  doi          = {10.1016/j.neucom.2025.129995},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129995},
  shortjournal = {Neurocomputing},
  title        = {Spatial–spectral morphological mamba for hyperspectral image classification},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding motor imagery hand direction in brain computer
interface from direction-dependent modulation of parietal connectivity
using a new brain functional connectivity measure. <em>NEUCOM</em>,
<em>636</em>, 129994. (<a
href="https://doi.org/10.1016/j.neucom.2025.129994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The posterior Parietal Cortex (PPC) of human and nonhuman primates plays a vital role in motor planning. However, EEG functional connectivity correlates within PPC associated with motor intentions are less investigated in the literature. In this study, we investigate whether parietal EEG exhibits direction-dependent modulation of functional connectivity, during bidirectional hand movement imagination in right and left directions. Further, the utility of parietal connectivity modulation patterns, in decoding the directions of imagined hand movement is also evaluated. Imagined movement directions of the dominant hand are decoded using connectivity features derived from parietal EEG. A new brain functional connectivity measure called Cumulative Phase Lag is proposed to evaluate the functional connectivity within the right and left hemispheres of the posterior parietal cortex. Parietal connectivity features are derived from twenty-three EEG subbands from both hemispheres. Further, hemispherical asymmetry is exploited to identify the hemisphere with dominant directive discriminability. Connectivity features of the selected hemisphere are used to identify the most discriminative subband and selected features of the discriminative subband are used to classify the directions of imagined hand movement. The proposed algorithm employing subject-specific connectivity features yielded an average right vs left-hand motor imagery direction decoding accuracy of 79.67 % among 15 healthy subjects. The study results revealed that connectivity patterns in the posterior parietal cortex exhibited direction-dependent variability, suggesting a direction-dependent modulation of connectivity within the posterior parietal cortex. The results suggest the use of the posterior parietal cortex as a potential source of control signals for neuro-prosthetic applications.},
  archive      = {J_NEUCOM},
  author       = {K. Sagila Gangadharan and A.P. Vinod},
  doi          = {10.1016/j.neucom.2025.129994},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129994},
  shortjournal = {Neurocomputing},
  title        = {Decoding motor imagery hand direction in brain computer interface from direction-dependent modulation of parietal connectivity using a new brain functional connectivity measure},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-reference generative exposure correction and adaptive
fusion for low-light image enhancement. <em>NEUCOM</em>, <em>636</em>,
129992. (<a href="https://doi.org/10.1016/j.neucom.2025.129992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing low-light image enhancement methods have the problem of difficulty in enhancing dark areas while controlling overexposed areas in natural images. To address this issue, a Generative Exposure Correction method based on Retinex theory is proposed in this paper, in which the Pseudo-Exposure Residual map and illumination map are deeply coupled based on the proposed intensity compensation prior to constrain the generative network’s output in order to simultaneously deal with overexposure and underexposure. Furthermore, to enhance the effect and prevent over-correction, an exposure fusion technique is proposed, which adaptively selects the best exposure area from the two corrected images and achieves a globally balanced exposure by using an intensity correction compensation operator. More importantly, our proposed method does not require the collection of additional external datasets, which also overcomes the difficulty of data acquisition. Experimental comparisons of our method with the other seven state-of-the-art methods on five public datasets demonstrate that our method achieves the best performance in terms of detail enhancement and natural color preservation.},
  archive      = {J_NEUCOM},
  author       = {Qing Pan and Zirong Zhang and Nili Tian},
  doi          = {10.1016/j.neucom.2025.129992},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129992},
  shortjournal = {Neurocomputing},
  title        = {Zero-reference generative exposure correction and adaptive fusion for low-light image enhancement},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extending evolution-guided policy gradient learning into the
multi-objective domain. <em>NEUCOM</em>, <em>636</em>, 129991. (<a
href="https://doi.org/10.1016/j.neucom.2025.129991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Objective Reinforcement Learning (MORL) poses significant challenges, primarily due to the necessity of balancing conflicting objectives—a limitation that traditional single-objective approaches fail to address. This paper introduces Multi-Objective Evolutionary Reinforcement Learning (MO-ERL), the first adaptation of Evolutionary Reinforcement Learning (ERL) specifically designed to address the complexities of the multi-objective domain effectively. MO-ERL integrates policy gradient-based reinforcement learning (RL), which optimizes expected utility, with evolutionary algorithms (EAs) that maintain diversity across the Pareto front. This combination leverages RL’s strength in exploitation and EAs’ proficiency in exploration, enabling MO-ERL to effectively navigate the trade-offs inherent in multi-objective optimization problems. Evaluation on multi-objective continuous control tasks using the MuJoCo physics engine demonstrates that MO-ERL outperforms state-of-the-art baselines, achieving up to 62.71% higher hypervolume and 196.28% greater expected utility. These results validate MO-ERL’s ability to balance solution diversity and optimality, setting a new benchmark for solving MORL tasks.},
  archive      = {J_NEUCOM},
  author       = {Adam Callaghan and Karl Mason and Patrick Mannion},
  doi          = {10.1016/j.neucom.2025.129991},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129991},
  shortjournal = {Neurocomputing},
  title        = {Extending evolution-guided policy gradient learning into the multi-objective domain},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HSACT: A hierarchical semantic-aware CNN-transformer for
remote sensing image spectral super-resolution. <em>NEUCOM</em>,
<em>636</em>, 129990. (<a
href="https://doi.org/10.1016/j.neucom.2025.129990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral remote sensing technology has demonstrated its spectral diagnosis advantages in numerous remote sensing observation fields. However, hyperspectral imaging is expensive and less portable compared to RGB imaging. To recover the corresponding hyperspectral image (HSI) from a remote sensing RGB image, this paper proposes a new hierarchical semantic-aware convolutional neural network (CNN)-Transformer (HSACT) for remote sensing image spectral super-resolution (SSR). Particularly, this work aims to reconstruct HSIs from RGB images within the same field of view using a lightweight semantic embedding architecture. Our HSACT consists of the following steps. First, an initial spectrum estimation module (from the RGB image to the HSI) is designed to progressively consider spectral estimation between RGB wavelength-inner and wavelength-outer information. Then, an attention-driven semantic-aware CNN-Transformer is developed to reconstruct the spatial and spectral details of HSI. Specifically, a trainable polymorphic superpixel convolution (PSConv) is proposed to capture features efficiently in the above module. Next, we introduce an information-lossless hierarchical network architecture to link the above modules and achieve end-to-end RGB image SSR through weight sharing. Experimental results on several datasets demonstrated that our HSACT outperforms traditional and advanced SSR methods. The codes of this paper are available from https://github.com/chengle-zhou/HSACT .},
  archive      = {J_NEUCOM},
  author       = {Chengle Zhou and Zhi He and Liwei Zou and Yunfei Li and Antonio Plaza},
  doi          = {10.1016/j.neucom.2025.129990},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129990},
  shortjournal = {Neurocomputing},
  title        = {HSACT: A hierarchical semantic-aware CNN-transformer for remote sensing image spectral super-resolution},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCSViT: Efficient and hardware friendly pyramid vision
transformer with channel and spatial self-attentions. <em>NEUCOM</em>,
<em>636</em>, 129987. (<a
href="https://doi.org/10.1016/j.neucom.2025.129987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformers (ViT) have been widely used in various visual tasks and have achieved great success due to their advantageous self-attention mechanism. However, most ViT models focus primarily on spatial self-attention, often overlooking the importance of channel attention. In this paper, we propose a channel self-attention module as a complementary addition to the standard self-attention module in ViTs. Then, we introduce an adaptive feed-forward network designed for different attention modules. Based on the proposed self-attention module and adaptive feed-forward network, we propose a flexible Vision Transformer with channel and spatial attentions (CSViT) and conduct a series of experiments to explore the optimal position of different attention modules. Additionally, we introduce PCSViT, which combines the strengths of CSViT and convolutional neural networks (CNNs). PCSViT features a pyramid architecture and incorporates local spatial attention, global spatial attention, and channel attention. We further explore hardware-friendly designs to efficiently implement and accelerate PCSViT on embedded devices. The performance of the proposed methods is evaluated on small datasets CIFAR and Fashion-MNIST, as well as the larger dataset ImageNet. Experimental results show that the proposed model reduces ViT’s reliance on large datasets and outperforms several lightweight state-of-the-art CNN and ViT models across a range of model sizes. The hardware-friendly designs achieve about 10% acceleration on a RISC-V CPU.},
  archive      = {J_NEUCOM},
  author       = {Xiaofeng Zou and Yuanxi Peng and Guoqing Li and Xinye Cao},
  doi          = {10.1016/j.neucom.2025.129987},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129987},
  shortjournal = {Neurocomputing},
  title        = {PCSViT: Efficient and hardware friendly pyramid vision transformer with channel and spatial self-attentions},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adjustable behavior-guided adaptive dynamic programming for
neural learning control. <em>NEUCOM</em>, <em>636</em>, 129986. (<a
href="https://doi.org/10.1016/j.neucom.2025.129986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an adjustable behavior-guided adaptive dynamic programming (BGADP) algorithm is designed to solve the optimal regulation problem for discrete-time systems. In conventional adaptive dynamic programming methods, gradient information of system dynamics is necessary for conducting policy improvement. However, these methods face challenges when gradient information cannot be computed or when the system dynamics is non-differentiable. To overcome these limitations, a human-behavior-inspired swarm intelligence approach is used to search for superior policies during the iterative process, eliminating the need for gradient information. Additionally, a relaxation factor is introduced into the value function update to accelerate the convergence speed of the algorithm. The monotonicity and convergence properties of the iterative value function are rigorously analyzed. Finally, the effectiveness and practicality of the adjustable BGADP algorithm are validated through two simulation studies, which are implemented using the actor–critic framework with neural networks.},
  archive      = {J_NEUCOM},
  author       = {Guohan Tang and Ding Wang and Ao Liu and Junfei Qiao},
  doi          = {10.1016/j.neucom.2025.129986},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129986},
  shortjournal = {Neurocomputing},
  title        = {Adjustable behavior-guided adaptive dynamic programming for neural learning control},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grid mamba: Grid state space model for large-scale point
cloud analysis. <em>NEUCOM</em>, <em>636</em>, 129985. (<a
href="https://doi.org/10.1016/j.neucom.2025.129985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale point cloud semantic segmentation aims to classify scene point clouds at the pixel level, which is crucial for understanding 3D real-world scenes. Existing Transformer-based models for point cloud segmentation face the challenge of quadratic computational complexity, limiting their ability to handle high-resolution and large-scale point clouds. Inspired by the recently proposed Mamba model, known for its efficient long-sequence modeling capabilities, we propose Grid Mamba in this work, which is a specialized network tailored for large-scale point cloud learning, achieving global linear computational complexity. Grid Mamba’s highlights consist of three parts: Grid Multi-view Scanning, Grid Sparsity Pooling, and Grid Mamba Block. Grid Multi-view Scanning can reduce the loss of spatial proximity caused by serialization. Grid Sparsity Pooling addresses the issue of local information loss during the pooling stage of large-scale point clouds. Additionally, Grid Mamba Block overcomes the limitations of Mamba in scene point cloud feature interactions. Extensive experimental results demonstrate that Grid Mamba achieves outstanding performance across multiple indoor and outdoor scene datasets.},
  archive      = {J_NEUCOM},
  author       = {Yulong Yang and Tianzhou Xun and Kuangrong Hao and Bing Wei and Xue-song Tang},
  doi          = {10.1016/j.neucom.2025.129985},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129985},
  shortjournal = {Neurocomputing},
  title        = {Grid mamba: Grid state space model for large-scale point cloud analysis},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GCD-net: Global consciousness-driven open-vocabulary
semantic segmentation network. <em>NEUCOM</em>, <em>636</em>, 129982.
(<a href="https://doi.org/10.1016/j.neucom.2025.129982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-vocabulary semantic segmentation aims to achieve accurate classification of different categories of pixels, even if these categories are not explicitly labeled during training. The current research trend in this field emphasizes the utilization of pre-trained visual–language models to augment exploration capabilities. The core of these methods is to use image-level models to guide the segmentation process at the pixel level, thereby enhancing the model’s ability to recognize and segment unseen categories during training. However, many approaches overlook global information, which may lead to a lack of comprehensive scene understanding when processing images. Thereby, GCD-Net is introduced as an innovative open-vocabulary semantic segmentation framework, which integrates a novel decoder with a hierarchical encoder to form an encoder–decoder architecture. The hierarchical encoder leverages a hierarchical backbone network to generate a pixel-level image–text cost map, which preserves spatial information effectively at different levels. The proposed decoder, known as the Feature Fusion Decoder, comprises three pivotal modules: the Global Feature Extraction Module, the Visual Enhancement Module, and the Feature Aggregation Module. These modules cooperate to process hierarchical feature maps from different levels to capture global context information and effectively aggregate pixel blocks into semantic regions for high-quality open-vocabulary semantic segmentation. Experiments on multiple open-vocabulary semantic segmentation datasets demonstrate that GCD-Net achieves an mIoU score of 17.5% on PC-459 and 94.3% on PAS-20, verifying the effectiveness and superiority of the method.},
  archive      = {J_NEUCOM},
  author       = {Xing Wu and Zhenyao Xu and Quan Qian and Bin Huang},
  doi          = {10.1016/j.neucom.2025.129982},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129982},
  shortjournal = {Neurocomputing},
  title        = {GCD-net: Global consciousness-driven open-vocabulary semantic segmentation network},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized inverse dead-zone formation control using
reinforcement learning for the nonlinear single-integrator dynamic
multi-agent system. <em>NEUCOM</em>, <em>636</em>, 129981. (<a
href="https://doi.org/10.1016/j.neucom.2025.129981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an optimized inverse dead-zone formation control using identifier–critic–actor reinforcement learning (RL) is studied for the nonlinear single-integral dynamic multi-agent system (MAS). Since MAS formation is often accompanied with a high energy expenditure, it is very necessary and essential to take optimization as a control design principle. In order to smoothly achieve the optimized MAS formation control, a simplified RL is developed by performing the gradient descent method to a simple positive function, which is equivalent to Hamilton–Jacobi–Bellman (HJB) equation. Furthermore, since the MAS formation cooperation is depended on the information exchange among agents, it is very possible to happen the control dead-zone phenomenon, which makes the actuator without control signal. For eliminating the effect of dead-zone, an adaptive inverse dead-zone method is developed and then is combined with RL for this optimized formation control. In comparison to the conventional inverse dead-zone approach, this design has the less adaptive parameters. Finally, the results of theoretical and simulation demonstrate viability of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Guoxing Wen and Wenxia Sun and Shuaihua Ma},
  doi          = {10.1016/j.neucom.2025.129981},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129981},
  shortjournal = {Neurocomputing},
  title        = {Optimized inverse dead-zone formation control using reinforcement learning for the nonlinear single-integrator dynamic multi-agent system},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shading- and geometry-aware lighting calibration network for
uncalibrated photometric stereo. <em>NEUCOM</em>, <em>636</em>, 129979.
(<a href="https://doi.org/10.1016/j.neucom.2025.129979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional measurement provides essential geometric information for fault diagnosis and product optimization in intelligent manufacturing applications. Photometric stereo is a non-destructive 3D measurement technique that estimates the surface normals of objects using shading cues from images under different lighting conditions. However, the generalized bas-relief (GBR) ambiguity caused by unknown or varying lighting will significantly decrease measurement accuracy. To address this issue, we propose a shading- and geometry-aware lighting calibration network (SGLC-Net) to mitigate the inherent ambiguity and enhance surface normal estimation in uncalibrated photometric stereo by generating accurate lighting information. The proposed method iteratively optimizes lighting direction and intensity by leveraging self-generated shading and normal prior features. To further improve the accuracy of the lighting estimation, we introduce collocated light into SGLC-Net to implicitly extract shading features of images to generate accurate rough lighting. Accurate rough lighting can generate accurate shading and normal prior features, which can be used to optimize rough lighting to generate fine lighting. Experimental results indicate that the proposed method significantly outperforms most uncalibrated photometric stereo methods in lighting estimation on multiple real-world datasets. Furthermore, our method can seamlessly integrate with most uncalibrated photometric stereo methods to effectively enhance the accuracy of the surface normal estimation under unknown illumination.},
  archive      = {J_NEUCOM},
  author       = {Yuze Yang and Jiahang Liu and Yangyu Fu and Yue Ni and Yan Xu},
  doi          = {10.1016/j.neucom.2025.129979},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129979},
  shortjournal = {Neurocomputing},
  title        = {Shading- and geometry-aware lighting calibration network for uncalibrated photometric stereo},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing offline reinforcement learning for wastewater
treatment via transition filter and prioritized approximation loss.
<em>NEUCOM</em>, <em>636</em>, 129977. (<a
href="https://doi.org/10.1016/j.neucom.2025.129977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wastewater treatment plays a crucial role in urban society, requiring efficient control strategies to optimize its performance. In this paper, we propose an enhanced offline reinforcement learning (RL) approach for wastewater treatment. Our algorithm improves the learning process. It uses a transition filter to sort out low-performance transitions and employs prioritized approximation loss to achieve prioritized experience replay with uniformly sampled loss. Additionally, the variational autoencoder is introduced to address the problem of distribution shift in offline RL. The proposed approach is evaluated on a nonlinear system and wastewater treatment simulation platform, demonstrating its effectiveness in achieving optimal control. The contributions of this paper include the development of an improved offline RL algorithm for wastewater treatment and the integration of transition filtering and prioritized approximation loss. Evaluation results demonstrate that the proposed algorithm achieves lower tracking error and cost.},
  archive      = {J_NEUCOM},
  author       = {Ruyue Yang and Ding Wang and Menghua Li and Chengyu Cui and Junfei Qiao},
  doi          = {10.1016/j.neucom.2025.129977},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129977},
  shortjournal = {Neurocomputing},
  title        = {Enhancing offline reinforcement learning for wastewater treatment via transition filter and prioritized approximation loss},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VLSG-net: Vision-language scene graphs network for paragraph
video captioning. <em>NEUCOM</em>, <em>636</em>, 129976. (<a
href="https://doi.org/10.1016/j.neucom.2025.129976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paragraph Video captioning seeks to automatically describe multiple events in a video. Despite significant progress, most current approaches fail to fully leverage scene graph knowledge when performing cross-modal alignment between video and text representations. Consequently, such methods may not learn causal associations between entities, leading to a degradation in captioning performance. In this paper, we propose an end-to-end Vision-Language Scene Graphs Network (VLSG-net) to address this issue. We first introduce an encoder that integrates scene graph knowledge with global features and predicates to understand visual scenes. Specifically, scene graph knowledge detects entities and models their correlations and constraints, enabling the representation of relationships between various entities. We then introduce a Knowledge-Enhanced Encoder paired with a contrastive loss to leverage scene graph knowledge, thereby enhancing multimodal structured representations. Finally, we propose a transformer-in-transformer decoder to model the coherency of intra- and inter-event relationships within the video and generate captions. By incorporating relationship reasoning among entities through scene graphs and video-language alignment learning, VLSG-net generates more logical and detailed captions. Extensive experiments confirm that VLSG-net performs favorably against the state-of-the-art methods on two widely used benchmark datasets, ActivityNet Captions, and YouCookII.},
  archive      = {J_NEUCOM},
  author       = {Yufeng Hou and Qingguo Zhou and Hui Lv and Lan Guo and Yan Li and La Duo and Zhenyu He},
  doi          = {10.1016/j.neucom.2025.129976},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129976},
  shortjournal = {Neurocomputing},
  title        = {VLSG-net: Vision-language scene graphs network for paragraph video captioning},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving and byzantine-robust federated broad
learning with chain-loop structure. <em>NEUCOM</em>, <em>636</em>,
129975. (<a href="https://doi.org/10.1016/j.neucom.2025.129975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) can collaboratively train a model by aggregating local models instead of aggregating raw data, which can protect privacy by ensuring that data remains on the client. However, the traditional FL still faces some challenges such as privacy leakage and the presence of Byzantine clients. We propose a privacy-preserving and Byzantine-robust federated broad learning framework with chain-loop structure i.e., PBFBL-CL, and this algorithm can simultaneously achieve protection of clients’ privacy and robustness against Byzantine attacks. In this paper, we apply Byzantine step-by-step co-validation algorithm to address the existence of Byzantine clients. We pass the aggregated model through the chain, so each client’s privacy is well protected. Moreover, PBFBL-CL can reduce the communication overhead between clients and server. Finally, we evaluate the PBFBL-CL algorithm in MNIST, Fashion-MNIST and NORB datasets, and the results show that our algorithm is better than existing FL algorithms in terms of model accuracy and training speed. Experimental results demonstrate that under the extreme scenario where Byzantine client proportion reaches 90%, the model achieves an accuracy of 89.53%, only 4.17% lower than the 93.7% accuracy observed in the ideal scenario without Byzantine clients.},
  archive      = {J_NEUCOM},
  author       = {Nan Li and Chang-E Ren and Siyao Cheng},
  doi          = {10.1016/j.neucom.2025.129975},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129975},
  shortjournal = {Neurocomputing},
  title        = {Privacy-preserving and byzantine-robust federated broad learning with chain-loop structure},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectrum-guided spatial feature enhancement network for
event-based lip-reading. <em>NEUCOM</em>, <em>636</em>, 129974. (<a
href="https://doi.org/10.1016/j.neucom.2025.129974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Automatic Lip-reading task aims to recognize spoken words through visual cues from the speaker’s lip movements. This crucial task complements audio-based speech recognition systems and can substitute them when sound is unavailable. Event-based lip-reading methods have gained increasing attention due to the advantages of event cameras, such as high temporal resolution and low power consumption. However, existing methods often fail to fully utilize the spatial information in event data due to its sparsity and the presence of random activations. To address this, we propose a novel Spectral-guided Spatial Enhancement Network (SSE-Net). SSE-Net introduces two core innovations: the Spectrum-guided Spatial Feature Enhance Module (SSEM) and the Multi-Scale Spatial Interaction Module (MS-SIM). SSEM employs frequency domain enhancement and spatial feature enhancement strategies to augment spatial features crucial for event-based lipreading tasks. MS-SIM conducts the fusion and interaction of multi-level semantics, enriching the contextual information of lip representations. We conducted experiments on the event-based lip-reading dataset DVS-Lip with our proposed method and demonstrated its superiority over other state-of-the-art event-based lip-reading methods.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Xiuping Liu and Hongchen Tan and Xin Li},
  doi          = {10.1016/j.neucom.2025.129974},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129974},
  shortjournal = {Neurocomputing},
  title        = {Spectrum-guided spatial feature enhancement network for event-based lip-reading},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HRL-painter: Optimal planning painter based on hierarchical
reinforcement learning. <em>NEUCOM</em>, <em>636</em>, 129972. (<a
href="https://doi.org/10.1016/j.neucom.2025.129972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke-based rendering method has shown its superiority in generating stylized paintings from realistic photographs. However, the existing methods often divide the image into regular blocks for parallel painting or start painting by progressively narrowing down the painting region from the entire canvas. Not only does this lead to an irrational allocation of stroke resources, but also deviates from the painting approach employed by human artists. To address this, we propose a novel painting method based on hierarchical reinforcement learning, namely HRL-Painter, which consists of a high-level agent that strategically plans the sequence of painting regions and a low-level agent that carries out specific painting tasks in the corresponding regions. In the initial stage, we consider the entire canvas as the painting region and then use a small number of strokes for a rough depiction. Next, our high-level agent plans the optimal sequence of painting regions based on the content of the target image, taking into account the error between the current canvas and the target image. Finally, the low-level agent is dedicated to executing detailed painting tasks within the painting regions proposed by the high-level agent. Extensive experiments on standard datasets including CelebA , ImageNet , CUB-200 Birds and Stanford Cars-196 demonstrate that our proposed hierarchical painting agent not only produce high-quality canvases but also exhibit a painting process that closely resembles the human painting style, showcasing excellent interpretability.},
  archive      = {J_NEUCOM},
  author       = {Jiong Zhang and Guangxin Xu and Xiaoyan Zhang},
  doi          = {10.1016/j.neucom.2025.129972},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129972},
  shortjournal = {Neurocomputing},
  title        = {HRL-painter: Optimal planning painter based on hierarchical reinforcement learning},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed neural predictor enhanced coordinated control of
AUVs. <em>NEUCOM</em>, <em>636</em>, 129971. (<a
href="https://doi.org/10.1016/j.neucom.2025.129971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates an enhanced tunnel prescribed performance coordinated control problem of multiple autonomous underwater vehicles (AUVs) under initial constraints. To meet high performance requirements in complex underwater conditions, AUV control faces challenges. In order to address these, an enhanced tunnel prescribed performance (ETPP) method is proposed, which is composed of composite error scaling function (CESF) and tunnel prescribed performance (TPP). In particular, a CESF-based error transformation is performed to scale the tracking error within the TPP limits. In the guidance loop, an ETPP-based guidance law is devised to guarantee the transient and steady-state behavior of the tracking error. In the control loop, based on the distributed learning strategy with weighted average, a quantized input-based distributed neural predictor (QDNP) is proposed to estimate the unknown external disturbances. Using the antidisturbance technique, a QDNP-based quantized control law is designed to stabilize multi-AUV formations. The uniformly ultimately bounded (UUB) stability of the overall closed-loop system is established in the Lyapunov sense. Finally, simulation examples with four AUVs are provided to demonstrate the effectiveness of the proposed distributed tunnel performance-guaranteed coordinated control method.},
  archive      = {J_NEUCOM},
  author       = {Minjing Wang and Di Wu and Lei Qiao and Rui Gao and Wenlong Feng},
  doi          = {10.1016/j.neucom.2025.129971},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129971},
  shortjournal = {Neurocomputing},
  title        = {Distributed neural predictor enhanced coordinated control of AUVs},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rad-mark: Reliable adversarial zero-watermarking.
<em>NEUCOM</em>, <em>636</em>, 129970. (<a
href="https://doi.org/10.1016/j.neucom.2025.129970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-watermarking is a lossless protection technique, and thus it is widely used in medical images, artworks and other carriers that require lossless protection. However, the current zero-watermarking suffers from the problem of high similarity between the feature images of different host images, which results in a high false positive rate. To address this challenge, we propose Rad-Mark, a deep learning-based zero-watermarking framework that leverages adversarial feature optimization to enhance the robustness and accuracy of watermark detection significantly for the first time. The adversarial samples are employed to significantly improve the framework’s security, which can achieve the NC value of false positives close to 0.5. Both image perturbation and Gaussian noise are incorporated into the training process. Specifically, our Rad-Mark involves a feature fusion design, a mapping network based on the fusion of locally filtered and global handcrafted features. We conduct an in-depth analysis of key parameters, including Gaussian noise, watermark dimensions, and weighting factors, exploring their impact on the performance of our Rad-Mark. Extensive experimental results demonstrate that Rad-Mark outperforms existing zero-watermarking methods in terms of both security and robustness.},
  archive      = {J_NEUCOM},
  author       = {Kun Hu and Dakai Zhai and Heng Gao and Haoyu Xie and Xingjun Wang},
  doi          = {10.1016/j.neucom.2025.129970},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129970},
  shortjournal = {Neurocomputing},
  title        = {Rad-mark: Reliable adversarial zero-watermarking},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An event-triggered reliable cloud control scheme based on
ADP and integral sliding mode. <em>NEUCOM</em>, <em>636</em>, 129968.
(<a href="https://doi.org/10.1016/j.neucom.2025.129968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates event-triggered (ET) reliable control problems for cloud control systems under actuator faults and data injection attacks via the adaptive dynamic programming (ADP) and integral sliding mode (ISM). A mist-fog-regional cloud control architecture is first given, which can improve computing efficiency of the cloud platform. In this architecture, a fog-based fault parameter estimation method is proposed with the aid of neural networks. It is driven by the feedback of fault parameter estimation errors, so as to achieve more accurate estimations of fault parameters. A double ET reliable cloud control scheme is further presented. It is composed of an ISM-based and an ADP-based regional cloud controllers. As a result, it not only saves communication resources, but also eliminates the influence of the attacks and matched uncertainties, as well as ensures the stability of the equivalent sliding-mode dynamics with optimal performance. Finally, the effectiveness of the proposed method is verified by the simulation results.},
  archive      = {J_NEUCOM},
  author       = {Xin Huang and Sicheng Bi and Xinyu Han and Shuyi Xiao and Qingyu Su},
  doi          = {10.1016/j.neucom.2025.129968},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129968},
  shortjournal = {Neurocomputing},
  title        = {An event-triggered reliable cloud control scheme based on ADP and integral sliding mode},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A memory failure computational model in alzheimer-like
disease via continuous delayed hopfield network with lurie control
system based healing. <em>NEUCOM</em>, <em>636</em>, 129967. (<a
href="https://doi.org/10.1016/j.neucom.2025.129967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a degenerative neurological condition that impacts millions of individuals across the globe and remains without a healing. In the search for new possibilities of treatments for this terrible disease, this work presents the improved Alzheimer-like disease (IALD) model for memory failure and connects it to a new control technique that establishes a cure for the memory lost, either in biological or in artificial neural networks. For the IALD model, continuous Hopfield neural networks (HNN) with time delay are used. From the healing side, a robust control technique is used, which is based on new discoveries in Lurie control systems. In addition, this paper reviews the development of Alzheimer-like disease (ALD) model, as well as, the relationship of HNN with Lurie system. Simulations are executed to validate the model and to show the efficacy of applying a new theorem from Lurie problem. With the results presented, this work proposes a new conceptual paradigm that could potentially be applied in memory failure treatments in AD, as well as in hardware implemented HNN under adversarial attacks or adverse environmental conditions.},
  archive      = {J_NEUCOM},
  author       = {Rafael Fernandes Pinheiro and Diego Colón and Rui Fonseca-Pinto},
  doi          = {10.1016/j.neucom.2025.129967},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129967},
  shortjournal = {Neurocomputing},
  title        = {A memory failure computational model in alzheimer-like disease via continuous delayed hopfield network with lurie control system based healing},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained hierarchical singular value decomposition for
convolutional neural networks compression and acceleration.
<em>NEUCOM</em>, <em>636</em>, 129966. (<a
href="https://doi.org/10.1016/j.neucom.2025.129966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) still remain crucial in the field of computer vision, especially in industrial-embedded scenarios. Although modern artificial intelligence chips such as embedded graphics processing units (GPUs) and neural process units (NPUs) are equipped with sufficient computability, making CNNs more lightweight always has non-negligible significance. Until now, many researchers have made multiple corresponding achievements, in which a series of tensor decomposition methods have represented their unique advantages such as concision, flexibility, and low-rank approximation theory. However, balancing the compression, acceleration, and precision, is still an open issue, because the traditional tensor decompositions are hard to deal with the trade-off between approximation and compression ability, while the so-called fine-grained tensor decompositions such as Kronecker canonical polyadic (KCP) have not created a way to merge the factors for efficient inference. In this paper, we first review related works on convolutional neural network (CNN) compression and the necessary prior knowledge. We then propose a novel matrix decomposition method, termed hierarchical singular value (HSV) decomposition, and validate its effectiveness. Subsequently, we introduce a fast contraction strategy based on the merged factors of HSV and explain how our method addresses the inefficiencies in inference associated with traditional contraction processes. Additionally, we validate the advantages of HSV by comparing its complexity with that of other classical tensor decomposition methods. Thereafter, we apply HSV to CNN compression and acceleration by transforming convolution operations into matrix multiplication. We also propose a self-adaptive rank selection algorithm tailored to standard CNN architecture and conduct a theoretical analysis of the convergence of our method. Multiple experiments on CIFAR-10, ImageNet, COCO, and Cityscapes benchmark datasets show that the proposed HSV-Conv can simultaneously gain considerable compression ratio and acceleration ratio, while the precision loss is almost non-existent. We also make a comprehensive comparison with the other related works, and the superiority of our method is further validated. Besides, we give a deep discussion about the rank selection issue of HSV in the aspects of practice and theory, which explains the strategy of the proposed self-adaptive rank selection and the reason for choosing fine-tuning rather than training from scratch.},
  archive      = {J_NEUCOM},
  author       = {Mengmeng Qi and Dingheng Wang and Wei Yang and Baorong Liu and Fuyong Wang and Zengqiang Chen},
  doi          = {10.1016/j.neucom.2025.129966},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129966},
  shortjournal = {Neurocomputing},
  title        = {Fine-grained hierarchical singular value decomposition for convolutional neural networks compression and acceleration},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level feature splicing 3D network based on multi-task
joint learning for video anomaly detection. <em>NEUCOM</em>,
<em>636</em>, 129964. (<a
href="https://doi.org/10.1016/j.neucom.2025.129964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In video anomaly detection research, deep learning is dedicated to identifying anomalous events accurately and efficiently. However, due to the scarcity and diversity of anomaly samples, previous methods have not adequately taken into account important information about location and timing. In addition, the overpowered generalization ability of the models leads to the fact that anomalies can also be well reconstructed or predicted. To address the above challenges, we propose a 3D network based on multi-level feature splicing with joint multi-task learning. The network is improved by the autoencoder (AE) as a backbone network. Firstly, we design a normal sample training task and a Gaussian noise task from a spatial perspective to enhance the reconstruction of positive samples. The frame-skipping task and the inverse sequence task of the video are designed from the temporal perspective to suppress the reconstruction ability of negative samples. Secondly, we use multi-level feature splicing in the encoding and decoding process to equip the network with the ability to explore sufficient information from the full scale. At the same time, we use an attention gating module to filter redundant features. The results show that our network is competitive with state-of-the-art methods. In terms of AUC, UCSD Ped2 achieves 99.3%, CUHK Avenue achieves 88.4%, and ShanghaiTech Campus achieves 74.2%.},
  archive      = {J_NEUCOM},
  author       = {Yang Li and Guoxiang Tong},
  doi          = {10.1016/j.neucom.2025.129964},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129964},
  shortjournal = {Neurocomputing},
  title        = {Multi-level feature splicing 3D network based on multi-task joint learning for video anomaly detection},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). L2M-GCN: A new framework for learning robust GCN against
structural attacks. <em>NEUCOM</em>, <em>636</em>, 129962. (<a
href="https://doi.org/10.1016/j.neucom.2025.129962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) have gained extensive attention due to their strong ability to learn from graphs. However, with the advent of stealthy attacks that cause significant differences in node embeddings, the vulnerability of GCNs to malicious attacks has been exposed. Although there are many studies on defense in the spatial or spectral domains, they neglect the complementary roles of the two. In this paper, we propose a new framework, Low frequency and 2-hop in Multi-channel GCN (L2M-GCN), which combines spatial and spectral defense. L2M-GCN has two GCN-based modules. In module one, a new structure reconstructed from learnable spectrum and low-frequency components replaces the adjacency matrix in GCN. In module two, purified 2-hop is introduced and the attention mechanism is used to learn the importance weights of node embeddings. The two modules are eventually assembled into L2M-GCN for joint learning in a parameter-sharing and end-to-end fashion. Extensive experiments demonstrate that L2M-GCN significantly improves the defense performance against structural attacks and outperforms the baselines and state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Haoran Chen and Xianchen Zhou and Jiwei Zhang and Hongxia Wang},
  doi          = {10.1016/j.neucom.2025.129962},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129962},
  shortjournal = {Neurocomputing},
  title        = {L2M-GCN: A new framework for learning robust GCN against structural attacks},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channel pruning for convolutional neural networks using
l0-norm constraints. <em>NEUCOM</em>, <em>636</em>, 129925. (<a
href="https://doi.org/10.1016/j.neucom.2025.129925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Channel pruning can effectively reduce the size and inference time of Convolutional Neural Networks (CNNs). However, existing channel pruning methods still face several issues, including high computational costs, extensive manual intervention, difficulty in hyperparameter tuning, and challenges in directly controlling the sparsity. To address these issues, this paper proposes two channel pruning methods based on l 0 -norm sparse optimization: the l 0 -norm Pruner and the Automated l 0 -norm Pruner. The l 0 -norm Pruner formulates the channel pruning problem as a sparse optimization problem involving the l 0 -norm and achieves a fast solution through a series of approximations and transformations. Inspired by this solution process, we devise the Zero-Norm (ZN) module, which can autonomously select output channels for each layer based on a predefined global pruning ratio. This approach incurs low computational cost and allows for precise control over the overall pruning ratio. Furthermore, to further enhance the performance of the pruned model, we have developed the Automated l 0 -norm Pruner. This method utilizes a Bee Colony Optimization algorithm to adjust the pruning ratio, mitigating the negative impact of manually preset pruning ratios on model performance. Our experiments demonstrate that the proposed pruning methods outperform several state-of-the-art techniques. The source code for our proposed methods is available at: https://github.com/TCCofWANG/l0_prune .},
  archive      = {J_NEUCOM},
  author       = {Enhao Chen and Hao Wang and Zhanglei Shi and Wei Zhang},
  doi          = {10.1016/j.neucom.2025.129925},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129925},
  shortjournal = {Neurocomputing},
  title        = {Channel pruning for convolutional neural networks using l0-norm constraints},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade-UDA: A cascade paradigm for unsupervised domain
adaptation. <em>NEUCOM</em>, <em>636</em>, 129924. (<a
href="https://doi.org/10.1016/j.neucom.2025.129924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) aims to enhance the performance of models on unlabeled target domains by utilizing labeled data from a related source domain. However, existing UDA methods often struggle with semantic confusion and distribution shifts. To address these issues, we propose a novel two-stage UDA framework called Cascade-UDA. In the first stage, we fine-tune CLIP-LoRA on the source domain to learn class-related, domain-invariant features while preserving semantic integrity. In the second stage, we freeze the fine-tuned CLIP-LoRA and introduce a textual prompt for target domain adaptation, refining pseudo-labels with knowledge from the source domain. Our proposed method effectively decouples semantic learning from domain-specific adaptation, enhancing performance on the target domain. Extensive experiments on public datasets demonstrate the superiority of our approach over existing methods.},
  archive      = {J_NEUCOM},
  author       = {Mengmeng Zhan and Zongqian Wu and Huafu Xu and Xiaofeng Zhu and Rongyao Hu},
  doi          = {10.1016/j.neucom.2025.129924},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129924},
  shortjournal = {Neurocomputing},
  title        = {Cascade-UDA: A cascade paradigm for unsupervised domain adaptation},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-ELWNet: A lightweight object detection network.
<em>NEUCOM</em>, <em>636</em>, 129904. (<a
href="https://doi.org/10.1016/j.neucom.2025.129904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a YOLO-based efficient lightweight network (YOLO-ELWNet) for onboard object detection based on the YOLOv3. A channel split and shuffle with coordinate attention module is developed in the backbone block, which effectively reduces the size of model parameters and computational cost while maintaining the detection accuracy. A new feature fusion network is proposed in the neck block, where a cross-stage partial with efficient bottleneck module is put forward to improve the feature extraction ability and reduce the computational cost. The Scylla intersection over union-based loss function is utilized in the head block, which accelerates the convergence speed of the YOLO-ELWNet. The effectiveness of the proposed YOLO-ELWNet is validated on the open source KITTI vision benchmark. The performance of YOLO-ELWNet is superior to some mainstream lightweight object detection models in terms of detection accuracy and computational cost, which demonstrates its applicability for resource-constrained onboard object detection.},
  archive      = {J_NEUCOM},
  author       = {Baoye Song and Jianyu Chen and Weibo Liu and Jingzhong Fang and Yani Xue and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2025.129904},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129904},
  shortjournal = {Neurocomputing},
  title        = {YOLO-ELWNet: A lightweight object detection network},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCFT: Dependency-aware continual learning fine-tuning for
sparse LLMs. <em>NEUCOM</em>, <em>636</em>, 129897. (<a
href="https://doi.org/10.1016/j.neucom.2025.129897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the size of Large Language Models (LLMs) increasing, they exhibit enhanced capabilities in general intelligence but also present greater challenges in deployment. Consequently, compressing LLMs has become critically important. Among the various compression techniques, post-training pruning is highly favored by researchers due to its efficiency. However, this one-shot pruning approach often results in a significant deterioration of model performance. To mitigate this issue, we introduce Dependency-aware Continual learning Fine-Tuning (DCFT) for sparse LLMs. This method facilitates fine-tuning across sequential tasks without compromising the model’s sparsity. Initially, we revisit the inference process in LLMs from a novel perspective, treating two matrices that previously required independent optimization as a unified entity. This strategy involves introduces merely 0.011‰ additional parameters to achieve efficient fine-tuning. Furthermore, we re-evaluate the parameter fine-tuning process through the lens of matrix space mapping. By constraining the similarity of the mapping matrices, our approach enables the model to retain its performance on prior tasks while learning new ones. We tested our method on models from the LLaMA-V1/V2 families, with parameters ranging from 7B to 70B, and under various sparsity ratios and patterns (unstructured and N:M sparsity). The results consistently demonstrate outstanding performance.},
  archive      = {J_NEUCOM},
  author       = {Yanzhe Wang and Yizhen Wang and Baoqun Yin},
  doi          = {10.1016/j.neucom.2025.129897},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129897},
  shortjournal = {Neurocomputing},
  title        = {DCFT: Dependency-aware continual learning fine-tuning for sparse LLMs},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel spatiotemporal network to recognize
micro-expression. <em>NEUCOM</em>, <em>636</em>, 129891. (<a
href="https://doi.org/10.1016/j.neucom.2025.129891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expressions are fleeting spontaneous facial expressions that commonly occur in high-stakes scenarios and reflect humans’ mental states. Thus, it is one of the crucial clues for lie detection. Furthermore, due to the brief duration of micro-expression, temporal information is important for micro-expression recognition. The paper proposes a Parallel Spatiotemporal Network (PSN) to recognize micro-expression. The proposed PSN includes a spatial sub-network and a temporal sub-network. The spatial sub-network is a shallow network with subtle motion information as the input. And the temporal sub-network is a network with a novel temporal feature extraction unit that extracts sparse temporal features of micro-expressions. Finally, we propose an element-wise addition with 1 × 1 convolutional kernel fusion model to fuse the spatial and temporal features. The proposed PSN gets better measurement metrics (such as recognition rate, F1 score, true positive rate, and true negative rate) than the other state-of-the-art methods on the consisted databases consisting of CASME, CASME II, CAS(ME) 2 , and SAMM.},
  archive      = {J_NEUCOM},
  author       = {Jingting Li and Su-Jing Wang and Yong Wang and Haoliang Zhou and Xiaolan Fu},
  doi          = {10.1016/j.neucom.2025.129891},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129891},
  shortjournal = {Neurocomputing},
  title        = {Parallel spatiotemporal network to recognize micro-expression},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Farewell to CycleGAN: Single GAN with decoupled constraint
for unpaired image dehazing. <em>NEUCOM</em>, <em>636</em>, 129888. (<a
href="https://doi.org/10.1016/j.neucom.2025.129888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unpaired image dehazing has attracted more and more attention, since the pair-wise training data which is prerequisite for the supervised dehazing methods leads to high cost if they are really captured or performance degradation on the real-hazy scenes if they are synthesized. The existing methods for unpaired image dehazing are all based on the CycleGAN-like framework with pixel-to-pixel constraint, which leads to burdensome model complexity and unstable training. In this paper, we propose a novel single GAN model for unpaired image dehazing (SinGAN-Dehaze), which gets rid of the cycle-consistency constraint. To be specific, the cycle-consistency is decoupled to content-consistency and style-consistency, where the pixel-to-pixel mapping is replaced by the patch-to-patch semantic mapping. The content-consistency is ensured by capturing local distinctive representations and global contextual dependencies. The style-consistency is achieved by forcing the high-frequency information distribution of dehazing result close to that of the clear image with similar style. Extensive experiments demonstrate that our proposal can achieve superior performance for unpaired image dehazing in terms of the objective index and visual effect on both synthetic and real-hazy scenarios.},
  archive      = {J_NEUCOM},
  author       = {Xiaotong Luo and Wenjin Yang and Yuan Xie and Yanyun Qu},
  doi          = {10.1016/j.neucom.2025.129888},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129888},
  shortjournal = {Neurocomputing},
  title        = {Farewell to CycleGAN: Single GAN with decoupled constraint for unpaired image dehazing},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid approach combining sentiment analysis and deep
learning to mitigate data sparsity in recommender systems.
<em>NEUCOM</em>, <em>636</em>, 129886. (<a
href="https://doi.org/10.1016/j.neucom.2025.129886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of recommendation systems (RS) is crucial for delivering personalized product suggestions. Despite their successes, RS approaches often face challenges, such as data sparsity in the user–item matrix, which can undermine their performance. To address these challenges, integrating additional information sources, such as item/user profiles and textual reviews, is essential. These sources offer valuable insights into user preferences and item characteristics, helping in understanding the contextual details of both. This study focuses on developing an advanced RS architecture that combines Singular Value Decomposition (SVD) with BERT-CB methods and a Hybrid Model-based Sentiment Analysis. By integrating BERT with Multilayer Perceptron (MLP) methods, the system gains a deeper understanding of item profiles, improving the comprehension of user preferences and item characteristics. Additionally, a novel hybrid approach for sentiment analysis is proposed, using GloVe embeddings and CNN-BiGRU, improving the accuracy and robustness of sentiment detection in user reviews. This comprehensive understanding, combined with collaborative filtering models like SVD, enables the system to provide highly accurate recommendations. The proposed approach consists of four main phases: first, embedding review text using GloVe embeddings and developing a hybrid sentiment analysis approach with CNN and BiGRU architectures; second, creating a BERT language model for generating embeddings from item profile texts, followed by dimensionality reduction using Auto-Encoder; third, using these vectors to build a novel MLP model; fourth, developing a Collaborative Filtering method using SVD, and finally, combining these methods into a hybrid approach and conducting a comprehensive evaluation. Empirical results clearly show the effectiveness of our approach, particularly the combination of GloVe-CNN-BiGRU and BERT-CB with SVD methodology, demonstrating significant improvements across various performance metrics. This confirms the practical value of using contextualized data from BERT-CB and the sentiment analysis approach, enhancing the recommendation system’s effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Ikram Karabila and Nossayba Darraz and Anas El-Ansari and Nabil Alami and Mostafa El Mallahi},
  doi          = {10.1016/j.neucom.2025.129886},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129886},
  shortjournal = {Neurocomputing},
  title        = {A hybrid approach combining sentiment analysis and deep learning to mitigate data sparsity in recommender systems},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural learning rules from associative networks theory.
<em>NEUCOM</em>, <em>636</em>, 129865. (<a
href="https://doi.org/10.1016/j.neucom.2025.129865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Associative networks theory is increasingly providing tools to interpret update rules of artificial neural networks. At the same time, deriving neural learning rules from a solid theory remains a fundamental challenge. We make some steps in this direction by considering general energy-based associative networks of continuous neurons and synapses that evolve in multiple time scales. We use the separation of these timescales to recover a limit in which the activation of the neurons, the energy of the system and the neural dynamics can all be recovered from a generating function. By allowing the generating function to depend on memories, we recover the conventional Hebbian modeling choice for the interaction strength between neurons. Finally, we propose and discuss a dynamics of memories that enables us to include learning in this framework.},
  archive      = {J_NEUCOM},
  author       = {Daniele Lotito},
  doi          = {10.1016/j.neucom.2025.129865},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129865},
  shortjournal = {Neurocomputing},
  title        = {Neural learning rules from associative networks theory},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive temperature distillation method for mining hard
samples’ knowledge. <em>NEUCOM</em>, <em>636</em>, 129745. (<a
href="https://doi.org/10.1016/j.neucom.2025.129745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation can transfer knowledge from a complex teacher network into a simple student one through a high temperature factor, improving the latter’s performance. However, existing studies usually use fixed temperatures, making them ineffective in mining the rich knowledge contained in hard samples. Specifically, high temperature tends to over-smooth knowledge on hard samples, whereas low temperature makes knowledge almost equivalent to hard labels on easy samples. In this paper, we propose an Adaptive Temperature Distillation (ATD) method to effectively address these challenges. A well-trained teacher network’s information entropy is used to assess a sample’s relative difficulty. Then, low temperature is used in a hard sample, which allows the student network to learn its dark knowledge more effectively. And high temperature is employed in an easy sample to prevent the student network from becoming overconfident and ignoring the dark knowledge of negative classes. Furthermore, we propose a mixup variant to enable the student network to access more hard samples with rich dark knowledge. Instead of focusing on data augmentation as the existing mixup studies, ATD pays attention to increasing the richness of dark knowledge by mixing the output logits of easy and hard samples. The overall performance of ATD is verified in multiple benchmark datasets by comparing it with state-of-the-art knowledge distillation methods.},
  archive      = {J_NEUCOM},
  author       = {Shunzhi Yang and Xiong Yang and Jin Ren and Liuchi Xu and Jinfeng Yang and Zhenhua Huang and Zheng Gong and Wenguang Wang},
  doi          = {10.1016/j.neucom.2025.129745},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129745},
  shortjournal = {Neurocomputing},
  title        = {Adaptive temperature distillation method for mining hard samples’ knowledge},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="nn---16">NN - 16</h2>
<ul>
<li><details>
<summary>
(2025). BSA-seg: A bi-level sparse attention network combining
narrow band loss for multi-target medical image segmentation.
<em>NN</em>, <em>188</em>, 107431. (<a
href="https://doi.org/10.1016/j.neunet.2025.107431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of multiple targets of varying sizes within medical images is of significant importance for the diagnosis of disease and pathological research. Transformer-based methods are emerging in the medical image segmentation, leveraging the powerful yet computationally intensive self-attention mechanism. A variety of attention mechanisms have been proposed to reduce computation at the cost of accuracy loss, utilizing handcrafted patterns within local or artificially defined receptive fields. Furthermore, the common region-based loss functions are insufficient for guiding the transformer to focus on tissue regions, resulting in their unsuitability for the segmentation of tissues with intricate boundaries. This paper presents the development of a bi-level sparse attention network and a narrow band (NB) loss function for the accurate and efficient multi-target segmentation of medical images. In particular, we introduce a bi-level sparse attention module (BSAM) and formulate a segmentation network based on this module. The BSAM consists of coarse-grained patch-level attention and fine-grained pixel-level attention, which captures fine-grained contextual features in adaptive receptive fields learned by patch-level attention. This results in enhanced segmentation accuracy while simultaneously reducing computational complexity. The proposed narrow-band (NB) loss function constructs a target region in close proximity to the tissue boundary. The network is thus guided to perform boundary-aware segmentation, thereby simultaneously alleviating the issues of over-segmentation and under-segmentation. A series of comprehensive experiments on whole brains, brain tumors and abdominal organs, demonstrate that our method outperforms other state-of-the-art segmentation methods. Furthermore, the BSAM and NB loss can be applied flexibly to a variety of network frameworks.},
  archive      = {J_NN},
  author       = {Zhiyong Zhou and Zhechen Zhou and Xusheng Qian and Jisu Hu and Bo Peng and Chen Geng and Bin Dai and He Huang and Wenbin Zhang and Yakang Dai},
  doi          = {10.1016/j.neunet.2025.107431},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107431},
  shortjournal = {Neural Netw.},
  title        = {BSA-seg: A bi-level sparse attention network combining narrow band loss for multi-target medical image segmentation},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive bigraph-based multi-view unsupervised
dimensionality reduction. <em>NN</em>, <em>188</em>, 107424. (<a
href="https://doi.org/10.1016/j.neunet.2025.107424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial machine learning technology, graph-based multi-view unsupervised dimensionality reduction aims to learn compact low-dimensional representations for unlabeled multi-view data using graph structures. However, it faces several challenges, including the integration of multiple heterogeneous views, the absence of label guidance, the rigidity of predefined similarity graphs, and high computational intensity. To address these issues, we propose a novel method called adaptive Bigraph-based Multi-view Unsupervised Dimensionality Reduction (BMUDR). BMUDR dynamically learns view-specific anchor sets and adaptively constructs a bigraph shared by multiple views, facilitating the discovery of low-dimensional representations through sample-anchor relationships. The generation of anchors and the construction of anchor similarity matrices are integrated into the dimensionality reduction process. Diverse contributions of different views are automatically weighed to leverage their complementary and consistent properties. In addition, an optimization algorithm is designed to enhance computational efficiency and scalability, and it provides impressive performance in low-dimensional representation learning, as demonstrated by extensive experiments on various benchmark datasets.},
  archive      = {J_NN},
  author       = {Qianyao Qiang and Bin Zhang and Chen Jason Zhang and Feiping Nie},
  doi          = {10.1016/j.neunet.2025.107424},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107424},
  shortjournal = {Neural Netw.},
  title        = {Adaptive bigraph-based multi-view unsupervised dimensionality reduction},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). L3Net: Localized and layered reparameterization for
incremental learning. <em>NN</em>, <em>188</em>, 107420. (<a
href="https://doi.org/10.1016/j.neunet.2025.107420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based class incremental learning (CIL) methods aim to address the challenge of catastrophic forgetting by retaining certain parameters and expanding the model architecture. However, retaining too many parameters can lead to an overly complex model, increasing inference overhead. Additionally, compressing these parameters to reduce the model size can result in performance degradation. To tackle these challenges, we propose a novel three-stage CIL framework called L ocalized and L ayered Reparameterization for Incremental L earning ( L 3 Net ). The rationale behind our approach is to balance model complexity and performance by selectively expanding and optimizing critical components. Specifically, the framework introduces a Localized Dual-path Expansion structure, which allows the model to learn simultaneously from both old and new features by integrating a fusion selector after each convolutional layer. To further minimize potential conflicts between old and new features, we implement the Feature Selectors Gradient Resetting method, which sparsifies the fusion selectors and reduces the influence of redundant old features. Additionally, to address classification bias resulting from class imbalance, we design the Decoupled Balanced Distillation technique and apply Logit Adjustment to more effectively retain knowledge from the rehearsal set. Extensive experiments demonstrate that our L 3 Net framework outperforms state-of-the-art methods on widely used benchmarks, including CIFAR-100 and ImageNet-100/1000.},
  archive      = {J_NN},
  author       = {Xuandi Luo and Huaidong Zhang and Yi Xie and Hongrui Zhang and Xuemiao Xu and Shengfeng He},
  doi          = {10.1016/j.neunet.2025.107420},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107420},
  shortjournal = {Neural Netw.},
  title        = {L3Net: Localized and layered reparameterization for incremental learning},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information-theoretic approach for heterogeneous
differentiable causal discovery. <em>NN</em>, <em>188</em>, 107417. (<a
href="https://doi.org/10.1016/j.neunet.2025.107417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of deep learning, a variety of differential causal discovery methods have emerged, inevitably attracting more attention for their excellent scalability and interpretability. However, these methods often struggle with complex heterogeneous datasets that exhibit environmental diversity and are characterized by shifts in noise distribution. To this end, we introduce a novel information-theoretic approach designed to enhance the robustness of differential causal discovery methods. Specifically, we integrate Minimum Error Entropy (MEE) as an adaptive error regulator into the structure learning framework. MEE effectively reduces error variability across diverse samples, enabling our model to adapt dynamically to varying levels of complexity and noise. This adjustment significantly improves the precision and stability of the model. Extensive experiments on both synthetic and real-world datasets have demonstrated significant performance enhancements over existing methods, affirming the effectiveness of our approach. The code is available at https://github.com/ElleZWQ/MHCD .},
  archive      = {J_NN},
  author       = {Wanqi Zhou and Shuanghao Bai and Yuqing Xie and Yicong He and Qibin Zhao and Badong Chen},
  doi          = {10.1016/j.neunet.2025.107417},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107417},
  shortjournal = {Neural Netw.},
  title        = {An information-theoretic approach for heterogeneous differentiable causal discovery},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CCA: Contrastive cluster assignment for supervised and
semi-supervised medical image segmentation. <em>NN</em>, <em>188</em>,
107415. (<a href="https://doi.org/10.1016/j.neunet.2025.107415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers have shown great potential in vision tasks such as semantic segmentation. However, most of the existing transformer-based segmentation models neglect the cross-attention between pixel features and class features which impedes the application of transformers. Inspired by the concept of object queries in k-means Mask Transformer, we develop cluster learning and contrastive cluster assignment (CCA) for medical image segmentation in this paper. The cluster learning leverages the object queries to fit the feature-level cluster centers. The contrastive cluster assignment is introduced to guide the pixel class prediction using the cluster centers. Our method is a plug-in and can be integrated into any model. We design two networks for supervised segmentation tasks and semi-supervised segmentation tasks respectively. We equip the decoder with our proposed modules for the supervised segmentation to improve the pixel-level predictions. For the semi-supervised segmentation, we enhance the feature extraction capability of the encoder by using our proposed modules. We conduct comprehensive comparison and ablation experiments on public medical image datasets (ACDC, LA, Synapse, and ISIC2018), the results demonstrate that our proposed models outperform state-of-the-art models consistently, validating the effectiveness of our proposed method. The source code is accessible at https://github.com/zhujinghua1234/CCA-Seg .},
  archive      = {J_NN},
  author       = {Jinghua Zhu and Chengying Huang and Heran Xi and Hui Cui},
  doi          = {10.1016/j.neunet.2025.107415},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107415},
  shortjournal = {Neural Netw.},
  title        = {CCA: Contrastive cluster assignment for supervised and semi-supervised medical image segmentation},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time synchronization of proportional delay memristive
complex-valued competitive neural networks. <em>NN</em>, <em>188</em>,
107411. (<a href="https://doi.org/10.1016/j.neunet.2025.107411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fixed-time synchronization (FXS) is considered for memristive complex-valued competitive neural networks (MCVCNNs) with proportional delays. Two less conservative criteria supporting the FXS of MCVCNNs are founded by involving Lyapunov method and inequality techniques. Suitable switch controllers are designed by defining different norms of complex numbers instead of treating complex-valued neural networks as two real-valued systems. Furthermore, the settling time (ST) has been approximated. Finally, two simulations are shown to confirm the effectiveness of criteria in this paper and the outcomes of practical application in image protection.},
  archive      = {J_NN},
  author       = {Jiapeng Han and Liqun Zhou},
  doi          = {10.1016/j.neunet.2025.107411},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107411},
  shortjournal = {Neural Netw.},
  title        = {Fixed-time synchronization of proportional delay memristive complex-valued competitive neural networks},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SuperM2M: Supervised and mixture-to-mixture co-learning for
speech enhancement and noise-robust ASR. <em>NN</em>, <em>188</em>,
107408. (<a href="https://doi.org/10.1016/j.neunet.2025.107408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current dominant approach for neural speech enhancement is based on supervised learning by using simulated training data. The trained models, however, often exhibit limited generalizability to real-recorded data. To address this, this paper investigates training enhancement models directly on real target-domain data. We propose to adapt mixture-to-mixture (M2M) training, originally designed for speaker separation, for speech enhancement, by modeling multi-source noise signals as a single, combined source. In addition, we propose a co-learning algorithm that improves M2M with the help of supervised algorithms. When paired close-talk and far-field mixtures are available for training, M2M realizes speech enhancement by training a deep neural network (DNN) to produce speech and noise estimates in a way such that they can be linearly filtered to reconstruct the close-talk and far-field mixtures. This way, the DNN can be trained directly on real mixtures, and can leverage close-talk and far-field mixtures as a weak supervision to enhance far-field mixtures. To improve M2M, we combine it with supervised approaches to co-train the DNN, where mini-batches of real close-talk and far-field mixture pairs and mini-batches of simulated mixture and clean speech pairs are alternately fed to the DNN, and the loss functions are respectively (a) the mixture reconstruction loss on the real close-talk and far-field mixtures and (b) the regular enhancement loss on the simulated clean speech and noise. We find that, this way, the DNN can learn from real and simulated data to achieve better generalization to real data. We name this algorithm SuperM2M (supervised and mixture-to-mixture co-learning). Evaluation results on the CHiME-4 dataset show its effectiveness and potential.},
  archive      = {J_NN},
  author       = {Zhong-Qiu Wang},
  doi          = {10.1016/j.neunet.2025.107408},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107408},
  shortjournal = {Neural Netw.},
  title        = {SuperM2M: Supervised and mixture-to-mixture co-learning for speech enhancement and noise-robust ASR},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting low-homophily for graph-based fraud detection.
<em>NN</em>, <em>188</em>, 107407. (<a
href="https://doi.org/10.1016/j.neunet.2025.107407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The openness of Internet stimulates a large number of fraud behaviors which have become a huge threat. Graph-based fraud detectors have attracted extensive interest since the abundant structure information of graph data has proved effective. Conventional Graph Neural Network (GNN) approaches reveal fraudsters based on the homophily assumption. But fraudsters typically generate heterophilous connections and label-imbalanced neighborhood. Such behaviors deteriorate the performance of GNNs in fraud detection tasks due to the low homophily in graphs. Though some recent works have noticed the challenges, they either treat the heterophilous connections as homophilous ones or tend to reduce heterophily, which roughly ignore the benefits from heterophily. In this work, an integrated two-strategy framework HeteGAD is proposed to balance both homophily and heterophily information from neighbors. The key lies in explicitly shrinking intra-class distance and increasing inter-class segregation. Specifically, the Heterophily-aware Aggregation Strategy tease out the feature disparity on heterophilous neighbors and augment the disparity between representations with different labels. And the Homophily-aware Aggregation Strategy are devised to capture the homophilous information in global text and augment the representation similarity with the same label. Finally, two corresponding inter-relational attention mechanisms are incorporated to refine the procedure of modeling the interaction of multiple relations. Experiments are conducted to evaluate the proposed method with two real-world datasets, and demonstrate that the HeteGAD outperforms 11 state-of-the-art baselines for fraud detection.},
  archive      = {J_NN},
  author       = {Tairan Huang and Qiutong Li and Cong Xu and Jianliang Gao and Zhao Li and Shichao Zhang},
  doi          = {10.1016/j.neunet.2025.107407},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107407},
  shortjournal = {Neural Netw.},
  title        = {Revisiting low-homophily for graph-based fraud detection},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intra-class progressive and adaptive self-distillation.
<em>NN</em>, <em>188</em>, 107404. (<a
href="https://doi.org/10.1016/j.neunet.2025.107404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, knowledge distillation (KD) has become widely used in compressing models, training compact and efficient students to reduce computational load and training time due to the increasing parameters in deep neural networks. To minimize training costs, self-distillation has been proposed, with methods like offline-KD and online-KD requiring pre-trained teachers and multiple networks. However, these self-distillation methods often overlook feature knowledge and category information. In this paper, we introduce Intra-class Progressive and Adaptive Self-Distillation (IPASD), which transfers knowledge from the front to the back in adjacent epochs. This method extracts class-typical features and promotes compactness within classes. By integrating feature-level and logits-level knowledge into strong teacher knowledge and using ground-truth labels as supervision signals, we adaptively optimize the model. We evaluated IPASD on CIFAR-10, CIFAR-100, Tiny ImageNet, Plant Village datasets, and ImageNet showing its superiority over state-of-the-art self-distillation methods in knowledge transfer and model compression. Our codes are available at: https://github.com/JLinye/IPASD .},
  archive      = {J_NN},
  author       = {Jianping Gou and Jiaye Lin and Lin Li and Weihua Ou and Baosheng Yu and Zhang Yi},
  doi          = {10.1016/j.neunet.2025.107404},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107404},
  shortjournal = {Neural Netw.},
  title        = {Intra-class progressive and adaptive self-distillation},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AAPMatcher: Adaptive attention pruning matcher for accurate
local feature matching. <em>NN</em>, <em>188</em>, 107403. (<a
href="https://doi.org/10.1016/j.neunet.2025.107403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local feature matching, which seeks to establish correspondences between two images, serves as a fundamental component in numerous computer vision applications, such as camera tracking and 3D mapping. Recently, Transformer has demonstrated remarkable capability in modeling accurate correspondences for the two input sequences owing to its long-range context integration capability. Whereas, indiscriminate modeling in traditional transformers inevitably introduces noise and includes irrelevant information which can degrade the quality of feature representations. Towards this end, we introduce an adaptive attention pruning matcher for accurate local feature matching (AAPMatcher) , which is designed for robust and accurate local feature matching. We overhaul the traditional uniform feature extraction for sequences by introducing the adaptive pruned transformer (APFormer), which adaptively retains the most profitable attention values for feature consolidation, enabling the network to obtain more useful feature information while filtering out useless information. Moreover, considering the fixed combination of self- and cross-APFormer greatly limits the flexibility of the network, we propose a two-stage adaptive hybrid attention strategy (AHAS) , which achieves the optimal combination for APFormers in a coarse to fine manner. Benefiting from the clean feature representations and the optimal combination of APFormers, AAPMatcher exceeds the state-of-the-art approaches over multiple benchmarks, including pose estimation, homography estimation, and visual localization.},
  archive      = {J_NN},
  author       = {Xuan Fan and Sijia Liu and Shuaiyan Liu and Lijun Zhao and Ruifeng Li},
  doi          = {10.1016/j.neunet.2025.107403},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107403},
  shortjournal = {Neural Netw.},
  title        = {AAPMatcher: Adaptive attention pruning matcher for accurate local feature matching},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure information preserving domain adaptation network
for fault diagnosis of sucker rod pumping systems. <em>NN</em>,
<em>188</em>, 107392. (<a
href="https://doi.org/10.1016/j.neunet.2025.107392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis is of great importance to the reliability and security of Sucker Rod Pumping (SRP) oil production system. With the development of digital oilfield, data-driven deep learning SRP fault diagnosis has become the development trend of oilfield system. However, due to the different working conditions, time periods, and areas, the fault diagnosis models trained from certain SRP data do not consider the statistical discrepancy of different SRP systems, resulting in insufficient generalization. To consider the fault diagnosis and generalization performances of deep models at the same time, this paper proposes a Structure Information Preserving Domain Adaptation Network (SIP-DAN) for SRP fault diagnosis. Different from the usual domain adaptation methods, SIP-DAN divides the source domain data into different subdomains according to the fault categories of the source domain, and then realizes structure information preserving domain adaptation through subdomains alignment of the source domain and the target domain. Due to the lack of fault category information in the target domain, we designed a Classifier Voting Assisted Alignment (CVAA) mechanism. The target domain data are divided into clusters using fuzzy clustering algorithm. Then, fault diagnosis classifier trained in source domain is employed to classify the samples in each cluster, and the majority voting principle is used to assign pseudo-labels to each cluster in the target domain. With these pseudo-labels, source and target subdomains alignment is carried out by optimizing the Local Maximum Mean Discrepancy (LMMD) loss to achieve fine-grained domain adaptation. Experimental results illustrate that the proposed method is better than the existing methods in fault diagnosis of SRP systems.},
  archive      = {J_NN},
  author       = {Xiaohua Gu and Fei Lu and Liping Yang and Kan Wang and Lusi Li and Guang Yang and Yiling Sun},
  doi          = {10.1016/j.neunet.2025.107392},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107392},
  shortjournal = {Neural Netw.},
  title        = {Structure information preserving domain adaptation network for fault diagnosis of sucker rod pumping systems},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stagger network: Rethinking information loss in medical
image segmentation with various-sized targets. <em>NN</em>,
<em>188</em>, 107386. (<a
href="https://doi.org/10.1016/j.neunet.2025.107386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation presents the challenge of segmenting various-size targets, demanding the model to effectively capture both local and global information. Despite recent efforts using CNNs and ViTs to predict annotations of different scales, these approaches often struggle to effectively balance the detection of targets across varying sizes. Simply utilizing local information from CNNs and global relationships from ViTs without considering potential significant divergence in latent feature distributions may result in substantial information loss. To address this issue, in this paper, we will introduce a novel Stagger Network (SNet) and argues that a well-designed fusion structure can mitigate the divergence in latent feature distributions between CNNs and ViTs, thereby reducing information loss. Specifically, to emphasize both global dependencies and local focus, we design a Parallel Module to bridge the semantic gap. Meanwhile, we propose the Stagger Module, trying to fuse the selected features that are more semantically similar. An Information Recovery Module is further adopted to recover complementary information back to the network. As a key contribution, we theoretically analyze that the proposed parallel and stagger strategies would lead to less information loss, thus certifying the SNet’s rationale. Experimental results clearly proved that the proposed SNet excels comparisons with recent SOTAs in segmenting on the Synapse dataset where targets are in various sizes. Besides, it also demonstrates superiority on the ACDC and the MoNuSeg datasets where targets are with more consistent dimensions.},
  archive      = {J_NN},
  author       = {Tianyi Liu and Zhaorui Tan and Haochuan Jiang and Kaizhu Huang},
  doi          = {10.1016/j.neunet.2025.107386},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107386},
  shortjournal = {Neural Netw.},
  title        = {Stagger network: Rethinking information loss in medical image segmentation with various-sized targets},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IBPL: Information bottleneck-based prompt learning for graph
out-of-distribution detection. <em>NN</em>, <em>188</em>, 107381. (<a
href="https://doi.org/10.1016/j.neunet.2025.107381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When training and test graph samples follow different data distributions, graph out-of-distribution (OOD) detection becomes an indispensable component of constructing the reliable and safe graph learning systems. Motivated by the significant progress on prompt learning, graph prompt-based methods, which enable a well-trained graph neural network to detect OOD graphs without modifying any model parameters, have been a standard benchmark with promising computational efficiency and model effectiveness. However, these methods ignore the influence of overlapping features existed in both in-distribution (ID) and OOD graphs, which weakens the difference between them and leads to sub-optimal detection results. In this paper, we present the I nformation B ottleneck-based P rompt L earning (IBPL) to overcome this challenging problem. Specifically, IBPL includes a new graph prompt that jointly performs the mask operation on node features and the graph structure. Building upon this, we develop an information bottleneck (IB)-based objective to optimize the proposed graph prompt. Since the overlapping features are inaccessible, IBPL introduces the noise data augmentation which generates a series of perturbed graphs to fully covering the overlapping features. Through minimizing the mutual information between the prompt graph and the perturbed graphs, our objective can eliminate the overlapping features effectively. In order to avoid the negative impact of perturbed graphs, IBPL simultaneously maximizes the mutual information between the prompt graph and the category label for better extracting the ID features. We conduct experiments on multiple real-world datasets in both supervised and unsupervised scenarios. The empirical results and extensive model analyses demonstrate the superior performance of IBPL over several competitive baselines.},
  archive      = {J_NN},
  author       = {Yanan Cao and Fengzhao Shi and Qing Yu and Xixun Lin and Chuan Zhou and Lixin Zou and Peng Zhang and Zhao Li and Dawei Yin},
  doi          = {10.1016/j.neunet.2025.107381},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107381},
  shortjournal = {Neural Netw.},
  title        = {IBPL: Information bottleneck-based prompt learning for graph out-of-distribution detection},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating uncertainty from feed-forward network based
sensing using quasi-linear approximation. <em>NN</em>, <em>188</em>,
107376. (<a href="https://doi.org/10.1016/j.neunet.2025.107376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A fundamental problem in neural network theory is the quantification of uncertainty as it propagates through these constructs. Such quantification is crucial as neural networks become integrated into broader engineered systems that render decisions based on their outputs. In this paper, we engage the problem of estimating uncertainty in feedforward neural network constructs. Mathematically, the problem, in essence, amounts to understanding how the moments of an input distribution become modifies as they move through network layers. Despite its straightforward formulation, the nonlinear nature of modern feedforward architectures makes this is a mathematically challenging problem. Most contemporary approaches rely on some form of Monte Carlo sampling to construct inter-laminar distributions. Here, we borrow an approach from the control systems community known as quasilinear approximation, to enable a more analytical approach to the uncertainty quantification problem in this setting. Specifically, by using quasilinear approximation, nonlinearities are linearized in terms of the expectation of their gain in an input–output sense. We derive these expectations for several commonly used nonlinearities, under the assumption of Gaussian inputs. We then establish that the ensuing approximation is accurate relative to traditional linearization. Furthermore, we provide a rigorous example how this method can enable formal estimation of uncertainty in latent variables upstream of the network, within a target-tracking case study.},
  archive      = {J_NN},
  author       = {Songhan Zhang and Matthew Singh and Delsin Menolascino and ShiNung Ching},
  doi          = {10.1016/j.neunet.2025.107376},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107376},
  shortjournal = {Neural Netw.},
  title        = {Estimating uncertainty from feed-forward network based sensing using quasi-linear approximation},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cauchy activation function and XNet. <em>NN</em>,
<em>188</em>, 107375. (<a
href="https://doi.org/10.1016/j.neunet.2025.107375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have developed a novel activation function, named the Cauchy Activation Function . This function is derived from the Cauchy Integral Theorem in complex analysis and is specifically tailored for problems requiring high precision. This innovation has led to the creation of a new class of neural networks, which we call (Comple)XNet, or simply XNet. We will demonstrate that XNet is particularly effective for high-dimensional challenges such as image classification and solving Partial Differential Equations (PDEs). Our evaluations show that XNet significantly outperforms established benchmarks like MNIST and CIFAR-10 in computer vision, and offers substantial advantages over Physics-Informed Neural Networks (PINNs) in both low-dimensional and high-dimensional PDE scenarios.},
  archive      = {J_NN},
  author       = {Xin Li and Zhihong Xia and Hongkun Zhang},
  doi          = {10.1016/j.neunet.2025.107375},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107375},
  shortjournal = {Neural Netw.},
  title        = {Cauchy activation function and XNet},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hierarchical mixture-of-experts framework for few labeled
node classification. <em>NN</em>, <em>188</em>, 107285. (<a
href="https://doi.org/10.1016/j.neunet.2025.107285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {F ew L abeled N ode C lassification ( FLNC ) is a challenging subtask of node classification, where training nodes are extremely limited, often with only one or two labels per class. While Graph Neural Networks (GNNs) show promise, they often suffer from feature convergence. A common method to address this challenge is multi-perspective feature extraction, with the Mixture of Experts (MoE) model being a popular approach. However, directly applying MoE to FLNC frequently results in overfitting. To address these issues, we propose the Hierarchical Mixture-of-Experts (HMoE) framework. First, we mitigate overfitting by applying three data augmentation techniques to enrich input features. Next, we design a novel hierarchical mixture-of-experts encoder to achieve diversified feature representations, where the first layer extracts unique feature information, and the second layer refines shared information. Additionally, we design an auxiliary task to distinguish between original and augmented data, using a gradient reversal mechanism to enhance the feature representation ability of graph data. The experimental results show that HMoE outperforms the baseline methods, achieving an average 1.2% performance improvement across six datasets.},
  archive      = {J_NN},
  author       = {Yimeng Wang and Zhiyao Yang and Xiangjiu Che},
  doi          = {10.1016/j.neunet.2025.107285},
  journal      = {Neural Networks},
  month        = {8},
  pages        = {107285},
  shortjournal = {Neural Netw.},
  title        = {A hierarchical mixture-of-experts framework for few labeled node classification},
  volume       = {188},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="orl---25">ORL - 25</h2>
<ul>
<li><details>
<summary>
(2025). Exact simulation scheme for the ornstein–uhlenbeck driven
stochastic volatility model with the karhunen–loève expansions.
<em>ORL</em>, <em>60</em>, 107280. (<a
href="https://doi.org/10.1016/j.orl.2025.107280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a fast exact simulation scheme for the Ornstein–Uhlenbeck driven stochastic volatility model. With the Karhunen–Loève expansions, the stochastic volatility path (Ornstein–Uhlenbeck process) is expressed as a sine series, and the time integrals of volatility and variance are analytically derived as infinite series of independent normal random variables. The new method is several hundred times faster than the existing method using numerical transform inversion. The simulation variance is further reduced with conditional simulation and the control variate.},
  archive      = {J_ORL},
  author       = {Jaehyuk Choi},
  doi          = {10.1016/j.orl.2025.107280},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107280},
  shortjournal = {Oper. Res. Lett.},
  title        = {Exact simulation scheme for the Ornstein–Uhlenbeck driven stochastic volatility model with the Karhunen–Loève expansions},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universally optimal staffing for erlang-a queues facing
uncertain arrival rates: The case of constraint satisfaction.
<em>ORL</em>, <em>60</em>, 107279. (<a
href="https://doi.org/10.1016/j.orl.2025.107279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by service systems where staffing decisions must be made before the arrival rate becomes known, we study the constraint satisfaction problem in an Erlang-A queue facing a random arrival rate. The objective is to find the minimum staffing level subject to a service level constraint that is modeled either (1) via an average constraint formulation that ensures a given quality-of-service (QoS) target holds on average by bounding the average fraction of abandoning customers below the said QoS target or (2) via a chance constraint formulation that ensures the QoS target for the random fraction of abandoning customers is met with high probability . Our primary contribution, under each constraint formulation, is to propose a policy that is shown to be universally optimal, i.e., irrespective of the magnitude of randomness in the arrival rate, the staffing gap between the proposed policy and the exact optimal policy remains bounded as the system size grows large. To the best of our knowledge, this is the first universal performance guarantee for constraint satisfaction in Erlang-A queues with random arrival rates and complements a recent result on cost minimization. The practical importance of this universality is that our proposed policy is a “one-size-fits-all” that is guaranteed to perform well for all levels of arrival rate uncertainty.},
  archive      = {J_ORL},
  author       = {Yaşar Levent Koçağa},
  doi          = {10.1016/j.orl.2025.107279},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107279},
  shortjournal = {Oper. Res. Lett.},
  title        = {Universally optimal staffing for erlang-A queues facing uncertain arrival rates: The case of constraint satisfaction},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-dependent stackelberg protection location games.
<em>ORL</em>, <em>60</em>, 107278. (<a
href="https://doi.org/10.1016/j.orl.2025.107278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a Stackelberg game in which a government positions rapid response teams and thereafter a terrorist attacks a location on a line segment. We assume the damage associated to such an attack to be time dependent. We show that there exists a subgame perfect Nash equilibrium that balances the possible damage on all intervals of the line segment that result from positioning the rapid response teams. We discuss implications for an instance of the model.},
  archive      = {J_ORL},
  author       = {Lotte van Aken and Loe Schlicher and Marco Slikker},
  doi          = {10.1016/j.orl.2025.107278},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107278},
  shortjournal = {Oper. Res. Lett.},
  title        = {Time-dependent stackelberg protection location games},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Positivity of incomplete cooperative games revisited.
<em>ORL</em>, <em>60</em>, 107277. (<a
href="https://doi.org/10.1016/j.orl.2025.107277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider incomplete cooperative games, where only some coalitions&#39; values are specified and others remain indeterminate. Focusing on positive extensions —fully defined cooperative games that agree with the partial data and have nonnegative dividends—we introduce a novel, two-stage dividend-assignment procedure that fully characterizes all such extensions. Our method offers a general criterion for positivity-extendability, introduces an explicit lower bound game, and provides an understanding of the structure of extreme points in the extension set. These contributions significantly expand the toolkit for theoretical analyses and practical computations of incomplete cooperative games, and also shed new light on properties of classical cooperative games.},
  archive      = {J_ORL},
  author       = {Martin Černý},
  doi          = {10.1016/j.orl.2025.107277},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107277},
  shortjournal = {Oper. Res. Lett.},
  title        = {Positivity of incomplete cooperative games revisited},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Offline expansion strategy of e-tailers as suppliers for
brick-and-mortar stores. <em>ORL</em>, <em>60</em>, 107276. (<a
href="https://doi.org/10.1016/j.orl.2025.107276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce giants have recently ventured into offline retail by serving as suppliers for brick-and-mortar stores. In this paper, we develop a game-theoretical model to investigate the economic rationale behind the strategy and its impacts on online and offline retail. We find that an offline monopolist will always have an incentive to participate in the e-tailer&#39;s offline expansion initiative, but may be deterred due to competition. Under certain conditions, the e-tailer prefers supplying third-party retailers over opening its own store.},
  archive      = {J_ORL},
  author       = {Wen He and Lu Wang and Qianbo Yin},
  doi          = {10.1016/j.orl.2025.107276},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107276},
  shortjournal = {Oper. Res. Lett.},
  title        = {Offline expansion strategy of E-tailers as suppliers for brick-and-mortar stores},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transient analysis of a renewal input multiserver queueing
model with infinite buffer. <em>ORL</em>, <em>60</em>, 107275. (<a
href="https://doi.org/10.1016/j.orl.2025.107275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a time-dependent solution for the system-content distribution of the infinite buffer G I / M / c queue. The supplementary variable and the difference equation technique is used to obtain the probabilities in terms of Laplace transform. Some relevant performance measures are derived and extensive numerical results are presented. It covers a comparison of the impact of heavy-tailed and light-tailed interarrival time distributions on the transient behavior of the system and the underlying system characteristics.},
  archive      = {J_ORL},
  author       = {Ashwini Soundararajan and F.P. Barbhuiya},
  doi          = {10.1016/j.orl.2025.107275},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107275},
  shortjournal = {Oper. Res. Lett.},
  title        = {Transient analysis of a renewal input multiserver queueing model with infinite buffer},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal retail pricing, interest rate, and interest
allocation ratio decisions in an online platform-assisted financing
system. <em>ORL</em>, <em>60</em>, 107268. (<a
href="https://doi.org/10.1016/j.orl.2025.107268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine an online financing system involving a platform, a bank, and a retailer, in which the bank makes the optimal interest rate decision before the bank-platform negotiation for the interest allocation ratio (scenario 1) or after the interest allocation ratio negotiation (scenario 2). We find that the retailer&#39;s sales and profits in scenario 1 are higher than those in scenario 2. Moreover, if the referral fee rate increases, the system-wide profit and the system efficiency for scenario 1 increase but those for scenario 2 decrease.},
  archive      = {J_ORL},
  author       = {Dianyao Kang and Mingming Leng},
  doi          = {10.1016/j.orl.2025.107268},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107268},
  shortjournal = {Oper. Res. Lett.},
  title        = {Optimal retail pricing, interest rate, and interest allocation ratio decisions in an online platform-assisted financing system},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite customer-pool queues. <em>ORL</em>, <em>60</em>,
107267. (<a href="https://doi.org/10.1016/j.orl.2025.107267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider an M/G/1-type queue fed by a finite customer-pool. In terms of transforms, we characterize the time-dependent distribution of the number of customers and the workload, as well as the associated waiting times.},
  archive      = {J_ORL},
  author       = {Onno Boxma and Offer Kella and Michel Mandjes},
  doi          = {10.1016/j.orl.2025.107267},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107267},
  shortjournal = {Oper. Res. Lett.},
  title        = {Finite customer-pool queues},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New axiomatizations of the priority value for cooperative
games with priority structure. <em>ORL</em>, <em>60</em>, 107266. (<a
href="https://doi.org/10.1016/j.orl.2025.107266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The principle of gain-loss imposes that whenever the total worth generated does not change, a player can only gain at the expense of another one. In this paper we provide two new axiomatizations of the Priority value using the axiom of gain-loss and the other standard properties serving as axiomatizations of the Shapley value. Also, we introduce the axiom of equal treatment of priority players among necessary players and we show that this axiom, jointly with the standard properties of additivity, null player and priority player out, characterizes the Priority value without relying on efficiency. In addition, we obtain a charaterization of the Priority value inspired by a more general result for the weighted Priority values in Béal et al. (2023) [2] .},
  archive      = {J_ORL},
  author       = {Songtao He and Erfang Shan and Yuxin Sun},
  doi          = {10.1016/j.orl.2025.107266},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107266},
  shortjournal = {Oper. Res. Lett.},
  title        = {New axiomatizations of the priority value for cooperative games with priority structure},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single sample prophet inequality for uniform matroids of
rank 2. <em>ORL</em>, <em>60</em>, 107257. (<a
href="https://doi.org/10.1016/j.orl.2025.107257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the prophet inequality when the gambler has an access only to a single sample from each distribution. Rubinstein, Wang and Weinberg showed that an optimal guarantee of 1/2 can be achieved when the underlying matroid has rank 1, i.e. in the single choice case. We show that this guarantee can be achieved also for a uniform matroid of rank 2, and we show that this is best possible guarantee among deterministic mechanisms.},
  archive      = {J_ORL},
  author       = {Kanstantsin Pashkovich and Alice Sayutina},
  doi          = {10.1016/j.orl.2025.107257},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107257},
  shortjournal = {Oper. Res. Lett.},
  title        = {Single sample prophet inequality for uniform matroids of rank 2},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategyproof and budget-balanced mechanisms for assembly.
<em>ORL</em>, <em>60</em>, 107256. (<a
href="https://doi.org/10.1016/j.orl.2025.107256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assembly problems involve exchange among a buyer and multiple sellers. The buyer wants to purchase possibly multiple items and sellers own one item each. We characterize the class of strategyproof, individually rational and budget balanced mechanisms for this problem when agents have private valuations.},
  archive      = {J_ORL},
  author       = {Soumendu Sarkar},
  doi          = {10.1016/j.orl.2025.107256},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107256},
  shortjournal = {Oper. Res. Lett.},
  title        = {Strategyproof and budget-balanced mechanisms for assembly},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pairwise independent correlation gap. <em>ORL</em>,
<em>60</em>, 107255. (<a
href="https://doi.org/10.1016/j.orl.2025.107255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the notion of a “pairwise independent correlation gap” for set functions with random elements. The pairwise independent correlation gap is defined as the ratio of the maximum expected value of a set function with arbitrary dependence among the elements with fixed marginal probabilities to the maximum expected value with pairwise independent elements with the same marginal probabilities. We show that for any nonnegative monotone submodular set function defined on n elements, this ratio is upper bounded by 4/3 in the following two cases: (a) n = 3 for all marginal probabilities and (b) all n for small marginal probabilities (and similarly large marginal probabilities). This differs from the bound on the “correlation gap” which holds with mutual independence and showcases the fundamental difference between pairwise independence and mutual independence. We discuss the implication of the results with two examples and end the paper with a conjecture.},
  archive      = {J_ORL},
  author       = {Arjun Ramachandra and Karthik Natarajan},
  doi          = {10.1016/j.orl.2025.107255},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107255},
  shortjournal = {Oper. Res. Lett.},
  title        = {Pairwise independent correlation gap},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strictly competitive games: Finite, countable and
uncountable strategies. <em>ORL</em>, <em>60</em>, 107252. (<a
href="https://doi.org/10.1016/j.orl.2025.107252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strictly competitive games are characterized by the fact that every pair of strategies is Pareto optimal in two-player games. We provide a characterization of strictly competitive games when the sets of strategies are not finite. The finite strategy case was settled by Adler, Daskalakis and Papadimitriou who fully proved a conjecture of Aumann.},
  archive      = {J_ORL},
  author       = {Roberto Raimondo},
  doi          = {10.1016/j.orl.2025.107252},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107252},
  shortjournal = {Oper. Res. Lett.},
  title        = {Strictly competitive games: Finite, countable and uncountable strategies},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monte carlo and importance sampling estimators of CoVaR.
<em>ORL</em>, <em>60</em>, 107250. (<a
href="https://doi.org/10.1016/j.orl.2025.107250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a Monte Carlo (MC) simulation approach to estimate CoVaR, which is one of the commonly used systemic risk measures and captures the tail dependency of losses between network systems and nodes. Given that CoVaR may involve rare events, we propose an importance sampling (IS) approach to enhance the efficiency of estimation. We also establish consistency and asymptotic normality for both MC and IS estimators. Finally, we illustrate the effectiveness of our approach through numerical experiments.},
  archive      = {J_ORL},
  author       = {Guangxin Jiang and Jianshu Hao and Tong Sun},
  doi          = {10.1016/j.orl.2025.107250},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107250},
  shortjournal = {Oper. Res. Lett.},
  title        = {Monte carlo and importance sampling estimators of CoVaR},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Super-stable common independent sets of generalized
matroids. <em>ORL</em>, <em>60</em>, 107248. (<a
href="https://doi.org/10.1016/j.orl.2025.107248">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of checking the existence of a super-stable common independent set of generalized matroids. We prove that this problem can be solved by slightly modifying the algorithm proposed by Yokoi for the problem of checking the existence of a stable common independent set of generalized matroids.},
  archive      = {J_ORL},
  author       = {Naoyuki Kamiyama},
  doi          = {10.1016/j.orl.2025.107248},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107248},
  shortjournal = {Oper. Res. Lett.},
  title        = {Super-stable common independent sets of generalized matroids},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence and bound computation for chance constrained
distributionally robust models using sample approximation. <em>ORL</em>,
<em>60</em>, 107246. (<a
href="https://doi.org/10.1016/j.orl.2025.107246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a distributionally robust chance constraint model with a general ambiguity set. We show that a sample based approximation of this model converges under suitable sufficient conditions. We also show that upper and lower bounds on the optimal value of the model can be estimated statistically. Specific ambiguity sets are discussed as examples.},
  archive      = {J_ORL},
  author       = {Jiaqi Lei and Sanjay Mehrotra},
  doi          = {10.1016/j.orl.2025.107246},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107246},
  shortjournal = {Oper. Res. Lett.},
  title        = {Convergence and bound computation for chance constrained distributionally robust models using sample approximation},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Outer approximation for generalized convex mixed-integer
nonlinear robust optimization problems. <em>ORL</em>, <em>60</em>,
107243. (<a href="https://doi.org/10.1016/j.orl.2025.107243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider mixed-integer nonlinear robust optimization problems with nonconvexities. In detail, the functions can be nonsmooth and generalized convex, i.e., f ∘ -quasiconvex or f ∘ -pseudoconvex. We propose a robust optimization method that requires no certain structure of the adversarial problem, but only approximate worst-case evaluations. The method integrates a bundle method, for continuous subproblems, into an outer approximation approach. We prove that our algorithm converges and finds an approximately robust optimal solution and propose robust gas transport as a suitable application.},
  archive      = {J_ORL},
  author       = {Martina Kuchlbauer},
  doi          = {10.1016/j.orl.2025.107243},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107243},
  shortjournal = {Oper. Res. Lett.},
  title        = {Outer approximation for generalized convex mixed-integer nonlinear robust optimization problems},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlated equilibrium of games with concave potential
functions. <em>ORL</em>, <em>60</em>, 107241. (<a
href="https://doi.org/10.1016/j.orl.2025.107241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neyman (1997) proves in a classical paper that, under certain mild regularity conditions, any strategic game with a smooth strictly concave potential function has a unique correlated equilibrium. We generalize this result by relaxing the smoothness condition, allowing the potential function to include a second part that is not necessarily smoothly concave but separably concave.},
  archive      = {J_ORL},
  author       = {Zhigang Cao and Zhibin Tan and Jinchuan Zhou},
  doi          = {10.1016/j.orl.2025.107241},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107241},
  shortjournal = {Oper. Res. Lett.},
  title        = {Correlated equilibrium of games with concave potential functions},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inventory placement on a network. <em>ORL</em>, <em>60</em>,
107240. (<a href="https://doi.org/10.1016/j.orl.2025.107240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of placing inventory on a network in advance of uncertain demand, in order to minimize the sum of inventory placement costs and expected fulfillment and shortage costs. Complexity results (in terms of inapproximability lower bounds) are derived under different assumptions. Then we develop two approximation guarantees: one is asymptotically optimal as demand grows large, and the other provides a constant guarantee with metric fulfillment costs.},
  archive      = {J_ORL},
  author       = {John R. Birge and Levi DeValve},
  doi          = {10.1016/j.orl.2025.107240},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107240},
  shortjournal = {Oper. Res. Lett.},
  title        = {Inventory placement on a network},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal allocation of active and standby redundancies in
series systems. <em>ORL</em>, <em>60</em>, 107237. (<a
href="https://doi.org/10.1016/j.orl.2024.107237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research focuses on determining the optimal allocation of redundancies within a system, strategically placing them to enhance system performance. The paper explores redundancy allocation strategies through stochastic comparisons of resulting system lifetimes in various stochastic orders. While previous studies mainly focused on two or n -component series systems with some specific distributions for component lifetimes, this study extends the investigation with arbitrary distributions or some semiparametric families. It presents some new and extended results, offering novel insights to the topic.},
  archive      = {J_ORL},
  author       = {Biplab Hawlader and Pradip Kundu and Amarjit Kundu},
  doi          = {10.1016/j.orl.2024.107237},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107237},
  shortjournal = {Oper. Res. Lett.},
  title        = {Optimal allocation of active and standby redundancies in series systems},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategic behavior in a time-limited markovian polling queue
with service rate regeneration. <em>ORL</em>, <em>60</em>, 107236. (<a
href="https://doi.org/10.1016/j.orl.2024.107236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a time-limited Markovian polling queueing system with service rate regeneration. When the server moves to a new station, it announces the next station to open based on a given discrete-time Markov chain. We calculate the expected waiting time for customers in each queue, which is shown to be monotonic with respect to their position in the queue. Personal optimal thresholds for the customers are then determined, and an optimal joining strategy is proposed based on these thresholds.},
  archive      = {J_ORL},
  author       = {Yuanyuan Liu and Zhaozeng Yan},
  doi          = {10.1016/j.orl.2024.107236},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107236},
  shortjournal = {Oper. Res. Lett.},
  title        = {Strategic behavior in a time-limited markovian polling queue with service rate regeneration},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extended formulations for the integer hull of strictly
δ-modular cographic polyhedral cones. <em>ORL</em>, <em>60</em>, 107235.
(<a href="https://doi.org/10.1016/j.orl.2024.107235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conforti et al. give a compact extended formulation for a class of bimodular-constrained integer programs, namely those that model the stable set polytope of a graph with no disjoint odd cycles. We extend their techniques to design compact extended formulations for the integer hull of translated polyhedral cones whose constraint matrix is strictly Δ-modular and has rows that represent a cographic matroid. Our work generalizes the important special case from Conforti et al. concerning 4-connected graphs with odd cycle transversal number at least 4. We also discuss the necessity of our assumptions.},
  archive      = {J_ORL},
  author       = {Joseph Paat and Zach Walsh and Luze Xu},
  doi          = {10.1016/j.orl.2024.107235},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107235},
  shortjournal = {Oper. Res. Lett.},
  title        = {Extended formulations for the integer hull of strictly Δ-modular cographic polyhedral cones},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributionally robust stochastic optimal control.
<em>ORL</em>, <em>60</em>, 107234. (<a
href="https://doi.org/10.1016/j.orl.2024.107234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main goal of this paper is to discuss construction of distributionally robust counterparts of stochastic optimal control problems. Randomized and non-randomized policies are considered. In particular necessary and sufficient conditions for existence of non-randomized policies are given.},
  archive      = {J_ORL},
  author       = {Alexander Shapiro and Yan Li},
  doi          = {10.1016/j.orl.2024.107234},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107234},
  shortjournal = {Oper. Res. Lett.},
  title        = {Distributionally robust stochastic optimal control},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reduced game and constrained egalitarianism. <em>ORL</em>,
<em>60</em>, 107231. (<a
href="https://doi.org/10.1016/j.orl.2024.107231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces two values for cooperative games, called the constrained equal individual worth value and the constrained equal marginal contribution value, respectively. We show that the first value is the unique value satisfying the bilateral projection reduced game property and constrained egalitarianism, and the second one is the unique value satisfying the bilateral complement reduced game property and constrained egalitarianism. Replacing constrained egalitarianism by other properties, we provide another axiomatization for each value.},
  archive      = {J_ORL},
  author       = {Doudou Gong and Wenzhong Li},
  doi          = {10.1016/j.orl.2024.107231},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107231},
  shortjournal = {Oper. Res. Lett.},
  title        = {Reduced game and constrained egalitarianism},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank extragradient methods for scalable semidefinite
optimization. <em>ORL</em>, <em>60</em>, 107230. (<a
href="https://doi.org/10.1016/j.orl.2024.107230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of important semidefinite optimization problems that involve a convex smooth or nonsmooth objective function and linear constraints. Focusing on high-dimensional settings with a low-rank solution that also satisfies a low-rank complementarity condition, we prove that the well-known Extragradient method, when initialized with a “warm-start”, converges with its standard convergence rate guarantees, using only efficient low-rank singular value decompositions to project onto the positive semidefinite cone. Supporting numerical evidence with a dataset of Max-Cut instances is provided.},
  archive      = {J_ORL},
  author       = {Dan Garber and Atara Kaplan},
  doi          = {10.1016/j.orl.2024.107230},
  journal      = {Operations Research Letters},
  month        = {5},
  pages        = {107230},
  shortjournal = {Oper. Res. Lett.},
  title        = {Low-rank extragradient methods for scalable semidefinite optimization},
  volume       = {60},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="parco---6">PARCO - 6</h2>
<ul>
<li><details>
<summary>
(2025). Estimating resource budgets to ensure autotuning efficiency.
<em>PARCO</em>, <em>123</em>, 103126. (<a
href="https://doi.org/10.1016/j.parco.2025.103126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many state-of-the-art HPC applications rely on autotuning to maintain peak performance. Autotuning allows a program to be re-optimized for new hardware, settings, or input — even during execution. However, the approach has an inherent problem that has yet to be properly addressed: since the autotuning process itself requires computational resources, it is also subject to optimization. In other words, while autotuning aims to decrease a program’s run time by improving its efficiency, it also introduces additional overhead that can extend the overall run time. To achieve optimal performance, both the application and the autotuning process should be optimized together, treating them as a single optimization criterion. This framing allows us to determine a reasonable tuning budget to avoid both undertuning, where insufficient autotuning leads to suboptimal performance, and overtuning, where excessive autotuning imposes overhead that outweighs the benefits of program optimization. In this paper, we explore the tuning budget optimization problem in detail, highlighting its interesting properties and implications, which have largely been overlooked in the literature. Additionally, we present several viable solutions for tuning budget optimization and evaluate their efficiency across a range of commonly used HPC kernels.},
  archive      = {J_PARCO},
  author       = {Jaroslav Olha and Jana Hozzová and Matej Antol and Jiří Filipovič},
  doi          = {10.1016/j.parco.2025.103126},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103126},
  shortjournal = {Parallel Comput.},
  title        = {Estimating resource budgets to ensure autotuning efficiency},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lowering entry barriers to developing custom simulators of
distributed applications and platforms with SimGrid. <em>PARCO</em>,
<em>123</em>, 103125. (<a
href="https://doi.org/10.1016/j.parco.2025.103125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers in parallel and distributed computing (PDC) often resort to simulation because experiments conducted using a simulator can be for arbitrary experimental scenarios, are less resource-, labor-, and time-consuming than their real-world counterparts, and are perfectly repeatable and observable. Many frameworks have been developed to ease the development of PDC simulators, and these frameworks provide different levels of accuracy, scalability, versatility, extensibility, and usability. The SimGrid framework has been used by many PDC researchers to produce a wide range of simulators for over two decades. Its popularity is due to a large emphasis placed on accuracy, scalability, and versatility, and is in spite of shortcomings in terms of extensibility and usability. Although SimGrid provides sensible simulation models for the common case, it was difficult for users to extend these models to meet domain-specific needs. Furthermore, SimGrid only provided relatively low-level simulation abstractions, making the implementation of a simulator of a complex system a labor-intensive undertaking. In this work we describe developments in the last decade that have contributed to vastly improving extensibility and usability, thus lowering or removing entry barriers for users to develop custom SimGrid simulators.},
  archive      = {J_PARCO},
  author       = {Henri Casanova and Arnaud Giersch and Arnaud Legrand and Martin Quinson and Frédéric Suter},
  doi          = {10.1016/j.parco.2025.103125},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103125},
  shortjournal = {Parallel Comput.},
  title        = {Lowering entry barriers to developing custom simulators of distributed applications and platforms with SimGrid},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable tasking runtime with parallelized builders for
explicit message passing architectures. <em>PARCO</em>, <em>123</em>,
103124. (<a href="https://doi.org/10.1016/j.parco.2024.103124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sequential task flow (STF) model introduces implicit data dependences to exploit task-based parallelism, simplifying programming but also introducing non-negligible runtime overhead. On emerging cache-less, explicit inter-core message passing (EMP) architectures, the long latency of memory access further amplifies the runtime overhead of the traditional STF model, resulting in unsatisfactory performance. This paper addresses two main components in the STF tasking runtime. We uncover abundant concurrency in the task dependence graph (TDG) building process through three sufficient conditions, put forward PBH, a parallelized TDG building algorithm with helpers which mixes pipeline parallelism and data parallelism to overcome the TDG building bottleneck for fine-grained tasks. We also introduce a centralized, lock-less task scheduler, EMP-C, based on the EMP interface, and propose three optimizations. These two techniques are implemented and evaluated on a product processor with EMP support, i.e. SW26010. Experimental results show that compared to traditional techniques, PBH achieves an average speedup of 1.55 for fine-grained task workloads, and the EMP-C scheduler brings speedups as high as 1.52 and 2.38 for fine-grained and coarse-grained task workloads, respectively. And the combination of these two techniques significantly improves the granularity scalability of the runtime, reducing the minimum effective task granularity (METG) to 0.1 ms and achieving an order of magnitude decrease in some cases.},
  archive      = {J_PARCO},
  author       = {Xiran Gao and Li Chen and Haoyu Wang and Huimin Cui and Xiaobing Feng},
  doi          = {10.1016/j.parco.2024.103124},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103124},
  shortjournal = {Parallel Comput.},
  title        = {Scalable tasking runtime with parallelized builders for explicit message passing architectures},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative methods in GPU-resident linear solvers for
nonlinear constrained optimization. <em>PARCO</em>, <em>123</em>,
103123. (<a href="https://doi.org/10.1016/j.parco.2024.103123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear solvers are major computational bottlenecks in a wide range of decision support and optimization computations. The challenges become even more pronounced on heterogeneous hardware, where traditional sparse numerical linear algebra methods are often inefficient. For example, methods for solving ill-conditioned linear systems have relied on conditional branching, which degrades performance on hardware accelerators such as graphical processing units (GPUs). To improve the efficiency of solving ill-conditioned systems, our computational strategy separates computations that are efficient on GPUs from those that need to run on traditional central processing units (CPUs). Our strategy maximizes the reuse of expensive CPU computations. Iterative methods, which thus far have not been broadly used for ill-conditioned linear systems, play an important role in our approach. In particular, we extend ideas from Arioli et al., (2007) to implement iterative refinement using inexact LU factors and flexible generalized minimal residual (FGMRES), with the aim of efficient performance on GPUs. We focus on solutions that are effective within broader application contexts, and discuss how early performance tests could be improved to be more predictive of the performance in a realistic environment.},
  archive      = {J_PARCO},
  author       = {Kasia Świrydowicz and Nicholson Koukpaizan and Maksudul Alam and Shaked Regev and Michael Saunders and Slaven Peleš},
  doi          = {10.1016/j.parco.2024.103123},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103123},
  shortjournal = {Parallel Comput.},
  title        = {Iterative methods in GPU-resident linear solvers for nonlinear constrained optimization},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards resilient and energy efficient scalable krylov
solvers. <em>PARCO</em>, <em>123</em>, 103122. (<a
href="https://doi.org/10.1016/j.parco.2024.103122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exascale computing must simultaneously address both energy efficiency and resilience as power limits impact scalability and faults are more common. Unfortunately, energy efficiency and resilience have been traditionally studied in isolation and optimizing one typically detrimentally impacts the other. To deliver the promised performance within the given power budget, exascale computing mandates a deep understanding of the interplay among energy efficiency, resilience, and scalability. In this work, we propose novel methods to analyze and optimize the costs of common resilience techniques including checkpoint-restart and forward recovery. We focus on sparse linear solvers as they are the fundamental kernels in many scientific applications. In particular, we present generalized analytical and experimental methods to analyze and quantify the time and energy costs of various recovery schemes on computer clusters, and develop and prototype performance optimization and power management strategies to improve energy efficiency. Moreover, we take a deep dive into the forward recovery that recently started to draw attention from researchers, and propose a practical matrix-aware optimization technique to reduce its recovery time. This work shows that while the time and energy costs of various resilience techniques are different, they share the common components and can be quantitatively evaluated with a generalized framework. This analysis framework can be used to guide the design of performance and energy optimization technologies. While each resilience technique has its advantages depending on the fault rate, system size, and power budget, the forward recovery can further benefit from matrix-aware optimizations for large-scale computing.},
  archive      = {J_PARCO},
  author       = {Zheng Miao and Jon C. Calhoun and Rong Ge},
  doi          = {10.1016/j.parco.2024.103122},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103122},
  shortjournal = {Parallel Comput.},
  title        = {Towards resilient and energy efficient scalable krylov solvers},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seesaw: A 4096-bit vector processor for accelerating kyber
based on RISC-v ISA extensions. <em>PARCO</em>, <em>123</em>, 103121.
(<a href="https://doi.org/10.1016/j.parco.2024.103121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ML-KEM standard based on Kyber algorithm is one of the post-quantum cryptography (PQC) standards released by the National Institute of Standards and Technology (NIST) to withstand quantum attacks. To increase throughput and reduce the execution time that is limited by the high computational complexity of the Kyber algorithm, an RISC-V-based processor Seesaw is designed to accelerate the Kyber algorithm. The 32 specialized extension instructions are mainly designed to enhance the parallel computing ability of the processor and accelerate all the processes of the Kyber algorithm by thoroughly analyzing its characteristics. Subsequently, by carefully designing hardware such as poly vector registers and algorithm execution units on the RISC-V processor, the support of microarchitecture for extension instructions was achieved. Seesaw supports 4096-bit vector calculations through its poly vector registers and execution unit to meet high-throughput requirements and is implemented on the field-programmable gate array (FPGA). In addition, we modify the compiler simultaneously to adapt to the instruction extension and execution of Seesaw. Experimental results indicate that the processor achieves a speed-up of 432 × and 18864 × for hash and NTT, respectively, compared with that without extension instructions and a speed-up of 5.6 × for the execution of the Kyber algorithm compared with the advanced hardware design.},
  archive      = {J_PARCO},
  author       = {Xiaofeng Zou and Yuanxi Peng and Tuo Li and Lingjun Kong and Lu Zhang},
  doi          = {10.1016/j.parco.2024.103121},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103121},
  shortjournal = {Parallel Comput.},
  title        = {Seesaw: A 4096-bit vector processor for accelerating kyber based on RISC-V ISA extensions},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="pr---31">PR - 31</h2>
<ul>
<li><details>
<summary>
(2025). Video summarization with temporal-channel visual
transformer. <em>PR</em>, <em>165</em>, 111631. (<a
href="https://doi.org/10.1016/j.patcog.2025.111631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video summarization task has gained widespread interest, benefiting from its valuable capabilities for efficient video browsing. Existing approaches generally focus on inter-frame temporal correlations, which may not be sufficient to identify crucial content because of the limited useful details that can be gleaned. To resolve these issues, we propose a novel transformer-based approach for video summarization, called Temporal-Channel Visual Transformer (TCVT). The proposed TCVT consists of three components, including a dual-stream embedding module, an inter-frame encoder, and an intra-segment encoder. The dual-stream embedding module creates the fusion embedding sequence by extracting visual features and short-range optical features, preserving appearance and motion details. The temporal-channel inter-frame correlations are learned by the inter-frame encoder with multiple temporal and channel attention modules. Meanwhile, the intra-segment representations are captured by the intra-segment encoder for the local temporal context modeling. Finally, we fuse the frame-level and segment-level representations for the frame-wise importance score prediction. Our network outperforms state-of-the-art methods on two benchmark datasets, with improvements from 55.3% to 56.9% on the SumMe dataset and from 69.3% to 70.4% on the TVSum dataset.},
  archive      = {J_PR},
  author       = {Xiaoyan Tian and Ye Jin and Zhao Zhang and Peng Liu and Xianglong Tang},
  doi          = {10.1016/j.patcog.2025.111631},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111631},
  shortjournal = {Pattern Recognition},
  title        = {Video summarization with temporal-channel visual transformer},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniHDSA: A unified relation prediction approach for
hierarchical document structure analysis. <em>PR</em>, <em>165</em>,
111617. (<a href="https://doi.org/10.1016/j.patcog.2025.111617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document structure analysis, aka document layout analysis, is crucial for understanding both the physical layout and logical structure of documents, serving information retrieval, document summarization, knowledge extraction, etc. Hierarchical Document Structure Analysis (HDSA) specifically aims to restore the hierarchical structure of documents created using authoring software with hierarchical schemas. Previous research has primarily followed two approaches: one focuses on tackling specific subtasks of HDSA in isolation, such as table detection or reading order prediction, while the other adopts a unified framework that uses multiple branches or modules, each designed to address a distinct task. In this work, we propose a unified relation prediction approach for HDSA, called UniHDSA, which treats various HDSA sub-tasks as relation prediction problems and consolidates relation prediction labels into a unified label space. This allows a single relation prediction module to handle multiple tasks simultaneously, whether at a page-level or document-level structure analysis. By doing so, our approach significantly reduces the risk of cascading errors and enhances system’s efficiency, scalability, and adaptability. To validate the effectiveness of UniHDSA, we develop a multimodal end-to-end system based on Transformer architectures. Extensive experimental results demonstrate that our approach achieves state-of-the-art performance on a hierarchical document structure analysis benchmark, Comp-HRDoc, and competitive results on a large-scale document layout analysis dataset, DocLayNet, effectively illustrating the superiority of our method across all sub-tasks.},
  archive      = {J_PR},
  author       = {Jiawei Wang and Kai Hu and Qiang Huo},
  doi          = {10.1016/j.patcog.2025.111617},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111617},
  shortjournal = {Pattern Recognition},
  title        = {UniHDSA: A unified relation prediction approach for hierarchical document structure analysis},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade residual learning based adaptive feature aggregation
for light field super-resolution. <em>PR</em>, <em>165</em>, 111616. (<a
href="https://doi.org/10.1016/j.patcog.2025.111616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light field (LF) super-resolution aims to enhance the spatial or angular resolutions of LF images. Most existing methods tend to decompose 4D LF images into multiple 2D subspaces such as spatial, angular, and epipolar plane image (EPI) domains, and devote efforts to designing various feature extractors for each subspace domain. However, it remains challenging to select an effective multi-domain feature fusion strategy, including the fusion order and structure. To this end, this paper proposes an adaptive feature aggregation framework based on cascade residual learning, which can adaptively select feature aggregation strategies through learning rather than designed artificially. Specifically, we first employ three types of 2D feature extractors for spatial, angular, and EPI feature extraction, respectively. Then, an adaptive feature aggregation (AFA) module is designed to cascade these feature extractors through multi-level residual connections. This design enables the network to flexibly aggregate various subspace features without introducing additional parameters. We conduct comprehensive experiments on both real-world and synthetic LF datasets for light field spatial super-resolution (LFSSR) and light field angular super-resolution (LFASR). Quantitative and visual comparisons demonstrate that our model achieves state-of-the-art super-resolution (SR) performance. The code is available at https://github.com/haozhang25/AFA-LFSR .},
  archive      = {J_PR},
  author       = {Hao Zhang and Wenhui Zhou and Lili Lin and Andrew Lumsdaine},
  doi          = {10.1016/j.patcog.2025.111616},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111616},
  shortjournal = {Pattern Recognition},
  title        = {Cascade residual learning based adaptive feature aggregation for light field super-resolution},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised polarization image dehazing method via
frequency domain generative adversarial networks. <em>PR</em>,
<em>165</em>, 111615. (<a
href="https://doi.org/10.1016/j.patcog.2025.111615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haze significantly hinders the application of autonomous driving, traffic surveillance, and remote sensing. Image dehazing serves as a key technology to enhance the clarity of images captured in hazy conditions. However, the lack of paired annotated training data significantly limits the performance of deep learning-based dehazing methods in real-world scenarios. In this work, we propose a self-supervised polarization image dehazing framework based on frequency domain generative adversarial networks. By incorporating a polarization calculation module into the generator, the Stokes parameters of airlight are accurately estimated, which are used to reconstruct the synthesized hazy image by combining the dehazed image generated via a densely connected encoder-decoder. Furthermore, we optimize the discriminator with frequency domain features extracted by frequency decomposition module and introduce a pseudo airlight coefficient supervision loss to enhance the self-supervised training. By discriminating between synthetic hazy images and real hazy images, we achieve adversarial training without the need for paired data. Simultaneously, supervised by the atmospheric scattering model, our network can iteratively generate more realistic dehazed images. Extensive experiments conducted on the constructed multi-view polarization datasets demonstrate that our method achieves state-of-the-art performance without requiring real-world ground truth.},
  archive      = {J_PR},
  author       = {Rui Sun and Long Chen and Tanbin Liao and Zhiguo Fan},
  doi          = {10.1016/j.patcog.2025.111615},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111615},
  shortjournal = {Pattern Recognition},
  title        = {Self-supervised polarization image dehazing method via frequency domain generative adversarial networks},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual fidelity and full-scale interaction driven network
for infrared and visible image fusion. <em>PR</em>, <em>165</em>,
111612. (<a href="https://doi.org/10.1016/j.patcog.2025.111612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of infrared and visible image fusion is to combine the unique strengths of source images into a single image that serves human visual perception and machine detection. The existing fusion networks are still lacking in the effective characterization and retention of source image features. To counter these deficiencies, we propose a visual fidelity and full-scale interaction driven network for infrared and visible image fusion, named VFFusion. First, a multi-scale feature encoder based on BiFormer is constructed, and a feature cascade interaction module is designed to perform full-scale interaction on features distributed across different scales. In addition, a visual fidelity branch is built to process multi-scale features in parallel with the fusion branch. Specifically, the visual fidelity branch uses blurred images for self-supervised training in the constructed auxiliary task, thereby obtaining an effective representation of the source image information. By exploring the complementary representational features of infrared and visible images as supervisory information, it constrains the fusion branch to retain the source image features in the fused image. Notably, the visual fidelity branch employs a multi-scale joint reconstruction loss, utilizing the rich supervisory signals provided by multi-scale original images to enhance the feature representation of targets at different scales, resulting in clear fusion of the targets. Extensive qualitative and quantitative comparative experiments are conducted on four datasets against nine advanced methods, demonstrating the superiority of our approach. The source code is available at https://github.com/XingLongH/VFFusion .},
  archive      = {J_PR},
  author       = {Liye Mei and Xinglong Hu and Zhaoyi Ye and Zhiwei Ye and Chuan Xu and Sheng Liu and Cheng Lei},
  doi          = {10.1016/j.patcog.2025.111612},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111612},
  shortjournal = {Pattern Recognition},
  title        = {Visual fidelity and full-scale interaction driven network for infrared and visible image fusion},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rank-revealing fully-connected tensor network decomposition
and its application to tensor completion. <em>PR</em>, <em>165</em>,
111610. (<a href="https://doi.org/10.1016/j.patcog.2025.111610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully-connected tensor network (FCTN) decomposition has become a powerful tool for handling high-dimensional data. However, for a given N th-order data, N ( N − 1 ) / 2 tuning parameters (i.e., FCTN rank) in FCTN decomposition is a tricky challenge, which hinders its wide deployments. Although many recent works have emerged to adaptively search for a (near)-optimal FCTN rank, these methods suffer from expensive computational costs since they require too many search and evaluation processes, significantly limiting their applications to high-dimensional data. To tackle the above challenges, we develop a rank-revealing FCTN (revealFCTN) decomposition, whose FCTN rank is adaptively and efficiently inferred. More specifically, by analyzing the sizes of the sub-network tensors in the FCTN decomposition, we establish the equivalent relationships between the FCTN rank and the ranks of single-mode and double-mode unfolding matrices of the given data. The FCTN rank can be directly revealed through the ranks of these unfolding matrices, which does not require any search and evaluation process, making the computational cost almost negligible compared to the search-based methods. To evaluate the performance of the developed revealFCTN decomposition, we test its performance on a representative task: tensor completion (TC). Comprehensive experimental results demonstrate that our method outperforms several state-of-the-art methods, achieving a MPSNR gain of around 1 dB in most cases compared to the original FCTN decomposition.},
  archive      = {J_PR},
  author       = {Yun-Yang Liu and Xi-Le Zhao and Gemine Vivone},
  doi          = {10.1016/j.patcog.2025.111610},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111610},
  shortjournal = {Pattern Recognition},
  title        = {Rank-revealing fully-connected tensor network decomposition and its application to tensor completion},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online asymmetric supervised discrete cross-modal hashing
for streaming multimedia data. <em>PR</em>, <em>165</em>, 111604. (<a
href="https://doi.org/10.1016/j.patcog.2025.111604">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal online hashing, which uses freshly received data to retrain the hash function gradually, has become a research hotspot as a means of handling the massive amounts of streaming data that have been brought about by the fast growth of multimedia technology and the popularity of portable devices. However, in the process of processing stream data in most methods, on the one hand, the relationship between modal classes and the common features between label vectors and binary codes is not fully explored. On the other hand, the semantic information in the old and new data modes is not fully utilized. In this post, we offer Online Asymmetric Supervised Discrete Cross-Modal Hashing for Streaming Multimedia Data (OASCH) as a solution. This study integrates the concept cognition mechanism of dynamic incremental samples and an asymmetric knowledge guidance mechanism into the online hash learning framework. The proposed algorithmic model takes into account the knowledge similarity between newly arriving data and the existing dataset, as well as the knowledge similarity within the new data itself. It projects the hash codes associated with new incoming sample data into the potential space of concept cognition. By doing so, the model maximizes the mining of implicit semantic similarities within streaming data across different time points, resulting in the generation of compact hash codes with enhanced discriminative power, we further propose an adaptive edge regression strategy. Our method surpasses several current sophisticated cross-modal hashing techniques regarding both retrieval efficiency and search accuracy, according to studies on three publicly available multimedia retrieval datasets.},
  archive      = {J_PR},
  author       = {Fan Yang and Xinqi Liu and Fumin Ma and Xiaojian Ding and Kaixiang Wang},
  doi          = {10.1016/j.patcog.2025.111604},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111604},
  shortjournal = {Pattern Recognition},
  title        = {Online asymmetric supervised discrete cross-modal hashing for streaming multimedia data},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Brain anatomy prior modeling to forecast clinical
progression of cognitive impairment with structural MRI. <em>PR</em>,
<em>165</em>, 111603. (<a
href="https://doi.org/10.1016/j.patcog.2025.111603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain structural MRI has been widely used to assess the future progression of cognitive impairment (CI). Previous learning-based studies usually suffer from the issue of small-sized labeled training data, while a huge amount of structural MRIs exist in large-scale public databases. Intuitively, brain anatomical structures derived from these public MRIs (even without task-specific label information) can boost CI progression trajectory prediction. However, previous studies seldom use such brain anatomy structure information as priors. To this end, this paper proposes a brain anatomy prior modeling (BAPM) framework to forecast the clinical progression of cognitive impairment with small-sized target MRIs by exploring anatomical brain structures. Specifically, the BAPM consists of a pretext model and a downstream model , with a shared brain anatomy-guided encoder to model brain anatomy prior using auxiliary tasks explicitly. Besides the encoder, the pretext model also contains two decoders for two auxiliary tasks ( i.e. , MRI reconstruction and brain tissue segmentation), while the downstream model relies on a predictor for classification. The brain anatomy-guided encoder is pre-trained with the pretext model on 9,344 auxiliary MRIs without diagnostic labels for anatomy prior modeling. With this encoder frozen, the downstream model is then fine-tuned on limited target MRIs for prediction. We validate BAPM on two CI-related studies with T1-weighted MRIs from 448 subjects. Experimental results suggest the effectiveness of BAPM in (1) four CI progression prediction tasks, (2) MR image reconstruction, and (3) brain tissue segmentation, compared with several state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Lintao Zhang and Jinjian Wu and Lihong Wang and Li Wang and David C. Steffens and Shijun Qiu and Guy G. Potter and Mingxia Liu},
  doi          = {10.1016/j.patcog.2025.111603},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111603},
  shortjournal = {Pattern Recognition},
  title        = {Brain anatomy prior modeling to forecast clinical progression of cognitive impairment with structural MRI},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSKA: Multi-stream keypoint attention network for sign
language recognition and translation. <em>PR</em>, <em>165</em>, 111602.
(<a href="https://doi.org/10.1016/j.patcog.2025.111602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign language serves as a non-vocal means of communication, transmitting information and significance through gestures, facial expressions, and bodily movements. The majority of current approaches for sign language recognition (SLR) and translation rely on RGB video inputs, which are vulnerable to fluctuations in the background. Employing a keypoint-based strategy not only mitigates the effects of background alterations but also substantially diminishes the computational demands of the model. Nevertheless, contemporary keypoint-based methodologies fail to fully harness the implicit knowledge embedded in keypoint sequences. To tackle this challenge, our inspiration is derived from the human cognition mechanism, which discerns sign language by analyzing the interplay between gesture configurations and supplementary elements. We propose a multi-stream keypoint attention network to depict a sequence of keypoints produced by a readily available keypoint estimator. In order to facilitate interaction across multiple streams, we investigate diverse methodologies such as keypoint fusion strategies, head fusion, and self-distillation. The resulting framework is denoted as MSKA-SLR, which is expanded into a sign language translation (SLT) model through the straightforward addition of an extra translation network. We carry out comprehensive experiments on well-known benchmarks like Phoenix-2014, Phoenix-2014T, and CSL-Daily to showcase the efficacy of our methodology. Notably, we have attained a novel state-of-the-art performance in the sign language translation task of Phoenix-2014T. The code and models can be accessed at: https://github.com/sutwangyan/MSKA .},
  archive      = {J_PR},
  author       = {Mo Guan and Yan Wang and Guangkun Ma and Jiarui Liu and Mingzu Sun},
  doi          = {10.1016/j.patcog.2025.111602},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111602},
  shortjournal = {Pattern Recognition},
  title        = {MSKA: Multi-stream keypoint attention network for sign language recognition and translation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptively robust high-order tensor factorization for
low-rank tensor reconstruction. <em>PR</em>, <em>165</em>, 111600. (<a
href="https://doi.org/10.1016/j.patcog.2025.111600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, various approaches have been proposed for tensor reconstruction from incomplete and contaminated data. However, most algorithms focus on third-order tensors, neglecting higher-order tensors that are common in real-world applications. Additionally, many studies use LASSO-type penalties or second-order statistics to capture noise patterns, which may not perform well with dense and gross outliers. To address these challenges, we propose a novel robust high-order tensor recovery model that simultaneously removes complex noise and completes missing entries. We introduce a factor Frobenius norm for the low-rank structures of high-order tensors and derive a nonconvex function via the L 2 criterion. An estimation algorithm is developed using the alternating minimization method. Our method jointly estimates tensor terms of interest and precision parameters, adapting to noise patterns for data-driven robustness. We analyze the convergence properties of our algorithm, and numerical experiments validate its superiority in natural image reconstruction, video restoration, and background modeling compared to state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Zihao Song and Yongyong Chen and Zhao Weihua},
  doi          = {10.1016/j.patcog.2025.111600},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111600},
  shortjournal = {Pattern Recognition},
  title        = {Adaptively robust high-order tensor factorization for low-rank tensor reconstruction},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidirectional trained tree-structured decoder for
handwritten mathematical expression recognition. <em>PR</em>,
<em>165</em>, 111599. (<a
href="https://doi.org/10.1016/j.patcog.2025.111599">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Handwritten Mathematical Expression Recognition (HMER) task is a critical branch in the field of Optical Character Recognition (OCR). Recent studies have demonstrated that incorporating bidirectional context information significantly improves the performance of HMER models. However, existing methods fail to effectively utilize bidirectional context information during the inference stage. Furthermore, current bidirectional training methods are primarily designed for string decoders and cannot adequately generalize to tree decoders, which offer superior generalization capabilities and structural analysis capacity. To overcome these limitations, we propose the Mirror-Flipped Symbol Layout Tree (MF-SLT) and Bidirectional Asynchronous Training (BAT) structure. Our method extends the bidirectional training strategy to the tree decoder, enabling more effective training by leveraging bidirectional information. Additionally, we analyze the impact of the visual and linguistic perception of the HMER model separately and introduce the Shared Language Modeling (SLM) mechanism. Through the SLM, we enhance the model’s robustness and generalization when dealing with visual ambiguity, especially in scenarios with abundant training data. Our approach has been validated through extensive experiments, demonstrating its ability to achieve new state-of-the-art results on the CROHME 2014, 2016, and 2019 datasets, as well as the HME100K dataset. The code used in our experiments will be publicly available at https://github.com/Hanbo-Cheng/BAT.git .},
  archive      = {J_PR},
  author       = {Hanbo Cheng and Chenyu Liu and Pengfei Hu and Zhenrong Zhang and Jiefeng Ma and Jun Du},
  doi          = {10.1016/j.patcog.2025.111599},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111599},
  shortjournal = {Pattern Recognition},
  title        = {Bidirectional trained tree-structured decoder for handwritten mathematical expression recognition},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disentanglement and codebook learning-induced feature match
network to diagnose neurodegenerative diseases on incomplete multimodal
data. <em>PR</em>, <em>165</em>, 111597. (<a
href="https://doi.org/10.1016/j.patcog.2025.111597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal data can provide complementary information to diagnose neurodegenerative diseases (NDs). However, image quality variations and high costs can result in the missing data problem. Although incomplete multimodal data can be projected onto a common space, the traditional projection process may increase alignment errors and lose some modality-specific information. A disentanglement and codebook learning-induced feature match network (DCFMnet) is proposed in this study to solve the aforementioned issues. First, multimodal data are disentangled into latent modality-common and -specific features to help preserve modality-specific information in the subsequent alignment of multimodal data. Second, the latent modal features of all available data are aligned into a common space to reduce alignment errors and fused to achieve ND diagnosis. Moreover, the latent modal features of the modality with missing data are explored in online updated feature codebooks. Last, DCFMnet is tested on two publicly available datasets to illustrate its excellent performance in ND diagnosis.},
  archive      = {J_PR},
  author       = {Wei Xiong and Tao Wang and Xiumei Chen and Yue Zhang and Wencong Zhang and Qianjin Feng and Meiyan Huang and Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.patcog.2025.111597},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111597},
  shortjournal = {Pattern Recognition},
  title        = {Disentanglement and codebook learning-induced feature match network to diagnose neurodegenerative diseases on incomplete multimodal data},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-world nighttime image dehazing using contrastive and
adversarial learning. <em>PR</em>, <em>165</em>, 111596. (<a
href="https://doi.org/10.1016/j.patcog.2025.111596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nighttime image dehazing is a challenging task due to the scarcity of real hazy images and the domain gap between synthetic and real data. To address these challenges, we propose a novel deep learning framework that integrates contrastive and adversarial learning. In the initial training phase, the dehazing generator is trained on synthetic data to produce dehazed images that closely match the ground truths while maintaining a significant distance from the original hazy images through contrastive learning. Simultaneously, the contrastive learning encoder is updated to enhance its ability to distinguish between the dehazed images and ground truths, thereby increasing the difficulty of the dehazing task and pushing the generator to fully exploit feature information for improved results. To bridge the gap between synthetic and real data, the model is fine-tuned using a small set of real hazy images. To mitigate bias from the limited amount of real data, an additional constraint is applied to regulate model adjustments during fine-tuning. Empirical evaluation on multiple benchmark datasets demonstrates that our model outperforms state-of-the-art methods, providing an effective solution for improving visibility in hazy nighttime images by effectively leveraging both synthetic and real data.},
  archive      = {J_PR},
  author       = {Jingwen Deng and Patrick P.K. Chan and Daniel S. Yeung},
  doi          = {10.1016/j.patcog.2025.111596},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111596},
  shortjournal = {Pattern Recognition},
  title        = {Real-world nighttime image dehazing using contrastive and adversarial learning},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSDC-NET: Semi-supervised superficial OCTA vessel
segmentation for false positive reduction. <em>PR</em>, <em>165</em>,
111592. (<a href="https://doi.org/10.1016/j.patcog.2025.111592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate vessel segmentation in Optical Coherence Tomography Angiography (OCTA) is essential for ocular disease diagnosis, monitoring, and treatment assessment. However, most current automatic segmentation methods overlook false positives in the segmentation results, leading to potential misdiagnosis and delayed treatment. To address this issue, we propose a Dynamic Spatial Semi-Supervised Vessel Segmentation with Dual Topological Consistency (DSDC-NET) for retinal superficial OCTA images. The network integrates a Dynamic Spatial Attention Mechanism that combines snake-shaped convolution, which captures tubular fine structures, with spatial attention to suppress background noise and artefacts. This design enhances vessel region responses while accurately capturing complex local structures, thereby reducing false positives arising from inaccurate localisation of vessel details. Furthermore, Dual Topological Consistency Loss integrates the Persistent Homology features of the vessel system with the topological skeleton features of major vessels, enhancing branching pattern recognition. A Warm-up mechanism balances the focus of the network between major and branch vessels across training phases, mitigating false positives from inadequate branching structure learning. Comprehensive evaluations on ROSE-1, OCTA-500, and ROSSA datasets demonstrate the superiority of DSDC-NET over existing methods. Notably, DSDC-NET effectively reduces the false discovery rate and improves segmentation accuracy, validating its effectiveness in reducing false positives.},
  archive      = {J_PR},
  author       = {Xinyi Liu and Hailan Shen and Wenyan Zhong and Wanqing Xiong and Zailiang Chen},
  doi          = {10.1016/j.patcog.2025.111592},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111592},
  shortjournal = {Pattern Recognition},
  title        = {DSDC-NET: Semi-supervised superficial OCTA vessel segmentation for false positive reduction},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalizable person re-identification method using
bi-stream interactive learning with feature reconstruction. <em>PR</em>,
<em>165</em>, 111591. (<a
href="https://doi.org/10.1016/j.patcog.2025.111591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that metric learning and representation learning are two main methods to improve the generalization ability of pedestrian re-identification models. However, their relationship has not been fully explored. Unlike GANs’ emphasis on adversarial learning, our objective is to develop an interactive and synergistic learning framework for them. To achieve this, we propose a generalized pedestrian re-identification method using bi-stream interactive learning. One of the learning streams is the correlation graph sampler (CGS) for metric learning, and the other learning stream is the global sparse attention network (GSANet) for representation learning. We establish an intrinsic connection between these two learning streams. Unlike many existing methods that have high memory and computation costs or lack learning ability, CGS provides a more efficient and effective solution. CGS uses local sensitive hashing and feature metrics to construct the nearest neighbor graph for all categories at the beginning of training, which ensures that each batch of training samples contains randomly selected base categories and their nearest neighbor categories, providing strong similarity and challenging learning examples. As CGS sampling performance is affected by the quality of the feature map, we propose a global feature sparse reconstruction module to enhance the global self-correlation of the feature map extracted by the backbone network. Additionally, we extensively evaluate our method on large-scale datasets, including CUHK03, Market-1501, and MSMT17, and our method outperforms current state-of-the-art methods. These results confirm the effectiveness of our method and demonstrate its potential in pedestrian re-identification applications.},
  archive      = {J_PR},
  author       = {Feng Min and Yuhui Liu and Yixin Mao},
  doi          = {10.1016/j.patcog.2025.111591},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111591},
  shortjournal = {Pattern Recognition},
  title        = {Generalizable person re-identification method using bi-stream interactive learning with feature reconstruction},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Eye-SCAN: Eye-movement-attention-based spatial channel
adaptive network for traffic accident prediction. <em>PR</em>,
<em>165</em>, 111590. (<a
href="https://doi.org/10.1016/j.patcog.2025.111590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the task of using visual cues extracted from DashCam video data to predict future accidents, understanding the dynamic spatio-temporal interactions in driving scenarios poses a major challenge. Given that the gaze attention information of experienced drivers during the driving process involves complex spatio-temporal interactions, this information can provide valuable guidance for training accident prediction models. Therefore, we propose an Eye-Movement-Attention-based Spatial Channel Adaptive Network (Eye-SCAN) for traffic accident prediction, which can efficiently learn multi-scale spatial channel information from driver gaze data. To integrate potential guidance information from driver eye movement information (EyeInfo) into Eye-SCAN, we propose two sub-modules in our model: the Spatial Adaptive Module (SAM), which helps Eye-SCAN adaptively learn low-dimensional spatial features of EyeInfo; and the Channel Adaptive Module (CAM), which aids Eye-SCAN to adaptively learning high-dimensional channel features of EyeInfo. Additionally, we introduce a novel recursive transmission strategy for temporal information to mitigate the impact of varying past results on the model’s current inferences. Experimental results demonstrate that our model outperforms state-of-the-art methods on two benchmark datasets, highlighting the contributions of each component and offering an effective solution for enhancing the safety of intelligent vehicles.},
  archive      = {J_PR},
  author       = {Xiaohui Yang and Yu Qiao and Tongzhen Si and Jing Wang and Tao Xu},
  doi          = {10.1016/j.patcog.2025.111590},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111590},
  shortjournal = {Pattern Recognition},
  title        = {Eye-SCAN: Eye-movement-attention-based spatial channel adaptive network for traffic accident prediction},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated subset selection and bandwidth estimation
algorithm for geographically weighted regression. <em>PR</em>,
<em>165</em>, 111589. (<a
href="https://doi.org/10.1016/j.patcog.2025.111589">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a mathematical programming-based algorithm for the integrated selection of variable subsets and bandwidth estimation in geographically weighted regression, a local regression method that allows the kernel bandwidth and regression coefficients to vary across study areas. Unlike standard approaches in the literature, in which bandwidth and regression parameters are estimated separately for each focal point on the basis of different criteria, our model uses a single objective function for the integrated estimation of regression and bandwidth parameters across all focal points, based on the regression likelihood function and variance modeling. The proposed model further integrates a procedure to select a single subset of independent variables for all focal points, whereas existing approaches may return heterogeneous subsets across focal points. We then propose an alternative direction method to solve the nonconvex mathematical model and show that it converges to a partial minimum. The computational experiment indicates that the proposed algorithm provides competitive explanatory power with stable spatially varying patterns, with the ability to select the best subset and account for additional constraints.},
  archive      = {J_PR},
  author       = {Hyunwoo Lee and Young Woong Park},
  doi          = {10.1016/j.patcog.2025.111589},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111589},
  shortjournal = {Pattern Recognition},
  title        = {Integrated subset selection and bandwidth estimation algorithm for geographically weighted regression},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granular-ball computing-based random walk for anomaly
detection. <em>PR</em>, <em>165</em>, 111588. (<a
href="https://doi.org/10.1016/j.patcog.2025.111588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is a key task in data mining, which has been successfully employed in many practical scenarios. However, most existing methods usually analyze the anomalous characteristics of samples at a single and finest granularity, which leads to high computational cost and low efficiency. As one of the significant mathematical models in the theory of granular computing, granular-ball computing can portray the distributional characteristics of data from a multi-granularity perspective. For this reason, this paper proposes an unsupervised anomaly detection method based on granular-ball computing. Firstly, the samples are covered by generating adaptive granular-balls, and the multi-granularity information represented by granular-balls with different sizes can reflect the data distribution characteristics of the corresponding region. Secondly, the granular-balls are used to fit the samples for constructing a state transfer matrix in Random walk. Then, the steady-state distribution is generated using iterative computation and is normalized as the degree of anomaly for each granular-ball. Finally, the anomaly score for each sample is computed by relating the anomaly degree of each granular-ball to the samples it covers. Comparative experiments show that the proposed anomaly detection method performs well on multiple datasets, demonstrating its feasibility and superiority in practical applications. The code is publicly available online at https://github.com/optimusprimeyy/GBRAD .},
  archive      = {J_PR},
  author       = {Sihan Wang and Zhong Yuan and Shitong Cheng and Hongmei Chen and Dezhong Peng},
  doi          = {10.1016/j.patcog.2025.111588},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111588},
  shortjournal = {Pattern Recognition},
  title        = {Granular-ball computing-based random walk for anomaly detection},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain consistency learning for continual test-time
adaptation in image semantic segmentation. <em>PR</em>, <em>165</em>,
111585. (<a href="https://doi.org/10.1016/j.patcog.2025.111585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the open-world scenario, the challenge of distribution shift persists. Test-time adaptation adjusts the model during test-time to fit the target domain’s data, addressing the distribution shift between the source and target domains. However, test-time adaptation methods still face significant challenges with continuously changing data distributions, especially since there are few methods applicable to continual test-time adaptation in image semantic segmentation. Furthermore, inconsistent semantic representations across different domains result in catastrophic forgetting in continual test-time adaptation. This paper focuses on the problem of continual test-time adaptation in semantic segmentation tasks and proposes a method named domain consistency learning for continual test-time adaptation. We mitigate catastrophic forgetting through feature-level and prediction-level consistency learning. Specifically, we propose domain feature consistency learning and class awareness consistency learning to guide model learning, enabling the target domain model to extract generalized knowledge. Additionally, to mitigate error accumulation, we propose a novel value-based sample selection method that jointly considers the pseudo-label confidence and style representativeness of the test images. Extensive experiments on widely-used semantic segmentation benchmarks demonstrate that our approach achieves satisfactory performance compared to state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Yanyu Ye and Wei Wei and Lei Zhang and Chen Ding and Yanning Zhang},
  doi          = {10.1016/j.patcog.2025.111585},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111585},
  shortjournal = {Pattern Recognition},
  title        = {Domain consistency learning for continual test-time adaptation in image semantic segmentation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Layerlink: Bridging remote sensing object detection and
large vision models with efficient fine-tuning. <em>PR</em>,
<em>165</em>, 111583. (<a
href="https://doi.org/10.1016/j.patcog.2025.111583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Vision Models (LVMs) exhibit robust feature extraction capabilities, offering significant potential to address performance bottlenecks in remote sensing object detection (RSOD). However, fine-tuning LVMs for RSOD remains challenging due to the high computational cost of large-resolution imagery, the complexity of densely packed objects and backgrounds, and the susceptibility to over-fitting on limited RSOD datasets. To address these challenges, we propose Layerlink , a parameter-efficient fine-tuning (PEFT) framework. Layerlink introduces the Conductor Adapter (CA) , a lightweight module that fine-tunes only a minimal set of parameters, enabling precise adaptation to complex object layouts while ensuring both computational and storage efficiency. Building on the strengths of CA, the Layerlink strategy integrates shared CA modules across hierarchical layers of the LVM, leveraging inter-layer feature similarities to enhance generalization and reduce redundancy. To validate our approach, we adapt state-of-the-art PEFT techniques originally developed for large language models to the RSOD domain, benchmarking them to establish a new standard for future research. Experiments on widely used RSOD datasets demonstrate that Layerlink achieves state-of-the-art performance while fine-tuning less than 8% of the entire network parameters. This innovation opens new avenues for efficient LVM utilization in RSOD. Code and models will be made publicly available.},
  archive      = {J_PR},
  author       = {Xingkui Zhu and Dingkang Liang and Xingyu Jiang and Yiran Guan and Yuliang Liu and Yingying Zhu and Xiang Bai},
  doi          = {10.1016/j.patcog.2025.111583},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111583},
  shortjournal = {Pattern Recognition},
  title        = {Layerlink: Bridging remote sensing object detection and large vision models with efficient fine-tuning},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual structure-aware consensus graph learning for incomplete
multi-view clustering. <em>PR</em>, <em>165</em>, 111582. (<a
href="https://doi.org/10.1016/j.patcog.2025.111582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to single-view data, multi-view data encompasses both additional complementary information and redundancies. The discriminative information presented in these aligned multiple views is helpful for enhancing the performance of clustering tasks. In reality, data views are frequently incomplete, which poses a significant challenge to the clustering task. In this paper, we introduce a new method, which we called Structured-aware Consensus Graph Learning for Incomplete Multi-View Clustering (SWCGLIMVC) to tackle the problem of incomplete multi-view clustering (IMVC). Specifically, considering that the neighbor relationships between samples are of utmost importance in unsupervised clustering tasks, SWCGLIMVC leverages the intrinsic geometry structure information of all samples and preserves their neighbor relationships through the graph Laplacian regularization constraint. Moreover, to reduce the adverse effects of the imbalanced useful information contained in different views, SWCGLIMVC incorporates a dynamically learnable vector to constrain the learning models of different views. This allows the method to effectively explore the information from all incomplete views for data clustering tasks. The effectiveness of SWCGLIMVC is evaluated by conducting experiments on six widely known datasets with the comparison of several state-of-the-art clustering methods. The experimental results show that the superior performance of SWCGLIMVC on IMVC tasks.},
  archive      = {J_PR},
  author       = {Lilei Sun and Wai Keung Wong and Yusen Fu and Jie Wen and Mu Li and Yuwu Lu and Lunke Fei},
  doi          = {10.1016/j.patcog.2025.111582},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111582},
  shortjournal = {Pattern Recognition},
  title        = {Dual structure-aware consensus graph learning for incomplete multi-view clustering},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomized quaternion tensor UTV decompositions for color
image and color video processing. <em>PR</em>, <em>165</em>, 111580. (<a
href="https://doi.org/10.1016/j.patcog.2025.111580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose novel quaternion matrix UTV (QUTV) and quaternion tensor UTV (QTUTV) decomposition methods, specifically designed for color image and video processing. We begin by defining both QUTV and QTUTV decompositions and provide detailed algorithmic descriptions. To enhance computational efficiency, we introduce randomized versions of these decompositions using random sampling from the quaternion normal distribution, which results in cost-effective and interpretable solutions. Extensive numerical experiments demonstrate that the proposed algorithms significantly improve computational efficiency while maintaining relative errors comparable to existing decomposition methods. These results underscore the strong potential of quaternion-based decompositions for real-world color image and video processing applications. Theoretical findings further support the robustness of the proposed methods, providing a solid foundation for their widespread use in practice.},
  archive      = {J_PR},
  author       = {Liqiao Yang and Jifei Miao and Tai-Xiang Jiang and Yanlin Zhang and Kit Ian Kou},
  doi          = {10.1016/j.patcog.2025.111580},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111580},
  shortjournal = {Pattern Recognition},
  title        = {Randomized quaternion tensor UTV decompositions for color image and color video processing},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identity-aware infrared person image generation and
re-identification via controllable diffusion model. <em>PR</em>,
<em>165</em>, 111561. (<a
href="https://doi.org/10.1016/j.patcog.2025.111561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible–infrared person re-identification (VI-ReID) aims to learn the identity-aware features between visible and infrared person images. However, most works rely on two publicly available datasets, i . e . , SYSU-MM01 and RegDB, which is limited by the limited amount of training data and the lack of rich scenes and perspectives. In this paper, we propose a controllable diffusion framework for infrared person image generation and re-identification. Our approach is beyond the existing diffusion model in two perspectives: (1) we use LoRA to fine-tune the existing diffusion models with VI-ReID dataset and therefore it helps the diffusion model understand the infrared modality. A text adapter is then utilized to transfer the semantic understanding ability of Large Language Model (LLMs) to our generation models; (2) we design a controllable generation module to make the generated person images, from the same textual description, identity-aware. After meticulous post-processing operations, our approach is capable of producing diverse visible and infrared person images, allowing for improving the discrimination of existing VI-ReID model without any annotations. We expand the VI-ReID dataset with our generated images, and conduct extensive experiments on VI-ReID models. Experimental results demonstrate the effectiveness of our method.},
  archive      = {J_PR},
  author       = {Xizhuo Yu and Chaojie Fan and Zhizhong Zhang and Yongbo Wang and Chunyang Chen and Tianjian Yu and Yong Peng},
  doi          = {10.1016/j.patcog.2025.111561},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111561},
  shortjournal = {Pattern Recognition},
  title        = {Identity-aware infrared person image generation and re-identification via controllable diffusion model},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FILP-3D: Enhancing 3D few-shot class-incremental learning
with pre-trained vision-language models. <em>PR</em>, <em>165</em>,
111558. (<a href="https://doi.org/10.1016/j.patcog.2025.111558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot class-incremental learning (FSCIL) aims to mitigate the catastrophic forgetting issue when a model is incrementally trained on limited data. However, many of these works lack effective exploration of prior knowledge, rendering them unable to effectively address the domain gap issue in the context of 3D FSCIL, thereby leading to catastrophic forgetting. The Contrastive Vision-Language Pre-Training (CLIP) model serves as a highly suitable backbone for addressing the challenges of 3D FSCIL due to its abundant shape-related prior knowledge. Unfortunately, its direct application to 3D FSCIL still faces the incompatibility between 3D data representation and the 2D features, primarily manifested as feature space misalignment and significant noise. To address the above challenges, we introduce the FILP-3D framework with two novel components: the Redundant Feature Eliminator (RFE) for feature space misalignment and the Spatial Noise Compensator (SNC) for significant noise. RFE aligns the feature spaces of input point clouds and their embeddings by performing a unique dimensionality reduction on the feature space of pre-trained models (PTMs), effectively eliminating redundant information without compromising semantic integrity. On the other hand, SNC is a graph-based 3D model designed to capture robust geometric information within point clouds, thereby augmenting the knowledge lost due to projection, particularly when processing real-world scanned data. Moreover, traditional accuracy metrics are proven to be biased due to the imbalance in existing 3D datasets. Therefore we propose 3D FSCIL benchmark FSCIL3D-XL and novel evaluation metrics that offer a more nuanced assessment of a 3D FSCIL model. Experimental results on both established and our proposed benchmarks demonstrate that our approach significantly outperforms existing state-of-the-art methods. Code is available at: https://github.com/HIT-leaderone/FILP-3D},
  archive      = {J_PR},
  author       = {Wan Xu and Tianyu Huang and Tianyuan Qu and Guanglei Yang and Yiwen Guo and Wangmeng Zuo},
  doi          = {10.1016/j.patcog.2025.111558},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111558},
  shortjournal = {Pattern Recognition},
  title        = {FILP-3D: Enhancing 3D few-shot class-incremental learning with pre-trained vision-language models},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised multiplex graph representation learning via
maximizing coding rate reduction. <em>PR</em>, <em>165</em>, 111557. (<a
href="https://doi.org/10.1016/j.patcog.2025.111557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised multiplex graph representation learning (UMGRL) has gained increasing attention for its effectiveness to extract discriminative and consistent representations without labels. However, previous methods ignore the diversity of extracted representations, leading to sub-optimal results. To address the aforementioned limitations, in this paper, we propose a unified framework to extract discriminative, diverse and consistent representations simultaneously for UMGRL. To do this, we first employ the Multi-Layer Perceptron encoder with the local preserve loss to extract high-quality representations, and then employ two constraints based on the coding rate to constrain representations’ diversity, discrimination, and consistency. Comprehensive experiments are conducted to verify the effectiveness of the proposed model. The results show that our method outperforms fourteen existing methods on four public benchmark datasets for three different downstream tasks. The code is available at https://github.com/OllieWangx/D2CMG .},
  archive      = {J_PR},
  author       = {Xin Wang and Liang Peng and Rongyao Hu and Ping Hu and Xiaofeng Zhu},
  doi          = {10.1016/j.patcog.2025.111557},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111557},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised multiplex graph representation learning via maximizing coding rate reduction},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchy-based diagram-sentence matching on dual-modal
graphs. <em>PR</em>, <em>165</em>, 111556. (<a
href="https://doi.org/10.1016/j.patcog.2025.111556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagram is a special kind of image drawn by domain experts, which mainly consists of graphic symbols and abstract drawings. It is essential to combine the diagrams with other modalities (e.g. textual descriptions and subtitles in teaching videos) for in-depth understanding of the knowledge concepts. Diagram-sentence matching, a novel task proposed to bridge abstract diagram representation and explicit natural language, is significant to textbook question answering (TQA) and diagram understanding but remains challenging. Existing vision-language matching works mainly focus on the field of natural images and are not applicable to diagrams due to the following two characteristics: (1) the relation in diagrams has diversified representation forms; (2) the knowledge concepts conveyed in diagrams are key to fine-grained diagram-sentence matching. In this paper, we propose the Hierarchy-Based Diagram-Sentence Matching (HBDSM) model and transfer this problem into a cross-modal knowledge concept matching task at multiple levels. To achieve this, the HBDSM first encodes the diagram and sentence as symmetrical dual-modal graphs. For diagram, a novel Visual Relation Structure Learning (VRSL) method is designed to explore the structural relations between objects, which constitute the edges. For sentence, words are fused into object and relation chunks as nodes, associated by edges according to their semantic dependencies. Motivated by the human cognitive process, the fine-grained correspondence between diagram and sentence is modeled based on the hierarchy of dual-modal graphs progressively, using from low-order to high-order information. Node-level matching establishes alignment of object nodes, based on which structure-level matching compares the internal structures of both graphs. Further, concept-level matching includes relation semantics to match the cross-modal concepts based on structure alignment. Extensive experiments demonstrate the effectiveness of HBDSM in diagram-sentence matching, achieving new state-of-the-art results with relative improvement of 20.0% at rSum on AI2D#. Competitive performances of image-sentence matching on Flickr30K and MSCOCO also verify certain applicability of HBDSM for natural images.},
  archive      = {J_PR},
  author       = {Wenjun Wu and Lingling Zhang and Jun Liu and Ming Ren and Xin Hu and Jiaxin Wang and Qianying Wang},
  doi          = {10.1016/j.patcog.2025.111556},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111556},
  shortjournal = {Pattern Recognition},
  title        = {Hierarchy-based diagram-sentence matching on dual-modal graphs},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal hypergraph contrastive learning for medical
image segmentation. <em>PR</em>, <em>165</em>, 111544. (<a
href="https://doi.org/10.1016/j.patcog.2025.111544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) has become a dominant approach in multi-modal medical image segmentation. However, existing methods, such as Seq SSL and Joint SSL, suffer from catastrophic forgetting and conflicts in representation learning across different modalities. To address these challenges, we propose a two-stage SSL framework, HyCon, for multi-modal medical image segmentation. It combines the advantages of Seq and Joint SSL using knowledge distillation to align similar topological samples across modalities. In the first stage, cross-modal features are learned through adversarial learning. Inspired by the Graph Foundation Models and further adapted to our task, the Hypergraph Contrastive Learning Network (HCLN) with a teacher-student architecture is subsequently introduced to capture high-order relationships across modalities by integrating hypergraphs with contrastive learning. The Topology Hybrid Distillation (THD) module distills topological information, contextual features, and relational knowledge into the student model. We evaluated HyCon on two organs, lung and brain. Our framework outperformed state-of-the-art SSL methods, achieving significant improvements in segmentation with limited labeled data. Both quantitative and qualitative experiments validate the effectiveness of the design of our framework. Code is available at: https://github.com/reeive/HyCon .},
  archive      = {J_PR},
  author       = {Weipeng Jing and Junze Wang and Donglin Di and Dandan Li and Yang Song and Lei Fan},
  doi          = {10.1016/j.patcog.2025.111544},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111544},
  shortjournal = {Pattern Recognition},
  title        = {Multi-modal hypergraph contrastive learning for medical image segmentation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep wavelet temporal-frequency attention for nonlinear fMRI
factorization in ASD. <em>PR</em>, <em>165</em>, 111543. (<a
href="https://doi.org/10.1016/j.patcog.2025.111543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal-frequency characteristics in fMRI data are key to distinguishing Autism Spectrum Disorder (ASD) from neurotypical individuals. However, the non-linearity and multidimensionality of fMRI data pose significant challenges. To address these, we introduce a Deep Non-linear Factorization method with a Wavelet Temporal-Frequency Attention module (Deep WTFAF) tailored for multidimensional fMRI analysis. By leveraging the wavelet domain, our approach applies temporal-frequency attention to assign weights to significant features, enhancing critical data while reconstructing incomplete fMRI data. This method enables deep non-linear factorization and effective feature representation for subsequent classification tasks. Validated on ASD-related fMRI datasets, Deep WTFAF outperforms traditional methods, maintaining essential information and ensuring robustness against high-dimensional and incomplete data. Stability theory proof further confirms the model’s reliability, crucial for clinical applications like neurological disorder classification.},
  archive      = {J_PR},
  author       = {Fengqin Wang and Hengjin Ke and Hongyin Ma and Yunbo Tang},
  doi          = {10.1016/j.patcog.2025.111543},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111543},
  shortjournal = {Pattern Recognition},
  title        = {Deep wavelet temporal-frequency attention for nonlinear fMRI factorization in ASD},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust trajectory forecasting in autonomous systems using
mixtures of student’s t-distributions with t-DistNet. <em>PR</em>,
<em>165</em>, 111524. (<a
href="https://doi.org/10.1016/j.patcog.2025.111524">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of predicting future trajectories of agents in complex traffic scenes, emphasizing the need for reliable predictions that are robust to various sources of uncertainty. Current methods for trajectory prediction often overlook the uncertainty aspect, although typically relying on deep neural networks (DNNs) trained to predict mixtures of Gaussian and Laplace distributions. In our study, we evaluate the significance of distribution choice for achieving reliable and robust predictions in uncertain environments and introduce T-DistNet, which employs a mixture of Student’s T-distributions for superior uncertainty modeling. This approach enables more accurate performance in scenarios with varying levels of uncertainty compared to other mixed distributions. Our analysis demonstrates that T-DistNet effectively models uncertainty, facilitating efficient and precise predictions.},
  archive      = {J_PR},
  author       = {Adrien Lafage and Gianni Franchi and Mathieu Barbier and David Filliat},
  doi          = {10.1016/j.patcog.2025.111524},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111524},
  shortjournal = {Pattern Recognition},
  title        = {Robust trajectory forecasting in autonomous systems using mixtures of student’s T-distributions with T-DistNet},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D microvascular reconstruction in retinal OCT angiography
images via domain-adaptive learning. <em>PR</em>, <em>165</em>, 111494.
(<a href="https://doi.org/10.1016/j.patcog.2025.111494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical Coherence Tomography Angiography (OCTA) is a non-invasive imaging technique that enables the acquisition of 3D depth-resolved information with micrometer resolution, facilitating the diagnosis of various eye-related diseases. In OCTA-based image analysis, 2D en face projected images are commonly used for quantifying microvascular changes, while the 3D images with rich depth information remains largely unexplored. This is mainly due to that direct 3D vessel reconstruction faces several challenges, including projection artifacts, complex vessel topology, and high computational cost. These limitations hinder comprehensive microvascular analysis and may obscure potentially vital 3D vessel biomarkers. In this study, we propose a novel method for 3D reconstruction of retinal microvasculature using 2D en face images. Our approach capitalizes on a elaborately generated 2D OCTA depth map for vessel reconstruction, thus eliminating the need for unavailable 3D volumetric data in certain retinal imaging devices. More specifically, we first build a structure-guided depth prediction network which incorporates a domain adaptation module to evaluate the depth maps obtained from different OCTA imaging devices. A point-cloud-to-surface reconstruction method is then utilized to reconstruct the corresponding 3D retinal vessels, based on the predicted depth maps and 2D vascular information. Experimental results demonstrate the superior performance of our method in comparison to existing state-of-the-art techniques. Furthermore, we extract 3D vessel-related features to assess disease correlation and classification, effectively evaluating the potential of our method for guiding subsequent clinical analysis. The results show promise of exploring 3D microvascular analysis for early diagnosis of various eye-related diseases.},
  archive      = {J_PR},
  author       = {Jiong Zhang and Shuai Yu and Yonghuai Liu and Dan Zhang and Jianyang Xie and Tao Chen and Yalin Zheng and Huazhu Fu and Yitian Zhao},
  doi          = {10.1016/j.patcog.2025.111494},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111494},
  shortjournal = {Pattern Recognition},
  title        = {3D microvascular reconstruction in retinal OCT angiography images via domain-adaptive learning},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual and uncertainty-aware approach for multi-person
pose estimation. <em>PR</em>, <em>165</em>, 111454. (<a
href="https://doi.org/10.1016/j.patcog.2025.111454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating human poses for multiple individuals in an image presents a significant challenge due to the requirement of identifying key body points for each person concurrently. Traditional methods struggle with occlusion, scale, and accuracy issues in 2D coordinate and heatmap-based approaches. Also, many approaches focus on single-person detection, which is impractical in real-world scenarios. Furthermore, traditional deep neural networks for pose estimation often neglect modeling the uncertainty associated with predicted poses. They often require additional parameters to estimate pose variance, increasing computational complexity and training challenges. This research addresses these challenges in multi-person pose estimation by proposing a novel approach, the Context-aware Bayesian Lightweight Capsule Network (CBLCapsNet). The key contributions of this work encompass the introduction of a highly effective cascaded Context Integration Block (CIB), allowing the acquisition of analyzing relative location and feature data to reconstruct the human body and challenging keypoints. Capsule blocks enhance spatial relationship capture between body parts, leading to more structured and hierarchical representations and improved accuracy in the proposed CBLCapsNet approach. A novel method is presented for estimating predictive uncertainty in 2D pose predictions directly from images, without introducing additional variability in the final layer. This method decomposes uncertainty into aleatoric and epistemic components, enhancing accuracy. Comprehensive experiments conducted on both COCO and MPII datasets confirm that the proposed approach enhances the performance of bottom-up pose estimation methods.},
  archive      = {J_PR},
  author       = {Pham Thanh Huu and Nguyen Thai An and Nguyen Ngoc Trung},
  doi          = {10.1016/j.patcog.2025.111454},
  journal      = {Pattern Recognition},
  month        = {9},
  pages        = {111454},
  shortjournal = {Pattern Recognition},
  title        = {Contextual and uncertainty-aware approach for multi-person pose estimation},
  volume       = {165},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ras---4">RAS - 4</h2>
<ul>
<li><details>
<summary>
(2025). Neural network-based intelligent perception guaranteed
performance control for mechanical arm. <em>RAS</em>, <em>190</em>,
104991. (<a href="https://doi.org/10.1016/j.robot.2025.104991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We concern with the intelligent perception control of a mechanical arm dynamic system with unknown initial state values, parameter perturbations, and external disturbances. Unlike existing prescribed performance control (PPC) methodologies which fail to preset convergence time via parameter setting, we propose a new type of PPC with predefined convergence time to impose prescribed behaviors on angle tracking errors. To accomplish such aim, we firstly define a predefined time stability criterion with an upper bound of convergence time that can be set in advance, and then we further convert the actual tracking error variable into a new variable with an initial value of zero by utilizing the error conversion function. Furthermore, a boundary amplitude intelligent extension algorithm is designed based on tracking error for performance constraint function (PCF), and meanwhile the radial basis function neural network (RBFNN) is adopted to approximate the mechanical arm system model. On this basis, a new PPC approach guaranteeing predefined convergence time is addressed for the mechanical arm system. Finally, the obtained simulation results reveal that the angle tracking error always evolves inside the extended boundary of the PCF, to satisfy better prescribed transient and steady-state properties in comparison with existing technics.},
  archive      = {J_RAS},
  author       = {Chunwu Yin and Pei Yi and Xiangwei Bu},
  doi          = {10.1016/j.robot.2025.104991},
  journal      = {Robotics and Autonomous Systems},
  month        = {8},
  pages        = {104991},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Neural network-based intelligent perception guaranteed performance control for mechanical arm},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-folding gravity compensation mechanism for a
supplementary folding robot arm: Design, analysis and implementation.
<em>RAS</em>, <em>190</em>, 104984. (<a
href="https://doi.org/10.1016/j.robot.2025.104984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a self-folding gravity compensation mechanism (SF-GCM) for supplementary folding robot arms to assist the worker. The foldable mechanism of SF-GCM consists of multiple links, torsional springs, pulleys, and cables to counter the moment due to the arm&#39;s weight and payload. The SF-GCM mechanism can fold and unfold according to the arm length and remotely provide a significant gravity compensation force. The design parameters of the robot arm are formulated, and a model of the equivalent stiffness model is proposed and analyzed. Analyzing the model was helpful to calculate the approximate stiffness values for designing the customized self-folding gravity compensation mechanism for foldable robots. A prototype of the SF-GCM mechanism was developed and its performance was evaluated experimentally for the payloads of 0.1 kg and 0.5 kg. It turns out that SF-GCM could compensate for the end-effector payload during arm extension and contraction.},
  archive      = {J_RAS},
  author       = {Bhivraj Suthar and Mohammad Zubair and Seul Jung},
  doi          = {10.1016/j.robot.2025.104984},
  journal      = {Robotics and Autonomous Systems},
  month        = {8},
  pages        = {104984},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Self-folding gravity compensation mechanism for a supplementary folding robot arm: Design, analysis and implementation},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Imitation learning-based direct visual servoing using the
large projection formulation. <em>RAS</em>, <em>190</em>, 104971. (<a
href="https://doi.org/10.1016/j.robot.2025.104971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today robots must be safe, versatile, and user-friendly to operate in unstructured and human-populated environments. Dynamical system-based imitation learning enables robots to perform complex tasks stably and without explicit programming, greatly simplifying their real-world deployment. To exploit the full potential of these systems it is crucial to implement closed loops that use visual feedback. Vision permits to cope with environmental changes, but is complex to handle due to the high dimension of the image space. This study introduces a dynamical system-based imitation learning for direct visual servoing. It leverages off-the-shelf deep learning-based perception modules to extract robust features from the raw input image, and an imitation learning strategy to execute sophisticated robot motions. The learning blocks are integrated using the large projection task priority formulation. As demonstrated through extensive experimental analysis, the proposed method realizes complex tasks with a robotic manipulator.},
  archive      = {J_RAS},
  author       = {Sayantan Auddy and Antonio Paolillo and Justus Piater and Matteo Saveriano},
  doi          = {10.1016/j.robot.2025.104971},
  journal      = {Robotics and Autonomous Systems},
  month        = {8},
  pages        = {104971},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Imitation learning-based direct visual servoing using the large projection formulation},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards a robotic intrusion prevention system: Combining
security and safety in cognitive social robots. <em>RAS</em>,
<em>190</em>, 104959. (<a
href="https://doi.org/10.1016/j.robot.2025.104959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social Robots need to be safe and reliable to share their space with humans. This paper reports on the first results of a research project that aims to create more safe and reliable, intelligent autonomous robots by investigating the implications and interactions between cybersecurity and safety. We propose creating a robotic intrusion prevention system (RIPS) that follows a novel approach to detect and mitigate intrusions in cognitive social robot systems and other cyber–physical systems. The RIPS detects threats at the robotic communication level and enables mitigation of the cyber–physical threats by using System Modes to define what part of the robotic system reduces or limits its functionality while the system is compromised. We demonstrate the validity of our approach by applying it to a cognitive architecture running in a real social robot that preserves the privacy and safety of humans while facing several cyber attack situations.},
  archive      = {J_RAS},
  author       = {Francisco Martín and Enrique Soriano-Salvador and José Miguel Guerrero and Gorka Guardiola Múzquiz and Juan Carlos Manzanares and Francisco J. Rodríguez},
  doi          = {10.1016/j.robot.2025.104959},
  journal      = {Robotics and Autonomous Systems},
  month        = {8},
  pages        = {104959},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Towards a robotic intrusion prevention system: Combining security and safety in cognitive social robots},
  volume       = {190},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="spa---4">SPA - 4</h2>
<ul>
<li><details>
<summary>
(2025). A definition of self-adjoint operators derived from the
schrödinger operator with the white noise potential on the plane.
<em>SPA</em>, <em>186</em>, 104642. (<a
href="https://doi.org/10.1016/j.spa.2025.104642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the white noise ξ on R 2 , an operator corresponding to a limit of − Δ + ξ ɛ + c ɛ as ɛ → 0 is realized as a self-adjoint operator, where, for each ɛ &gt; 0 , c ɛ is a constant, ξ ɛ is a smooth approximation of ξ defined by exp ( ɛ 2 Δ ) ξ , and Δ is the Laplacian. This result is a variant of results obtained by Allez and Chouk, Mouzard, and Ugurcan. The proof in this paper is based on the heat semigroup approach of the paracontrolled calculus, referring the proof by Mouzard. For the obtained operator, the spectral set is shown to be R .},
  archive      = {J_SPA},
  author       = {Naomasa Ueki},
  doi          = {10.1016/j.spa.2025.104642},
  journal      = {Stochastic Processes and Their Applications},
  month        = {8},
  pages        = {104642},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {A definition of self-adjoint operators derived from the schrödinger operator with the white noise potential on the plane},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limit theorems for high-dimensional betti numbers in the
multiparameter random simplicial complexes. <em>SPA</em>, <em>186</em>,
104641. (<a href="https://doi.org/10.1016/j.spa.2025.104641">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the multiparameter random simplicial complex on a vertex set { 1 , … , n } , which is parameterized by multiple connectivity probabilities. Our key results concern the topology of this complex of dimensions higher than the critical dimension. We show that the higher-dimensional Betti numbers satisfy strong laws of large numbers and central limit theorems. Moreover, lower tail large deviations for these Betti numbers are also discussed. Some of our results indicate an occurrence of phase transitions in terms of the scaling constants of the central limit theorem, and the exponentially decaying rate of convergence of lower tail large deviation probabilities.},
  archive      = {J_SPA},
  author       = {Takashi Owada and Gennady Samorodnitsky},
  doi          = {10.1016/j.spa.2025.104641},
  journal      = {Stochastic Processes and Their Applications},
  month        = {8},
  pages        = {104641},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Limit theorems for high-dimensional betti numbers in the multiparameter random simplicial complexes},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large deviations for empirical measures of self-interacting
markov chains. <em>SPA</em>, <em>186</em>, 104640. (<a
href="https://doi.org/10.1016/j.spa.2025.104640">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let Δ o be a finite set and, for each probability measure m on Δ o , let G ( m ) be a transition kernel on Δ o . Consider the sequence { X n } of Δ o -valued random variables such that, given X 0 , … , X n , the conditional distribution of X n + 1 is G ( L n + 1 ) ( X n , ⋅ ) , where L n + 1 = 1 n + 1 ∑ i = 0 n δ X i . Under conditions on G we establish a large deviation principle for the sequence { L n } . As one application of this result we obtain large deviation asymptotics for the Aldous et al. (1988) approximation scheme for quasi-stationary distributions of finite state Markov chains. The conditions on G cover other models as well, including certain models with edge or vertex reinforcement.},
  archive      = {J_SPA},
  author       = {Amarjit Budhiraja and Adam Waterbury and Pavlos Zoubouloglou},
  doi          = {10.1016/j.spa.2025.104640},
  journal      = {Stochastic Processes and Their Applications},
  month        = {8},
  pages        = {104640},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Large deviations for empirical measures of self-interacting markov chains},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harmonizable multifractional stable field: Sharp results on
sample path behavior. <em>SPA</em>, <em>186</em>, 104638. (<a
href="https://doi.org/10.1016/j.spa.2025.104638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For about three decades now, there is an increasing interest in study of multifractional processes/fields. The paradigmatic example of them is Multifractional Brownian Field (MBF) over R N , which is a Gaussian generalization with varying Hurst parameter (the Hurst function) of the well-known Fractional Brownian Motion (FBM). Harmonizable Multifractional Stable Field (HMSF) is a very natural (and maybe the most natural) extension of MBF to the framework of heavy-tailed Symmetric α -Stable (S α S) distributions. Many methods related with Gaussian fields fail to work in such a non-Gaussian framework, this is what makes study of HMSF to be difficult. In our article we construct wavelet type random series representations for the S α S stochastic field generating HMSF and for related fields. Then, under weakened versions of the usual Hölder condition on the Hurst function, we obtain sharp results on sample path behavior of HMSF: optimal global and pointwise moduli of continuity, quasi-optimal pointwise modulus of continuity on a universal event of probability 1 not depending on the location, and an estimate of the behavior at infinity which is optimal when the Hurst function has a limit at infinity to which it converges at a logarithmic rate.},
  archive      = {J_SPA},
  author       = {Antoine Ayache and Christophe Louckx},
  doi          = {10.1016/j.spa.2025.104638},
  journal      = {Stochastic Processes and Their Applications},
  month        = {8},
  pages        = {104638},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Harmonizable multifractional stable field: Sharp results on sample path behavior},
  volume       = {186},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="swevo---9">SWEVO - 9</h2>
<ul>
<li><details>
<summary>
(2025). OS-BiTP: Objective sorting-informed bidomain-information
transfer prediction for dynamic multiobjective optimization.
<em>SWEVO</em>, <em>95</em>, 101918. (<a
href="https://doi.org/10.1016/j.swevo.2025.101918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction response mechanisms based on transfer learning are extensively prevalent in dynamic multiobjective optimization algorithms (DMOAs), which transform historical information into a new environment for tracking the Pareto set (PS) or front (PF). However, many existing methods learn information of overall changes from old to new populations for prediction. Due to the different characteristics of individual variation within the population, this inevitably causes the valid information of more relevant individuals to be partially weakened during the training process, thus reducing transfer prediction-based accuracy. Therefore, this paper proposes an objective sorting-informed bidomain-information transfer prediction (OS-BiTP) for the DMOA based on individual objective variation, with the aim of transferring individuals within the same characteristics. The three core components in OS-BiTP are variation-based objective sorting (VOS), bidomain-information transfer within objective space (BiTOS), and bidomain-information transfer within decision space (BiTDS). Specifically, VOS divides the current PF into high- and low-objective variation classes and designs a modified linear prediction mechanism to forecast new environmental objective vectors. Afterward, VOS trains an easy transfer learning model to match old and new environmental individuals with the same objective variation classes to increase the transfer efficiency of individuals. To accurately track dynamic PFs and PSs, BiTOS and BiTDS perform intraclass correlation alignment for the same class of objective vectors and nondominated solutions and fine-tune the predicted objective vectors and solutions based on their variation differences. The numerical results demonstrate the superior performance and application of OS-BiTP via a systematic comparison with seven state-of-the-art DMOAs.},
  archive      = {J_SWEVO},
  author       = {Shijie Zhao and Tianran Zhang and Lei Zhang and Jinling Song},
  doi          = {10.1016/j.swevo.2025.101918},
  journal      = {Swarm and Evolutionary Computation},
  month        = {6},
  pages        = {101918},
  shortjournal = {Swarm Evol. Comput.},
  title        = {OS-BiTP: Objective sorting-informed bidomain-information transfer prediction for dynamic multiobjective optimization},
  volume       = {95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing MapReduce efficiency and reducing complexity with
enhanced particle swarm optimization (MR-MPSO). <em>SWEVO</em>,
<em>95</em>, 101917. (<a
href="https://doi.org/10.1016/j.swevo.2025.101917">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data&#39;s explosive growth poses serious data management difficulties, especially given the data&#39;s unequal distribution across massive databases. Because of this mismatch, traditional software systems are less effective, which leads to complex and wasteful data processing. We provide MapReduce-Modified Particle Swarm Optimization (MR-MPSO), a unique optimization technique, to tackle this problem. This strategy not only improves the administration of enormous datasets but also tackles the complexity issue of data imbalance. The MR framework is used to handle large-scale data processing tasks, with MR-MPSO driving the map and reducing functions. Our technique combines adaptive inertia weight with Particle Swarm Optimization (PSO) to improve the accuracy and efficiency of optimization for 10 unimodal and multimodal benchmark functions. MR-MPSO outperforms four optimization algorithms—MR K-means, MR bat, MR whale, and regular MR-on measures such as fitness value mean, median, and standard deviation. Furthermore, MR-MPSO regularly enhances throughput and average I/O rate, especially in complex write operations, with gains ranging from 1.4 % to 28.9 % in throughput and 2.1 % to 17.7 % in I/O rate over typical MR approaches.},
  archive      = {J_SWEVO},
  author       = {Chander Diwaker and Vijay Hasanpuri and Yonis Gulzar and Bhanu Sharma},
  doi          = {10.1016/j.swevo.2025.101917},
  journal      = {Swarm and Evolutionary Computation},
  month        = {6},
  pages        = {101917},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Optimizing MapReduce efficiency and reducing complexity with enhanced particle swarm optimization (MR-MPSO)},
  volume       = {95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A single-objective sequential search assistance-based
multi-objective algorithm framework. <em>SWEVO</em>, <em>95</em>,
101916. (<a href="https://doi.org/10.1016/j.swevo.2025.101916">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-objective optimization has garnered significant attention from researchers. Evolutionary algorithms are proven to be highly effective in solving complex optimization problems in plenty of cases. However, in the pursuit of improved performance, the focus on generality and efficiency has gradually been sidelined. To address this problem, this paper proposes a generalized framework, called Single-objective Sequential Search Assistance-based Multi-objective Algorithm Framework (SSMAF), to enhance the efficiency of existing multi-objective algorithms while reducing computational costs. The framework comprises two phases. The first phase involves two mechanisms to expedite the convergence of the population: (1) A Sequential Search Mechanism (SSM) is utilized to sequentially search corner solutions to enhance the quality of final population, which includes a corner solution search step and a standard solution detection step to search the Pareto Front (PF) while avoiding obtaining unexpected solutions; (2) A Diversity Search Method (DSM) is designed to conduct reinforced searches within localized regions and assess the population’s crowding degree to prevent it from getting stuck in local optima. After obtaining a population with better distribution, the existing multi-objective algorithms can regard it as the initial population to further search the PF. In the experiments, SSMAF is compared with 13 existing algorithms on 42 widely used benchmark test problems and 4 real-world problems. The experimental results show that SSMAF simultaneously improves the solution quality of existing algorithms while reducing their computational complexity.},
  archive      = {J_SWEVO},
  author       = {Peng Chen and Jing Liang and Kangjia Qiao and Xuanxuan Ban and P.N. Suganthan and Hongyu Lin and Jilong Zhang},
  doi          = {10.1016/j.swevo.2025.101916},
  journal      = {Swarm and Evolutionary Computation},
  month        = {6},
  pages        = {101916},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A single-objective sequential search assistance-based multi-objective algorithm framework},
  volume       = {95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Particle swarm optimization algorithm based on comprehensive
scoring framework for high-dimensional feature selection.
<em>SWEVO</em>, <em>95</em>, 101915. (<a
href="https://doi.org/10.1016/j.swevo.2025.101915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) plays an important role in data preprocessing. However, with the ever-increasing dimensionality of the dataset, most FS methods based on evolutionary computational (EC) face the challenge of “the dimensionality curse”. To address this challenge, we propose an new particle swarm optimization algorithm based on comprehensive scoring framework (PSO-CSM) for high-dimensional feature selection. First, a piecewise initialization strategy based on feature importance is used to initialize the population, which can help to obtain a diversity population and eliminate some redundant features. Then, a comprehensive scoring mechanism is proposed for screening important features. In this mechanism, a scaling adjustment factor is set to adjust the size of the feature space automatically. As the population continues to evolve, its feature space is further reduced so as to focus on the more promising area. Finally, a general comprehensive scoring framework (CSM) is designed to improve the performance of EC methods in FS task. The proposed PSO-CSM is compared with 10 representative FS algorithms on 18 datasets. The experimental results show that PSO-CSM is highly competitive in solving high-dimensional FS problems.},
  archive      = {J_SWEVO},
  author       = {Bo Wei and Shanshan Yang and Wentao Zha and Li Deng and Jiangyi Huang and Xiaohui Su and Feng Wang},
  doi          = {10.1016/j.swevo.2025.101915},
  journal      = {Swarm and Evolutionary Computation},
  month        = {6},
  pages        = {101915},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Particle swarm optimization algorithm based on comprehensive scoring framework for high-dimensional feature selection},
  volume       = {95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Swarm-intelligence-based value iteration for optimal
regulation of continuous-time nonlinear systems. <em>SWEVO</em>,
<em>95</em>, 101913. (<a
href="https://doi.org/10.1016/j.swevo.2025.101913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a swarm-intelligence-based value iteration (VI) algorithm is constructed to resolve the optimal control issue for continuous-time (CT) nonlinear systems. By leveraging the evolutionary concept of particle swarm optimization (PSO), the challenge of gradient vanishing is effectively overcome compared to traditional adaptive dynamic programming (ADP). Specifically, a PSO-based action network is implemented to perform policy improvement, eliminating the reliance on gradient information. Furthermore, within the ADP framework, the swarm-intelligence-based VI algorithm for CT systems is developed to address the challenges associated with constraints of initial admissible conditions and the difficulty of selecting probing signals in the traditional policy iteration method. The theoretical analysis is provided to show the convergence of the developed VI algorithm and the stability of the closed-loop system, respectively. Finally, under affine and non-affine backgrounds, two simulations are conducted to demonstrate the effectiveness and optimality of the established swarm-intelligence-based VI scheme for CT systems.},
  archive      = {J_SWEVO},
  author       = {Ding Wang and Qinna Hu and Ao Liu and Junfei Qiao},
  doi          = {10.1016/j.swevo.2025.101913},
  journal      = {Swarm and Evolutionary Computation},
  month        = {6},
  pages        = {101913},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Swarm-intelligence-based value iteration for optimal regulation of continuous-time nonlinear systems},
  volume       = {95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition-based dual-population evolutionary algorithm
for constrained multi-objective problem. <em>SWEVO</em>, <em>95</em>,
101912. (<a href="https://doi.org/10.1016/j.swevo.2025.101912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems require optimizing and solving multiple objectives while satisfying the constraints. However, in the process of solving this problem, some constraints created infeasible obstacle regions, which led to the neglect of a portion of the constrained Pareto front (CPF). In order to solve this problem, A novel decomposition-based dual-population constrained multi-objective evolutionary algorithm (DD-CMOEA) is proposed. DD-CMOEA adopts a dual population collaborative search strategy, which can quickly find CPF. In the first stage, DD-CMOEA conducts dual population searches on CPF and unconstrained Pareto front (UPF) separately. During the search process, sub-population A uses unconstrained global exploration to obtain information that helps sub-population B jump through infeasible obstacle areas. In the second stage, when the convergence of the sub-population searching for UPF stagnates, the angle-based constraint advantage principle is used for reverse search. It ensures that the searched CPF solution set can be evenly distributed throughout the entire search space. The experimental results on three standard benchmark function suites show that DD-CMOEA outperforms the other six state-of-the-art algorithms in solving constrained multi-objective optimization problems.},
  archive      = {J_SWEVO},
  author       = {Yufeng Wang and Yong Zhang and Chunyu Xu and Wen Bai and Ke Zheng and Wenyong Dong},
  doi          = {10.1016/j.swevo.2025.101912},
  journal      = {Swarm and Evolutionary Computation},
  month        = {6},
  pages        = {101912},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Decomposition-based dual-population evolutionary algorithm for constrained multi-objective problem},
  volume       = {95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cooperative discrete artificial bee colony algorithm with
q-learning for solving the distributed permutation flowshop group
scheduling problem with preventive maintenance. <em>SWEVO</em>,
<em>95</em>, 101910. (<a
href="https://doi.org/10.1016/j.swevo.2025.101910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of manufacturing technology, the multi-factory production considering group-based job processing and machine maintenance is being given increased focus, due to its potential for enhancing cost efficiency and productivity. Group constraints and machine maintenance play a critical role in modern manufacturing by reducing machine downtime, balancing production loads, and extending equipment lifespan. This paper studies the distributed permutation flowshop group scheduling problem with preventive maintenance (DPFGSP/PM) by proposing a cooperative discrete artificial bee colony (CDABC) algorithm, which is based on cooperative strategy, with the objective of minimizing the total flow time (TFT). A novel heuristic based on the group scheduling principles and TFT optimization is introduced in the initialization phase. In the evolutionary phase, the decomposition strategy and the Q-learning strategy are applied to evolve the populations of jobs and groups. Subsequently, these populations are merged to construct the complete solution, and the evaluation criterion is used to determine whether to expand the solution space. Extensive computational experiments and comparisons with state-of-the-art algorithms demonstrate that the proposed CDABC algorithm is an effective solution for DPFGSP/PM.},
  archive      = {J_SWEVO},
  author       = {Wan-Zhong Wu and Hong-Yan Sang and Quan Ke Pan and Qiu-Yang Han and Heng-Wei Guo},
  doi          = {10.1016/j.swevo.2025.101910},
  journal      = {Swarm and Evolutionary Computation},
  month        = {6},
  pages        = {101910},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A cooperative discrete artificial bee colony algorithm with Q-learning for solving the distributed permutation flowshop group scheduling problem with preventive maintenance},
  volume       = {95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parrot optimization algorithm for improved multi-strategy
fusion for feature optimization of data in medical and industrial field.
<em>SWEVO</em>, <em>95</em>, 101908. (<a
href="https://doi.org/10.1016/j.swevo.2025.101908">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is crucial in machine learning, data mining and pattern recognition, aiming at refining data features and improving model performance. Data features in the medical-industrial field are numerous and often contain redundant and irrelevant information, which affects model efficiency and generalization ability. Given that the superior performance of meta-heuristic algorithms in dealing with complex constrained problems has been demonstrated and many researchers have used them for feature selection to process data with better results than traditional methods, this study innovatively proposes an improved Multi-Strategy Fused Parrot Optimization Algorithm (MIPO) to optimize the feature selection process targeting the medical-industrial data. MIPO incorporates four core mechanisms: first, balanced and optimized foraging behavior to pinpoint key features; second, lens imaging reverse dwell behavior to strengthen local search; third, vertical and horizontal cross-communication behavior to promote population co-evolution; and fourth, memory behavior to intelligently guide the search direction. In addition, the pacifying behavior strategy is introduced to enhance the stability and robustness of the algorithm in complex space. To fully validate MIPO, this paper designs exhaustive experiments, including ablation experiments, experiments comparing with mainstream algorithms and comparisons with other feature selection methods, to demonstrate its superior performance in multiple dimensions. Based on the S/V transfer function, nine binary variants are constructed to cope with the challenge of diverse feature selection. The experimental results show that MIPO and its variants exhibit efficient, general and strong generalization capabilities on 23 medical-industrial datasets. Further, by combining KNN, SVM, and RF classifiers, MIPO significantly improves the model accuracy, with average improvement rates of 55.38%, 35.53%, and 49.59%, respectively, compared with the original parrot algorithm, and the optimal variant also performs well on all types of classifiers, with average improvement rates of 53.91%, 34.38%, and 49.94% for the optimal variant, proving the wide applicability of MIPO. In this study, the adaptability of MIPO and classifiers is deeply explored to provide scientific guidance and practical suggestions for practical applications, which not only promotes the technological progress in the field of feature selection, but also provides a powerful tool for data processing and analysis in the field of medical and industrial.},
  archive      = {J_SWEVO},
  author       = {Gaoxia Huang and Jianan Wei and Yage Yuan and Haisong Huang and Hualin Chen},
  doi          = {10.1016/j.swevo.2025.101908},
  journal      = {Swarm and Evolutionary Computation},
  month        = {6},
  pages        = {101908},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Parrot optimization algorithm for improved multi-strategy fusion for feature optimization of data in medical and industrial field},
  volume       = {95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient history-guided surrogate models-assisted
niching evolutionary algorithm for expensive multimodal optimization.
<em>SWEVO</em>, <em>95</em>, 101906. (<a
href="https://doi.org/10.1016/j.swevo.2025.101906">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work addresses the challenge of multimodal optimization, aiming to identify multiple optimal solutions in costly and time-consuming evaluation scenarios, known as expensive multimodal optimization problems (EMMOPs). Existing methods that adopt surrogate models to approximate costly evaluations with challenges, such as high costs of constructing training sets, inaccurate optima detection, and difficulties balancing exploration and exploitation in multimodal landscapes. To address these issues, we propose an efficient Binary Space Partitioning (BSP)-based surrogate models (SMs)-assisted niching evolutionary algorithm (NEA), termed BSP-SMs-NEA. The BSP tree provides a structured method for storing and retrieving historical information, enabling efficient construction of training sets for SMs. The SMs are then adaptively constructed and updated across niches to maintain high accuracy. Furthermore, BSP-SMs assist the NEA in selective evolution, optimizing resource utilization while balancing exploration and exploitation. Compared with 11 existing methods on EMMOP benchmark, BSP-SMs-NEA demonstrates superior performance, achieving the best precision on 80% of test functions, along with the top success rate and statistical results of the best fitness value across all test functions.},
  archive      = {J_SWEVO},
  author       = {Ting Huang and Bing-Bing Niu and Yue-Jiao Gong and Jing Liu},
  doi          = {10.1016/j.swevo.2025.101906},
  journal      = {Swarm and Evolutionary Computation},
  month        = {6},
  pages        = {101906},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An efficient history-guided surrogate models-assisted niching evolutionary algorithm for expensive multimodal optimization},
  volume       = {95},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="tcs---10">TCS - 10</h2>
<ul>
<li><details>
<summary>
(2025). Convex language semantics for nondeterministic probabilistic
automata. <em>TCS</em>, <em>1040</em>, 115191. (<a
href="https://doi.org/10.1016/j.tcs.2025.115191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore language semantics for automata combining probabilistic and nondeterministic behaviors. We first show that there are precisely two natural semantics for probabilistic automata with nondeterminism. For both choices, we show that these automata are strictly more expressive than deterministic probabilistic automata, and we prove that the problem of checking language equivalence is undecidable by reduction from the threshold problem. However, we provide a discounted metric that can be computed to arbitrarily high precision.},
  archive      = {J_TCS},
  author       = {Gerco van Heerdt and Justin Hsu and Joël Ouaknine and Alexandra Silva},
  doi          = {10.1016/j.tcs.2025.115191},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115191},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Convex language semantics for nondeterministic probabilistic automata},
  volume       = {1040},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient diagonalization of symmetric matrices associated
with graphs of small treewidth. <em>TCS</em>, <em>1040</em>, 115187. (<a
href="https://doi.org/10.1016/j.tcs.2025.115187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let M = ( m i j ) be a symmetric matrix of order n whose elements lie in an arbitrary field F , and let G be the graph with vertex set { 1 , … , n } such that distinct vertices i and j are adjacent if and only if m i j ≠ 0 . We introduce a dynamic programming algorithm that finds a diagonal matrix that is congruent to M . If G is given with a tree decomposition T of width k , then this can be done in time O ( k | T | + k 2 n ) , where | T | denotes the number of nodes in T . Among other things, this allows the computation of the determinant, the rank and the inertia of a symmetric matrix in time O ( k | T | + k 2 n ) .},
  archive      = {J_TCS},
  author       = {Martin Fürer and Carlos Hoppen and Vilmar Trevisan},
  doi          = {10.1016/j.tcs.2025.115187},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115187},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Efficient diagonalization of symmetric matrices associated with graphs of small treewidth},
  volume       = {1040},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TCS special issue on selected papers from AlgoWin 2023.
<em>TCS</em>, <em>1040</em>, 115183. (<a
href="https://doi.org/10.1016/j.tcs.2025.115183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TCS},
  author       = {Konstantinos Georgiou and Evangelos Kranakis},
  doi          = {10.1016/j.tcs.2025.115183},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115183},
  shortjournal = {Theor. Comput. Sci.},
  title        = {TCS special issue on selected papers from AlgoWin 2023},
  volume       = {1040},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theory of fine-grained lineage for functions on structured
objects. <em>TCS</em>, <em>1039</em>, 115192. (<a
href="https://doi.org/10.1016/j.tcs.2025.115192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lineage is the process of keeping track of the relationship between the inputs of a data processing task and the parts of the output they contribute to produce. Depending on its precise definition, lineage can be seen as a form of database provenance, a means of tracking information flow in computer programs, or be used to express causality and provide counter-examples for the falsity of a logical statement. In this paper, we establish the formal foundations of a notion of lineage for arbitrary abstract functions manipulating objects that are “composite” –that is, can be made of multiple other objects. Three definitions of lineage over functions are formally defined, respectively called explanation, participation and extraction; we then establish explanation relationships for a set of elementary functions, and for compositions thereof. A fully functional implementation of these concepts is finally presented and experimentally evaluated.},
  archive      = {J_TCS},
  author       = {Sylvain Hallé and Hugo Tremblay},
  doi          = {10.1016/j.tcs.2025.115192},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115192},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A theory of fine-grained lineage for functions on structured objects},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved algorithms for optimal k sink location on path
networks. <em>TCS</em>, <em>1039</em>, 115190. (<a
href="https://doi.org/10.1016/j.tcs.2025.115190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of placing k sinks on dynamic-flow path networks with n vertices so as to minimize their maximum evacuation completion time. We develop two different algorithms that, when all edges have the same capacity, run respectively in O ( n + k 2 log 2 ⁡ n ) and O ( n log ⁡ n ) time. When the edge capacities can be different, i.e., are general , they run respectively in O ( n log ⁡ n + k 2 log 4 ⁡ n ) and O ( n log 3 ⁡ n ) time. These algorithms improve upon the previously most efficient algorithms, which had time complexities O ( k n ) and O ( k n log 2 ⁡ n ) , respectively, for the uniform and general edge capacity models. The improvements are achieved by moving from a dynamic programming based approach to a parametric-search based one.},
  archive      = {J_TCS},
  author       = {Binay Bhattacharya and Mordecai J. Golin and Yuya Higashikawa and Tsunehiko Kameda and Naoki Katoh},
  doi          = {10.1016/j.tcs.2025.115190},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115190},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Improved algorithms for optimal k sink location on path networks},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The reliability of (n,k)-star network in terms of
non-inclusive fault pattern. <em>TCS</em>, <em>1039</em>, 115189. (<a
href="https://doi.org/10.1016/j.tcs.2025.115189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability assessment is of significant importance in the design maintenance and improvement of multiprocessor systems which take interconnection networks as underlying topologies. System-level diagnosis is a primary strategy to identify faulty processors by analyzing the syndrome of testing in a system. The newly proposed non-inclusive diagnosability greatly enhances the ability in evaluating the reliability of interconnection networks when comparing to the classical diagnosability. In this article, we first study the non-inclusive diagnosability and the non-inclusive 1-extra diagnosability of ( n , k ) -star network under the MM* model, respectively. Then we design a fast and adaptive non-inclusive fault identification algorithm to identify faulty nodes and fault-free nodes in the ( n , k ) -star network. Furthermore, we implement simulation experiments in terms of TNR, TPR, ACCR, FNR, FPR and F1. Simulation results demonstrate that our proposed method achieves excellent performance in fault detection and network reliability.},
  archive      = {J_TCS},
  author       = {Qigong Chen and Jiafei Liu and Chia-Wei Lee and Jingli Wu and Gaoshi Li},
  doi          = {10.1016/j.tcs.2025.115189},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115189},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The reliability of (n,k)-star network in terms of non-inclusive fault pattern},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Opinion diffusion in graphs: An adversarial approach.
<em>TCS</em>, <em>1039</em>, 115188. (<a
href="https://doi.org/10.1016/j.tcs.2025.115188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study a novel majority-based opinion diffusion model. Consider a graph G , which represents a social network. Assume that initially a subset of nodes, called seed nodes or early adopters, are colored either black or white, which correspond to positive or negative opinion regarding a consumer product or a technological innovation. Then, in each round an uncolored node, which is adjacent to at least one colored node, chooses the most frequent color among its neighbors. Consider a marketing campaign which advertises a product of poor quality and its ultimate goal is that more than half of the population believe in the quality of the product at the end of the opinion diffusion process. We focus on three types of attackers which can select the seed nodes in a deterministic or random fashion and manipulate almost half of them to adopt a positive opinion toward the product (that is, to choose black color). We say that an attacker succeeds if a majority of nodes are black at the end of the process. Our main purpose is to characterize classes of graphs where an attacker cannot succeed. In particular, we prove that if the maximum degree of the underlying graph is not too large or if it has strong expansion properties, then it is fairly resilient to such attacks. Furthermore, we prove tight bounds on the stabilization time of the process (that is, the number of rounds it needs to end) in both settings of choosing the seed nodes deterministically and randomly. We also provide several hardness results for some optimization problems regarding stabilization time and choice of seed nodes.},
  archive      = {J_TCS},
  author       = {Ahad N. Zehmakan},
  doi          = {10.1016/j.tcs.2025.115188},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115188},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Opinion diffusion in graphs: An adversarial approach},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cost-sharing games with rank-based utilities. <em>TCS</em>,
<em>1039</em>, 115186. (<a
href="https://doi.org/10.1016/j.tcs.2025.115186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies in behavioral science show that individuals are often concerned primarily about their relative welfare, rather than their absolute well-being. In this paper we define and study a variant of congestion games that reflects this phenomenon. In a cost-sharing game with rank-based utilities (CSRB-game, for short), the players are partitioned into competition sets , and the goal of every player is to minimize its cost relative to its competitors . Specifically, the primary goal of a player is to minimize the rank of its cost among its competitors, while minimizing the cost itself is a secondary objective. We show that CSRB-games are significantly different from classical cost-sharing games, and that competition may lead to a poor outcome. In particular, singleton CSRB-games need not have a pure Nash equilibrium, and even when a NE exists, natural dynamics may not converge to a NE, and the price of stability is linear in the number of players. We then analyze several natural restricted classes of singleton CSRB-games, for which we present positive results. We provide tight characterization of classes for which a NE exists and can be computed efficiently, and bound the equilibrium inefficiency, based on the competition structure, the number of players and resources, the uniformity of resources&#39; costs, and the strategy space of competing players.},
  archive      = {J_TCS},
  author       = {Shaul Rosner and Tami Tamir},
  doi          = {10.1016/j.tcs.2025.115186},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115186},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Cost-sharing games with rank-based utilities},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-stabilizing multivalued consensus in the presence of
byzantine faults and asynchrony. <em>TCS</em>, <em>1039</em>, 115184.
(<a href="https://doi.org/10.1016/j.tcs.2025.115184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus, abstracting myriad problems in which processes must agree on a single value, is one of the most celebrated problems of fault-tolerant distributed computing. Consensus applications include fundamental services for the Cloud and Blockchain environments, and in such challenging environments, malicious behaviors are often modeled as adversarial Byzantine faults. At OPODIS 2010, Mostéfaoui and Raynal (in short, MR) presented a Byzantine-tolerant solution to consensus in which the decided value cannot be proposed only by Byzantine processes. MR has optimal resilience coping with up to t &lt; n / 3 Byzantine nodes over n processes. MR provides this multivalued consensus object (which accepts proposals taken from a finite set of values), assuming the availability of a single binary consensus object (which accepts proposals taken from the set { 0 , 1 } ). This work, which focuses on multivalued consensus, aims to design an even more robust solution than MR. Our proposal expands MR&#39;s fault-model with self-stabilization, a vigorous notion of fault-tolerance. In addition to tolerating Byzantine, self-stabilizing systems can automatically recover after arbitrary transient-faults occur. These faults represent any violation of the assumptions according to which the system was designed to operate (provided that the algorithm code remains intact). To the best of our knowledge, we propose the first self-stabilizing solution for multivalued consensus for asynchronous message-passing systems prone to Byzantine failures. Our solution has an O ( t ) stabilization time from arbitrary transient faults.},
  archive      = {J_TCS},
  author       = {Romaric Duvignau and Michel Raynal and Elad Michael Schiller},
  doi          = {10.1016/j.tcs.2025.115184},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115184},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Self-stabilizing multivalued consensus in the presence of byzantine faults and asynchrony},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-shortest simple paths in bounded treewidth graphs.
<em>TCS</em>, <em>1039</em>, 115182. (<a
href="https://doi.org/10.1016/j.tcs.2025.115182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -shortest simple paths problem asks to compute a set of top- k shortest simple paths from a source to a sink in a graph G = ( V , E ) with | V | = n vertices and | E | = m edges. The most well-known algorithm for solving this problem is due to Yen (1971) with time complexity in O ( k n ( m + n log ⁡ n ) ) and the fastest algorithm is due to Gotthilf and Lewenstein (2009) with time complexity in O ( k n ( m + n log ⁡ log ⁡ n ) ) . For bounded treewidth graphs, Eppstein and Kurz (2017) lowered the computational complexity to O ( k n ) by retrieving paths from the k smallest solutions of a monadic second-order formula, and to O ( n + k log ⁡ ( n ) ) to retrieve the k shortest simple distances only. In this paper, we provide an algorithm that answers k -shortest simple distances in O ( k + n ) time on graphs with treewidth at most 2, and a constructive algorithm, simpler than that of Eppstein and Kurz, that solves the k -shortest simple paths problem in O ( k n ) time on bounded treewidth graphs.},
  archive      = {J_TCS},
  author       = {David Coudert and Andrea D&#39;Ascenzo and Clément Rambaud},
  doi          = {10.1016/j.tcs.2025.115182},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115182},
  shortjournal = {Theor. Comput. Sci.},
  title        = {K-shortest simple paths in bounded treewidth graphs},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
