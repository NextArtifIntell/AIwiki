<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CAAITIT_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="caaitit---19">CAAITIT - 19</h2>
<ul>
<li><details>
<summary>
(2025). Multi-sensor missile-borne LiDAR point cloud data
augmentation based on monte carlo distortion simulation.
<em>CAAITIT</em>, <em>10</em>(1), 300–316. (<a
href="https://doi.org/10.1049/cit2.12389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CAAITIT},
  author       = {Luda Zhao and Yihua Hu and Fei Han and Zhenglei Dou and Shanshan Li and Yan Zhang and Qilong Wu},
  doi          = {10.1049/cit2.12389},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {300-316},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Multi-sensor missile-borne LiDAR point cloud data augmentation based on monte carlo distortion simulation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extraction of typical operating scenarios of new power
system based on deep time series aggregation. <em>CAAITIT</em>,
<em>10</em>(1), 283–299. (<a
href="https://doi.org/10.1049/cit2.12369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting typical operational scenarios is essential for making flexible decisions in the dispatch of a new power system. A novel deep time series aggregation scheme (DTSAs) is proposed to generate typical operational scenarios, considering the large amount of historical operational snapshot data. Specifically, DTSAs analyse the intrinsic mechanisms of different scheduling operational scenario switching to mathematically represent typical operational scenarios. A Gramian angular summation field-based operational scenario image encoder was designed to convert operational scenario sequences into high-dimensional spaces. This enables DTSAs to fully capture the spatiotemporal characteristics of new power systems using deep feature iterative aggregation models. The encoder also facilitates the generation of typical operational scenarios that conform to historical data distributions while ensuring the integrity of grid operational snapshots. Case studies demonstrate that the proposed method extracted new fine-grained power system dispatch schemes and outperformed the latest high-dimensional feature-screening methods. In addition, experiments with different new energy access ratios were conducted to verify the robustness of the proposed method. DTSAs enable dispatchers to master the operation experience of the power system in advance, and actively respond to the dynamic changes of the operation scenarios under the high access rate of new energy.},
  archive      = {J_CAAITIT},
  author       = {Zhaoyang Qu and Zhenming Zhang and Nan Qu and Yuguang Zhou and Yang Li and Tao Jiang and Min Li and Chao Long},
  doi          = {10.1049/cit2.12369},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {283-299},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Extraction of typical operating scenarios of new power system based on deep time series aggregation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pre-trained SAM as data augmentation for image segmentation.
<em>CAAITIT</em>, <em>10</em>(1), 268–282. (<a
href="https://doi.org/10.1049/cit2.12381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation plays an important role in training deep neural model by expanding the size and diversity of the dataset. Initially, data augmentation mainly involved some simple transformations of images. Later, in order to increase the diversity and complexity of data, more advanced methods appeared and evolved to sophisticated generative models. However, these methods required a mass of computation of training or searching. In this paper, a novel training-free method that utilises the Pre-Trained Segment Anything Model (SAM) model as a data augmentation tool (PTSAM-DA) is proposed to generate the augmented annotations for images. Without the need for training, it obtains prompt boxes from the original annotations and then feeds the boxes to the pre-trained SAM to generate diverse and improved annotations. In this way, annotations are augmented more ingenious than simple manipulations without incurring huge computation for training a data augmentation model. Multiple comparative experiments on three datasets are conducted, including an in-house dataset, ADE20K and COCO2017. On this in-house dataset, namely Agricultural Plot Segmentation Dataset, maximum improvements of 3.77% and 8.92% are gained in two mainstream metrics, mIoU and mAcc, respectively. Consequently, large vision models like SAM are proven to be promising not only in image segmentation but also in data augmentation.},
  archive      = {J_CAAITIT},
  author       = {Junjun Wu and Yunbo Rao and Shaoning Zeng and Bob Zhang},
  doi          = {10.1049/cit2.12381},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {268-282},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Pre-trained SAM as data augmentation for image segmentation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WaveSeg-UNet model for overlapped nuclei segmentation from
multi-organ histopathology images. <em>CAAITIT</em>, <em>10</em>(1),
253–267. (<a href="https://doi.org/10.1049/cit2.12351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclei segmentation is a challenging task in histopathology images. It is challenging due to the small size of objects, low contrast, touching boundaries, and complex structure of nuclei. Their segmentation and counting play an important role in cancer identification and its grading. In this study, WaveSeg-UNet, a lightweight model, is introduced to segment cancerous nuclei having touching boundaries. Residual blocks are used for feature extraction. Only one feature extractor block is used in each level of the encoder and decoder. Normally, images degrade quality and lose important information during down-sampling. To overcome this loss, discrete wavelet transform (DWT) alongside max-pooling is used in the down-sampling process. Inverse DWT is used to regenerate original images during up-sampling. In the bottleneck of the proposed model, atrous spatial channel pyramid pooling (ASCPP) is used to extract effective high-level features. The ASCPP is the modified pyramid pooling having atrous layers to increase the area of the receptive field. Spatial and channel-based attention are used to focus on the location and class of the identified objects. Finally, watershed transform is used as a post processing technique to identify and refine touching boundaries of nuclei. Nuclei are identified and counted to facilitate pathologists. The same domain of transfer learning is used to retrain the model for domain adaptability. Results of the proposed model are compared with state-of-the-art models, and it outperformed the existing studies.},
  archive      = {J_CAAITIT},
  author       = {Hameed Ullah Khan and Basit Raza and Muhammad Asad Iqbal Khan and Muhammad Faheem},
  doi          = {10.1049/cit2.12351},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {253-267},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {WaveSeg-UNet model for overlapped nuclei segmentation from multi-organ histopathology images},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Terahertz image denoising via multiscale hybrid-convolution
residual network. <em>CAAITIT</em>, <em>10</em>(1), 235–252. (<a
href="https://doi.org/10.1049/cit2.12380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Terahertz imaging technology has great potential applications in areas, such as remote sensing, navigation, security checks, and so on. However, terahertz images usually have the problems of heavy noises and low resolution. Previous terahertz image denoising methods are mainly based on traditional image processing methods, which have limited denoising effects on the terahertz noise. Existing deep learning-based image denoising methods are mostly used in natural images and easily cause a large amount of detail loss when denoising terahertz images. Here, a residual-learning-based multiscale hybrid-convolution residual network (MHRNet) is proposed for terahertz image denoising, which can remove noises while preserving detail features in terahertz images. Specifically, a multiscale hybrid-convolution residual block (MHRB) is designed to extract rich detail features and local prediction residual noise from terahertz images. Specifically, MHRB is a residual structure composed of a multiscale dilated convolution block, a bottleneck layer, and a multiscale convolution block. MHRNet uses the MHRB and global residual learning to achieve terahertz image denoising. Ablation studies are performed to validate the effectiveness of MHRB. A series of experiments are conducted on the public terahertz image datasets. The experimental results demonstrate that MHRNet has an excellent denoising effect on synthetic and real noisy terahertz images. Compared with existing methods, MHRNet achieves comprehensive competitive results.},
  archive      = {J_CAAITIT},
  author       = {Heng Wu and Zijie Guo and Chunhua He and Shaojuan Luo and Bofang Song},
  doi          = {10.1049/cit2.12380},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {235-252},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Terahertz image denoising via multiscale hybrid-convolution residual network},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A criterion for selecting the appropriate one from the
trained models for model-based offline policy evaluation.
<em>CAAITIT</em>, <em>10</em>(1), 223–234. (<a
href="https://doi.org/10.1049/cit2.12376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline policy evaluation, evaluating and selecting complex policies for decision-making by only using offline datasets is important in reinforcement learning. At present, the model-based offline policy evaluation (MBOPE) is widely welcomed because of its easy to implement and good performance. MBOPE directly approximates the unknown value of a given policy using the Monte Carlo method given the estimated transition and reward functions of the environment. Usually, multiple models are trained, and then one of them is selected to be used. However, a challenge remains in selecting an appropriate model from those trained for further use. The authors first analyse the upper bound of the difference between the approximated value and the unknown true value. Theoretical results show that this difference is related to the trajectories generated by the given policy on the learnt model and the prediction error of the transition and reward functions at these generated data points. Based on the theoretical results, a new criterion is proposed to tell which trained model is better suited for evaluating the given policy. At last, the effectiveness of the proposed criterion is demonstrated on both benchmark and synthetic offline datasets.},
  archive      = {J_CAAITIT},
  author       = {Chongchong Li and Yue Wang and Zhi-Ming Ma and Yuting Liu},
  doi          = {10.1049/cit2.12376},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {223-234},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {A criterion for selecting the appropriate one from the trained models for model-based offline policy evaluation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). D2LFS2Net: Multi-class skin lesion diagnosis using deep
learning and variance-controlled marine predator optimisation: An
application for precision medicine. <em>CAAITIT</em>, <em>10</em>(1),
207–222. (<a href="https://doi.org/10.1049/cit2.12267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In computer vision applications like surveillance and remote sensing, to mention a few, deep learning has had considerable success. Medical imaging still faces a number of difficulties, including intra-class similarity, a scarcity of training data, and poor contrast skin lesions, notably in the case of skin cancer. An optimisation-aided deep learning-based system is proposed for accurate multi-class skin lesion identification. The sequential procedures of the proposed system start with preprocessing and end with categorisation. The preprocessing step is where a hybrid contrast enhancement technique is initially proposed for lesion identification with healthy regions. Instead of flipping and rotating data, the outputs from the middle phases of the hybrid enhanced technique are employed for data augmentation in the next step. Next, two pre-trained deep learning models, MobileNetV2 and NasNet Mobile, are trained using deep transfer learning on the upgraded enriched dataset. Later, a dual-threshold serial approach is employed to obtain and combine the features of both models. The next step was the variance-controlled Marine Predator methodology, which the authors proposed as a superior optimisation method. The top features from the fused feature vector are classified using machine learning classifiers. The experimental strategy provided enhanced accuracy of 94.4% using the publicly available dataset HAM10000. Additionally, the proposed framework is evaluated compared to current approaches, with remarkable results.},
  archive      = {J_CAAITIT},
  author       = {Veena Dillshad and Muhammad Attique Khan and Muhammad Nazir and Oumaima Saidani and Nazik Alturki and Seifedine Kadry},
  doi          = {10.1049/cit2.12267},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {207-222},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {D2LFS2Net: multi-class skin lesion diagnosis using deep learning and variance-controlled marine predator optimisation: an application for precision medicine},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visible and near-infrared image fusion based on information
complementarity. <em>CAAITIT</em>, <em>10</em>(1), 193–206. (<a
href="https://doi.org/10.1049/cit2.12378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images with complementary spectral information can be recorded using image sensors that can identify visible and near-infrared spectrum. The fusion of visible and near-infrared (NIR) aims to enhance the quality of images acquired by video monitoring systems for the ease of user observation and data processing. Unfortunately, current fusion algorithms produce artefacts and colour distortion since they cannot make use of spectrum properties and are lacking in information complementarity. Therefore, an information complementarity fusion (ICF) model is designed based on physical signals. In order to separate high-frequency noise from important information in distinct frequency layers, the authors first extracted texture-scale and edge-scale layers using a two-scale filter. Second, the difference map between visible and near-infrared was filtered using the extended-DoG filter to produce the initial visible-NIR complementary weight map. Then, to generate a guide map, the near-infrared image with night adjustment was processed as well. The final complementarity weight map was subsequently derived via an arctanI function mapping using the guide map and the initial weight maps. Finally, fusion images were generated with the complementarity weight maps. The experimental results demonstrate that the proposed approach outperforms the state-of-the-art in both avoiding artificial colours as well as effectively utilising information complementarity.},
  archive      = {J_CAAITIT},
  author       = {Zhuo Li and Shiliang Pu and Mengqi Ji and Feng Zeng and Bo Li},
  doi          = {10.1049/cit2.12378},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {193-206},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Visible and near-infrared image fusion based on information complementarity},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MultiJSQ: Direct joint segmentation and quantification of
left ventricle with deep multitask-derived regression network.
<em>CAAITIT</em>, <em>10</em>(1), 175–192. (<a
href="https://doi.org/10.1049/cit2.12382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantitative analysis of clinical function parameters from MRI images is crucial for diagnosing and assessing cardiovascular disease. However, the manual calculation of these parameters is challenging due to the high variability among patients and the time-consuming nature of the process. In this study, the authors introduce a framework named MultiJSQ, comprising the feature presentation network (FRN) and the indicator prediction network (IEN), which is designed for simultaneous joint segmentation and quantification. The FRN is tailored for representing global image features, facilitating the direct acquisition of left ventricle (LV) contour images through pixel classification. Additionally, the IEN incorporates specifically designed modules to extract relevant clinical indices. The authors’ method considers the interdependence of different tasks, demonstrating the validity of these relationships and yielding favourable results. Through extensive experiments on cardiac MR images from 145 patients, MultiJSQ achieves impressive outcomes, with low mean absolute errors of 124 mm 2 , 1.72 mm, and 1.21 mm for areas, dimensions, and regional wall thicknesses, respectively, along with a Dice metric score of 0.908. The experimental findings underscore the excellent performance of our framework in LV segmentation and quantification, highlighting its promising clinical application prospects.},
  archive      = {J_CAAITIT},
  author       = {Xiuquan Du and Zheng Pei and Ying Liu and Xinzhi Cao and Lei Li and Shuo Li},
  doi          = {10.1049/cit2.12382},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {175-192},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {MultiJSQ: Direct joint segmentation and quantification of left ventricle with deep multitask-derived regression network},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grey-box modelling for estimation of optimum cut point
temperature of crude distillation column. <em>CAAITIT</em>,
<em>10</em>(1), 160–174. (<a
href="https://doi.org/10.1049/cit2.12386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A grey-box modelling framework was developed for the estimation of cut point temperature of a crude distillation unit (CDU) under uncertainty in crude composition and process conditions. First principle (FP) model of CDU was developed for Pakistani crudes from Zamzama and Kunnar fields. A hybrid methodology based on the integration of Taguchi method and genetic algorithm (GA) was employed to estimate the optimal cut point temperature for various sets of process variables. Optimised datasets were utilised to develop an artificial neural networks (ANN) model for the prediction of optimum values of cut points. The ANN model was then used to replace the hybrid framework of the Taguchi method and the GA. The integration of the ANN and FP model makes it a grey-box (GB) model. For the case of Zamama crude, the GB model helped in the decrease of up to 38.93% in energy required per kilo barrel of diesel and an 8.2% increase in diesel production compared to the stand-alone FP model under uncertainty. Similarly, for Kunnar crude, up to 18.87% decrease in energy required per kilo barrel of diesel and a 33.96% increase in diesel production was observed in comparison to the stand-alone FP model.},
  archive      = {J_CAAITIT},
  author       = {Junaid Shahzad and Iftikhar Ahmad and Muhammad Ahsan and Farooq Ahmad and Husnain Saghir and Manabu Kano and Hakan Caliskan and Hiki Hong},
  doi          = {10.1049/cit2.12386},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {160-174},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Grey-box modelling for estimation of optimum cut point temperature of crude distillation column},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilingual phrase induction with local hard negative
sampling. <em>CAAITIT</em>, <em>10</em>(1), 147–159. (<a
href="https://doi.org/10.1049/cit2.12383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilingual lexicon induction focuses on learning word translation pairs, also known as bitexts, from monolingual corpora by establishing a mapping between the source and target embedding spaces. Despite recent advancements, bilingual lexicon induction is limited to inducing bitexts consisting of individual words, lacking the ability to handle semantics-rich phrases. To bridge this gap and support downstream cross-lingual tasks, it is practical to develop a method for bilingual phrase induction that extracts bilingual phrase pairs from monolingual corpora without relying on cross-lingual knowledge. In this paper, the authors propose a novel phrase embedding training method based on the skip-gram structure. Specifically, a local hard negative sampling strategy that utilises negative samples of central tokens in sliding windows to enhance phrase embedding learning is introduced. The proposed method achieves competitive or superior performance compared to baseline approaches, with exceptional results recorded for distant languages. Additionally, we develop a phrase representation learning method that leverages multilingual pre-trained language models. These mPLMs-based representations can be combined with the above-mentioned static phrase embeddings to further improve the accuracy of the bilingual phrase induction task. We manually construct a dataset of bilingual phrase pairs and integrate it with MUSE to facilitate the bilingual phrase induction task.},
  archive      = {J_CAAITIT},
  author       = {Hailong Cao and Hualin Miao and Weixuan Wang and Liangyou Li and Wei Peng and Tiejun Zhao},
  doi          = {10.1049/cit2.12383},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {147-159},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Bilingual phrase induction with local hard negative sampling},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-station multi-robot task assignment method based on
deep reinforcement learning. <em>CAAITIT</em>, <em>10</em>(1), 134–146.
(<a href="https://doi.org/10.1049/cit2.12394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of multi-station multi-robot spot welding task assignment, and proposes a deep reinforcement learning (DRL) framework, which is made up of a public graph attention network and independent policy networks. The graph of welding spots distribution is encoded using the graph attention network. Independent policy networks with attention mechanism as a decoder can handle the encoded graph and decide to assign robots to different tasks. The policy network is used to convert the large scale welding spots allocation problem to multiple small scale single-robot welding path planning problems, and the path planning problem is quickly solved through existing methods. Then, the model is trained through reinforcement learning. In addition, the task balancing method is used to allocate tasks to multiple stations. The proposed algorithm is compared with classical algorithms, and the results show that the algorithm based on DRL can produce higher quality solutions.},
  archive      = {J_CAAITIT},
  author       = {Junnan Zhang and Ke Wang and Chaoxu Mu},
  doi          = {10.1049/cit2.12394},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {134-146},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Multi-station multi-robot task assignment method based on deep reinforcement learning},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource-adaptive and OOD-robust inference of deep neural
networks on IoT devices. <em>CAAITIT</em>, <em>10</em>(1), 115–133. (<a
href="https://doi.org/10.1049/cit2.12384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently executing inference tasks of deep neural networks on devices with limited resources poses a significant load in IoT systems. To alleviate the load, one innovative method is branching that adds extra layers with classification exits to a pre-trained model, enabling inputs with high-confidence predictions to exit early, thus reducing inference cost. However, branching networks, not originally tailored for IoT environments, are susceptible to noisy and out-of-distribution (OOD) data, and they demand additional training for optimal performance. The authors introduce BrevisNet, a novel branching methodology designed for creating on-device branching models that are both resource-adaptive and noise-robust for IoT applications. The method leverages the refined uncertainty estimation capabilities of Dirichlet distributions for classification predictions, combined with the superior OOD detection of energy-based models. The authors propose a unique training approach and thresholding technique that enhances the precision of branch predictions, offering robustness against noise and OOD inputs. The findings demonstrate that BrevisNet surpasses existing branching techniques in training efficiency, accuracy, overall performance, and robustness.},
  archive      = {J_CAAITIT},
  author       = {Cailen Robertson and Ngoc Anh Tong and Thanh Toan Nguyen and Quoc Viet Hung Nguyen and Jun Jo},
  doi          = {10.1049/cit2.12384},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {115-133},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Resource-adaptive and OOD-robust inference of deep neural networks on IoT devices},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KitWaSor: Pioneering pre-trained model for kitchen waste
sorting with an innovative million-level benchmark dataset.
<em>CAAITIT</em>, <em>10</em>(1), 94–114. (<a
href="https://doi.org/10.1049/cit2.12399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent sorting is an important prerequisite for the full quantitative consumption and harmless disposal of kitchen waste. The existing object detection method based on an ImageNet pre-trained model is an effective way of sorting. Owing to significant domain gaps between natural images and kitchen waste images, it is difficult to reflect the characteristics of diverse scales and dense distribution in kitchen waste based on an ImageNet pre-trained model, leading to poor generalisation. In this article, the authors propose the first pre-trained model for kitchen waste sorting called KitWaSor, which combines both contrastive learning (CL) and masked image modelling (MIM) through self-supervised learning (SSL). First, to address the issue of diverse scales, the authors propose a mixed masking strategy by introducing an incomplete masking branch based on the original random masking branch. It prevents the complete loss of small-scale objects while avoiding excessive leakage of large-scale object pixels. Second, to address the issue of dense distribution, the authors introduce semantic consistency constraints on the basis of the mixed masking strategy. That is, object semantic reasoning is performed through semantic consistency constraints to compensate for the lack of contextual information. To train KitWaSor, the authors construct the first million-level kitchen waste dataset across seasonal and regional distributions, named KWD-Million. Extensive experiments show that KitWaSor achieves state-of-the-art (SOTA) performance on the two most relevant downstream tasks for kitchen waste sorting (i.e. image classification and object detection), demonstrating the effectiveness of the proposed KitWaSor.},
  archive      = {J_CAAITIT},
  author       = {Leyuan Fang and Shuaiyu Ding and Hao Feng and Junwu Yu and Lin Tang and Pedram Ghamisi},
  doi          = {10.1049/cit2.12399},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {94-114},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {KitWaSor: Pioneering pre-trained model for kitchen waste sorting with an innovative million-level benchmark dataset},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral image restoration using noise gradient and
dual priors under mixed noise conditions. <em>CAAITIT</em>,
<em>10</em>(1), 72–93. (<a
href="https://doi.org/10.1049/cit2.12355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images obtained from hyperspectral sensors provide information about the target area that extends beyond the visible portions of the electromagnetic spectrum. However, due to sensor limitations and imperfections during the image acquisition and transmission phases, noise is introduced into the acquired image, which can have a negative impact on downstream analyses such as classification, target tracking, and spectral unmixing. Noise in hyperspectral images (HSI) is modelled as a combination from several sources, including Gaussian/impulse noise, stripes, and deadlines. An HSI restoration method for such a mixed noise model is proposed. First , a joint optimisation framework is proposed for recovering hyperspectral data corrupted by mixed Gaussian-impulse noise by estimating both the clean data as well as the sparse/impulse noise levels. Second , a hyper-Laplacian prior is used along both the spatial and spectral dimensions to express sparsity in clean image gradients. Third , to model the sparse nature of impulse noise, an ℓ 1 − norm over the impulse noise gradient is used. Because the proposed methodology employs two distinct priors, the authors refer to it as the hyperspectral dual prior (HySpDualP) denoiser. To the best of authors&#39; knowledge, this joint optimisation framework is the first attempt in this direction. To handle the non-smooth and non-convex nature of the general ℓp − norm-based regularisation term, a generalised shrinkage/thresholding (GST) solver is employed. Finally , an efficient split-Bregman approach is used to solve the resulting optimisation problem. Experimental results on synthetic data and real HSI datacube obtained from hyperspectral sensors demonstrate that the authors’ proposed model outperforms state-of-the-art methods, both visually and in terms of various image quality assessment metrics.},
  archive      = {J_CAAITIT},
  author       = {Hazique Aetesam and Suman Kumar Maji and V. B. Surya Prasath},
  doi          = {10.1049/cit2.12355},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {72-93},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Hyperspectral image restoration using noise gradient and dual priors under mixed noise conditions},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving long-tail classification via decoupling and
regularisation. <em>CAAITIT</em>, <em>10</em>(1), 62–71. (<a
href="https://doi.org/10.1049/cit2.12374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data always exhibit an imbalanced and long-tailed distribution, which leads to poor performance for neural network-based classification. Existing methods mainly tackle this problem by reweighting the loss function or rebalancing the classifier. However, one crucial aspect overlooked by previous research studies is the imbalanced feature space problem caused by the imbalanced angle distribution. In this paper, the authors shed light on the significance of the angle distribution in achieving a balanced feature space, which is essential for improving model performance under long-tailed distributions. Nevertheless, it is challenging to effectively balance both the classifier norms and angle distribution due to problems such as the low feature norm. To tackle these challenges, the authors first thoroughly analyse the classifier and feature space by decoupling the classification logits into three key components: classifier norm (i.e. the magnitude of the classifier vector), feature norm (i.e. the magnitude of the feature vector), and cosine similarity between the classifier vector and feature vector. In this way, the authors analyse the change of each component in the training process and reveal three critical problems that should be solved, that is, the imbalanced angle distribution, the lack of feature discrimination, and the low feature norm. Drawing from this analysis, the authors propose a novel loss function that incorporates hyperspherical uniformity, additive angular margin, and feature norm regularisation. Each component of the loss function addresses a specific problem and synergistically contributes to achieving a balanced classifier and feature space. The authors conduct extensive experiments on three popular benchmark datasets including CIFAR-10/100-LT, ImageNet-LT, and iNaturalist 2018. The experimental results demonstrate that the authors’ loss function outperforms several previous state-of-the-art methods in addressing the challenges posed by imbalanced and long-tailed datasets, that is, by improving upon the best-performing baselines on CIFAR-100-LT by 1.34, 1.41, 1.41 and 1.33, respectively.},
  archive      = {J_CAAITIT},
  author       = {Shuzheng Gao and Chaozheng Wang and Cuiyun Gao and Wenjian Luo and Peiyi Han and Qing Liao and Guandong Xu},
  doi          = {10.1049/cit2.12374},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {62-71},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Improving long-tail classification via decoupling and regularisation},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral imagery quality assessment and band
reconstruction using the prophet model. <em>CAAITIT</em>,
<em>10</em>(1), 47–61. (<a
href="https://doi.org/10.1049/cit2.12373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Hyperspectral Imaging (HSI), the detrimental influence of noise and distortions on data quality is profound, which has severely affected the following-on analytics and decision-making such as land mapping. This study presents an innovative framework for assessing HSI band quality and reconstructing the low-quality bands, based on the Prophet model. By introducing a comprehensive quality metric to start, the authors approach factors in both spatial and spectral characteristics across local and global scales. This metric effectively captures the intricate noise and distortions inherent in the HSI data. Subsequently, the authors employ the Prophet model to forecast information within the low-quality bands, leveraging insights from neighbouring high-quality bands. To validate the effectiveness of the authors’ proposed model, extensive experiments on three publicly available uncorrected datasets are conducted. In a head-to-head comparison, the framework against six state-of-the-art band reconstruction algorithms including three spectral methods, two spatial-spectral methods and one deep learning method is benchmarked. The authors’ experiments also delve into strategies for band selection based on quality metrics and the quality evaluation of the reconstructed bands. In addition, the authors assess the classification accuracy utilising these reconstructed bands. In various experiments, the results consistently affirm the efficacy of the authors’ method in HSI quality assessment and band reconstruction. Notably, the authors’ approach obviates the need for manually prefiltering of noisy bands. This comprehensive framework holds promise in addressing HSI data quality concerns whilst enhancing the overall utility of HSI.},
  archive      = {J_CAAITIT},
  author       = {Ping Ma and Jinchang Ren and Zhi Gao and Yinhe Li and Rongjun Chen},
  doi          = {10.1049/cit2.12373},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {47-61},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Hyperspectral imagery quality assessment and band reconstruction using the prophet model},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Longitudinal velocity control of autonomous driving based on
extended state observer. <em>CAAITIT</em>, <em>10</em>(1), 36–46. (<a
href="https://doi.org/10.1049/cit2.12397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active Disturbance Rejection Control (ADRC) possesses robust disturbance rejection capabilities, making it well-suited for longitudinal velocity control. However, the conventional Extended State Observer (ESO) in ADRC fails to fully exploit feedback from first-order and higher-order estimation errors and tracking error simultaneously, thereby diminishing the control performance of ADRC. To address this limitation, an enhanced car-following algorithm utilising ADRC is proposed, which integrates the improved ESO with a feedback controller. In comparison to the conventional ESO, the enhanced version effectively utilises multi-order estimation and tracking errors. Specifically, it enhances convergence rates by incorporating feedback from higher-order estimation errors and ensures the estimated value converges to the reference value by utilising tracking error feedback. The improved ESO significantly enhances the disturbance rejection performance of ADRC. Finally, the effectiveness of the proposed algorithm is validated through the Lyapunov approach and experiments.},
  archive      = {J_CAAITIT},
  author       = {Hongbo Gao and Hanqing Yang and Xiaoyu Zhang and Xiangyun Ren and Fenghua Liang and Ruidong Yan and Qingchao Liu and Mingmao Hu and Fang Zhang and Jiabing Gao and Siyu Bao and Keqiang Li and Deyi Li and Danwei Wang},
  doi          = {10.1049/cit2.12397},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {36-46},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Longitudinal velocity control of autonomous driving based on extended state observer},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning on medical image analysis. <em>CAAITIT</em>,
<em>10</em>(1), 1–35. (<a
href="https://doi.org/10.1049/cit2.12356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image analysis plays an irreplaceable role in diagnosing, treating, and monitoring various diseases. Convolutional neural networks (CNNs) have become popular as they can extract intricate features and patterns from extensive datasets. The paper covers the structure of CNN and its advances and explores the different types of transfer learning strategies as well as classic pre-trained models. The paper also discusses how transfer learning has been applied to different areas within medical image analysis. This comprehensive overview aims to assist researchers, clinicians, and policymakers by providing detailed insights, helping them make informed decisions about future research and policy initiatives to improve medical image analysis and patient outcomes.},
  archive      = {J_CAAITIT},
  author       = {Jiaji Wang and Shuihua Wang and Yudong Zhang},
  doi          = {10.1049/cit2.12356},
  journal      = {CAAI Transactions on Intelligence Technology},
  month        = {2},
  number       = {1},
  pages        = {1-35},
  shortjournal = {CAAI Trans. Intell. Technol.},
  title        = {Deep learning on medical image analysis},
  volume       = {10},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
