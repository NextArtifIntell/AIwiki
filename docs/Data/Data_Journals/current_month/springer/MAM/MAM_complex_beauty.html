<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MAM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mam---9">MAM - 9</h2>
<ul>
<li><details>
<summary>
(2025). Physical programmability. <em>MAM</em>, <em>35</em>(2),
1–29. (<a href="https://doi.org/10.1007/s11023-025-09714-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article delivers an account of what it is for a physical system to be programmable. Despite its significance in computing and beyond, today’s philosophical discourse on programmability is impoverished. This contribution offers a novel definition of physical programmability as the degree to which the selected operations of an automaton can be reconfigured in a controlled way. The framework highlights several key insights: the constrained applicability of physical programmability to material automata, the characterization of selected operations within the neo-mechanistic framework, the understanding of controlled reconfiguration through the causal theory of interventionism, and the recognition of physical programmability as a gradual notion. The account can be used to individuate programmable (computing) systems and taxonomize concrete systems based on their programmability. The article closes by posing some open questions and offering avenues for future research in this domain.},
  archive      = {J_MAM},
  author       = {Wiggershaus, Nick},
  doi          = {10.1007/s11023-025-09714-3},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Minds Mach.},
  title        = {Physical programmability},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Persons, unique value and avatars. <em>MAM</em>,
<em>35</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s11023-025-09715-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An individual human has value partly in virtue of their uniqueness. Personal avatar technology—technology which creates a digital replication of a real person—appears to have the potential to undermine that value. Here I explore if and how avatars might make humans less valuable by undermining the value that a human gains from being unique. Ultimately, I conclude that, while avatars cannot make humans no longer unique, they could significantly undermine the value that we place on human uniqueness. First, I argue that a qualitative model of uniqueness cannot account for the unique value that a person has. This leads to the significant and surprising claim that necessarily unique properties of humans cannot accommodate the value arising from human uniqueness: humans have unique value in virtue of being contingently irreplaceable. I explore how the use of personal avatars might undermine or even destroy that value. Finally, I consider further applications of the theory of unique human value, including how it might explain and accommodate our attachment to personal avatars themselves.},
  archive      = {J_MAM},
  author       = {Sweeney, Paula},
  doi          = {10.1007/s11023-025-09715-2},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Minds Mach.},
  title        = {Persons, unique value and avatars},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How do social media algorithms appear? A phenomenological
response to the black box metaphor. <em>MAM</em>, <em>35</em>(2), 1–21.
(<a href="https://doi.org/10.1007/s11023-025-09716-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article challenges the dominant ‘black box’ metaphor in critical algorithm studies by proposing a phenomenological framework for understanding how social media algorithms manifest themselves in user experience. While the black box paradigm treats algorithms as opaque, self-contained entities that exist only ‘behind the scenes’, this article argues that algorithms are better understood as genetic phenomena that unfold temporally through user-platform interactions. Recent scholarship in critical algorithm studies has already identified various ways in which algorithms manifest in user experience: through affective responses, algorithmic self-reflexivity, disruptions of normal experience, points of contention, and folk theories. Yet, while these studies gesture toward a phenomenological understanding of algorithms, they do so without explicitly drawing on phenomenological theory. This article demonstrates how phenomenology, particularly a Husserlian genetic approach, can further conceptualize these already-documented algorithmic encounters. Moving beyond both the paradigm of artifacts and static phenomenological approaches, the analysis shows how algorithms emerge as inherently relational processes that co-constitute user experience over time. By reconceptualizing algorithms as genetic phenomena rather than black boxes, this paper provides a theoretical framework for understanding how algorithmic awareness develops from pre-reflective affective encounters to explicit folk theories, while remaining inextricably linked to users’ self-understanding. This phenomenological framework contributes to a more nuanced understanding of algorithmic mediation in contemporary social media environments and opens new pathways for investigating digital technologies.},
  archive      = {J_MAM},
  author       = {Longo, Anthony},
  doi          = {10.1007/s11023-025-09716-1},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Minds Mach.},
  title        = {How do social media algorithms appear? a phenomenological response to the black box metaphor},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In honor of james moor: A grateful retrospective.
<em>MAM</em>, <em>35</em>(2), 1–6. (<a
href="https://doi.org/10.1007/s11023-025-09718-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MAM},
  author       = {Ess, Charles M.},
  doi          = {10.1007/s11023-025-09718-z},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-6},
  shortjournal = {Minds Mach.},
  title        = {In honor of james moor: A grateful retrospective},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The quantum panopticon: A theory of surveillance for the
quantum era. <em>MAM</em>, <em>35</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s11023-025-09723-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of quantum computing will compromise current asymmetric cryptography. Awaiting this moment, global superpowers are routinely collecting and storing encrypted data, so as to later decrypt it once sufficiently strong quantum computers are in place. We argue that this situation gives rise to a new mode of global surveillance that we refer to as a quantum panopticon. Unlike traditional forms of panoptic surveillance, the quantum panopticon introduces a temporal axis, whereby data subjects’ future pasts can be monitored from an unknown “superposition” in the quantum future. It also introduces a new level of uncertainty, in that the future watchman’s very existence becomes a function of data subjects’ efforts to protect themselves from being monitored in the present. Encryption may work as a momentary protection, but increases the likelihood of long-term preservation for future decryption, because encrypted data is stored longer than plaintext data. To illustrate the political and ethical aspects of these features, we draw on cryptographic as well as theoretical surveillance literature and call for urgent consideration of the wider implications of quantum computing for the global surveillance landscape.},
  archive      = {J_MAM},
  author       = {Olsson, Erik and Öhman, Carl},
  doi          = {10.1007/s11023-025-09723-2},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Minds Mach.},
  title        = {The quantum panopticon: A theory of surveillance for the quantum era},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Moor’s “are there decisions computers should never make?”
<em>MAM</em>, <em>35</em>(2), 1–8. (<a
href="https://doi.org/10.1007/s11023-025-09719-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {‘Are There Decisions Computers Should Never Make?’ is one of James H. Moor’s many groundbreaking papers in computer ethics, and it is one that I have thought a good deal about since its publication in 1979 and especially in recent years in relation to current discourse on AI. In this paper, I describe Jim’s analysis, reflect on its relevance to current thinking about AI, and take issue with several of his arguments. The conclusion of Jim’s paper is that computers should never choose human values and goals. I suggest that this is not possible because of the nature of values and how they are intertwined in computer decision making.},
  archive      = {J_MAM},
  author       = {Johnson, Deborah G.},
  doi          = {10.1007/s11023-025-09719-y},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-8},
  shortjournal = {Minds Mach.},
  title        = {Moor’s ‘Are there decisions computers should never make?’},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Moor on ethics for emerging technologies: Some environmental
considerations. <em>MAM</em>, <em>35</em>(2), 1–7. (<a
href="https://doi.org/10.1007/s11023-025-09721-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Around the turn of this century a number of emerging technologies were in the news, raising some potentially significant ethical questions. Given that they were emerging they as yet had no, or very few, impacts, so it was not obvious how best to assess them ethically. Jim Moor addressed this issue and offered three suggestions for a better ethics for emerging technologies. His first was that ethics should be dynamic, that is, it should be an ongoing process before, during and after the technological development. Second, there should be close collaboration between the researchers and developers on the one hand, and ethicists and social scientists on the other. Finally, ethical analyses should be more sophisticated. In this paper I argue that environmental issues and the questioning of core ethical values should be a central part of the ethics of emerging technologies, using AI examples. Given the kind of beings that we are, technology and the environment are closely connected for human flourishing.},
  archive      = {J_MAM},
  author       = {Weckert, John},
  doi          = {10.1007/s11023-025-09721-4},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-7},
  shortjournal = {Minds Mach.},
  title        = {Moor on ethics for emerging technologies: Some environmental considerations},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). James moor’s privacy framework: A theory in need of further
exploration. <em>MAM</em>, <em>35</em>(2), 1–7. (<a
href="https://doi.org/10.1007/s11023-025-09717-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is intended as a tribute to the late James Moor. An esteemed Dartmouth professor, who published in many areas of philosophy, including logic, Moor is perhaps best remembered today for his pioneering work in the field of computer ethics. His seminal (and award-winning) article, “What Is Computer Ethics?” (Metaphilosophy, 1985) was highly influential both in defining and shaping the then nascent field of computer ethics. Many other computer-ethics-related papers followed over the next quarter century, in which Moor examined a range of topics – from moral responsibility to autonomy to privacy in the context of computing and emerging technologies, including nanotechnology and AI. And while the insights and frameworks put forth in many of his published works have received the acclaim they deserve, Moor’s contribution to the privacy literature remains, in my view, underappreciated. In trying to show why his privacy theory deserves much more attention than received to date, I also briefly describe the evolution of Moor’s position on privacy – from his earlier publications on that topic to a comprehensive and systematic privacy framework. I then suggest that a further exploration of his privacy theory would benefit researchers working in technology ethics in general, and AI ethics in particular. Finally, I encourage privacy scholars to take a closer look at Moor’s privacy framework to see whether they might be able to tease out and disclose some potential insights and features that may still be embedded in that robust theory of privacy.},
  archive      = {J_MAM},
  author       = {Tavani, Herman T.},
  doi          = {10.1007/s11023-025-09717-0},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-7},
  shortjournal = {Minds Mach.},
  title        = {James moor’s privacy framework: A theory in need of further exploration},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The historical development of ethics of emerging
technologies. <em>MAM</em>, <em>35</em>(2), 1–9. (<a
href="https://doi.org/10.1007/s11023-025-09720-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article traces the historical development of the ethics of emerging technologies. It argues that during the late 2000s and 2010s, the field of ethics of technology transformed from a fragmented, reactive, and methodologically underdeveloped discipline focused on mature technologies and lacking policy orientation into a more cohesive, proactive, methodologically sophisticated, and policy-focused field with a strong emphasis on emerging technologies. An agenda for this transition was set in Jim Moor’s seminal publication “Why We Need Better Ethics for Emerging Technologies”.},
  archive      = {J_MAM},
  author       = {Brey, Philip A. E.},
  doi          = {10.1007/s11023-025-09720-5},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-9},
  shortjournal = {Minds Mach.},
  title        = {The historical development of ethics of emerging technologies},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
