<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NCA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nca---44">NCA - 44</h2>
<ul>
<li><details>
<summary>
(2025). Improving paraphrase generation using supervised
neural-based statistical machine translation framework. <em>NCA</em>,
<em>37</em>(11), 7705–7719. (<a
href="https://doi.org/10.1007/s00521-023-08830-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In phrase generation (PG), a sentence in the natural language is changed into a new one with a different syntactic structure but having the same semantic meaning. The present sequence-to-sequence strategy aims to recall the words and structures from the training dataset rather than learning the words&#39; semantics. As a result, the resulting statements are frequently grammatically accurate but incorrect linguistically. The neural machine translation approach suffers to handle unusual words, domain mismatch, and unfamiliar words, but it takes context well. This work presents a novel model for creating paraphrases that use neural-based statistical machine translation (NSMT). Our approach creates potential paraphrases for any source input, calculates the level of semantic similarity between text segments of any length, and encodes paraphrases in a continuous space. To evaluate the suggested model, Quora Question Pair and Microsoft Common Objects in Context benchmark datasets are used. We demonstrate that the proposed technique achieves cutting-edge performance on both datasets using automatic and human assessments. Experimental findings across tasks and datasets demonstrate that the suggested NSMT-based PG outperforms those achieved with traditional phrase-based techniques. We also show that the proposed technique may be used automatically for the development of paraphrases for a variety of languages.},
  archive      = {J_NCA},
  author       = {Razaq, Abdur and Shah, Babar and Khan, Gohar and Alfandi, Omar and Ullah, Abrar and Halim, Zahid and Ur Rahman, Atta},
  doi          = {10.1007/s00521-023-08830-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7705-7719},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving paraphrase generation using supervised neural-based statistical machine translation framework},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of tampered real time videos using deep neural
networks. <em>NCA</em>, <em>37</em>(11), 7691–7703. (<a
href="https://doi.org/10.1007/s00521-024-09988-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a significant increase in the creation and sharing of videos that promote the utilization of digitally interactive multimedia, including music, graphics, and videos, across various devices. This trend encompasses both social networking applications and everyday tasks, mirroring the growing reliance on digital communication devices. Forgery techniques and motivations in the digital realm have undergone significant advancements. Previously, video editing methods were employed to enhance digital content. However, the proliferation of affordable and user-friendly video editing software has introduced several drawbacks and risks associated with these editing techniques. These editing tools can be misused to create misleading, altered, or fabricated videos for malicious purposes, such as spreading misinformation, deception, or defamation. In order to produce altered or fraudulent videos, additional footage is mixed, edited, or synthesized. Sophisticated editing techniques can make it challenging to detect forged videos, making it easier for forgeries to be mistakenly perceived as genuine. Existing method uses methods that detect forgery in videos with simply static backgrounds only. Proposed systems uses a deep learning strategy that incorporates transfer learning utilizing VGG16 and Customized CNN layers to categorize real time videos as tampered or authentic. With the aid of deep neural networks, the suggested method may identify forgery in films with both static and moving backgrounds. The experimental findings show that the suggested strategy is more accurate and effective than existing methods also it provides trustworthy results with low computing cost and strong detection performance.},
  archive      = {J_NCA},
  author       = {Koshy, Litty and Shyry, S. Prayla},
  doi          = {10.1007/s00521-024-09988-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7691-7703},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of tampered real time videos using deep neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study of progressive data flow knowledge tracing based on
reconstructed attention mechanism. <em>NCA</em>, <em>37</em>(11),
7675–7689. (<a
href="https://doi.org/10.1007/s00521-024-10011-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) is an essential task in intellectual education, which measures learners’ ability to learn new knowledge by collecting historical learning information from learners. With the introduction of Recurrent Neural Networks (RNN) and Transformer into the field of KT, although effective, they focus only on the temporal order in which the learner information is affected. To model accurately, we propose a KT model BPKT (Bayesian-Attention mechanism Progressive data flow for KT) that allows exercise embedding to be layered in different forms and incorporated into the model multiple times. The BPKT model integrates the relationship between exercises covering knowledge points in both the temporal and spatial aspects, and defines a Bayesian-Attention mechanism based on this, with an in-depth analysis of the realistic meaning of the micro-parameters Q, K, and V in the mechanism. Through experiments on four real benchmark datasets, the results show that the BPKT model is helpful for predicting learners’ future responses on large-scale datasets.},
  archive      = {J_NCA},
  author       = {Wu, Qianxi and Wang, Min and Zhou, Guohui and Ji, Weidong},
  doi          = {10.1007/s00521-024-10011-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7675-7689},
  shortjournal = {Neural Comput. Appl.},
  title        = {A study of progressive data flow knowledge tracing based on reconstructed attention mechanism},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep perceptual framework for affective video tagging
through multiband EEG signals modeling. <em>NCA</em>, <em>37</em>(11),
7657–7674. (<a
href="https://doi.org/10.1007/s00521-023-09086-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, multimedia content, such as photographs and movies, is ingrained in every aspect of human lives and has become a vital component of their entertainment. Multimedia content, such as videos or movie clips, is typically created with the intent to evoke certain feelings or emotions in viewers. Thus, by examining the viewer’s cognitive state while watching such content, its affectiveness can be evaluated. Considering the emotional aspect of videos, in this paper, a deep learning-based paradigm for affective tagging of video clips is proposed, in which participants’ irrational EEG responses are used to examine how people perceive videos. The information behind different brain regions, frequency waves, and connections among them play an important role in understanding a human’s cognitive state. Thus, here a contribution is made toward the effective modeling of EEG signals through two different representations, i.e., spatial feature matrix and combined power spectral density maps. The proposed feature representations highlight the spatial features of EEG signals and are therefore used to train a convolution neural network model for implicit tagging of two categories of videos in the Arousal domain, i.e., “Low Arousal” and “High Arousal.” The arousal emotional space represents the excitement level of the viewer; thus, this domain is selected to analyze the viewer’s engagement while watching video clips. The proposed model is developed using the EEG data taken from publicly available datasets “AMIGOS” and “DREAMER.” The model is tested using two different approaches, i.e., single-subject classification and multi-subject classification, and an average accuracy of 90%-95% and 90%-93% is achieved, respectively. The simulations presented in this paper show the pioneering applicability of the proposed framework for the development of brain–computer interface (BCI) devices for affective tagging of videos.},
  archive      = {J_NCA},
  author       = {Sharma, Shanu and Dubey, Ashwani Kumar and Ranjan, Priya and Rocha, Alvaro},
  doi          = {10.1007/s00521-023-09086-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7657-7674},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep perceptual framework for affective video tagging through multiband EEG signals modeling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising histopathology images for the detection of breast
cancer. <em>NCA</em>, <em>37</em>(11), 7641–7655. (<a
href="https://doi.org/10.1007/s00521-023-08771-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the leading causes of mortality for women worldwide, both in developing and developed economies, is breast cancer. The gold standard for diagnosing cancer is still histological diagnosis, despite major advances in medical understanding. Admittedly, due to the sophistication of histopathology images and the significant increase in workload, this process takes a long time. Therefore, this field requires the development of automated and precise histopathology image analysis tools. Using deep learning, we proposed a system for denoising, detecting, and classifying breast cancer using deep learning architectures that are designed to solve certain related problems. CNN-based architectures are used to extract features from images, which are then put into a fully connected layer for the classification of malignant and benign cells, as well as their subclasses, in the suggested framework. The effectiveness of the suggested framework is evaluated through experiments leveraging accepted benchmark data sets. We achieve an accuracy of 94% and an F1 score of more than 90%.},
  archive      = {J_NCA},
  author       = {Zeb, Muhammad Haider and Al-Obeidat, Feras and Tubaishat, Abdallah and Qayum, Fawad and Fazeel, Ahsan and Amin, Muhammad},
  doi          = {10.1007/s00521-023-08771-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7641-7655},
  shortjournal = {Neural Comput. Appl.},
  title        = {Denoising histopathology images for the detection of breast cancer},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic gait analysis through computer vision: A pilot
study. <em>NCA</em>, <em>37</em>(11), 7619–7639. (<a
href="https://doi.org/10.1007/s00521-023-08549-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kinesiologists who study people&#39;s posture during walking depend on spreadsheets and visual posture reviews. Gold-standard evaluation relies on expert evaluation, not mediated by technology. However, today there are technological advances to automate specific processes adequately. Our proposal focuses on developing software based on computer vision and artificial intelligence (AI) to support recognition in the gait cycle and walking activities. The software is deployed in an architecture based on microservices to support the image analysis process with high concurrency. We opted for an open-source alternative, Openpose, because it is one of the most popular detection libraries for pose estimation and is capable of real-time multi-person pose analysis. We validate the choice through a proof of concept in which we prove that it can be possible to obtain valuable results for the kinesiology care process. This software assists specialists in analyzing and measuring lower extremity angles and distances during gait. We developed an information system based on open-source pose estimation algorithms for clinical decision-making. The technological approach was obtained by analyzing similar proposals and considering the characteristics of the clinic. We used a real-time multi-person pose estimation as an essential element enabling machines to visually comprehend and analyze humans and their interactions. In this instance, we identified accuracy metrics and optimized the evaluation process time. Using a non-probabilistic sample, we analyzed the videos of users performing the gait exercises. These results indicate that although the algorithms still need to achieve perfect accuracy, they save manual work for the final evaluation. On average, using the platforms reduces by about 50% the total time required to generate the final reports delivered by the kinesiology clinic. This proposal has always been justified as a support to the professional work and not as a replacement. We propose an information system based on open-source pose estimation algorithms for clinical decision-making. The technological approach was obtained by analyzing similar proposals and considering the characteristics of the clinic. We used a real-time multi-person pose estimation as an essential element enabling machines to visually comprehend and analyze humans and their interactions. While these recognition alternatives have been explored for some time, linking with particular needs and improving healthcare processes is critical.},
  archive      = {J_NCA},
  author       = {Díaz-Arancibia, Jaime and Córdova, Matías and Arango-López, Jeferson and Ahumada, Danay and Moreira, Fernando},
  doi          = {10.1007/s00521-023-08549-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7619-7639},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic gait analysis through computer vision: A pilot study},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A non-invasive approach for calcium deficiency detection in
pears using machine learning. <em>NCA</em>, <em>37</em>(11), 7609–7618.
(<a href="https://doi.org/10.1007/s00521-023-08444-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A pear is a sweet fruit that is rich in dietary fiber, antioxidants, and plant compounds. The nutritional disorder in pears is either due to deficiency of nutrients or toxicity of nutrients. The techniques to identify the nutrients deficiencies include tissue testing, soil analysis, plant analysis, and visual deficiency symptoms. The effects of alfalfa greening, black end, and cork spot are minimised by correcting the calcium nutrition in the pear tree. In this paper, a two-class decision jungle model is proposed for the recognition of calcium deficiency in pears based on a non-invasive approach. The calcium deficiency in pears makes a bumpy fruit surface and leaves yellow color on the affected area than the rest of the skin results in the greyish corky lesion. The nutrient deficiency that results in serious disorders in pears not only influences the plant but also impacts the fruit quality. The introduction of artificial intelligence in the agriculture industry has helped farmers to produce healthier fruits. The artificial intelligence provides a real-time data for the classifier that results in increasing agricultural efficiencies, better crop yields and reduce fruit production costs by facilitating the routine and most complex tasks. The two-class decision jungle model achieves an accuracy of 98% with a database of 1000 samples. The other approaches, such as Boosted decision tree, Bayes point machine, Logistic regression, Neural Network, and SVM, have an accuracy of 92.20%, 84.3%, 72.5%, 82.4%, and 72.5%, respectively for the equivalent datasets. The highest accuracy is achieved with the proposed two class decision jungle that has non-linear decision boundaries and the performance is resilient in the presence of features that consist of noise. The number of calcium-deficient and healthy pears is 500 each. The geometrical features are extracted for the development of an artificial intelligence-based model for the classification of two classes like calcium deficient and healthy pear. The extracted features are split into training, validation, and testing. For training, validation, and testing, 80%, 10% and 10% samples are used respectively. The precision level is observed to be 0.974 and test accuracy is achieved as 98.7% and the overall accuracy 98% which are better than the existing 88.2% accuracy for pears using Support Vector Machine.},
  archive      = {J_NCA},
  author       = {Yogesh and Dubey, Ashwani Kumar and Rocha, Alvaro},
  doi          = {10.1007/s00521-023-08444-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7609-7618},
  shortjournal = {Neural Comput. Appl.},
  title        = {A non-invasive approach for calcium deficiency detection in pears using machine learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of integrated information theory: A
perspective from artificial intelligence and the cognitive sciences.
<em>NCA</em>, <em>37</em>(11), 7575–7607. (<a
href="https://doi.org/10.1007/s00521-023-08328-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of consciousness has gained momentum in recent years by the scientific community. In this same sense, the relationship between cognitive sciences and artificial intelligence presents a fundamental theoretical framework in the study of integrated information theory (IIT) as a theory that makes its way into the knowledge of consciousness. However, there are few studies that integrate these topics and a systematic review of the literature is highly pertinent. This paper seeks to identify methods, methodologies or computational solutions using artificial intelligence and cognitive science fundamentals that can provide some kind of solution to the challenges posed by IIT.},
  archive      = {J_NCA},
  author       = {Guerrero, Luz Enith and Castillo, Luis Fernando and Arango-López, Jeferson and Moreira, Fernando},
  doi          = {10.1007/s00521-023-08328-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7575-7607},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic review of integrated information theory: A perspective from artificial intelligence and the cognitive sciences},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SureUnet: Sparse autorepresentation encoder u-net for noise
artifact suppression in low-dose CT. <em>NCA</em>, <em>37</em>(11),
7561–7573. (<a
href="https://doi.org/10.1007/s00521-023-08847-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-dose computed tomography (LDCT) is desirable due to ionizing radiation, but the resulting images suffer from serious streak artifacts and spot noise. Recently, deep learning (DL)-based methods have emerged as promising alternatives for medical image processing. However, most DL-based methods are built intuitively and lack interpretability, and it is difficult to effectively separate the artifacts and noise in LDCT images. Obtaining diagnostically useful images, especially when using a low-dose scanner protocol, remains an open challenge. To improve the quality of LDCT images, we developed a novel processing network called the sparse autorepresentation U-Net (SureUnet). First, inspired by multilayer convolutional sparse coding (CSC), we constructed a sparse autorepresentation encoder to sufficiently capture and represent hierarchical image features. Then, we chose the widely used U-Net model for sparse autorepresentation block applications and designed SureUnet by adding a feature decoding block. Therefore, every module has well-defined interpretability in our network. Additionally, hybrid loss functions were specifically designed, including the mean absolute error, edge loss and perceptual loss. Through the cooperation of multiple loss functions, the noise artifact suppression effect of the network was improved. The visual results obtained on the MAYO and UIH datasets show that the proposed method’s noise artifact suppression effect was more significant. The quantitative results showed promising improvement levels compared to those of the other state-of-the-art methods. The SureUnet model significantly outperformed the compared methods on two datasets, with margins of 0.4 dB for the PSNR, 0.007 for the SSIM, and 1.6 for the FID on the MAYO dataset and margins of 0.5 dB for the PSNR, 0.004 for the SSIM and 2.9 for the FID on the UIH dataset. This work paves the way for sparse autorepresentation in DL for processing LDCT images. Experimental results have demonstrated the competitive performance of SureUnet in terms of noise suppression, structural fidelity and visual impression improvement.},
  archive      = {J_NCA},
  author       = {Liu, Jin and Zhang, Tingyu and Kang, Yanqin and Qiang, Jun and Hu, Dianlin and Zhang, Yikun},
  doi          = {10.1007/s00521-023-08847-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7561-7573},
  shortjournal = {Neural Comput. Appl.},
  title        = {SureUnet: Sparse autorepresentation encoder U-net for noise artifact suppression in low-dose CT},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MixDA: Mixup domain adaptation for glaucoma detection on
fundus images. <em>NCA</em>, <em>37</em>(11), 7541–7560. (<a
href="https://doi.org/10.1007/s00521-023-08572-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network has achieved promising results for automatic glaucoma detection on fundus images. Nevertheless, the intrinsic discrepancy across glaucoma datasets is challenging for the data-driven neural network approaches. This discrepancy leads to the domain gap that affects model performance and declines model generalization capability. Existing domain adaptation-based transfer learning methods mostly fine-tune pretrained models on target domains to reduce the domain gap. However, this feature learning-based adaptation method is implicit, and it is not an optimal solution for transfer learning on the diverse glaucoma datasets. In this paper, we propose a mixup domain adaptation (mixDA) method that bridges domain adaptation with domain mixup to improve model performance across divergent glaucoma datasets. Specifically, the domain adaptation reduces the domain gap of glaucoma datasets in transfer learning with an explicit adaptation manner. Meanwhile, the domain mixup further minimizes the risk of outliers after domain adaptation and improves the model generalization capability. Extensive experiments show the superiority of our mixDA on several public glaucoma datasets. Moreover, our method outperforms state-of-the-art methods by a large margin on four glaucoma datasets: REFUGE, LAG, ORIGA, and RIM-ONE.},
  archive      = {J_NCA},
  author       = {Yan, Ming and Lin, Yun and Peng, Xi and Zeng, Zeng},
  doi          = {10.1007/s00521-023-08572-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7541-7560},
  shortjournal = {Neural Comput. Appl.},
  title        = {MixDA: Mixup domain adaptation for glaucoma detection on fundus images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diabetic retinopathy classification based on dense
connectivity and asymmetric convolutional neural network. <em>NCA</em>,
<em>37</em>(11), 7527–7540. (<a
href="https://doi.org/10.1007/s00521-022-07952-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is the leading cause of blindness in diabetics. The low contrast and microscopic nature of the lesions lead to a high false positive rate for automated DR screening. To address this issue, we propose a neural network named AC-DenseNet for the five-stage DR classification. In order to exploit the shallow features and enhance the feature extraction performance, dense connectivity is added to the convolution layer of AC-DenseNet. For the convolution layer to be more robust for DR detection in rotated or flipped pictures, asymmetric convolution branches are also introduced. In addition, attention mechanisms and auxiliary classifiers are incorporated into the network for the improvement of the performance of DR classification. We validate AC-DenseNet on the enhanced Kaggle dataset. The results show that AC-DenseNet can achieve 88.8% accuracy, 97.1% specificity, and 88.7% sensitivity, demonstrating that our model outperforms several state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Cao, Juan and Chen, Jiaran and Zhang, Xinying and Peng, Yang},
  doi          = {10.1007/s00521-022-07952-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7527-7540},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diabetic retinopathy classification based on dense connectivity and asymmetric convolutional neural network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DH-GAC: Deep hierarchical context fusion network with
modified geodesic active contour for multiple neurofibromatosis
segmentation. <em>NCA</em>, <em>37</em>(11), 7511–7526. (<a
href="https://doi.org/10.1007/s00521-022-07945-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delineating accurately and simultaneously all lesions is vital and challenging for computer-aided diagnosis for multiple neurofibromatosis (NF). However, existing CNN-based segmentation methods paid little attention to weak boundaries. Moreover, due to the intensity-inhomogeneous distribution of medical images, the ambiguous boundaries, and highly variable locations, sizes and shapes of the lesions, delineating multiple lesions simultaneously remains quite challenging. To address these challenges, we introduce a novel end-to-end segmentation framework of multiple NF, deep hierarchical geodesic active contour (DH-GAC). It leverages the elaborately designed deep hierarchical context fusion network (DH-CFN) to improve the generalization and robustness of DH-GAC, and the modified geodesic active contour (MGAC) to delineate precisely all lesions as much as possible. Specifically, it employs DH-CFN to predict specific parameter maps of each image for MGAC and feeds them into the energy function of MGAC to delineate NF lesions, which makes DH-GAC end-to-end trainable. Moreover, to improve the generalization of DH-GAC, we adopt two different settings to initialize the surface for DH-GAC. Experimental results demonstrate that DH-GAC not only improves the segmentation precision, but also overcomes the intrinsic drawback of classical geodesic active contour in boundary delineation.},
  archive      = {J_NCA},
  author       = {Wu, Xiangqiong and Tan, Guanghua and Pu, Bin and Duan, Mingxing and Cai, Wenli},
  doi          = {10.1007/s00521-022-07945-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7511-7526},
  shortjournal = {Neural Comput. Appl.},
  title        = {DH-GAC: Deep hierarchical context fusion network with modified geodesic active contour for multiple neurofibromatosis segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CSPP-IQA: A multi-scale spatial pyramid pooling-based
approach for blind image quality assessment. <em>NCA</em>,
<em>37</em>(11), 7499–7510. (<a
href="https://doi.org/10.1007/s00521-022-07874-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional image quality assessment (IQA) methods are usually based on convolutional neural networks (CNNs). For these IQA methods using CNNs, limited by the feature size of the fully connected layer, the input image needs be tailored to a pre-defined size, which usually results in destroying the original structure and content of the input image and thus reduces the accuracy of the quality assessment. In this paper, a blind image quality assessment method (named CSPP-IQA), which is based on multi-scale spatial pyramid pooling, is proposed. CSPP-IQA allows inputting the original image when assessing the image quality without any image adjustment. Moreover, by facilitating the convolutional block attention module and image understanding module, CSPP-IQA achieved better accuracy, generalization and efficiency than traditional IQA methods. The result of experiments running on real-scene IQA datasets in this study verified the effectiveness and efficiency of CSPP-IQA.},
  archive      = {J_NCA},
  author       = {Chen, Jingjing and Qin, Feng and Lu, Fangfang and Guo, Lingling and Li, Chao and Yan, Ke and Zhou, Xiaokang},
  doi          = {10.1007/s00521-022-07874-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7499-7510},
  shortjournal = {Neural Comput. Appl.},
  title        = {CSPP-IQA: A multi-scale spatial pyramid pooling-based approach for blind image quality assessment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CWC-transformer: A visual transformer approach for
compressed whole slide image classification. <em>NCA</em>,
<em>37</em>(11), 7485–7497. (<a
href="https://doi.org/10.1007/s00521-022-07857-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Artificial Intelligence (AI) technology accelerates the application of computational pathology in clinical decision-making. Due to the restriction of computing resources and annotation information, it is challenging for AI-based computational pathology methods to effectively process and analyze the gigapixel whole slide image (WSI). Conventional methods utilize multiple instance learning (MIL) to convert WSI into patches for classification. However, without the patch-level annotation, it is difficult to extract discriminative features, even with pre-trained networks. Furthermore, forcibly applying the patch-level conversion will break the pathological characteristics of WSI from the spatial structure. In this study, we present a two-stage framework named Compressed WSI Classification (CWC-Transformer) to effectively solve the problems of feature extraction and spatial information loss in WSI classification. In the compression stage, we adopt contrastive learning to present a feature compression method, which not only extracts the discriminative features but also decreases the data deviation caused by staining and scanning inconsistency. In the learning stage, we extend the advantages of the convolutional neural network and transformer mechanism to enhance the co-relations between local and global information to provide the final results jointly. Experiments on three large-scale public datasets of different tasks show that our proposed framework outperforms other advanced methods in terms of robustness and interpretation.},
  archive      = {J_NCA},
  author       = {Wang, Yaowei and Guo, Jing and Yang, Yun and Kang, Yan and Xia, Yuelong and Li, Zhenhui and Duan, Yongchun and Wang, Kelong},
  doi          = {10.1007/s00521-022-07857-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7485-7497},
  shortjournal = {Neural Comput. Appl.},
  title        = {CWC-transformer: A visual transformer approach for compressed whole slide image classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Most relevant point query on road networks. <em>NCA</em>,
<em>37</em>(11), 7473–7483. (<a
href="https://doi.org/10.1007/s00521-022-07485-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are widespread in many real-life practical applications. One of a graph’s fundamental and popular researches is investigating the relations between two given vertices. The relationship between nodes in the graph can be measured by the shortest distance. Moreover, the number of paths is also a popular metric to assess the relationship of different nodes. In many location-based services, users make decisions on the basis of both the two metrics. To address this problem, we propose a new hybrid-metric based on the number of paths with a distance constraint for road networks, which are special graphs. Based on it, a most relevant node query on road networks is identified. To handle this problem, we first propose a Shortest-Distance Constrained DFS, which uses the shortest distance to prune unqualified nodes. To further improve query efficiency, we present Batch Query DFS algorithm, which only needs only one DFS search. Our experiments on four real-life road networks demonstrate the performance of the proposed algorithms.},
  archive      = {J_NCA},
  author       = {Zhang, Zining and Yang, Shenghong and Qin, Yunchuan and Yang, Zhibang and Huang, Yang and Zhou, Xu},
  doi          = {10.1007/s00521-022-07485-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7473-7483},
  shortjournal = {Neural Comput. Appl.},
  title        = {Most relevant point query on road networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-instance discriminative contrastive learning for brain
image representation. <em>NCA</em>, <em>37</em>(11), 7459–7472. (<a
href="https://doi.org/10.1007/s00521-022-07524-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of learning discriminative representation for brain images, which is a critical task toward understanding brain developments. Related studies usually extract manual and statistical features from the functional magnetic resonance images (MRIs) to differentiate brain patterns. However, these features fail to consider the implicit and high-order variances, and the existing representation methods often suffer from the weak manual features and the small-size sample. This paper introduces a weakly-supervised representation learning model, dubbed multi-instance discriminative contrastive learning (MIDCL), to identify the different MRI patterns. MIDCL yields two versions for each instance of a subject by introducing noise patterns and then achieves latent representations for them via training an encoder network and a projection network. Due to the multi-instance problem, MIDCL simultaneously minimizes an unsupervised contrastive loss (UCL) between the two representations at the level of instances and a supervised contrastive loss (SCL) between the two concatenated feature vectors at the level of subjects. We finally conducted experiments on two publicly available brain image datasets. The experiment results manifest that MIDCL could benefit from both UCL and SCL, thereby improving brain image classification performance in comparison with the state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Zhang, Yupei and Liu, Shuhui and Qu, Xiran and Shang, Xuequn},
  doi          = {10.1007/s00521-022-07524-7},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7459-7472},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-instance discriminative contrastive learning for brain image representation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Research on mining collaborative behaviour
patterns of dynamic supply chain network from the perspective of big
data. <em>NCA</em>, <em>37</em>(10), 7457–7458. (<a
href="https://doi.org/10.1007/s00521-025-11023-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Leng, Kaijun and Jing, Linbo and Lin, I.-Ching and Chang, Sheng-Hung and Lam, Anthony},
  doi          = {10.1007/s00521-025-11023-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7457-7458},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Research on mining collaborative behaviour patterns of dynamic supply chain network from the perspective of big data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RETRACTED ARTICLE: Deep learning-based algorithm for optimum
cluster head selection in sustainable wireless communication system.
<em>NCA</em>, <em>37</em>(10), 7455. (<a
href="https://doi.org/10.1007/s00521-023-08861-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Revanesh, M. and Mary, S. A. Sahaaya Arul and Gnaneswari, G. and Jones, G. Maria and Kanimozhi, K. V. and Kamalam, G. K.},
  doi          = {10.1007/s00521-023-08861-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7455},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Deep learning-based algorithm for optimum cluster head selection in sustainable wireless communication system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RETRACTED ARTICLE: Energy-efficient and sustainable
communication in optical networks for eliminating path reservation
criteria and providing guaranteed packet transmission between nodes.
<em>NCA</em>, <em>37</em>(10), 7453. (<a
href="https://doi.org/10.1007/s00521-023-08866-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Asha, P. and Kalaavathi, B. and Shantha Kumari, K. and Malarvizhi, K. and Kishore Kumar, A. and Sobitha Ahila, S.},
  doi          = {10.1007/s00521-023-08866-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7453},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Energy-efficient and sustainable communication in optical networks for eliminating path reservation criteria and providing guaranteed packet transmission between nodes},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RETRACTED ARTICLE: Analysis of complex cognitive task and
pattern recognition using distributed patterns of EEG signals with
cognitive functions. <em>NCA</em>, <em>37</em>(10), 7451. (<a
href="https://doi.org/10.1007/s00521-020-05439-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhao, Jianyu and Li, Ke and Xi, Xi and Wang, Shanshan and Saravanan, Vijayalakshmi and Samuel, R. Dinesh Jackson},
  doi          = {10.1007/s00521-020-05439-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7451},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Analysis of complex cognitive task and pattern recognition using distributed patterns of EEG signals with cognitive functions},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Leveraging large language models for word sense
disambiguation. <em>NCA</em>, <em>37</em>(10), 7449–7450. (<a
href="https://doi.org/10.1007/s00521-025-11082-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yae, Jung H. and Skelly, Nolan C. and Ranly, Neil C. and LaCasse, Phillip M.},
  doi          = {10.1007/s00521-025-11082-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7449-7450},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Leveraging large language models for word sense disambiguation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Securing IIoT operations with recurrent
federated network-based enhanced local search grasshopper. <em>NCA</em>,
<em>37</em>(10), 7447. (<a
href="https://doi.org/10.1007/s00521-024-10907-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Alassafi, Madini O.},
  doi          = {10.1007/s00521-024-10907-7},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7447},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Securing IIoT operations with recurrent federated network-based enhanced local search grasshopper},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Software effort estimation using convolutional
neural network and fuzzy clustering. <em>NCA</em>, <em>37</em>(10),
7445. (<a href="https://doi.org/10.1007/s00521-024-10906-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Azzeh, Mohammad and Alkhateeb, Abedalrhman and Nassif, Ali Bou},
  doi          = {10.1007/s00521-024-10906-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7445},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Software effort estimation using convolutional neural network and fuzzy clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: An artificial intelligence strategy for the
deployment of future microservice-based applications in 6G networks.
<em>NCA</em>, <em>37</em>(10), 7443. (<a
href="https://doi.org/10.1007/s00521-024-10754-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ssemakula, John Bosco and Gorricho, Juan-Luis and Kibalya, Godfrey and Serrat-Fernandez, Joan},
  doi          = {10.1007/s00521-024-10754-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7443},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: An artificial intelligence strategy for the deployment of future microservice-based applications in 6G networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CONELPABO: Composite networks learning via parallel bayesian
optimization to predict remaining useful life in predictive maintenance.
<em>NCA</em>, <em>37</em>(10), 7423–7441. (<a
href="https://doi.org/10.1007/s00521-025-10995-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintaining equipment and machinery in industries is imperative for maximizing operational efficiency and prolonging their lifespan. The adoption of predictive maintenance enhances resource allocation, productivity, and product quality by proactively identifying and addressing potential equipment anomalies through rigorous data analysis before they escalate into critical issues. Consequently, these measures strengthen market competitiveness and generate favorable economic outcomes. In many applications, sensors operate at high frequencies or capture data over extended periods. This work introduces CONELPABO (Composite Networks Learning via Parallel Bayesian Optimization), a framework for analyzing long time series data, particularly for predicting the remaining useful life of a system or component. It uses a divide-and-conquer strategy to manage the exponential growth in the hyperparameter search space during Bayesian Optimization and to accelerate model training by 50%. Additionally, this strategy enables the training of deeper networks with limited resources. The usefulness of the framework is demonstrated through two case studies, in which it achieves state-of-the-art results, showing that CNN-CNN and RNN-RNN architectures are highly effective for long time-series data. These architectures outperform many existing approaches and challenge the common academic focus on CNN-RNN hybrids.},
  archive      = {J_NCA},
  author       = {Solís-Martín, David and Galán-Páez, Juan and Borrego-Díaz, Joaquín},
  doi          = {10.1007/s00521-025-10995-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7423-7441},
  shortjournal = {Neural Comput. Appl.},
  title        = {CONELPABO: Composite networks learning via parallel bayesian optimization to predict remaining useful life in predictive maintenance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic economic dispatch with uncertain wind power
generation using an enhanced artificial hummingbird algorithm.
<em>NCA</em>, <em>37</em>(10), 7397–7422. (<a
href="https://doi.org/10.1007/s00521-025-10982-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimum scheduling of the conventional thermal generators for three different dynamic test systems is percolated in this article. In pursuit of this objective, a developed version of a recent optimization algorithm, denoted as the leader artificial hummingbird algorithm, is introduced. The profile with the largest penetration of wind energy is obtained by calculating wind power from hourly wind speed using the Weibull distribution density function. After that, the test system and the wind profiles were connected to carry out dynamic economic dispatch (DED). The DED problem with wind uncertainty poses important challenges because of its complication, considered by multiple constraints including ramp rate limits and the valve-point effects (VPEs), nonconvexity, and nonlinearity, as well as the uncertainty of the wind energy. These complications make it critical to discover innovative optimization algorithms to find optimum solutions for the DED problem. First, in order to demonstrate the validity of the suggested LAHA approach in comparison with four contemporary techniques, simulations are run on 23 benchmark functions. Next, the 5-unit, 10-unit with/without transmission losses, 15-unit, modified 10-unit with transmission losses, and wind power test systems are used to evaluate the LAHA’s performance. The numerical results demonstrate how competitive the suggested approach is in reaching reduced total generation cost when compared to the other documented optimization algorithms.},
  archive      = {J_NCA},
  author       = {Hassan, Mohamed H. and Mohamed, Ehab Mahmoud and Kamel, Salah and Eslami, Mahdiyeh},
  doi          = {10.1007/s00521-025-10982-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7397-7422},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic economic dispatch with uncertain wind power generation using an enhanced artificial hummingbird algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoML for shape-writing biometrics. <em>NCA</em>,
<em>37</em>(10), 7379–7396. (<a
href="https://doi.org/10.1007/s00521-025-10983-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape-writing is a text entry method that allows users to type words on mobile devices by gliding their finger across the keyboard from one character to the next. This creates a trajectory of touch coordinates that contains rich information about the user. Previous work exploited this information to create Machine Learning (ML) models to predict demographic and behavioral targets, such as age, nationality, or handedness. However, previous work used pseudo-grid search, which is a bit tedious and rather inefficient. We show how to find better models with Automated Machine Learning (AutoML), by completely automating the architecture design process, outperforming all models reported in previous work. Our study suggests that researchers should incorporate AutoML to their training pipelines, as classification performance will likely be better than manually designing the model architecture. Taken together, our results show that it is possible to decode user’s latent information from shape-writing trajectories with higher performance than previously reported.},
  archive      = {J_NCA},
  author       = {Weber, Louis and Leiva, Luis A.},
  doi          = {10.1007/s00521-025-10983-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7379-7396},
  shortjournal = {Neural Comput. Appl.},
  title        = {AutoML for shape-writing biometrics},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing facial expression recognition in uncontrolled
environment: A lightweight CNN approach with pre-processing.
<em>NCA</em>, <em>37</em>(10), 7363–7378. (<a
href="https://doi.org/10.1007/s00521-025-10974-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expressions play a key role in human non-verbal type of communication, providing key insights into emotions and intentions. These expressions serve as universal signals, helping individuals convey their internal states across various personal and social contexts. With the growing interest in automatic facial emotion recognition, deep neural networks have emerged as a popular approach for detecting human emotions, even under challenging, real-world conditions. However, external factors can affect the system&#39;s performance, degrading the quality of facial features and making emotion detection more difficult. In the presented paper, we propose a highly optimized lightweight convolutional neural network (LCNN) for emotion recognition in controlled and uncontrolled environments. The proposed model is designed to learn hidden nonlinear patterns from facial images. The proposed convolutional neural network consisting a series of convolutional layers followed by max-pooling layers. The model&#39;s performance is evaluated with and without pre-processing steps to highlight the importance of pre-processing in improving detection accuracy. The LCNN achieves 65% accuracy on the FER-2013 dataset and 98% on the CK + dataset.},
  archive      = {J_NCA},
  author       = {Grover, Richa and Bansal, Sandhya},
  doi          = {10.1007/s00521-025-10974-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7363-7378},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing facial expression recognition in uncontrolled environment: A lightweight CNN approach with pre-processing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing electroencephalogram signal quality in epileptic
patients using bidirectional stochastic long short-term memory network.
<em>NCA</em>, <em>37</em>(10), 7339–7361. (<a
href="https://doi.org/10.1007/s00521-025-10977-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artifacts frequently disrupt electroencephalogram (EEG) signal recordings, originating from diverse sources such as eye-blinks and muscle twitches. These artifacts present significant challenges when employing automated systems for diagnosing neurological disorders. In this research, we introduce an innovative architectural solution designed to effectively eliminate these artifacts from EEG signals acquired from individuals with epilepsy. Our proposed framework combines bidirectional long short-term memory networks with bidirectional stochastic configuration networks (BSCN). This integration empowers the model to discern intricate patterns within both past and future time steps of the EEG signal. Furthermore, the non-iterative training characteristic of the BSCN-based classifier enhances training efficiency. To assess the effectiveness of our approach, we conducted experiments on four epilepsy datasets and a sleep dataset. The performance of our novel technique was evaluated using a range of performance metrics, and the results unequivocally indicate its superiority over existing artifact removal methods.},
  archive      = {J_NCA},
  author       = {Pandey, Anviti and Singh, Sanjay Kumar and Udmale, Sandeep S. and Shukla, K. K.},
  doi          = {10.1007/s00521-025-10977-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7339-7361},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing electroencephalogram signal quality in epileptic patients using bidirectional stochastic long short-term memory network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel human actions recognition and classification using
semantic segmentation with deep learning techniques. <em>NCA</em>,
<em>37</em>(10), 7321–7337. (<a
href="https://doi.org/10.1007/s00521-024-10962-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel method for recognizing human actions through the semantic segmentation of images. The aim is to enhance action-motion dynamics by directing attention toward regions crucial for action recognition. The proposed approach utilizes a SegNet model with an incorporated attention mechanism and modified bidirectional gated recurrent unit (BiGRU) backbone. The process begins with the generation of binary masks for each frame in a video dataset, achieved through a combination of grayscale conversion, Gaussian blurring, and adaptive thresholding. The emphasis on crucial regions for action recognition and capturing temporal variations is heightened through the application of the frame-ranking method. In our experiments, we observed that the proposed method significantly enhances the dynamics of the action-motion representation. The SegNet architecture was designed for semantic segmentation tasks and features an encoder-decoder architecture. In this structure, the model performs hierarchical feature extraction from the input image via the encoder, whereas the decoder focuses on reconstructing the segmented output. Attention is paid to the encoded feature maps, augmenting the model&#39;s capability to capture dependencies over extensive spatial ranges. A bidirectional GRU layer is employed to capture the sequential dependencies in the concatenated feature maps. The integration of the SegNet model with the attention mechanism and a BiGRU backbone, featuring an encoder-decoder architecture for feature extraction, classification, and segmentation, demonstrated superior performance in capturing nuanced spatiotemporal features. The proposed method demonstrated an accuracy of 98.52% for UCF101 and 84.25% for HMDB51. The findings reveal that the model achieves state-of-the-art results in human action recognition tasks, outperforming the existing methods in terms of accuracy. The combination of semantic segmentation and BiGRU-based temporal modeling proved effective in discerning intricate patterns of human motion, showcasing its potential for real-world applications in video analysis and surveillance systems.},
  archive      = {J_NCA},
  author       = {Jayamohan, M. and Yuvaraj, S.},
  doi          = {10.1007/s00521-024-10962-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7321-7337},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel human actions recognition and classification using semantic segmentation with deep learning techniques},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-synchronization analysis of heterogeneous neural
networks with multiple delays under impulsive control. <em>NCA</em>,
<em>37</em>(10), 7303–7319. (<a
href="https://doi.org/10.1007/s00521-024-10948-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the quasi-synchronization of impulsive controlled heterogeneous dynamic neutral networks with time-varying delay, distributed delays and proportional delay is discussed. Compared with the existing literature, the significant advantage of this paper is that all three types of delays are taken into account. Here we consider time-varying delay depending on probability distribution conditions, so the results of this paper also rely on the problem of probability distribution of time-varying delay. By establishing a suitable comparison system, creating a new kind of impulsive delay inequality and applying Bernoulli distributions and Lyapunov theory, some conditions to realize quasi-synchronization of heterogeneous neural networks are studied. Finally we illustrate the validity of our theorem with numerical examples.},
  archive      = {J_NCA},
  author       = {Wang, Qing and Guo, Yingxin and Zhang, Chuan and Fu, Jianting},
  doi          = {10.1007/s00521-024-10948-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7303-7319},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quasi-synchronization analysis of heterogeneous neural networks with multiple delays under impulsive control},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced model for abstractive arabic text summarization
using natural language generation and named entity recognition.
<em>NCA</em>, <em>37</em>(10), 7279–7301. (<a
href="https://doi.org/10.1007/s00521-024-10949-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of Arabic digital content, effective summarization methods are essential. Current Arabic text summarization systems face challenges such as language complexity and vocabulary limitations. We introduce an innovative framework using Arabic Named Entity Recognition to enhance abstractive summarization, crucial for NLP applications like question answering and knowledge graph construction. Our model, based on natural language generation techniques, adapts to diverse datasets. It identifies key information, synthesizes it into coherent summaries, and ensures grammatical accuracy through deep learning. Evaluated on the EASC dataset, our model achieved a 74% ROUGE1 score and a 97.6% accuracy in semantic coherence, with high readability and relevance scores. This sets a new standard for Arabic text summarization, greatly improving NLP information processing.},
  archive      = {J_NCA},
  author       = {Essa, Nada and El-Gayar, M. M. and El-Daydamony, Eman M.},
  doi          = {10.1007/s00521-024-10949-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7279-7301},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced model for abstractive arabic text summarization using natural language generation and named entity recognition},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-light few-shot object detection via curve contrast
enhancement and flow-encoder-based variational autoencoder.
<em>NCA</em>, <em>37</em>(10), 7261–7278. (<a
href="https://doi.org/10.1007/s00521-024-10885-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem of insufficient samples in low-light object detection in some environments, a low-light few-shot object detection method based on curve contrast enhancement and flow-encoder-based variational autoencoder (CCEFVAE) is proposed. Our approach involves designing a CCE module to enhance the detailed features and contrast of low-light images by deriving a relationship expression between the enhanced image and the low-light image through the recursive relationship of high-order curves. The lumination estimation module in the CCE module estimates the parameters of the expression to calculate the pixel values of the enhanced image. Moreover, we propose an FVAE module to improve the decoupling of support features by combining the flow model encoder with the variational autoencoder, facilitating subsequent feature aggregation and classification. To ensure the consistency of the loss function of the flow model with the few-shot object detection loss, we design a negative Jacobian determinant transformation function. This enables direct addition of the two losses, allowing for unified optimization. Experimental results demonstrate that our proposed algorithm outperforms mainstream few-shot object detection models by an average of 13.1–23% in average after training on the low-light dataset (ExDark), and shows an average improvement of 5.8% compared to the state-of-the-art (SOTA) few-shot object detection model VFA. When trained on the normal lighting dataset (PASCAL VOC), the proposed algorithm exhibits a 1.7% improvement in average compared to VFA.},
  archive      = {J_NCA},
  author       = {Jiang, Zetao and Jin, Xin and Kang, Junjie},
  doi          = {10.1007/s00521-024-10885-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7261-7278},
  shortjournal = {Neural Comput. Appl.},
  title        = {Low-light few-shot object detection via curve contrast enhancement and flow-encoder-based variational autoencoder},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supercell thunderstorm algorithm (STA): A nature-inspired
metaheuristic algorithm for engineering optimization. <em>NCA</em>,
<em>37</em>(10), 7207–7260. (<a
href="https://doi.org/10.1007/s00521-024-10848-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an optimization algorithm called supercell thunderstorm algorithm (STA) is proposed. STA draws inspiration from the strategies employed by storms, such as spiral motion, tornado formation, and the jet stream. It is a computational algorithm specifically designed to simulate and model the behavior of supercell thunderstorms. These storms are known for their rotating updrafts, strong wind shear, and potential for generating tornadoes. The optimization procedures of the STA algorithm are based on three distinct approaches: exploring a divergent search space using spiral motion, exploiting a convergent search space through tornado formation, and navigating through the search space with the aid of the jet stream. To evaluate the effectiveness of the proposed STA algorithm in achieving optimal solutions for various optimization problems, a series of test sequences were conducted. Initially, the algorithm was tested on a set of 23 well-established functions. Subsequently, the algorithm’s performance was assessed on more complex problems, including ten CEC2019 test functions, in the second experimental sequence. Finally, the algorithm was applied to five real-world engineering problems to validate its effectiveness. The experimental results of the STA algorithm were compared to those of contemporary metaheuristic methods. The analysis clearly demonstrates that the developed STA algorithm outperforms other methods in terms of performance.},
  archive      = {J_NCA},
  author       = {Hassan, Mohamed H. and Kamel, Salah},
  doi          = {10.1007/s00521-024-10848-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7207-7260},
  shortjournal = {Neural Comput. Appl.},
  title        = {Supercell thunderstorm algorithm (STA): A nature-inspired metaheuristic algorithm for engineering optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond administrative reports: A deep learning framework for
classifying and monitoring crime and accidents leveraging large-scale
online news. <em>NCA</em>, <em>37</em>(10), 7183–7205. (<a
href="https://doi.org/10.1007/s00521-024-10833-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating prevalence of violent crimes and accidents underscores the urgent need for efficient and timely monitoring systems. Traditional methods reliant on administrative reports often suffer from significant delays. This paper proposes CRIMSON, a novel framework that leverages large-scale online news to provide real-time insights into crime and accident trends. CRIMSON utilizes a multi-label classification technique that leverages a fine-tuned, pre-trained, cross-lingual language model to accurately categorize news articles. Our experimental results, conducted on a substantial dataset of Thai news articles, demonstrate superior performance, achieving an average F1 score of 86%. Beyond classification, CRIMSON aggregates categorized news into real-time statistics, revealing strong correlations between news-reported incidents and official crime data. This study pioneers online news as a reliable and timely crime and accident monitoring source, offering valuable insights for law enforcement, policymakers, and researchers.},
  archive      = {J_NCA},
  author       = {Tuarob, Suppawong and Tatiyamaneekul, Phonarnun and Pongpaichet, Siripen and Tawichsri, Tanisa and Noraset, Thanapon},
  doi          = {10.1007/s00521-024-10833-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7183-7205},
  shortjournal = {Neural Comput. Appl.},
  title        = {Beyond administrative reports: A deep learning framework for classifying and monitoring crime and accidents leveraging large-scale online news},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GP-PSENet: A group-related dilated and a parallel
extensional dilation-wise residual encoder for scene text detection.
<em>NCA</em>, <em>37</em>(10), 7159–7181. (<a
href="https://doi.org/10.1007/s00521-024-10688-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, scene text detection is grabbing more and more attention as an offshoot of machine vision. However, due to the existing long types of text instances and complex background context, less exact localization and higher missed detection cases still remain in text detection domain. Accordingly, with the aim of tackling these two issues, we propose a text detector named GP-PSENet that comprises a combination of a group-related dilated encoder, a parallel extensional dilation-wise residual encoder and a mixed upsample. Firstly, feature maps of the lowest level processed by the backbone network are sent to a dilated encoder with group linkage. And the group residual module provides stratification to join group coefficients and dilated factors. This module can enhance the correctness of predictions about longer boundary boxes. Secondly, semantic information from the highest level is fed into a parallel extensional dilation-wise residual encoder. The extensional dilation-wise module is capable of obtaining diverse receptive fields by more parallel branches. And it can alleviate error detection from interfering material in the background. Thirdly, the feature maps processed in the second step are given to the mixed upsample module for transforming so as to the next fuse. Finally, the processed two-level feature maps are fused and sent to the progressive scale expansion algorithm for the final post-processing to gain the predicted coordinate points. Ablation experiments are conducted on CTW1500, ICDAR15, MSRA-TD500 and Total-Text datasets to confirm the availability of the proposed method. The values of precision on these datasets reach 86.24%, 87.84%, 73.98% and 90.48%. The proposed method is also competitive with other scene detection methods.},
  archive      = {J_NCA},
  author       = {Huang, Liwen and Yang, Wenyuan},
  doi          = {10.1007/s00521-024-10688-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7159-7181},
  shortjournal = {Neural Comput. Appl.},
  title        = {GP-PSENet: A group-related dilated and a parallel extensional dilation-wise residual encoder for scene text detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time optimal energy management of microgrid based on
multi-agent proximal policy optimization. <em>NCA</em>, <em>37</em>(10),
7145–7157. (<a
href="https://doi.org/10.1007/s00521-024-10654-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to achieve economic operation of the microgrid (MG), energy management problem (EMP) has attracted attention from scholars worldwide. In order to overcome the lack of flexibility when coping with uncertainties and topology changes, a multi-agent based proximal policy optimization algorithm (MAPPO) is proposed in this paper. Different from the offline training and online implementing mode, the proposed decentralized MAPPO algorithm has the characteristic of online training and online application, which can get higher optimization efficiency and lower communication burden. Taking into account users’ satisfaction, renewable energy utilization rate and operating costs, an optimization model is established. Aiming at the difficulty on satisfying the power balance constraint in EMPU using reinforcement learning (RL), a novel power imbalance penalty is designed. Compared with the traditional penalty function, the proposed penalty function can effectively avoid the phenomenon of power imbalance. Finally, 24-hour energy management results are provided to verify the effectiveness of the proposed algorithm. Moreover, the proposed MAPPO is compared with several popular multi-agent based RL algorithms. Simulation results show that the proposed algorithm has higher efficiency and can obtain better energy management strategies.},
  archive      = {J_NCA},
  author       = {Wang, Danlu and Sun, Qiuye and Su, Hanguang},
  doi          = {10.1007/s00521-024-10654-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7145-7157},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time optimal energy management of microgrid based on multi-agent proximal policy optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal consistent loss diffusion model for sentinel-3
single image super resolution. <em>NCA</em>, <em>37</em>(10), 7121–7143.
(<a href="https://doi.org/10.1007/s00521-024-10573-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of Earth observation, the trade-off between spatial, spectral, and temporal resolution often limits the versatility of remote sensing images in many important applications. In response, this paper introduces a novel deep learning diffusion model, specifically tailored to improve the spatial resolution of the optical products acquired by the Sentinel-3 (S3) satellite. Our framework employs a diffusion probabilistic model, benefiting from the higher spatial resolution of the Sentinel-2 satellite during training via a new multi-modal loss formulation. This ensures consistency with the original S3 images while enhancing the spatial details. Two distinct conditional low-resolution encoders were experimented with, providing insights into their respective contributions to the diffusion process. The efficacy of the proposed model is demonstrated through extensive ablation studies and comparisons with state-of-the-art methods, using both synthetic and real S3 products. The findings indicate that our model successfully improves spatial resolution while maintaining the integrity of the spectral information, contributing to the field of remote sensing single-image super-resolution.},
  archive      = {J_NCA},
  author       = {Ibañez, Damian and Fernandez-Beltran, Ruben and Pla, Filiberto and Yokoya, Naoto and Xia, Junshi},
  doi          = {10.1007/s00521-024-10573-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7121-7143},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-modal consistent loss diffusion model for sentinel-3 single image super resolution},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic generative r-CNN. <em>NCA</em>, <em>37</em>(10),
7107–7120. (<a
href="https://doi.org/10.1007/s00521-024-10739-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different techniques have been developed for object detection and recognition. These techniques can be divided into single-shot and two-shot methods. Single-shot methods focus on real-time applications, while two-shot methods are used in applications requiring higher accuracy. However, different versions of the two-shot techniques produce limited results in terms of accuracy and speed, or both. Therefore, this study proposes a novel model called dynamic generative R-CNN (DGR-CNN) that reduces the number of proposed regions using a dynamic programming model that applies the graph similarity method over graph-based image segmentation. Additionally, the proposed model employs DCGAN technique to improve detection performance. DGR-CNN reduces the overall detection and classification time and enhances the detection accuracy. The PASCAL VOC2007 and MS COCO datasets were utilized to evaluate the model. The results showed that DGR-CNN significantly reduces the number of candidate regions compared to the selective search algorithm employed in R-CNN and fast R-CNN. Although fast R-CNN utilizes 2000 regions and faster R-CNN utilizes 300 regions, DGR-CNN reduces the number of regions to approximately 130. The mean average precision of the proposed method was 75.1% on the PASCAL VOC2007, while fast and faster R-CNN scored 66.9% and 69.9%, respectively. Moreover, the DGR-CNN model significantly improved the classification accuracy when tested on the MS COCO dataset, achieving an MAP of 68.76%, compared with 32.64% and 42.3% for fast and faster R-CNN. This increase in accuracy was achieved without significantly compromising the speed compared with faster R-CNN.},
  archive      = {J_NCA},
  author       = {Saffarini, Rasha and Khamayseh, Faisal and Awwad, Yousef and Sabha, Muath and Eleyan, Derar},
  doi          = {10.1007/s00521-024-10739-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7107-7120},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic generative R-CNN},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing a continuous action learning automata (CALA)
optimizer for training artificial neural networks. <em>NCA</em>,
<em>37</em>(10), 7089–7105. (<a
href="https://doi.org/10.1007/s00521-024-10546-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep artificial neural networks (ANNs) get bigger, deeper, and used in more challenging applications, the need for non-gradient based training methods becomes more desirable. This paper explores a new non-gradient-based method to train ANNs and deep ANNs, the Continuous Action Learning Automata (CALA) optimizer. The CALA optimizer assigns a Learning Automata agent to every weight in a neural network and uses game theory to coordinate actions of the agents. We show that the CALA optimizer is computationally efficient, that it converges to a desired error rate faster than current gradient-based methods like stochastic gradient descent (SGD) and show how one could use a Finite Action Learning Automata (FALA) algorithm to find optimal values for the hyper-parameters required to optimize the CALA controller. The CALA method contrasts itself against other non-gradient methods in that it approaches the computational efficiency of top gradient descent methods like SGD. The CALA method converges fast, and there is any easy-to-follow algorithm to tune the hyper-parameters of the algorithm. These advantages address weaknesses that other non-gradient methods suffer from. Therefore, the CALA controller has the potential to see far greater implementation than other non-gradient-based optimization methods for training deep ANNs.},
  archive      = {J_NCA},
  author       = {Lindsay, James and Givigi, Sidney},
  doi          = {10.1007/s00521-024-10546-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7089-7105},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing a continuous action learning automata (CALA) optimizer for training artificial neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive dual-weighted feature network for insulator
detection in transmission lines. <em>NCA</em>, <em>37</em>(10),
7067–7087. (<a
href="https://doi.org/10.1007/s00521-024-10957-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of electrical power applications, high-voltage insulators necessitate routine inspection to assure the security and stability of the whole electric power system operation. Accurately positioning the insulator is extremely crucial for proceeding to the insulator defect detection. However, during UAV electrical line inspection, the presence of the electric power line magnetic field engenders a reduction in the pixel representation of the insulator within the image data, thereby diminishing the accuracy of insulator detection. In response to the prevailing issues, we present the creation of the adaptive dual-weighted feature network in this paper. Simultaneously, we create an insulator dataset to substantiate the effectiveness of enhanced model in detecting small insulators. Firstly, the integration of context fusion network is employed to capture comprehensive contextual features for each effective feature map. In addition, a cross-scale residual perception network is incorporated into the neck prior to three concatenation modules, facilitating the collection of diverse information across levels. Finally, a Dual-Weighted Feature Fusion module is designed to replace the conventional concatenation pattern within the neck, thus achieving a more precise representation of object features. Experiments are conducted on the insulator dataset, the RSOD dataset and the NWPU VHR-10 dataset to evaluate the designed model, resulting in mAP values that were 3.92%, 1.55% and 2.39% higher than the YOLOv7, respectively.},
  archive      = {J_NCA},
  author       = {Zhang, Jie and Wang, Xiabing and Li, Yinhua and Li, Dailin and Wang, Fengxian and Li, Linwei and Zhang, Huanlong and Shi, Xiaoping},
  doi          = {10.1007/s00521-024-10957-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7067-7087},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive dual-weighted feature network for insulator detection in transmission lines},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward better semantic segmentation by retaining spectral
information using matched wavelet pooling. <em>NCA</em>,
<em>37</em>(10), 7049–7066. (<a
href="https://doi.org/10.1007/s00521-025-11008-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pooling operations, such as average pooling, strided convolution, and max pooling, have become fundamental components of convolutional neural networks (CNNs) due to their ability to capture local features, expand receptive fields, and reduce computational costs. However, in the context of semantic segmentation, these pooling techniques can lead to the loss of crucial spatial details that are necessary for accurate pixel-level predictions. To tackle this issue, extensive research has focused on refining deep CNN models through architectural adaptations and novel training methods. Recent studies have demonstrated the importance of pooling layers, exemplified by innovations like the introduction of wavelet pooling. In our study, we highlight the value of incorporating our previously proposed matched wavelet pooling (MWP) into CNNs to enhance semantic segmentation pipelines. The core concept of MWP challenges the notion that including all sub-bands generated from wavelet decomposition consistently improves accuracy. Instead, we advocate for selecting specific sub-bands for the pooling process in each image during both training and testing. This approach introduces sub-band selection protocols customized for image-specific pooling, designed specifically for semantic segmentation CNN architectures, with a particular focus on the UNet and SegNet models. Across three widely used datasets, our proposed MWP- based pipeline, featuring the MWP-UNet architecture, consistently outperforms conventional pooling methods. It achieves a significant average improvement in intersection over union (IoU) of over 25% compared to recent literature. Additionally, our MWP-SegNet model outperformed the standard SegNet by 12.5% mIoU, further demonstrating the effectiveness of our matched wavelet pooling approach across different network architectures.},
  archive      = {J_NCA},
  author       = {El-Khamy, Said and El-Bana, Shimaa and Al-Kabbany, Ahmad and Elragal, Hassan},
  doi          = {10.1007/s00521-025-11008-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7049-7066},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward better semantic segmentation by retaining spectral information using matched wavelet pooling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on arabic text augmentation:
Approaches, challenges, and applications. <em>NCA</em>, <em>37</em>(10),
7015–7048. (<a
href="https://doi.org/10.1007/s00521-025-11020-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arabic is a linguistically complex language with a rich structure and valuable syntax that pose unique challenges for natural language processing (NLP), primarily due to the scarcity of large, reliable annotated datasets essential for training models. The varieties of dialects and mixtures of more than one language within a single conversation further complicate the development and efficacy of deep learning models targeting Arabic. Data augmentation (DA) techniques have emerged as a promising solution to tackle data scarcity and improve model performance. However, implementing DA in Arabic NLP presents its challenges, particularly in maintaining semantic integrity and adapting to the language’s intricate morphological structure. This survey comprehensively examines various aspects of Arabic data augmentation techniques, covering strategies for model training, methods for evaluating augmentation performance, understanding the effects and applications of augmentation on data, studying NLP downstream tasks, addressing augmentation problems, proposing solutions, conducting in-depth literature reviews, and drawing conclusions. Through detailed analysis of 75 primary and 9 secondary papers, we categorize DA methods into diversity enhancement, resampling, and secondary approaches, each targeting specific challenges inherent in augmenting Arabic datasets. The goal is to offer insights into DA effectiveness, identify research gaps, and suggest future directions for advancing NLP in Arabic.},
  archive      = {J_NCA},
  author       = {ElSabagh, Ahmed Adel and Azab, Shahira Shaaban and Hefny, Hesham Ahmed},
  doi          = {10.1007/s00521-025-11020-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7015-7048},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive survey on arabic text augmentation: Approaches, challenges, and applications},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding silent speech: A machine learning perspective on
data, methods, and frameworks. <em>NCA</em>, <em>37</em>(10), 6995–7013.
(<a href="https://doi.org/10.1007/s00521-024-10456-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At the nexus of signal processing and machine learning (ML), silent speech recognition (SSR) has evolved as a game-changing technology that allows for communication without audible voice. This study offers a thorough overview of SSR, tracing its evolution from early waveform analysis to the most recent ML methods. We start by examining current SSR techniques using ML and determining the essential conditions for efficient SSR systems. After that, we look at the datasets and data collection techniques currently employed in SSR research, highlighting the difficulties posed by the variety of articulatory movements and the scarcity of data. Examining state-of-the-art SSR frameworks, the paper covers important topics such signal processing, feature extraction, ML techniques for decoding and optimizing and assessing the performance of SSR models. We emphasize how deep learning (DL) and ML models have evolved to increase SSR resilience and accuracy. The field&#39;s proposed procedures are examined, with an emphasis on sophisticated feature extraction and classification methods. Modern SSR techniques are compared in terms of performance, highlighting the advantages and disadvantages of different models. There is also discussion of ethical issues, especially those pertaining to privacy and consent. The integration of multimodal information—visual cues, electromyography signals, and neuroimaging data—to improve SSR systems is covered in this work. We investigate the functions of transfer learning and domain adaptation in handling cross-subject variability. Lastly, the study offers suggestions and future prospects for SSR research, providing practitioners, engineers, and academics with a road map. As SSR continues to push the frontiers of human–machine interaction, our study aims to increase our collective understanding of the technological advances and societal effects of SSR in the ML age.},
  archive      = {J_NCA},
  author       = {Chowdhury, Adiba Tabassum and Newaz, Mehrin and Saha, Purnata and AbuHaweeleh, Mohannad Natheef and Mohsen, Sara and Bushnaq, Diala and Chabbouh, Malek and Aljindi, Raghad and Pedersen, Shona and Chowdhury, Muhammad E. H.},
  doi          = {10.1007/s00521-024-10456-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {6995-7013},
  shortjournal = {Neural Comput. Appl.},
  title        = {Decoding silent speech: A machine learning perspective on data, methods, and frameworks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
