<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>springer_all</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h1 id="springer">SPRINGER</h1>
<h2 id="aamas---22">AAMAS - 22</h2>
<ul>
<li><details>
<summary>
(2025). Epistemic selection of costly alternatives: The case of
participatory budgeting. <em>AAMAS</em>, <em>39</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10458-024-09677-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate the study of voting rules for participatory budgeting using the so-called epistemic approach, where one interprets votes as noisy reflections of some ground truth regarding the objectively best set of projects to fund. Using this approach, we first show that both the most studied rules in the literature and the most widely used rule in practice cannot be justified on epistemic grounds: they cannot be interpreted as maximum likelihood estimators, whatever assumptions we make about the accuracy of voters. Focusing then on welfare-maximising rules, we obtain both positive and negative results regarding epistemic guarantees.},
  archive      = {J_AAMAS},
  author       = {Rey, Simon and Endriss, Ulle},
  doi          = {10.1007/s10458-024-09677-2},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Epistemic selection of costly alternatives: The case of participatory budgeting},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ability and knowledge: From epistemic transition systems to
labelled stit models. <em>AAMAS</em>, <em>39</em>(1), 1–41. (<a
href="https://doi.org/10.1007/s10458-024-09661-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is possible to know that one can guarantee a certain result and yet not know how to guarantee it. In such cases one has the ability to guarantee something in a causal sense, but not in an epistemic sense. In this paper we focus on two formalisms used to model both conceptions of ability: one formalism based on epistemic transition systems and the other on labelled stit models. We show a strong correspondence between the two formalisms by providing mappings from the former to the latter for both the languages and the structures. Moreover, we demonstrate that our extension of labelled stit logic is more expressive than the logic of epistemic transition systems.},
  archive      = {J_AAMAS},
  author       = {Kuncová, Alexandra and Broersen, Jan and Duijf, Hein and Ramírez Abarca, Aldo Iván},
  doi          = {10.1007/s10458-024-09661-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-41},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Ability and knowledge: From epistemic transition systems to labelled stit models},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information gathering in POMDPs using active inference.
<em>AAMAS</em>, <em>39</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s10458-024-09683-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gathering information about the environment state is the main goal in several planning tasks for autonomous agents, such as surveillance, inspection and tracking of objects. Such planning tasks are typically modeled using a Partially Observable Markov Decision Process (POMDP), and in the literature several approaches have emerged to consider information gathering during planning and execution. Similar developments can be seen in the field of active inference, which focuses on active information collection in order to be able to reach a goal. Both fields use POMDPs to model the environment, but the underlying principles for action selection are different. In this paper we create a bridge between both research fields by discussing how they relate to each other and how they can be used for information gathering. Our contribution is a tailored approach to model information gathering tasks directly in the active inference framework. A series of experiments demonstrates that our approach enables agents to gather information about the environment state. As a result, active inference becomes an alternative to common POMDP approaches for information gathering, which opens the door towards more cross cutting research at the intersection of both fields. This is advantageous, because recent advancements in POMDP solvers may be used to accelerate active inference, and the principled active inference framework may be used to model POMDP agents that operate in a neurobiologically plausible fashion.},
  archive      = {J_AAMAS},
  author       = {Walraven, Erwin and Sijs, Joris and Burghouts, Gertjan J.},
  doi          = {10.1007/s10458-024-09683-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Information gathering in POMDPs using active inference},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aggregating bipolar opinions through bipolar
assumption-based argumentation. <em>AAMAS</em>, <em>39</em>(1), 1–34.
(<a href="https://doi.org/10.1007/s10458-024-09684-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel method to aggregate bipolar argumentation frameworks expressing opinions of different parties in debates. We use Bipolar Assumption-based Argumentation (ABA) as an all-encompassing formalism for bipolar argumentation under different semantics. By leveraging on recent results on judgement aggregation in social choice theory, we prove several preservation results for relevant properties of bipolar ABA using quota and oligarchic rules. Specifically, we prove (positive and negative) results about the preservation of conflict-free, closed, admissible, preferred, complete, set-stable, well-founded and ideal extensions in bipolar ABA, as well as the preservation of acceptability, acyclicity and coherence for individual assumptions. Finally, we illustrate our methodology and results in the context of a case study on opinion aggregation for the treatment of long COVID patients.},
  archive      = {J_AAMAS},
  author       = {Dickie, Charles and Lauren, Stefan and Belardinelli, Francesco and Rago, Antonio and Toni, Francesca},
  doi          = {10.1007/s10458-024-09684-3},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Aggregating bipolar opinions through bipolar assumption-based argumentation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). La VIDA: Towards a motivated goal reasoning agent.
<em>AAMAS</em>, <em>39</em>(1), 1–36. (<a
href="https://doi.org/10.1007/s10458-024-09685-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An autonomous agent deployed to operate over extended horizons in uncertain environments will encounter situations for which it was not designed. A class of these situations involves an invalidation of agent goals and limited guidance in establishing a new set of goals to pursue. An agent will benefit from some mechanism that will allow it to pursue new goals under these circumstances such that the goals are broadly useful in its environment and take advantage of its existing skills while aligning with societal norms. We propose augmenting a goal reasoning agent, i.e., an agent that can deliberate on and self-select its goals, with a motivation system that can be used to both constrain and motivate agent behavior. A human-like motivation system coupled with a goal-self concordant selection technique allows the approach to be framed as an optimization problem in which the agent selects goals that have high utility while simultaneously in harmony with its motivations. Over the agent’s operational lifespan its motivation system adjusts incrementally to more closely reflect the reality of its goal reasoning and goal pursuit experiences. Experiments performed with an ablation testing technique comparing the average utility of goals achieved in the presence and absence of a motivation system suggest that the motivated version of the system leads to pursuing more useful goals than the baseline.},
  archive      = {J_AAMAS},
  author       = {Addison, Ursula},
  doi          = {10.1007/s10458-024-09685-2},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {La VIDA: Towards a motivated goal reasoning agent},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Budget-feasible egalitarian allocation of conflicting jobs.
<em>AAMAS</em>, <em>39</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10458-024-09686-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Allocating conflicting jobs among individuals while respecting a budget constraint for each individual is an optimization problem that arises in various real-world scenarios. In this paper, we consider the situation where each individual derives some satisfaction from each job. We focus on finding a feasible allocation of conflicting jobs that maximize egalitarian cost, i.e., the satisfaction of the individual who is worst-off. To the best of our knowledge, this is the first paper to combine egalitarianism, budget-feasibility, and conflict-freeness in allocations. We provide a systematic study of the computational complexity of finding budget-feasible conflict-free egalitarian allocation and show that our problem generalizes a large number of classical optimization problems. Therefore, unsurprisingly, our problem is NP-hard even for two individuals and when there is no conflict between any jobs. We show that the problem admits algorithms when studied in the realm of approximation algorithms and parameterized algorithms with a host of natural parameters that match and in some cases improve upon the running time of known algorithms.},
  archive      = {J_AAMAS},
  author       = {Gupta, Sushmita and Jain, Pallavi and Mohanapriya, A. and Tripathi, Vikash},
  doi          = {10.1007/s10458-024-09686-1},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Budget-feasible egalitarian allocation of conflicting jobs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reflexive anticipatory reasoning by BDI agents.
<em>AAMAS</em>, <em>39</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s10458-025-09687-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates how predictions about the future behaviour of an agent can be exploited to improve its decision-making in the present. Future states are foreseen by a simulation technique, which is based on models of both the environment and the agent. Although the environment model is usually taken into account for prediction in artificial intelligence (e.g., in automated planning), the agent model receives less attention. We leverage the agent model to speed up the simulation and as a source of alternative decisions. Our proposal bases the agent model on the practical knowledge the developer has given to the agent, especially in the case of BDI agents. This knowledge is thus exploited in the proposed future-concerned reasoning mechanisms. We present a prototype implementation of our approach as well as the results from its evaluation on static and dynamic environments. This allows us to better understand the relation between the improvement in agent decisions and the quality of the knowledge provided by the developer.},
  archive      = {J_AAMAS},
  author       = {Hübner, Jomi Fred and Burattini, Samuele and Ricci, Alessandro and Mayer, Simon},
  doi          = {10.1007/s10458-025-09687-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Reflexive anticipatory reasoning by BDI agents},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disagree and commit: Degrees of argumentation-based
agreements. <em>AAMAS</em>, <em>39</em>(1), 1–38. (<a
href="https://doi.org/10.1007/s10458-025-09688-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cooperative human decision-making, agreements are often not total; a partial degree of agreement is sufficient to commit to a decision and move on, as long as one is somewhat confident that the involved parties are likely to stand by their commitment in the future, given no drastic unexpected changes. In this paper, we introduce the notion of agreement scenarios that allow artificial autonomous agents to reach such agreements, using formal models of argumentation, in particular abstract argumentation and value-based argumentation. We introduce the notions of degrees of satisfaction and (minimum, mean, and median) agreement, as well as a measure of the impact a value in a value-based argumentation framework has on these notions. We then analyze how degrees of agreement are affected when agreement scenarios are expanded with new information, to shed light on the reliability of partial agreements in dynamic scenarios. An implementation of the introduced concepts is provided as part of an argumentation-based reasoning software library.},
  archive      = {J_AAMAS},
  author       = {Kampik, Timotheus and Nieves, Juan Carlos},
  doi          = {10.1007/s10458-025-09688-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Disagree and commit: Degrees of argumentation-based agreements},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-level explainability framework for engineering and
understanding BDI agents. <em>AAMAS</em>, <em>39</em>(1), 1–42. (<a
href="https://doi.org/10.1007/s10458-025-09689-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the complexity of software systems rises, explainability - i.e. the ability of systems to provide explanations of their behaviour - becomes a crucial property. This is true for any AI-based systems, including autonomous systems that exhibit decisionmaking capabilities such as multi-agent systems. Although explainabil- ity is generally considered useful to increase the level of trust for end-users, we argue it is also an interesting property for software engineers, developers, and designers to debug and validate the system’s behaviour. In this paper, we propose a multi-level explainability framework for BDI agents to generate explanations of a running system from logs at different levels of abstraction, tailored to different users and their needs. We describe the mapping from logs to explanations, and present a prototype tool based on the JaCaMo platform which implements the framework.},
  archive      = {J_AAMAS},
  author       = {Yan, Elena and Burattini, Samuele and Hübner, Jomi Fred and Ricci, Alessandro},
  doi          = {10.1007/s10458-025-09689-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-42},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A multi-level explainability framework for engineering and understanding BDI agents},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A formal testing method for multi-agent systems using
colored petri nets. <em>AAMAS</em>, <em>39</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s10458-025-09690-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomy in software, a system’s ability to make decisions and take actions independently without human intervention, is a fundamental characteristic of multi-agent systems. Testing, a crucial phase of software validation, is particularly challenging in multi-agent systems due to its complexity, as the interaction between autonomous agents can result in emergent behaviors and collective intelligence, leading to system properties not found in individual agents. A multi-agent system operates on at least three main dimensions: the individual level, the social level, and the communication interfaces. An organizational model formally defines a multi-agent system’s structure, roles, relationships, and interactions. It represents the social layer, capturing agents’ collective dynamics and dependencies, facilitating coherent and efficient collaboration to achieve individual and collective goals. During the literature review, a gap was identified when testing the social layer of multi-agent systems. This paper presents a testing approach by formally introducing steps to map an organizational model, here $$\mathcal {M}$$ oise $$^+$$ , into a colored Petri net. This mapping aims to generate a formal system model, which is used to generate and count test cases based on a coverage criterion. Finally, a use case called Inspector was presented to demonstrate the method by generating test cases, executing the test, and identifying execution errors.},
  archive      = {J_AAMAS},
  author       = {Machado, Ricardo Arend and Cardoso, Arthur da Silva Zelindro and Farias, Giovani Parente and Gonçalves, Eder Mateus Nunes and Adamatti, Diana Francisca},
  doi          = {10.1007/s10458-025-09690-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A formal testing method for multi-agent systems using colored petri nets},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An introduction to computational argumentation research from
a human argumentation perspective. <em>AAMAS</em>, <em>39</em>(1), 1–59.
(<a href="https://doi.org/10.1007/s10458-025-09692-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational Argumentation studies how human argumentative reasoning can be approached from a computational viewpoint. Human argumentation is a complex process that has been studied from different perspectives (e.g., philosophical or linguistic) and that involves many different aspects beyond pure reasoning, such as the role of emotions, values, social contexts, and practical constraints, which are often overlooked in computational approaches to argumentation. The heterogeneity of human argumentation is present in Computational Argumentation research, in the form of various tasks that approach the main phases of argumentation individually. With the increasing interest of researchers in Artificial Intelligence, we consider that it is of great importance to provide guidance on the Computational Argumentation research area. Thus, in this paper, we present a general overview of Computational Argumentation, from the perspective of how humans argue. For that purpose, the following contributions are produced: (i) a consistent structure for Computational Argumentation research mapped with the human argumentation process; (ii) a collective understanding of the tasks approached by Computational Argumentation and their synergies; (iii) a thorough review of important advances in each of these tasks; and (iv) an analysis and a classification of the future trends in Computational Argumentation research and relevant open challenges in the area.},
  archive      = {J_AAMAS},
  author       = {Ruiz-Dolz, Ramon and Heras, Stella and García-Fornes, Ana},
  doi          = {10.1007/s10458-025-09692-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-59},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {An introduction to computational argumentation research from a human argumentation perspective},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low variance trust region optimization with independent
actors and sequential updates in cooperative multi-agent reinforcement
learning. <em>AAMAS</em>, <em>39</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s10458-025-09695-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative multi-agent reinforcement learning assumes each agent shares the same reward function and can be trained effectively using the Trust Region framework of single-agent. Instead of relying on other agents’ actions, the independent actors setting considers each agent to act based only on its local information, thus having more flexible applications. However, in the sequential update framework, it is required to re-estimate the joint advantage function after each individual agent’s policy step. Despite the practical success of importance sampling, the updated advantage function suffers from exponentially high variance problems, which likely results in unstable convergence. In this work, we first analyze the high variance advantage both empirically and theoretically. To overcome this limitation, we introduce a clipping objective to control the upper bounds of the advantage fluctuation in sequential updates. With the proposed objective, we provide a monotonic bound with sub-linear convergence to $$\varepsilon$$ -Nash Equilibria. We further derive two new practical algorithms using our clipping objective. The experiment results on three popular multi-agent reinforcement learning benchmarks show that our proposed method outperforms the tested baselines in most environments. By carefully analyzing different training settings, our proposed method is highlighted with both stable convergence properties and the desired low advantage variance estimation. For reproducibility purposes, our source code is publicly available at https://github.com/giangbang/Low-Variance-Trust-Region-MARL .},
  archive      = {J_AAMAS},
  author       = {Le, Bang Giang and Ta, Viet Cuong},
  doi          = {10.1007/s10458-025-09695-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Low variance trust region optimization with independent actors and sequential updates in cooperative multi-agent reinforcement learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving multi-agent games on networks. <em>AAMAS</em>,
<em>39</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10458-025-09696-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent games on networks (GoNs) have nodes that represent agents and edges that represent interactions among agents. A special class of GoNs is composed of 2-players games on each of their edges. General GoNs have games that are played by all agents in each neighborhood. Solutions to games on networks are stable states (i.e., pure Nash equilibria), and in general one is interested in efficient solutions (of high global social welfare). This study addresses the multi-agent aspect of games on networks—a system of multiple agents that compose a game and seek a solution by performing a multi-agent (distributed) algorithm. The agents playing the game are assumed to be strategic and an iterative distributed algorithm is proposed, that lets the agents interact (i.e., negotiate) in neighborhoods in a process that guarantees the convergence of any multi-agent game on network to a globally stable state. The proposed algorithm—the TECon algorithm—iterates, one neighborhood at a time, performing a repeated social choice action. A truth-enforcing mechanism is integrated into the algorithm, collecting the valuations of agents in each neighborhood and computing incentives while eliminating strategic behavior. The proposed method is proven to converge to globally stable states that are at least as efficient as the initial state, for any game on network. A specific version of the algorithm is given for the class of Public Goods Games, where the main properties of the algorithm are guaranteed even when the strategic agents playing the game consider their possible future valuations when interacting. An extensive experimental evaluation on randomly generated games on networks demonstrates that the TECon algorithm converges very rapidly. On general forms of public goods games, the proposed algorithm outperforms former solving methods, where former methods are applicable.},
  archive      = {J_AAMAS},
  author       = {Vaknin, Yair and Meisels, Amnon},
  doi          = {10.1007/s10458-025-09696-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Solving multi-agent games on networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A game-theoretic approach for hierarchical epidemic control.
<em>AAMAS</em>, <em>39</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10458-025-09697-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design and analyze a multi-level game-theoretic model of hierarchical policy interventions for epidemic control, such as those in response to the COVID-19 pandemic. Our model captures the potentially mismatched priorities among a hierarchy of policy-makers (e.g., federal, state, and local governments) with respect to two cost components that have opposite dependence on the policy strength—post-intervention infection rates and the socio-economic cost of policy implementation. Additionally, our model includes a crucial third factor in decisions: a cost of non-compliance with the policy-maker immediately above in the hierarchy, such as non-compliance of counties with state-level policies. We propose two novel algorithms for approximating solutions to such games. The first is based on best response dynamics (BRD) and exploits the tree structure of the game. The second combines quadratic integer programming (QIP), which enables us to collapse the two lowest levels of the game, with the best response dynamics. We experimentally characterize the scalability and equilibrium approximation quality of our two approaches against model parameters. Finally, we conduct experiments in simulations based on both synthetic and real-world data under various parameter configurations and analyze the resulting (approximate) equilibria to gain insight into the impact of decentralization on overall welfare (measured as the negative sum of costs) as well as emergent properties like social welfare, free-riding, and fairness in cost distribution among policy-makers.},
  archive      = {J_AAMAS},
  author       = {Jia, Feiran and Mate, Aditya and Li, Zun and Jabbari, Shahin and Chakraborty, Mithun and Tambe, Milind and Wellman, Michael P. and Vorobeychik, Yevgeniy},
  doi          = {10.1007/s10458-025-09697-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A game-theoretic approach for hierarchical epidemic control},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent language: A survey and taxonomy. <em>AAMAS</em>,
<em>39</em>(1), 1–73. (<a
href="https://doi.org/10.1007/s10458-025-09691-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of emergent language represents a novel area of research within the domain of artificial intelligence, particularly within the context of multi-agent reinforcement learning. Although the concept of studying language emergence is not new, early approaches were primarily concerned with explaining human language formation, with little consideration given to its potential utility for artificial agents. In contrast, studies based on reinforcement learning aim to develop communicative capabilities in agents that are comparable to or even superior to human language. Thus, they extend beyond the learned statistical representations that are common in natural language processing research. This gives rise to a number of fundamental questions, from the prerequisites for language emergence to the criteria for measuring its success. This paper addresses these questions by providing a comprehensive review of relevant scientific publications on emergent language in artificial intelligence. Its objective is to serve as a reference for researchers interested in or proficient in the field. Consequently, the main contributions are the definition and overview of the prevailing terminology, the analysis of existing evaluation methods and metrics, and the description of the identified research gaps.},
  archive      = {J_AAMAS},
  author       = {Peters, Jannik and Waubert de Puiseau, Constantin and Tercan, Hasan and Gopikrishnan, Arya and Lucas de Carvalho, Gustavo Adolpho and Bitter, Christian and Meisen, Tobias},
  doi          = {10.1007/s10458-025-09691-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-73},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Emergent language: A survey and taxonomy},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal matchings with one-sided preferences: Fixed and
cost-based quotas. <em>AAMAS</em>, <em>39</em>(1), 1–36. (<a
href="https://doi.org/10.1007/s10458-025-09693-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the well-studied many-to-one bipartite matching problem of assigning applicants $${\varvec{\mathcal {A}}}$$ to posts $${\varvec{\mathcal {P}}}$$ where applicants rank posts in the order of preference. This setting models many important real-world allocation problems like assigning students to courses, applicants to jobs, amongst many others. In such scenarios, it is natural to ask for an allocation that satisfies guarantees of the form “match at least 80% of applicants to one of their top three choices” or “it is unacceptable to leave more than 10% of applicants unassigned”. The well-studied notions of rank-maximality and fairness fail to capture such requirements due to their property of optimizing extreme ends of the signature of a matching. We, therefore, propose a novel optimality criterion, which we call the “weak dominance ” of ranks. We investigate the computational complexity of the new notion of optimality in the setting where posts have associated fixed quotas. We prove that under the fixed quota setting, the problem turns out to be NP-hard under natural restrictions. We provide randomized algorithms in the fixed quota setting when the number of ranks is constant. We also study the problem under a cost-based quota setting and show that a matching that weakly dominates the input signature and has minimum total cost can be computed efficiently. Apart from circumventing the hardness, the cost-based quota setting is motivated by real-world applications like course allocation or school choice where the capacities or quotas need not be rigid. We also show that when the objective is to minimize the maximum cost, the problem under the cost-based quota setting turns out to be NP-hard. To complement the hardness, we provide a randomized algorithm when the number of ranks is constant. We also provide an approximation algorithm which is an asymptotic faster alternative to the randomized algorithm.},
  archive      = {J_AAMAS},
  author       = {Santhini, K. A. and Sankar, Govind S. and Nasre, Meghana},
  doi          = {10.1007/s10458-025-09693-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Optimal matchings with one-sided preferences: Fixed and cost-based quotas},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the impact of direct punishment on the
emergence of cooperation in multi-agent reinforcement learning systems.
<em>AAMAS</em>, <em>39</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10458-025-09698-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the problem of cooperation is fundamentally important for the creation and maintenance of functional societies. Problems of cooperation are omnipresent within human society, with examples ranging from navigating busy road junctions to negotiating treaties. As the use of AI becomes more pervasive throughout society, the need for socially intelligent agents capable of navigating these complex cooperative dilemmas is becoming increasingly evident. Direct punishment is a ubiquitous social mechanism that has been shown to foster the emergence of cooperation in both humans and non-humans. In the natural world, direct punishment is often strongly coupled with partner selection and reputation and used in conjunction with third-party punishment. The interactions between these mechanisms could potentially enhance the emergence of cooperation within populations. However, no previous work has evaluated the learning dynamics and outcomes emerging from multi-agent reinforcement learning populations that combine these mechanisms. This paper addresses this gap. It presents a comprehensive analysis and evaluation of the behaviors and learning dynamics associated with direct punishment, third-party punishment, partner selection, and reputation. Finally, we discuss the implications of using these mechanisms on the design of cooperative AI systems.},
  archive      = {J_AAMAS},
  author       = {Dasgupta, Nayana and Musolesi, Mirco},
  doi          = {10.1007/s10458-025-09698-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Investigating the impact of direct punishment on the emergence of cooperation in multi-agent reinforcement learning systems},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relationship design for socially-aware behavior in static
games. <em>AAMAS</em>, <em>39</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10458-025-09699-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous agents can adopt socially-aware behaviors to reduce social costs, mimicking the way animals interact in nature and humans in society. We present a new approach to model socially-aware decision-making that includes two key elements: bounded rationality and inter-agent relationships. We capture the inter-agent relationships by introducing a novel model called a relationship game and encode agents’ bounded rationality using quantal response equilibria. For each relationship game, we define a social cost function and formulate a mechanism design problem to optimize weights for relationships that minimize social cost at the equilibrium. We address the multiplicity of equilibria by presenting the problem in two forms: Min-Max and Min-Min, aimed respectively at minimization of the highest and lowest social costs in the equilibria. We compute the quantal response equilibrium by solving a least-squares problem defined with its Karush-Kuhn-Tucker conditions, and propose two projected gradient descent algorithms to solve the mechanism design problems. Numerical results, including two-lane congestion and congestion with an ambulance, confirm that these algorithms consistently reach the equilibrium with the intended social costs.},
  archive      = {J_AAMAS},
  author       = {Chen, Shenghui and Bayiz, Yigit E. and Fridovich-Keil, David and Topcu, Ufuk},
  doi          = {10.1007/s10458-025-09699-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Relationship design for socially-aware behavior in static games},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double mixing networks based monotonic value function
decomposition algorithm for swarm intelligence in UAVs. <em>AAMAS</em>,
<em>39</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s10458-025-09700-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-agent systems, particularly when facing challenges of partial observability, reinforcement learning demonstrates significant autonomous decision-making capabilities. Aiming at addressing resource allocation and collaboration issues in drone swarms operating in dynamic and unknown environments, we propose a novel deep reinforcement learning algorithm, DQMIX. We employ a framework of centralized training with decentralized execution and incorporate a partially observable Markov game model to describe the complex game environment of drone swarms. The core innovation of the DQMIX algorithm lies in its dual-mixing network structure and soft-switching mechanism. Two independent mixing networks handle local Q-values and synthesize them into a global Q-value. This structure enhances decision accuracy and system adaptability under different scenarios and data conditions. The soft-switching module allows the system to transition smoothly between the two networks, selecting the output of the network with smaller TD-errors to enhance decision stability and coherence. Simultaneously, we introduce Hindsight Experience Replay to learn from failed experiences. Experimental results using JSBSim demonstrate that DQMIX provides an effective solution for drone swarm game problems, especially in resource allocation and adversarial environments.},
  archive      = {J_AAMAS},
  author       = {Qu, Pingping and He, Chenglong and Wu, Xiaotong and Wang, Ershen and Xu, Song and Liu, Huan and Sun, Xinhui},
  doi          = {10.1007/s10458-025-09700-0},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Double mixing networks based monotonic value function decomposition algorithm for swarm intelligence in UAVs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). “Provably fair” algorithms may perpetuate racial and gender
bias: A study of salary dispute resolution. <em>AAMAS</em>,
<em>39</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10458-025-09703-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior work suggests automated dispute resolution tools using “provably fair” algorithms can address disparities between demographic groups. These methods use multi-criteria elicited preferences from all disputants and satisfy constraints to generate “fair” solutions. However, we analyze the potential for inequity to permeate proposals through the preference elicitation stage. This possibility arises if differences in dispositional attitudes differ between demographics, and those dispositions affect elicited preferences. Specifically, risk aversion plays a prominent role in predicting preferences. Risk aversion predicts a weaker relative preference for salary and a softer within-issue utility for each issue; this leads to worse compensation packages for risk-averse groups. These results raise important questions in AI-value alignment about whether an AI mediator should take explicit preferences at face value.},
  archive      = {J_AAMAS},
  author       = {Hale, James and Kim, Peter H. and Gratch, Jonathan},
  doi          = {10.1007/s10458-025-09703-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {“Provably fair” algorithms may perpetuate racial and gender bias: A study of salary dispute resolution},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On fair and efficient solutions for budget apportionment.
<em>AAMAS</em>, <em>39</em>(1), 1–31. (<a
href="https://doi.org/10.1007/s10458-025-09694-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article deals with an apportionment problem involving n agents and a common budget B. Each agent submits some demands which are indivisible portions of the budget, and a central authority has to decide which demands to accept. The utility of an agent corresponds to the total amount of her accepted demands. In this context, it is desirable to be fair among the agents and efficient by not wasting the budget. An ideal solution would be to spend exactly B/n for every agent but this is rarely possible because of the indivisibility of the demands. Since combining fairness with efficiency is highly desirable but often impossible, we explore relaxed notions of fairness and efficiency, in order to determine if they go together. Our approach is also constructive because polynomial algorithms that build fair and efficient solutions are also given. The fairness criteria under consideration are the maximization of the minimum agent utility (max–min), proportionality, a customized notion of envy-freeness called jealousy-freeness, and the relaxations up to one or any demand of the previous two concepts. Efficiency in this work is either the maximization of the utilitarian social welfare or Pareto optimality. First we consider fairness and efficiency separately. The existence and computation of solutions that are either fair or efficient are studied. A complete picture of the relations that connect the fairness and efficiency concepts is provided. Second, we determine when fairness and efficiency can be combined for every possible instance. We prove that Pareto optimality is compatible with two notions of fairness, namely max–min and proportionality up to any demand. In contrast, none of the fairness concepts under consideration can be paired with the maximization of utilitarian social welfare. Therefore, we finally conduct a thorough analysis of the price of fairness which bounds the loss of efficiency caused by imposing fairness or one of its relaxations.},
  archive      = {J_AAMAS},
  author       = {Cardi, Pierre and Gourvès, Laurent and Lesca, Julien},
  doi          = {10.1007/s10458-025-09694-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {On fair and efficient solutions for budget apportionment},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptation procedure in misinformation games.
<em>AAMAS</em>, <em>39</em>(1), 1–47. (<a
href="https://doi.org/10.1007/s10458-025-09704-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study interactions between agents in multi-agent systems, in which the agents are misinformed with regards to the game that they play, essentially having a subjective and incorrect understanding of the setting, without being aware of it. For that, we introduce a new game-theoretic concept, called misinformation games, that provides the necessary toolkit to study this situation. Subsequently, we enhance this framework by developing a time-discrete procedure (called the Adaptation Procedure) that captures iterative interactions in the above context. During the Adaptation Procedure, the agents update their information and reassess their behaviour in each step. We demonstrate our ideas through an implementation, which is used to study the efficiency and characteristics of the Adaptation Procedure.},
  archive      = {J_AAMAS},
  author       = {Varsos, Konstantinos and Papamichail, Merkouris and Flouris, Giorgos and Bitsaki, Marina},
  doi          = {10.1007/s10458-025-09704-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-47},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Adaptation procedure in misinformation games},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ail---10">AIL - 10</h2>
<ul>
<li><details>
<summary>
(2025). AI, law and beyond. A transdisciplinary ecosystem for the
future of AI &amp; law. <em>AIL</em>, <em>33</em>(1), 253–270. (<a
href="https://doi.org/10.1007/s10506-024-09404-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We live in exciting times for AI and Law: technical developments are moving at a breakneck pace, and at the same time, the call for more robust AI governance and regulation grows stronger. How should we as an AI &amp; Law community navigate these dramatic developments and claims? In this Presidential Address, I present my ideas for a way forward: researching, developing and evaluating real AI systems for the legal field with researchers from AI, Law and beyond. I will demonstrate how we at the Netherlands National Police Lab AI are developing responsible AI by combining insights from different disciplines, and how this connects to the future of our field.},
  archive      = {J_AIL},
  author       = {Bex, Floris J.},
  doi          = {10.1007/s10506-024-09404-y},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {253-270},
  shortjournal = {Artif. Intell. Law},
  title        = {AI, law and beyond. a transdisciplinary ecosystem for the future of AI &amp; law},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automating petition classification in brazil’s legal system:
A two-step deep learning approach. <em>AIL</em>, <em>33</em>(1),
227–251. (<a href="https://doi.org/10.1007/s10506-023-09385-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated classification of legal documents has been the subject of extensive research in recent years. However, this is still a challenging task for long documents, since it is difficult for a model to identify the most relevant information for classification. In this paper, we propose a two-stage supervised learning approach for the classification of petitions, a type of legal document that requests a court order. The proposed approach is based on a word-level encoder–decoder Seq2Seq deep neural network, such as a Bidirectional Long Short-Term Memory (BiLSTM) or a Bidirectional Encoder Representations from Transformers (BERT) model, and a document-level Support Vector Machine classifier. To address the challenges posed by the lengthy legal documents, the approach introduces a human-in-the-loop approach, whose task is to localize and tag relevant segments of text in the word-level training part, which dramatically reduces the dimension of the document classifier input vector. We performed experiments to validate our approach using a real-world dataset comprised of 270 intermediate petitions, which were carefully annotated by specialists from the 15th civil unit of the State of Alagoas, Brazil. Our results revealed that both BiLSTM and BERT-Convolutional Neural Networks variants achieved an accuracy of up to 95.49%, and also outperformed baseline classifiers based on the Term Frequency–Inverse Document Frequency test vectorizer. The proposed approach is currently being utilized to automate the aforementioned justice unit, thereby increasing its efficiency in handling repetitive tasks.},
  archive      = {J_AIL},
  author       = {Costa, Yuri D. R. and Oliveira, Hugo and Nogueira, Valério and Massa, Lucas and Yang, Xu and Barbosa, Adriano and Oliveira, Krerley and Vieira, Thales},
  doi          = {10.1007/s10506-023-09385-4},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {227-251},
  shortjournal = {Artif. Intell. Law},
  title        = {Automating petition classification in brazil’s legal system: A two-step deep learning approach},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward representing interpretation in factor-based models of
precedent. <em>AIL</em>, <em>33</em>(1), 199–226. (<a
href="https://doi.org/10.1007/s10506-023-09384-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the desirability and feasibility of modeling precedents with multiple interpretations within factor-based models of precedential constraint. The main idea is that allowing multiple reasonable interpretations of cases and modeling precedential constraint as a function of what all reasonable interpretations compel may be advantageous. The article explains the potential benefits of extending the models in this way with a focus on incorporating a theory of vertical precedent in U.S. federal appellate courts. It also considers the costs of extending the models in this way, such as the significant increase in the functional size of the case base and the need to provide some kind of ordering on interpretations to select a “best” interpretation. Finally, the article suggests partially incorporating multiple interpretations of dimensions as a realistic starting point for incorporating interpretations generally, and shows how doing so can help address difficulties with dimensions. The conclusion remarks on the use of interpretations to deal with inconsistent precedents.},
  archive      = {J_AIL},
  author       = {Rigoni, Adam},
  doi          = {10.1007/s10506-023-09384-5},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {199-226},
  shortjournal = {Artif. Intell. Law},
  title        = {Toward representing interpretation in factor-based models of precedent},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision support for detecting sensitive text in government
records. <em>AIL</em>, <em>33</em>(1), 171–197. (<a
href="https://doi.org/10.1007/s10506-023-09383-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Freedom of information laws promote transparency by permitting individuals and organizations to obtain government documents. However, exemptions from disclosure are necessary to protect privacy and to permit government officials to deliberate freely. Deliberative language is often the most challenging and burdensome exemption to detect, leading to high processing costs and delays in responding to open-records requests. This paper describes a novel deliberative-language detection model trained on a new annotated training set. The deliberative-language detection model is a component of a decision-support system for open-records requests under the US Freedom of Information Act, the FOIA Assistant, that ingests documents responsive to an open-records requests, suggests passages likely to be subject to deliberative language, privacy, or other exemptions, and assists analysts in rapidly redacting suggested passages. The tool’s interface is based on extensive human-factors and usability studies with analysts and is currently in operational testing by multiple US federal agencies.},
  archive      = {J_AIL},
  author       = {Branting, Karl and Brown, Bradford and Giannella, Chris and Guilder, James Van and Harrold, Jeff and Howell, Sarah and Baron, Jason R.},
  doi          = {10.1007/s10506-023-09383-6},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {171-197},
  shortjournal = {Artif. Intell. Law},
  title        = {Decision support for detecting sensitive text in government records},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). Correction to: Reasoning with inconsistent precedents.
<em>AIL</em>, <em>33</em>(1), 167–170. (<a
href="https://doi.org/10.1007/s10506-024-09392-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIL},
  author       = {Canavotto, Ilaria},
  doi          = {10.1007/s10506-024-09392-z},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {167-170},
  shortjournal = {Artif. Intell. Law},
  title        = {Correction to: Reasoning with inconsistent precedents},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). Reasoning with inconsistent precedents. <em>AIL</em>,
<em>33</em>(1), 137–166. (<a
href="https://doi.org/10.1007/s10506-023-09382-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational models of legal precedent-based reasoning developed in AI and Law are typically based on the simplifying assumption that the background set of precedent cases is consistent. Besides being unrealistic in the legal domain, this assumption is problematic for recent promising applications of these models to the development of explainable AI methods. In this paper I explore a model of legal precedent-based reasoning that, unlike existing models, does not rely on the assumption that the background set of precedent cases is consistent. The model is a generalization of the reason model of precedential constraint. I first show that the model supports an interesting deontic logic, where consistent obligations can be derived from inconsistent case bases. I then provide an explanation of this surprising result by proposing a reformulation of the model in terms of cases that support a new potential decision and cases that conflict with it. Finally, I show that the reformulation of the model allows us to verify that inconsistent case bases do not make verification that a decision is permissible substantially more complex than consistent case bases and to introduce intuitive criteria to compare different permissible decisions.},
  archive      = {J_AIL},
  author       = {Canavotto, Ilaria},
  doi          = {10.1007/s10506-023-09382-7},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {137-166},
  shortjournal = {Artif. Intell. Law},
  title        = {Reasoning with inconsistent precedents},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural network to identify requests, decisions, and
arguments in court rulings on custody. <em>AIL</em>, <em>33</em>(1),
101–135. (<a href="https://doi.org/10.1007/s10506-023-09380-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Court rulings are among the most important documents in all legal systems. This article describes a study in which natural language processing is used for the automatic characterization of Spanish judgments that deal with the physical custody (joint or individual) of minors. The model was trained to identify a set of elements: the type of custody requested by the plaintiff, the type of custody decided on by the court, and eight of the most commonly used arguments in this type of judgment. Two jurists independently annotated more than 3000 judgments, which were used to train a model based on transformers. The main difficulties encountered in this task were the complexity of the judicial language and the need to work with appellate court rulings that have a more complicated structure than decisions at first instance. For the complete court rulings, the F1 score of the inter-annotator agreement ranged from 0.60 to 0.86 and the Kappa index from 0.33 to 0.73. The F1 score of the agreement between the model and the annotators ranged from 0.66 to 0.93 and the Kappa index from 0.57 to 0.80. These results in which the model performance exceeds even the inter-annotator agreement show the high ability of transformers to identify abstract entities in legal texts.},
  archive      = {J_AIL},
  author       = {Muñoz-Soro, José Félix and del Hoyo Alonso, Rafael and Montañes, Rosa and Lacueva, Francisco},
  doi          = {10.1007/s10506-023-09380-9},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {101-135},
  shortjournal = {Artif. Intell. Law},
  title        = {A neural network to identify requests, decisions, and arguments in court rulings on custody},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Natural language processing for legal document review:
Categorising deontic modalities in contracts. <em>AIL</em>,
<em>33</em>(1), 79–100. (<a
href="https://doi.org/10.1007/s10506-023-09379-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contract review process can be a costly and time-consuming task for lawyers and clients alike, requiring significant effort to identify and evaluate the legal implications of individual clauses. To address this challenge, we propose the use of natural language processing techniques, specifically text classification based on deontic tags, to streamline the process. Our research question is whether natural language processing techniques, specifically dense vector embeddings, can help semi-automate the contract review process and reduce time and costs for legal professionals reviewing deontic modalities in contracts. In this study, we create a domain-specific dataset and train both baseline and neural network models for contract sentence classification. This approach offers a more efficient and cost-effective solution for contract review, mimicking the work of a lawyer. Our approach achieves an accuracy of 0.90, showcasing its effectiveness in identifying and evaluating individual contract sentences.},
  archive      = {J_AIL},
  author       = {Graham, S. Georgette and Soltani, Hamidreza and Isiaq, Olufemi},
  doi          = {10.1007/s10506-023-09379-2},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {79-100},
  shortjournal = {Artif. Intell. Law},
  title        = {Natural language processing for legal document review: Categorising deontic modalities in contracts},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large scale benchmark for session-based recommendations on
the legal domain. <em>AIL</em>, <em>33</em>(1), 43–78. (<a
href="https://doi.org/10.1007/s10506-023-09378-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of legal documents in various formats and their dispersion across multiple courts present a significant challenge for users seeking precise matches to their information requirements. Despite notable advancements in legal information retrieval systems, research into legal recommender systems remains limited. A plausible factor contributing to this scarcity could be the absence of extensive publicly accessible datasets or benchmarks. While a few studies have emerged in this field, a comprehensive analysis of the distinct attributes of legal data that influence the design of effective legal recommenders is notably absent in the current literature. This paper addresses this gap by initially amassing a comprehensive session-based dataset from Jusbrasil, one of Brazil’s largest online legal platforms. Subsequently, we scrutinize and discourse key facets of legal session-based recommendation data, including session duration, types of recommendable legal artifacts, coverage, and popularity. Furthermore, we introduce the first session-based recommendation benchmark tailored to the legal domain, shedding light on the performance and constraints of several renowned session-based recommendation approaches. These evaluations are based on real-world data sourced from Jusbrasil.},
  archive      = {J_AIL},
  author       = {Domingues, Marcos Aurélio and de Moura, Edleno Silva and Marinho, Leandro Balby and da Silva, Altigran},
  doi          = {10.1007/s10506-023-09378-3},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {43-78},
  shortjournal = {Artif. Intell. Law},
  title        = {A large scale benchmark for session-based recommendations on the legal domain},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating legal event and context information for chinese
similar case analysis. <em>AIL</em>, <em>33</em>(1), 1–42. (<a
href="https://doi.org/10.1007/s10506-023-09377-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Similar case analysis (SCA) is an essential topic in legal artificial intelligence, serving as a reference for legal professionals. Most existing works treat SCA as a traditional text classification task and ignore some important legal elements that affect the verdict and case similarity, like legal events, and thus are easily misled by semantic structure. To address this issue, we propose a Legal Event-Context Model named LECM to improve the accuracy and interpretability of SCA based on Chinese legal corpus. The event-context integration mechanism, which is an essential component of the LECM, is proposed to integrate the legal event and context information based on the attention mechanism, enabling legal events to be associated with their corresponding relevant contexts. We introduce an event detection module to obtain the legal event information, which is pre-trained on a legal event detection dataset to avoid labeling events manually. We conduct extensive experiments on two SCA tasks, i.e., similar case matching (SCM) and similar case retrieval (SCR). Compared with baseline models, LECM is validated by about 13% and 11% average improvement in terms of mean average precision and accuracy respectively, for SCR and SCM tasks. These results indicate that LECM effectively utilizes event-context knowledge to enhance SCA performance and its potential application in various legal document analysis tasks.},
  archive      = {J_AIL},
  author       = {Dan, Jingpei and Xu, Lanlin and Wang, Yuming},
  doi          = {10.1007/s10506-023-09377-4},
  journal      = {Artificial Intelligence and Law},
  month        = {3},
  number       = {1},
  pages        = {1-42},
  shortjournal = {Artif. Intell. Law},
  title        = {Integrating legal event and context information for chinese similar case analysis},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="air---32">AIR - 32</h2>
<ul>
<li><details>
<summary>
(2025). Learn to optimise for job shop scheduling: A survey with
comparison between genetic programming and reinforcement learning.
<em>AIR</em>, <em>58</em>(6), 1–53. (<a
href="https://doi.org/10.1007/s10462-024-11059-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Job shop scheduling holds significant importance due to its relevance and impact on various industrial and manufacturing processes. It involves dynamically assigning and sequencing jobs to machines in a flexible production environment, where job characteristics, machine availability, and other factors might change over time. Genetic programming and reinforcement learning have emerged as powerful approaches to automatically learn high-quality scheduling heuristics or directly optimise sequences of specific job-machine pairs to generate efficient schedules in manufacturing. Existing surveys on job shop scheduling typically provide overviews from a singular perspective, focusing solely on genetic programming or reinforcement learning, but overlook the hybridisation and comparison of both approaches. This survey aims to bridge this gap by reviewing recent developments in genetic programming and reinforcement learning approaches for job shop scheduling problems, providing a comparison in terms of the learning principles and characteristics for solving different kinds of job shop scheduling problems. In addition, this survey identifies and discusses current issues and challenges in the field of learning to optimise for job shop scheduling. This comprehensive exploration of genetic programming and reinforcement learning in job shop scheduling provides valuable insights into the learning principles for optimising different job shop scheduling problems. It deepens our understanding of recent developments, suggesting potential research directions for future advancements.},
  archive      = {J_AIR},
  author       = {Xu, Meng and Mei, Yi and Zhang, Fangfang and Zhang, Mengjie},
  doi          = {10.1007/s10462-024-11059-9},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-53},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Learn to optimise for job shop scheduling: A survey with comparison between genetic programming and reinforcement learning},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive gaining-sharing knowledge-based variant algorithm
with historical probability expansion and its application in escape
maneuver decision making. <em>AIR</em>, <em>58</em>(6), 1–43. (<a
href="https://doi.org/10.1007/s10462-024-11096-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To further improve the performance of adaptive gaining-sharing knowledge-based algorithm (AGSK), a novel adaptive gaining sharing knowledge-based algorithm with historical probability expansion (HPE-AGSK) is proposed by modifying the search strategies. Based on AGSK, three improvement strategies are proposed. First, expansion sharing strategy is proposed and added in junior gaining-sharing phase to boost local search ability. Second, historical probability expansion strategy is proposed and added in senior gaining-sharing phase to strengthen global search ability. Last, reverse gaining strategy is proposed and utilized to expand population distribution at the beginning of iterations. The performance of HPE-AGSK is initially evaluated using IEEE CEC 2021 test suite, compared with fifteen state-of-the-art algorithms (AGSK, APGSK, APGSK-IMODE, GLAGSK, EDA2, AAVS-EDA, EBOwithCMAR, LSHADE-SPACMA, HSES, IMODE, MadDE, CJADE, and iLSHADE-RSP). The results demonstrate that HPE-AGSK outperforms both state-of-the-art GSK-based variants and past winners of IEEE CEC competitions. Subsequently, GSK-based variants and other exceptional algorithms in CEC 2021 are selected to further evaluate the performance of HPE-AGSK using IEEE CEC 2018 test suite. The statistical results show that HPE-AGSK has superior exploration ability than the comparison algorithms, and has strong competition with APGSK (state-of-the-art AGSK variant) and IMODE (CEC 2020 Winner) in exploitation ability. Finally, HPE-AGSK is utilized to solve the beyond visual range escape maneuver decision making problem. Its success rate is 100%, and mean maneuver time is 9.10 s, these results show that HPE-AGSK has good BVR escape maneuver decision-making performance. In conclusion, HPE-AGSK is a highly promising AGSK variant that significantly enhances the performance, and is an outstanding development of AGSK. The code of HPE-AGSK can be downloaded from https://github.com/xieleilei0305/HPE-AGSK-CODE.git . (The link will be available for readers after the paper is published).},
  archive      = {J_AIR},
  author       = {Xie, Lei and Wang, Yuan and Tang, Shangqin and Li, Yintong and Zhang, Zhuoran and Huang, Changqiang},
  doi          = {10.1007/s10462-024-11096-4},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-43},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Adaptive gaining-sharing knowledge-based variant algorithm with historical probability expansion and its application in escape maneuver decision making},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Environmental sound recognition on embedded devices using
deep learning: A review. <em>AIR</em>, <em>58</em>(6), 1–35. (<a
href="https://doi.org/10.1007/s10462-025-11106-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sound recognition has a wide range of applications beyond speech and music, including environmental monitoring, sound source classification, mechanical fault diagnosis, audio fingerprinting, and event detection. These applications often require real-time data processing, making them well-suited for embedded systems. However, embedded devices face significant challenges due to limited computational power, memory, and low power consumption. Despite these constraints, achieving high performance in environmental sound recognition typically requires complex algorithms. Deep Learning models have demonstrated high accuracy on existing datasets, making them a popular choice for such tasks. However, these models are resource-intensive, posing challenges for real-time edge applications. This paper presents a comprehensive review of integrating Deep Learning models into embedded systems, examining their state-of-the-art applications, key components, and steps involved. It also explores strategies to optimise performance in resource-constrained environments through a comparison of various implementation approaches such as knowledge distillation, pruning, and quantization, with studies achieving a reduction in complexity of up to 97% compared to the unoptimized model. Overall, we conclude that in spite of the availability of lightweight deep learning models, input features, and compression techniques, their integration into low-resource devices, such as microcontrollers, remains limited. Furthermore, more complex tasks, such as general sound classification, especially with expanded frequency bands and real-time operation have yet to be effectively implemented on these devices. These findings highlight the need for a standardised research framework to evaluate these technologies applied to resource-constrained devices, and for further development to realise the wide range of potential applications.},
  archive      = {J_AIR},
  author       = {Gairí, Pau and Pallejà, Tomàs and Tresanchez, Marcel},
  doi          = {10.1007/s10462-025-11106-z},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-35},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Environmental sound recognition on embedded devices using deep learning: A review},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-model integration for dynamic forecasting (MIDF): A
framework for wind speed and direction prediction. <em>AIR</em>,
<em>58</em>(6), 1–37. (<a
href="https://doi.org/10.1007/s10462-025-11140-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of wind speed and direction is critical for the efficient integration of wind power into energy systems, ensuring reliable renewable energy production and grid stability. Traditional methods often struggle with capturing nonlinear interdependencies, quantifying uncertainties, and providing reliable long-term predictions, particularly in complex atmospheric conditions. To address these challenges, this study introduces multi-model Integration for dynamic forecasting (MIDF), an ensemble machine learning framework that combines the strengths of DeepAR and temporal fusion transformer (TFT) models through a two-step meta-learning process. MIDF leverages DeepAR’s probabilistic forecasting capabilities and TFT’s attention mechanisms to enhance accuracy, robustness, and interpretability. Using a custom meteorological dataset spanning January 2010 to May 2023, the model was evaluated against standalone alternatives across multiple metrics, including MSE, RMSE, and R2. MIDF achieved superior performance, with MSE, RMSE, and R2 values of 0.0035, 0.01913, and 0.89 for wind speed, and 0.00052, 0.02507, and 0.86 for wind direction, significantly reducing errors compared to existing methods. These results underscore the potential of ensemble learning in advancing wind forecasting accuracy, enabling more reliable renewable energy management, operational planning, and risk mitigation in meteorological applications.},
  archive      = {J_AIR},
  author       = {Maruthi, Molaka and Kim, Bubryur and Sujeen, Song and An, Jinwoo and Chen, Zengshun},
  doi          = {10.1007/s10462-025-11140-x},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-37},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-model integration for dynamic forecasting (MIDF): A framework for wind speed and direction prediction},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of small object detection based on deep learning in
aerial images. <em>AIR</em>, <em>58</em>(6), 1–67. (<a
href="https://doi.org/10.1007/s10462-025-11150-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection poses a formidable challenge in the field of computer vision, particularly when it comes to analyzing aerial remote sensing images. Despite the rapid development of deep learning and significant progress in detection techniques in natural scenes, the migration of these algorithms to aerial images has not met expectations. This is primarily due to limitations in imaging acquisition conditions, including small target size, viewpoint specificity, background complexity, as well as scale and orientation diversity. Although the increasing application of deep learning-based algorithms to overcome these problems, few studies have summarized the optimization of different deep learning strategies used for small target detection in aerial images. Therefore, this paper aims to explore the application of deep learning methods for small object detection in aerial images. The primary challenges in small object detection in aerial images will be summarized. Next, a meticulous analysis and categorization of the prevailing deep learning optimization strategies employed to surmount the challenges encountered in aerial image detection is undertaken. Following that, we provide a comprehensive presentation of the object detection datasets utilized in aerial remote sensing images, along with the evaluation metrics employed. Additionally, we furnish experimental data pertaining to the currently proposed detection algorithms. Finally, the advantages and disadvantages of various optimization strategies and potential development trends are discussed. Hopefully, it can provide a reference for researchers in this field.},
  archive      = {J_AIR},
  author       = {Hua, Wei and Chen, Qili},
  doi          = {10.1007/s10462-025-11150-9},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-67},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A survey of small object detection based on deep learning in aerial images},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BERT applications in natural language processing: A review.
<em>AIR</em>, <em>58</em>(6), 1–49. (<a
href="https://doi.org/10.1007/s10462-025-11162-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BERT (Bidirectional Encoder Representations from Transformers) has revolutionized Natural Language Processing (NLP) by significantly enhancing the capabilities of language models. This review study examines the complex nature of BERT, including its structure, utilization in different NLP tasks, and the further development of its design via modifications. The study thoroughly analyses the methodological aspects, conducting a comprehensive analysis of the planning process, the implemented procedures, and the criteria used to decide which data to include or exclude in the evaluation framework. In addition, the study thoroughly examines the influence of BERT on several NLP tasks, such as Sentence Boundary Detection, Tokenization, Grammatical Error Detection and Correction, Dependency Parsing, Named Entity Recognition, Part of Speech Tagging, Question Answering Systems, Machine Translation, Sentiment analysis, fake review detection and Cross-lingual transfer learning. The review study adds to the current literature by integrating ideas from multiple sources, explicitly emphasizing the problems and prospects in BERT-based models. The objective is to comprehensively comprehend BERT and its implementations, targeting both experienced researchers and novices in the domain of NLP. Consequently, the present study is expected to inspire more research endeavors, promote innovative adaptations of BERT, and deepen comprehension of its extensive capabilities in various NLP applications. The results presented in this research are anticipated to influence the advancement of future language models and add to the ongoing discourse on enhancing technology for understanding natural language.},
  archive      = {J_AIR},
  author       = {Gardazi, Nadia Mushtaq and Daud, Ali and Malik, Muhammad Kamran and Bukhari, Amal and Alsahfi, Tariq and Alshemaimri, Bader},
  doi          = {10.1007/s10462-025-11162-5},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-49},
  shortjournal = {Artif. Intell. Rev.},
  title        = {BERT applications in natural language processing: A review},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GFSNet: Gaussian fourier with sparse attention network for
visual question answering. <em>AIR</em>, <em>58</em>(6), 1–30. (<a
href="https://doi.org/10.1007/s10462-025-11163-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual question answering (VQA), a core task in multimodal learning, requires models to effectively integrate visual and natural language information to perform reasoning and semantic understanding in complex scenarios. However, self-attention mechanisms often struggle to capture multi-scale information and key region features within images comprehensively. Moreover, VQA involves multidimensional and deep reasoning about image content, particularly in scenarios involving spatial relationships and frequency-domain features. Existing methods face limitations in modeling multi-scale features and filtering irrelevant information effectively. This paper proposes an innovative Gaussian Fourier with Sparse Attention Network (GFSNet) to address these challenges. GFSNet leverages Fourier transforms to map image attention weights generated by the self-attention mechanism from the spatial domain to the frequency domain, enabling comprehensive modeling of multi-scale frequency information. This enhances the model’s adaptability to complex structures and its capacity for relational modeling. To further improve feature robustness, a Gaussian filter is introduced to suppress high-frequency noise in the frequency domain, preserving critical visual information. Additionally, a sparse attention mechanism dynamically selects optimized frequency-domain features, effectively reducing interference from redundant information while improving interpretability and computational efficiency. Without increasing parameter counts or computational complexity, GFSNet achieves efficient modeling of multi-scale visual information. Experimental results on benchmark VQA datasets (VQA v2, GQA, and CLEVR) demonstrate that GFSNet significantly enhances reasoning capabilities and cross-modal alignment performance, validating its superiority and effectiveness. The code is available at https://github.com/shenxiang-vqa/GFSNet .},
  archive      = {J_AIR},
  author       = {Shen, Xiang and Han, Dezhi and Chang, Chin-Chen and Oad, Ammar and Wu, Huafeng},
  doi          = {10.1007/s10462-025-11163-4},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-30},
  shortjournal = {Artif. Intell. Rev.},
  title        = {GFSNet: Gaussian fourier with sparse attention network for visual question answering},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent games meeting with multi-agent deep
reinforcement learning: A comprehensive review. <em>AIR</em>,
<em>58</em>(6), 1–53. (<a
href="https://doi.org/10.1007/s10462-025-11166-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the great achievement of the AI-driven intelligent games, such as AlphaStar defeating the human experts, and numerous intelligent games have come into the public view. Essentially, deep reinforcement learning (DRL), especially multiple-agent DRL (MADRL) has empowered a variety of artificial intelligence fields, including intelligent games. However, there is lack of systematical review on their correlations. This article provides a holistic picture on smoothly connecting intelligent games with MADRL from two perspectives: theoretical game concepts for MADRL, and MADRL for intelligent games. From the first perspective, information structure and game environmental features for MADRL algorithms are summarized; and from the second viewpoint, the challenges in intelligent games are investigated, and the existing MADRL solutions are correspondingly explored. Furthermore, the state-of-the-art (SOTA) MADRL algorithms for intelligent games are systematically categorized, especially from the perspective of credit assignment. Moreover, a comprehensively review on notorious benchmarks are conducted to facilitate the design and test of MADRL based intelligent games. Besides, a general procedure of MADRL simulations is offered. Finally, the key challenges in integrating intelligent games with MADRL, and potential future research directions are highlighted. This survey hopes to provide a thoughtful insight of developing intelligent games with the assistance of MADRL solutions and algorithms.},
  archive      = {J_AIR},
  author       = {Wang, Yiqin and Wang, Yufeng and Tian, Feng and Ma, Jianhua and Jin, Qun},
  doi          = {10.1007/s10462-025-11166-1},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-53},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Intelligent games meeting with multi-agent deep reinforcement learning: A comprehensive review},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning frameworks for MRI-based diagnosis of
neurological disorders: A systematic review and meta-analysis.
<em>AIR</em>, <em>58</em>(6), 1–37. (<a
href="https://doi.org/10.1007/s10462-025-11146-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic diagnosis of neurological disorders using Magnetic Resonance Imaging (MRI) is a widely researched problem. MRI is a non-invasive and highly informative imaging modality, which is one of the most widely accepted and used neuroimaging modalities for visualizing the human brain. The advent of tremendous processing capabilities, multi-modal data, and deep-learning techniques has enabled researchers to develop intelligent, sufficiently accurate classification methods. A comprehensive literature review has revealed extensive research on the automatic diagnosis of neurological disorders. However, despite numerous studies, a systematically developed framework is lacking, that relies on a sufficiently robust dataset or ensures reliable accuracy. To date, no consolidated framework has been established to classify multiple diseases and their subtypes effectively based on various types and their planes of orientation in structural and functional MR images. This systematic review provides a detailed and comprehensive analysis of research reported from 2000 to 2023. Systems developed in prior art have been categorized according to their disease diagnosis capabilities. The datasets employed and the tools developed are also summarized to assist researchers to conduct further studies in this crucial domain. The contributions of this research include facilitating the design of a unified framework for multiple neurological disease diagnoses, resulting in the development of a generic assistive tool for hospitals and neurologists to diagnose disorders precisely and swiftly thus potentially saving lives, in addition to increasing the quality of life of patients suffering from neurodegenerative disorders.},
  archive      = {J_AIR},
  author       = {Ali, Syed Saad Azhar and Memon, Khuhed and Yahya, Norashikin and Khan, Shujaat},
  doi          = {10.1007/s10462-025-11146-5},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-37},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Deep learning frameworks for MRI-based diagnosis of neurological disorders: A systematic review and meta-analysis},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning operations landscape: Platforms and tools.
<em>AIR</em>, <em>58</em>(6), 1–37. (<a
href="https://doi.org/10.1007/s10462-025-11164-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the field of machine learning advances, managing and monitoring intelligent models in production, also known as machine learning operations (MLOps), has become essential. Organizations are increasingly adopting artificial intelligence as a strategic tool, thus increasing the need for reliable, and scalable MLOps platforms. Consequently, every aspect of the machine learning life cycle, from workflow orchestration to performance monitoring, presents both challenges and opportunities that require sophisticated, flexible, and scalable technological solutions. This research addresses this demand by providing a comprehensive assessment framework of MLOps platforms highlighting the key features necessary for a robust MLOps solution. The paper examines 16 MLOps tools widely used, which revolve around capabilities within AI infrastructure management, including but not limited to experiment tracking, model deployment, and model inference. Our three-step evaluation framework starts with a feature analysis of the MLOps platforms, then GitHub stars growth assessment for adoption and prominence, and finally, a weighted scoring method to single out the most influential platforms. From this process, we derive valuable insights into the essential components of effective MLOps systems and provide a decision-making flowchart that simplifies platform selection. This framework provides hands-on guidance for organizations looking to initiate or enhance their MLOps strategies, whether they require an end-end solutions or specialized tools.},
  archive      = {J_AIR},
  author       = {Berberi, Lisana and Kozlov, Valentin and Nguyen, Giang and Sáinz-Pardo Díaz, Judith and Calatrava, Amanda and Moltó, Germán and Tran, Viet and López García, Álvaro},
  doi          = {10.1007/s10462-025-11164-3},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-37},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Machine learning operations landscape: Platforms and tools},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of hyperspectral image classification based on
graph neural networks. <em>AIR</em>, <em>58</em>(6), 1–56. (<a
href="https://doi.org/10.1007/s10462-025-11169-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral images provide rich spectral-spatial information but pose significant classification challenges due to high dimensionality, noise, mixed pixels, and limited labeled samples. Graph Neural Networks (GNNs) have emerged as a promising solution, offering a semi-supervised framework that can capture complex spatial-spectral relationships inherent in non-Euclidean hyperspectral image data. However, existing reviews often concentrate on specific aspects, thus limiting a comprehensive understanding of GNN-based hyperspectral image classification. This review systematically outlines the fundamental concepts of hyperspectral image classification and GNNs, and summarizes leading approaches from both traditional machine learning and deep learning. Then, it categorizes GNN-based methods into four paradigms: graph recurrent neural networks, graph convolutional networks, graph autoencoders, and hybrid graph neural networks, discussing their theoretical underpinnings, architectures, and representative applications. Finally, five key directions are further highlighted: adaptive graph construction, dynamic graph processing, deeper architectures, self-supervised strategies, and robustness enhancement. These insights aim to facilitate continued innovation in GNN-based hyperspectral imaging, guiding researchers toward more efficient and accurate classification frameworks.},
  archive      = {J_AIR},
  author       = {Zhao, Xiaofeng and Ma, Junyi and Wang, Lei and Zhang, Zhili and Ding, Yao and Xiao, Xiongwu},
  doi          = {10.1007/s10462-025-11169-y},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-56},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A review of hyperspectral image classification based on graph neural networks},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polyp segmentation in medical imaging: Challenges,
approaches and future directions. <em>AIR</em>, <em>58</em>(6), 1–61.
(<a href="https://doi.org/10.1007/s10462-025-11173-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer has been considered as the third most dangerous disease among the most common cancer types. The early diagnosis of the polyps weakens the spread of colorectal cancer and is significant for more productive treatment. The segmentation of polyps from the colonoscopy images is very critical and significant to identify colorectal cancer. In this comprehensive study, we meticulously scrutinize research papers focused on the automated segmentation of polyps in clinical settings using colonoscopy images proposed in the past five years. Our analysis delves into various dimensions, including input data (datasets and preprocessing methods), model design (encompassing CNNs, transformers, and hybrid approaches), loss functions, and evaluation metrics. By adopting a systematic perspective, we examine how different methodological choices have shaped current trends and identify critical limitations that need to be addressed. To facilitate meaningful comparisons, we provide a detailed summary table of all examined works. Moreover, we offer in-depth future recommendations for polyp segmentation based on the insights gained from this survey study. We believe that our study will serve as a great resource for future researchers in the subject of polyp segmentation offering vital support in the development of novel methodologies.},
  archive      = {J_AIR},
  author       = {Qayoom, Abdul and Xie, Juanying and Ali, Haider},
  doi          = {10.1007/s10462-025-11173-2},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-61},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Polyp segmentation in medical imaging: Challenges, approaches and future directions},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A context and sequence-based recommendation framework using
GRU networks. <em>AIR</em>, <em>58</em>(6), 1–36. (<a
href="https://doi.org/10.1007/s10462-025-11174-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems play a significant contribution in e-commerce for predicting the more relevant product to the customers based on their interests. The recommendation system refers to the user-item interaction and predicts the next item by considering the similar kind of user interest or item purchased. The context-aware and sequential recommendation is built to predict the interested product based on the current context and sequential behavior pattern interactions. To fulfill the customers’ requirements, this paper proposes a new hybrid personalized recommendation system framework called Target User Context Sequential Prediction Gated Recurrent Unit (TUCSP-GRU) using deep learning methods to recommend suitable products to the users based on their interests and context. The proposed system uses the newly calculated Target User Specific Product Rating (TUS-PR) score, the proposed TUS Gated Recurrent Unit (TUS-GRU) model, and the proposed Top-N item prediction method. Here, (i) the TUS-PR score is used to improve the product rating, (ii) the new TUS-GRU model is used to find the sequence purchase behavior pattern of customers by considering their long-term and short-term interests, and (iii) the proposed Top-N item dynamic prediction method is used to adjust the next interested item list based on the response using the back propagation continuous learning method. The experiment results of the TUCSP-GRU framework show better accuracy in predicting the interested and relevant products or items when compared to existing similar recommendation systems with respect to the standard evaluation metrics.},
  archive      = {J_AIR},
  author       = {Karthik, R. V. and Pandiyaraju, V. and Ganapathy, Sannasi},
  doi          = {10.1007/s10462-025-11174-1},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-36},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A context and sequence-based recommendation framework using GRU networks},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of machine learning in early warning system of
geotechnical disaster: A systematic and comprehensive review.
<em>AIR</em>, <em>58</em>(6), 1–45. (<a
href="https://doi.org/10.1007/s10462-025-11175-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancements in monitoring and computational technology have facilitated data accessibility and utilization. Machine learning, as an integral component of the realm of computational technology, is renowned for its universality and efficacy, rendering it pervasive across various domains. Geotechnical disaster early warning systems serve as a crucial safeguard for the preservation of human lives and assets. Machine learning exhibits the capacity to meet the exigencies of prompt and precise disaster prediction, prompting substantial interest in the nexus of these two domains in recent decades. This study accentuates the deployment of machine learning in addressing geotechnical engineering disaster prediction issues through an examination of four types of engineering-specialized research articles spanning the period 2009 to 2024. The study elucidates the evolution and significance of machine learning within the domain of geotechnical engineering disaster prediction, with an emphasis on data analytics and modeling. Addressing the lacunae in existing literature, a user-friendly front-end graphical interface, integrated with machine learning algorithms, is devised to better cater to the requisites of engineering professionals. Furthermore, this research delves into a critical analysis of the prevalent research limitations and puts forth prospective investigational avenues from an applied standpoint.},
  archive      = {J_AIR},
  author       = {Lin, Shan and Liang, Zenglong and Guo, Hongwei and Hu, Quanke and Cao, Xitailang and Zheng, Hong},
  doi          = {10.1007/s10462-025-11175-0},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-45},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Application of machine learning in early warning system of geotechnical disaster: A systematic and comprehensive review},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification using hyperdimensional computing: A review
with comparative analysis. <em>AIR</em>, <em>58</em>(6), 1–41. (<a
href="https://doi.org/10.1007/s10462-025-11181-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperdimensional computing (HD), also known as vector symbolic architectures (VSA), is an emerging and promising paradigm for cognitive computing. At its core, HD/VSA is characterized by its distinctive approach to compositionally representing information using high-dimensional randomized vectors. The recent surge in research within this field gains momentum from its computational efficiency stemming from low-resolution representations and ability to excel in few-shot learning scenarios. Nonetheless, the current literature is missing a comprehensive comparative analysis of various methods since each of them uses a different benchmark to evaluate its performance. This gap obstructs the monitoring of the field’s state-of-the-art advancements and acts as a significant barrier to its overall progress. To address this gap, this review not only offers a conceptual overview of the latest literature but also introduces a comprehensive comparative study of HD/VSA classification methods. The exploration starts with an overview of the strategies proposed to encode information as high-dimensional vectors. These vectors serve as integral components in the construction of classification models. Furthermore, we evaluate diverse classification methods as proposed in the existing literature. This evaluation encompasses techniques such as retraining and regenerative training to augment the model’s performance. To conclude our study, we present a comprehensive empirical study. This study serves as an in-depth analysis, systematically comparing various HD/VSA classification methods using two benchmarks, the first being a set of seven popular datasets used in HD/VSA and the second consisting of 121 datasets being the subset from the UCI Machine Learning repository. To facilitate future research on classification with HD/VSA, we open-sourced the benchmarking and the implementations of the methods we review. Since the considered data are tabular, encodings based on key-value pairs emerge as optimal choices, boasting superior accuracy while maintaining high efficiency. Secondly, iterative adaptive methods demonstrate remarkable efficacy, potentially complemented by a regenerative strategy, depending on the specific problem. Furthermore, we show how HD/VSA is able to generalize while training with a limited number of training instances. Lastly, we demonstrate the robustness of HD/VSA methods by subjecting the model memory to a large number of bit-flips. The results illustrate that the model’s performance remains reasonably stable until the occurrence of 40% of bit flips, where the model’s performance is drastically degraded. Overall, this study performed a thorough performance evaluation on different methods and, on the one hand, a positive trend was observed in terms of improving classification performance but, on the other hand, these developments could often be surpassed by off-the-shelf methods. This calls for better integration with the broader machine learning literature; the developed benchmarking framework provides practical means for doing so.},
  archive      = {J_AIR},
  author       = {Vergés, Pere and Heddes, Mike and Nunes, Igor and Kleyko, Denis and Givargis, Tony and Nicolau, Alexandru},
  doi          = {10.1007/s10462-025-11181-2},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-41},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Classification using hyperdimensional computing: A review with comparative analysis},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context in object detection: A systematic literature review.
<em>AIR</em>, <em>58</em>(6), 1–89. (<a
href="https://doi.org/10.1007/s10462-025-11186-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context is an important factor in computer vision as it offers valuable information to clarify and analyze visual data. Utilizing the contextual information inherent in an image or a video can improve the precision and effectiveness of object detectors. For example, where recognizing an isolated object might be challenging, context information can improve comprehension of the scene. This study explores the impact of various context-based approaches to object detection. Initially, we investigate the role of context in object detection and survey it from several perspectives. We then review and discuss the most recent context-based object detection approaches and compare them. Finally, we conclude by addressing research questions and identifying gaps for further studies. More than 265 publications are included in this survey, covering different aspects of context in different categories of object detection, including general object detection, video object detection, small object detection, camouflaged object detection, zero-shot, one-shot, and few-shot object detection. This literature review presents a comprehensive overview of the latest advancements in context-based object detection, providing valuable contributions such as a thorough understanding of contextual information and effective methods for integrating various context types into object detection, thus benefiting researchers.},
  archive      = {J_AIR},
  author       = {Jamali, Mahtab and Davidsson, Paul and Khoshkangini, Reza and Ljungqvist, Martin Georg and Mihailescu, Radu-Casian},
  doi          = {10.1007/s10462-025-11186-x},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-89},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Context in object detection: A systematic literature review},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LiDAR, IMU, and camera fusion for simultaneous localization
and mapping: A systematic review. <em>AIR</em>, <em>58</em>(6), 1–59.
(<a href="https://doi.org/10.1007/s10462-025-11187-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is a crucial technology for intelligent unnamed systems to estimate their motion and reconstruct unknown environments. However, the SLAM systems with merely one sensor have poor robustness and stability due to the defects in the sensor itself. Recent studies have demonstrated that SLAM systems with multiple sensors, mainly consisting of LiDAR, camera, and IMU, achieve better performance due to the mutual compensation of different sensors. This paper investigates recent progress on multi-sensor fusion SLAM. The review includes a systematic analysis of the advantages and disadvantages of different sensors and the imperative of multi-sensor solutions. It categorizes multi-sensor fusion SLAM systems into four main types by the fused sensors: LiDAR-IMU SLAM, Visual-IMU SLAM, LiDAR-Visual SLAM, and LiDAR-IMU-Visual SLAM, with detailed analysis and discussions of their pipelines and principles. Meanwhile, the paper surveys commonly used datasets and introduces evaluation metrics. Finally, it concludes with a summary of the existing challenges and future opportunities for multi-sensor fusion SLAM.},
  archive      = {J_AIR},
  author       = {Fan, Zheng and Zhang, Lele and Wang, Xueyi and Shen, Yilan and Deng, Fang},
  doi          = {10.1007/s10462-025-11187-w},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-59},
  shortjournal = {Artif. Intell. Rev.},
  title        = {LiDAR, IMU, and camera fusion for simultaneous localization and mapping: A systematic review},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive review on financial explainable AI.
<em>AIR</em>, <em>58</em>(6), 1–49. (<a
href="https://doi.org/10.1007/s10462-024-11077-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of artificial intelligence (AI), and deep learning models in particular, has led to their widespread adoption across various industries due to their ability to process huge amounts of data and learn complex patterns. However, due to their lack of explainability, there are significant concerns regarding their use in critical sectors, such as finance and healthcare, where decision-making transparency is of paramount importance. In this paper, we provide a comparative survey of methods that aim to improve the explainability of deep learning models within the context of finance. We categorize the collection of explainable AI methods according to their corresponding characteristics, and we review the concerns and challenges of adopting explainable AI methods, together with future directions we deemed appropriate and important.},
  archive      = {J_AIR},
  author       = {Yeo, Wei Jie and Van Der Heever, Wihan and Mao, Rui and Cambria, Erik and Satapathy, Ranjan and Mengaldo, Gianmarco},
  doi          = {10.1007/s10462-024-11077-7},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-49},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A comprehensive review on financial explainable AI},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dna coding theory and algorithms. <em>AIR</em>,
<em>58</em>(6), 1–37. (<a
href="https://doi.org/10.1007/s10462-025-11132-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DNA computing is an emerging computational model that has garnered significant attention due to its distinctive advantages at the molecular biological level. Since it was introduced by Adelman in 1994, this field has made remarkable progress in solving NP-complete problems, enhancing information security, encrypting images, controlling diseases, and advancing nanotechnology. A key challenge in DNA computing is the design of DNA coding, which aims to minimize nonspecific hybridization and enhance computational reliability. The DNA coding design is a classical combinatorial optimization problem focused on generating high-quality DNA sequences that meet specific constraints, including distance, thermodynamics, secondary structure, and sequence requirements. This paper comprehensively examines the advances in DNA coding design, highlighting mathematical models, counting theory, and commonly used DNA coding methods. These methods include the template method, multi-objective evolutionary methods, and implicit enumeration techniques.},
  archive      = {J_AIR},
  author       = {Xu, Jin and Liu, Wenbin and Zhang, Kai and Zhu, Enqiang},
  doi          = {10.1007/s10462-025-11132-x},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-37},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Dna coding theory and algorithms},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Current and future roles of artificial intelligence in
retinopathy of prematurity. <em>AIR</em>, <em>58</em>(6), 1–55. (<a
href="https://doi.org/10.1007/s10462-025-11153-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinopathy of prematurity (ROP) is a severe condition affecting premature infants, leading to abnormal retinal blood vessel growth, retinal detachment, and potential blindness. While semi-automated systems have been used in the past to diagnose ROP-related plus disease by quantifying retinal vessel features, traditional machine learning (ML) models face challenges like accuracy and overfitting. Recent advancements in deep learning (DL), especially convolutional neural networks (CNNs), have significantly improved ROP detection and classification. The i-ROP deep learning (i-ROP-DL) system also shows promise in detecting plus disease, offering reliable ROP diagnosis potential. This research comprehensively examines the contemporary progress and challenges associated with using retinal imaging and artificial intelligence (AI) to detect ROP, offering valuable insights that can guide further investigation in this domain. Based on 84 original studies in this field (out of 2025 studies that were comprehensively reviewed), we concluded that traditional methods for ROP diagnosis suffer from subjectivity and manual analysis, leading to inconsistent clinical decisions. AI holds great promise for improving ROP management. This review explores AI’s potential in ROP detection, classification, diagnosis, and prognosis.},
  archive      = {J_AIR},
  author       = {Jafarizadeh, Ali and Maleki, Shadi Farabi and Pouya, Parnia and Sobhi, Navid and Abdollahi, Mirsaeed and Pedrammehr, Siamak and Lim, Chee Peng and Asadi, Houshyar and Alizadehsani, Roohallah and Tan, Ru-San and Islam, Sheikh Mohammed Shariful and Acharya, U. Rajendra},
  doi          = {10.1007/s10462-025-11153-6},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-55},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Current and future roles of artificial intelligence in retinopathy of prematurity},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale graph diffusion convolutional network for
multi-view learning. <em>AIR</em>, <em>58</em>(6), 1–23. (<a
href="https://doi.org/10.1007/s10462-025-11158-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning has attracted considerable attention owing to its capability to learn more comprehensive representations. Although graph convolutional networks have achieved encouraging results in multi-view research, their limitation to considering only nearest neighbors results in the decrease on the ability to obtain high-order information. Many existing methods acquire high-order correlation by stacking multiple layers onto the model, yet they could lead to the issue of over-smoothing. In this paper, we propose a framework termed multi-scale graph diffusion convolutional network, which aims to gather comprehensive higher-order information without stacking multiple convolutional layers. Specifically, in order to better expand the receptive field of the node and reduce the parameter complexity, the proposed framework utilizes a contractive mapping to transform features from multiple views on decoupled propagation rules. Our framework introduces a multi-scale graph-based diffusion mechanism to adaptively extract the abundant high-order knowledge embedded within multi-scale graphs. Experiments show that the proposed method outperforms other state-of-the-art methods in terms of multi-view semi-supervised classification.},
  archive      = {J_AIR},
  author       = {Wang, Shiping and Li, Jiacheng and Chen, Yuhong and Wu, Zhihao and Huang, Aiping and Zhang, Le},
  doi          = {10.1007/s10462-025-11158-1},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-scale graph diffusion convolutional network for multi-view learning},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emrnet: Enhanced micro-expression recognition network with
attention and distance correlation. <em>AIR</em>, <em>58</em>(6), 1–27.
(<a href="https://doi.org/10.1007/s10462-025-11159-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expression recognition (MER) is inherently challenging due to the difficulty of extracting subtle, localized changes in micro-expressions (MEs). Various optical flow-based methods have been proposed for MER, as optical flow can effectively suppress facial identity information while capturing the movement patterns of MEs. However, these methods, characterized by simple architectures, often fail to extract discriminative features, resulting in suboptimal performance. In this paper, we propose an Enhanced Micro-expression Recognition Network with attention and distance correlation (EMRNet) for MER. EMRNet consists of three key phases: First, we introduce a novel channel-wise region-aware attention mechanism within two identical Inception networks, designed to extract global and local expression features in parallel, based on the optical flow input of the same ME. Second, to enhance ME representations, we propose a regularized dilated loss function incorporating distance correlation, which improves the information entropy transferred between the two branches. Last, emotion categories are predicted by fusing the expression-dilated features in the classification branch. Extensive experiments conducted on the composite database from the MEGC 2019 challenge demonstrate the effectiveness of EMRNet under both leave-one-subject-out (LOSO) cross-validation and the composite database evaluation (CDE) protocol. The results show that our approach successfully generates discriminative features, achieving substantial performance gains. Furthermore, EMRNet outperforms existing single-stream and dual-stream models, delivering superior results in MER.},
  archive      = {J_AIR},
  author       = {Liu, Gaqiong and Huang, Shucheng and Wang, Gang and Li, Mingxing},
  doi          = {10.1007/s10462-025-11159-0},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-27},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Emrnet: Enhanced micro-expression recognition network with attention and distance correlation},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bibliometric analysis of artificial intelligence cyberattack
detection models. <em>AIR</em>, <em>58</em>(6), 1–40. (<a
href="https://doi.org/10.1007/s10462-025-11167-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cybercriminals have increasingly adopted advanced and cutting-edge methods that expand the scale and speed of their attacks in recent years. This trend coincides with the rising demand for and scarcity of highly skilled cybersecurity specialists, making them both expensive and difficult to find. Recently, researchers have demonstrated the effectiveness of Artificial Intelligence (AI) approaches in combating sophisticated cyberattacks. However, comprehensive bibliometric data illustrating the study of AI approaches in cyberattack detection remain sparse. This study addresses this gap by investigating the current state of AI-based cyberattack detection research. The study analyzed the Scopus database using bibliometric analysis on a pool of over 2,338 articles published between 2014 and 2024, including 1217 journal articles, 828 conference papers, 121 conference reviews, 85 book chapters, 70 reviews, 5 editorials, and 2 books and short surveys. The study explores various AI-based cyberattack detection approaches globally, focusing on machine learning and deep learning algorithms. The bibliometric analysis was conducted using R, an open-source statistical tool, and Biblioshiny. The findings establish that AI, particularly machine learning and deep learning, enhances intrusion detection accuracy and is a growing research trend. Researchers have effectively employed these techniques for malware detection. The USA leads in AI cyberattack research, followed by India, China, Saudi Arabia, and Australia. Despite publishing fewer articles, Canada and Italy received significant citations. Additionally, strong research collaboration exists among the USA, China, Australia, Saudi Arabia, and India. Keyword analysis highlights AI’s effectiveness in identifying patterns and malicious behaviours, enhancing intrusion detection even in complex cyberattacks. Machine learning can detect intrusions based on anomalies caused by malicious or compromised devices, as well as unknown threats, with speed, accuracy, and a low false-positive rate.},
  archive      = {J_AIR},
  author       = {Guembe, Blessing and Misra, Sanjay and Azeta, Ambrose and Lopez-Baldominos, Ines},
  doi          = {10.1007/s10462-025-11167-0},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-40},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Bibliometric analysis of artificial intelligence cyberattack detection models},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MambaYOLACT: You only look at mamba prediction head for
head-neck lymph nodes. <em>AIR</em>, <em>58</em>(6), 1–24. (<a
href="https://doi.org/10.1007/s10462-025-11177-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lymph nodes in the head-neck are often infected when malignant tumors metastasize. At present, Magnetic Resonance Imaging (MRI) is widely used in the evaluation of head-neck lymph nodes. However, there are some problems, such as different sizes, low contrast of head-neck lymph nodes. The instance segmentation accuracy of head-neck lymph nodes is decreased, which affects the patients treatment decision and the surgical effect evaluation. To solve these problems, a single stage Mamba YOLACT instance segmentation model is proposed in this paper. The main contributions are as follows: Firstly, a Cross-field and Cross-direction Feature Enhancement module (CCFE) is designed. The module through the channel grouping mechanism, effectively enhances the ability of each group of features to express different spatial semantic information, by mixing attention mechanism to improve the feature extraction ability of lesions with different dimensions. Secondly, a MambaNet-based prediction head module is designed. The module combined the State-Space Model (SSM) and self-attention mechanism to accurately capture global image dependencies, highlight the lesion area. Thirdly, A dataset of MRI images of head-neck lymph nodes is used to verify the model effectiveness. The results show that the values of APdet, APseg, ARdet, ARseg, mAPdet and mAPseg are 69.8%, 70.9%, 55.3%, 56.4%, 39.4% and 41.0%, respectively. The model can achieve accurate segmentation of the lymph nodes, which has positive significance for lymph nodes auxiliary diagnosis.},
  archive      = {J_AIR},
  author       = {Zhou, Tao and Chai, Wenwen and Chang, Defang and Chen, Kaixiong and Zhang, Zhe and Lu, HuiLing},
  doi          = {10.1007/s10462-025-11177-y},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Artif. Intell. Rev.},
  title        = {MambaYOLACT: You only look at mamba prediction head for head-neck lymph nodes},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guidelines for designing visualization tools for group
fairness analysis in binary classification. <em>AIR</em>,
<em>58</em>(6), 1–38. (<a
href="https://doi.org/10.1007/s10462-025-11179-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of machine learning in decision-making has become increasingly pervasive across various fields, from healthcare to finance, enabling systems to learn from data and improve their performance over time. The transformative impact of these new technologies warrants several considerations that demand the development of modern solutions through responsible artificial intelligence—the incorporation of ethical principles into the creation and deployment of AI systems. Fairness is one such principle, ensuring that machine learning algorithms do not produce biased outcomes or discriminate against any group of the population with respect to sensitive attributes, such as race or gender. In this context, visualization techniques can help identify data imbalances and disparities in model performance across different demographic groups. However, there is a lack of guidance towards clear and effective representations that support entry-level users in fairness analysis, particularly when considering that the approaches to fairness visualization can vary significantly. In this regard, the goal of this work is to present a comprehensive analysis of current tools directed at visualizing and examining group fairness in machine learning, with a focus on both data and binary classification model outcomes. These visualization tools are reviewed and discussed, concluding with the proposition of a focused set of visualization guidelines directed towards improving the comprehensibility of fairness visualizations.},
  archive      = {J_AIR},
  author       = {Cruz, António and Salazar, Teresa and Carvalho, Manuel and Maçãs, Catarina and Machado, Penousal and Abreu, Pedro Henriques},
  doi          = {10.1007/s10462-025-11179-w},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-38},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Guidelines for designing visualization tools for group fairness analysis in binary classification},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computer vision based approaches for fish monitoring
systems: A comprehensive study. <em>AIR</em>, <em>58</em>(6), 1–44. (<a
href="https://doi.org/10.1007/s10462-025-11180-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fish monitoring has become increasingly popular due to its growing real-world applications and recent advancements in intelligent technologies such as AI, Computer Vision, and Robotics. The primary objective of this article is to review benchmark datasets used in fish monitoring while introducing a novel framework that categorizes fish monitoring applications into four main domains: Fish Detection and Recognition (FDR), Fish Biomass Estimation (FBE), Fish Behavior Classification (FBC), and Fish Health Analysis (FHA). Additionally, this study proposes dedicated workflows for each domain, marking the first comprehensive effort to establish such a structured approach in this field. The detection and recognition of fish involve identifying fish and fish species. Estimating fish biomass focuses on counting fish and measuring their size and weight. Fish Behavior Classification tracks and analyzes movement and extracts behavioral patterns. Finally, health analysis assesses the general health of the fish. The methodologies and techniques are analyzed separately within each domain, providing a detailed examination of their specific applications and contributions to fish monitoring. These innovations enable fish species classification, fish freshness evaluation, fish counting, and body length measurement for biomass estimation. The study concludes by reviewing the development of key datasets and techniques over time, identifying existing gaps and limitations in current frameworks, and proposing future research directions in fish monitoring applications.},
  archive      = {J_AIR},
  author       = {Al-Abri, Said and Keshvari, Sanaz and Al-Rashdi, Khalfan and Al-Hmouz, Rami and Bourdoucen, Hadj},
  doi          = {10.1007/s10462-025-11180-3},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-44},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Computer vision based approaches for fish monitoring systems: A comprehensive study},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pathologyvlm: A large vision-language model for pathology
image understanding. <em>AIR</em>, <em>58</em>(6), 1–19. (<a
href="https://doi.org/10.1007/s10462-025-11190-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The previous advancements in pathology image understanding primarily involved developing models tailored to specific tasks. Recent studies have demonstrated that the large vision-language model can enhance the performance of various downstream tasks in medical image understanding. In this study, we developed a domain-specific large vision-language model (PathologyVLM) for pathology image understanding. Specifically, (1) we first construct a human pathology image-text dataset by cleaning the public medical image-text data for domain-specific alignment; (2) Using the proposed image-text data, we first train a pathology language-image pretraining (PLIP) model as the specialized visual encoder to extract the features of pathology image, and then we developed scale-invariant connector to avoid the information loss caused by image scaling; (3) We adopt two-stage learning to train PathologyVLM, first stage for domain alignment, and second stage for end to end visual question &amp; answering (VQA) task. In experiments, we evaluate our PathologyVLM on both supervised and zero-shot VQA datasets, our model achieved the best overall performance among multimodal models of similar scale. The ablation experiments also confirmed the effectiveness of our design. We posit that our PathologyVLM model and the datasets presented in this work can promote research in field of computational pathology. All codes are available at: https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA},
  archive      = {J_AIR},
  author       = {Dai, Dawei and Zhang, Yuanhui and Yang, Qianlan and Xu, Long and Shen, Xiaojing and Xia, Shuyin and Wang, Guoyin},
  doi          = {10.1007/s10462-025-11190-1},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Pathologyvlm: A large vision-language model for pathology image understanding},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sustainable AI-driven wind energy forecasting: Advancing
zero-carbon cities and environmental computation. <em>AIR</em>,
<em>58</em>(6), 1–35. (<a
href="https://doi.org/10.1007/s10462-025-11191-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of wind speed and power is transforming renewable wind farm management, facilitating efficient energy supply for smart and zero-energy cities. This paper introduces a novel low-carbon Sustainable AI-Driven Wind Energy Forecasting System (SAI-WEFS) developed from a promising real-world case study in MENA region. The SAI-WEFS evaluates twelve machine learning algorithms, utilizing both single and ensemble models for forecasting wind speed (WSF) and wind power (WPF) across multiple timeframes (10 min, 30 min, 6 h, 24 h, and 36 h). The system integrates multi-time horizon predictions, where the WSF output is input for the WPF model. The environmental impact of each algorithm is assessed based on CO2 emissions for each computational hour. Predictive accuracy is assessed using mean square error (MSE) and mean absolute percentage error (MAPE). Results indicate that ensemble algorithms consistently outperform single ML models, with tree-based models demonstrating a lower environmental impact, emitting approximately 60 g of CO2 per computational hour compared to deep learning models, which emit up to 500 g per hour. This system enhances the Urban Energy Supply Decarbonization Framework (UESDF) by predicting the Urban Carbon Emission Index (UCEI) to illustrate the Urban Carbon Transition Curve.},
  archive      = {J_AIR},
  author       = {Elmousalami, Haytham and Alnaser, Aljawharah A. and Hui, Felix Kin Peng},
  doi          = {10.1007/s10462-025-11191-0},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-35},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Sustainable AI-driven wind energy forecasting: Advancing zero-carbon cities and environmental computation},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-strategy improved snow ablation optimizer: A case
study of optimization of kernel extreme learning machine for flood
prediction. <em>AIR</em>, <em>58</em>(6), 1–47. (<a
href="https://doi.org/10.1007/s10462-025-11192-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kernel Extreme Learning Machine (KELM) has the advantage of automatically extracting data features, learning and processing nonlinear problems from historical data, which can help achieve better prediction results for flood prediction problems with complex and sudden causes. Traditional flood disaster prediction usually only considers one influencing factor without considering the complex factors that affect flood occurrence. This article develops a new method for predicting the probability of flood occurrence based on 20 influencing factors. Firstly, in order to better utilize KELM performance, an improved snow ablation optimization algorithm (MESAO) was proposed for subsequent experiments by introducing a level based selection pressure mechanism, covariance matrix learning strategy, historical position based boundary adjustment strategy, and random centroid reverse learning strategy into snow ablation optimization (SAO). Secondly, MESAO is used to perform hyperparameter optimization on the regularization coefficient C and kernel function parameter S of the KELM model. Finally, the construction of a multi feature input–output model for the application of MESAO-KELM in flood prediction problems was completed. In terms of hyperparameter optimization, the numerical experimental results of this method were superior to the prediction results of 10 other intelligent algorithms and 5 regression prediction models. According to the evaluation index results, the best adaptability of MESAO optimized KELM and higher prediction accuracy and stability compared to other prediction models were demonstrated. This method overcomes the limitations of traditional prediction models based on a single influencing factor and can predict the probability of flood occurrence based on complex and variable factors. It can be said that MESAO-KELM has strong generalization ability. Accurate flood prediction can provide early warning and take measures in advance to protect and reduce the impact of floods on human and social development.},
  archive      = {J_AIR},
  author       = {Cui, Lele and Hu, Gang and Zhu, Yaolin},
  doi          = {10.1007/s10462-025-11192-z},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-47},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Multi-strategy improved snow ablation optimizer: A case study of optimization of kernel extreme learning machine for flood prediction},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A step gravitational search algorithm for function
optimization and STTM’s synchronous feature selection-parameter
optimization. <em>AIR</em>, <em>58</em>(6), 1–49. (<a
href="https://doi.org/10.1007/s10462-025-11193-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The support tensor train machine (STTM) can make full use of the correlation of tensor data structures, while the parameter training is inefficient and feature redundancy is large. For this, a step gravitational search algorithm (SGSA) is proposed and used for synchronous feature selection and parameter optimization of STTM in this paper. Since the single population structure of the gravitational search algorithm is difficult to balance exploration and exploitation effectively, a new dual population structure is defined by the step function. Subpopulation Pop1 focuses on exploration, and a Kbest-Elite hybrid learning strategy is designed to avoid the rapid decline of exploration ability due to the rapid reduction of the size of Kbest set as well as the gravitational constant G. Subpopulation Pop2 focuses on exploitation, and a position update strategy that integrates Cauchy distribution and Gaussian distribution is designed to make Pop2 always have a certain exploration ability. Finally, use SGSA to solve the synchronous feature selection and parameter optimization problem of STTM (the resulting model is denoted as SGSA-STTM). The algorithm’s optimization performance test results show that SGSA can obtain relatively best results on most test functions compared with other state-of-the-art algorithms. The classification performance test on fMRI datasets shows that SGSA-STTM can remove more than 40% of redundant features on most datasets, which can effectively improve the efficiency of the algorithm, and the classification accuracy for the StarPlus fMRI dataset and the CMU Science 2008 fMRI dataset reached 60 and 70%, respectively.},
  archive      = {J_AIR},
  author       = {Fan, Chaodong and Yang, Laurence T. and Xiao, Leyi},
  doi          = {10.1007/s10462-025-11193-y},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-49},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A step gravitational search algorithm for function optimization and STTM’s synchronous feature selection-parameter optimization},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic literature review on municipal solid waste
management using machine learning and deep learning. <em>AIR</em>,
<em>58</em>(6), 1–51. (<a
href="https://doi.org/10.1007/s10462-025-11196-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population growth and urbanization have led to a significant increase in solid waste. However, conventional methods of treating and recycling this waste have inherent problems, such as low efficiency, poor precision, high cost, and severe environmental hazards. To address these challenges, Artificial Intelligence (AI) has gained popularity in recent years as a potential solution for municipal solid-waste management (MSWM). A few applications of AI, based on Machine Learning (ML) and Deep Learning (DL) techniques, have been used for MSWM. This study reviews the current landscape in MSWM, highlighting the existing advantages and disadvantages of 69 studies published between 2018 and 2024 using the PRISMA methodology. The applications of ML and DL algorithms demonstrate their ability to enhance decision-making processes, improve resource recovery rates, and promote circular economy principles. Although these technologies offer promising solutions, challenges such as data availability, quality, and interdisciplinary collaboration hinder their effective implementation. The paper suggests future research directions focusing on developing robust datasets, fostering partnerships across sectors, and integrating advanced technologies with traditional waste management strategies. This research aligns with the United Nations’ Sustainable Development Goals (SDG), particularly Goal 11, which aims to make cities inclusive, safe, resilient, and sustainable. In the future, this research can contribute to making cities smarter, greener, and more resilient using ML and DL techniques.},
  archive      = {J_AIR},
  author       = {Dawar, Ishaan and Srivastava, Anisha and Singal, Maanas and Dhyani, Nirjara and Rastogi, Suvi},
  doi          = {10.1007/s10462-025-11196-9},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-51},
  shortjournal = {Artif. Intell. Rev.},
  title        = {A systematic literature review on municipal solid waste management using machine learning and deep learning},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised hypergraph structure learning. <em>AIR</em>,
<em>58</em>(6), 1–30. (<a
href="https://doi.org/10.1007/s10462-025-11199-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Hypergraph Neural Networks (HGNNs) often assume that hypergraph structures are perfectly constructed, yet real-world hypergraphs are typically corrupted by noise, missing data, or irrelevant information, limiting the effectiveness of hypergraph learning. To address this challenge, we propose SHSL, a novel Self-supervised Hypergraph Structure Learning framework that jointly explores and optimizes hypergraph structures without external labels. SHSL consists of two key components: a self-organizing initialization module that constructs latent hypergraph representations, and a differentiable optimization module that refines hypergraphs through gradient-based learning. These modules collaboratively capture high-order dependencies to enhance hypergraph representations. Furthermore, SHSL introduces a dual learning mechanism to simultaneously guide structure exploration and optimization within a unified framework. Experiments on six public datasets demonstrate that SHSL outperforms state-of-the-art baselines, achieving Accuracy improvements of 1.36% $$-$$ 32.37% and 2.23% $$-$$ 27.54% on hypergraph exploration and optimization tasks, and 1.19% $$-$$ 8.4% on non-hypergraph datasets. Robustness evaluations further validate SHSL’s effectiveness under noisy and incomplete scenarios, highlighting its practical applicability. The implementation of SHSL and all experimental codes are publicly available at: https://github.com/MingyuanLi88888/SHSL.},
  archive      = {J_AIR},
  author       = {Li, Mingyuan and Yang, Yanlin and Meng, Lei and Peng, Lu and Zhao, Haixing and Ye, Zhonglin},
  doi          = {10.1007/s10462-025-11199-6},
  journal      = {Artificial Intelligence Review},
  month        = {6},
  number       = {6},
  pages        = {1-30},
  shortjournal = {Artif. Intell. Rev.},
  title        = {Self-supervised hypergraph structure learning},
  volume       = {58},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="aism---5">AISM - 5</h2>
<ul>
<li><details>
<summary>
(2025). Testing overidentifying restrictions on high-dimensional
instruments and covariates. <em>AISM</em>, <em>77</em>(2), 331–352. (<a
href="https://doi.org/10.1007/s10463-024-00918-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The validity of instruments plays a crucial role in addressing endogenous treatment effects and instruments that violate the exclusion restriction are invalid. This paper concerns the overidentifying restrictions test for evaluating the validity of instruments in the high-dimensional instrumental variable model. We confront the challenge of high dimensionality by introducing a new testing procedure based on U-statistic. Our procedure allows the number of instruments and covariates to be in exponential order of the sample size. Under some mild conditions, we establish the asymptotic normality of the proposed test statistic under the null and local alternative hypotheses. The effectiveness of the proposed method is clearly supported by simulations and its application to a real dataset on trade and economic growth.},
  archive      = {J_AISM},
  author       = {Shi, Hongwei and Zhang, Xinyu and Guo, Xu and He, Baihua and Wang, Chenyang},
  doi          = {10.1007/s10463-024-00918-5},
  journal      = {Annals of the Institute of Statistical Mathematics},
  month        = {4},
  number       = {2},
  pages        = {331-352},
  shortjournal = {Ann. Inst. Stat. Math.},
  title        = {Testing overidentifying restrictions on high-dimensional instruments and covariates},
  volume       = {77},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random mixture cox point processes. <em>AISM</em>,
<em>77</em>(2), 289–330. (<a
href="https://doi.org/10.1007/s10463-024-00915-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study a new class of Cox point processes, based on random mixture models of exponential family components for the intensity function of the underlying Poisson process. We investigate theoretical properties of the proposed probability distributions of the point process, as well as provide procedures for parameter estimation using a classical and Bayesian approach. We illustrate the richness of the new models through examples, simulations and real data applications.},
  archive      = {J_AISM},
  author       = {Micheas, A. C.},
  doi          = {10.1007/s10463-024-00915-8},
  journal      = {Annals of the Institute of Statistical Mathematics},
  month        = {4},
  number       = {2},
  pages        = {289-330},
  shortjournal = {Ann. Inst. Stat. Math.},
  title        = {Random mixture cox point processes},
  volume       = {77},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-sample properties of multiple imputation estimators
for parameters of logistic regression with covariates missing at random
separately or simultaneously. <em>AISM</em>, <em>77</em>(2), 251–287.
(<a href="https://doi.org/10.1007/s10463-024-00914-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine the asymptotic properties of two multiple imputation (MI) estimators, given in the study of Lee et al. (Computational Statistics, 38, 899–934, 2023) for the parameters of logistic regression with both sets of discrete or categorical covariates that are missing at random separately or simultaneously. The proposed estimated asymptotic variances of the two MI estimators address a limitation observed with Rubin’s estimated variances, which lead to underestimate the variances of the two MI estimators (Rubin, 1987, Statistical Analysis with Missing Data, New York:Wiley). Simulation results demonstrate that our two proposed MI methods outperform the complete-case, semiparametric inverse probability weighting, random forest MI using chained equations, and stochastic approximation of expectation-maximization methods. To illustrate the methodology’s practical application, we provide a real data example from a survey conducted at the Feng Chia night market in Taichung City, Taiwan.},
  archive      = {J_AISM},
  author       = {Tran, Phuoc-Loc and Lee, Shen-Ming and Le, Truong-Nhat and Li, Chin-Shang},
  doi          = {10.1007/s10463-024-00914-9},
  journal      = {Annals of the Institute of Statistical Mathematics},
  month        = {4},
  number       = {2},
  pages        = {251-287},
  shortjournal = {Ann. Inst. Stat. Math.},
  title        = {Large-sample properties of multiple imputation estimators for parameters of logistic regression with covariates missing at random separately or simultaneously},
  volume       = {77},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison and equality of generalized <span
class="math display"><em>ψ</em></span> -estimators. <em>AISM</em>,
<em>77</em>(2), 217–250. (<a
href="https://doi.org/10.1007/s10463-024-00916-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We solve the comparison problem for generalized $$\psi $$ -estimators introduced by Barczy and Páles (arXiv: 2211.06026, 2022). Namely, we derive several necessary and sufficient conditions under which a generalized $$\psi $$ -estimator less than or equal to another $$\psi $$ -estimator for any sample. We also solve the corresponding equality problem for generalized $$\psi $$ -estimators. We also apply our results for some known statistical estimators such as for empirical expectiles and Mathieu-type estimators and for solutions of likelihood equations in case of normal, a Beta-type, Gamma, Lomax (Pareto type II), lognormal and Laplace distributions.},
  archive      = {J_AISM},
  author       = {Barczy, Mátyás and Páles, Zsolt},
  doi          = {10.1007/s10463-024-00916-7},
  journal      = {Annals of the Institute of Statistical Mathematics},
  month        = {4},
  number       = {2},
  pages        = {217-250},
  shortjournal = {Ann. Inst. Stat. Math.},
  title        = {Comparison and equality of generalized $$\psi $$ -estimators},
  volume       = {77},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confidence bounds for the true discovery proportion based on
the exact distribution of the number of rejections. <em>AISM</em>,
<em>77</em>(2), 191–216. (<a
href="https://doi.org/10.1007/s10463-024-00920-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiple hypotheses testing it has become widely popular to make inference on the true discovery proportion (TDP) of a set $$\mathscr {M}$$ of null hypotheses. This approach is useful for several application fields, such as neuroimaging and genomics. Several procedures to compute simultaneous lower confidence bounds for the TDP have been suggested in prior literature. Simultaneity allows for post-hoc selection of $$\mathscr {M}$$ . If sets of interest are specified a priori, it is possible to gain power by removing the simultaneity requirement. We present an approach to compute lower confidence bounds for the TDP if the set of null hypotheses is defined a priori. The proposed method determines the bounds using the exact distribution of the number of rejections based on a step-up multiple testing procedure under independence assumptions. We assess robustness properties of our procedure and apply it to real data from the field of functional magnetic resonance imaging.},
  archive      = {J_AISM},
  author       = {Preusse, Friederike and Vesely, Anna and Dickhaus, Thorsten},
  doi          = {10.1007/s10463-024-00920-x},
  journal      = {Annals of the Institute of Statistical Mathematics},
  month        = {4},
  number       = {2},
  pages        = {191-216},
  shortjournal = {Ann. Inst. Stat. Math.},
  title        = {Confidence bounds for the true discovery proportion based on the exact distribution of the number of rejections},
  volume       = {77},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="amai---14">AMAI - 14</h2>
<ul>
<li><details>
<summary>
(2025). Single MCMC chain parallelisation on decision trees.
<em>AMAI</em>, <em>93</em>(1), 219–232. (<a
href="https://doi.org/10.1007/s10472-023-09876-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees (DT) are highly famous in machine learning and usually acquire state-of-the-art performance. Despite that, well-known variants like CART, ID3, random forest, and boosted trees miss a probabilistic version that encodes prior assumptions about tree structures and shares statistical strength between node parameters. Existing work on Bayesian DT depends on Markov Chain Monte Carlo (MCMC), which can be computationally slow, especially on high dimensional data and expensive proposals. In this study, we propose a method to parallelise a single MCMC DT chain on an average laptop or personal computer that enables us to reduce its run-time through multi-core processing while the results are statistically identical to conventional sequential implementation. We also calculate the theoretical and practical reduction in run time, which can be obtained utilising our method on multi-processor architectures. Experiments showed that we could achieve 18 times faster running time provided that the serial and the parallel implementation are statistically identical.},
  archive      = {J_AMAI},
  author       = {Drousiotis, Efthyvoulos and Spirakis, Paul},
  doi          = {10.1007/s10472-023-09876-9},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {219-232},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Single MCMC chain parallelisation on decision trees},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two parameter-tuned multi-objective evolutionary-based
algorithms for zoning management in marine spatial planning.
<em>AMAI</em>, <em>93</em>(1), 187–218. (<a
href="https://doi.org/10.1007/s10472-023-09853-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic spatial planning is becoming more popular around the world as a decision-making way to build a unified vision for directing the medium- to long-term development of land/marine areas. Recently, the study of marine areas in terms of spatial planning such as Marine Spatial Planning (MSP) has received much attention. One of the challenging issues in MSP is to make a balance between determining the ideal zone for a new activity while also considering the locations of existing activities. This spatial zoning problem for multi-uses with multiple objectives could be formulated as optimization models. This paper presents and compares the results of two multi-objective evolutionary-based algorithms (MOEAs), Synchronous Hypervolume-based non-dominated sorting genetic algorithm-II (SH-NSGA-II) which is an extension of NSGA-II and a memetic algorithm (MA) in which SH-NSGA-II is enhanced with a local search. These proposed algorithms are used to solve the multi-objective spatial zoning optimization problem, which seeks to maximize the zone interest value assigned to the new activity while simultaneously maximizing its spatial compactness. We introduce several innovations in these proposed algorithms to address the problem constraints and to improve the robustness of the traditional NSGA-II and MA approaches. Unlike traditional ones, a different stop condition, multiple crossover, mutation, and repairing operators, and also a local search operator are developed. A comparative study is presented between the results obtained using both algorithms. To guarantee robust results for both algorithms, their parameters are calibrated and tuned using the Multi-Response Surface Methodology (MRSM) method. The effective and non-effective components, as well as the validity of the regression models, are determined using analysis of variance (ANOVA). Although SH-NSGA-II has revealed a good efficiency, its performance is still improved using a local search scheme within SH-NSGA-II, which is specially tailored to the problem characteristics. The two methods are designed for raster data.},
  archive      = {J_AMAI},
  author       = {Basirati, Mohadese and Billot, Romain and Meyer, Patrick},
  doi          = {10.1007/s10472-023-09853-2},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {187-218},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Two parameter-tuned multi-objective evolutionary-based algorithms for zoning management in marine spatial planning},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clique detection with a given reliability. <em>AMAI</em>,
<em>93</em>(1), 173–186. (<a
href="https://doi.org/10.1007/s10472-024-09928-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a new notion of a clique reliability. The clique reliability is understood as the ratio of the number of statistically significant links in a clique to the number of edges of the clique. This notion relies on a recently proposed original technique for separating inferences about pairwise connections between vertices of a network into significant and admissible ones. In this paper, we propose an extension of this technique to the problem of clique detection. We propose a method of step-by-step construction of a clique with a given reliability. The results of constructing cliques with a given reliability using data on the returns of stocks included in the Dow Jones index are presented.},
  archive      = {J_AMAI},
  author       = {Semenov, Dmitry and Koldanov, Alexander and Koldanov, Petr and Pardalos, Panos},
  doi          = {10.1007/s10472-024-09928-8},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {173-186},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Clique detection with a given reliability},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing doubly stochastic matrices for average consensus
through swarm and evolutionary algorithms. <em>AMAI</em>,
<em>93</em>(1), 151–171. (<a
href="https://doi.org/10.1007/s10472-023-09912-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Doubly-stochastic matrices play a vital role in modern applications of complex networks such as tracking and decentralized state estimation, coordination and control of autonomous agents. A central theme in all of the above is consensus, that is, nodes reaching agreement about the value of an underlying variable (e.g. the state of the environment). Despite the fact that complex networks have been studied thoroughly, the communication graphs are usually described by symmetric matrices due to their advantageous theoretical properties. We do not yet have methods for optimizing generic doubly-stochastic matrices. In this paper, we propose a novel formulation and framework, EvoDSM, for achieving fast linear distributed averaging by: (a) optimizing the weights of a fixed graph topology, and (b) optimizing for the topology itself. We are concerned with graphs that can be described by positive doubly-stochastic matrices. Our method relies on swarm and evolutionary optimization algorithms and our experimental results and analysis showcase that our method (1) achieves comparable performance with traditional methods for symmetric graphs, (2) is applicable to non-symmetric network structures and edge weights, and (3) is scalable and can operate effectively with moderately large graphs without engineering overhead.},
  archive      = {J_AMAI},
  author       = {Syriopoulos, Panos K. and Chatzilygeroudis, Konstantinos I. and Kalampalikis, Nektarios G. and Vrahatis, Michael N.},
  doi          = {10.1007/s10472-023-09912-8},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {151-171},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Optimizing doubly stochastic matrices for average consensus through swarm and evolutionary algorithms},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel method for solving universum twin bounded support
vector machine in the primal space. <em>AMAI</em>, <em>93</em>(1),
131–150. (<a href="https://doi.org/10.1007/s10472-023-09896-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supervised learning, the Universum, a third class that is not a part of either class in the classification task, has proven to be useful. In this study we propose (N $$ \mathfrak {U} $$ TBSVM), a Newton-based approach for solving in the primal space the optimization problems related to Twin Bounded Support Vector Machines with Universum data ( $$ \mathfrak {U} $$ TBSVM). In the N $$ \mathfrak {U} $$ TBSVM, the constrained programming problems of $$ \mathfrak {U} $$ TBSVM are converted into unconstrained optimization problems, and a generalization of Newton’s method for solving the unconstrained problems is introduced. Numerical experiments on synthetic, UCI, and NDC data sets show the ability and effectiveness of the proposed N $$ \mathfrak {U} $$ TBSVM. We apply the suggested method for gender detection from face images, and compare it with other methods.},
  archive      = {J_AMAI},
  author       = {Moosaei, Hossein and Khosravi, Saeed and Bazikar, Fatemeh and Hladík, Milan and Rosario Guarracino, Mario},
  doi          = {10.1007/s10472-023-09896-5},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {131-150},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {A novel method for solving universum twin bounded support vector machine in the primal space},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Realtime gray-box algorithm configuration using
cost-sensitive classification. <em>AMAI</em>, <em>93</em>(1), 109–130.
(<a href="https://doi.org/10.1007/s10472-023-09890-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A solver’s runtime and the quality of the solutions it generates are strongly influenced by its parameter settings. Finding good parameter configurations is a formidable challenge, even for fixed problem instance distributions. However, when the instance distribution can change over time, a once effective configuration may no longer provide adequate performance. Realtime algorithm configuration (RAC) offers assistance in finding high-quality configurations for such distributions by automatically adjusting the configurations it recommends based on instances seen so far. Existing RAC methods treat the solver as a black box, meaning the solver is given a configuration as input, and it outputs either a solution or runtime as an objective function for the configurator. However, analyzing intermediate output from the solver can enable configurators to avoid wasting time on poorly performing configurations. We propose a gray-box approach that utilizes intermediate output during evaluation and implement it within the RAC method Contextual Preselection with Plackett-Luce (CPPL blue). We apply cost-sensitive machine learning with pairwise comparisons to determine whether ongoing evaluations can be terminated to free resources. We compare our approach to a black-box equivalent on several experimental settings and show that our approach reduces the total solving time in several scenarios and improves solution quality in an additional scenario.},
  archive      = {J_AMAI},
  author       = {Weiss, Dimitri and Tierney, Kevin},
  doi          = {10.1007/s10472-023-09890-x},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {109-130},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Realtime gray-box algorithm configuration using cost-sensitive classification},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel SVM-based classification approaches for evaluating
pancreatic carcinoma. <em>AMAI</em>, <em>93</em>(1), 93–108. (<a
href="https://doi.org/10.1007/s10472-023-09888-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop two SVM-based classifiers named stable nested one-class support vector machines (SN-1SVMs) and decoupled margin-moment based SVMs (DMMB-SVMs), to predict the specific type of pancreatic carcinoma using quantitative histopathological signatures of images. For each patient, the diagnosis can produce hundreds of images, which can be used to classify the pancreatic tissues into three classes: chronic pancreatitis, intraductal papillary mucinous neoplasms, and pancreatic carcinoma. The proposed two approaches tackle the classification problems from two different perspectives: the SN-1SVM treats each image as a classification point in a nested fashion to predict malignancy of the tissues, while the DMMB-SVM treats each patient as a classification point by assembling information across images. One attractive feature of the DMMB-SVM is that, in addition to utilizing the mean information, it also takes into account the covariance of features extracted from images for each patient. We conduct numerical experiments to evaluate and compare performance of the two methods. It is observed that the SN-1SVM can take advantage of the data structure more effectively, while the DMMB-SVM demonstrates better computational efficiency and classification accuracy. To further improve interpretability of the final classifier, we also consider the $$\ell _1$$ -norm in the DMMB-SVM to handle feature selection.},
  archive      = {J_AMAI},
  author       = {Washburn, Ammon and Fan, Neng and Zhang, Hao Helen},
  doi          = {10.1007/s10472-023-09888-5},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {93-108},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Novel SVM-based classification approaches for evaluating pancreatic carcinoma},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian optimization over the probability simplex.
<em>AMAI</em>, <em>93</em>(1), 77–91. (<a
href="https://doi.org/10.1007/s10472-023-09883-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian Process based Bayesian Optimization is largely adopted for solving problems where the inputs are in Euclidean spaces. In this paper we associate the inputs to discrete probability distributions which are elements of the probability simplex. To search in the new design space, we need a distance between distributions. The optimal transport distance (aka Wasserstein distance) is chosen due to its mathematical structure and the computational strategies enabled by it. Both the GP and the acquisition function is generalized to an acquisition functional over the probability simplex. To optimize this functional two methods are proposed, one based on auto differentiation and the other based on proximal-point algorithm and the gradient flow. Finally, we report a preliminary set of computational results on a class of problems whose dimension ranges from 5 to 100. These results show that embedding the Bayesian optimization process in the probability simplex enables an effective algorithm whose performance over standard Bayesian optimization improves with the increase of problem dimensionality.},
  archive      = {J_AMAI},
  author       = {Candelieri, Antonio and Ponti, Andrea and Archetti, Francesco},
  doi          = {10.1007/s10472-023-09883-w},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {77-91},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Bayesian optimization over the probability simplex},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KNN classification: A review. <em>AMAI</em>, <em>93</em>(1),
43–75. (<a href="https://doi.org/10.1007/s10472-023-09882-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k-nearest neighbors (k/NN) algorithm is a simple yet powerful non-parametric classifier that is robust to noisy data and easy to implement. However, with the growing literature on k/NN methods, it is increasingly challenging for new researchers and practitioners to navigate the field. This review paper aims to provide a comprehensive overview of the latest developments in the k/NN algorithm, including its strengths and weaknesses, applications, benchmarks, and available software with corresponding publications and citation analysis. The review also discusses the potential of k/NN in various data science tasks, such as anomaly detection, dimensionality reduction and missing value imputation. By offering an in-depth analysis of k/NN, this paper serves as a valuable resource for researchers and practitioners to make informed decisions and identify the best k/NN implementation for a given application.},
  archive      = {J_AMAI},
  author       = {Syriopoulos, Panos K. and Kalampalikis, Nektarios G. and Kotsiantis, Sotiris B. and Vrahatis, Michael N.},
  doi          = {10.1007/s10472-023-09882-x},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {43-75},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {KNN classification: A review},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved multi-task least squares twin support vector
machine. <em>AMAI</em>, <em>93</em>(1), 21–41. (<a
href="https://doi.org/10.1007/s10472-023-09877-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-task learning (MTL) has become a popular field in machine learning and has a key role in various domains. Sharing knowledge across tasks in MTL can improve the performance of learning algorithms and enhance their generalization capability. A new approach called the multi-task least squares twin support vector machine (MTLS-TSVM) was recently proposed as a least squares variant of the direct multi-task twin support vector machine (DMTSVM). Unlike DMTSVM, which solves two quadratic programming problems, MTLS-TSVM solves two linear systems of equations, resulting in a reduced computational time. In this paper, we propose an enhanced version of MTLS-TSVM called the improved multi-task least squares twin support vector machine (IMTLS-TSVM). IMTLS-TSVM offers a significant advantage over MTLS-TSVM by operating based on the empirical risk minimization principle, which allows for better generalization performance. The model achieves this by including regularization terms in its objective function, which helps control the model’s complexity and prevent overfitting. We demonstrate the effectiveness of IMTLS-TSVM by comparing it to several single-task and multi-task learning algorithms on various real-world data sets. Our results highlight the superior performance of IMTLS-TSVM in addressing multi-task learning problems.},
  archive      = {J_AMAI},
  author       = {Moosaei, Hossein and Bazikar, Fatemeh and Pardalos, Panos M.},
  doi          = {10.1007/s10472-023-09877-8},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {21-41},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {An improved multi-task least squares twin support vector machine},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guest editorial: Revised selected papers from the LION 16
conference. <em>AMAI</em>, <em>93</em>(1), 19–20. (<a
href="https://doi.org/10.1007/s10472-024-09958-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AMAI},
  author       = {Kotsireas, Ilias S. and Pardalos, Panos M.},
  doi          = {10.1007/s10472-024-09958-2},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {19-20},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Guest editorial: Revised selected papers from the LION 16 conference},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep data density estimation through donsker-varadhan
representation. <em>AMAI</em>, <em>93</em>(1), 7–17. (<a
href="https://doi.org/10.1007/s10472-024-09943-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the data density is one of the challenging problem topics in the deep learning society. In this paper, we present a simple yet effective methodology for estimating the data density using the Donsker-Varadhan variational lower bound on the KL divergence and the modeling based on the deep neural network. We demonstrate that the optimal critic function associated with the Donsker-Varadhan representation on the KL divergence between the data and the uniform distribution can estimate the data density. Also, we present the deep neural network-based modeling and its stochastic learning procedure. The experimental results and possible applications of the proposed method demonstrate that it is competitive with the previous methods for data density estimation and has a lot of possibilities for various applications.},
  archive      = {J_AMAI},
  author       = {Park, Seonho and Pardalos, Panos M.},
  doi          = {10.1007/s10472-024-09943-9},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {7-17},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Deep data density estimation through donsker-varadhan representation},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The future starts now. <em>AMAI</em>, <em>93</em>(1), 5–6.
(<a href="https://doi.org/10.1007/s10472-025-09970-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AMAI},
  author       = {Dix, Jürgen and Fisher, Michael},
  doi          = {10.1007/s10472-025-09970-0},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {5-6},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {The future starts now},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 35 years of math and AI. <em>AMAI</em>, <em>93</em>(1), 1–3.
(<a href="https://doi.org/10.1007/s10472-025-09969-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AMAI},
  author       = {Golumbic, Martin Charles},
  doi          = {10.1007/s10472-025-09969-7},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {35 years of math and AI},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="apin---34">APIN - 34</h2>
<ul>
<li><details>
<summary>
(2025). Unveiling the frontiers of deep learning: Innovations
shaping diverse domains. <em>APIN</em>, <em>55</em>(7), 1–55. (<a
href="https://doi.org/10.1007/s10489-025-06259-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) allows computer models to learn, visualize, optimize, refine, and predict data. To understand its present state, examining the most recent advancements and applications of deep learning across various domains is essential. However, prior reviews focused on DL applications in only one or two domains. The current review thoroughly investigates the use of DL in four different broad fields due to the plenty of relevant research literature in these domains. This wide range of coverage provides a comprehensive and interconnected understanding of DL’s influence and opportunities, which is lacking in other reviews. The study also discusses DL frameworks and addresses the benefits and challenges of utilizing DL in each field, which is only occasionally available in other reviews. DL frameworks like TensorFlow and PyTorch make it easy to develop innovative DL applications across diverse domains by providing model development and deployment platforms. This helps bridge theoretical progress and practical implementation. Deep learning solves complex problems and advances technology in many fields, demonstrating its revolutionary potential and adaptability. CNN-LSTM models with attention mechanisms can forecast traffic with 99% accuracy. Fungal-diseased mango leaves can be classified with 97.13% accuracy by the multi-layer CNN model. However, deep learning requires rigorous data collection to analyze and process large amounts of data because it is independent of training data. Thus, large-scale medical, research, healthcare, and environmental data compilation are challenging, reducing deep learning effectiveness. Future research should address data volume, privacy, domain complexity, and data quality issues in DL datasets.},
  archive      = {J_APIN},
  author       = {Ahmed, Shams Forruque and Alam, Md. Sakib Bin and Kabir, Maliha and Afrin, Shaila and Rafa, Sabiha Jannat and Mehjabin, Aanushka and Gandomi, Amir H.},
  doi          = {10.1007/s10489-025-06259-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-55},
  shortjournal = {Appl. Intell.},
  title        = {Unveiling the frontiers of deep learning: Innovations shaping diverse domains},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated interpretation and clustering model based on
attribute grouping. <em>APIN</em>, <em>55</em>(7), 1–13. (<a
href="https://doi.org/10.1007/s10489-025-06262-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a technique in unsupervised learning used to group unlabeled data. However, traditional clustering algorithms cannot provide explanations for the clustering process and its results, which limits their applicability in certain fields. Existing methods to address the lack of interpretability in clustering algorithms typically focus on explaining the results after the clustering process is complete. Few studies explore embedding interpretability directly into the clustering process, and most of these methods rely on data prototypes to express interpretability, which often leads to explanations that are not intuitive and user-friendly. To address this, a feature-based method is proposed to embed interpretability into the clustering process. This approach provides users with intuitive and easy-to-understand explanations and introduces a new direction for research on embedding interpretability into clustering. The method operates in two stages: in the first stage, all attributes are grouped; in the second stage, an optimization formula is used to complete both the clustering and the weighting of each attribute group. The proposed method was evaluated on multiple synthetic and real-world datasets and compared with other methods. The experimental results show that the method improves clustering accuracy by approximately 5 percent and interpretability by around 40 percent compared to existing approaches.},
  archive      = {J_APIN},
  author       = {Chen, Liang and Sun, Leming and Zhong, Caiming},
  doi          = {10.1007/s10489-025-06262-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {An integrated interpretation and clustering model based on attribute grouping},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep attribute graph clustering based on bisymmetric network
information fusion and mutual influence. <em>APIN</em>, <em>55</em>(7),
1–19. (<a href="https://doi.org/10.1007/s10489-025-06295-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep attribute graph clustering has always been a challenging task and an important research topic for real-world data. In recent years, there has been a growing trend in using multi-network information fusion for deep attributed graph clustering. However, existing methods in deep attributed graph clustering have not effectively integrated representations learned from multiple networks and failed to construct a joint loss function that could impact the overall network model, resulting in poor clustering results. To address the aforementioned issues, we proposed AGC-BNIFI, an attribute graph clustering method based on dual symmetric network information fusion and mutual influence. The network of this method consists of a symmetric graph autoencoder and an autoencoder. The two different encoders are combined to improve the attribute learning ability. First, a symmetric graph autoencoder with a symmetric structure is proposed to capture complex linear and adapt to complex graph structure relationships and propagate heterogeneous information of joint embedding and structural features, and can reconstruct the attribute matrix and adjacency matrix; secondly, a layer-by-layer adaptive dynamic fusion module is designed to adaptively fuse the representations learned by each layer of the two encoders, and then learn a better joint representation for clustering tasks; finally, a multi-distribution self-supervision module with soft clustering assignments obtained from different networks that learn from each other and influence each other is proposed, which integrates representation learning and clustering tasks into an end-to-end framework, and jointly optimizes representation learning and clustering tasks by designing a joint loss function. Extensive experimental results on four graph datasets demonstrate the superiority of AGC-BNIFI over state-of-the-art methods. On the Coauthor-Physics dataset, compared to MBN, AGC-BNIFI achieved improvements of 2.6%, 1.1%, 4.3%, and 6.3% in four clustering metrics, respectively.},
  archive      = {J_APIN},
  author       = {Tan, Shuqiu and Zhang, Lei and Liu, Yahui and Zhang, Jianxun},
  doi          = {10.1007/s10489-025-06295-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Deep attribute graph clustering based on bisymmetric network information fusion and mutual influence},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic linguistic hesitant fuzzy multi-attribute
decision making for rural revitalization project selection of china.
<em>APIN</em>, <em>55</em>(7), 1–41. (<a
href="https://doi.org/10.1007/s10489-025-06305-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rural revitalization strategy has pointed out the right direction for solving Chinese &quot;three rural&quot; problems. Selecting the most suitable rural revitalization project can be regarded as a multi-attribute decision making (MADM) problem. This paper utilizes the probabilistic linguistic (PL) hesitant fuzzy sets (PLHFSs) to characterize the uncertain information of evaluating rural revitalization projects. PLHFS introduces the characteristics of linguistic hesitant fuzzy set (LHFS) into probabilistic linguistic term set (PLTS), which can represent the membership degrees of linguistic terms (LTs) and the associated probabilities to the set, simultaneously. The normalized and ordered PLHFS is proposed. Some new operation laws for PLHFSs are defined by using Archimedean T-norm and T-conorm (ATT) functions. By employing the Maclaurin symmetric mean (MSM) operator and power average (PA) operator, this paper develops a probabilistic linguistic hesitant fuzzy Archimedean power Maclaurin symmetric mean (PLHFAPMSM) operator and a probabilistic linguistic hesitant fuzzy Archimedean power weighted Maclaurin symmetric mean (PLHFAPWMSM) operator. Some desirable properties of the PLHFAPMSM and PLHFAPWMSM operators are discussed deeply. For MADM with PLHFSs, the individual attribute weight vector for each alternative is derived by data envelopment analysis (DEA). Further, the comprehensive attribute weight vector is determined by a linear goal programming model. Thereby, using the PLHFAPWMSM operator, a new method for MADM with PLHFSs is proposed. Finally, a practical example of rural revitalization project selection is analyzed to illustrate the effectiveness and feasibility of the proposed method.},
  archive      = {J_APIN},
  author       = {Dong, Jiu-Ying and Gong, Si-Hang and Wan, Shu-Ping},
  doi          = {10.1007/s10489-025-06305-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-41},
  shortjournal = {Appl. Intell.},
  title        = {Probabilistic linguistic hesitant fuzzy multi-attribute decision making for rural revitalization project selection of china},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep reinforcement learning approach and its application
in multi-USV adversarial game simulation. <em>APIN</em>, <em>55</em>(7),
1–24. (<a href="https://doi.org/10.1007/s10489-025-06380-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the progression of unmanned surface vehicle (USV) intelligence and the maturation of cluster control technologies, intelligent decision-making methods for multi-USV adversarial games have become pivotal technological focuses. Deep reinforcement learning (DRL), a prominent subset of artificial intelligence, has recently achieved notable advancements, heralding significant potential for this field. The intrinsic curiosity module (ICM), self-play (SP), and posthumous credit assignment (POCA) are integrated with proximal policy optimization (PPO) to address the challenges of sparse reward, low sample utilization, and credit assignment in multi-USV adversarial games, and a novel proximal policy optimization algorithm (PPO-ICMSPPOCA) is finally constructed. The algorithm generates intrinsic rewards through iterative training during multi-USV adversarial games while simultaneously addressing the evaluation of each USV&#39;s specific contribution to the team and the challenge of varying numbers of USVs. A perturbation mathematical model for a USV with three degrees of freedom is established, considering the influence of external environmental disturbances and variations in the USV&#39;s state on its hydrodynamic performance in this paper. With the Unity3D and ML-Agents toolkit platforms, multi-USV adversarial game simulation scenes, which can integrate and load various reinforcement learning (RL) algorithms, have been developed. Symmetric or asymmetric game experiments of different scales are conducted in adversarial games. The experiments show that the red teams with our algorithms can learn adversarial tactics more quickly, such as troop dispersion and coordinated attacks. Over 100 episodes, the red teams with ICM, SP, and POCA achieved win rates of 88.25%, 86.75%, and 91.33%, respectively, exhibiting higher game intelligence while obtaining higher cumulative rewards.},
  archive      = {J_APIN},
  author       = {Rao, Jinjun and Wang, Cong and Liu, Mei and Chen, Jinbo and Lei, Jingtao and Giernacki, Wojciech},
  doi          = {10.1007/s10489-025-06380-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {A deep reinforcement learning approach and its application in multi-USV adversarial game simulation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New 2D hyperchaotic cubic-tent map and improved 3D hilbert
diffusion for image encryption. <em>APIN</em>, <em>55</em>(7), 1–25. (<a
href="https://doi.org/10.1007/s10489-025-06414-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In image encryption, the effectiveness of chaotic maps significantly affects the effect of image encryption technology. However, existing chaotic maps have an issue of uneven value distribution when generating chaotic sequences, which could pose a threat to information security. To address this issue, a new two-dimensional Cubic-Tent map (2D-CTM) has been developed based on the Cubic and Tent maps. A series of comparative experiments on the 2D-CTM effectively validate its excellent chaotic properties. A novel image encryption algorithm utilizing 2D-CTM (CTM-IEA) is developed to encrypt images. This algorithm includes bit-level random scrambling, bit-level flipping, and improved 3D Hilbert diffusion process. First, the binary elements corresponding to different pixels in the plaintext image are randomly scrambled. Subsequently, the scrambled binary elements are flipped using a chaotic matrix, thoroughly obfuscating the binary information of the plaintext image and successfully hiding the plaintext information. Finally, the improved 3D Hilbert diffusion is applied to the image, eliminating pixel correlation in the original image and enhancing its security. Additionally, bit-level scrambling and diffusion are carried out in three rounds, which bolster the image’s defense against differential attacks. Compared to traditional encryption methods, this approach offers improved security by ensuring more uniform chaotic sequences and integrating a multi-round, bit-level encryption process. The security analysis shows that the key space reaches $${2}^{471}$$ , with correlation coefficients of 0.0006, 0.00004, and $$-$$ 0.0010, and an information entropy of 7.9998. The NPCR is 99.6084%, and the UACI is 33.4620%, which prove the effectiveness and reliability of the algorithm.},
  archive      = {J_APIN},
  author       = {Xu, Xin-li and Song, Xin-guang and Liu, Si-hang and Zhou, Nan-run and Wang, Meng-meng},
  doi          = {10.1007/s10489-025-06414-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {New 2D hyperchaotic cubic-tent map and improved 3D hilbert diffusion for image encryption},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demystifying the black box: AI-enhanced logistic regression
for lead scoring. <em>APIN</em>, <em>55</em>(7), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06430-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate interpretability challenges in business decision-making due to the black-box nature of generative Artificial Intelligence(AI), and to address high information processing costs and inconsistent feature collection standards, a novel marketing lead evaluation framework integrating large language models (LLMs) and classical machine learning algorithms was developed. The framework encompasses three modules: (1) a multi-agent question-answering system leveraging Retrieval-Augmented Generation(RAG) and LLMs; (2) a feature extraction and memory module for precise natural language and public data processing; and (3) a logistic regression (LR) model, trained on 540,000 automotive lead records, with associated calculation logic for decision support. Results indicate that the multi-agent system accurately identifies intentions and routes modules, the feature extraction module reduces manual follow-up costs, and the LR-guided LLM output enhances interpretability. These findings highlight the framework’s potential for auditing abnormal events and advancing marketing intelligence and business systematization.},
  archive      = {J_APIN},
  author       = {LIU, Bingran},
  doi          = {10.1007/s10489-025-06430-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Demystifying the black box: AI-enhanced logistic regression for lead scoring},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual heterogeneous graph contrastive learning for QoS
prediction. <em>APIN</em>, <em>55</em>(7), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06431-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of Web Services leads to homogeneity issues, making accurate Quality of Service (QoS) prediction extremely helpful for inexperienced users to choose suitable services. However, the complex relationship between users and services in service invocation poses numerous challenges on QoS prediction. Given the capability of graph neural networks in modeling diverse relationships, a Dual Heterogeneous Graph Contrastive Learning method (DHGCL) is proposed in this paper to achieve high-accuracy QoS prediction. First, a dual heterogeneous graph is innovatively constructed, in which a global interaction graph is generated by a proposed graph learning to enable the direct interactions concerning the distant neighbors, while a local relationship graph is simultaneously constructed to enhance the close associations between users and services through spectral clustering. On this basis, the graph convolution network on the meta-paths is further designed to acquire the embedding of nodes for both of these two graphs. Finally, the global-local contrastive learning is served as a self-supervised mechanism to balance global interaction and local relationship information, and to complete the final QoS prediction. Extensive experiments have proven that our DHGCL method can achieve significantly higher accuracy than most of existing methods with the help of the dual heterogeneous graph.},
  archive      = {J_APIN},
  author       = {Xiu, Yuting and Ding, Ding and Wu, Ziteng and Zhao, Yuekun and Liu, Jiaqi},
  doi          = {10.1007/s10489-025-06431-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Dual heterogeneous graph contrastive learning for QoS prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel classification method based on an online extended
belief rule base with a human-in-the-loop strategy. <em>APIN</em>,
<em>55</em>(7), 1–26. (<a
href="https://doi.org/10.1007/s10489-025-06434-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification methods, such as fault diagnosis and intrusion detection, are widely used in modeling complex systems. The accuracy and credibility of these methods directly affect the reliability of the modeling results, which in turn determines the effectiveness of engineering decisions. Additionally, the model&#39;s ability to be dynamically updated should be considered, given the intricate and ever-changing nature of engineering environments. For online models, adding new training samples without considering their suitability can lead to problems such as poor model performance and increased rule base complexity. Furthermore, amid constantly arriving new samples in a dynamic environment, modeling based only on initial expert knowledge can result in new samples not being fully used. Therefore, a novel classification method based on an online extended belief rule base with a human-in-the-loop strategy (OEBRB-H) is proposed in this paper. First, a fuzzy c-means algorithm based on expert knowledge (FBE) is designed to evaluate model parameters online. Second, a human-in-the-loop strategy for dividing the new sample set and a domain-value-based rule updating method are proposed for model optimization. Finally, two case studies, namely, aeroengine inter-shaft bearing fault diagnosis and industrial control intrusion detection, are performed. The results indicate that the model proposed in this paper can maintain both credibility and high accuracy in dynamic environments.},
  archive      = {J_APIN},
  author       = {Li, Jinyuan and Qian, Guangyu and He, Wei and Zhu, Hailong and Zhou, Guohui},
  doi          = {10.1007/s10489-025-06434-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {A novel classification method based on an online extended belief rule base with a human-in-the-loop strategy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IAMTrack: Interframe appearance and modality tokens
propagation with temporal modeling for RGBT tracking. <em>APIN</em>,
<em>55</em>(7), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06438-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGBT tracking has emerged as a robust solution for various applications, including surveillance, autonomous driving, and robotics, owing to its resilience in challenging environments. However, existing RGBT tracking approaches often overlook target appearance changes, location shifts, and the dynamic significance of modality features, limiting long-term tracking accuracy. To address these limitations, we propose IAMTrack, a novel transformer-based framework that achieves sequential tracking by propagating modality and appearance tokens across frames. The method compresses the discriminative features of each modality into modality tokens to transmit modality quality and target location information in real time, allowing the model to focus more on features with high modality quality and features with high target probability, while suppressing noise and redundant information. It also compresses the appearance features of objects similar in appearance across frames into appearance tokens to convey changes in appearance. To further enhance the token learning capability, we design a temporal generalized relation modelling approach that guides future predictions based on past information. The experimental results show that IAMTrack outperforms existing methods in various RGBT tracking scenarios, especially in UAV tracking tasks. Compared with those of previous methods, the MPRs and MSRs of the VTUAV short-term and long-term subdatasets are improved by $$1.7\%/2.1\%$$ and $$2.5\%/2.2\%$$ , respectively.},
  archive      = {J_APIN},
  author       = {Shi, Huiwei and Mu, Xiaodong and He, Hao and Zhong, Chengliang and Zhang, Bo and Zhao, Peng},
  doi          = {10.1007/s10489-025-06438-w},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {IAMTrack: Interframe appearance and modality tokens propagation with temporal modeling for RGBT tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine sound anomaly detection based on dual-channel
feature fusion variational auto-encoder. <em>APIN</em>, <em>55</em>(7),
1–17. (<a href="https://doi.org/10.1007/s10489-025-06449-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing intelligence and automation of industrial equipment, the technology for detecting equipment anomalies has become increasingly important. Compared to image-based anomaly detection methods, sound-based anomaly detection methods have the advantages of being non-intrusive, real-time and having lower data collection costs. These advantages make them highly valuable for research. Currently, deep learning methods that focus on spectrogram reconstruction have become widely utilized in the field of machine sound anomaly detection research. However, previous methods only attempted to mitigate the impact of noise without enabling the model to fully learn the distribution of sound features during the reconstruction process. In this paper, a novel Dual-Channel Feature Fusion Variational Autoencoder (DCFF-VAE) is proposed to effectively improve its reconstruction ability and help it better learn the normal sound features. In this method, the deep features extracted from the convolution layer and bidirectional gated cycle unit in the encoder are integrated by means of concatenation to make full use of the important features in the sound. Subsequently, grouped deconvolution is applied in the decoder to reduce model complexity while enhancing its perceptual ability for features. Additionally, during the anomaly detection phase, anomaly scores are calculated based on the Mahalanobis distance to better capture the differences between normal and abnormal sounds. Anomaly detection experiments conducted on five types of machines demonstrate that DCFF-VAE not only achieves the best stability but also surpasses the best comparison method by 3.14% and 1.21% in AUC and pAUC metrics, respectively.},
  archive      = {J_APIN},
  author       = {Zhang, Chen and Wei, Yongkang and Wang, Xiaofeng and Wu, Xiaoxuan and Zhu, Xuhui},
  doi          = {10.1007/s10489-025-06449-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Machine sound anomaly detection based on dual-channel feature fusion variational auto-encoder},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harmful data enhanced anomaly detection for quasi-periodic
multivariate time series. <em>APIN</em>, <em>55</em>(7), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06461-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate quasiperiodic time series (MQTS) anomaly detection has demonstrated significant potential across various practical applications, including health monitoring, intelligent maintenance, and quantitative trading. Recent research has introduced diverse methods based on autoencoders (AEs) and generative adversarial networks (GANs) that learn latent representations of normal data and subsequently detect anomalies through reconstruction errors. However, anomalous training set data can cause model pollution, which harms the ability to of the utilized model reconstruct normal data. The current data extreme imbalance creates an enormous challenge in terms of stripping out these anomalies. In this paper, we propose a GAN-based multivariate quasiperiodic time series anomaly detection method called IGANomaly (I represents isolation). This method isolates normal and harmful samples via pseudolabeling and then learns harmful data patterns to enhance the process of reconstructing of normal samples. First, the reconstruction error and potential feature distribution are jointly analyzed. Bimodal dynamic alignment is achieved through multiview clustering, thus overcoming the limitation of unidimensional determination. Second, dual reconstruction constraints for the generator and a gradient penalty mechanism for the discriminator are constructed. While maintaining the reconstruction quality achieved for normal samples, the propagation path of abnormal features is actively perturbed through a gradient inversion strategy. On three public datasets, IGANomaly achieves $$F1\ scores$$ of 0.811, 0.846, and 0.619, demonstrating an average improvement of 18.9% over the best baseline methods.},
  archive      = {J_APIN},
  author       = {Wang, Liyuan and Zhou, Yong and Ke, Wuping and Zheng, Desheng and Min, Fan and Li, Hui},
  doi          = {10.1007/s10489-025-06461-x},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Harmful data enhanced anomaly detection for quasi-periodic multivariate time series},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical-enhanced graph convolutional networks
leveraging causal inference for aspect-based sentiment analysis.
<em>APIN</em>, <em>55</em>(7), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06465-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) aims to determine the sentiment polarity of a particular aspect in a sentence. Existing research focuses on shortening the distance between opinion words and aspect words, resulting in spurious correlations. At the same time, the use of different dependent tools will bring different types of noise, destroying the effectiveness of the model. To address these issues, we propose a causal model of hierarchically augmented graph convolutional networks (CausalGCN). Specifically, we subdivide the language features into four relationships and then construct their corresponding mask matrices based on different relationships. At the same time, we introduce an instrumental variable to eliminate the confounders generated by the tool. Our model then combines the resulting mask matrix with localized attention at multiple levels. We treat the relationships between words and adjacent tensors as nodes and edges respectively, resulting in a multi-channel graph. Finally, we utilize graph convolutional networks to enhance relationship-aware node representations. Experimental results on three benchmark datasets demonstrate the effectiveness of the proposed model.},
  archive      = {J_APIN},
  author       = {Zhou, Fengling and Li, Zhixin and Zhang, Canlong and Ma, Huifang},
  doi          = {10.1007/s10489-025-06465-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Hierarchical-enhanced graph convolutional networks leveraging causal inference for aspect-based sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRHGNN: A dynamic residual hypergraph neural network for
aspect sentiment triplet extraction. <em>APIN</em>, <em>55</em>(7),
1–13. (<a href="https://doi.org/10.1007/s10489-025-06466-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect Sentiment Triple Extraction (ASTE) is an emerging sentiment analysis task. Many existing methods focus on designing a new labeling scheme to enable end-to-end operation of the model. However, these methods overlook the relationships between words in the ASTE task. In this paper, we propose the Dynamic Residual Hypergraph Neural Network (DRHGNN), which fully considers the relationships between words. Specifically, based on the pre-defined ten types of word pair relationships, we employ a graph attention network to model sentence features as a relational graph matrix. Subsequently, we use a dynamic hypergraph network to learn deep features from the transformed graph structure, then constructing relation-aware node representations. Furthermore, we integrate a residual connection to improve the performance of our DRHGNN model. Finally, we design a relationship constraint to dynamically control the number of hyperedges, thereby enhancing the effectiveness of the dynamic hypergraph neural network. Extensive experimental results on benchmark datasets show that our proposed model significantly outperforms state-of-the-art methods, demonstrating the effectiveness and robustness of the model.},
  archive      = {J_APIN},
  author       = {Guo, Peng and Yu, Zihao and Li, Chao and Sun, Jun},
  doi          = {10.1007/s10489-025-06466-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {DRHGNN: A dynamic residual hypergraph neural network for aspect sentiment triplet extraction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ResU-KAN: A medical image segmentation model integrating
residual convolutional attention and atrous spatial pyramid pooling.
<em>APIN</em>, <em>55</em>(7), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06467-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of medical imaging data, precise segmentation and analysis of medical images face unprecedented challenges. Addressing small sample sizes, significant variations, and structurally complex medical imaging data to improve the accuracy of early diagnosis has become a key issue in the medical field. This study proposes a Residual U-KAN model (ResU-KAN) to tackle this challenge and improve medical image segmentation accuracy. First, to address the model’s shortcomings in capturing long-distance dependencies and issues like potential gradient vanishing (or explosion) and overfitting, we introduce a Residual Convolution Attention (RCA) module. Second, to expand the model’s receptive field while performing multi-scale feature extraction, we introduce an Atrous Spatial Pyramid Pooling module (ASPP). Finally, experiments were conducted on three publicly available medical imaging datasets, and comparative analysis with existing state-of-the-art methods demonstrated the effectiveness of the proposed approach. Project page: https://github.com/Alfreda12/ResU-KAN},
  archive      = {J_APIN},
  author       = {Wang, Haibin and Zhao, Zhenfeng and Liu, Qi and Wang, Shenwen},
  doi          = {10.1007/s10489-025-06467-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {ResU-KAN: A medical image segmentation model integrating residual convolutional attention and atrous spatial pyramid pooling},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal context-aware network for 3D-craft
generation. <em>APIN</em>, <em>55</em>(7), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06468-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generative modeling of 3D objects in the real world is an interesting but challenging task commonly constrained by process and order. Most existing methods focus on spatial relations to address this issue, neglecting the rich information between temporal sequences. To close this gap, we deliver a spatial-temporal context-aware network to explore the prediction of ordered actions for 3D object construction. Specifically, our approach is mainly formed by two modules, i.e., the spatial-context module and the temporal-context module. The spatial-context module is designed to learn the physical constraints in 3D object construction, such as spatial constraints and gravity. Meanwhile, the temporal-context module integrates the temporal context of action orders in history on the fly toward more accurate predictions. After that, the features of such two modules are merged to finalize the perdition of the following action’s position and block type. The entire model is optimized by the stochastic gradient descent optimization (SGD) method in an end-to-end manner. Extensive experiments conducted on the 3D-Craft dataset demonstrate that the proposed method surpasses the state-of-the-art methods with a large margin, i.e., improving $$4.5\%$$ absolute ACC@1, $$3.3\%$$ absolute ACC@5, and $$4.1\%$$ absolute ACC@10. Moreover, the comprehensive ablation studies and insightful analysis further validate the effectiveness of the proposed method.},
  archive      = {J_APIN},
  author       = {Ji, Ruyi and Wang, Qunbo and Wang, Boying and Zhang, Hangu and Zhang, Wentao and Dai, Lin and Wang, Yanni},
  doi          = {10.1007/s10489-025-06468-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Spatial-temporal context-aware network for 3D-craft generation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective selection of public IoT services by learning
uncertain environmental factors using fingerprint attention.
<em>APIN</em>, <em>55</em>(7), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06472-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The scope of the Internet of Things (IoT) environment has been expanding from private to public spaces, where selecting the most appropriate service by predicting the service quality has become a timely problem. However, IoT services can be physically affected by (1) uncertain environmental factors such as obstacles and (2) interference among services in the same environment while interacting with users. Using the traditional modeling-based approach, analyzing the influence of such factors on the service quality requires modeling efforts and lacks generalizability. In this study, we propose Learning Physical Environment factors based on the Attention mechanism to Select Services for UsERs (PLEASSURE), a novel framework that selects IoT services by learning the uncertain influence and predicting the long-term quality from the users’ feedback without additional modeling. Furthermore, we propose fingerprint attention that extends the attention mechanism to capture the physical interference among services. We evaluate PLEASSURE by simulating various IoT environments with mobile users and IoT services. The results show that PLEASSURE outperforms the baseline algorithms in rewards consisting of users’ feedback on satisfaction and interference.},
  archive      = {J_APIN},
  author       = {Baek, KyeongDeok and Ko, In-Young},
  doi          = {10.1007/s10489-025-06472-8},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Effective selection of public IoT services by learning uncertain environmental factors using fingerprint attention},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable multi-agent reinforcement learning via
multi-head variational autoencoders. <em>APIN</em>, <em>55</em>(7),
1–19. (<a href="https://doi.org/10.1007/s10489-025-06473-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent deep reinforcement learning (RL) is increasingly proficient at making collective decisions in complex systems. However, the black-box nature of DRL decision networks often renders agent behaviors difficult to interpret, thereby undermining human trust. Although several reinforcement learning explanation methods have been proposed, most mainly identify factors influencing decisions without elucidating the underlying causal mechanisms based on physical models. Moreover, these methods do not address the generalizability of interpretability within multi-agent system settings. To overcome these challenges, we propose a multi-agent RL network based on multi-head variational autoencoders (MVAE), which generates decisions with interpretable physical semantics for unmanned systems. The MVAE directly encodes multiple types of semantically meaningful features with physical interpretations from the latent space and generates decisions by integrating these semantics according to physical models. Furthermore, considering the different latent variable distributions in continuous and discrete action scenarios, we design two distinct MVAE models based on Gaussian and Dirichlet distributions, respectively, and design training frameworks using deterministic policy gradient networks and proximal policy optimization networks in a multi-agent environment. Additionally, we develop a visualization method to intuitively convey interpretability in both continuous and discrete action scenarios. Simulation experiments comparing our method with existing baselines demonstrate that our approach achieves superior decision-making performance under interpretability conditions, and further validate its performance in large-scale scenarios.},
  archive      = {J_APIN},
  author       = {Li, Peizhang and Fei, Qing and Chen, Zhen},
  doi          = {10.1007/s10489-025-06473-7},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Interpretable multi-agent reinforcement learning via multi-head variational autoencoders},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A filter-wrapper model for high-dimensional feature
selection based on evolutionary computation. <em>APIN</em>,
<em>55</em>(7), 1–13. (<a
href="https://doi.org/10.1007/s10489-025-06474-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning, feature selection plays an important role in improving prediction accuracy and reducing time complexity. This paper proposes a filter-wrapper model to obtain a feature subset from high-dimensional data in a short time. Firstly, features are ranked by information gain and Fisher Score. Secondly, the feature search is realized by binary evolutionary computation based on wrapper. To avoid wasting a lot of searches on low-ranked features, an adaptive feature selection strategy is adopted to guide population search and position update. Finally, a learning strategy is proposed, in which learners study from exemplars and complete position update, and the exemplars are constituted by optimal solutions to balance exploration and exploitation. To demonstrate the effectiveness and efficiency of the proposed model, three binary evolutionary computations, including particle swarm optimization, grey wolf optimizer, and fish migration optimization, are applied to the model, and they present excellent performance in high-dimensional data sets.},
  archive      = {J_APIN},
  author       = {Hu, Pei and Zhu, Jiulong},
  doi          = {10.1007/s10489-025-06474-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {A filter-wrapper model for high-dimensional feature selection based on evolutionary computation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust stochastic quasi-newton algorithm for non-convex
machine learning. <em>APIN</em>, <em>55</em>(7), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06475-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic quasi-Newton methods have garnered considerable attention within large-scale machine learning optimization. Nevertheless, the presence of a stochastic gradient equaling zero poses a significant obstacle to updating the quasi-Newton matrix, thereby impacting the stability of the quasi-Newton algorithm. To address this issue, a checkpoint mechanism is introduced, i.e., checking the value of $$\textbf{s}_k$$ before updating the quasi-Newton matrix, which effectively prevents zero increments in the optimization variable and enhances algorithmic stability during iterations. Meanwhile, a novel gradient incremental formulation is introduced to satisfy curvature conditions, facilitating convergence for non-convex objectives. Additionally, finite-memory techniques are employed to reduce storage requirements in large-scale machine learning tasks. The last iteration of the proposed algorithm is proven to converge in a non-convex setting, which is better than average and minimum iteration convergence. Finally, experiments are conducted on benchmark datasets to compare the proposed RSLBFGS algorithm with other popular first and second-order methods, demonstrating the effectiveness and robustness of RSLBFGS.},
  archive      = {J_APIN},
  author       = {Liu, Hanger and Liang, Yuqing and Liu, Jinlan and Xu, Dongpo},
  doi          = {10.1007/s10489-025-06475-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {A robust stochastic quasi-newton algorithm for non-convex machine learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view clustering with filtered bipartite graph.
<em>APIN</em>, <em>55</em>(7), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06476-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key challenge of graph-based multi-view clustering methods lies in how to capture a consensus clustering structure. Although existing methods have achieved good performances, they still share the following limitations: 1) The high computational complexity caused by large graph leaning. 2) The contaminated information in different views reduces the consistency of the fused graph. 3) The two-stage clustering strategy leads to sub-optimal solutions and error accumulation. To solve the above issues, we propose a novel multi-view clustering algorithm termed Multi-View Clustering with Filtered Bipartite Graph (MVC-FBG). In the graph construction stage, we select representative anchors to construct anchor graphs with less space complexity. Then we explicitly filter out the contaminated information to preserve the consistency in different views. Moreover, a low-rank constraint is imposed on the Laplacian matrix of the unified graph to obtain the clustering results directly. Furthermore, we design an efficient alternating optimization algorithm to solve our model, which enjoys a linear time complexity that can scale well with the data size. Extensive experimental results on different scale datasets demonstrate the effectiveness and efficiency of our proposed method.},
  archive      = {J_APIN},
  author       = {Ji, Jintian and Peng, Hailei and Feng, Songhe},
  doi          = {10.1007/s10489-025-06476-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view clustering with filtered bipartite graph},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WMFusion: A w-shaped dual encoder and single decoder network
for multimodal medical image fusion. <em>APIN</em>, <em>55</em>(7),
1–16. (<a href="https://doi.org/10.1007/s10489-025-06477-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current deep learning-based multimodal medical image fusion algorithms usually use a single feature extractor to extract features from images of different modalities. However, these approaches tend to overlook the distinctive features of different modality medical images, resulting in feature loss. In addition, applying complex network structures to low-level image-processing tasks would waste computational power. Therefore, we innovatively design an end-to-end multimodal fusion network with a dual encoder and single decoder structure, which resembles the letter ‘W’, and we have termed WMFusion. Specifically, we first develop a multi-scale context dynamic feature extractor (MCDFE) that employs context-gated convolution to extract multiscale features from different modalities effectively. Subsequently, we propose a local-global feature fusion module (LGFM) for fusing features of different scales, and we design a cross-modality bidirectional interaction structure in the local branch. Finally, feature redundancy is suppressed and the fusion image is reconstructed by a spatial channel reconstruction module (SCRM) with a spatial and channel reconstruction unit. A large number of experimental results demonstrate that our proposed WMFusion method is superior to some state-of-the-art algorithms in terms of both subjective and objective evaluation metrics, and has satisfactory computation efficiency.},
  archive      = {J_APIN},
  author       = {Shao, Yu and Yu, Lei and Tang, Haozhe},
  doi          = {10.1007/s10489-025-06477-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {WMFusion: A W-shaped dual encoder and single decoder network for multimodal medical image fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximizing diversity in k-pattern set mining through
constraint programming and entropy. <em>APIN</em>, <em>55</em>(7), 1–24.
(<a href="https://doi.org/10.1007/s10489-025-06482-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting diverse and frequent closed itemsets from large datasets is a core challenge in pattern mining, with significant implications across domains such as fraud detection, recommendation systems, and machine learning. Existing approaches often lack flexibility and efficiency, and struggle with initial itemset selection bias and redundancy. This paper addresses these research gaps by introducing a compact and modular constraint programming model that formalizes the search for diverse patterns. Our approach incorporates a novel global constraint derived from a relaxed Overlap diversity measure, using tighter lower and upper bounds to improve filtering capabilities. Unlike traditional methods, we leverage an entropy-based optimization framework that combines joint entropy maximization with top-k pattern mining to identify the maximally k-diverse pattern set. Our approach ensures more comprehensive and informative pattern discovery by minimizing redundancy and promoting pattern diversity. Extensive experiments validate the effectiveness of the proposed method, demonstrating significant performance gains and superior pattern quality compared to state-of-the-art approaches. Implemented in both sequential and parallel versions, the framework offers an efficient and adaptable solution for anytime pattern mining tasks in various domains.},
  archive      = {J_APIN},
  author       = {Douad, Mohamed El Amine and Aribi, Noureddine and Loudni, Samir and Hien, Arnold and Lebbah, Yahia},
  doi          = {10.1007/s10489-025-06482-6},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Maximizing diversity in k-pattern set mining through constraint programming and entropy},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-layer contrastive learning for aspect-aligned
multimodal sentiment analysis. <em>APIN</em>, <em>55</em>(7), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06483-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal Aspect-Based Sentiment Analysis (MABSA) aims to identify the sentiment polarity of aspects by incorporating visual information into text. Image and text are two types of modality information with significant modality gaps in both data form and semantic expression. Narrowing the modality gaps and feature fusion are two crucial challenges in MABSA. To address these issues, this paper introduces an aspect-enhanced alignment and fusion strategy with dual-layer contrastive learning to tackle the cross-modal fusion problem. Unlike traditional contrastive learning methods, our approach increases the number of negative samples, enabling the model to learn more discriminative features and better capture fine-grained cross-modal relationships. The proposed approach leverages overlapping aspect information as multi-modal pivots to first bridge the modality gaps and then integrate visual and text information in the multi-modal feature space, thereby improving multi-modal sentiment analysis performance. We first introduce an aspect-guided modality alignment strategy that narrows the fundamental modality gaps between image and text using modality contrastive learning. Then, we design an aspect-oriented multi-modal fusion approach to promote cross-modal feature fusion through symmetric cross-modal interaction. Extensive experiments demonstrate that the proposed approach outperforms other state-of-the-art (SOTA) MABSA methods on three MABSA benchmark datasets. In-depth analysis further validates the effectiveness of the proposed multi-modal fusion approach for MABSA.},
  archive      = {J_APIN},
  author       = {Guo, Junjun and Yan, Zida and Zhang, Guanghua},
  doi          = {10.1007/s10489-025-06483-5},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Dual-layer contrastive learning for aspect-aligned multimodal sentiment analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale spatiotemporal normality learning for
unsupervised video anomaly detection. <em>APIN</em>, <em>55</em>(7),
1–15. (<a href="https://doi.org/10.1007/s10489-025-06485-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection aims to automatically identify abnormal spatiotemporal patterns in surveillance videos. While unsupervised methods avoid the high cost of collecting abnormal data by learning from regular events, they often struggle to effectively model the inherent multiscale nature of video data. To address this challenge, we propose Multi-Scale Spatiotemporal Normality Learning (MS $$^2$$ NL), a unified framework that systematically processes and integrates multiscale features across both spatial and temporal dimensions. Our framework employs an attention-enhanced stepwise fusion module to aggregate spatial features at different resolutions, enabling comprehensive modeling of appearance patterns from local textures to global structures. For temporal information processing, we design a dynamic aggregation module based on one-dimensional dilated convolutions that effectively captures motion dependencies across multi-scale feature maps while maintaining computational efficiency. These multiscale features are processed through dual decoders: a temporal decoder that learns motion normality through RGB-to-optical-flow mapping, and a spatial decoder that models appearance normality via future frame prediction, with multiscale prototype features stored in an external memory network. This sophisticated handling of multiscale information enables MS $$^2$$ NL to capture subtle spatial deviations while maintaining sensitivity to temporal anomalies. Extensive experiments on benchmark datasets demonstrate the effectiveness of our approach, achieving state-of-the-art frame-level AUROCs of 98.3%, 91.5%, and 74.9% on the UCSD Ped2, CUHK Avenue, and ShanghaiTech datasets, respectively.},
  archive      = {J_APIN},
  author       = {Liu, Caitian and Gong, Linxiao and Chen, Xiong},
  doi          = {10.1007/s10489-025-06485-3},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale spatiotemporal normality learning for unsupervised video anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive federated deep reinforcement learning for edge
offloading in heterogeneous AGI-MEC networks. <em>APIN</em>,
<em>55</em>(7), 1–22. (<a
href="https://doi.org/10.1007/s10489-025-06486-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To support massive applications of mobile terminals (MTs), the combination of air-ground integrated (AGI) networks and mobile edge computing (MEC) technology has emerged. However, how to intelligently manage MTs to satisfy their performance requirements faces several challenges, such as the high communication burden of collaborative decision-making, real-time changes in environmental information, MT mobility, and heterogeneous performance requirements. To deal with these challenges, we propose an adaptive federated deep deterministic policy gradient (AFDDPG) algorithm tailored to the edge offloading problem. Specifically, an adaptive federated training framework is first constructed to acquire global knowledge by sharing model parameters instead of original data among agents. This framework enables the algorithm to maintain a low communication burden while achieving high solution accuracy. Then, a hybrid reward function is proposed to enhance the exploration intensity in the action space by jointly considering the group interests and the unique features of each agent. Accordingly, the convergence performance of the algorithm in complex environments with multiple constraints is improved. Subsequently, an adaptive local update method is presented, which generates personalized local models through biased model aggregation to cope with the heterogeneous requirements of MTs. Finally, the convergence of the proposed AFDDPG algorithm is analysed, and the effectiveness of the algorithm is demonstrated by extensive simulations.},
  archive      = {J_APIN},
  author       = {Fan, Chenchen and Wang, Qingling},
  doi          = {10.1007/s10489-025-06486-2},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive federated deep reinforcement learning for edge offloading in heterogeneous AGI-MEC networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated text annotation: A new paradigm for generalizable
text-to-image person retrieval. <em>APIN</em>, <em>55</em>(7), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06487-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieving specific person images based on textual descriptions, known as Text-to-Image Person Retrieval (TIPR), has emerged as a challenging research problem. While existing methods primarily focus on architectural refinements and feature representation enhancements, the critical aspect of textual description quality remains understudied. We propose a novel framework that automatically generates stylistically consistent textual descriptions to enhance TIPR generalizability. Specifically, we develop a dual-model architecture employing both captioning and retrieval models to quantitatively evaluate the impact of textual descriptions on retrieval performance. Comparative analysis reveals that manually annotated descriptions exhibit significant stylistic variations due to subjective biases among different annotators. To address this, our framework utilizes the captioning model to generate structurally consistent textual descriptions, enabling subsequent training and inference of the retrieval model based on automated annotations. Notably, our framework achieves a 18.60% improvement in Rank-1 accuracy over manual annotations on the RSTPReid dataset. We systematically investigate the impact of identity quantity during testing and explore prompt-guided strategy to enhance image caption quality. Furthermore, this paradigm ensures superior generalization capabilities for well-trained retrieval models. Extensive experiments demonstrate that our approach improves the applicability of TIPR systems. Comparison framework of manual and automated annotation performance. The left panel illustrates the process of generating automated annotations and the details of captioner training and testing. The right panel demonstrates the training and testing processes using different image-text pairs and compares the final results on the RSTPReid dataset. This results show that the performance of automated annotations surpasses that of manual annotations on this dataset},
  archive      = {J_APIN},
  author       = {Liu, Delong and Wang, Peng and Zhao, Zhicheng and Su, Fei},
  doi          = {10.1007/s10489-025-06487-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Automated text annotation: A new paradigm for generalizable text-to-image person retrieval},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COFA: Counterfactual attention framework for trustworthy
wafer map failure classification. <em>APIN</em>, <em>55</em>(7), 1–21.
(<a href="https://doi.org/10.1007/s10489-025-06488-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifying wafer map failure pattern plays a crucial role in semiconductor manufacturing, as it can help identify the underlying cause of abnormalities, thus reducing production costs. Existing works have shown that deep learning methods have great advantages in recognizing failure patterns. However, recent studies mainly focus on utilizing attention mechanisms to pinpoint critical regions as salient features, while ignoring the imperceptible underlying features and the causal relationship between prediction results and attention. This paper introduces a model-agnostic classification framework that leverages counterfactual explanations to enhance attention. Our approach consists of two steps: counterfactual example generation (Explain) and attention-based classifier refinement (Reinforce). The counterfactual explainer is designed to identify key pixel-level features, the adjustment of which could lead to different predictions. These generated counterfactual examples reveal hidden causal factors in the classifier’s decision-making process. Then the classifier utilizes these pixel features as attention, conducting reliable classification under the guidance of counterfactual examples. Through extensive experiments on real-world datasets, we demonstrate the effectiveness of our proposed model. It achieves an accuracy of 98.125 $$\%$$ in the defect classification task on the WM-811K dataset and 92.544 $$\%$$ on the MixedWM38 dataset, outperforming state-of-the-art attention methods such as SENet, CBAM, and Vision Transformer by over 5%. Our results highlight the superiority of our approach and its potential for practical implementation in the semiconductor manufacturing domain.},
  archive      = {J_APIN},
  author       = {Feng, Kaiyue and Wang, Jia and Yin, Chenke and Li, Andong},
  doi          = {10.1007/s10489-025-06488-0},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {COFA: Counterfactual attention framework for trustworthy wafer map failure classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPPSLF: A lightweight privacy-preserving split learning
framework for smart surveillance systems. <em>APIN</em>, <em>55</em>(7),
1–18. (<a href="https://doi.org/10.1007/s10489-025-06489-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smart surveillance systems, cameras often have limited computational capacity, which necessitates the offloading of captured images or videos to cloud servers for analysis, raising significant privacy concerns. To address these challenges, we propose a lightweight privacy-preserving split learning framework tailored for smart surveillance systems. In this framework, an upper model is deployed on resource-constrained cameras to extract intermediate features from image segments, which are then transmitted to a lower model on the cloud for further analysis and training. This approach reduces the likelihood of sensitive data exposure by avoiding the transmission of raw images or videos. Furthermore, our framework incorporates adversarial training to defend against reconstruction attacks, preventing adversaries from deducing private information from the intermediate features. Compared to traditional split learning methods, the proposed solution significantly reduces client-side memory usage and computation time, making it well-suited for deployment on low-resource devices. Experimental results on CIFAR10, CIFAR100, and SVHN datasets demonstrate the effectiveness of our framework, with reductions in the server-side decoder’s reconstruction classification accuracy to 12.18%, 2.18%, and 13.09%, respectively. These results validate the framework’s ability to enhance privacy while maintaining computational efficiency.},
  archive      = {J_APIN},
  author       = {Wang, Liang and Chen, Hao and Zuo, Lina and Liu, Haibo},
  doi          = {10.1007/s10489-025-06489-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {LPPSLF: A lightweight privacy-preserving split learning framework for smart surveillance systems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced frustrum multi-scale VoteNet for 3D object
detection in cluttered indoor scene. <em>APIN</em>, <em>55</em>(7),
1–15. (<a href="https://doi.org/10.1007/s10489-025-06492-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-cost Kinect sensor is capable of simultaneously acquiring RGB images and depth information, providing a comprehensive representation of 3D scenes. However, a significant drawback of the Kinect sensor is its susceptibility to low perception accuracy, particularly in cluttered indoor scenes. To tackle these issues, we introduce a novel EF-MSVoteNet framework for Kinect-based indoor 3D object detection. This framework integrates two key modules: The Enhanced Frustum (EF) and Multi-Scale Voting Network (MSVoteNet). After obtaining 2D bounding boxes via a 2D detector, the EF module no longer segments the scene but instead accumulates all frustum regions within a three-dimensional space. The EF module not only enhances the resolution of point clouds within the frustum in relation to the background but also substantially enhances the feature representation of object-related point clouds within the 3D scene. In addition, the proposed MSVoteNet module is a structurally flexible multi-scale voting network. It enhances feature extraction and integration across different scales by incorporating a multi-scale structure into the traditional VoteNet. The performance analysis is carried out on the SUN RGB-D and ScanNet datasets, which were collected using RGB-D sensors in cluttered indoor environments, and it demonstrates the efficacy and effectiveness of our proposed methods. The source code is available at: https://github.com/zerrows2/EF-MSVoteNet},
  archive      = {J_APIN},
  author       = {Zhang, Xuesong and He, Yu and Song, Cunli and Zhuang, Yan},
  doi          = {10.1007/s10489-025-06492-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Enhanced frustrum multi-scale VoteNet for 3D object detection in cluttered indoor scene},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AuGQ: Augmented quantization granularity to overcome
accuracy degradation for sub-byte quantized deep neural networks.
<em>APIN</em>, <em>55</em>(7), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06495-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deployment of neural networks on IoT devices unleashes the potential for various innovative applications, but the sheer size and computation of many deep learning (DL) networks prevented its widespread. Quantization mitigates this issue by reducing model precision, enabling deployment on resource-constrained edge devices. However, at extremely low bit-widths, such as 2-bit and 4-bit, the aggressive compression leads to significant accuracy degradation due to the reduced representational capacity of the neural network. A critical aspect of effective quantization is identifying the range of real values (FP32) that impact model accuracy. To address accuracy loss at sub-byte levels, we introduce Augmented Quantization (AuGQ), a novel granularity technique tailored for low bit-width quantization. AuGQ segments the range of real-valued (FP32) weight and activation distributions into small uniform intervals, applying affine quantization in each interval to enhance accuracy. We evaluated AuGQ using both post-training quantization (PTQ) and quantization-aware training (QAT) methods, achieving accuracy levels comparable to full precision (32-bit) DL networks. Our findings demonstrate that AuGQ is agnostic to the training pipeline and batch normalization folding, distinguishing it from conventional quantization techniques. Furthermore, when integrated into state-of-the-art PTQ algorithms, AuGQ necessitates only 64 training samples for fine-tuning which is $$16\times $$ fewer than traditional methods. This reduction facilitates the application of high-accuracy quantization at sub-byte bit-widths, making it suitable for practical IoT deployments and enhancing computational efficiency on edge devices.},
  archive      = {J_APIN},
  author       = {Mujtaba, Ahmed and Lee, Wai Kong and Ko, Byoung Chul and Chang, Hyung Jin and Hwang, Seong Oun},
  doi          = {10.1007/s10489-025-06495-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {AuGQ: Augmented quantization granularity to overcome accuracy degradation for sub-byte quantized deep neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning with selective nets. <em>APIN</em>,
<em>55</em>(7), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06497-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of foundation models has significantly transformed machine learning, enabling even straightforward architectures to achieve results comparable to state-of-the-art methods. Inspired by the brain’s natural learning process-where studying a new concept activates distinct neural pathways and recalling that memory requires a specific stimulus to fully recover the information-we present a novel approach to dynamic task identification and submodel selection in continual learning. Our method leverages the power of the learning robust visual features without supervision model (DINOv2) foundation model to handle multi-experience datasets by dividing them into multiple experiences, each representing a subset of classes. To build a memory of these classes, we employ strategies such as using random real images, distilled images, k-nearest neighbours (kNN) to identify the closest samples to each cluster, and support vector machines (SVM) to select the most representative samples. During testing, where the task identification (ID) is not provided, we extract features of the test image and use distance measurements to match it with the stored features. Additionally, we introduce a new forgetting metric specifically designed to measure the forgetting rate in task-agnostic continual learning scenarios, unlike traditional task-specific approaches. This metric captures the extent of knowledge loss across tasks where the task identity is unknown during inference. Despite its simple architecture, our method delivers competitive performance across various datasets, surpassing state-of-the-art results in certain instances.},
  archive      = {J_APIN},
  author       = {Tung Luu, Hai and Szemenyei, Marton},
  doi          = {10.1007/s10489-025-06497-z},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Continual learning with selective nets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition dynamic multi-graph convolutional recurrent
network for traffic forecasting. <em>APIN</em>, <em>55</em>(7), 1–17.
(<a href="https://doi.org/10.1007/s10489-025-06503-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is crucial for urban traffic management. Traffic data is typically collected from sensors deployed along roadways, which often record both valid and erroneous data. However, most existing studies assume that the collected data is perfectly accurate, overlooking the existence of erroneous data. Meanwhile, graph neural networks are widely applied in traffic forecasting due to their ability to effectively capture correlations between nodes in a network. However, existing methods often rely solely on either static or dynamic graph structures, which may not accurately reflect the complex spatial relationships between nodes. To address these issues, we propose a decomposition dynamic multi-graph convolutional recurrent network (DDMGCRN). DDMGCRN utilizes a residual decomposition mechanism to separate erroneous data from valid data, thereby mitigating its impact. Additionally, DDMGCRN introduces sensor-specific spatial identity embeddings and timestamp embeddings to construct dynamic graphs. It further integrates static graphs for multi-graph fusion, facilitating more effective spatial feature extraction. Furthermore, to address the limitations of RNN-based models in capturing global temporal dependencies, DDMGCRN incorporates a global temporal attention module. Experimental results on four real-world datasets show that DDMGCRN outperforms all baseline models on the PEMS08 dataset, achieving a mean absolute error (MAE) of 14.13, which improves performance by approximately 4.85% compared to the best baseline model. The source code is available at https://github.com/hulongfei123/DDMGCRN .},
  archive      = {J_APIN},
  author       = {Hu, Longfei and Wei, Lai and Lin, Yeqing},
  doi          = {10.1007/s10489-025-06503-4},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Decomposition dynamic multi-graph convolutional recurrent network for traffic forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolution-aware networks for random missing traffic data
imputation. <em>APIN</em>, <em>55</em>(7), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06506-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integrity of traffic data is fundamental to alleviating the challenges in urban cities by computing. However, traffic data often exhibits a random missing characteristic due to sensor failure or network packet loss. Existing methods endowed too much prior knowledge on random missing data, such as data decay over time or data distribution correlation analysis. Thus, there is an urgent need for a data-driven and efficient traffic data interpolation method to assist downstream urban computing. Therefore, this paper proposes a fully convolutional spatial-temporal graph neural network (FC-STGNN) for traffic data imputation. Specifically, we apply a temporal convolutional network (TCN) to extract temporal features. Due to the dilated causal convolutions, it is possible to extract temporal features across time nodes, effectively alleviating the impact of data loss at a certain moment. Furthermore, we design a graph convolutional network (GCN) with residual connections to aggregate traffic data between adjacent road segments in the road network. Combining these two components enables spatiotemporal modeling of traffic data in data-missing environments. Finally, we conduct experiments on two real-world traffic datasets. The experiments demonstrate that our proposed method outperforms most baseline methods and owns a modest computational cost.},
  archive      = {J_APIN},
  author       = {Zhao, Zhenzhen and Shen, Guojiang and Zhou, Wenfeng and Gu, Wenjie and Chen, Chao and Kong, Xiangjie},
  doi          = {10.1007/s10489-025-06506-1},
  journal      = {Applied Intelligence},
  month        = {5},
  number       = {7},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Convolution-aware networks for random missing traffic data imputation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ar---9">AR - 9</h2>
<ul>
<li><details>
<summary>
(2025). Mori-zwanzig approach for belief abstraction with
application to belief space planning. <em>AR</em>, <em>49</em>(1), 1–23.
(<a href="https://doi.org/10.1007/s10514-024-10185-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a learning-based method to extract symbolic representations of the belief state and its dynamics in order to solve planning problems in a continuous-state partially observable Markov decision processes (POMDP) problem. While existing approaches typically parameterize the continuous-state POMDP into a finite-dimensional Markovian model, they are unable to preserve fidelity of the abstracted model. To improve accuracy of the abstracted representation, we introduce a memory-dependent abstraction approach to mitigate the modeling error. The first major contribution of this paper is we propose a Neural Network based method to learn the non-Markovian transition model based on the Mori-Zwanzig (M-Z) formalism. Different from existing work in applying M-Z formalism to autonomous time-invariant systems, our approach is the first work generalizing the M-Z formalism to robotics, by addressing the non-Markovian modeling of the belief dynamics that is dependent on historical observations and actions. The second major contribution is we theoretically show that modeling the non-Markovian memory effect in the abstracted belief dynamics improves the modeling accuracy, which is the key benefit of the proposed algorithm. Simulation experiment of a belief space planning problem is provided to validate the performance of the proposed belief abstraction algorithms.},
  archive      = {J_AR},
  author       = {Hou, Mengxue and Lin, Tony X. and Zhou, Enlu and Zhang, Fumin},
  doi          = {10.1007/s10514-024-10185-1},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Auton. Robot.},
  title        = {Mori-zwanzig approach for belief abstraction with application to belief space planning},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrative biomechanics of a human–robot carrying task:
Implications for future collaborative work. <em>AR</em>, <em>49</em>(1),
1–12. (<a href="https://doi.org/10.1007/s10514-024-10184-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients with sarcopenia, who face difficulties in carrying heavy loads, may benefit from collaborative robotic assistance that is modeled after human–human interaction. The objective of this study is to describe the kinematics and spatio-temporal parameters during a collaborative carrying task involving both human and robotic partners. Fourteen subjects carried a table while moving forward with a human and a robotic partner. The movements were recorded using a three-dimensional motion capture system. The subjects successfully completed the task of carrying the table with the robot. No significant differences were found in the shoulder and elbow flexion/extension angles. In human–human dyads, the center of mass naturally oscillated vertically with an amplitude of approximately 2 cm. The here presented results of the human–human interaction serve as a model for the development of future robotic systems, designed for collaborative manipulation.},
  archive      = {J_AR},
  author       = {Schuengel, Verena and Braunstein, Bjoern and Goell, Fabian and Braun, Daniel and Reißner, Nadine and Safronov, Kirill and Weiser, Christian and Heieis, Jule and Albracht, Kirsten},
  doi          = {10.1007/s10514-024-10184-2},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Auton. Robot.},
  title        = {Integrative biomechanics of a human–robot carrying task: Implications for future collaborative work},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe and stable teleoperation of quadrotor UAVs under haptic
shared autonomy. <em>AR</em>, <em>49</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10514-024-10186-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel approach that aims to address both safety and stability of a haptic teleoperation system within a framework of Haptic Shared Autonomy (HSA). We use Control Barrier Functions (CBFs) to generate the control input that follows the user’s input as closely as possible while guaranteeing safety. In the context of stability of the human-in-the-loop system, we limit the force feedback perceived by the user via a small $$\mathcal {L}_2$$ -gain, which is achieved by limiting the control and the force feedback via a differential constraint. Specifically, with the property of HSA, we propose two pathways to design the control and the force feedback: Sequential Control Force (SCF) and Joint Control Force (JCF). Both designs can achieve safety and stability but with different responses to the user’s commands. We conducted experimental simulations to evaluate and investigate the properties of the designed methods. We also tested the proposed method on a physical quadrotor UAV and a haptic interface.},
  archive      = {J_AR},
  author       = {Zhang, Dawei and Tron, Roberto},
  doi          = {10.1007/s10514-024-10186-0},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Auton. Robot.},
  title        = {Safe and stable teleoperation of quadrotor UAVs under haptic shared autonomy},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthesizing compact behavior trees for probabilistic
robotics domains. <em>AR</em>, <em>49</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10514-024-10187-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex robotics domains (e.g., remote exploration applications and scenarios involving interactions with humans) require encoding high-level mission specifications that consider uncertainty. Most current fielded systems in practice require humans to manually encode mission specifications in ways that require amounts of time and expertise that can become infeasible and limit mission scope. Therefore, we propose a method of automating the process of encoding mission specifications as behavior trees. In particular, we present an algorithm for synthesizing behavior trees that represent the optimal policy for a user-defined specification of a domain and problem in the Probabilistic Planning Domain Definition Language (PPDDL). Our algorithm provides access to behavior tree advantages including compactness and modularity, while alleviating the need for the time-intensive manual design of behavior trees, which requires substantial expert knowledge. Our method converts the PPDDL specification into solvable MDP matrices, simplifies the solution, i.e. policy, using Boolean algebra simplification, and converts this simplified policy to a compact behavior tree that can be executed by a robot. We present simulated experiments for a marine target search and response scenario and an infant-robot interaction for mobility domain. Our results demonstrate that the synthesized, simplified behavior trees have approximately between 15 x and 26 x fewer nodes and an average of between 8 x and 13 x fewer active conditions for selecting the active action than they would without simplification. These compactness and activity results suggest an increase in the interpretability and execution efficiency of the behavior trees synthesized by the proposed method. Additionally, our results demonstrate that this synthesis method is robust to a variety of user input mistakes, and we empirically confirm that the synthesized behavior trees perform equivalently to the optimal policy that they are constructed to logically represent.},
  archive      = {J_AR},
  author       = {Scheide, Emily and Best, Graeme and Hollinger, Geoffrey A.},
  doi          = {10.1007/s10514-024-10187-z},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Auton. Robot.},
  title        = {Synthesizing compact behavior trees for probabilistic robotics domains},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). View: Visual imitation learning with waypoints. <em>AR</em>,
<em>49</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s10514-024-10188-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots can use visual imitation learning (VIL) to learn manipulation tasks from video demonstrations. However, translating visual observations into actionable robot policies is challenging due to the high-dimensional nature of video data. This challenge is further exacerbated by the morphological differences between humans and robots, especially when the video demonstrations feature humans performing tasks. To address these problems we introduce Visual Imitation lEarning with Waypoints (VIEW), an algorithm that significantly enhances the sample efficiency of human-to-robot VIL. VIEW achieves this efficiency using a multi-pronged approach: extracting a condensed prior trajectory that captures the demonstrator’s intent, employing an agent-agnostic reward function for feedback on the robot’s actions, and utilizing an exploration algorithm that efficiently samples around waypoints in the extracted trajectory. VIEW also segments the human trajectory into grasp and task phases to further accelerate learning efficiency. Through comprehensive simulations and real-world experiments, VIEW demonstrates improved performance compared to current state-of-the-art VIL methods. VIEW enables robots to learn manipulation tasks involving multiple objects from arbitrarily long video demonstrations. Additionally, it can learn standard manipulation tasks such as pushing or moving objects from a single video demonstration in under 30 min, with fewer than 20 real-world rollouts. Code and videos here: https://collab.me.vt.edu/view/},
  archive      = {J_AR},
  author       = {Jonnavittula, Ananth and Parekh, Sagar and P. Losey, Dylan},
  doi          = {10.1007/s10514-024-10188-y},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Auton. Robot.},
  title        = {View: Visual imitation learning with waypoints},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Eigen-factors a bilevel optimization for plane SLAM of 3D
point clouds. <em>AR</em>, <em>49</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10514-025-10189-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern depth sensors can generate a huge number of 3D points in few seconds to be later processed by Localization and Mapping algorithms. Ideally, these algorithms should handle efficiently large sizes of Point Clouds (PC) under the assumption that using more points implies more information available. The Eigen Factors (EF) is a new algorithm that solves PC SLAM by using planes as the main geometric primitive. To do so, EF exhaustively calculates the error of all points at complexity O(1), thanks to the Summation matrix S of homogeneous points. The solution of EF is a bilevel optimization where the lower-level problem estimates the plane variables in closed-form, and the upper-level non-linear problem uses second order optimization to estimate sensor poses (trajectory). We provide a direct analytical solution for the gradient and Hessian based on the homogeneous point-plane constraint. In addition, two variants of the EF are proposed: one pure analytical derivation and a second one approximating the problem to an alternating optimization showing better convergence properties. We evaluate the optimization processes (back-end) of EF and other state-of-the-art plane SLAM algorithms in a synthetic environment, and extended to ICL dataset (RGBD) and LiDAR KITTI datasets. EF demonstrates superior robustness and accuracy of the estimated trajectory and improved map metrics. Code is publicly available at https://github.com/prime-slam/EF-plane-SLAM with python bindings and pip package.},
  archive      = {J_AR},
  author       = {Ferrer, Gonzalo and Iarosh, Dmitrii and Kornilova, Anastasiia},
  doi          = {10.1007/s10514-025-10189-5},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Auton. Robot.},
  title        = {Eigen-factors a bilevel optimization for plane SLAM of 3D point clouds},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Isolated kalman filtering: Theory and decoupled estimator
design. <em>AR</em>, <em>49</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s10514-025-10191-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a state decoupling strategy for Kalman filtering problems, when the dynamics of individual estimates are decoupled and their outputs are sparsely coupled. The algorithm is termed Isolated Kalman Filtering (IsoKF) and exploits the sparsity in the output coupling by applying approximations that mitigate the need for non-involved estimates. We prove that the approximations made during the isolated coupling of estimates are based on an implicit maximum determinant completion of the incomplete a priori covariance matrix. The steady state behavior is studied on eleven different observation graphs and a buffering scheme to support delayed (i.e. out-of-order) measurements is proposed. We discussed handling of delayed measurements in both, an optimal or a suboptimal way. The credibility of the isolated estimates are evaluated on a linear and nonlinear toy example in Monte Carlo simulations. The presented paradigm is made available online to the community within a generic C++ estimation framework supporting both, modular sensor fusion and collaborative state estimation.},
  archive      = {J_AR},
  author       = {Jung, Roland and Luft, Lukas and Weiss, Stephan},
  doi          = {10.1007/s10514-025-10191-x},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Auton. Robot.},
  title        = {Isolated kalman filtering: Theory and decoupled estimator design},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Between reality and delusion: Challenges of applying large
language models to companion robots for open-domain dialogues with older
adults. <em>AR</em>, <em>49</em>(1), 1–41. (<a
href="https://doi.org/10.1007/s10514-025-10190-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throughout our lives, we interact daily in conversations with our friends and family, covering a wide range of topics, known as open-domain dialogue. As we age, these interactions may diminish due to changes in social and personal relationships, leading to loneliness in older adults. Conversational companion robots can alleviate this issue by providing daily social support. Large language models (LLMs) offer flexibility for enabling open-domain dialogue in these robots. However, LLMs are typically trained and evaluated on textual data, while robots introduce additional complexity through multi-modal interactions, which has not been explored in prior studies. Moreover, it is crucial to involve older adults in the development of robots to ensure alignment with their needs and expectations. Correspondingly, using iterative participatory design approaches, this paper exposes the challenges of integrating LLMs into conversational robots, deriving from 34 Swedish-speaking older adults’ (one-to-one) interactions with a personalized companion robot, built on Furhat robot with GPT $$-$$ 3.5. These challenges encompass disruptions in conversations, including frequent interruptions, slow, repetitive, superficial, incoherent, and disengaging responses, language barriers, hallucinations, and outdated information, leading to frustration, confusion, and worry among older adults. Drawing on insights from these challenges, we offer recommendations to enhance the integration of LLMs into conversational robots, encompassing both general suggestions and those tailored to companion robots for older adults.},
  archive      = {J_AR},
  author       = {Irfan, Bahar and Kuoppamäki, Sanna and Hosseini, Aida and Skantze, Gabriel},
  doi          = {10.1007/s10514-025-10190-y},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-41},
  shortjournal = {Auton. Robot.},
  title        = {Between reality and delusion: Challenges of applying large language models to companion robots for open-domain dialogues with older adults},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASAP-MPC: An asynchronous update scheme for online motion
planning with nonlinear model predictive control. <em>AR</em>,
<em>49</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10514-025-10192-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a Nonlinear Model Predictive Control (NMPC) update scheme targeted at motion planning for mechatronic motion systems, such as drones and mobile platforms. NMPC-based motion planning typically requires low computation times to be able to provide control inputs at the required rate for system stability, disturbance rejection, and overall performance. To achieve online NMPC updates in complex situations, works in literature typically rely on one of two approaches: attempting to reduce the solution times in NMPC by sacrificing feasibility guarantees, or allowing more time to the motion planning algorithm, which requires additional strategies to ensure robust tracking of the planned motion, e.g., state feedback. Following this second paradigm, this paper presents As-Soon-As-Possible MPC (ASAP-MPC), an asynchronous update scheme for online motion planning with optimal control that abandons the idea of having to satisfy restrictive real-time update rates and that solves the optimal control problem to full convergence. ASAP-MPC combines trajectory generation through optimal control with additional tracking control for improved robustness against disturbances and plant-model mismatch. The scheme seamlessly connects trajectories, resulting from subsequent NMPC solutions, providing a smooth and continuous overall trajectory for the motion system. This framework’s applicability to embedded applications is shown on two different experiment setups where a state-of-the-art method fails to successfully navigate through a given environment: a quadcopter flying through a cluttered environment with hardware-in-the-loop simulation and a scale model truck-trailer manoeuvring in a structured physical lab environment.},
  archive      = {J_AR},
  author       = {Dirckx, Dries and Bos, Mathias and Vandewal, Bastiaan and Vanroye, Lander and Swevers, Jan and Decré, Wilm},
  doi          = {10.1007/s10514-025-10192-w},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Auton. Robot.},
  title        = {ASAP-MPC: An asynchronous update scheme for online motion planning with nonlinear model predictive control},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="alg---5">Alg - 5</h2>
<ul>
<li><details>
<summary>
(2025). Reforming an envy-free matching. <em>Alg</em>,
<em>87</em>(4), 594–620. (<a
href="https://doi.org/10.1007/s00453-025-01294-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of reforming an envy-free matching when each agent has a strict preference over items and is assigned a single item. Given an envy-free matching, we consider an operation to exchange the item of an agent with an unassigned item preferred by the agent that results in another envy-free matching. We repeat this operation as long as we can. We prove that the resulting envy-free matching is uniquely determined up to the choice of an initial envy-free matching, and can be found in polynomial time. We call the resulting matching a reformist envy-free matching, and study a shortest sequence to obtain the reformist envy-free matching from an initial envy-free matching. We prove that a shortest sequence is computationally hard to obtain. We also give polynomial-time algorithms when each agent accepts at most three items or each item is accepted by at most two agents. Inapproximability and fixed-parameter (in)tractability are also discussed.},
  archive      = {J_Alg},
  author       = {Ito, Takehiro and Iwamasa, Yuni and Kakimura, Naonori and Kamiyama, Naoyuki and Kobayashi, Yusuke and Nozaki, Yuta and Okamoto, Yoshio and Ozeki, Kenta},
  doi          = {10.1007/s00453-025-01294-z},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {594-620},
  shortjournal = {Algorithmica},
  title        = {Reforming an envy-free matching},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guarding polyominoes under k-hop visibility. <em>Alg</em>,
<em>87</em>(4), 572–593. (<a
href="https://doi.org/10.1007/s00453-024-01292-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the Art Gallery Problem under k-hop visibility in polyominoes. In this visibility model, two unit squares of a polyomino can see each other if and only if the shortest path between the respective vertices in the dual graph of the polyomino has length at most k. In this paper, we show that the VC dimension of this problem is 3 in simple polyominoes, and 4 in polyominoes with holes. Furthermore, we provide a reduction from Planar Monotone 3Sat, thereby showing that the problem is NP-complete even in thin polyominoes (i.e., polyominoes that do not a contain a $$2\times 2$$ block of cells). Complementarily, we present a linear-time 4-approximation algorithm for simple 2-thin polyominoes (which do not contain a $$3\times 3$$ block of cells) for all $$k\in {\mathbb {N}}$$ .},
  archive      = {J_Alg},
  author       = {Filtser, Omrit and Krohn, Erik and Nilsson, Bengt J. and Rieck, Christian and Schmidt, Christiane},
  doi          = {10.1007/s00453-024-01292-7},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {572-593},
  shortjournal = {Algorithmica},
  title        = {Guarding polyominoes under k-hop visibility},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed parameter multi-objective evolutionary algorithms for
the w-separator problem. <em>Alg</em>, <em>87</em>(4), 537–571. (<a
href="https://doi.org/10.1007/s00453-024-01290-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parameterized analysis provides powerful mechanisms for obtaining fine-grained insights into different types of algorithms. In this work, we combine this field with evolutionary algorithms and provide parameterized complexity analysis of evolutionary multi-objective algorithms for the W-separator problem, which is a natural generalization of the vertex cover problem. The goal is to remove the minimum number of vertices such that each connected component in the resulting graph has at most W vertices. We provide different multi-objective formulations involving two or three objectives that provably lead to fixed-parameter evolutionary algorithms with respect to the value of an optimal solution OPT and W. Of particular interest are kernelizations and the reducible structures used for them. We show that in expectation the algorithms make incremental progress in finding such structures and beyond. The current best known kernelization of the W-separator uses linear programming methods and requires non-trivial post-processing steps to extract the reducible structures. We provide additional structural features to show that evolutionary algorithms with appropriate objectives are also capable of extracting them. Our results show that evolutionary algorithms with different objectives guide the search and admit fixed parameterized runtimes to solve or approximate (even arbitrarily close) the W-separator problem.},
  archive      = {J_Alg},
  author       = {Baguley, Samuel and Friedrich, Tobias and Neumann, Aneta and Neumann, Frank and Pappik, Marcus and Zeif, Ziena},
  doi          = {10.1007/s00453-024-01290-9},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {537-571},
  shortjournal = {Algorithmica},
  title        = {Fixed parameter multi-objective evolutionary algorithms for the W-separator problem},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The compact genetic algorithm struggles on cliff functions.
<em>Alg</em>, <em>87</em>(4), 507–536. (<a
href="https://doi.org/10.1007/s00453-024-01281-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimation of distribution algorithms (EDAs) are general-purpose optimizers that maintain a probability distribution over a given search space. This probability distribution is updated through sampling from the distribution and a reinforcement learning process which rewards solution components that have shown to be part of good quality samples. The compact genetic algorithm (cGA) is a non-elitist EDA able to deal with difficult multimodal fitness landscapes that are hard to solve by elitist algorithms. We investigate the cGA on the Cliff function for which it was shown recently that non-elitist evolutionary algorithms and artificial immune systems optimize it in expected polynomial time. We point out that the cGA faces major difficulties when solving the Cliff function and investigate its dynamics both experimentally and theoretically. Our experimental results indicate that the cGA requires exponential time for all values of the update strength 1/K. We show theoretically that, under sensible assumptions, there is a negative drift when sampling around the location of the cliff. Experiments further suggest that there is a phase transition for K where the expected optimization time drops from $$n^{\Theta (n)}$$ to $$2^{\Theta (n)}$$ .},
  archive      = {J_Alg},
  author       = {Neumann, Frank and Sudholt, Dirk and Witt, Carsten},
  doi          = {10.1007/s00453-024-01281-w},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {507-536},
  shortjournal = {Algorithmica},
  title        = {The compact genetic algorithm struggles on cliff functions},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). XNLP-completeness for parameterized problems on graphs with
a linear structure. <em>Alg</em>, <em>87</em>(4), 465–506. (<a
href="https://doi.org/10.1007/s00453-024-01274-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we showcase the class XNLP as a natural place for many hard problems parameterized by linear width measures. This strengthens existing W[1]-hardness proofs for these problems, since XNLP-hardness implies W[t]-hardness for all t. It also indicates, via a conjecture by Pilipczuk and Wrochna (ACM Trans Comput Theory 9:1–36, 2018), that any XP algorithm for such problems is likely to require XP space. In particular, we show XNLP-completeness for natural problems parameterized by pathwidth, linear clique-width, and linear mim-width. The problems we consider are Independent Set, Dominating Set, Odd Cycle Transversal, (q-)Coloring, Max Cut, Maximum Regular Induced Subgraph, Feedback Vertex Set, Capacitated (Red-Blue) Dominating Set, Capacitated Vertex Cover and Bipartite Bandwidth.},
  archive      = {J_Alg},
  author       = {Bodlaender, Hans L. and Groenland, Carla and Jacob, Hugo and Jaffke, Lars and Lima, Paloma T.},
  doi          = {10.1007/s00453-024-01274-9},
  journal      = {Algorithmica},
  month        = {4},
  number       = {4},
  pages        = {465-506},
  shortjournal = {Algorithmica},
  title        = {XNLP-completeness for parameterized problems on graphs with a linear structure},
  volume       = {87},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="bcyb---1">BCYB - 1</h2>
<ul>
<li><details>
<summary>
(2025). Optimal control for stochastic neural oscillators.
<em>BCYB</em>, <em>119</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s00422-025-01007-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study develops an event-based, energy-efficient control strategy for desynchronizing coupled neuronal networks using optimal control theory. Inspired by phase resetting techniques in Parkinson’s disease treatment, we incorporate stochasticity of the system’s dynamics into deterministic models to address neural system intrinsic noise. We use an advanced computational solver for nonlinear stochastic partial differential equations to solve the stochastic Hamilton–Jacobi–Bellman equation via level set methods for a single neuron model; this allows us to find control inputs which drive the dynamics close to the system’s phaseless set. When applied to coupled neuronal networks, these inputs achieve effective randomization of neuronal spike timing, leading to significant network desynchronization. Compared to its deterministic counterpart, our stochastic method can achieve considerable energy savings. The event-based control minimizes unnecessary charge transfer, potentially extending implanted stimulator battery life while maintaining robustness against variations in neuronal coupling strengths and network heterogeneities. These findings highlight the potential for developing energy-efficient neurostimulation techniques with implications for deep brain stimulation protocols. The presented computational framework could also be applied to other domains for which stochastic optimal control problems are prevalent.},
  archive      = {J_BCYB},
  author       = {Rajabi, Faranak and Gibou, Frederic and Moehlis, Jeff},
  doi          = {10.1007/s00422-025-01007-3},
  journal      = {Biological Cybernetics},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Biol. Cybern.},
  title        = {Optimal control for stochastic neural oscillators},
  volume       = {119},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cc---21">CC - 21</h2>
<ul>
<li><details>
<summary>
(2025). Deep learning innovations in the detection of lung cancer:
Advances, trends, and open challenges. <em>CC</em>, <em>17</em>(2),
1–46. (<a href="https://doi.org/10.1007/s12559-025-10408-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is the second leading cause of death worldwide, and within this type of disease, lung cancer is the second most diagnosed, but the leading cause of death. Early detection is crucial to increase patient survival rates. One of the primary methods for detecting this disease is through medical imaging, which, due to its features, is well-suited for analysis by deep learning techniques. These techniques have demonstrated exceptional results in similar tasks. Therefore, this paper focusses on analyzing the latest work related to lung cancer detection using deep learning, providing a clear overview of the state of the art and the most common research directions pursued by researchers. We have reviewed DL techniques for lung cancer detection between 2018 and 2023, analyzing the different datasets that have been used in this domain and providing an analysis between the different investigations. In this state-of-the-art review, we describe the main datasets used in this field and the primary deep learning techniques used to detect radiological signs, predominantly convolutional neural networks (CNNs). As the impact of these systems in medicine can pose risks to patients, we also examine the extent to which explainable AI techniques have been applied to enhance the understanding of these systems, a crucial aspect for their real-world application. Finally, we will discuss the trends that the domain is expected to follow in the coming years and the challenges that researchers will need to address.},
  archive      = {J_CC},
  author       = {Liz-López, Helena and de Sojo-Hernández, Áurea Anguera and D’Antonio-Maceiras, Sergio and Díaz-Martínez, Miguel Angel and Camacho, David},
  doi          = {10.1007/s12559-025-10408-2},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-46},
  shortjournal = {Cogn. Comput.},
  title        = {Deep learning innovations in the detection of lung cancer: Advances, trends, and open challenges},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-source adversarial domain adaptive fault diagnosis
method based on multi-classifier alignment. <em>CC</em>, <em>17</em>(2),
1–17. (<a href="https://doi.org/10.1007/s12559-025-10414-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning–based fault diagnosis has received intensive attention from researchers. Under various working conditions, high-precision cross-domain fault diagnosis remains a problem due to distribution differences between different source domains and between source and target domains. Therefore, reducing the distribution difference between source domain and target domain data is crucial for improving the model’s ability to learn domain-invariant features and fault-representative features. To address this challenge, this paper proposes a multi-source adversarial domain adaptation approach for fault diagnosis, referred to as MSD-MCA, which is based on the alignment of multiple classifiers. The method constructs a sub-network for each source domain and utilizes domain adversarial training to extract domain-invariant features. It then generates a fault feature set for each source domain by leveraging the domain-invariant features corresponding to various fault types. To align the target domain with the source domains, the Wasserstein distance is calculated between the target features and each fault feature set. Minimizing the entropy of the distribution distance vector facilitates the learning of fault-representative features. Additionally, an association matrix is employed to enhance the stability of the decision boundaries during the training process. This approach improves the model’s capacity to generalize across multiple domains while effectively capturing fault-related information. To validate the efficacy of the proposed MSD-MCA method, a comparative analysis was conducted against several state-of-the-art diagnostic approaches. The evaluation was performed on bearing fault data from Case Western Reserve University, as well as two real-world industrial datasets. The results indicate that MSD-MCA shows improved accuracy and enhanced generalization capabilities across both datasets. Consequently, MSD-MCA can better learn the domain-invariant features and fault-representative features and improve the accuracy of fault diagnosis.},
  archive      = {J_CC},
  author       = {Zheng, Zhiwei and He, Yu and Ma, Tianyu and Xiang, Qingsong},
  doi          = {10.1007/s12559-025-10414-4},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-source adversarial domain adaptive fault diagnosis method based on multi-classifier alignment},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional time series modeling for pneumoconiosis
progression risk prediction with missing data. <em>CC</em>,
<em>17</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s12559-025-10417-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pneumoconiosis is a serious occupational disease with high morbidity and disability rates. However, the evolution of pneumoconiosis is complex and changeable, and the course of most cases is incomplete, resulting in a lack of continuity in a large number of data samples, which makes it challenging for radiologists to accurately assess the development of the disease. We propose a conditional self-attention TimesNet as the backbone network for time series analysis tasks, aiming to improve prognosis prediction based on disease progression information in pneumoconiosis image data at different time periods. In our approach, we train the model using chest X-ray images of the same patient at different time points, incorporating a hierarchical attention structure and self-attention blocks to fully consider the contextual correlation information of consecutive time-point images. Additionally, diverse clinical features of patients are utilized as conditional inputs in disease progression prediction. The goal is to better learn the progression status of the disease and reflect the disease trajectory representation of missing time series data, enhancing the model’s predictive capabilities. Simultaneously, an adversarial diffusion generation model is designed to fill in missing values in the time series data. The missing data generated by the model effectively improves radiologists’ judgment of pneumoconiosis progression. We trained our model using missing time series images to predict clinical outcomes. Experimental validation on two medical datasets shows that the AUC, sensitivity, specificity, and DSC achieved 90.33%, 87.89%, 85.01%, and 88.54%, respectively. These results highlight the competitive performance of our method across multiple evaluation metrics. Our model can capture the correlation between short-term/long-term/missing time series lesion features and time in pneumoconiosis images. This approach holds significant implications for predicting clinical outcomes and progression risk in pneumoconiosis, providing valuable guidance for the assessment and prognosis of pneumoconiosis.},
  archive      = {J_CC},
  author       = {Ren, Xueting and Zhao, Zijuan and Jia, Liye and Zhao, Juanjuan and Jia, Baoping and Qiang, Yan and Zhao, Huilan and Yue, Huajie},
  doi          = {10.1007/s12559-025-10417-1},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Cogn. Comput.},
  title        = {Conditional time series modeling for pneumoconiosis progression risk prediction with missing data},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GSAC-UFormer: Groupwise self-attention convolutional
transformer-based UNet for medical image segmentation. <em>CC</em>,
<em>17</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s12559-025-10425-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional transformers struggle to effectively capture local contextual information. Conversely, CNNs face challenges in modeling long-range dependencies. To address these limitations, this paper introduces GSAC-UFormer, an innovative Groupwise Self-Attention Convolutional Transformer-based UNet for medical image segmentation. The design of GSAC-UFormer focuses on efficiently integrating both local and global information, balancing the strengths of different processing techniques. At the core of GSAC-UFormer is the GSAC-Former block. This module combines groupwise convolution with a CNN-adaptive self-attention mechanism, enabling parallel integration of local and global contexts. This architecture allows the model to effectively capture intricate dependencies across various data dimensions while processing local features with high efficiency. The Guided Contextual Feature Attention (GCFA) mechanism further enhances feature selection. It emphasizes the most relevant contextual information, refining spatial and channel-wise relationships in the extracted features. This targeted approach mitigates noise and improves model accuracy. Additionally, the Multi-Depth Partitioned Depthwise Convolution Transformer (MDPDC-Former) serves as a bottleneck module. It optimizes feature mapping and enhances network learning efficiency by dynamically adjusting the receptive field. This enables the model to capture multi-scale semantic information more effectively. Experimental results highlight the superior performance of GSAC-UFormer compared to state-of-the-art methods. It achieves Dice coefficients of 91.6%, 94.61%, and 82.24% on the MICCAI 2017 (red lesion), PH2, and CVC-ClinicalDB datasets, respectively. These results underscore its effectiveness in advancing medical image segmentation.},
  archive      = {J_CC},
  author       = {Garbaz, Anass and Oukdach, Yassine and Charfi, Said and El Ansari, Mohamed and Koutti, Lahcen and Salihoun, Mouna},
  doi          = {10.1007/s12559-025-10425-1},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {GSAC-UFormer: Groupwise self-attention convolutional transformer-based UNet for medical image segmentation},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved alternative queuing method of interval-set
dissimilarity measures and possibility degrees for multi-expert
multi-criteria decision-making. <em>CC</em>, <em>17</em>(2), 1–24. (<a
href="https://doi.org/10.1007/s12559-025-10426-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-expert multi-criteria decision-making (MEMCDM) based on interval-set information is novel and valuable, and it already adopts an effective strategy of alternative queuing method (AQM), called AQM-IS. AQM-IS mainly relies on dissimilarity measures and possibility degrees of interval sets, and the two types of uncertainty measures have absolute-quantitative limitations on rough information extraction to imply improvement space. In this work, improved dissimilarity measures and possibility degrees of interval sets are constructed from a better perspective of relative quantization related to systematic structuring and statistical fusion, so improved AQM (called IAQM-IS) is established to advance MEMCDM by using the interval-set information transformation. As bases, relative dissimilarity measures are proposed to modify absolute dissimilarity measures for both interval-set pairs and families on closeness and deviation; thus, relevant internal relationships, mutual sizes, axiomatic properties, and illustrative examples are acquired. Aiming at interval-set information, improved AQM (i.e., IAQM-IS) is investigated for MEMCDM. Concretely, absolute dissimilarity measures are chosen to determine criterion weights based on judgement matrix and maximum deviation, and improved possibility degrees of interval sets are proposed by systematic likelihood characterizations and arithmetic mean combination; using the weight arithmetic mean of improved dissimilarity measures and possibility degrees, a more powerful index for sorting alternatives is generated to formulate IAQM-IS. For algorithmic evaluation, two assessment indices of decision rankings (called separability and goodness) are designed; accordingly, the two algorithms of MEMCDM — AQM-IS and IAQM-IS — are demonstrated and compared via both an applied examples of e-commerce platforms and six simulated experiments of public datasets, and thus the effectiveness and superiority of IAQM-IS are verified. In summary by the double-quantization technique, the improved dissimilarity measures and possibility degrees deepen uncertainty measures of interval-set information tables, and corresponding IAQM-IS has better decision performance than current AQM-IS in specific application scenarios of social cognition.},
  archive      = {J_CC},
  author       = {Xie, Xin and Zhang, Xianyong and Lv, Zhiying and Chen, Jiang},
  doi          = {10.1007/s12559-025-10426-0},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-24},
  shortjournal = {Cogn. Comput.},
  title        = {Improved alternative queuing method of interval-set dissimilarity measures and possibility degrees for multi-expert multi-criteria decision-making},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLKT: Optimizing cognitive load management in knowledge
tracing. <em>CC</em>, <em>17</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s12559-025-10427-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of online adaptive learning, Knowledge Tracing (KT) has become an indispensable component of online education systems. KT assesses the knowledge level of each learner by tracing their learning activities. Managing cognitive load is crucial in the learners’ cognitive process; too low a load may lead to a lack of concentration, while excessively high cognitive load can impede information processing. In pursuit of an ideal learning model, this paper proposes the Cognitive Load-based Knowledge Tracing (CLKT) model. This model employs a Heterogeneous Cognitive Graph Convolutional Network (HCGCN) to extract learners’ knowledge representations and establish connections between learning tasks or instructional resources and learners, providing the model with interpretable learning path recommendations. By introducing the Attention Concentration (AC) mechanism, the model dynamically processes information and efficiently integrates it into learners’ knowledge structures to maintain an appropriate cognitive load level, thus maximizing effective learning. Experiments conducted on the ASSISTMENTS dataset, which contains real-world student interaction data from an online tutoring system, focus on studying the impact of different cognitive loads on the learning process. The experimental results delve into the effects of cognitive load on learner performance, ensuring that learners can engage in learning with appropriate pace and difficulty, thereby enhancing their learning outcomes.},
  archive      = {J_CC},
  author       = {Wu, Qianxi and Ji, Weidong and Zhou, Guohui},
  doi          = {10.1007/s12559-025-10427-z},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Cogn. Comput.},
  title        = {CLKT: Optimizing cognitive load management in knowledge tracing},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging graph convolutional networks for semi-supervised
learning in multi-view non-graph data. <em>CC</em>, <em>17</em>(2),
1–15. (<a href="https://doi.org/10.1007/s12559-025-10428-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning with a graph-based approach has gained prominence in machine learning, particularly in scenarios where labeling data involves substantial costs. Graph convolution networks (GCNs) have found widespread application in semi-supervised learning, predominantly on graph-structured data such as citation and social networks. However, a noticeable gap exists in the application of these methods to non-graph multi-view data, such as collections of images. In an effort to address this gap, we introduce two innovative deep semi-supervised multi-view classification models specifically tailored for non-graph data. Both models share a common architecture, leveraging GCNs and integrating a label smoothing constraint. The primary distinction lies in the construction of the consensus similarity graph. The first model directly reconstructs the consensus graph from different views using a specialized objective function designed for flexible graph-based semi-supervised classification. In contrast, the second model independently reconstructs individual graphs and subsequently adaptively merges them into a unified consensus graph. Our experiments encompass various multiple-view image datasets. The results consistently demonstrate the superior performance of our proposed approach compared to traditional fusion methods with GCNs. In this research, we present two approaches for tackling semi-supervised classification challenges involving multiple views. One method is named Semi-supervised Classification with a Unified Graph (SCUG), and the other is referred to as Semi-supervised Classification with a Fused Graph (SC-Fused). Both methods share a common semi-supervised classification process, utilizing the GCN framework and incorporating label smoothing. However, the key distinction lies in the construction of the similarity graph. Unlike traditional ad hoc graph construction approaches, our proposed methods, SCUG and SC-Fused, estimate the unified graph or individual graphs, respectively, alongside the labels. This results in more optimized graphs that benefit from data smoothing and the semi-supervised context.},
  archive      = {J_CC},
  author       = {Dornaika, F. and Bi, J. and Charafeddine, J.},
  doi          = {10.1007/s12559-025-10428-y},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Cogn. Comput.},
  title        = {Leveraging graph convolutional networks for semi-supervised learning in multi-view non-graph data},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A holistic comparative study of large language models as
emotional support dialogue systems. <em>CC</em>, <em>17</em>(2), 1–21.
(<a href="https://doi.org/10.1007/s12559-025-10429-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotional support conversation aims to convey understanding, sympathy, care, and support through conversation, to help others cope with emotional distress, pressure, or challenges. In this study, we conduct a holistic comparative study to investigate how well the most recent large language models (LLMs), which have recently proved to have empathy, and act as emotional supporters. To this end, we make use of the emotional support conversation (ESC) framework and assess multiple maintain LLMs accordingly. We then have an in-depth comparison between these LLM-based emotional supporters to humans in terms of the use of emotional support strategies as well as the use of language. Surprisingly, we find that there is still a huge gap until these LLMs become effective emotional supporters. This is because, on the one hand, they have strong preference biases on using a limited set of strategies, making them always show empathy but rarely take real actions (such as providing suggestions), which is key in ESC. On the other hand, they often over-generate responses, making what they utter a departure from those of human experts.},
  archive      = {J_CC},
  author       = {Bai, Xin and Chen, Guanyi and He, Tingting and Zhou, Chenlian and Guo, Cong},
  doi          = {10.1007/s12559-025-10429-x},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Cogn. Comput.},
  title        = {A holistic comparative study of large language models as emotional support dialogue systems},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-enabled multi-layer subword joint learning for
chinese word embedding. <em>CC</em>, <em>17</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s12559-025-10431-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Chinese word embeddings have attracted significant attention in the field of natural language processing (NLP). The complex structures and diverse influences of Chinese characters present distinct challenges for semantic representation. As a result, Chinese word embeddings are primarily investigated in conjunction with characters and their subcomponents. Previous research has demonstrated that word vectors frequently fail to capture the subtle semantics embedded within the complex structure of Chinese characters. Furthermore, they often neglect the varying contributions of subword information to semantics at different levels. To tackle these challenges, we present a weight-based word vector model that takes into account the internal structure of Chinese words at various levels. The model further categorizes the internal structure of Chinese words into six layers of subword information: words, characters, components, pinyin, strokes, and structures. The semantics of Chinese words can be derived by integrating the subword information from various layers. Moreover, the model considers the varying contributions of each subword layer to the semantics of Chinese words. It utilizes an attention mechanism to determine the weights between and within the subword layers, facilitating the comprehensive extraction of word semantics. The word-level subwords act as the attention mechanism query for subwords in other layers to learn semantic bias. Experimental results show that the proposed word vector model achieves enhancements in various evaluation metrics, such as word similarity, word analogy, text categorization, and case studies.},
  archive      = {J_CC},
  author       = {Xue, Pengpeng and Xiong, Jing and Tan, Liang and Liu, Zhongzhu and Liu, Kanglong},
  doi          = {10.1007/s12559-025-10431-3},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Cogn. Comput.},
  title        = {Attention-enabled multi-layer subword joint learning for chinese word embedding},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling visual attention based on gestalt theory.
<em>CC</em>, <em>17</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s12559-025-10410-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gestalt theory laid the foundation for modern cognitive learning theory and emphasizes that the whole is greater than the sum of its parts, where similarity and proximity are two important principles. However, exploiting Gestalt theory to detect multiple salient objects remains challenging. In this paper, we propose a very simple yet efficient saliency model based on Gestalt theory, namely, the color similarity and spatial proximity (CSSP) model. It utilizes content-based image retrieval (CBIR) techniques to detect salient objects. The methodology has three important highlights: (1) a novel weighted distance is proposed to calculate spatial proximity. It can control spatial proximity within a certain range and detect salient objects robustly. (2) Two novel and efficient saliency scoring calculation methods are proposed under the framework of CBIR techniques, where color similarity and spatial proximity are used for image matching and the ordering of retrieved images. This enables the robust identification of multiple salient objects. (3) A very simple yet efficient integration method is proposed to combine saliency maps. Using this integration method, impurities around salient objects are greatly reduced, and their interiors are highlighted robustly. Experiments with several well-known benchmark datasets validate the performance of the CSSP model. The CSSP method resulted in fewer grey patches inside salient objects, and it is superior to many existing state-of-the-art methods. The detected salient regions were brighter, improving the effectiveness of multiple salient objects detection. In addition, the CSSP method can detect salient objects robustly even when they touch the image boundaries. It has demonstrated that modeling visual attention based on Gestalt theory is a novel, viable approach.},
  archive      = {J_CC},
  author       = {Liu, Guang-Hai and Yang, Jing-Yu},
  doi          = {10.1007/s12559-025-10410-8},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {Modeling visual attention based on gestalt theory},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-way decision approach based on utility and dynamic
localization transformational procedures within a circular q-rung
orthopair fuzzy set for ranking and grading large language models.
<em>CC</em>, <em>17</em>(2), 1–26. (<a
href="https://doi.org/10.1007/s12559-025-10432-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made significant advancements in natural language processing (NLP), impacting both academia and industry. Evaluating LLMs is crucial, as these models are developed for multiple NLP tasks. However, no single LLM has successfully fulfilled all tasks simultaneously, creating a research gap. This, in turn, leads to the identification of the most and least effective LLMs in real-world problems, presenting a multi-criteria decision-making (MCDM) challenge due to the diversity of evaluation tasks, task prioritization, data variability, and issues related to ranking and grading with binary data. While the three-way decision (3WD) approach based on MCDM methods can address this, it often leaves uncertainty as an open issue, highlighting a theoretical gap. To address this, the contribution of this study is the development of a new 3WD approach based on utility and dynamic localization transformational procedures within a circular q-rung orthopair fuzzy set (C-q-ROFS) for ranking and grading LLMs. The methodology includes (1) reformulating the fuzzy weighted zero inconsistency-based interrelationship process (FWZICbIP) using C-q-ROFS (C-q-ROFS–FWZICbIP method) to prioritize tasks and address weighting uncertainty; (2) formulating a decision matrix by intersecting LLMs with NLP tasks while applying utility and dynamic localization procedures to handle binary input issues; and (3) reformulating the conditional probabilities by opinion scores (CPOS) method within the C-q-ROFS context (C-q-ROFS–CPOS method) to determine decision thresholds for each LLM. This involves incorporating Bayesian decision theory under C-q-ROFS to establish decision thresholds for all LLMs, thereby enhancing the certainty and effectiveness of the grading process. Based on this, the 3WD approach is developed to offer a robust mechanism for ranking and grading LLMs. Forty LLMs were ranked and graded across 11 NLP tasks, with the findings showing that LLM14 demonstrated high efficacy, ranking in the positive region for nine σ values, but falling into the boundary region at σ = 0.05. Sensitivity and comparison analyses were conducted to evaluate the robustness and stability of the methodology.},
  archive      = {J_CC},
  author       = {Qahtan, Sarah and Mourad, Nahia and Alsattar, H. A. and Zaidan, A. A. and Zaidan, B. B. and Pamucar, Dragan and Simic, Vladimir and Ding, Weiping and Yatim, Khaironi},
  doi          = {10.1007/s12559-025-10432-2},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-26},
  shortjournal = {Cogn. Comput.},
  title        = {Three-way decision approach based on utility and dynamic localization transformational procedures within a circular q-rung orthopair fuzzy set for ranking and grading large language models},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A communication-efficient distributed frank-wolfe online
algorithm with an event-triggered mechanism. <em>CC</em>,
<em>17</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s12559-025-10438-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed learning is an effective method for solving large-scale cognitively inspired online machine learning problems. However, frequent communications between nodes lead to expensive communication burden. Meanwhile, projection operations because of the constraints in decision variables cause a lot of computational cost. In order to address the above problems, this paper presents a communication-efficient distributed Frank-Wolfe online optimization method, which integrates the event-triggered mechanism into the distributed projection-free online optimization algorithm. Furthermore, we provide a rigorous theoretical analysis for the regret of the proposed algorithm. Finally, we verify the performance of the proposed method through a variety of numerical experiments. The theoretical results show that the regret reaches a sublinear growth of iterations for convex objective functions. The proposed algorithm outperforms the baseline methods on two datasets. Our research indicates that, in addition to reducing computational overhead, the event-triggered scheme has the potential to enhance the communication efficiency of distributed network system.},
  archive      = {J_CC},
  author       = {Gao, Huimin and Liu, Muhua and Ji, Zhihang and Zheng, Ruijuan and Wu, Qingtao},
  doi          = {10.1007/s12559-025-10438-w},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Cogn. Comput.},
  title        = {A communication-efficient distributed frank-wolfe online algorithm with an event-triggered mechanism},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online signature watermarking in the transform domain.
<em>CC</em>, <em>17</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s12559-025-10436-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing reliance on digital signatures for secure authentication and verification necessitates advanced watermarking techniques to protect signature integrity. Transform-domain methods, including the discrete cosine transform (DCT) and the discrete wavelet transform (DWT), are proposed for their potential to balance robustness, imperceptibility, and recognition accuracy in online signature biometrics. This study explores multi-bit watermarking approaches applied to online handwritten signatures using the MCYT signature database. We investigate the effects of embedding multiple bits per sample with adjustable watermark strength ( $$\alpha $$ ) in the DCT and DWT domains. The trade-offs between signal distortion, watermark extraction accuracy, and biometric recognition rates are systematically evaluated. Experimental results reveal that while increasing $$\alpha $$ enhances watermark robustness, it also leads to perceptible distortions in signature samples. We identify the minimum $$\alpha $$ thresholds required for error-free watermark extraction and analyze their impact on identification and verification performance. The proposed multi-bit embedding strategy in the DCT domain demonstrates a viable compromise between robustness and imperceptibility, maintaining acceptable biometric recognition rates. Transform-domain watermarking techniques provide a promising solution for secure and robust online signature biometrics. This study highlights the feasibility of incorporating multi-bit watermarking schemes with adjustable strength into online signature systems, enhancing security while preserving recognition accuracy.},
  archive      = {J_CC},
  author       = {Faundez-Zanuy, Marcos},
  doi          = {10.1007/s12559-025-10436-y},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {Online signature watermarking in the transform domain},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rain streak removal using improved generative adversarial
network with loss function optimization. <em>CC</em>, <em>17</em>(2),
1–15. (<a href="https://doi.org/10.1007/s12559-025-10435-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rain is a typical meteorological phenomenon that can significantly impair the functionality of outdoor computer vision systems, including autonomous navigation and surveillance. Depending on how far away the streaks are from the camera, they may appear differently in the images. One input image serves as the foundation for the majority of current rain removal techniques. However, estimating a trustworthy depth map for rain removal is challenging on a single image. To overcome these challenges, this research introduces a novel approach for rain streak removal utilizing generative adversarial networks (GANs). Leveraging the discriminative power of GANs, the proposed technique effectively distinguishes between rain streaks and clean image content, resulting in the generation of realistic, rain-free images. The workflow involves initial image pre-processing using a cross-guided bilateral filter for detail layer extraction. The rain streak removal is then executed through an improved de-rain GAN (DR_GAN), where the generator module is replaced with a dense bidirectional network with self-attention (Attn_DBNet). This integration incorporates DenseNet-121, bidirectional gated recurrent unit (BiGRU), and self-attention mechanisms, enhancing the overall performance of the rain streak removal process. The research further introduces chaotic logistic gazelle optimization (CL-G) for optimizing the loss function, addressing local optimal trapping issues through the incorporation of chaotic logistic mapping. With notable gains in the metrics, comparative analysis shows that the proposed method is superior to the state-of-the-art approaches. These successes demonstrate the usefulness and superiority of the proposed GAN-based rain streak removal method over dual CNN, QSAM-Net, and MGPDNet approaches, with significant percentage advantages over these networks.},
  archive      = {J_CC},
  author       = {R, Prabha and R, Suma and Babu D, Suresh and Saila, S},
  doi          = {10.1007/s12559-025-10435-z},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Cogn. Comput.},
  title        = {Rain streak removal using improved generative adversarial network with loss function optimization},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). T-norms and t-conorms of symmetrical linear orthopair fuzzy
sets and their cognitive applications in multiple-criteria
decision-making. <em>CC</em>, <em>17</em>(2), 1–29. (<a
href="https://doi.org/10.1007/s12559-025-10439-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orthopair fuzzy sets (OFSs) generally include q-rung orthopair fuzzy sets (q-ROFSs) and symmetrical linear orthopair fuzzy sets (SLOFSs), and the latter two models have a common element: intuitionistic fuzzy sets (IFSs). T-norms, t-conorms, and multiple-criteria decision-making (MCDM) are applied to q-ROFSs, but they have not been applied to SLOFSs. These valuable parts of SLOFSs are investigated by extending and simulating relevant results in IFSs, and their operational connections to addition and scalar multiplication are addressed in detail. For SLOFSs, axiomatic definitions, general properties, and concrete constructions for t-norms and t-conorms are first given. Then, special types of t-norms and t-conorms are used to motivate the addition and scalar multiplication operations, and related properties of the operations are obtained. Finally, addition and scalar multiplication are linearly combined with aggregation, and a relevant technique for order preference by similarity to an ideal solution (TOPSIS) method is designed for decision cognition. In this way, a new MCDM method based on SLOFSs is established, and its high reliability is validated by comparing the corresponding method based on q-ROFSs in two practical examples. This study advances work on SLOFSs and linearly extends IFS results, thus enriching OFSs, especially for cognitive computations and applications.},
  archive      = {J_CC},
  author       = {Gao, Shan and Zhang, Xianyong and Mo, Zhiwen},
  doi          = {10.1007/s12559-025-10439-9},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Cogn. Comput.},
  title        = {T-norms and T-conorms of symmetrical linear orthopair fuzzy sets and their cognitive applications in multiple-criteria decision-making},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: A novel interpretable graph convolutional
neural network for multimodal brain tumor segmentation. <em>CC</em>,
<em>17</em>(2), 1. (<a
href="https://doi.org/10.1007/s12559-025-10440-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Choudhry, Imran Arshad and Iqbal, Saeed and Alhussein, Musaed and Aurangzeb, Khursheed and Qureshi, Adnan N. and Hussain, Amir},
  doi          = {10.1007/s12559-025-10440-2},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1},
  shortjournal = {Cogn. Comput.},
  title        = {Correction to: A novel interpretable graph convolutional neural network for multimodal brain tumor segmentation},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-criteria group decision-making using complex p,
q-quasirung orthopair fuzzy sets: Application in the selection of
renewable energy projects for investments. <em>CC</em>, <em>17</em>(2),
1–23. (<a href="https://doi.org/10.1007/s12559-025-10424-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the hesitation inherent in decision-making models is a significant hurdle for experts. The p, q-quasirung fuzzy set (p, q-QOFS) is a new development in fuzzy set theory that plays a vital role in addressing these challenges. This article integrates the notions of p, q-QOFSs and complex fuzzy sets (CFSs) to introduce complex p, q-quasirung orthopair fuzzy sets (Cp,qQOFSs) and outline their basic principles. The Cp,qQOFSs expend the range of membership and non-membership degree of p, q-QOFS from real numbers to encompass complex unit disc values. In the first phase, some basic operational laws and their properties are defined. Future, we will use these operational laws to define some aggregation operators such as complex p, q-quasirung orthopair fuzzy weighted averaging and complex p, q-quasirung orthopair fuzzy weighted geometric operators to aggregated complex p, q-quasirung orthopair fuzzy information. Based on these aggregation operators, a new multi-attribute group decision-making (MCGDM) approach is constructed to handle real-life complex decision-making problems. Moreover, the weights of the criteria are calculated using the entropy method. An illustrative numerical example showcasing the proposed MCGDM method has been provided, focusing on renewable energy investments with seven alternatives and five criteria. Additionally, we conduct the sensitivity analysis to demonstrate the impact of parameters p and q over aggregated results. Lastly, the proposed approach is compared with existing methods to highlight its superiority and flexibility.},
  archive      = {J_CC},
  author       = {Rahim, Muhammad and Bajri, Sanaa Ahmed and Alqahtani, Haifa and Alhabeeb, Somayah Abdualziz and Khalifa, Hamiden Abd El-Wahed},
  doi          = {10.1007/s12559-025-10424-2},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-criteria group decision-making using complex p, q-quasirung orthopair fuzzy sets: Application in the selection of renewable energy projects for investments},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medivision: Empowering colorectal cancer diagnosis and tumor
localization through supervised learning classifications and grad-CAM
visualization of medical colonoscopy images. <em>CC</em>,
<em>17</em>(2), 1–39. (<a
href="https://doi.org/10.1007/s12559-025-10433-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medivision is a modern diagnostic system that has been developed to improve colorectal cancer detection.  By applying deep learning acquisitions, including convolutional neural networks, Gray-Level Co-occurrence Matrix feature extraction, and visualization with Grad-CAM. After developing the Medivision system, several colonoscopy image datasets were used for evaluating a number of state-of-the-art deep CNN architectures, such as ResNet50, VGG16, VGG19, and DenseNet201—namely, CVC Clinic DB, Kvasir2, and Hyper Kvasir, however, through exhaustive model comparisons with integrated CNNs DEV-22 and RV-22. By the incorporation of GLCM feature extraction, textual analysis has become enhanced in the capturing of some critical features within an image that enhances model sensitivity in the detection of subtle variation within colorectal polyps. Grad-CAM visualizations enhance interpretability by enabling clinicians to attribute diagnostically important regions and insight into the model’s process of decision-making, incorporated with cloud storage.  This work confirmed the stability and reliability of VGG16 in different conditions of image shooting. Among these, the best performances for all datasets were obtained by the model VGG16, confirming its consistency and robustness in varying conditions of image acquisition. On the CVC Clinic DB, VGG16 assured a training accuracy of 99.22% and a testing accuracy of 96.12%. The model, when trained on the Kvasir2 dataset, achieved an accuracy of 96.56% during training and 94.25% when testing, while on the Hyper Kvasir dataset, the model supported training accuracy of 95.19% and a testing accuracy of 98.87%. Apart from that, VGG16 also showed a good localization capability for the average IoU of 0.78 on CVC Clinic DB, 0.79 on Kvasir2, and 0.77 on Hyper Kvasir, indicating its precision in identifying polyp regions. It also tested the performance of integrated CNN models DEV-22 and RV-22 in complex multi-dataset scenarios. DEV-22 gave the best-performing integrated model against test accuracies of 97.86% against CVC Clinic DB, 89.37% against Kvasir2, and 76.08% against Hyper Kvasir, while RV-22 resulted in relatively poor performance across these datasets.This indicates that DEV-22 might be much better suited for colorectal cancer detection tasks whenever multiple datasets are concerned. The high testing accuracy and precise localization capabilities of VGG16 and DEV-22 show their robustness within the Medivision system for delivering appropriate clinically relevant returns on colorectal cancer screening across all three datasets.  Medivision enables real-time analysis in an accessible and efficient way for healthcare providers. This paper presents the clinical relevance of this system in enhancing diagnostic accuracy and interpretation for colorectal cancer screening workflows. It represents a state-of-the-art integration of high-performance deep CNN models, GLCM, and Grad-CAM for accurate, interpretable, and actionable outcomes in the diagnosis of colorectal cancer, by representing one great bound in AI-mediated medical diagnosis.},
  archive      = {J_CC},
  author       = {Raju, Akella S. Narasimha and Venkatesh, K and Gatla, Ranjith Kumar and Hussain, Shaik Jakeer and Polamuri, Subba Rao},
  doi          = {10.1007/s12559-025-10433-1},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-39},
  shortjournal = {Cogn. Comput.},
  title        = {Medivision: Empowering colorectal cancer diagnosis and tumor localization through supervised learning classifications and grad-CAM visualization of medical colonoscopy images},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-valued neutrosophic distance measure-based
MEREC-RANCOM-WISP for solving sustainable energy storage technology
problem. <em>CC</em>, <em>17</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s12559-025-10437-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy storage technology (EST) is crucial in mitigating the environmental impact of energy storage and reducing carbon footprints. It is a vital component of renewable energy sources and decarbonization of world energy structures. The selection of a suitable EST depends on multiple aspects of sustainability; thus, the decision-making methods are a more proper way to systematically deal with this problem. Uncertainty is commonly occurred in the selection of a suitable EST. As a generalization of a fuzzy set, a single-valued neutrosophic set (SVNS) has been demonstrated as a useful framework for handling indeterminate, inconsistent, and uncertain data of realistic decision-making situations. Considering the idea of SVNS, this paper develops a hybrid multi-criteria group decision-making (MCGDM) approach to assess and prioritize ESTs over different qualitative and quantitative criteria. The proposed “simple weighted sum product (WISP)” method combines the Hellinger distance measure-based decision experts’ weighting tool and integrated criteria weight-determining model to deal the single-valued neutrosophic information (SVNI)-based MCGDM problems with completely unknown weights of decision experts (DEs) as well as defined criteria. To evade the drawbacks of extent distance measures, we introduce a novel single-valued neutrosophic Hellinger distance measure to compute the degree of discrimination on SVNSs. Some illustrative examples are taken to exemplify the efficiency of developed Hellinger distances over existing ones. Further, the developed Hellinger distance is utilized to derive the weight of DEs. In addition, the criteria weight-determining procedure is given by integrating objective weight through a “method based on the removal effects of criteria (MEREC)” and subjective weight through “ranking comparison (RANCOM)” under SVNI. Based on these models, a combined WISP approach is developed to rank the alternatives on SVNI. The proposed ranking framework is employed in an empirical study of the EST selection problem, which shows its practicality and feasibility. In this study, the evaluation criteria are categorized into technical, environmental, social, economic, and performance dimensions with the DEs’ opinions. Comparative and sensitivity analyses are made to approve the validity and stability of the developed ranking approach. The present study offers valuable insights for choosing multi-criteria EST under an indeterminate, inconsistent, and uncertain environment, which also expands the application scopes of the combined MEREC-SWARA-WISP method.},
  archive      = {J_CC},
  author       = {Mishra, Arunodaya Raj and Pamucar, Dragan and Rani, Pratibha and Hezam, Ibrahim M.},
  doi          = {10.1007/s12559-025-10437-x},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Cogn. Comput.},
  title        = {Single-valued neutrosophic distance measure-based MEREC-RANCOM-WISP for solving sustainable energy storage technology problem},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Curriculum-guided self-supervised representation learning of
dynamic heterogeneous networks. <em>CC</em>, <em>17</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s12559-025-10441-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since most real-world network data include nodes and edges that evolve gradually, an embedding model for dynamic heterogeneous networks is crucial for network analysis. Transformer models have remarkable success in natural language processing but are rarely applied to learning representations of dynamic heterogeneous networks. In this study, we propose a new transformer model (DHG-BERT) that (i) constructs a dataset based on a network curriculum and (ii) includes pre/post-learning through self-supervised learning. Our proposed model learns complex relationships by leveraging an easier understanding of relationships through data reconstruction. Additionally, we use self-supervised learning to learn network structural features and temporal changes in structure and then fine-tune the proposed model by focusing on specific meta-paths by considering domain characteristics or target tasks. We evaluated the quality of the vector representation produced by the proposed transducer model using real bibliographic networks. Our model achieved an average accuracy of 0.94 in predicting research collaboration between researchers, outperforming existing models by a minimum of 0.13 and a maximum of 0.35. As a result, we confirmed that DHG-BERT is an effective transformer model tailored to dynamic heterogeneous network embeddings. Our study highlights the model’s ability to understand complex network relationships and appropriately capture the structural nuances and temporal changes inherent in networks. This study provides future research directions for applying the transformer model to real-world network data and a new approach to analyzing dynamic heterogeneous networks using transformers.},
  archive      = {J_CC},
  author       = {Jung, Namgyu and Camacho, David and Choi, Chang and Lee, O.-Joun},
  doi          = {10.1007/s12559-025-10441-1},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Cogn. Comput.},
  title        = {Curriculum-guided self-supervised representation learning of dynamic heterogeneous networks},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). <span class="math display"><em>A</em><sup>2</sup></span> DM:
Enhancing EEG artifact removal by fusing artifact representation into
the time-frequency domain. <em>CC</em>, <em>17</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s12559-025-10442-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electroencephalogram (EEG) provides essential data for analyzing brain activities. However, artifacts such as electrooculography (EOG) and electromyography (EMG) often interleave with the EEG signals, significantly affecting the quality of EEG signal analysis. The heterogeneous distribution of these artifacts in the time-frequency domain makes it challenging to remove multiple artifacts using a unified model. In this paper, we propose an artifact-aware EEG denoising model, referred to as $$A^2$$ DM, to effectively remove various types of artifacts in a unified manner. We first obtain an artifact representation that indicates the type of artifact from a pre-trained artifact classification model. This artifact representation is then used as prior knowledge, which is fused into the denoising model in the time-frequency domain. This enables the model to become aware of the artifact type and precisely remove artifacts based on their type. Due to the heterogeneous distributions of artifacts in the frequency domain, we introduce a frequency enhancement module that can identify specific types of artifacts based on their representation and remove them using a hard attention mechanism. Additionally, we design a time-domain compensation module to enhance the denoising capability of $$A^2$$ DM by compensating for potential losses of global information. Comprehensive experiments demonstrate that $$A^2$$ DM significantly outperforms the novel CNN in denoising EEG signals, showing a notable 12% improvement in correlation coefficient (CC) metrics. This work demonstrates that artifact representation can be used in artifact removal models to effectively remove multiple types of artifacts.},
  archive      = {J_CC},
  author       = {Li, Haoran and Feng, Fan and Kang, Jiarong and Zhang, Jin and Gong, Xiaoli and Lu, Tingjuan and Li, Shuang and Sun, Zhe and Solé-Casals, Jordi},
  doi          = {10.1007/s12559-025-10442-0},
  journal      = {Cognitive Computation},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Cogn. Comput.},
  title        = {$$A^{2}$$ DM: Enhancing EEG artifact removal by fusing artifact representation into the time-frequency domain},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cis---20">CIS - 20</h2>
<ul>
<li><details>
<summary>
(2025). Mcaaco: A multi-objective strategy heuristic search
algorithm for solving capacitated vehicle routing problems.
<em>CIS</em>, <em>11</em>(5), 1–21. (<a
href="https://doi.org/10.1007/s40747-025-01826-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle routing is a critical issue in the logistics and distribution industry. In practical applications, optimizing vehicle capacity allocation can significantly improve route optimization performance and service coverage. However, solving this problem remains challenging due to the complex constraints involved. Therefore, to address this real-world challenge, a novel intelligent optimization method, multi-objective capacity adjustment ant colony optimization algorithm (MCAACO), is proposed, which integrates advanced multi-objective optimization strategies, including capacity adjustment operators and crossover operators. Combined with pheromone updating and Pareto front-end optimization, the method effectively resolves the conflict between vehicle capacity constraints and multi-objective optimization. To further enhance the algorithm’s performance, dynamic pheromone updating mechanisms and elite individual retention strategies are proposed. Additionally, an adaptive parameter adjustment strategy is designed to balance global search and local exploitation capabilities. Through a series of experiments, it is demonstrated that compared to multi-objective particle swarm optimization (MOPSO), non-dominated sorting genetic algorithm II (NSGA-II), and multi-objective sparrow search algorithm (MOSSA), the proposed MCAACO significantly reduces travel paths by an average of 3.05% and increases vehicle service coverage by an average of 3.2%, while satisfying vehicle capacity constraints. Experimental indicators demonstrate that the breakthrough algorithm significantly addresses the issues of high costs and low efficiency prevalent in the practical logistics distribution industry.},
  archive      = {J_CIS},
  author       = {Chen, Yanling and Wei, Jingyi and Luo, Tao and Zhou, Jie},
  doi          = {10.1007/s40747-025-01826-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-21},
  shortjournal = {Complex Intell. Syst.},
  title        = {Mcaaco: A multi-objective strategy heuristic search algorithm for solving capacitated vehicle routing problems},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heuristic-assisted deep reinforcement learning algorithm
for flexible job shop scheduling with transport constraints.
<em>CIS</em>, <em>11</em>(5), 1–21. (<a
href="https://doi.org/10.1007/s40747-025-01828-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated guided vehicles (AGVs) are widely used for transportation in flexible job shop (FJS) systems, and their transportation task scheduling has the same substantial impact on production efficiency as machine scheduling does. However, traditional FJS scheduling methods often prioritize job sequencing and machine selection while ignoring the impact of AGV transportation, resulting in suboptimal scheduling solutions and even difficulties in implementation. To address this issue, this paper formulates a cooperative scheduling model by introducing the AGV scheduling problem into the classical FJS scheduling problem, abbreviated as the FJS-AGV problem, with the objective of minimizing the makespan. With respect to the FJS-AGV problem, a heuristic-assisted deep Q-network (HA-DQN) algorithm is proposed, which leverages heuristic rules to enable the decision agent to perform multiple actions at each decision point, which includes determining the responses to the following questions: Which operation should be processed next? On which machine? By which AGV? This decision mechanism enables the agent to make more informed decisions, leading to improved performance and resource allocation in the FJS-AGV system. The practicability of the proposed FJS-AGV model and the efficiency of the HA-DQN algorithm in solving the FJS-AGV problem are verified through various international benchmarks. Specifically, when solving instances in a large benchmark, the HA-DQN algorithm yields a significant 12.63% reduction in makespan compared with that when traditional heuristics are employed.},
  archive      = {J_CIS},
  author       = {Dong, Xiaoting and Wan, Guangxi and Zeng, Peng},
  doi          = {10.1007/s40747-025-01828-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-21},
  shortjournal = {Complex Intell. Syst.},
  title        = {A heuristic-assisted deep reinforcement learning algorithm for flexible job shop scheduling with transport constraints},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-attention-based graph transformation learning for
anomaly detection in multivariate time series. <em>CIS</em>,
<em>11</em>(5), 1–13. (<a
href="https://doi.org/10.1007/s40747-025-01839-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series anomaly detection has widely applications in many fields such as finance, power, and industry. Recently, Graph Neural Network (GNN) have achieved great success in this task due to their powerful ability of modeling multivariate relationships. However, most existing methods employ shallow networks with only two layers, resulting in restricted node information transfer range and limited sensing field. In this paper, we propose a self-attention based graph transformation learning (AT-GTL) method to solve this problem. AT-GTL uses a global self-attention graph pooling (GATP) module to aggregate all node features to obtain global features. Then, a graph transformation learning pipeline is constructed based on neural transformation learning, and a triplet contrastive loss (TCL) is constructed to optimize the global feature extraction networks using potential features from multi-viewpoints. Extensive experiments on three real-world datasets demonstrate that our method can effectively aggregate global graph features and detect anomalies, providing a new transformation learning solution for multivariate time series anomaly detection.},
  archive      = {J_CIS},
  author       = {Wang, Qiushi and Zhu, Yueming and Sun, Zhicheng and Li, Dong and Ma, Yunbin},
  doi          = {10.1007/s40747-025-01839-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-13},
  shortjournal = {Complex Intell. Syst.},
  title        = {Self-attention-based graph transformation learning for anomaly detection in multivariate time series},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight vision transformer with weighted global
average pooling: Implications for IoMT applications. <em>CIS</em>,
<em>11</em>(5), 1–19. (<a
href="https://doi.org/10.1007/s40747-025-01842-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformers (ViTs) have garnered significant interest for analysing medical images in Internet of Medical Things (IoMT) systems due to their ability to capture global context. However, deploying ViTs in resource-constrained IoMT environments requires addressing the challenge of adapting these computationally intensive models to meet device limitations while maintaining efficiency. To tackle this issue, we introduce LightAMViT, a lightweight attention mechanism-enhanced ViT, which incorporates K-means clustering layers to reduce the computational complexity of the self-attention matrix, along with an optimized global average pooling layer that leverages all stacked attention block outputs, each weighted by learnable parameters. Additionally, it employs an adaptive learning strategy that facilitates faster convergence by dynamically adjusting the learning rate. We evaluate the proposed technique on two medical image datasets: BUSI and ISIC2020. Our model outperforms conventional CNNs and demonstrates competitive performance compared to the original ViTs, showcasing improvements in both accuracy and computational efficiency. These findings indicate the model’s robustness and generalisation across various medical image analysis tasks, thereby enhancing the applicability of ViTs in resource-limited IoMT devices.},
  archive      = {J_CIS},
  author       = {Dong, Huiyao and Kotenko, Igor and Dong, Shimin},
  doi          = {10.1007/s40747-025-01842-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-19},
  shortjournal = {Complex Intell. Syst.},
  title        = {A lightweight vision transformer with weighted global average pooling: Implications for IoMT applications},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generative model-based coevolutionary training framework
for noise-tolerant softsensors in wastewater treatment processes.
<em>CIS</em>, <em>11</em>(5), 1–25. (<a
href="https://doi.org/10.1007/s40747-025-01845-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven softsensors have gained widespread application in process monitoring and quality prediction, offering advantages over traditional measurement techniques by mitigating their limitations and costs. However, the effectiveness of softsensor models is often hindered by noise in data acquisition, posing significant challenges for model training. To tackle this issue, this study introduces a coevolutionary training framework based on generative models to mitigate the impact of noise corruption. The framework employs a denoising variational autoencoder to extract global and local features from auxiliary data, enhancing population distribution and constructing a deep nonlinear representation to counter noise effects. Additionally, a dual population coding method inspired by evolutionary computation is proposed, enabling the coevolution of network parameters and structure. The proposed multiobjective evolutionary network optimization with denoising strategy (MENO-D) demonstrated exceptional performance in various experiments. On a water quality prediction dataset, the MENO-D-trained softsensor model achieved the lowest prediction error under 10% and 20% noise interference. Further, on the WWTP benchmark dataset across three weather conditions, MENO-D-trained softsensor model exhibited competitive accuracy and robustness.},
  archive      = {J_CIS},
  author       = {Peng, Yu and Li, Erchao},
  doi          = {10.1007/s40747-025-01845-5},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-25},
  shortjournal = {Complex Intell. Syst.},
  title        = {A generative model-based coevolutionary training framework for noise-tolerant softsensors in wastewater treatment processes},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TransRNetFuse: A highly accurate and precise boundary
FCN-transformer feature integration for medical image segmentation.
<em>CIS</em>, <em>11</em>(5), 1–19. (<a
href="https://doi.org/10.1007/s40747-025-01847-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging examinations are integral to the diagnosis and treatment of cancer. Nevertheless, the intricate nature of medical images frequently necessitates that physicians follow time-consuming and potentially fallible diagnostic procedures. In response to these challenges, deep learning-based image segmentation technology has emerged as a potent instrument for aiding physicians in navigating diagnostic complexities by extracting pivotal information from extensive sets of medical images. Nonetheless, the majority of existing models prioritize overall high accuracy, often overlooking the sensitivity to local salient features and the precision of segmentation boundaries. This oversight limits the full realization of the practical utility of deep learning models in clinical settings. This study introduces a novel pathological image segmentation method, termed TransRNetFuse, which incorporates stepwise feature aggregation and a residual fully convolutional network architecture. The objective of this method is to address the issues associated with the extraction of local key features and the accurate delineation of boundaries in medical image segmentation. The proposed model achieves enhanced overall performance by merging a fully convolutional network branch with a Transformer branch and utilizing residual blocks along with dense U-net skip connections. It prevents attentional dispersion by emphasizing local features, and further employs an automatic augmentation strategy to identify the optimal data augmentation scheme, which is particularly advantageous for small-sample datasets. Furthermore, this paper introduces an edge enhancement loss function to enhance the model&#39;s sensitivity to tumor boundaries. A dataset comprising 2164 pathological images, provided by Hunan Medical University General Hospital, was utilized for model training. The experimental results indicate that the proposed method outperforms existing techniques, such as MedT, in terms of both accuracy and edge precision, thereby demonstrating its significant potential for application in the medical field. Code: https://github.com/GFF1228/-TransRNetFuse.git .},
  archive      = {J_CIS},
  author       = {Li, Baotian and Zhou, Jing and Gou, Fangfang and Wu, Jia},
  doi          = {10.1007/s40747-025-01847-3},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-19},
  shortjournal = {Complex Intell. Syst.},
  title        = {TransRNetFuse: A highly accurate and precise boundary FCN-transformer feature integration for medical image segmentation},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing cyber defense strategies with discrete
multi-dimensional z-numbers: A multi-attribute decision-making approach.
<em>CIS</em>, <em>11</em>(5), 1–24. (<a
href="https://doi.org/10.1007/s40747-025-01786-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of intelligent technologies and network environments, the efficient and accurate handling of uncertain decision-making information has become an urgent challenge. Traditional methods often struggle to process complex and incomplete information, especially in cyber defense. To address this, we introduce discrete multi-dimensional Z-numbers (MZs) as a mathematical tool for modeling uncertainty and reliability in network defense decisions. This paper proposes a synthesis method for MZs, enabling the integration of multi-source information while considering both uncertainty and reliability. By leveraging a hidden probability model, we extend MZs into multi-dimensional Z+-numbers, enhancing their expressiveness in handling uncertainty. Furthermore, we define utility functions based on MZs and develop a multi-attribute group decision-making framework tailored for network defense. This approach offers a novel perspective for designing strategies against highly adaptive and covert cyberattacks. The proposed method is validated through a case study on the network security assessment of an intelligent logistics company. Results demonstrate significant improvements in the accuracy and efficiency of decision-making, highlighting the method’s advantages and broad potential in cyber defense. Beyond logistics, this integrated MZ-based decision framework provides an adaptable and intelligent tool for strengthening network security defenses.},
  archive      = {J_CIS},
  author       = {Yao, Aiting and Chen, Huang and Zhang, Weiqi and Dong, Chengzu and Lu, Meiqu and Mao, Junjun and Liu, Xiao and Li, Xuejun},
  doi          = {10.1007/s40747-025-01786-z},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-24},
  shortjournal = {Complex Intell. Syst.},
  title        = {Enhancing cyber defense strategies with discrete multi-dimensional Z-numbers: A multi-attribute decision-making approach},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffic signal optimization control method based on
attention mechanism updated weights double deep q network. <em>CIS</em>,
<em>11</em>(5), 1–14. (<a
href="https://doi.org/10.1007/s40747-025-01841-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a critical guidance facility for vehicle convergence and diversion in urban traffic networks, the control effect of traffic signals directly affects traffic efficiency and road congestion level. As a mature deep reinforcement learning algorithm, the double deep Q network has shown a significant optimization effect in intelligent traffic signal control research. In this paper, for the feature extraction defects of deep double Q network and the problem of underestimating the evaluation value of actions, we propose an Attention Mechanism Updated Weights Double Deep Q Network (AMUW–DDQN) based on the attention mechanism for the optimal control of traffic signals. The AMUW–DDQN method enhances the perceptual ability of the network by introducing the attention mechanism of Squeeze And Excitation Networks (SENet) to make the neural network pay attention to important state components automatically, and based on the idea that accurate representation of potentially optimal action values is better than the balanced representation of all the action values, it is considered that underestimated actions have a certain probability of being the optimal action and the loss function is weighted to optimize the action values. Simulation experiments were also conducted using the traffic flow data of the intersection of Fengze Street–Tian’an South Road, Fengze District, Quanzhou City, Fujian Province, China. The experimental results show that the method proposed in this paper has the most significant final convergence effect for the same number of iterations, and has better performance in the evaluation indexes such as vehicle queue length and vehicle delay time.},
  archive      = {J_CIS},
  author       = {Zhang, Huizhen and Fang, Zhenwei and Chen, Youqing and Dai, Haotian and Jiang, Qi and Zeng, Xinyan},
  doi          = {10.1007/s40747-025-01841-9},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-14},
  shortjournal = {Complex Intell. Syst.},
  title        = {Traffic signal optimization control method based on attention mechanism updated weights double deep q network},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-based multiple instance learning network with 2D
positional encoding for histopathology image classification.
<em>CIS</em>, <em>11</em>(5), 1–17. (<a
href="https://doi.org/10.1007/s40747-025-01779-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital medical imaging, particularly pathology images, is essential for cancer diagnosis but faces challenges in direct model training due to its super-resolution nature. Although weakly supervised learning has reduced the need for manual annotations, many multiple instance learning (MIL) methods struggle to effectively capture crucial spatial relationships in histopathological images. Existing methods incorporating positional information often overlook nuanced spatial correlations or use positional encoding strategies that do not fully capture the unique spatial dynamics of pathology images. To address this issue, we propose a new framework named TMIL (Transformer-based Multiple Instance Learning Network with 2D positional encoding), which leverages multiple instance learning for weakly supervised classification of histopathological images. TMIL incorporates a 2D positional encoding module, based on the Transformer, to model positional information and explore correlations between instances. Furthermore, TMIL divides histopathological images into pseudo-bags and trains patch-level feature vectors with deep metric learning to enhance classification performance. Finally, the proposed approach is evaluated on a public colorectal adenoma dataset. The experimental results show that TMIL outperforms existing MIL methods, achieving an AUC of 97.28% and an ACC of 95.19%. These findings suggest that TMIL’s integration of deep metric learning and positional encoding offers a promising approach for improving the efficiency and accuracy of pathology image analysis in cancer diagnosis.},
  archive      = {J_CIS},
  author       = {Yang, Bin and Ding, Lei and Li, Jianqiang and Li, Yong and Qu, Guangzhi and Wang, Jingyi and Wang, Qiang and Liu, Bo},
  doi          = {10.1007/s40747-025-01779-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-17},
  shortjournal = {Complex Intell. Syst.},
  title        = {Transformer-based multiple instance learning network with 2D positional encoding for histopathology image classification},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SLPOD: Superclass learning on point cloud object detection.
<em>CIS</em>, <em>11</em>(5), 1–15. (<a
href="https://doi.org/10.1007/s40747-025-01781-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of point cloud object detection, classification tasks emphasize extracting common features to enhance generalization, often at the expense of individual-specific features. This limitation becomes particularly evident when handling intricate datasets like KITTI. Traditional models struggle to adequately capture individual-specific features, resulting in a scattered distribution of samples within the feature space and compromising the precision of object bounding boxes. To tackle this challenge, we introduce SLPOD, a Superclass-based point cloud object detection algorithm. Employing a siamese network structure, SLPOD conducts unsupervised clustering of samples within the same category to enhance the extraction of individual-specific features, thereby improving detection accuracy when confronted with complex datasets. Additionally, our approach integrates strategies such as voxel and point cloud feature fusion, global feature acquisition, and dynamic adjustment of sampling rates based on point sparsity, further enhancing the network’s capability to extract features. Experimental results demonstrate that SLPOD outperforms baseline algorithms in mean Average Precision on both KITTI and Waymo datasets, exhibiting robustness across diverse scenarios.},
  archive      = {J_CIS},
  author       = {Yang, Xiaokang and Zhang, Kai and Feng, Yangyue and Su, Beibei and Cai, Yiming and Zhang, Kaibo and Zhang, Zhiheng},
  doi          = {10.1007/s40747-025-01781-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Complex Intell. Syst.},
  title        = {SLPOD: Superclass learning on point cloud object detection},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reliability centred maintenance-oriented framework for
modelling, evaluating, and optimising complex repairable flow networks.
<em>CIS</em>, <em>11</em>(5), 1–25. (<a
href="https://doi.org/10.1007/s40747-025-01787-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few would argue that maximising the performance of the many flow networks (FNs) that operate for the benefit of our society and the economy is anything but essential. Through seeking to mitigate the risks posed by different asset failure modes, maintenance is critical to minimising disruptions and maximising resilience. Repairable flow network (RFN) optimisation and reliability centred maintenance (RCM) are both used to support asset related decisions in FNs but independently; meaning, attempts to maximise FN performance using RCM are likely to result in suboptimal outcomes. There is limited work bringing RFN optimisation and RCM together to support evaluating maintenance decisions in the context of holistic network level performance (measured in terms of profitability) and in a way that considers the complex structural and topological relationships that exist between process components, equipment components, and failure modes. Hence, this paper addresses this by developing the complex repairable flow network (CRFN) modelling framework with the goal of ensuring RFN optimisation integrates complex process and equipment (including failure modes) component topologies, such that it operates in alignment with the needs of RCM as part of maximising network flow in terms of gross profitability. This was done through the creation of a novel and transdisciplinary multi-layered network-based approach that integrates information from what were termed the facility, process, maintainable item, and failure mode levels. Furthermore, through running simulation experiments on an example CRFN, it is demonstrated that the CRFN modelling framework can be used to evaluate the impact different maintenance strategies have on maximising network flow in terms of gross profitability.},
  archive      = {J_CIS},
  author       = {Kaliszewski, Nicholas and Marian, Romeo and Chahl, Javaan},
  doi          = {10.1007/s40747-025-01787-y},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-25},
  shortjournal = {Complex Intell. Syst.},
  title        = {A reliability centred maintenance-oriented framework for modelling, evaluating, and optimising complex repairable flow networks},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Co-evolutionary algorithm with a region-based diversity
enhancement strategy. <em>CIS</em>, <em>11</em>(5), 1–26. (<a
href="https://doi.org/10.1007/s40747-025-01819-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When addressing constrained multi-objective optimization problems, the presence of complex constraints often results in a non-connected feasible region, segmenting the Pareto front into multiple discrete segments. This fragmentation can significantly limit population diversity. To tackle this issue, we have designed two mechanisms aimed at preserving population diversity and have developed a constrained multi-objective co-evolutionary algorithm (DESCA) based on the framework of a two-population co-evolutionary algorithm. The proposed algorithm consists of two populations: a main population dedicated to exploring the constrained Pareto front and an auxiliary population tasked with exploring the unconstrained Pareto front. To sustain the diversity within both populations, the algorithm dynamically adjusts the genetic operator based on the observed states of the populations. Moreover, when the main population encounters stagnation, a regional mating mechanism is employed between the main population and the auxiliary population, accompanied by a relaxation of the constraints on the main population. Conversely, when the auxiliary population experiences stagnation, a diversity-first individual selection strategy is implemented; this strategy utilizes a regional distribution index to assess individual diversity and mitigates population stagnation by enhancing diversity. The performance of DESCA has been evaluated across 33 benchmark problems and 6 real-world problems. Experimental results demonstrate that DESCA exhibits strong competitiveness compared to seven other typical state-of-the-art algorithms.},
  archive      = {J_CIS},
  author       = {Li, Kangshun and Ruan, RuoLin and Xie, Shumin and Wang, Hui},
  doi          = {10.1007/s40747-025-01819-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-26},
  shortjournal = {Complex Intell. Syst.},
  title        = {Co-evolutionary algorithm with a region-based diversity enhancement strategy},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on knowledge tracing based on learner fatigue
state. <em>CIS</em>, <em>11</em>(5), 1–31. (<a
href="https://doi.org/10.1007/s40747-025-01831-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing aims to predict how learners will perform in future exercises on related concepts and to track changes in their knowledge state. Existing models have not fully considered the physical and mental fatigue that occurs in learners during prolonged learning tasks, which leads to reduced problem-solving ability and affects their learning efficiency and performance. This article proposes Attention-Centric Knowledge Tracing to address the above issues. This method combines the Grit theory to evaluate the learner’s fatigue state and explores the potential impact of learning tasks on the learner’s fatigue state through deep graph convolutional networks. In particular, this article employs a multilayer perceptual network with scaled dot-product attention to process information dynamically, focusing on the critical information the learner needs at a given moment and effectively incorporating it into the knowledge framework. This article compared the fourteen knowledge tracing models in the experiment to the two benchmark data sets. The results indicate that knowledge tracing in the center of attention outperforms the baseline model in predicting learners’ future responses.},
  archive      = {J_CIS},
  author       = {Wang, Haoyu and Wu, Qianxi and Bao, Chengke and Ji, Weidong and Zhou, Guohui},
  doi          = {10.1007/s40747-025-01831-x},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-31},
  shortjournal = {Complex Intell. Syst.},
  title        = {Research on knowledge tracing based on learner fatigue state},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study of enhanced visual perception of marine biology
images based on diffusion-GAN. <em>CIS</em>, <em>11</em>(5), 1–20. (<a
href="https://doi.org/10.1007/s40747-025-01832-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the influence of factors such as the special optical characteristics of water bodies on the perceptual quality of generated images, this paper proposes the DifSG2-CCL model for reducing the special optical characteristics of water bodies and the DPL-SG2 model for introducing perceptual loss. Combining the ideas of cyclic consistency and style migration, this paper builds the Underwater Cycle Consistency Loss (U-CCL) module. The DifSG2-CCL model is based on the method of image reconstruction, which converts the underwater image into the style of the land image to reduce the influence of the water body factors. VGG16 is introduced as a perceptual loss into the DPL-SG2 to enhance the visual perception of the image by feature extraction with different layers and tonal weighting. Furthermore, in addition to the already disclosed SA dataset, a T dataset with a resolution of 256 × 256 in 9.366k sheets is provided in this paper. The experimental results show that DifSG2-CCL and DPL-SG2 can effectively enhance the perceptual quality of the images. The unique underwater image generation of DifSG2-CCL produces excellent results in qualitative analysis and reduces its FID value to 8.97. DPL-SG2 is more outstanding in the training of T dataset, and its FID value is reduced to 5.39. Therefore, the U-CCL and VGG16 can be applied as an innovative approach to enhance visual perception of underwater images. The experimental code with pre-trained models will be published shortly at https://github.com/yff0428/DPL-SG2/tree/main .},
  archive      = {J_CIS},
  author       = {Yao, Feifan and Zhang, Huiying and Gong, Yifei and Zhang, Qinghua and Xiao, Pan},
  doi          = {10.1007/s40747-025-01832-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-20},
  shortjournal = {Complex Intell. Syst.},
  title        = {A study of enhanced visual perception of marine biology images based on diffusion-GAN},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parallel large-scale multiobjective evolutionary algorithm
based on two-space decomposition. <em>CIS</em>, <em>11</em>(5), 1–37.
(<a href="https://doi.org/10.1007/s40747-025-01835-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decomposition is an effective and popular strategy used by evolutionary algorithms to solve multiobjective optimization problems (MOPs). It can reduce the difficulty of directly solving MOPs, increase the diversity of the obtained solutions, and facilitate parallel computing. However, with the increase of the number of decision variables, the performance of multiobjective evolutionary algorithms (MOEAs) often deteriorates sharply. The advantages of the decomposition strategy are not fully exploited when solving such large-scale MOPs (LSMOPs). To this end, this paper proposes a parallel MOEA based on two-space decomposition (TSD) to solve LSMOPs. The main idea of the algorithm is to decompose the objective space and decision space into multiple subspaces, each of which is expected to contain some complete Pareto-optimal solutions, and then use multiple populations to conduct parallel searches in these subspaces. Specifically, the objective space decomposition approach adopts the traditional reference vector-based method, whereas the decision space decomposition approach adopts the proposed method based on a diversity design subspace (DDS). The algorithm uses a message passing interface (MPI) to implement its parallel environment. The experimental results demonstrate the effectiveness of the proposed DDS-based method. Compared with the state-of-the-art MOEAs in solving various benchmark and real-world problems, the proposed algorithm exhibits advantages in terms of general performance and computational efficiency.},
  archive      = {J_CIS},
  author       = {Yin, Feng and Cao, Bin},
  doi          = {10.1007/s40747-025-01835-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-37},
  shortjournal = {Complex Intell. Syst.},
  title        = {A parallel large-scale multiobjective evolutionary algorithm based on two-space decomposition},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing implicit sentiment analysis via knowledge
enhancement and context information. <em>CIS</em>, <em>11</em>(5), 1–15.
(<a href="https://doi.org/10.1007/s40747-025-01840-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis (SA) is a vital research direction in natural language processing (NLP). Compared with the widely-concerned explicit sentiment analysis, implicit sentiment analysis (ISA) is more challenging and rarely studied due to the lack of sentiment words. However, existing implicit sentiment analysis methods are hard to identify implicit sentiment without the support of commonsense and contextual background. To address these limitations, we propose a knowledge-enhanced framework that integrates external knowledge graphs and contextual information for implicit sentiment analysis. We draw an analogy between the word in the target sentence and the knowledge graph entities and propose a retrieving and selecting method to automatically extract helpful knowledge graph entity embedding for implicit sentiment analysis. By introducing external knowledge from the knowledge graph, the proposed approach can extend semantic of implicit sentiment expressions. Then, a knowledge fusion module based on dynamic Coattention has been designed to integrate the extracted helpful knowledge with the context representation, effectively enriching the semantic representation of texts. The experiments on two implicit sentiment analysis datasets and two explicit sentiment analysis datasets prove that our model can achieve better performances in text sentiment analysis by fully utilizing external commonsense knowledge and context information.},
  archive      = {J_CIS},
  author       = {Mao, Yanying and Liu, Qun and Zhang, Yu},
  doi          = {10.1007/s40747-025-01840-w},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-15},
  shortjournal = {Complex Intell. Syst.},
  title        = {Enhancing implicit sentiment analysis via knowledge enhancement and context information},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge graph-based entity alignment with unified
representation for auditing. <em>CIS</em>, <em>11</em>(5), 1–12. (<a
href="https://doi.org/10.1007/s40747-025-01843-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Auditing is facilitated by audit knowledge graphs, while the biggest challenge in constructing an audit knowledge graph is entity alignment. Entity alignment involves linking entity pairs with the same real-world identity and aims to integrate heterogeneous knowledge across different knowledge graphs. However, most existing works do not effectively combine both attribute and relation representations into a unified framework for entity alignment, which is essential to link entities within an audit knowledge graph accurately. In this study, we propose a knowledge graph-based entity alignment approach with multi-attribute and weighted-relation fusion (KG-Marfia) for intelligent auditing. Our proposed KG-Marfia first extracts entity representations by addressing the imbalance of attributes and relations, and then designs a stacked graph convolutional network as an encoder to fuse attribute and relation information, learning unified representations for entities. In particular, we adopt an SVM-based classifier for the alignment task in intelligent auditing. Experiments conducted on two public datasets, as well as three audit datasets, demonstrate that our KG-Marfia outperforms state-of-the-art entity alignment methods.},
  archive      = {J_CIS},
  author       = {Zhou, Youhua and Yan, Xueming and Huang, Han and Hao, Zhifeng and Zhu, Haofeng and Liu, Fangqing},
  doi          = {10.1007/s40747-025-01843-7},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-12},
  shortjournal = {Complex Intell. Syst.},
  title        = {Knowledge graph-based entity alignment with unified representation for auditing},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The opinion dynamics model for group decision making with
probabilistic uncertain linguistic information. <em>CIS</em>,
<em>11</em>(5), 1–22. (<a
href="https://doi.org/10.1007/s40747-025-01844-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-criteria group decision making (MCGDM) is the important part in decision-making process, which has been used in many industries. Coordinating differing opinions and ultimately reaching group consensus in a group decision-making process has become an important area of research. This paper uses probabilistic uncertain linguistic term sets (PULTSs) to express the uncertainty of evaluation information, and proposes a group consensus reaching method based on the opinion dynamics model which exhaustively considers how decision-makers’ (DMs) viewpoints can influence each other and evolve over time in MCGDM environments. First, we gathers the group’s preference information regarding the alternatives and their stubbornness to peer influence. Next, an influence matrix is determined based on the authority index of the DMs, and a probabilistic uncertain linguistic Friedkin–Johnsen model (PUL-FJ) is constructed. Then, a group consensus reaching method based on the PUL-Friedkin-Johnsen model is proposed to address the feedback mechanism in the consensus-reaching process (CRP). Finally, we proposes a novel approach for ranking. To better achieve group decision-making, we constructs an improved PUL similarity measure that based on the Wasserstein distance. Additionally, this paper proposes a new approach for expert weight, resulting in a comprehensive expert weight that balances individual expertise of the different criteria and group consensus. In the end, an example is provided, and the method’s feasibility is validated through sensitivity analysis and comparative analysis.},
  archive      = {J_CIS},
  author       = {Fan, Jianping and Jin, Zhuxuan and Wu, Meiqin},
  doi          = {10.1007/s40747-025-01844-6},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-22},
  shortjournal = {Complex Intell. Syst.},
  title        = {The opinion dynamics model for group decision making with probabilistic uncertain linguistic information},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An exploration-enhanced hybrid algorithm based on regularity
evolution for multi-objective multi-UAV 3-d path planning. <em>CIS</em>,
<em>11</em>(5), 1–20. (<a
href="https://doi.org/10.1007/s40747-025-01846-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning poses a complex optimization challenge essential for the safe operation and successful mission execution of unmanned aerial vehicles (UAVs). Developing objectives, constraints, and decision-making processes for three-dimensional path planning involving multiple UAVs presents substantial challenges within the multi-objective optimization community. Traditional modeling approaches primarily aim to minimize path length and collision risks, often overlooking the need for a quantitative assessment of communication quality among UAVs. This neglect causes an inadequate representation of their true cooperative capabilities. In addition, there is difficulty in achieving an optimal balance between convergence, diversity, and feasibility. Therefore, this study introduces a bi-objective, three-dimensional path planning model specifically designed for UAVs. This model features an objective function that quantitatively evaluates inter-UAV communication quality throughout their flights. To solve this problem, this study proposes the dual-population regularity evolution algorithm (DPREA), which incorporates an auto-switching regularity evolutionary reproduction operator known as autoRE. It conducts extensive experiments across six testing suites and three path-planning simulation cases to validate the effectiveness of DPREA. The simulation results showed that its performance in addressing constrained multi-objective problems is significantly superior or at least comparable to that of state-of-the-art algorithms in most instances.},
  archive      = {J_CIS},
  author       = {Bai, Zhenzu and Zhou, Haiyin and Wei, Juhui and Zhou, Xuanying and Ning, Yida and Wang, Jiongqi},
  doi          = {10.1007/s40747-025-01846-4},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1-20},
  shortjournal = {Complex Intell. Syst.},
  title        = {An exploration-enhanced hybrid algorithm based on regularity evolution for multi-objective multi-UAV 3-D path planning},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Edge-centric optimization: A novel strategy
for minimizing information loss in graph-to-text generation.
<em>CIS</em>, <em>11</em>(5), 1. (<a
href="https://doi.org/10.1007/s40747-025-01850-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CIS},
  author       = {Zheng, Yao and Li, Jingyuan and Cen, Jianhe and Sun, Shiqi and Yin, Dahu and Wang, Yuanzhuo},
  doi          = {10.1007/s40747-025-01850-8},
  journal      = {Complex &amp; Intelligent Systems},
  month        = {5},
  number       = {5},
  pages        = {1},
  shortjournal = {Complex Intell. Syst.},
  title        = {Correction to: edge-centric optimization: a novel strategy for minimizing information loss in graph-to-text generation},
  volume       = {11},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cms---8">CMS - 8</h2>
<ul>
<li><details>
<summary>
(2025). Additive hazards regression for misclassified current status
data. <em>CMS</em>, <em>13</em>(2), 507–526. (<a
href="https://doi.org/10.1007/s40304-023-00335-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss regression analysis of current status data with the additive hazards model when the failure status may suffer misclassification. Such data occur commonly in many scientific fields involving the diagnosis test with imperfect sensitivity and specificity. In particular, we consider the situation where the sensitivity and specificity are known and propose a nonparametric maximum likelihood approach. For the implementation of the method, a novel EM algorithm is developed, and the asymptotic properties of the resulting estimators are established. Furthermore, the estimated regression parameters are shown to be semiparametrically efficient. We demonstrate the empirical performance of the proposed methodology in a simulation study and show its substantial advantages over the naive method. Also an application to a motivated study on chlamydia is provided.},
  archive      = {J_CMS},
  author       = {Wang, Wenshan and Zhao, Shishun and Li, Shuwei and Sun, Jianguo},
  doi          = {10.1007/s40304-023-00335-9},
  journal      = {Communications in Mathematics and Statistics},
  month        = {4},
  number       = {2},
  pages        = {507-526},
  shortjournal = {Commun. Math. Stat.},
  title        = {Additive hazards regression for misclassified current status data},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symbolic treatment of trigonometric parametrizations: The
general unirational case and applications. <em>CMS</em>, <em>13</em>(2),
481–505. (<a href="https://doi.org/10.1007/s40304-023-00334-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider symbolic (hybrid trigonometric) parametrizations defined as tuples of real rational expressions involving circular and hyperbolic trigonometric functions as well as monomials, with the restriction that variables in each block of functions are different. We prove that the varieties parametrizable in this way are exactly the class of real unirational varieties of any dimension. In addition, we provide symbolic algorithms to implicitize and to convert a hybrid trigonometric parametrization into a unirational one, and vice versa. We illustrate by some examples the applicability of having these different types of parametrizations, namely, hybrid trigonometric and unirational.},
  archive      = {J_CMS},
  author       = {Lastra, Alberto and Sendra, Juan Rafael and Sendra, Juana},
  doi          = {10.1007/s40304-023-00334-w},
  journal      = {Communications in Mathematics and Statistics},
  month        = {4},
  number       = {2},
  pages        = {481-505},
  shortjournal = {Commun. Math. Stat.},
  title        = {Symbolic treatment of trigonometric parametrizations: The general unirational case and applications},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On construction of mappable nearly orthogonal arrays with
column-orthogonality. <em>CMS</em>, <em>13</em>(2), 455–480. (<a
href="https://doi.org/10.1007/s40304-023-00333-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For designs of computer experiments, two important and desirable properties are projection uniformity and column-orthogonality. However, it is always a challenging task to construct designs with both properties. This paper constructs a series of designs which possess both (near) column-orthogonality and projection uniformity, called (nearly) column-orthogonal mappable nearly orthogonal arrays (MNOAs). Furthermore, we enhance the MNOAs’ projection uniformity on any one dimension by using the constructed (nearly) column-orthogonal MNOAs and rotation matrices. Compared with the existing results (such as Sun and Tang in J Am Stat Assoc 112:683–689, 2017), the newly constructed designs are able to accommodate more design columns and have a much better projection uniformity, for the same run sizes.},
  archive      = {J_CMS},
  author       = {Liu, Haiyan and Sun, Fasheng and Lin, Dennis K. J. and Liu, Min-Qian},
  doi          = {10.1007/s40304-023-00333-x},
  journal      = {Communications in Mathematics and Statistics},
  month        = {4},
  number       = {2},
  pages        = {455-480},
  shortjournal = {Commun. Math. Stat.},
  title        = {On construction of mappable nearly orthogonal arrays with column-orthogonality},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A flexible model for time series of counts with
overdispersion or underdispersion, zero-inflation and heavy-tailedness.
<em>CMS</em>, <em>13</em>(2), 431–454. (<a
href="https://doi.org/10.1007/s40304-022-00327-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series of counts observed in practice often exhibit overdispersion or underdispersion, zero inflation and even heavy-tailedness (the tail probabilities are non-negligible or decrease very slowly). In this article, we propose a more flexible integer-valued GARCH model based on the generalized Conway–Maxwell–Poisson distribution to model time series of counts, which offers a unified framework to deal with overdispersed or underdispersed, zero-inflated and heavy-tailed time series of counts. This distribution generalizes the Conway–Maxwell–Poisson distribution by adding a parameter, which plays the role of controlling the length of the tail. We investigate basic properties of the proposed model and obtain estimators of parameters via the conditional maximum likelihood method. The numerical results with both simulated and real data confirm the good performance of the proposed model.},
  archive      = {J_CMS},
  author       = {Qian, Lianyong and Zhu, Fukang},
  doi          = {10.1007/s40304-022-00327-1},
  journal      = {Communications in Mathematics and Statistics},
  month        = {4},
  number       = {2},
  pages        = {431-454},
  shortjournal = {Commun. Math. Stat.},
  title        = {A flexible model for time series of counts with overdispersion or underdispersion, zero-inflation and heavy-tailedness},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Isogeometric analysis using basis functions of splines
spaces over hierarchical t-meshes with high level differences.
<em>CMS</em>, <em>13</em>(2), 403–430. (<a
href="https://doi.org/10.1007/s40304-022-00324-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By using the method of space mapping, basis functions of biquadratic polynomial spline spaces over the hierarchical T-meshes without limitation for level difference can be constructed. In this paper, the basis functions defined over hierarchical T-meshes with high level differences are adopted for the application in the isogeometric analysis problems with rapidly changing local features. Without subdividing redundant cells to ensure the level difference of the adjacent cells, the refinement becomes more local, and fewer cells are subdivided for each refinement of the hierarchical T-mesh. Therefore, the dimension of the biquadratic polynomial spline space over the hierarchical T-mesh can be reduced, the superfluous control points or coefficients can be avoided, and the quantity of calculations can be decreased. Numerical examples show that these basis functions can work well on physical domains with different boundaries for the application in IGA.},
  archive      = {J_CMS},
  author       = {Liu, Jingjing and Deng, Fang and Ma, Huanhuan and Deng, Jiansong},
  doi          = {10.1007/s40304-022-00324-4},
  journal      = {Communications in Mathematics and Statistics},
  month        = {4},
  number       = {2},
  pages        = {403-430},
  shortjournal = {Commun. Math. Stat.},
  title        = {Isogeometric analysis using basis functions of splines spaces over hierarchical T-meshes with high level differences},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A class of structured high-dimensional dynamic covariance
matrices. <em>CMS</em>, <em>13</em>(2), 371–401. (<a
href="https://doi.org/10.1007/s40304-022-00321-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional covariance matrices have attracted much attention of statisticians and econometricians during the past decades. Vast literature is devoted to the research in high-dimensional covariance matrices. However, most of them are for constant covariance matrices. In many applications, constant covariance matrices are not appropriate, e.g., in portfolio allocation, dynamic covariance matrices would make much more sense. Simply assuming each entry of a covariance matrix is a function of time to introduce a dynamic structure would not work. In this paper, we are going to introduce a class of high-dimensional dynamic covariance matrices in which a kind of additive structure is embedded. We will show the proposed high-dimensional dynamic covariance matrices have many advantages in applications. An estimation procedure is also proposed to estimate the proposed high-dimensional dynamic covariance matrices. Asymptotic properties are built to justify the proposed estimation procedure. Intensive simulation studies show the proposed estimation procedure works very well when sample size is finite. Finally, we apply the proposed high-dimensional dynamic covariance matrices, together with the proposed estimation procedure, to portfolio allocation. The results look very interesting.},
  archive      = {J_CMS},
  author       = {Yang, Jin and Lian, Heng and Zhang, Wenyang},
  doi          = {10.1007/s40304-022-00321-7},
  journal      = {Communications in Mathematics and Statistics},
  month        = {4},
  number       = {2},
  pages        = {371-401},
  shortjournal = {Commun. Math. Stat.},
  title        = {A class of structured high-dimensional dynamic covariance matrices},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-associative categories of octonionic bimodules.
<em>CMS</em>, <em>13</em>(2), 303–369. (<a
href="https://doi.org/10.1007/s40304-022-00310-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Category is put to work in the non-associative realm in the article. We focus on a typical example of non-associative category. Its objects are octonionic bimodules, morphisms are octonionic para-linear maps, and compositions are non-associative in general. The octonionic para-linear map is the main object of octonionic Hilbert theory because of the octonionic Riesz representation theorem. An octonionic para-linear map f is in general not octonionic linear since it subjects to the rule $$\begin{aligned} \text {Re}\,\big (f(px)-pf(x)\big ) =0. \end{aligned}$$ The composition should be modified as $$\begin{aligned} f\circledcirc g(x):=f(g(x))-\sum _{j=1}^7 e_j\text {Re}\,\Big (f\big (g(e_ix)\big )-f\big (e_ig(x)\big )\Big ) \end{aligned}$$ so that it preserves the octonionic para-linearity. In this non-associative category, we introduce the Hom and Tensor functors which constitute an adjoint pair. We establish the Yoneda lemma in terms of the new notion of weak functor. To define the exactness in a non-associative category, we introduce the notion of the enveloping category via a universal property. This allows us to establish the exactness of the Hom functor and Tensor functor.},
  archive      = {J_CMS},
  author       = {Huo, Qinghai and Ren, Guangbin},
  doi          = {10.1007/s40304-022-00310-w},
  journal      = {Communications in Mathematics and Statistics},
  month        = {4},
  number       = {2},
  pages        = {303-369},
  shortjournal = {Commun. Math. Stat.},
  title        = {Non-associative categories of octonionic bimodules},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter estimation of beta-exponential distribution using
linear combination of order statistics. <em>CMS</em>, <em>13</em>(2),
261–301. (<a href="https://doi.org/10.1007/s40304-022-00306-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Beta-Exponential Distribution (BED) is proposed by Nadarajah and Samuel Kotz which contains several well-known distributions. With the addition of two shape parameters, this distribution can fit a wider range of data and therefore has been widely used in life testing. However, there are few literature on the properties of order statitics from this distribution, especially the best linear unbiased estimation (BLUE) of the location-scale parameters. In this paper, a new algorithm is proposed by us to obtain closed-form expression for variance-covariance matrix of order statistics from this distribution and give the BLUE for the location-scale parameters for the first time. Compared with several other classical parameter estimation methods (MLE, trimmed L-moments (TL-moments), probability weighted moments (PWM)), BLUE is more suitable for location-scale parameter estimation under small sample size for this distribution. Besides, the explicit expressions for moments of order statistics under the independent identically distributed (IID) case and independent not identically distributed (INID) case are also derived. Furthermore, for BED with three parameters (two shape parameters and scale parameter), we propose an improved TL-moments estimation method based on order statistics isotone transformation under two different trimmed schemes ( $$s=t=1$$ and $$s=1,t=0$$ ) as well as an improved PWM estimation method and conduct simulation study to compare the performance of each new method with MLE. As a result, the improved TL-moments estimation ( $$s=t=1$$ ) and the improved PWM estimation perform better than MLE on the whole.},
  archive      = {J_CMS},
  author       = {Guan, Ruijie and Cheng, Weihu and Rong, Yaohua and Zhao, Xu},
  doi          = {10.1007/s40304-022-00306-6},
  journal      = {Communications in Mathematics and Statistics},
  month        = {4},
  number       = {2},
  pages        = {261-301},
  shortjournal = {Commun. Math. Stat.},
  title        = {Parameter estimation of beta-exponential distribution using linear combination of order statistics},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="coap---10">COAP - 10</h2>
<ul>
<li><details>
<summary>
(2025). On the well-posedness of tracking dirichlet data for
bernoulli free boundary problems. <em>COAP</em>, <em>91</em>(1),
311–349. (<a href="https://doi.org/10.1007/s10589-025-00662-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to study the shape optimization method for solving the Bernoulli free boundary problem, a well-known ill-posed problem that seeks the unknown free boundary through Cauchy data. Different formulations have been proposed in the literature that differ in the choice of the objective functional. Specifically, it was shown respectively in Eppler and Harbrecht (SIAM J Control Optim 48:2901–2916, 2010, J Optim Theory Appl 145:17–35, 2010) that tracking Neumann data is well-posed but tracking Dirichlet data is not. In this paper we propose a new well-posed objective functional that tracks Dirichlet data at the free boundary. By calculating the Euler derivative and the shape Hessian of the objective functional we show that the new formulation is well-posed, i.e., the shape Hessian is coercive at the minima. The coercivity of the shape Hessian may ensure the existence of optimal solutions for the nonlinear Ritz–Galerkin approximation method and its convergence, thus is crucial for the formulation. As a summary, we conclude that tracking Dirichlet or Neumann data in their energy norm is not sufficient, but tracking them in a half an order higher norm will be well-posed. To support our theoretical results we carry out extensive numerical experiments.},
  archive      = {J_COAP},
  author       = {Gong, Wei and Liu, Le},
  doi          = {10.1007/s10589-025-00662-3},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {311-349},
  shortjournal = {Comput. Optim. Appl.},
  title        = {On the well-posedness of tracking dirichlet data for bernoulli free boundary problems},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Speeding up l-BFGS by direct approximation of the inverse
hessian matrix. <em>COAP</em>, <em>91</em>(1), 283–310. (<a
href="https://doi.org/10.1007/s10589-025-00665-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {L-BFGS is one of the widely used quasi-Newton methods. Instead of explicitly storing an approximation H of the inverse Hessian, L-BFGS keeps a limited number of vectors that can be used for computing the product of H by the gradient. However, this computation is sequential, each step depending on the outcome of the previous step. To solve this problem, we propose the Direct L-BFGS (DirL-BFGS) method that, seeing H as a linear operator, directly stores a low-rank plus diagonal (LRPD) representation of H. Employing the LRPD representation enables us to leverage the benefits of vector processing, leading to accelerating and parallelizing the calculations in the form of single instruction, multiple data. We evaluate our proposed method on different quadratic optimization problems and several regression and classification tasks with neural networks. Numerical results show that DirL-BFGS is faster overall than L-BFGS.},
  archive      = {J_COAP},
  author       = {Sadeghi-Lotfabadi, Ashkan and Ghiasi-Shirazi, Kamaledin},
  doi          = {10.1007/s10589-025-00665-0},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {283-310},
  shortjournal = {Comput. Optim. Appl.},
  title        = {Speeding up L-BFGS by direct approximation of the inverse hessian matrix},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The <span class="math display"><em>ω</em></span> -condition
number: Applications to preconditioning and low rank generalized
jacobian updating. <em>COAP</em>, <em>91</em>(1), 235–282. (<a
href="https://doi.org/10.1007/s10589-025-00669-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preconditioning is essential in iterative methods for solving linear systems. It is also the implicit objective in updating approximations of Jacobians in optimization methods, e.g., in quasi-Newton methods. We study a nonclassic matrix condition number, the $$\omega $$ -condition number, $$\omega $$ for short. $$\omega $$ is the ratio of: the arithmetic and geometric means of the singular values, rather than the largest and smallest for the classical $$\kappa $$ -condition number. The simple functions in $$\omega $$ allow one to exploit first order optimality conditions. We use this fact to derive explicit formulae for (i) $$\omega $$ -optimal low rank updating of generalized Jacobians arising in the context of nonsmooth Newton methods; and (ii) $$\omega $$ -optimal preconditioners of special structure for iterative methods for linear systems. In the latter context, we analyze the benefits of $$\omega $$ for (a) improving the clustering of eigenvalues; (b) reducing the number of iterations; and (c) estimating the actual condition of a linear system. Moreover we show strong theoretical connections between the $$\omega $$ -optimal preconditioners and incomplete Cholesky factorizations, and highlight the misleading effects arising from the inverse invariance of $$\kappa $$ . Our results confirm the efficacy of using the $$\omega $$ -condition number compared to the $$\kappa $$ -condition number.},
  archive      = {J_COAP},
  author       = {Jung, Woosuk L. and Torregrosa-Belén, David and Wolkowicz, Henry},
  doi          = {10.1007/s10589-025-00669-w},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {235-282},
  shortjournal = {Comput. Optim. Appl.},
  title        = {The $$\omega $$ -condition number: Applications to preconditioning and low rank generalized jacobian updating},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inertial accelerated stochastic mirror descent for
large-scale generalized tensor CP decomposition. <em>COAP</em>,
<em>91</em>(1), 201–233. (<a
href="https://doi.org/10.1007/s10589-025-00668-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of classic tensor CP decomposition models are designed for squared loss, utilizing Euclidean distance as a local proximal term. However, the Euclidean distance is unsuitable for the generalized loss function applicable to diverse types of real-world data, such as integer and binary data. Consequently, algorithms developed under the squared loss are not easily adaptable to handle these generalized losses, partially due to the absence of the gradient Lipschitz continuity. This paper explores generalized tensor CP decomposition, employing the Bregman distance as the proximal term and introducing an inertial accelerated block randomized stochastic mirror descent algorithm (iTableSMD). Within a broader multi-block variance reduction and inertial acceleration framework, we demonstrate the sublinear convergence rate for the subsequential sequence produced by the iTableSMD algorithm. We further show that iTableSMD requires at most $$\mathcal {O}(\varepsilon ^{-2})$$ iterations in expectation to attain an $$\varepsilon $$ -stationary point and establish the global convergence of the sequence. Numerical experiments on real datasets demonstrate that our proposed algorithm is efficient and achieves better performance than the existing state-of-the-art methods.},
  archive      = {J_COAP},
  author       = {Liu, Zehui and Wang, Qingsong and Cui, Chunfeng and Xia, Yong},
  doi          = {10.1007/s10589-025-00668-x},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {201-233},
  shortjournal = {Comput. Optim. Appl.},
  title        = {Inertial accelerated stochastic mirror descent for large-scale generalized tensor CP decomposition},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a family of relaxed gradient descent methods for strictly
convex quadratic minimization. <em>COAP</em>, <em>91</em>(1), 173–200.
(<a href="https://doi.org/10.1007/s10589-025-00670-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the convergence properties of a family of Relaxed $$\ell $$ -Minimal Gradient Descent methods for quadratic optimization; the family includes the omnipresent Steepest Descent method, as well as the Minimal Gradient method. Simple proofs are provided that show, in an appropriately chosen norm, the gradient and the distance of the iterates from optimality converge linearly, for all members of the family. Moreover, the function values decrease linearly, and iteration complexity results are provided. All theoretical results hold when (fixed) relaxation is employed. It is also shown that, given a fixed overhead and storage budget, every Relaxed $$\ell $$ -Minimal Gradient Descent method can be implemented using exactly one matrix vector product. Numerical experiments are presented that illustrate the benefits of relaxation across the family.},
  archive      = {J_COAP},
  author       = {MacDonald, Liam and Murray, Rua and Tappenden, Rachael},
  doi          = {10.1007/s10589-025-00670-3},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {173-200},
  shortjournal = {Comput. Optim. Appl.},
  title        = {On a family of relaxed gradient descent methods for strictly convex quadratic minimization},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finding search directions in quasi-newton methods for
minimizing a quadratic function subject to uncertainty. <em>COAP</em>,
<em>91</em>(1), 145–171. (<a
href="https://doi.org/10.1007/s10589-025-00661-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate quasi-Newton methods for minimizing a strongly convex quadratic function which is subject to errors in the evaluation of the gradients. In particular, we focus on computing search directions for quasi-Newton methods that all give identical behavior in exact arithmetic, generating minimizers of Krylov subspaces of increasing dimensions, thereby having finite termination. The BFGS quasi-Newton method may be seen as an ideal method in exact arithmetic and is empirically known to behave very well on a quadratic problem subject to small errors. We investigate large-error scenarios, in which the expected behavior is not so clear. We consider memoryless methods that are less expensive than the BFGS method, in that they generate low-rank quasi-Newton matrices that differ from the identity by a symmetric matrix of rank two. In addition, a more advanced model for generating the search directions is proposed, based on solving a chance-constrained optimization problem. Our numerical results indicate that for large errors, such a low-rank memoryless quasi-Newton method may perform better than a BFGS method. In addition, the results indicate a potential edge by including the chance-constrained model in the memoryless quasi-Newton method.},
  archive      = {J_COAP},
  author       = {Peng, Shen and Canessa, Gianpiero and Ek, David and Forsgren, Anders},
  doi          = {10.1007/s10589-025-00661-4},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {145-171},
  shortjournal = {Comput. Optim. Appl.},
  title        = {Finding search directions in quasi-newton methods for minimizing a quadratic function subject to uncertainty},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadratic convex reformulations for a class of complex
quadratic programming problems. <em>COAP</em>, <em>91</em>(1), 125–144.
(<a href="https://doi.org/10.1007/s10589-025-00672-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a class of complex quadratic programming problems characterized by unit-modulus and discrete argument constraints. This problem can be reformulated as a mixed-integer quadratic programming problem, which could be addressed using a commercial solver such as Gurobi. However, the solver’s efficiency is often unsatisfying if the problem formulation is inadequately designed. In this paper, we introduce several quadratic convex reformulations aimed at enhancing the solver’s performance. We extend the classical diagonal perturbation-based reformulation technique to this problem. Additionally, by leveraging the unique structure of the problem, we derive a new quadratic convex reformulation that provides a tighter continuous relaxation compared to the diagonal perturbation-based approach. The numerical tests on random instances and the unimodular code design problem demonstrate the superiority of the newly proposed reformulation.},
  archive      = {J_COAP},
  author       = {Lu, Cheng and Kang, Gaojian and Qu, Guangtai and Deng, Zhibin},
  doi          = {10.1007/s10589-025-00672-1},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {125-144},
  shortjournal = {Comput. Optim. Appl.},
  title        = {Quadratic convex reformulations for a class of complex quadratic programming problems},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a globally convergent semismooth* newton method in
nonsmooth nonconvex optimization. <em>COAP</em>, <em>91</em>(1), 67–124.
(<a href="https://doi.org/10.1007/s10589-025-00658-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present GSSN, a globalized SCD semismooth $$^{*}$$ Newton method for solving nonsmooth nonconvex optimization problems. The global convergence properties of the method are ensured by the proximal gradient method, whereas locally superlinear convergence is established via the SCD semismooth $$^{*}$$ Newton method under quite weak assumptions. The Newton direction is based on the SC (subspace containing) derivative of the subdifferential mapping and can be computed by the (approximate) solution of an equality-constrained quadratic program. Special attention is given to the efficient numerical implementation of the overall method.},
  archive      = {J_COAP},
  author       = {Gfrerer, Helmut},
  doi          = {10.1007/s10589-025-00658-z},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {67-124},
  shortjournal = {Comput. Optim. Appl.},
  title        = {On a globally convergent semismooth* newton method in nonsmooth nonconvex optimization},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proximal gradient method for convex multiobjective
optimization problems without lipschitz continuous gradients.
<em>COAP</em>, <em>91</em>(1), 27–66. (<a
href="https://doi.org/10.1007/s10589-025-00663-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes a proximal gradient method for nondifferentiable convex multiobjective optimization problems, where the components of the objective function are the sum of a proper lower semicontinuous function and a continuously differentiable function. By adopting a typical line search procedure, it is found that without a Lipschitz continuity of the gradients of the smooth part of the objective function, the proposed method is able to generate sequences that converge to weakly Pareto optimal points. The convergence rate of the method is found to be $$\mathcal {O}(1/k)$$ . Further, if the smooth component in the objective function is strongly convex, then the convergence rate is $$\mathcal {O}(r^k)$$ for some $$r\in (0,1)$$ . Moreover, in the absence of a strong convexity assumption, we also consider the accelerated version of the proposed approach based on the Nesterov step strategy. We obtain the improved convergence rate of $$\mathcal {O}(1/k^2)$$ , which is measured by a merit function. Numerical implementation strategies and performance profiles of the proposed methods on the considered problem involving $$\ell _1$$ -norm and indicator function are also provided.},
  archive      = {J_COAP},
  author       = {Zhao, Xiaopeng and Raushan, Ravi and Ghosh, Debdas and Yao, Jen-Chih and Qi, Min},
  doi          = {10.1007/s10589-025-00663-2},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {27-66},
  shortjournal = {Comput. Optim. Appl.},
  title        = {Proximal gradient method for convex multiobjective optimization problems without lipschitz continuous gradients},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A symmetric version of the generalized
chambolle-pock-he-yuan method for saddle point problems. <em>COAP</em>,
<em>91</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s10589-025-00671-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A primal-dual method for solving convex-concave saddle point problems was initially proposed by Chambolle and Pock, and its convergence was first proved by He and Yuan later. This primal-dual method (“CPHY&quot; for short) reduces to the Arrow–Hurwicz method (as well as the primal-dual hybrid gradient method) when the combination parameter $$\theta =0$$ , and to a special case of the proximal point algorithm when $$\theta =1$$ , both of which have been well-studied. However, for $$\theta \in (0,1)$$ , some theoretical aspects are not yet well-understood, particularly regarding the convergence behavior without imposing strong assumptions. Additionally, although saddle point problems inherently exhibit symmetry between primal and dual variables, the CPHY does not fully exploit this symmetry, as only one variable is updated using an extrapolated step. In this work, we propose a symmetric version of the CPHY by incorporating both symmetry and extrapolation techniques. The resulting algorithm guarantees convergence for $$\theta \in (-1,1)$$ and ensures symmetric updates for both primal and dual variables. Numerical experiments on LASSO, TV image inpainting, and graph cuts demonstrate the algorithm’s improved efficiency.},
  archive      = {J_COAP},
  author       = {Ma, Feng and Li, Si and Zhang, Xiayang},
  doi          = {10.1007/s10589-025-00671-2},
  journal      = {Computational Optimization and Applications},
  month        = {5},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Comput. Optim. Appl.},
  title        = {A symmetric version of the generalized chambolle-pock-he-yuan method for saddle point problems},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="dmkd---8">DMKD - 8</h2>
<ul>
<li><details>
<summary>
(2025). Multilayer horizontal visibility graphs for multivariate
time series analysis. <em>DMKD</em>, <em>39</em>(3), 1–42. (<a
href="https://doi.org/10.1007/s10618-025-01089-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series analysis is a vital but challenging task, with multidisciplinary applicability, tackling the characterization of multiple interconnected variables over time and their dependencies. Traditional methodologies often adapt univariate approaches or rely on assumptions specific to certain domains or problems, presenting limitations. A recent promising alternative is to map multivariate time series into high-level network structures such as multiplex networks, with past work relying on connecting successive time series components with interconnections between contemporary timestamps. In this work, we first define a novel cross-horizontal visibility mapping between lagged timestamps of different time series and then introduce the concept of multilayer horizontal visibility graphs. This allows describing cross-dimension dependencies via inter-layer edges, leveraging the entire structure of multilayer networks. To this end, a novel parameter-free topological measure is proposed and common measures are extended for the multilayer setting. Our approach is general and applicable to any kind of multivariate time series data. We provide an extensive experimental evaluation with both synthetic and real-world datasets. We first explore the proposed methodology and the data properties highlighted by each measure, showing that inter-layer edges based on cross-horizontal visibility preserve more information than previous mappings, while also complementing the information captured by commonly used intra-layer edges. We then illustrate the applicability and validity of our approach in multivariate time series mining tasks, showcasing its potential for enhanced data analysis and insights.},
  archive      = {J_DMKD},
  author       = {Freitas Silva, Vanessa and Silva, Maria Eduarda and Ribeiro, Pedro and Silva, Fernando},
  doi          = {10.1007/s10618-025-01089-4},
  journal      = {Data Mining and Knowledge Discovery},
  month        = {5},
  number       = {3},
  pages        = {1-42},
  shortjournal = {Data Mining Knowl. Discov.},
  title        = {Multilayer horizontal visibility graphs for multivariate time series analysis},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forming coordinated teams that balance task coverage and
expert workload. <em>DMKD</em>, <em>39</em>(3), 1–37. (<a
href="https://doi.org/10.1007/s10618-025-01090-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a new formulation of the team-formation problem, where the goal is to form teams to work on a given set of tasks requiring different skills. Deviating from the classic problem setting where one is asking to cover all skills of each given task, we aim to cover as many skills as possible while also trying to minimize the maximum workload among the experts. We do this by combining penalization terms for the coverage and load constraints into one objective. We call the corresponding assignment problem Balanced-Coverage, and show that it is $$\textbf{NP}$$ -hard. We also consider a variant of this problem, where the experts are organized into a graph, which encodes how well they work together. Utilizing such a coordination graph, we aim to find teams to assign to tasks such that each team’s radius does not exceed a given threshold. We refer to this problem as Network-Balanced-Coverage. We develop a generic template algorithm for approximating both problems in polynomial time, and we show that our template algorithm for Balanced-Coverage has provable guarantees. We describe a set of computational speedups that we can apply to our algorithms and make them scale for reasonably large datasets. From the practical point of view, we demonstrate how to efficiently tune the two parts of the objective and tailor their importance to a particular application. Our experiments with a variety of real-world datasets demonstrate the utility of our problem formulation as well as the efficiency of our algorithms in practice.},
  archive      = {J_DMKD},
  author       = {Vombatkere, Karan and Gionis, Aristides and Terzi, Evimaria},
  doi          = {10.1007/s10618-025-01090-x},
  journal      = {Data Mining and Knowledge Discovery},
  month        = {5},
  number       = {3},
  pages        = {1-37},
  shortjournal = {Data Mining Knowl. Discov.},
  title        = {Forming coordinated teams that balance task coverage and expert workload},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient outlier detection in numerical and categorical
data. <em>DMKD</em>, <em>39</em>(3), 1–46. (<a
href="https://doi.org/10.1007/s10618-024-01084-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to spot outliers in a large, unlabeled dataset with both numerical and categorical attributes? How to do it in a fast and scalable way? Outlier detection has many applications; it is covered therefore by an extensive literature. The distance-based detectors are the most popular ones. However, they still have two major drawbacks: (a) the intensive neighborhood search that takes hours or even days to complete in large data, and; (b) the inability to process categorical attributes. This paper tackles both problems by presenting HySortOD: a new, fast and scalable detector for numerical and categorical data. Our main focus is the analysis of datasets with many instances, and a low-to-moderate number of attributes. We studied dozens of real, benchmark datasets with up to one million instances; HySortOD outperformed nine competitors from the state of the art in runtime, being up to six orders of magnitude faster in large data, while maintaining high accuracy. Finally, we also performed an extensive experimental evaluation that confirms the ability of our method to obtain high-quality results from both real and synthetic datasets with categorical attributes.},
  archive      = {J_DMKD},
  author       = {Cabral, Eugênio F. and Sánchez Vinces, Braulio V. and Silva, Guilherme D. F. and Sander, Jörg and Cordeiro, Robson L. F.},
  doi          = {10.1007/s10618-024-01084-1},
  journal      = {Data Mining and Knowledge Discovery},
  month        = {5},
  number       = {3},
  pages        = {1-46},
  shortjournal = {Data Mining Knowl. Discov.},
  title        = {Efficient outlier detection in numerical and categorical data},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recommending the right academic programs: An interest mining
approach using BERTopic. <em>DMKD</em>, <em>39</em>(3), 1–40. (<a
href="https://doi.org/10.1007/s10618-024-01087-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prospective students face the challenging task of selecting a university program that will shape their academic and professional careers. For decision-makers and support services, it is often time-consuming and extremely difficult to match personal interests with suitable programs due to the vast and complex catalogue information available. This paper presents the first information system that provides students with efficient recommendations based on both program content and personal preferences. BERTopic, a powerful topic modeling algorithm, is used that leverages text embedding techniques to generate topic representations. It enables us to mine interest topics from all course descriptions, representing the full body of knowledge taught at the institution. Underpinned by the student’s individual choice of topics, a shortlist of the most relevant programs is computed through statistical backtracking in the knowledge map, a novel characterization of the program-course relationship. This approach can be applied to a wide range of educational settings, including professional and vocational training. A case study at a post-secondary school with 80 programs and over 5,000 courses shows that the system provides immediate and effective decision support. The presented interest topics are meaningful, leading to positive effects such as serendipity, personalization, and fairness, as revealed by a qualitative study involving 65 students. Over 98% of users indicated that the recommendations aligned with their interests, and about 94% stated they would use the tool in the future. Quantitative analysis shows the system can be configured to ensure fairness, achieving 98% program coverage while maintaining a personalization score of 0.77. These findings suggest that universities could expand student support services by implementing this real-time, user-centered, data-driven system to improve the program selection process.},
  archive      = {J_DMKD},
  author       = {Hill, Alessandro and Goo, Kalen and Agarwal, Puneet},
  doi          = {10.1007/s10618-024-01087-y},
  journal      = {Data Mining and Knowledge Discovery},
  month        = {5},
  number       = {3},
  pages        = {1-40},
  shortjournal = {Data Mining Knowl. Discov.},
  title        = {Recommending the right academic programs: An interest mining approach using BERTopic},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-neighbor social recommendation with attentional graph
convolutional network. <em>DMKD</em>, <em>39</em>(3), 1–22. (<a
href="https://doi.org/10.1007/s10618-025-01094-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The social network is usually utilized as auxiliary data to alleviate data sparsity and cold start problems of recommender systems. However, the social network obeys the power-law distribution and the social relations are indiscriminately utilized, resulting in providing insufficient and inaccurate information. Early efforts ignore these drawbacks and fail to exploit abundant information fully. In this paper, we propose a novel multi-neighbor social recommendation framework MNGCN based on graph convolutional network. The representations of user and item could be learned by iteratively integrating their multiple types of neighbor information. In addition, we apply a node-level attention mechanism to aggregate the same type of neighbors and a category-level attention mechanism to incorporate different categories of neighbors. A sampler is utilized to accurately select the social neighbors of users with regard to different items. Besides, the interactions and ratings are captured simultaneously in the user-item interactive network. Extensive experiments on two classical datasets illustrate that MNGCN achieves the best performance, and the ablation study demonstrates the necessity and the effectiveness of each component.},
  archive      = {J_DMKD},
  author       = {Zhang, Min and Liao, Xiao and Wang, Xinlei and Wang, Xiaojuan and Jin, Lei},
  doi          = {10.1007/s10618-025-01094-7},
  journal      = {Data Mining and Knowledge Discovery},
  month        = {5},
  number       = {3},
  pages        = {1-22},
  shortjournal = {Data Mining Knowl. Discov.},
  title        = {Multi-neighbor social recommendation with attentional graph convolutional network},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextualization of soccer analysis with tactical
periodization and machine learning. <em>DMKD</em>, <em>39</em>(3), 1–34.
(<a href="https://doi.org/10.1007/s10618-025-01092-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has become common practice in topflight leagues to track position data of soccer players and the ball. Analyzing sports performance based on this high-resolution data is a non-trivial task due to the great complexity and simultaneous lack of structure of the game. Sports practitioners tackle this problem through tactical periodization, i.e., mapping the course of the game onto different states, so-called match phases. However, creating manual tactical periodizations is a time-consuming task prone to subjective biases. Automatic approaches are thus preferred, but validated and open match phase models are currently lacking. The present study addresses this issue by (1) formalizing a domain-specific, qualitative match phase annotation scheme from related work, (2) creating and validating a multi-annotator set of annotations, (3) training several supervised machine learning architectures to fully automate the task of annotation, and (4) demonstrating the usefulness by conducting a contextualized detection of playing formations with the best model, referred to as FeatGRU. Steps (2) through (4) were performed on a set of real-world soccer data and the best-performing model is made available. FeatGRU is of value to the soccer community as it provides a fully automatic, frame-by-frame match phase annotation that matches domain experts’ opinions with 80% accuracy while being modular extendable for future work. Moreover, we found a strong relation between semantic complexity of matchphases, expert agreements, and classification performance, highlighting the importance of valid label generation. Thus, our approach presents an interesting benchmark to domains where automatic approaches are required while ambiguity between human expert opinions exists.},
  archive      = {J_DMKD},
  author       = {Biermann, Henrik and Memmert, Daniel and Petersen, Niklas and Raabe, Dominik},
  doi          = {10.1007/s10618-025-01092-9},
  journal      = {Data Mining and Knowledge Discovery},
  month        = {5},
  number       = {3},
  pages        = {1-34},
  shortjournal = {Data Mining Knowl. Discov.},
  title        = {Contextualization of soccer analysis with tactical periodization and machine learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ada-context: Adaptive context-aware grid-based approach for
curation of data streams. <em>DMKD</em>, <em>39</em>(3), 1–30. (<a
href="https://doi.org/10.1007/s10618-025-01095-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stream processing and real-time applications have changed how data is collected and processed. However, data quality is crucial for its usefulness. In this paper, we introduce Ada-Context, an approach that uses external contextual information to improve data quality assessment. It involves offline and online analysis components and uses a grid structure to map streaming data to cells, enhancing performance of quality control in data streams. Results show that contextual data especially external context improves data cleansing accuracy and the grid design boosts quality control effectiveness for data streams.},
  archive      = {J_DMKD},
  author       = {Mirzaie, Mostafa and Behkamal, Behshid and Allahbakhsh, Mohammad and Paydar, Samad and Bertino, Elisa},
  doi          = {10.1007/s10618-025-01095-6},
  journal      = {Data Mining and Knowledge Discovery},
  month        = {5},
  number       = {3},
  pages        = {1-30},
  shortjournal = {Data Mining Knowl. Discov.},
  title        = {Ada-context: Adaptive context-aware grid-based approach for curation of data streams},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting anomalies using rotated isolation forest.
<em>DMKD</em>, <em>39</em>(3), 1–31. (<a
href="https://doi.org/10.1007/s10618-025-01096-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Isolation Forest (iForest), proposed by Liu et al. at TKDE 2012, has become a prominent tool for unsupervised anomaly detection. However, recent research by Hariri, Kind, and Brunner, published in TKDE 2021, has revealed issues with iForest. They identified the presence of axis-aligned ghost clusters that can be misidentified as normal clusters, leading to biased anomaly scores and inaccurate predictions. In response, they developed the Extended Isolation Forest (EIF), which effectively solves these issues by eliminating the ghost clusters introduced by iForest. This enhancement results in improved consistency of anomaly scores and superior performance. We reveal a previously overlooked problem in the EIF, showing that it is vulnerable to ghost inter-clusters between normal clusters of data points. In this paper, we introduce the Rotated Isolation Forest (RIF) algorithm which effectively addresses both the axis-aligned ghost clusters observed in iForest and the ghost inter-clusters seen in EIF. RIF accomplishes this by randomly rotating the dataset (using random rotation matrices and QR decomposition) before feeding it into the iForest construction, thereby increasing dataset variation and eliminating ghost clusters. Our experiments conclusively demonstrate that the RIF algorithm outperforms iForest and EIF, as evidenced by the results obtained from both synthetic datasets and real-world datasets.},
  archive      = {J_DMKD},
  author       = {Monemizadeh, Vahideh and Kiani, Kourosh},
  doi          = {10.1007/s10618-025-01096-5},
  journal      = {Data Mining and Knowledge Discovery},
  month        = {5},
  number       = {3},
  pages        = {1-31},
  shortjournal = {Data Mining Knowl. Discov.},
  title        = {Detecting anomalies using rotated isolation forest},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ei---16">EI - 16</h2>
<ul>
<li><details>
<summary>
(2025). Multiple global peaks big bang-big crunch algorithm for
multimodal optimization. <em>EI</em>, <em>18</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s12065-025-01016-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main challenge of multimodal optimization problems is identifying multiple peaks with high accuracy in multidimensional search spaces with irregular landscapes. This work proposes the Multiple Global Peaks Big Bang-Big Crunch (MGP-BBBC) algorithm, which addresses the challenge of multimodal optimization problems by introducing a specialized mechanism for each operator. The algorithm expands the Big Bang-Big Crunch algorithm, a state-of-the-art metaheuristic inspired by the universe’s evolution. Specifically, MGP-BBBC groups the best individuals of the population into cluster-based centers of mass and then expands them with a progressively lower disturbance to guarantee convergence. During this process, it (i) applies a distance-based filtering to remove unnecessary elites such that the ones on smaller peaks are not lost, (ii) promotes isolated individuals based on their niche count after clustering, and (iii) balances exploration and exploitation during offspring generation to target specific accuracy levels. Experimental results on twenty multimodal benchmark test functions show that MGP-BBBC generally performs better or competitively with respect to other state-of-the-art multimodal optimizers.},
  archive      = {J_EI},
  author       = {Stroppa, Fabio and Astar, Ahmet},
  doi          = {10.1007/s12065-025-01016-y},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Evol. Intell.},
  title        = {Multiple global peaks big bang-big crunch algorithm for multimodal optimization},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence in the diagnosis of shoulder
injuries through magnetic resonance imaging: A scoping review.
<em>EI</em>, <em>18</em>(2), 1–10. (<a
href="https://doi.org/10.1007/s12065-025-01017-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of this review is to summarise the evidence about the artificial intelligence models in the assessment of shoulder magnetic resonance imaging. This scoping review included observational studies focused on the use of artificial intelligence to improve the diagnosis of shoulder injuries in magnetic resonance imaging. The studies that mixed joints or whose approach was theoretical were excluded. Regarding the analysis of each study, the data included were study type, population profile, sample size, method of deep learning, outcome variables, accuracy measurements, and statistical significance. 26 studies with a total of 9019 subjects were included. Seven studies focused on the accuracy of segmentation; thirteen, on the diagnosis, five, on the image quality, and one, on the acquisition time. For these purposes, all studies bet on convolutional neural networks, with seven choosing the 3D U-Net model and seven opting for more specific models such as 1-Lipschitz neural network, V-Net, ViVGG19, or CapsNet. Furthermore, six studies opted for the conjunction of models such as block-based AlexNet, GoogLeNet inception v3, ResNet or SqueezeNet with the 3D U-Net model. These models obtained statistically significant improvements in image quality (p = 0.001–0.028) and accuracy of segmentation (p = 0.001–0.043). However, despite obtaining a slight optimization of diagnostic sensitivity, these differences were not significant in all studies (p = 0.001–0.99). Deep learning stands out as a promising tool in the management of imaging tests in shoulder pathology, but more research is required to draw consistent conclusions.},
  archive      = {J_EI},
  author       = {Ramírez-Pérez, Laura and Cuesta-Vargas, Antonio Ignacio},
  doi          = {10.1007/s12065-025-01017-x},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-10},
  shortjournal = {Evol. Intell.},
  title        = {Artificial intelligence in the diagnosis of shoulder injuries through magnetic resonance imaging: A scoping review},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Capacity prediction model for lithium-ion batteries based on
bi-directional LSTM neural network optimized by adaptive convergence
factor gold rush optimizer. <em>EI</em>, <em>18</em>(2), 1–30. (<a
href="https://doi.org/10.1007/s12065-024-01013-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lithium-ion batteries play a crucial role in our daily lives. Accurately predicting the State of Health (SOH) and Remaining Useful Life of lithium-ion batteries is essential. To solve the limitations in prediction accuracy of traditional methods, a new approach is proposed that uses an adaptive convergence factor improved Gold Rush Optimizer (GRO) to optimize a Bi-directional Long Short-Term Memory (BiLSTM) neural network for predicting lithium-ion battery capacity. Since the capacity degradation of lithium-ion batteries follows time series patterns, BiLSTM has been chosen to solve this issue effectively. At the same time, to enhance the learning capability of BiLSTM, GRO is used to optimize the network&#39;s weights and bias parameters, resulting in higher prediction accuracy. In addition, an adaptive convergence factor is proposed to balance GRO&#39;s local and global search capabilities. Compared to other neural networks such as Feed-forward Neural Network (FNN), Long Short-Term Memory (LSTM) neural network, and BiLSTM, as well as different meta-heuristic optimization algorithms to optimize BiLSTM like Differential Evolution (DE), Harris Hawk Optimization (HHO), Whale Optimization Algorithm (WOA) and Great Trevally Optimization (GTO), the experimental results show that the optimized model performs better and predicts battery capacity with increased accuracy.},
  archive      = {J_EI},
  author       = {Wang, Xiao-Tian and Wang, Jie-Sheng and Zhang, Song-Bo and Liu, Xun and Sun, Yong-Cheng and Shang-Guan, Yi-Peng},
  doi          = {10.1007/s12065-024-01013-7},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-30},
  shortjournal = {Evol. Intell.},
  title        = {Capacity prediction model for lithium-ion batteries based on bi-directional LSTM neural network optimized by adaptive convergence factor gold rush optimizer},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Document clustering with evolved multi-word search queries.
<em>EI</em>, <em>18</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s12065-025-01018-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text clustering holds significant value across various domains due to its ability to identify patterns and group related information. Current approaches which rely heavily on a computed similarity measure between documents are often limited in accuracy and interpretability. We present a novel approach to the problem based on a set of evolved search queries. Clusters are formed as the set of documents matched by a single search query in the set of queries. The queries are optimized to maximize the number of documents returned and to minimize the overlap between clusters (documents returned by more than one query). Where queries contain more than one word they are interpreted disjunctively. We have found it useful to assign one word to be the root and constrain the query construction such that the set of documents returned by any additional query words intersect with the set returned by the root word. Not all documents in a collection are returned by any of the search queries in a set, so once the search query evolution is completed a second stage is performed whereby a KNN algorithm is applied to assign all unassigned documents to their nearest cluster. We describe the method and present results using 8 text datasets comparing effectiveness with well-known existing algorithms. We note that as well as achieving the highest accuracy on these datasets the search query format provides the qualitative benefits of being interpretable and modifiable whilst providing a causal explanation of cluster construction.},
  archive      = {J_EI},
  author       = {Hirsch, Laurence and Hirsch, Robin and Ogunleye, Bayode},
  doi          = {10.1007/s12065-025-01018-w},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Evol. Intell.},
  title        = {Document clustering with evolved multi-word search queries},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic literature review on the use of metaheuristics
for the optimisation of multimodal transportation. <em>EI</em>,
<em>18</em>(2), 1–37. (<a
href="https://doi.org/10.1007/s12065-025-01020-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimisation of multimodal transportation is constantly evolving, striving to provide commuters with seamless mobility and sustainable networks. Multimodal transportation problems often, however, present optimisation challenges because of their high dimensionality, compounded by network size, modelling criteria, and modes. Among these challenges is computational complexity, which can be reduced with the use of metaheuristic solution approaches that strive to find an acceptable solution within a reasonable timeframe. In addition, as machine learning finds integration within real-world applications, the demand for parallel computing and robust computational infrastructure is on the rise. Given these rapid shifts, this paper is motivated to present a comprehensive systematic literature review on the optimisation of multimodal transportation, focusing on the urban mobility of passengers, using metaheuristics. After conducting a systematic bibliographic search, a thorough classification of studies based on their problem scope, mathematical formulation, methodology, temporal- and network settings is conducted. Overall, findings provide insights into tackling the challenges of multimodal urban transport optimisation for future investigation, addressing concerns over scalability and efficiency for real-time deployment.},
  archive      = {J_EI},
  author       = {Chau, Matina L. Y. and Gkiotsalitis, Konstantinos},
  doi          = {10.1007/s12065-025-01020-2},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-37},
  shortjournal = {Evol. Intell.},
  title        = {A systematic literature review on the use of metaheuristics for the optimisation of multimodal transportation},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic optimization of predictive models for water
quality analysis in treatment plants using machine learning and
evolutionary algorithms. <em>EI</em>, <em>18</em>(2), 1–24. (<a
href="https://doi.org/10.1007/s12065-025-01022-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enhancing the assessment of water quality is essential for sustainable water management, given its critical impact on environmental health and human well-being. Accurate assessment presents several difficulties due to the complexity and variability of water ecosystems. Among the various machine learning techniques employed, Support Vector Regression and Adaptive Boosting have emerged as two of the most widely used and effective methods. In recent years, many evolutionary algorithms have been developed to find approximate solutions to optimization problems. In this study, we investigate how efficient new algorithms consisting of hybrids of machine learning methods and evolutionary algorithms can be for some problems. We extensively investigate Support Vector Regression with various kernels, including linear, radial basis function, polynomial, and sigmoid. In addition, we introduce Modified Support Vector Regression and Modified Adaboost where standalone ML models are combined with the swarm-based algorithms, such as Particle Swarm Optimization, Limited-memory Broyden–Fletcher–Goldfarb–Shanno, and Distributed Evolutionary Algorithms in Python. We apply the proposed hybrid algorithms to the problem of measuring water quality. Accurate modeling and assessment of river water quality are essential endeavors with multifaceted challenges. We focus on the Tigris River modeling in Baghdad Governorate, particularly at three water treatment plants: Eastern Tigris, AL-Karkh, and AL-Wathba. The dataset comprises multiple water quality parameters, with a total dissolved solids target. Incorporating swarm-based algorithms into the adopted models has synergistically enhanced their predictive capabilities, resulting in a significant augmentation of the overall predictive prowess of the ML models. The proposed hybrid algorithms successfully enhanced SVR model performance, with the L-BFGS-B algorithm yielding mean squared error reductions of 46.23% and 28.09% on the East Tigris and Karkh plants, respectively. In comparison, the MSVR-PSO approach reduced the Wathba plant by up to 85.96%. These findings have a significant impact on advancing water treatment plants. A thorough understanding of these variations is required when deciding on the optimal machine learning model for individual applications and generalization for Tigris River water quality scale evaluation and beyond.},
  archive      = {J_EI},
  author       = {Ghareeb, Ahmed and Nooruldeen, Orhan and Arslan, Chelang A. and Kapp, Sean and Choi, Jun-Ki},
  doi          = {10.1007/s12065-025-01022-0},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-24},
  shortjournal = {Evol. Intell.},
  title        = {Synergistic optimization of predictive models for water quality analysis in treatment plants using machine learning and evolutionary algorithms},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective optimization for order assignment in the
food cart evaluation system. <em>EI</em>, <em>18</em>(2), 1–32. (<a
href="https://doi.org/10.1007/s12065-025-01023-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the food delivery industry, driven by increasingly busy lifestyles, presents customers with the challenge of finding high-quality food at an optimal price. This decision-making process is made more difficult by the lack of a trustworthy food cart evaluation system. This study proposes a model that enables customers to evaluate food carts based on service quality, food quality, and cost-effectiveness. The model applies multi-objective optimization to balance these factors, using three evolutionary algorithms: Non-Dominated Sorting Genetic algorithm II, Strength Pareto Evolutionary Algorithm 2, and Indicator-Based Evolutionary Algorithm. The proposed system generates Pareto-optimal solutions that guide customers in selecting the best food carts. Additionally, the effectiveness of the proposed food cart evaluation system can be validated by comparing it with other algorithms in terms of Pareto optimal results, Hypervolume, Generational Distance, Inverted Generation Distance and Epsilon Indicator. The model was validated by Swiggy Food Chain data, which demonstrated that our approach effectively minimizes costs while maximizing food cart ratings. The results demonstrate that the proposed system can significantly enhance customer decision-making in selecting food carts, offering a practical tool for both consumers and the food delivery industry. Finally, using statistical techniques, we present a comparative study of the results with the current Zomato and Swiggy Food Chain data ratings.},
  archive      = {J_EI},
  author       = {Tunga, Harinandan and Kar, Samarjit and Hossain, Hasanuj-Jaman and Giri, Debasis},
  doi          = {10.1007/s12065-025-01023-z},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-32},
  shortjournal = {Evol. Intell.},
  title        = {Multi-objective optimization for order assignment in the food cart evaluation system},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing metaheuristic algorithms performance and the
causes of the zero-bias problem: A different perspective in benchmarks.
<em>EI</em>, <em>18</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s12065-025-01024-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an alternative approach to evaluate the explorative capabilities of metaheuristic algorithms by analyzing their performance on benchmark functions. Unlike conventional methods that focus on the precision of final solutions, the proposed method evaluates how often algorithms locate the region containing the global optimum. By defining a threshold fitness value that distinguishes between global and local optima, the study provides a direct measure of exploration success. Eleven metaheuristic algorithms were compared on multimodal and shifted benchmark functions, uncovering significant differences in their exploration efficiency. Notably, a pervasive flaw—the zero-bias problem—was identified in several algorithms, which artificially boosts performance on certain benchmarks while hindering real-world applicability. This paper proposes fixes for these issues and highlights standout performers with robust exploration capabilities. The findings offer researchers a clearer understanding of exploration mechanisms and provide practical insights for designing more effective optimization algorithms.},
  archive      = {J_EI},
  author       = {Morales-Castañeda, Bernardo and Pérez-Cisneros, Marco and Cuevas, Erik and Zaldívar, Daniel and Toski, Miguel and Rodríguez, Alma},
  doi          = {10.1007/s12065-025-01024-y},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Evol. Intell.},
  title        = {Analyzing metaheuristic algorithms performance and the causes of the zero-bias problem: A different perspective in benchmarks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing exploration and exploitation in genetic algorithm
optimization: A novel selection operator. <em>EI</em>, <em>18</em>(2),
1–32. (<a href="https://doi.org/10.1007/s12065-025-01028-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of genetic algorithms (GA) is dependent on the selection of operators utilized. A multitude of researchers have proposed a variety of operators with the aim of improving the performance of GA. The results demonstrate that achieving optimal outcomes necessitates a balance between exploration and exploitation. Prior to the implementation of crossover and mutation operators, the process of selecting parent individuals to produce offspring is of paramount importance in maintaining equilibrium. In this paper, we put forward a novel parent selection operator with the objective of improving the balance between exploration and exploitation. Moreover, proposed operator have been compared with existing operators in the literature in terms of convergence rate on a total of 30 distinct traveling salesman problems, 11 of which are symmetric and 19 of which are asymmetric. Finally, the statistical merit of the proposed operator is demonstrated through the use of a critical difference diagram (CD). The results obtained demonstrate that the proposed method is more effective than those presented in the existing literature.},
  archive      = {J_EI},
  author       = {Dalkılıç, Şahin Burak and Özgür, Atilla and Erdem, Hamit},
  doi          = {10.1007/s12065-025-01028-8},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-32},
  shortjournal = {Evol. Intell.},
  title        = {Balancing exploration and exploitation in genetic algorithm optimization: A novel selection operator},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An oppositional learning and chaotic local search-based
artificial electric field algorithm for engineering optimization.
<em>EI</em>, <em>18</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s12065-025-01025-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms are stochastic optimization techniques inspired by natural phenomena, with their performance driven by two key operators: exploration and exploitation. Despite their success, a common limitation is their susceptibility to premature convergence and slow progress toward optimal solutions. To address these challenges, this study presents an innovative extension of the Artificial Electric Field Algorithm (AEFA), a method rooted in charged system search principles. The proposed algorithm incorporates oppositional-based learning (OBL) and an elite chaotic local search mechanism to enhance both global and local search capabilities. OBL improves the exploration of the global search space, while the elite chaotic local search focuses on refining solutions around near-optimal regions, ensuring accelerated convergence. This hybrid approach is tested on CEC2020 bound-constrained numerical optimization problems and real-world applications such as topology optimization and gear train design. The findings demonstrate the superiority of the proposed algorithm in terms of achieving better optimal solutions, faster convergence rates, and reduced algorithmic complexity when compared to existing state-of-the-art algorithms. Some notable performance of the proposed algorithm are, it demonstrates superior performance over all listed algorithms for 10D problems $$f_1, f_2, f_3, f_5, f_7, f_9, f_{10}$$ , and most 20D problems $$f_1, f_2, f_3, f_5, f_7, f_8, f_9$$ . It shows comparable results with other algorithms for specific cases ( $$f_4, f_6, f_8$$ ) in both 10D and 20D settings, consistently outperforming or matching state-of-the-art alternatives. This highlights OC-AEFA’s robustness and versatility across diverse benchmark problems.},
  archive      = {J_EI},
  author       = {Anita and Chamoli, Shrishti and Yadav, Anupam},
  doi          = {10.1007/s12065-025-01025-x},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Evol. Intell.},
  title        = {An oppositional learning and chaotic local search-based artificial electric field algorithm for engineering optimization},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced fractional probabilistic self-organizing maps with
genetic algorithm optimization (EF-PRSOM). <em>EI</em>, <em>18</em>(2),
1–23. (<a href="https://doi.org/10.1007/s12065-025-01019-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Fractional derivatives offer an effective method for incorporating memory into systems, increasing efficiency for tasks that require long-term memory processes. They provide considerable advantages over classical derivatives, enabling deeper analysis of complex processes through effective access to underlying aspects. Leveraging these benefits, this paper introduces a new clustering approach, Enhanced Fractional Probabilistic Self-Organizing Map and Genetic Algorithm optimization. This approach addresses the problem of kernel locality and the challenges associated with selecting the parameter $$\alpha$$ . To determine the appropriate order of $$\alpha$$ , we implemented an efficient method using Genetic Algorithm optimization, enhancing clustering quality by considering model complexity, goodness of fit, and cluster separation. Furthermore, the optimized EF-PRSOM was compared to several clustering methods across multiple datasets using the Dunn index. Remarkably, EF-PRSOM consistently outperformed its counterparts across all metrics. Additionally, the optimized EF-PRSOM has the potential to be applied to various tasks, including image compression, where its effectiveness could be assessed using performance measures such as Peak Signal-to-Noise Ratio and Structural Similarity Index. This highlights the versatility of the proposed EF-PRSOM method across different applications.},
  archive      = {J_EI},
  author       = {Safouan, Safaa and El Moutaouakil, Karim},
  doi          = {10.1007/s12065-025-01019-9},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Evol. Intell.},
  title        = {Enhanced fractional probabilistic self-organizing maps with genetic algorithm optimization (EF-PRSOM)},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tower crane location optimization problem: A comprehensive
metaheuristic algorithm approach. <em>EI</em>, <em>18</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s12065-025-01021-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facility layout planning is crucial in construction projects due to its significant impact on project time and cost. The strategic location and capacity selection of tower cranes, given their high cost, are essential components of this process, alongside the placement of material supply point. Addressing this complex, combinatorial, and NP-hard decision-making problem, this study employs a comprehensive analysis of ten advanced metaheuristic algorithms to optimize the type and location of tower cranes with material supply points at construction sites. By formulating the problem as a mathematical model, the objective function seeks to minimize the overall material transportation cost while considering job site constraints. To evaluate the performance of these algorithms, we designed three real-world scenarios, providing a robust assessment framework. Our findings highlight that Ant Colony Optimization (ACO) delivers superior performance compared to other algorithms, excelling in both execution time and cost efficiency in this problem. This study&#39;s contribution lies in its exhaustive approach to problem-solving, offering valuable insights into algorithmic performance across varied construction scenarios.},
  archive      = {J_EI},
  author       = {Amiri, Roya and Tahmouresi, Amirhossein and Momenaei Kermani, Vahid and Mirjalili, Seyedali and Majrouhi Sardroud, Javad},
  doi          = {10.1007/s12065-025-01021-1},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Evol. Intell.},
  title        = {Tower crane location optimization problem: A comprehensive metaheuristic algorithm approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian combined arms algorithm: A novel meta-heuristic
approach for solving engineering problems. <em>EI</em>, <em>18</em>(2),
1–36. (<a href="https://doi.org/10.1007/s12065-025-01026-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the Gaussian Combined Arms (GCA) algorithm, a novel metaheuristic approach inspired by military strategies, designed to address high-dimensional and complex optimization challenges in engineering. The algorithm employs a dual-agent strategy by dividing search agents into two coordinated groups: ground forces for intensively refining solutions within promising regions and air forces for extensively exploring the search space to avoid local optima. By integrating Gaussian distribution principles, the GCA algorithm dynamically balances exploration and exploitation, ensuring adaptability and efficiency across diverse optimization landscapes. Experimental evaluations are first applied on three sets of test functions, including the standard benchmark set, CEC2017 and CEC2019, followed by several real-world engineering problems, such as Economic Load Dispatch and structural design optimization. The results demonstrate that GCA achieves superior accuracy, robustness, and convergence rates compared to conventional metaheuristic algorithms. These findings underscore the potential of GCA as a reliable tool for solving intricate engineering optimization problems.},
  archive      = {J_EI},
  author       = {Etesami, Reza and Madadi, Mohsen and Keynia, Farshid and Arabpour, Alireza},
  doi          = {10.1007/s12065-025-01026-w},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-36},
  shortjournal = {Evol. Intell.},
  title        = {Gaussian combined arms algorithm: A novel meta-heuristic approach for solving engineering problems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid multi-objective particle swarm optimization feature
selection approach with firefly algorithm using decision tree
classifier. <em>EI</em>, <em>18</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s12065-025-01029-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In machine learning, the importance of relevant data increases exponentially. In our proposed approach, we introduce an optimization method that combines Particle Swarm Optimization (PSO) and the Firefly Algorithm (FA) to enhance feature selection using decision tree-based classification. PSO is well-suited for small search spaces, while the Firefly Algorithm is effective for large search spaces. The proposed method, PSOFA-DT aims to improve classification performance by reducing dimensionality and optimizing feature selection. PSO’s global search capabilities are complemented by FA’s localized search, and the algorithm’s effectiveness is evaluated using decision tree accuracy and hold-out cross-validation. Experimental results demonstrate that PSOFA-DT outperforms individual implementations of PSO and FA in feature reduction and classification accuracy. Decision tree accuracy is used as the primary fitness metric, while the Firefly Algorithm refines the feature selection process. The algorithm balances exploration and exploitation by adjusting key parameters such as inertia weight, learning factors, and attraction coefficients. The Firefly Algorithm further optimizes feature selection, enhancing decision tree performance.},
  archive      = {J_EI},
  author       = {Singh, Ashish Kumar and Kumar, Anoj},
  doi          = {10.1007/s12065-025-01029-7},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Evol. Intell.},
  title        = {Hybrid multi-objective particle swarm optimization feature selection approach with firefly algorithm using decision tree classifier},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced snow ablation optimizer using advanced quadratic
and newton interpolation with taylor neighbourhood search and
second-order differential perturbation strategies for high-dimensional
feature selection. <em>EI</em>, <em>18</em>(2), 1–49. (<a
href="https://doi.org/10.1007/s12065-025-01030-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is essential in data mining and machine learning, significantly enhancing classification accuracy and reducing computational overhead. As datasets increase in size, identifying optimal feature subsets becomes more complex, necessitating the use of metaheuristic optimization techniques. Unlike traditional methods, these techniques effectively navigate extensive search spaces. The Snow Ablation Optimizer (SAO), a novel and widely adopted nature-inspired metaheuristic, is recognized for its simplicity and optimization efficacy. Nevertheless, SAO, like other nature-inspired algorithms, encounters limitations such as accuracy constraints, restricted population diversity, and premature convergence, particularly in complex, high-dimensional datasets. To address these limitations, this study proposes an improved variant of the recent optimization algorithm known as the Enhanced Snow Ablation Optimizer (ESAO), along with a wrapper-based feature selection (FS) method that utilizes the k-nearest neighbour (KNN) classifier. In the initial phase, the proposed algorithm employs a position update mechanism using advanced quadratic and Newton interpolation operators to navigate complex search spaces and accelerate convergence. Taylor neighbourhood strategies broaden the search scope, enhancing exploration and solution discovery while minimizing the risk of local optima. Second-order differential perturbation strategies further improve exploration and exploitation by capturing objective function nonlinearities, ensuring more accurate and efficient optimization, and promoting diverse solutions. The SAO algorithm, originally formulated for continuous search spaces, currently employs eight transfer functions: S-shaped, V-shaped, Z-shaped, and three U-shaped, customized to address optimization challenges within binary spaces. Its efficacy was validated using 21 high-dimensional datasets and compared against eight competitor algorithms. Subsequently, the “Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS)” method assesses optimal transfer functions based on classification accuracy, highlighting significant progress with accuracies ranging from 88 to 100%.},
  archive      = {J_EI},
  author       = {Thapliyal, Shivankur and Kumar, Narender},
  doi          = {10.1007/s12065-025-01030-0},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-49},
  shortjournal = {Evol. Intell.},
  title        = {Enhanced snow ablation optimizer using advanced quadratic and newton interpolation with taylor neighbourhood search and second-order differential perturbation strategies for high-dimensional feature selection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network-driven scenario prediction for adaptive
routing in MANETs using expanding ring search and random early
detection. <em>EI</em>, <em>18</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s12065-025-01032-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Routing in Mobile Ad Hoc Networks (MANETs) is complex due to their decentralized topology and dynamic environments. Conventional routing protocols frequently have trouble maintaining reliable end-to-end communication, leading to issues such as high packet loss, unstable routes, and increased delays. The research presented a novel deep-learning model with hybrid optimization to maintain route stability through stable node prediction and optimal route discovery in a MANET environment. Here Dynamic Sparse Recurrent-Convolutional Neural Network (DSR-CNN), an advanced variant of the R-CNN family is employed to detect the stable node in a sparse and dynamic environment. The weight parameters of the DSR-CNN are optimized by the Enhanced Fick’s Law Optimization Algorithm for the improved node prediction maintaining reliability and connectivity. Moreover, the most stable routes are constructed through the Giant Trevally Optimizer, optimizing route exploration and recovery. The model is designed and simulated in a Python environment with the required network settings. The utilization of the proposed research in the MANET communication shows 98% prediction accuracy, 2.48 ms delay, 25Mbps throughput, and 99% of packet delivery ratio which are more efficient than the prevailing technique’s results showing the highest route stability. These findings highlight the potential of DSR-CNN to significantly improve the reliability and performance of MANETs, setting a new benchmark for future routing protocols.},
  archive      = {J_EI},
  author       = {Gunavathie, M. A. and Shirode, Ujwal Ramesh and Rajesh, Nichenametla and Sudha, V.},
  doi          = {10.1007/s12065-025-01032-y},
  journal      = {Evolutionary Intelligence},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Evol. Intell.},
  title        = {Neural network-driven scenario prediction for adaptive routing in MANETs using expanding ring search and random early detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="focm---8">FoCM - 8</h2>
<ul>
<li><details>
<summary>
(2025). Stable spectral methods for time-dependent problems and the
preservation of structure. <em>FoCM</em>, <em>25</em>(2), 683–723. (<a
href="https://doi.org/10.1007/s10208-024-09647-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with orthonormal systems in real intervals, given with zero Dirichlet boundary conditions. More specifically, our interest is in systems with a skew-symmetric differentiation matrix (this excludes orthonormal polynomials). We consider a simple construction of such systems and pursue its ramifications. In general, given any $$\text {C}^1(a,b)$$ weight function such that $$w(a)=w(b)=0$$ , we can generate an orthonormal system with a skew-symmetric differentiation matrix. Except for the case $$a=-\infty $$ , $$b=+\infty $$ , only few powers of that matrix are bounded and we establish a connection between properties of the weight function and boundedness. In particular, we examine in detail two weight functions: the Laguerre weight function $$x^\alpha \textrm{e}^{-x}$$ for $$x&gt;0$$ and $$\alpha &gt;0$$ and the ultraspherical weight function $$(1-x^2)^\alpha $$ , $$x\in (-1,1)$$ , $$\alpha &gt;0$$ , and establish their properties. Both weights share a most welcome feature of separability, which allows for fast computation. The quality of approximation is highly sensitive to the choice of $$\alpha $$ , and we discuss how to choose optimally this parameter, depending on the number of zero boundary conditions.},
  archive      = {J_FoCM},
  author       = {Iserles, Arieh},
  doi          = {10.1007/s10208-024-09647-w},
  journal      = {Foundations of Computational Mathematics},
  month        = {4},
  number       = {2},
  pages        = {683-723},
  shortjournal = {Found. Comput. Math.},
  title        = {Stable spectral methods for time-dependent problems and the preservation of structure},
  volume       = {25},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polynomial factorization over henselian fields.
<em>FoCM</em>, <em>25</em>(2), 631–681. (<a
href="https://doi.org/10.1007/s10208-024-09646-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an algorithm that, given an irreducible polynomial g over a general valued field (K, v), finds the factorization of g over the Henselianization of K under certain conditions. The analysis leading to the algorithm follows the footsteps of Ore, Mac Lane, Okutsu, Montes, Vaquié and Herrera–Olalla–Mahboub–Spivakovsky, whose work we review in our context. The correctness is based on a key new result (Theorem 4.10), exhibiting relations between generalized Newton polygons and factorization in the context of an arbitrary valuation. This allows us to develop a polynomial factorization algorithm and an irreducibility test that go beyond the classical discrete, rank-one case. These foundational results may find applications for various computational tasks involved in arithmetic of function fields, desingularization of hypersurfaces, multivariate Puiseux series or valuation theory.},
  archive      = {J_FoCM},
  author       = {Alberich-Carramiñana, Maria and Guàrdia, Jordi and Nart, Enric and Poteaux, Adrien and Roé, Joaquim and Weimann, Martin},
  doi          = {10.1007/s10208-024-09646-x},
  journal      = {Foundations of Computational Mathematics},
  month        = {4},
  number       = {2},
  pages        = {631-681},
  shortjournal = {Found. Comput. Math.},
  title        = {Polynomial factorization over henselian fields},
  volume       = {25},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete pseudo-differential operators and applications to
numerical schemes. <em>FoCM</em>, <em>25</em>(2), 587–630. (<a
href="https://doi.org/10.1007/s10208-024-09645-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a class of discrete operators introduced by O. Chodosh, acting on infinite sequences and mimicking standard properties of pseudo-differential operators. By using a new approach, we extend this class to finite or periodic sequences, allowing a general representation of discrete pseudo-differential operators obtained by finite differences approximations and easily transferred to time discretizations. In particular we can define the notion of order and regularity, and we recover the fundamental property, well known in pseudo-differential calculus, that the commutator of two discrete operators gains one order of regularity. As examples of practical applications, we revisit standard error estimates for the convergence of splitting methods, obtaining in some Hamiltonian cases no loss of derivative in the error estimates, in particular for discretizations of general waves and/or water-waves equations. Moreover, we give an example of preconditioner constructions inspired by normal form analysis to deal with the similar question for more general cases.},
  archive      = {J_FoCM},
  author       = {Faou, Erwan and Grébert, Benoît},
  doi          = {10.1007/s10208-024-09645-y},
  journal      = {Foundations of Computational Mathematics},
  month        = {4},
  number       = {2},
  pages        = {587-630},
  shortjournal = {Found. Comput. Math.},
  title        = {Discrete pseudo-differential operators and applications to numerical schemes},
  volume       = {25},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of a modified regularity-preserving euler scheme
for parabolic semilinear SPDEs: Total variation error bounds for the
numerical approximation of the invariant distribution. <em>FoCM</em>,
<em>25</em>(2), 511–586. (<a
href="https://doi.org/10.1007/s10208-024-09644-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a modification of the standard linear implicit Euler integrator for the weak approximation of parabolic semilinear stochastic PDEs driven by additive space-time white noise. This new method can easily be combined with a finite difference method for the spatial discretization. The proposed method is shown to have improved qualitative properties compared with the standard method. First, for any time-step size, the spatial regularity of the solution is preserved, at all times. Second, the proposed method preserves the Gaussian invariant distribution of the infinite dimensional Ornstein–Uhlenbeck process obtained when the nonlinearity is removed, for any time-step size. The weak order of convergence of the proposed method is shown to be equal to 1/2 in a general setting, like for the standard Euler scheme. A stronger weak approximation result is obtained when considering the approximation of a Gibbs invariant distribution, when the nonlinearity is a gradient: one obtains an approximation in total variation distance of order 1/2, which does not hold for the standard method. This is the first result of this type in the literature and this is the major and most original result of this article.},
  archive      = {J_FoCM},
  author       = {Bréhier, Charles-Edouard},
  doi          = {10.1007/s10208-024-09644-z},
  journal      = {Foundations of Computational Mathematics},
  month        = {4},
  number       = {2},
  pages        = {511-586},
  shortjournal = {Found. Comput. Math.},
  title        = {Analysis of a modified regularity-preserving euler scheme for parabolic semilinear SPDEs: Total variation error bounds for the numerical approximation of the invariant distribution},
  volume       = {25},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the existence of monge maps for the gromov–wasserstein
problem. <em>FoCM</em>, <em>25</em>(2), 463–510. (<a
href="https://doi.org/10.1007/s10208-024-09643-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gromov–Wasserstein problem is a non-convex optimization problem over the polytope of transportation plans between two probability measures supported on two spaces, each equipped with a cost function evaluating similarities between points. Akin to the standard optimal transportation problem, it is natural to ask for conditions guaranteeing some structure on the optimizers, for instance, if these are induced by a (Monge) map. We study this question in Euclidean spaces when the cost functions are either given by (i) inner products or (ii) squared distances, two standard choices in the literature. We establish the existence of an optimal map in case (i) and of an optimal 2-map (the union of the graphs of two maps) in case (ii), both under an absolute continuity condition on the source measure. Additionally, in case (ii) and in dimension one, we numerically design situations where optimizers of the Gromov–Wasserstein problem are 2-maps but are not maps. This suggests that our result cannot be improved in general for this cost. Still in dimension one, we additionally establish the optimality of monotone maps under some conditions on the measures, thereby giving insight into why such maps often appear to be optimal in numerical experiments.},
  archive      = {J_FoCM},
  author       = {Dumont, Théo and Lacombe, Théo and Vialard, François-Xavier},
  doi          = {10.1007/s10208-024-09643-0},
  journal      = {Foundations of Computational Mathematics},
  month        = {4},
  number       = {2},
  pages        = {463-510},
  shortjournal = {Found. Comput. Math.},
  title        = {On the existence of monge maps for the Gromov–Wasserstein problem},
  volume       = {25},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete helmholtz decompositions of piecewise constant and
piecewise affine vector and tensor fields. <em>FoCM</em>,
<em>25</em>(2), 417–461. (<a
href="https://doi.org/10.1007/s10208-024-09642-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete Helmholtz decompositions dissect piecewise polynomial vector fields on simplicial meshes into piecewise gradients and rotations of finite element functions. This paper concisely reviews established results from the literature which all restrict to the lowest-order case of piecewise constants. Its main contribution consists of the generalization of these decompositions to 3D and of novel decompositions for piecewise affine vector fields in terms of Fortin–Soulie functions. While the classical lowest-order decompositions include one conforming and one nonconforming part, the decompositions of piecewise affine vector fields require a nonconforming enrichment in both parts. The presentation covers two and three spatial dimensions as well as generalizations to deviatoric tensor fields in the context of the Stokes equations and symmetric tensor fields for the linear elasticity and fourth-order problems. While the proofs focus on contractible domains, generalizations to multiply connected domains and domains with non-connected boundary are discussed as well.},
  archive      = {J_FoCM},
  author       = {Bringmann, Philipp and Ketteler, Jonas W. and Schedensack, Mira},
  doi          = {10.1007/s10208-024-09642-1},
  journal      = {Foundations of Computational Mathematics},
  month        = {4},
  number       = {2},
  pages        = {417-461},
  shortjournal = {Found. Comput. Math.},
  title        = {Discrete helmholtz decompositions of piecewise constant and piecewise affine vector and tensor fields},
  volume       = {25},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-dimensional invariant embeddings for universal geometric
learning. <em>FoCM</em>, <em>25</em>(2), 375–415. (<a
href="https://doi.org/10.1007/s10208-024-09641-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies separating invariants: mappings on D-dimensional domains which are invariant to an appropriate group action and which separate orbits. The motivation for this study comes from the usefulness of separating invariants in proving universality of equivariant neural network architectures. We observe that in several cases the cardinality of separating invariants proposed in the machine learning literature is much larger than the dimension D. As a result, the theoretical universal constructions based on these separating invariants are unrealistically large. Our goal in this paper is to resolve this issue. We show that when a continuous family of semi-algebraic separating invariants is available, separation can be obtained by randomly selecting $$2D+1 $$ of these invariants. We apply this methodology to obtain an efficient scheme for computing separating invariants for several classical group actions which have been studied in the invariant learning literature. Examples include matrix multiplication actions on point clouds by permutations, rotations, and various other linear groups. Often the requirement of invariant separation is relaxed and only generic separation is required. In this case, we show that only $$D+1$$ invariants are required. More importantly, generic invariants are often significantly easier to compute, as we illustrate by discussing generic and full separation for weighted graphs. Finally we outline an approach for proving that separating invariants can be constructed also when the random parameters have finite precision.},
  archive      = {J_FoCM},
  author       = {Dym, Nadav and Gortler, Steven J.},
  doi          = {10.1007/s10208-024-09641-2},
  journal      = {Foundations of Computational Mathematics},
  month        = {4},
  number       = {2},
  pages        = {375-415},
  shortjournal = {Found. Comput. Math.},
  title        = {Low-dimensional invariant embeddings for universal geometric learning},
  volume       = {25},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phaseless sampling on square-root lattices. <em>FoCM</em>,
<em>25</em>(2), 351–374. (<a
href="https://doi.org/10.1007/s10208-024-09640-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its appearance in a remarkably wide field of applications, such as audio processing and coherent diffraction imaging, the short-time Fourier transform (STFT) phase retrieval problem has seen a great deal of attention in recent years. A central problem in STFT phase retrieval concerns the question for which window functions $$g \in {L^2({\mathbb R}^d)}$$ and which sampling sets $$\Lambda \subseteq {\mathbb R}^{2d}$$ is every $$f \in {L^2({\mathbb R}^d)}$$ uniquely determined (up to a global phase factor) by phaseless samples of the form $$\begin{aligned} |V_gf(\Lambda )| = \left\{ |V_gf(\lambda )|: \lambda \in \Lambda \right\} , \end{aligned}$$ where $$V_gf$$ denotes the STFT of f with respect to g. The investigation of this question constitutes a key step towards making the problem computationally tractable. However, it deviates from ordinary sampling tasks in a fundamental and subtle manner: recent results demonstrate that uniqueness is unachievable if $$\Lambda $$ is a lattice, i.e $$\Lambda = A{\mathbb Z}^{2d}, A \in \textrm{GL}(2d,{\mathbb R})$$ . Driven by this discretization barrier, the present article centers around the initiation of a novel sampling scheme which allows for unique recovery of any square-integrable function via phaseless STFT-sampling. Specifically, we show that square-root lattices, i.e., sets of the form $$\begin{aligned} \Lambda = A \left( \sqrt{{\mathbb Z}} \right) ^{2d}, \ \sqrt{{\mathbb Z}} = \{ \pm \sqrt{n}: n \in {\mathbb N}_0 \}, \end{aligned}$$ guarantee uniqueness of the STFT phase retrieval problem. The result holds for a large class of window functions, including Gaussians},
  archive      = {J_FoCM},
  author       = {Grohs, Philipp and Liehr, Lukas},
  doi          = {10.1007/s10208-024-09640-3},
  journal      = {Foundations of Computational Mathematics},
  month        = {4},
  number       = {2},
  pages        = {351-374},
  shortjournal = {Found. Comput. Math.},
  title        = {Phaseless sampling on square-root lattices},
  volume       = {25},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="gpem---15">GPEM - 15</h2>
<ul>
<li><details>
<summary>
(2025). Review: “Computational evolution of neural and morphological
development,” yaochu jin, ISBN 978-981-99-1853-9, springer, 2023.
<em>GPEM</em>, <em>26</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s10710-024-09499-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Vroomans, Renske},
  doi          = {10.1007/s10710-024-09499-x},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Review: “Computational evolution of neural and morphological development”, yaochu jin, ISBN 978-981-99-1853-9, springer, 2023},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on batch training in genetic programming.
<em>GPEM</em>, <em>26</em>(1), 1–28. (<a
href="https://doi.org/10.1007/s10710-024-09501-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Machine Learning (ML), the use of subsets of training data, referred to as batches, rather than the entire dataset, has been extensively researched to reduce computational costs, improve model efficiency, and enhance algorithm generalization. Despite extensive research, a clear definition and consensus on what constitutes batch training have yet to be reached, leading to a fragmented body of literature that could otherwise be seen as different facets of a unified methodology. To address this gap, we propose a theoretical redefinition of batch training, creating a clearer and broader overview that integrates diverse perspectives. We then apply this refined concept specifically to Genetic Programming (GP). Although batch training techniques have been explored in GP, the term itself is seldom used, resulting in ambiguity regarding its application in this area. This review seeks to clarify the existing literature on batch training by presenting a new and practical classification system, which we further explore within the specific context of GP. We also investigate the use of dynamic batch sizes in ML, emphasizing the relatively limited research on dynamic or adaptive batch sizes in GP compared to other ML algorithms. By bringing greater coherence to previously disjointed research efforts, we aim to foster further scientific exploration and development. Our work highlights key considerations for researchers designing batch training applications in GP and offers an in-depth discussion of future research directions, challenges, and opportunities for advancement.},
  archive      = {J_GPEM},
  author       = {Rosenfeld, Liah and Vanneschi, Leonardo},
  doi          = {10.1007/s10710-024-09501-6},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {A survey on batch training in genetic programming},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harnessing evolutionary algorithms for enhanced
characterization of ENSO events. <em>GPEM</em>, <em>26</em>(1), 1–24.
(<a href="https://doi.org/10.1007/s10710-024-09497-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The El Niño-Southern Oscillation (ENSO) significantly influences the complexity and variability of the global climate system, driving its variability. ENSO events’ irregularity and unpredictability arise from intricate ocean–atmosphere interactions and nonlinear feedback mechanisms, complicating their prediction of timing, intensity, and geographic impacts. This study applies Genetic Programming and Genetic Algorithms within the EASEA (EAsy Specification of Evolutionary Algorithms) Evolutionary Algorithms (EA) framework to develop a repository of symbolic equations for El Niño and La Niña events, spanning their various intensities. By analyzing data from the Oceanic Niño Index, this approach yields equation-based characterizations of ENSO events. This methodology not only enhances ENSO characterization strategies but also contributes to expanding the use of EAs in climate event analysis. The resulting equations have the potential to offer insights beyond academia, benefiting education, climate policy, and environmental management. This highlights the importance of ongoing refinement, validation, and exploration in these fields through EAs.},
  archive      = {J_GPEM},
  author       = {Abdulkarimova, Ulviya and Abarca-del-Rio, Rodrigo and Collet, Pierre},
  doi          = {10.1007/s10710-024-09497-z},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Harnessing evolutionary algorithms for enhanced characterization of ENSO events},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hardware real-time individualised blood glucose predictor
generator based on grammars and cartesian genetic programming.
<em>GPEM</em>, <em>26</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s10710-024-09500-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a novel grammar-guided technique based on genetic programming for on-chip, real-time, configurable hardware design of model generators on an FPGA. The technique integrates grammar-based design, Cartesian Genetic Programming, and a (1+ $$\lambda$$ ) Evolutionary Strategy and is demonstrated through the implementation of a wearable hardware predictor for blood glucose prediction. People with diabetes need to manage their blood glucose levels to prevent life-threatening situations and long-term complications. Effective glucose management requires accurate blood glucose predictions, yet most existing methods rely on heuristic estimators. This system enables the training and testing of personalized models using real patient data. We validated the approach by generating and evaluating models for 30- and 60-min forecasting predictions on ten patients, creating a total of 200 models. The system achieved state-of-the-art results, with 98% and 90% of predictions falling within clinically acceptable regions according to Clarke error grid analysis, for 30- and 60-min horizons, respectively. Unlike software implementations, our technique does not suffer from hardware limitations and provides an efficient, adaptable solution through wearable hardware with minimal errors and low power consumption. This is the first demonstration of combining Cartesian Genetic Programming with a hardware implementation for grammar-based blood glucose prediction, potentially enabling real-time embedded systems for portable devices.},
  archive      = {J_GPEM},
  author       = {Cano, Jorge and Hidalgo, J. Ignacio and Garnica, Óscar},
  doi          = {10.1007/s10710-024-09500-7},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Hardware real-time individualised blood glucose predictor generator based on grammars and cartesian genetic programming},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparison of representations in grammar-guided genetic
programming in the context of glucose prediction in people with
diabetes. <em>GPEM</em>, <em>26</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s10710-024-09502-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The representation of individuals in Genetic Programming (GP) has a large impact on the evolutionary process. In previous work, we investigated the evolutionary process of three Grammar-Guided GP (GGGP) methods, Context-Free Grammars GP (CFG-GP), Grammatical Evolution (GE) and Structured Grammatical Evolution (SGE), in the context of the complex, real-world problem of predicting the glucose level of people with diabetes two hours ahead of time. We concluded that representation choice is more impactful with a higher maximum depth, and that CFG-GP better explores the search space for deeper trees, achieving better results. Furthermore, we find that CFG-GP relies more on feature construction, whereas GE and SGE rely more on feature selection. Additionally, we altered the GGGP methods in two ways: using $$\epsilon$$ -lexicase selection, which solved the overfitting problem of CFG-GP and helps it to adapt to patients with high glucose variability; and with a penalization of complex trees, to create more interpretable trees. Combining $$\epsilon$$ -lexicase selection with CFG-GP performed best. In this work, we extend on the previous work and evaluated the impact of initialization methods in the quality of solutions. We found that they have no significant impact, even when the change of representation has.},
  archive      = {J_GPEM},
  author       = {Ingelse, Leon and Hidalgo, J. Ignacio and Colmenar, J. Manuel and Lourenço, Nuno and Fonseca, Alcides},
  doi          = {10.1007/s10710-024-09502-5},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {A comparison of representations in grammar-guided genetic programming in the context of glucose prediction in people with diabetes},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking GSGP: Still competitive 10 years later?
<em>GPEM</em>, <em>26</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10710-024-09504-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geometric Semantic Genetic Programming (GSGP) reimagined how to search for symbolic models using an evolutionary process. It addressed one of the main weaknesses of standard Genetic Programming (GP) by performing the search directly within the semantic space of a problem, which can define a convex and unimodal fitness landscape. Since the method does not require the syntactic evaluation of offspring, GSGP allowed more efficient and effective learning systems compared to standard GP. However, recent benchmarking results have suggested that GSGP is no longer a competitive approach, particularly in the symbolic regression domain, despite its previous success in several real-world tasks. Therefore, the research question of this work is an empirical one, stated as: Is GSGP still a competitive symbolic regression method 10 years after it was proposed? A comprehensive benchmark of black-box problems and comparisons with state-of-the-art methods were used to answer this question. In particular, a recently developed parallel version of GSGP is used, extending the implementation to also include the previously proposed optimal mutation step computation, as well as using the analytical quotient operator instead of a protected division. Results show that with simple, but important, extensions to the original GSGP algorithm, the answer to the research question is yes.},
  archive      = {J_GPEM},
  author       = {Muñoz Contreras, Jose Manuel and Trujillo, Leonardo and Hernandez, Daniel E. and Cardenas Florido, Luis A.},
  doi          = {10.1007/s10710-024-09504-3},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Benchmarking GSGP: Still competitive 10 years later?},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Review of PySR: High-performance symbolic regression in
python and julia. <em>GPEM</em>, <em>26</em>(1), 1–4. (<a
href="https://doi.org/10.1007/s10710-024-09503-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Tonda, Alberto},
  doi          = {10.1007/s10710-024-09503-4},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-4},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Review of PySR: High-performance symbolic regression in python and julia},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using FPGA devices to accelerate the evaluation phase of
tree-based genetic programming: An extended analysis. <em>GPEM</em>,
<em>26</em>(1), 1–48. (<a
href="https://doi.org/10.1007/s10710-024-09505-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes the potential of accelerating the evaluation phase of tree-based genetic programming through contemporary field-programmable gate array (FPGA) technology. This exploration stems from the fact that FPGAs can sometimes leverage increased levels of both data and function parallelism, as well as superior power/energy efficiency, when compared to general-purpose CPU/GPU systems. In this investigation, we introduce a fixed-depth, tree-based architecture that can fully parallelize tree evaluation for type-consistent primitives that are unrolled and pipelined. We show that our accelerator on a 14nm FPGA achieves an average speedup of 43 $$\times$$ when compared to a recent open-source GPU solution, TensorGP, implemented on 8nm process-node technology, and an average speedup of 4,902 $$\times$$ when compared to a popular baseline GP software tool, DEAP, running parallelized across all cores of a 2-socket, 28-core (56-thread), 14nm CPU server. Despite our single-FPGA accelerator being 2.4 $$\times$$ slower on average when compared to the recent state-of-the-art Operon tool executing on the same 2-processor, 28-core CPU system, we show that this single-FPGA system is 1.4 $$\times$$ better than Operon in terms of performance-per-watt. Importantly, we also describe six future extensions that could provide at least a 64–192 $$\times$$ speedup over our current design. Therefore, our initial results provide considerable motivation for the continued exploration of FPGA-based GP systems. Overall, any success in significantly improving runtime and energy efficiency could potentially enable novel research efforts through faster and/or less costly GP runs, similar to how GPUs unlocked the power of deep learning during the past fifteen years.},
  archive      = {J_GPEM},
  author       = {Crary, Christopher and Piard, Wesley and Stitt, Greg and Hicks, Benjamin and Bean, Caleb and Burlacu, Bogdan and Banzhaf, Wolfgang},
  doi          = {10.1007/s10710-024-09505-2},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-48},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Using FPGA devices to accelerate the evaluation phase of tree-based genetic programming: An extended analysis},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The science of soft robots, koichi suzumori, kenjiro fukuda,
ryuma niiyama, and kohei nakajima: ISBN 978-9811951732, springer 2023.
<em>GPEM</em>, <em>26</em>(1), 1–3. (<a
href="https://doi.org/10.1007/s10710-025-09508-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Medvet, Eric and Salvato, Erica},
  doi          = {10.1007/s10710-025-09508-7},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {The science of soft robots, koichi suzumori, kenjiro fukuda, ryuma niiyama, and kohei nakajima: ISBN 978-9811951732, springer 2023},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). “Machine learning assisted evolutionary multi- and
many-objective optimization” by dhish kumar saxena, sukrit mittal,
kalyanmoy deb, and erik d. Goodman, ISBN 978-981-99-2095-2, springer,
2024. <em>GPEM</em>, <em>26</em>(1), 1–3. (<a
href="https://doi.org/10.1007/s10710-025-09509-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Selçuklu, Saltuk Buğra},
  doi          = {10.1007/s10710-025-09509-6},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {“Machine learning assisted evolutionary multi- and many-objective optimization” by dhish kumar saxena, sukrit mittal, kalyanmoy deb, and erik d. goodman, ISBN 978-981-99-2095-2, springer, 2024},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memetic semantic boosting for symbolic regression.
<em>GPEM</em>, <em>26</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10710-024-09506-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel approach called semantic boosting regression (SBR), leveraging the principles of boosting algorithms in symbolic regression using a Memetic Semantic GP for Symbolic Regression (MSGP) algorithm as weak learners. Memetic computation facilitates the integration of domain knowledge into a population-based approach, and semantic-based algorithms enhance local improvements to achieve targeted outputs. The fusion of memetic and semantic approaches allows us to augment the exploration and exploitation capabilities inherent in Genetic Programming (GP) and identify concise symbolic expressions that maintain interpretability without compromising the expressive power of symbolic regression. Our approach echoes the boosting algorithm’s characteristic, where weak learners (e.g., MSGP) are sequentially improved upon, focusing on correcting previous errors and continuously enhancing overall performance. This iterative strategy, intrinsic to boosting methods, is adeptly adapted to our SBR model. Experimental results demonstrate that our memetic-semantic approach has equal or better performance when compared to state-of-the-art evolutionary-based techniques when addressing real-world symbolic regression challenges. This advancement helps tackle the bloating issue in GP and significantly improves generalization capabilities. However, akin to classic boosting algorithms, one limitation of our approach is the increased computational cost due to the sequential training of boosting learners.},
  archive      = {J_GPEM},
  author       = {Leite, Alessandro and Schoenauer, Marc},
  doi          = {10.1007/s10710-024-09506-1},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Memetic semantic boosting for symbolic regression},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial introduction for the special issue on highlights
of genetic programming 2023 events. <em>GPEM</em>, <em>26</em>(1), 1–3.
(<a href="https://doi.org/10.1007/s10710-025-09507-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {Pappa, Gisele L. and Giacobini, Mario and Hu, Ting and Jakobović, Domagoj},
  doi          = {10.1007/s10710-025-09507-8},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Editorial introduction for the special issue on highlights of genetic programming 2023 events},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constraining genetic symbolic regression via semantic
backpropagation. <em>GPEM</em>, <em>26</em>(1), 1–31. (<a
href="https://doi.org/10.1007/s10710-025-09510-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary symbolic regression approaches are powerful tools that can approximate an explicit mapping between input features and observation for various problems. However, ensuring that explored expressions maintain consistency with domain-specific constraints remains a crucial challenge. While neural networks are able to employ additional information like conservation laws to achieve more appropriate and robust approximations, the potential remains unrealized within genetic algorithms. This disparity is rooted in the inherent discrete randomness of recombining and mutating to generate new mapping expressions, making it challenging to maintain and preserve inferred constraints or restrictions in the course of the exploration. To address this limitation, we propose an approach centered on semantic backpropagation incorporated into the Gene Expression Programming (GEP), which integrates domain-specific properties in a vector representation as corrective feedback during the evolutionary process. By creating backward rules akin to algorithmic differentiation and leveraging pre-computed subsolutions, the mechanism allows the enforcement of any constraint within an expression tree by determining the misalignment and propagating desired changes back. To illustrate the effectiveness of constraining GEP through semantic backpropagation, we take the constraint of physical dimension as an example. This framework is applied to discover physical equations from the Feynman lectures. Results have shown not only an increased likelihood of recovering the original equation but also notable robustness in the presence of noisy data.},
  archive      = {J_GPEM},
  author       = {Reissmann, Maximilian and Fang, Yuan and Ooi, Andrew S. H. and Sandberg, Richard D.},
  doi          = {10.1007/s10710-025-09510-z},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {Constraining genetic symbolic regression via semantic backpropagation},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RSCID: Requirements selection considering interactions and
dependencies. <em>GPEM</em>, <em>26</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s10710-025-09511-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Requirements selection is one of the essential aspects of requirement engineering. So far, a lot of work has been done in this field. But, it is difficult to choose the right set of software requirements, taking into account their interactions and dependencies and only a few researches have paid attention to interactions and dependencies between requirements. However, in this paper, an attempt has been made to provide a method by considering interactions and dependencies between requirements. To better manage these features, we have also improved the search-based methods used in this area. According to the proposed method called RSCID, before choosing the optimized subset of requirements, dependencies between requirements are extracted. In  the next step, an algorithm is proposed based on the NSGA-II method. In this algorithm, a hybrid fitness function is introduced in addition to two other functions that are used. To tradeoff between cost and value functions, user interactions are also deployed. Another algorithm is used in this paper to choose an appropriate requirements subset, the combination of the NSGA-II method and a genetic algorithm to obtain three fitness functions. The results of the proposed methods have been compared to other methods based on the evaluation criteria in this field. The experiments show the efficiency of the proposed methods to select efficient and useful requirements.},
  archive      = {J_GPEM},
  author       = {Keyvanpour, Mohammad Reza and Karimi Zandian, Zahra and Sodagari, Elham},
  doi          = {10.1007/s10710-025-09511-y},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {RSCID: Requirements selection considering interactions and dependencies},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of “symbolic regression” by gabriel kronberger,
bogdan burlacu, michael kommenda, stephan m. Winkler, and michael
affenzeller, ISBN 978-1-138-05481-3, 2024, CRC press. <em>GPEM</em>,
<em>26</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s10710-025-09513-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_GPEM},
  author       = {La Cava, William G},
  doi          = {10.1007/s10710-025-09513-w},
  journal      = {Genetic Programming and Evolvable Machines},
  month        = {6},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Genet. Program. Evol. Mach.},
  title        = {A review of “Symbolic regression” by gabriel kronberger, bogdan burlacu, michael kommenda, stephan m. winkler, and michael affenzeller, ISBN 978-1-138-05481-3, 2024, CRC press.},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijcis---68">IJCIS - 68</h2>
<ul>
<li><details>
<summary>
(2025a). Image registration using the arithmetic optimization
algorithm for robotic visual servoing. <em>IJCIS</em>, <em>18</em>(1),
1–12. (<a href="https://doi.org/10.1007/s44196-024-00612-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual servoing using image registration is a method employed in robotics to control the movement of a system using visual information. In this context, we propose a new intensity-based image registration algorithm (IBIR) that uses information derived from images acquired at different times or from different views to determine the parameters of the geometric transformations needed to align these images. The Arithmetic Optimization Algorithm (AOA) is used to optimize these parameters, minimizing the difference between the images to be aligned. The proposed algorithm, Intensity-Based Image Registration via Arithmetic Optimisation Algorithm (IBIRAOA), is robust to image data fluctuations and perturbations and can avoid local optima. Simulation results prove the importance and efficiency of the proposed algorithm in terms of computation time and similarity of aligned images compared to other methods based on various metaheuristics. In addition, our results confirm a significant improvement in the trajectory of the wheeled mobile robot, thus reinforcing the overall effectiveness of our method in practical navigation and robotic control applications.},
  archive      = {J_IJCIS},
  author       = {Kmich, Mohamed and Harrade, Inssaf and Karmouni, Hicham and Sayyouri, Mhamed and Askar, S. S. and Abouhawwash, Mohamed},
  doi          = {10.1007/s44196-024-00612-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Image registration using the arithmetic optimization algorithm for robotic visual servoing},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MORKO: A multi-objective runge–kutta optimizer for
multi-domain optimization problems. <em>IJCIS</em>, <em>18</em>(1),
1–34. (<a href="https://doi.org/10.1007/s44196-024-00714-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current landscape, there is a rapid increase in the creation of new algorithms designed for specialized problem scenarios. The performance of these algorithms in unfamiliar or practical settings often remains untested. This paper presents a new development, the multi-objective Runge–Kutta optimizer (MORKO), which is built upon the principles of elitist non-dominated sorting and crowding distance. The goal is to achieve superior efficiency, diversity, and robustness in solutions. MORKO effectiveness is further enhanced by incorporating various strategies that maintain a balance between diversity and execution efficiency. This approach not only directs the search toward optimal regions but also ensures that the process does not become stagnant. The efficiency of MORKO is compared against renowned algorithms like the multi-objective marine predicator algorithm (MOMPA), multi-objective gradient-based optimizer (MOGBO), multi-objective evolutionary algorithm based on decomposition (MOEA/D), and non-dominated sorting genetic algorithm (NSGA-II) on several test benchmarks such as ZDT, DTLZ, constraint (CONSTR, TNK, SRN, BNH, OSY and KITA) and real-world engineering design (brushless DC wheel motor, safety isolating transformer, helical spring, two-bar truss, welded beam, disk brake, tool spindle and cantilever beam) problems. We used unique, non-overlapping performance metrics for this comparison and suggested a fresh correlation analysis technique for exploration. The MORKO algorithm outcomes were rigorously tested and confirmed using the non-parametric statistical evaluations. The MORKO algorithm proves to excel in deriving comprehensive and varied solutions for many tests and practical challenges, owing to its multifaceted features. Looking ahead, MORKO has potential applications in complex engineering and management tasks.},
  archive      = {J_IJCIS},
  author       = {Kalita, Kanak and Jangir, Pradeep and Pandya, Sundaram B. and Alzahrani, Ahmed Ibrahim and Alblehai, Fahad and Abualigah, Laith and Ezugwu, Absalom E.},
  doi          = {10.1007/s44196-024-00714-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MORKO: A multi-objective Runge–Kutta optimizer for multi-domain optimization problems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective particle swarm optimization with integrated
fireworks algorithm and size double archiving. <em>IJCIS</em>,
<em>18</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s44196-024-00722-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-objective particle swarm optimization (MOPSO) is an optimization technique that mimics the foraging behavior of birds to solve difficult optimization problems. MOPSO is well known for its strong global search capability, which efficiently locates solutions that are close to the global optimum across a wide search domain. However, similar to many other optimization algorithms, the fast convergence property of MOPSO can occasionally lead to the population entering the local optimum too soon, obstructing researchers from investigating more efficient solutions. To address this challenge, the study proposes a novel framework that integrates the fireworks algorithm (FA) into MOPSO and establishes a size-double archiving mechanism to maintain population diversity. By preventing population homogenization, this mechanism promotes the retention of better solutions. Additionally, by fusing evolutionary data analysis with particle information, the study offers new individual optimal choices and adaptive parameter tuning to improve the algorithm’s robustness and adaptability and better manage the complexity of multi-objective optimization problems (MOPs). The suggested algorithm is compared with several existing MOPSOs and multi-objective evolutionary algorithms (MOEAs) in simulation experiments. Standard test problems like ZDT, UF, and DTLZ are used in the experiments. The new algorithm performs exceptionally well in terms of improving convergence and population diversity, as well as demonstrating significant competitiveness for solving MOPs.},
  archive      = {J_IJCIS},
  author       = {Zhang, Yansong and Liu, Yanmin and Zhang, Xiaoyan and Song, Qian and Ouyang, Aijia and Yang, Jie},
  doi          = {10.1007/s44196-024-00722-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Multi-objective particle swarm optimization with integrated fireworks algorithm and size double archiving},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock market prediction based multi-attribute decision
making model using picture fuzzy <span
class="math display"><em>Ẑ</em></span> -information. <em>IJCIS</em>,
<em>18</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s44196-024-00664-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As demonstrated in the section above, the stock market place is a dynamic factor, which makes it possible for traders and investors to make good decisions based on the information acquired through accurate prediction. This research aims at improving the prediction of stock market by applying a new method to Multi-attribute Group Decision making (MAGDM). MAGDM goes through a cycle of evaluating and ranking several criteria hence enhancing the decision-making aspects further. To overcome the shortcomings of prior models, some EU and FU is incorporated by combining Zadeh’s $${\hat{Z}}$$ -numbers with Picture Fuzzy Sets (PFSs). This integration is to enhance the ability of the model to address completely unclear decisions utilizing the peculiarities of $${\hat{Z}}$$ -numbers. To compare decisions between decision-makers, we proposed picture fuzzy $${\hat{Z}}$$ -numbers (PF $${\hat{Z}}$$ N) and for their aggregation, introduced picture fuzzy weighted averaging, picture fuzzy ordered weighted averaging, picture fuzzy hybrid averaging, picture fuzzy weighted geometric, picture fuzzy ordered weighted geometric and picture fuzzy hybrid geometric operators based algebraic $${\mathfrak {T}}$$ -norm ( $${\mathfrak {T}}-N$$ ) and $${\mathfrak {T}}$$ -conorm ( $${\mathfrak {T}}-CNs$$ ) To verify the efficiency of our suggested technique, we compare these operators with the Combined Compromised Solution (CoCoSo) model focusing on the stock market analysis. Our results, therefore, show how these operators are important in improving decision making accuracy and precision in conditions of risk. This research laid down the basis for enhancing decision-making and dealing with uncertainty in different fields especially in the application of stock market prediction. The proposed methodology can be attributed to providing a systematic and a more efficient way of dealing with uncertainty which in one way or the other has an outcome of enhancing the credibility of the decision making process in the financial sector.},
  archive      = {J_IJCIS},
  author       = {Ashraf, Shahzaib and Khalid, Amna and Batool, Bushra and Tlija, Mehdi and Jana, Chiranjibe and Pamucar, Dragan},
  doi          = {10.1007/s44196-024-00664-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Stock market prediction based multi-attribute decision making model using picture fuzzy $${\hat{Z}}$$ -information},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid dynamic harris hawks optimized gated
recurrent unit approach for breast cancer prediction. <em>IJCIS</em>,
<em>18</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00712-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The breast cancer (BC) prediction is improved through the machine learning (ML) techniques. In this study, we develop an innovative forecasting framework called the Dynamic Harris Hawks Optimized Gated Recurrent Unit (DHH-GRU) for the prediction of BC. It combines the Gated Recurrent Unit (GRU) and Harris Hawks Optimization (HHO) methods. We gathered data and a training set that included the Wisconsin diagnostic BC (WDBC) dataset, which contains 569 patients with malignant and beginning cases. The collected data were pre-processed using min–max normalization, and important features were extracted by Fast Fourier transform (FFT) and the process of reducing the dimensionality with principal component analysis (PCA). Decimal scaling is employed to equalize the various feature effects. The proposed DHH-GRU technique incorporated the GRU for capturing sequential connections on temporal medical information, and the optimization process, DHH optimization, is utilized. The proposed method&#39;s effectiveness is compared and estimated with various existing techniques in terms of log-loss (0.06%), accuracy (98.05%), precision (98.09%), F1-score (98.28%), and recall (98.15%). The proposed DHH-GRU method has a more predictive ability with the sequential dependency in capturing GRU and DHH optimization’s combined behaviour of hunting. This method significantly improved the accuracy of BC prediction.},
  archive      = {J_IJCIS},
  author       = {Natarajan, Rajesh and Krishna, Sujatha and Gururaj, H. L. and Flammini, Francesco and Alfurhood, Badria Sulaiman and Kumar, C. M. Naveen},
  doi          = {10.1007/s44196-024-00712-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel hybrid dynamic harris hawks optimized gated recurrent unit approach for breast cancer prediction},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive ensemble learning model-based binary white shark
optimizer for software defect classification. <em>IJCIS</em>,
<em>18</em>(1), 1–51. (<a
href="https://doi.org/10.1007/s44196-024-00716-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software dominates modern enterprises, affecting numerous functions. Software firms constantly experiment with new methodologies to define and assess software quality to stay competitive and ensure excellence. Software engineering uses fundamentals and cutting-edge technology to develop great software. In recent decades, Data-mining techniques and machine learning for classifying problematic software projects have emerged to improve software quality. ML approaches, especially ensemble learning models, are becoming fundamental to software engineers’ daily jobs. This work created a binary white shark optimizer (WSO) to optimize standard ensemble learning models. The objective is to identify the most suitable ensemble number for weak learners to maximize accuracy on benchmark datasets. The EM model uses 14 weak learners. Twenty-one experimental runs are performed on 15 software-defective module datasets. The optimized ensemble model outperforms the standard Ensemble learning model in AUC-ROC, Accuracy, Precision, Recall, F1-Score, and Specificity. The enhanced model has an average accuracy of 86%, compared to 76% for the standard ensemble model across all datasets. The optimized model outperformed the conventional ensemble for the same datasets, with an average AUC of 72% compared to 61% for the standard ensemble. The optimized model was more stable than the standard model, with an STD of 5.53E−03 vs 7.24E−02 for the ensemble model. The WSO optimization process strengthens and generalizes optimizeels. The study suggests that evolutionary metaheuristic approaches can enhance EM models’ accuracy, trustworthiness, and adaptability.},
  archive      = {J_IJCIS},
  author       = {Saraireh, Jameel and Agoyi, Mary and Kassaymeh, Sofian},
  doi          = {10.1007/s44196-024-00716-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-51},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Adaptive ensemble learning model-based binary white shark optimizer for software defect classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Properties and applications of neutrosophic burr XII
distribution. <em>IJCIS</em>, <em>18</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s44196-024-00721-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Primarily, when the hazards function has intricate structures, the BrXII distribution is an established framework for lifetime data analysis. However, classical probability models are limited in the sense that they cannot measure or record the data in exactness fueling the notion of indeterminacy in data collection process. This study addresses this issue by proposing the idea of neutrosophic BrXII (NeS-BrXII) distribution. The primary objective is to study the statistical properties of the proposed model by providing explicit expressions of reliability properties, the expression of moments and generating function, expression of order statistics, mean residual life, mean inactivity time, stochastic ordering, income inequality measures, and entropy in neutrosophic realm. In addition, the neutrosophic model parameters are estimated using the principle of maximum-likelihood estimation. Further, the precision of these model estimates is verified via a simulation study of the proposed model. Applying the model on two real-world material sciences data sets reinforces its efficacy with the NeS-BrXII distribution proving to be more suitable for managing anomalies in neutrosophic surface analysis among other models.},
  archive      = {J_IJCIS},
  author       = {Al-Essa, Laila A. and Jamal, Farrukh and Shafiq, Shakaiba and Khan, Sadaf and Abbas, Qamer and Khan Sherwani, Rehan Ahmad and Aslam, Muhammad},
  doi          = {10.1007/s44196-024-00721-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Properties and applications of neutrosophic burr XII distribution},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). A two-way crossed effects fuzzy panel linear regression
model. <em>IJCIS</em>, <em>18</em>(1), 1–10. (<a
href="https://doi.org/10.1007/s44196-024-00723-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last two decades, the panel data model has become a focus of applied research. While there are numerous proposals for soft regression models in the literature, only a few linear regression models have been proposed based on fuzzy panel data. However, these models have serious limitations. This study is an attempt to propose a kind of two-way fuzzy panel regression model with crossed effects, fuzzy responses and crisp predictors to overcome the shortcomings of these models in real applications. The corresponding parameter estimation is provided based on a three-step procedure. For this purpose, the conventional least absolute error technique is employed. Two real data sets are analyzed to investigate the fitting and predictive capabilities of the proposed fuzzy panel regression model. These real data applications demonstrate that our proposed model has good fitting accuracy and predictive performance.},
  archive      = {J_IJCIS},
  author       = {Hesamian, Gholamreza and Johannssen, Arne},
  doi          = {10.1007/s44196-024-00723-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-10},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A two-way crossed effects fuzzy panel linear regression model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: A model for estimating resiliency of AI-based
classifiers defending against cyber attacks. <em>IJCIS</em>,
<em>18</em>(1), 1. (<a
href="https://doi.org/10.1007/s44196-024-00725-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Barik, Kousik and Misra, Sanjay and Fernandez-Sanz, Luis},
  doi          = {10.1007/s44196-024-00725-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: A model for estimating resiliency of AI-based classifiers defending against cyber attacks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel conflict deduction algorithm based on contradiction
separation inference rule. <em>IJCIS</em>, <em>18</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-024-00726-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated reasoning, a significant field within artificial intelligence, has attracted increased attention in recent years due to the rising demand for trustworthy AI. Binary resolution, among other inference rules, is crucial in automated reasoning of first-order logic, including the new conflict resolution method. Conflict resolution processes only two clauses in each deduction step and eliminates a complementary pairs of literals from input clauses. This paper proposes a contradiction separation conflict deduction (CSCD) method based on the contradiction separation rule to address these limitations. This novel resolution methodology, together with its automated reasoning theory and method, handles several clauses in each deduction step to seek for conflicts and generates learnt clauses through synergized deduction. Thus, the approach improves deduction by detecting conflicts more effectively, especially with lengthier input clauses. CSCD and conflict resolution are analyzed in detail, then how to create a practical CSCD algorithm and its implementation is summarized. We tested the CSCD algorithm to solve the CASC-26 problems and also applied it to the current leading ATP system (Eprover). Experimental results show that the CSCD deduction approach improves reasoning capability of conflict deduction method. Additionally, the Eprover with the proposed CSCD algorithm improves its performance and has solved various problems with a rating of 1 from the benchmark database TPTP.},
  archive      = {J_IJCIS},
  author       = {Guo, Hailin and Cao, Feng and Yi, Jianbing and Wu, Guanfeng and Li, Weicai},
  doi          = {10.1007/s44196-024-00726-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel conflict deduction algorithm based on contradiction separation inference rule},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing FACTS device placement using the fata morgana
algorithm: A cost and power loss minimization approach in uncertain load
scenario-based systems. <em>IJCIS</em>, <em>18</em>(1), 1–38. (<a
href="https://doi.org/10.1007/s44196-024-00727-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, reliable power delivery and increasing demand are important issues in modern power systems. Flexible Alternating Current Transmission Systems (FACTS) devices are used to control transmission line parameters to increase power transfer and stability. Nevertheless, the problem of determining the optimal placement and sizing of these devices is still challenging, as the placement and sizing of the devices affects generation costs, power losses, voltage stability, and system reliability. This study proposes the Fata Morgana Algorithm (FATA), an optimization algorithm inspired by the natural process of mirage formation to optimize placement and sizing of FACTS devices in an IEEE 30 bus system with wind turbine integration. The FATA algorithm is evaluated against recently developed and improved optimization techniques, such as rime-ice formation phenomenon based Improved RIME (IRIME) Algorithm, Newton–Raphson-Based Optimization (NRBO), Resistance Capacitance Algorithm (RCA), Krill Optimization Algorithm (KOA), and Grey Wolf Optimizer (GWO), across multiple optimization objectives: reduction in generation cost, reduction in power loss and combined generation cost plus power loss, termed as Gross cost function. Results obtained show that FATA consistently outperforms the other algorithms in terms of convergence and solution quality, offering a robust approach to solving single objective optimization problems. FATA theoretically provides a good balance between exploration and exploitation, and produces better global solutions. It practically increases power system efficiency by lowering operational costs and losses and improving stability. Results indicate that the FATA algorithm produced minimum generation cost of 807.0405 $/h, which is 0.088–0.426% less than the competing algorithms. It also reduced power losses to 5.5917 MW, which is 1.095–6.781% less than other methods. For gross cost minimization, the FATA algorithm achieved a minimum gross cost of 1366.3727 $/h, which is 0.4799% better than the next best algorithm and 3.2261% better than the worst. The results also show that FATA is robust in solving complex optimization problems in power systems, and it provides significant improvements in run time and convergence efficiency. The main advantage for readers is that FATA provides a reliable and efficient way to optimize power systems. Future work could also investigate the application of FATA in real time, as well as in larger power networks with more renewable energy sources.},
  archive      = {J_IJCIS},
  author       = {Aljaidi, Mohammad and Jangir, Pradeep and Agrawal, Sunilkumar P. and Pandya, Sundaram B. and Parmar, Anil and Alkoradees, Ali Fayez and Arpita and Smerat, Aseel},
  doi          = {10.1007/s44196-024-00727-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimizing FACTS device placement using the fata morgana algorithm: A cost and power loss minimization approach in uncertain load scenario-based systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time facial expression recognition based on image
processing in virtual reality. <em>IJCIS</em>, <em>18</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-024-00729-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More virtual reality (VR) scenarios have become more prevalent in recent years. More and more people are getting into VR, meaning that objective physiological measures to assess a user&#39;s emotional state automatically are becoming more critical. Individuals’ emotional states impact their behaviour, opinions, emotions, and decisions. They may be used to analyze VR experiences and make systems react to and engage with the user’s emotions. VR environments require users to wear head-mounted displays (HMDs), blocking off their upper faces. That makes traditional Facial Expression Recognition (FER) approaches very limited in their usefulness. Thus, a Deep Learning (DL) solution combined with image processing is utilized to classify universal emotions: sadness, happiness, disgust, anger, fear and surprise. Hence, this paper suggests the Deep Automatic Facial Expression Recognition Model (DAFERM) for interactive virtual reality (VR) applications such as intelligent education, social networks, and virtual training. Two main parts comprise the system: one that uses deep neural networks (DNNs) for facial emotion identification and another that automatically tracks and segments faces. The system begins by following a marker on the front of the head-mounted display (HMD). With the help of the spatial data that has been retrieved, the positions and rotations of the face are estimated to segment the mouth. Finally, the system interacts with DNN using the pixels processed by the lips. It obtains the facial expression results in real time using an adaptive method for histogram-based mouth segmentation.},
  archive      = {J_IJCIS},
  author       = {Gong, Qingzhen and Liu, Xuefang and Ma, Yongqiang},
  doi          = {10.1007/s44196-024-00729-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Real-time facial expression recognition based on image processing in virtual reality},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized novel text embedding approach for fake news
detection on twitter x: Integrating social context, temporal dynamics,
and enhanced interpretability. <em>IJCIS</em>, <em>18</em>(1), 1–36. (<a
href="https://doi.org/10.1007/s44196-024-00730-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of widespread misinformation, detecting fake news has become a crucial challenge, particularly on social media platforms. This paper introduces an optimized approach for Fake News Detection, combining BERT and GloVe embeddings with Principal Component Analysis (PCA) and attention mechanisms, enriched by social and temporal features for more effective text representation. Leveraging the CIC Truth Seeker Dataset 2023, we applied SHAP for feature selection and interpretability, ensuring transparency in the model’s predictions. Our methodology achieved a remarkable accuracy of 99.9% using a Random Forest classifier, showcasing the efficacy of this optimized hybrid approach. The integration of interpretability techniques such as LIME and SHAP provides deeper insights into the model’s decisions, making it a reliable tool for combating misinformation. This novel approach offers a robust and transparent solution to the growing threat of fake news, contributing significantly to the integrity of online information and public discourse on platforms like Twitter X.},
  archive      = {J_IJCIS},
  author       = {AlJamal, Mahmoud and Alquran, Rabee and Alsarhan, Ayoub and Aljaidi, Mohammad and Al-Jamal, Wafa’ Q. and Alkoradees, Ali Fayez},
  doi          = {10.1007/s44196-024-00730-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimized novel text embedding approach for fake news detection on twitter x: Integrating social context, temporal dynamics, and enhanced interpretability},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-driven optimized chaotic encryption scheme for
medical image transmission in IoT-edge environment. <em>IJCIS</em>,
<em>18</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s44196-024-00731-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) is adopted in a wide spectrum of applications in which a vast amount of data are produced and distributed to centralized cloud platforms to deliver various services. It involves smart devices that collect thousands of terabytes of heterogeneous data and deployed this to make instant decision that aids for the better performance and most comfort life. Traditional IoT architecture is heavily centralized, where it stores the most sensitive information that creates the multiple threats and security breaches as the attackers target towards these centralized cloud systems. To improve the security chain in IoT environment, edge computing (EC) was introduced to distribute the applications of IoT at the edge of the communication networks. However, these edge-based IoT are also vulnerable to many threats due to their decentralized and in secured management. Block chain (BC) technology offers a most trusted solution to resolve the security issues in the IoT-Edge computing environment. This research study presents the block chain driven medical image encryption technique using modified honey badger optimization with the ensemble chaotic systems. The proposed block chain framework uses the divergent methods that integrates differential scroll, Hénon chaotic maps and modified honey badger optimization to generate the optimum keys and high secured image data. These high secured data are stored in the block chain, ensuring the image security to be stored in edge nodes. The complete framework was experimented using Ethereum using Ganache API and Python3.19 are utilized as the major programs for designing the varied interfaces of the recommended model. The comprehensive experimentation is undertaken to assess the security strength of the recommended encryption scheme. The evaluation metrics like as NACI, UACI, Entropy and standard verification methods such as NIST standard tests are deployed and analyzed. To prove it security strength, proposed secured BC framework is compared with the wide-variety of secured frameworks. The experimental findings reveal that the suggested framework establishes a more robust and secure environment for image exchange, surpassing the performance of other blockchain-based systems in terms of integrity, robustness and security. Finally, the paper spreads the bright light of advantages in deploying the proposed framework to formulate the most secured environment in the IoT-Edge environment for medical image transmission.},
  archive      = {J_IJCIS},
  author       = {Archana, Goli and Goyal, Rajeev and Kumar, K. M. V. Madan},
  doi          = {10.1007/s44196-024-00731-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Blockchain-driven optimized chaotic encryption scheme for medical image transmission in IoT-edge environment},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing stock portfolio selection with trapezoidal bipolar
fuzzy VIKOR technique with boruta-GA hybrid optimization model: A
multicriteria decision-making approach. <em>IJCIS</em>, <em>18</em>(1),
1–30. (<a href="https://doi.org/10.1007/s44196-025-00733-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The investors’ main objective is to minimize the risks and to get the maximum returns in the random stock market requires them to choose the correct mix of the stocks. The traditional portfolio selection methods often struggle with market volatility, leading to less-than-the targeted profits. This research attempts to apply trapezoidal bipolar fuzzy Vise Kriterijumska Optimizacija I Kompromisno Resenje (VIKOR) method to help in decision-making. It also combines the fuzzy set theory with the VIKOR method, the trapezoidal bipolar fuzzy with VIKOR (TrBFV) approach offers a comprehensive and flexible system for evaluating investment options. The proposed approach has been validated through real-world illustrations. The analysis has been made with the VIKOR method and its integration with trapezoidal bipolar fuzzy sets. Financial decision-making can be very hard for investors who have access to big data due to the overwhelming amount of information they are required to interpret. The Boruta-GA approach combines the advantages of the Genetic Algorithm (GA) and Boruta Optimization Algorithm (BOA) methods, implementing the comprehensive feature selection capability of Boruta to detect all relevant features and harnessing the strength of GA to bring about improvement within a wide range of datasets. The result shows that this novel approach is effective and can help to investors to take decisions in the unpredictable financial market. This study is an attempt to provides investors with an appropriate approach to navigate the challenges of stock market investment. Abbreviations serve as a nomenclature table, detailing all acronyms.},
  archive      = {J_IJCIS},
  author       = {Sharma, Sunil Kumar},
  doi          = {10.1007/s44196-025-00733-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing stock portfolio selection with trapezoidal bipolar fuzzy VIKOR technique with boruta-GA hybrid optimization model: A multicriteria decision-making approach},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). Publisher correction: Image registration using the
arithmetic optimization algorithm for robotic visual servoing.
<em>IJCIS</em>, <em>18</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s44196-025-00735-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Kmich, Mohamed and Harrade, Inssaf and Karmouni, Hicham and Sayyouri, Mhamed and Askar, S. S. and Abouhawwash, Mohamed},
  doi          = {10.1007/s44196-025-00735-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Publisher correction: Image registration using the arithmetic optimization algorithm for robotic visual servoing},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal sizing and techno-economic analysis of combined
solar wind power system, fuel cell and tidal turbines using
meta-heuristic algorithms: A case study of lavan island. <em>IJCIS</em>,
<em>18</em>(1), 1–28. (<a
href="https://doi.org/10.1007/s44196-025-00737-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Combined renewable energy sources (RESs) are emerging as a competitive alternative to conventional energy production facilities due to their sustainability and zero-emission characteristics. However, determining the optimal system size is complicated by two major challenges: the cost of energy (COE) and the intermittent nature of RESs. This study introduces a novel mathematical approach to optimize the sizing of photovoltaic (PV), wind, hydrogen, battery, and fuel cell systems with electrolyzers, specifically tailored for the remote area of Lavan Island. The proposed method aims to deliver electricity without reliance on the traditional electricity distribution grid, while offering a scalable solution applicable to other geographical regions. The primary objective is to achieve cost-effective electricity generation while ensuring a reliable energy supply through the evaluation of system reliability indices. A fuzzy logic system is employed to minimize the costs of a hybrid system incorporating hydroelectric, wind, solar, and battery technologies, while simultaneously calculating two key reliability metrics: the Loss of Power Supply Probability (LPSP) and the Dump Energy Probability (DEP). To optimize the objective function, this study applies three advanced algorithms: the Shuffled Frog Leaping Algorithm (SFLA), the Grasshopper Optimization Algorithm (GOA), and the Honey Badger Algorithm (HBA). These algorithms are used to determine the global optimum, with comparative analyses conducted to highlight the performance of the proposed approach. The results are evaluated based on statistical metrics, including consistency, execution time, convergence speed, and the minimization of the objective function. The findings demonstrate the superiority and the reliability of the proposed method over alternative approaches, paving the way for cost-efficient and sustainable energy solutions in isolated regions.},
  archive      = {J_IJCIS},
  author       = {Talebi, Hessameddin and Nikoukar, Javad and Gandomkar, Majid},
  doi          = {10.1007/s44196-025-00737-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimal sizing and techno-economic analysis of combined solar wind power system, fuel cell and tidal turbines using meta-heuristic algorithms: A case study of lavan island},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic graph convolutional network relation extraction
model combining dependency syntax and contrastive learning.
<em>IJCIS</em>, <em>18</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s44196-025-00738-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In current relation extraction tasks, when the input sentence structure is complex, the performance of in-context learning methods based on large language model is still lower than that of traditional pre-train fine-tune models. For complex sentence structures, dependency syntax information can provide effective prior text structure information for relation extraction. However, most studies are affected by the noise in the syntactic information automatically extracted by natural language processing toolkits. Additionally, traditional pre-training encoders have issues such as an overly centralized representation of word embedding for high-frequency words, which adversely affects the model to learn contextual semantic information. To address proposed problem, the paper proposes a Hyperbolic Graph Convolutional Network Relation Extraction Model Combine Dependency Syntax and Contrastive Learning. Based on the hyperbolic graph neural network, dependent syntactic information and information optimization strategies are introduced to solve the problem of word embedding concentration. Simultaneously, to mitigate the impact of noise in dependency syntax information on the relation extraction task, a contrastive learning approach is employed. After the model learns context semantics separately in the original dependency syntax information and dependency syntax information with added random noise, it maximizes the mutual information between entity words to assist the model in distinguishing noise in dependency syntax. The experiments indicate that the proposed model in this paper can effectively enhance the performance of relation extraction on public datasets, especially achieving significantly higher precision on datasets with complex sentence structures compared to in-context learning.},
  archive      = {J_IJCIS},
  author       = {Li, Jinzhe},
  doi          = {10.1007/s44196-025-00738-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hyperbolic graph convolutional network relation extraction model combining dependency syntax and contrastive learning},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced LSTM approach for detecting IoT-based DDoS
attacks using honeypot data. <em>IJCIS</em>, <em>18</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-025-00741-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the widening perils in network security is the Distributed Denial of Service (DDoS) attacks on the Internet of Things (IoT) ecosystem. This paper presents an enhanced Intrusion Detection System (IDS) through the proposal of an enhanced version of the long short-term memory (LSTM) model to detect DDoS attacks using honeypot-generated data. The proposed model aggregates the Conv1D, Bidirectional Long Short-Term Memory (Bi-LSTM), Bidirectional Gated Recurrent Unit (Bi-GRU), and dropout layers to extract temporal and spatial features from IoT traffic effectively. We tested the efficacy of the proposed system on a real-world IoT-DH dataset, which showed a remarkable accuracy of 99.41%, with an AUC score of 0.9999. A comparative analysis with other baseline models, such as LSTM, Bidirectional LSTM (Bi-LSTM), Gated Recurrent Unit (GRU), Recurrent Neural Network (RNN), Feedforward Neural Network (FNN), and Temporal Convolutional Network (TCN), proved that enhanced LSTM outperformed the other models. This indicates the robustness of the proposed model in correctly detecting DDoS attacks with high generalization capability for unseen traffic data. The contribution of this paper will be an addition to the deep learning techniques applied for the solution of intrusion detection systems (IDS), which will also allow the building and implementation of more efficient security mechanisms in IoT environments.},
  archive      = {J_IJCIS},
  author       = {Arnob, Arjun Kumar Bose and Mridha, M. F. and Safran, Mejdl and Amiruzzaman, Md and Islam, Md. Rajibul},
  doi          = {10.1007/s44196-025-00741-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An enhanced LSTM approach for detecting IoT-based DDoS attacks using honeypot data},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). ExAIRFC-GSDC: An advanced machine learning-based
interpretable framework for accurate gas leakage detection and
classification. <em>IJCIS</em>, <em>18</em>(1), 1–33. (<a
href="https://doi.org/10.1007/s44196-025-00742-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas leakage detection is imperative in various sectors, including chemical industries, coal mines, and household applications. The escalating number of accidents in coal mines, chemical industries, and homes underscores the urgency of swift and accurate gas detection methods. This research focuses on developing advanced systems that promptly identify gas types to prevent harm to human lives and the environment. This paper addresses the challenges of gas leakage detection and classification in diverse environments, such as industrial, residential, and mining scenarios. The proposed ExAIRFC-GSDC model integrates machine learning algorithms, particularly a Random Forest Classifier, with explainable artificial intelligence (XAI) techniques to enhance interpretability. This study employs a dataset comprising gas sensor measurements that encompassing gasses, such as Liquid Petroleum Gas (LPG), Compressed Natural Gas (CNG), Methane, Propane, and others. Various machine learning classifiers, including K-Nearest Neighbors, Decision Tree, Support Vector Machines, XGBoost, and others, are compared with ExAIRFC-GSDC for gas detection. The model demonstrates superior performance, achieving an accuracy rate of 98.67%. Incorporating SHAP and LIME explanations enhances the model&#39;s interpretability, providing insights into the contributions of individual sensors. Statistical analysis confirms the significant differences in sensor readings across different gas types. ExAIRFC-GSDC is a robust and explainable solution for accurate gas detection and classification in complex environments.},
  archive      = {J_IJCIS},
  author       = {Lalithadevi, B. and Krishnaveni, S.},
  doi          = {10.1007/s44196-025-00742-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {ExAIRFC-GSDC: An advanced machine learning-based interpretable framework for accurate gas leakage detection and classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BERT-BiGRU-senti-GCN: An advanced NLP framework for
analyzing customer sentiments in e-commerce. <em>IJCIS</em>,
<em>18</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-025-00747-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis plays an important role in understanding employee feedback and improving workplace culture. By leveraging NLP techniques to analyze this feedback accurately, organizations can pinpoint specific areas that need improvement, address employee concerns, and foster a positive work environment. These NLP-driven deep learning models offer valuable tools for E-Commerce HR and sales departments, enabling monitoring employee and users’ sentiment trends over time and assisting in implementing targeted interventions. Focusing on the e-commerce industry, this work utilizes NLP-driven deep learning methodologies to analyze employee and user feedback, aiming to identify sentiments. The proposed NLP-driven, deep learning-based framework is designed to classify user feedback into positive, negative, or neutral sentiments. The key steps in this framework include data collection, NLP-enhanced feature extraction using BERT-BiGRU, and final classification using a Graph Neural Network-based finite-state automata. The effectiveness of this NLP-centric approach was tested on diverse datasets of customer feedback from the e-commerce industry. The results demonstrate the framework’s efficacy, achieving an impressive 93.35% accuracy rate, surpassing existing benchmark methods. The research significantly benefits e-commerce by refining product portfolios and enhancing workplace culture.},
  archive      = {J_IJCIS},
  author       = {Rana, Muhammad Rizwan Rashid and Nawaz, Asif and Rehman, Saif Ur and Abid, Muhammad Ali and Garayevi, Mubariz and Kajanová, Jana},
  doi          = {10.1007/s44196-025-00747-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {BERT-BiGRU-senti-GCN: An advanced NLP framework for analyzing customer sentiments in E-commerce},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of hybrid intrusion detection system leveraging
ensemble stacked feature selectors and learning classifiers to mitigate
the DoS attacks. <em>IJCIS</em>, <em>18</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-025-00750-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Denial of service (DoS) attacks occur more frequently with the progressive development of the Internet of things (IoT) and other Internet-based communication technologies. Since these technologies are deeply rooted in the individual’s comfort life, protecting the user’s privacy and security against the growing DoS attack has become a major challenge among researchers. In recent times, intrusion detection systems (IDS) have developed a vital part in ensuring security against these growing attacks. IDS is still unable to attain the optimum categorization performance due to a few bottlenecks. The speed and performance of the existing IDS are challenged by the intricacy of high-dimensional data and the efficacy of the conventional base classifiers. To tackle this aforementioned problem, this research article presents the hybrid IDS based on the combination of stacked feature selection methods such as Random Boruta Selector (RFS), Relief, Pearson coefficient (PCE) and Stacked learning classifiers (SLF). To reduce the dimension of the data features and to select the optimal feature sets, novel integration of RFS, Relief, PCE are deployed. As the final step, stacked classifiers are used for the classification of DoS attacks. All the trials in this framework were accompanied utilizing CICDDoS-2019 datasets and contrasted with the other similar models. The validation boundaries such as accuracy, precision, recall, specificity, and F1-score are used to evaluate the proposed framework. With an F1-score of 96%, accuracy of 96.5%, precision of 96.0%, and recall of 95.8%, the suggested model obtained a CICDDoS-2019 score of 96%. Compared with the other traditional classifiers, the suggested framework has produced the best classification performance in detecting the DoS attacks.},
  archive      = {J_IJCIS},
  author       = {Mamatha, P. and Balaji, S. and Anuraghav, S. Sai},
  doi          = {10.1007/s44196-025-00750-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Development of hybrid intrusion detection system leveraging ensemble stacked feature selectors and learning classifiers to mitigate the DoS attacks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessments of student’s adaptability using convoluted
geyser bidirectional long short-term memory in online education.
<em>IJCIS</em>, <em>18</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-024-00724-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid transition from traditional in-person education to online classrooms has highlighted the need to effectively assess student engagement in virtual learning environments supported by learning management systems. Despite this shift, there remains a significant gap in predictive models that generalize across diverse blended courses, disciplines, and student demographics. Addressing this gap is essential for improving the accuracy and efficiency of predicting student adaptability in online education. To address these issues, this research introduces a novel student adaptability learning model named Convoluted Geyser Bidirectional Long Short-Term Memory (CGBiLSTM) model, designed to predict student adaptability in online entrepreneurship education. This technique has its ability to capture complicated patterns and dependencies in sequential data, which is critical for accurately assessing student adaptability. Furthermore, incorporating the Geyser Optimization Algorithm (GOA) into CGBiLSTM improves the performance by optimizing the learning process and training capabilities, resulting in more accurate and dependable predictions. The CGBiLSTM technique achieves an accuracy of 98.94%, a precision of 99.03%, a recall of 98.71%, and an F1-score of 98.15% proving its efficacy in assessing student adaptability. The CGBiLSTM model, enhanced by the GOA, provides a highly accurate and reliable solution for predicting student adaptability in online education, making it a vital tool for educators in the evolving virtual learning landscape.},
  archive      = {J_IJCIS},
  author       = {Baskar, B. S. Vijaya and Kesavan, Ramesh},
  doi          = {10.1007/s44196-024-00724-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Assessments of student’s adaptability using convoluted geyser bidirectional long short-term memory in online education},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coverage-based variable precision (i, PSO)-fuzzy rough sets
with applications to emergency decision-making. <em>IJCIS</em>,
<em>18</em>(1), 1–33. (<a
href="https://doi.org/10.1007/s44196-024-00728-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the characteristics of imprecise, incomplete and fuzzy data in emergency environment, a novel emergency decision-making method based on coverage-based variable precision (I, PSO)-fuzzy rough set model is proposed. First, an improved (I, PSO)-fuzzy rough set model is proposed, which combines the covering-based fuzzy rough set (CFRS) and the variable precision fuzzy rough set (VPFRS). Second, inspired by the idea of attribute reduction, a novel method for determining attribute weights is introduced to optimize weight assignment in emergency decision-making. Last but not least, to illustrate the feasibility and effectiveness of the proposed method, an example of post-flood rescue force allocation in urban areas is demonstrated. Finally, the stability and superiority of the method are verified through sensitivity analysis and comparative evaluation.},
  archive      = {J_IJCIS},
  author       = {Yin, Ran and Chen, Minge and Wu, Jian and Liu, Yu},
  doi          = {10.1007/s44196-024-00728-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Coverage-based variable precision (I, PSO)-fuzzy rough sets with applications to emergency decision-making},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time athlete fatigue monitoring using fuzzy decision
support systems. <em>IJCIS</em>, <em>18</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-025-00732-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sports scientists worry about fatigue, because it affects performance, increases injury risk, and harms health. Traditional fatigue measurements may miss this complicated and ever-changing state, placing athletes at risk of injury while training. This study tests the premise that cutting-edge, real-time monitoring devices improve athlete health and performance. This research aims to reduce tiredness by developing a Fuzzy Decision Support System for Real-Time Athlete Weariness Monitoring. Fuzzy logic can handle unclear performance data, making it a more flexible and advanced alternative to standard methods. Sports athlete fatigue is complicated and dynamic, requiring improved, more precise, and real-time monitoring approaches. The FDSS-RAFM model uses fuzzy logic to account for human performance and physiology. The FDSS-RAFM model assesses athlete fatigue in a comprehensive and context-aware manner. This study’s findings can help coaches, players, and sports scientists improve training programs, reduce injury risk, and improve performance in ever-changing athletic contexts. Fuzzy decision-support systems and other cutting-edge technology can improve athletes’ health and performance, adding to sports science literature. Experimental results show that the proposed FDSS-RAFM model outperforms competing models in sensitivity (97%), specificity (89%), accuracy (96%), and dynamic adaptation error analysis (2.41%).},
  archive      = {J_IJCIS},
  author       = {Li, Aiqin},
  doi          = {10.1007/s44196-025-00732-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Real-time athlete fatigue monitoring using fuzzy decision support systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced heart disease prediction through spatial and
temporal feature learning with SCN-deep BiLSTM. <em>IJCIS</em>,
<em>18</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s44196-025-00734-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease prediction using machine learning methods faces various challenges, such as low data quality, missing irrelevant values, and underfit and overfit problems, which increase the time complexity and degrade the model&#39;s prediction performance. Moreover, the hybrid models for heart disease prediction showed poor accuracy due to the irrelevancy in the dataset. Therefore, a search optimizer with a deep convolutional neural network coupled with a Deep Bidirectional long short-term memory classifier (SCN-Deep BiLSTM) is proposed to handle the abovementioned issue. The importance of SCN-Deep BiLSTM relies upon establishing the spatial information and temporal features from the ECG signals that support learning while minimizing the computational complexity associated with learning from raw signals.The SCN-Deep BiLSTM model achieves the accuracy, F-score, precision, recall, and critical success index of 0.97, 0.97, 0.98, 0.99, and 0.97, respectively for 80% of model training, whereas the SCN-Deep BiLSTM model attained 0.97, 0.98, 0.96, 0.94, and 0.96 for accuracy, F-score, precision, recall and critical success index, respectively when K-Fold is 10. The performance outcome emphasizes the model’s efficacy and accurate prediction and classification of heart disease.},
  archive      = {J_IJCIS},
  author       = {Pandey, Vivek and Lilhore, Umesh Kumar and Walia, Ranjan},
  doi          = {10.1007/s44196-025-00734-6},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Advanced heart disease prediction through spatial and temporal feature learning with SCN-deep BiLSTM},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of physical education teaching quality based on
hierarchical fuzzy set theory. <em>IJCIS</em>, <em>18</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s44196-025-00736-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of physical education often faces challenges due to inadequate evaluation methods that fail to provide accurate, real-time teaching evaluation. These challenges influence student performance and overall teaching quality. This article introduces a quality assessment method using fuzzy set theory (QAM-FST) to evaluate physical education teaching. The proposed method extracts and classifies all the available teaching data to compute the students&#39; performance over sessions through fuzzy rough set differentiations over partial and complete derivatives. The complete derivatives identify the factors contributing the maximum to the teaching quality, while the partial derivatives acquire the minimal influence factors. These derivatives are clubbed together through the hierarchical process to identify the precise quality impacting factors and least impacting factors to replace or recommend alternate suggestions. The QAM-FST framework offers a comprehensive, data-driven assessment ensuring the enhancement of PE teaching quality. The QAM-FST outperforms three current models in terms of suggestion accuracy (96.8%), assessment time reduction (22.66%), and total performance evaluation efficiency (16.78%). This data-driven platform guarantees improved physical education instruction quality through actionable insights obtained from real-time feedback.},
  archive      = {J_IJCIS},
  author       = {Tang, Chunlong},
  doi          = {10.1007/s44196-025-00736-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Analysis of physical education teaching quality based on hierarchical fuzzy set theory},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An algorithm for extracting features of basketball players’
foul actions based on an attention mechanism. <em>IJCIS</em>,
<em>18</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s44196-025-00743-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Basketball foul action usually involves multiple features, and it is difficult to extract effective features from complex and diverse features. Therefore, a feature extraction algorithm for basketball players&#39; foul action based on attention mechanism is proposed. On the basis of ResNet50 network model, the attention mechanism is integrated to build a basketball player foul action feature extraction model. The machine vision system is used to obtain basketball player action video as the input of the model. The space attention module and time attention module are, respectively, introduced into the video slow frame rate branch and video fast frame rate branch of ResNet50 network. By making the network give greater weight to the key areas of a single frame of video, and improving the network&#39;s attention to important video frames, the best spatio-temporal characteristics of foul actions are obtained. After fusion, the feature fusion results are input into the classifier with the cross-entropy loss function as the loss function, and the probability value of each possible foul action and the tag target probability are output, complete basketball player foul action feature extraction. The experimental results show that the algorithm can effectively identify the identification of basketball players, the cumulative matching feature value of foul action recognition can reach more than 95%, and the average accuracy is more than 70%; the F1 value and stability are high, which can reduce the error caused by data fluctuation and noise; the error rate of real-time detection is less than 4.5%, the omission rate is less than 4.7%, the detection time is lower than 14 ms, and the application effect is good.},
  archive      = {J_IJCIS},
  author       = {Wang, Peng},
  doi          = {10.1007/s44196-025-00743-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An algorithm for extracting features of basketball players&#39; foul actions based on an attention mechanism},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E-commerce live-streaming platform and decision support
system based on fuzzy association rule mining. <em>IJCIS</em>,
<em>18</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-025-00744-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Live streaming of e-commerce platforms attracts consumers for their products/purchases and hence the familiarity is retained high amid different competitors. Fuzzy decision systems are incorporated to filter the streaming content of the platforms to improve consumer augmentations at different promotions. Therefore to support such augmentation and consumer building process, this article proposes a filtered sale streaming model to improve the circulation of new launches and to project the existing products through sustainable promotions. In this process, the comprehensive transition rule for product promotions and sale improvements is defined using fuzzy mining. The fuzzy process introduces the different performance members based on consumer access rate and sale count. The rule modifications are defined using the above factors’ decrease over filtered promotions to boost the augmentation. Using the highest possible member weights over a product, sale, and consumers, the linear improvements between the three factors are estimated over the closure observed at each sale interval. Thus, the streaming modifications and the product exposures are modeled using different mining rules adaptable for e-commerce platforms.},
  archive      = {J_IJCIS},
  author       = {Liao, Hua},
  doi          = {10.1007/s44196-025-00744-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {E-commerce live-streaming platform and decision support system based on fuzzy association rule mining},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal AC power flow with energy storage and renewable
energy: An efficient RL algorithm capable of handling equality
constraints. <em>IJCIS</em>, <em>18</em>(1), 1–38. (<a
href="https://doi.org/10.1007/s44196-025-00745-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using energy storage to solve the multiperiod OPF problem for renewable energy fluctuation is an effective way to increase operation safety and reduce the cost of power systems. However, in solving this OPF problem, model-based methods cannot accurately model uncertain scenarios, while traditional RL methods cannot satisfy the constraints well, and both methods have limitations. Therefore, we propose an RL method, ERL-HC, that does not require scene modelling and can handle general forms of physical constraints. First, a constraint policy network (CPN) is proposed that corrects the output of a neural network on the basis of the inequality generalized reduced gradient (GRG) method; the outputs of this network satisfy all constraints, and it can be trained in an end-to-end manner. Second, the critic network is improved based on the IM method to increase the sample learning efficiency by improving the agent&#39;s understanding of state interdependencies. Finally, the adaptive-tuning Lagrange multiplier method is applied in the AC framework to reduce the number of iterations of the inequality GRG in the CPN and efficiently train ERL-HC. ERL-HC was tested on two systems of different sizes. The results show that ERL-HC has a better learning ability than general safe RL algorithms, overcomes the limitations of mainstream safe RL methods in handling equality constraints, and addresses the poor generalization issues of RL methods that can handle equality constraints.},
  archive      = {J_IJCIS},
  author       = {Liu, Mingde and Zhu, Jianquan and Liu, Mingbo},
  doi          = {10.1007/s44196-025-00745-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimal AC power flow with energy storage and renewable energy: An efficient RL algorithm capable of handling equality constraints},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entropy-weighted TOPSIS-based bird strike risk assessment
for an airport. <em>IJCIS</em>, <em>18</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s44196-025-00746-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To identify the factors with higher bird strike risk at a certain airport, and to provide a theoretical basis for the airport to develop targeted and dynamic bird strike prevention strategies, this study has established a bird strike risk assessment index system for the airport based on the “3M1E” theory and relevant content of the “Management Measures for the Prevention and Control of Bird Strikes and Animal Intrusions at Transport Airports”. Then, under the premise of reasonably selecting the parameters of generalized intuitionistic fuzzy entropy, the entropy method is used to simultaneously determine the expert weights and indicator weights. Finally, a weighted TOPSIS model was utilized to assess and rank the high-risk factors contributing to bird strike incidents. Then, taking the bird strike event occurrence at a certain airport as an example for analysis, the second-level indicators are ranked. The results show that the top three indicators are Bird Prevention Funding ( $$D_3$$ ), Habitat Distribution ( $$C_1$$ ), and Dispersal Activities ( $$D_5$$ ). The assessment results provide the necessary basic data for the bird strike prevention work of the airport.},
  archive      = {J_IJCIS},
  author       = {Yu, Changyang and Zhao, Fan and Yin, Yu and Wu, Yi},
  doi          = {10.1007/s44196-025-00746-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Entropy-weighted TOPSIS-based bird strike risk assessment for an airport},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and implementation evaluation of personalized and
differentiated teaching strategies for preschool children based on fuzzy
decision support systems. <em>IJCIS</em>, <em>18</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-025-00748-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {School operations have changed due to information technology. Personalized teaching for preschool children requires innovative and adaptable strategies for providing the best-afford experience and learning environment. Conventional teaching approaches may not always accommodate students’ learning styles. This can lower performance and involvement. The expanding variety of pre-schoolers necessitates creative evaluation and optimization methods that promote inclusion and success for all children. The article introduces a preschool teaching evaluation model to improve the students’ learning experience. In particular, the evaluation model is designed for various assessment strategies irrespective of personalization. The proposed model inputs the students’ learning feasibility and the teaching mode to evaluate the personalization adaptability. The fuzzy decision support system improves the evaluation based on the above factors. It evaluates student-specific indicators, including attentiveness, body language, and engagement, to determine instructional flexibility. The model uses real-time classroom observations and student assessments to find realistic approaches with low-to-high fuzzy derivatives. The proposed system is designed to compute the adaptability from both factors under low-to-high fuzzy derivatives. By defining the maximum feasibility range, the teaching strategy is optimized to meet the adaptability. Thus, the low-level strategies are discarded using adaptability measures to reduce personalization failures. The proposed model is verified using adaptability, feasibility, and mode improvements. Research shows that the fuzzy decision support system makes courses more adaptive and feasible in many contexts, particularly those that involve games, audiovisual approaches, and crafts. Preschoolers, parents, and teachers indicated increased enjoyment, fewer customization failures, and greater involvement. Fuzzy-based evaluation increased feasibility ratings and approach versatility. The research provides a valuable foundation for solving classroom customization difficulties in preschool settings, emphasizing data-driven, adaptive teaching techniques. This method enables scalable applications in early childhood education through fuzzy decision-making and real-time evaluations.},
  archive      = {J_IJCIS},
  author       = {Hou, Yali},
  doi          = {10.1007/s44196-025-00748-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Design and implementation evaluation of personalized and differentiated teaching strategies for preschool children based on fuzzy decision support systems},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-source fusion positioning system based on MDAW-PF
algorithm and PDR. <em>IJCIS</em>, <em>18</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-025-00749-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to multiple occlusions and strong interference in an indoor environment, the traditional single signal source location method is difficult to meet the requirements of high precision and high robustness. Therefore, this paper proposes a multi-source fusion location system based on an adaptive vector particle filter, which combines fingerprint location, pedestrian dead reckoning and map information. The received signal intensity is optimized by offline fingerprint calibration and Kalman filter. The adaptive vector particle filter adopts multi-direction sampling and weight adjustment, which effectively improves the diversity of particles and reduces errors. Compared with the single-source method and other multi-source systems, the positioning accuracy and trajectory fitting degree of the proposed system were significantly improved. The positioning error probability was 97%, the average error was 0.67 m, and the positioning accuracy reached 90.1%. In summary, the proposed multi-source fusion system provides an effective solution for indoor high-precision and reliable positioning.},
  archive      = {J_IJCIS},
  author       = {Wu, Wennan and Xu, Yigang and Li, Zhimin and Lai, Jizhou},
  doi          = {10.1007/s44196-025-00749-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A multi-source fusion positioning system based on MDAW-PF algorithm and PDR},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter adaptive manta ray foraging optimization for
global continuous optimization problems and parameter estimation of
solar photovoltaic models. <em>IJCIS</em>, <em>18</em>(1), 1–36. (<a
href="https://doi.org/10.1007/s44196-025-00753-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manta ray foraging optimization (MRFO) algorithm suffers from a fixed parameter $$ S $$ , limiting its adaptability in balancing search capability and convergence speed during different optimization stages. To address this limitation, a success-history-based parameter adaptation strategy is proposed to dynamically adjust $$ S $$ . Furthermore, to enhance population diversity and avoid premature convergence, a randomly selected individual from the top $$ G $$ high-quality solutions replaces the current best individual in the somersault foraging behavior. Based on these improvements, a parameter adaptive manta ray foraging optimization (PAMRFO) algorithm is developed. The experimental results demonstrate the effectiveness of PAMRFO. On the IEEE CEC2017 benchmark function set, PAMRFO achieved an average win rate of 82.39% across 29 functions compared to seven state-of-the-art algorithms. On 22 IEEE CEC2011 real-world optimization problems, PAMRFO achieved an average win rate of 55.91% compared to ten advanced algorithms. Sensitivity analysis identified optimal parameter settings, and further stability analysis revealed that PAMRFO exhibits higher success rates and computational efficiency among the four MRFO variants. Population diversity and exploration-exploitation analysis demonstrated the effectiveness of the proposed update mechanism in maintaining diversity and balancing exploration and exploitation. In solving parameter estimation problems for six multimodal solar photovoltaic models, PAMRFO outperformed other competing methods with a 100% success rate, highlighting its superior performance in the photovoltaic field. These findings validate the robustness, efficiency, and wide applicability of PAMRFO, providing advanced solutions for optimization problems in the new energy domain.},
  archive      = {J_IJCIS},
  author       = {Tang, Zhentao and Wang, Kaiyu and Yao, Yongxuan and Zhu, Mingxin and Zhuang, Lan and Chen, Huiqin and Li, Jing and Yan, Li and Gao, Shangce},
  doi          = {10.1007/s44196-025-00753-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Parameter adaptive manta ray foraging optimization for global continuous optimization problems and parameter estimation of solar photovoltaic models},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure authentication and key exchange protocol for
vehicles to infrastructure network. <em>IJCIS</em>, <em>18</em>(1),
1–16. (<a href="https://doi.org/10.1007/s44196-025-00754-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles technology has been widely applied in various communication scenarios, including vehicles to vehicles, vehicles to roadside facilities, vehicles to pedestrians, and vehicles to cloud. Owing to transmitting data through public channels, various security issues like identity leakage, man in the middle attack, key leakage and etc., are also introduced simultaneously and still challenging to be solved. Researches and practices have shown that authentication and key exchange protocols are effective methods to solve such security issues. However, most existing security protocols for Internet of Vehicles are established on the premise that the registration process is with a secure channel, which is usually not satisfied and deviates from practical applications. Accordingly, an authentication and key exchange protocol with an insecure channel has been proposed, in which the operations of symmetric encryption and XOR encryption are adopted for all interactive processes to improve protocol security. The theoretical analysis and formal verification demonstrate that the proposed protocol satisfies security properties including authentication and confidentiality, and reduces the costs of computation and communication compared with the method with public key encryption.},
  archive      = {J_IJCIS},
  author       = {Xu, Peng and Wang, Xiuzhen and Chen, Meirong},
  doi          = {10.1007/s44196-025-00754-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A secure authentication and key exchange protocol for vehicles to infrastructure network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). Publisher correction: A two-way crossed effects fuzzy panel
linear regression model. <em>IJCIS</em>, <em>18</em>(1), 1. (<a
href="https://doi.org/10.1007/s44196-025-00756-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Hesamian, Gholamreza and Johannssen, Arne},
  doi          = {10.1007/s44196-025-00756-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Publisher correction: A two-way crossed effects fuzzy panel linear regression model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). Correction: ExAIRFC-GSDC: An advanced machine
learning-based interpretable framework for accurate gas leakage
detection and classification. <em>IJCIS</em>, <em>18</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s44196-025-00758-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIS},
  author       = {Lalithadevi, B. and Krishnaveni, S.},
  doi          = {10.1007/s44196-025-00758-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Correction: ExAIRFC-GSDC: an advanced machine learning-based interpretable framework for accurate gas leakage detection and classification},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing solid oxide fuel cell efficiency through advanced
model identification using differential evolutionary mutation fennec fox
algorithm. <em>IJCIS</em>, <em>18</em>(1), 1–31. (<a
href="https://doi.org/10.1007/s44196-025-00759-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuel cells (FCs) are increasingly attracting attention for their efficient conversion of chemical energy into electricity without the need for combustion. Their high efficiency and versatility make them a promising technology across various applications. Researchers are actively exploring ways to optimize FC systems to meet specific energy needs. Among the different types of fuel cells, solid oxide fuel cells (SOFCs) stand out as a promising clean energy technology that generates electricity through electrochemical reactions. However, accurately modeling SOFCs, which is essential for reducing design costs, presents a challenge due to their complex and nonlinear characteristics. An ideal model should be adaptable to varying operating pressures and temperatures. This research introduces a novel approach for optimal SOFC model identification using a differential evolutionary mutation Fennec fox algorithm (DEMFFA). A real-world case study demonstrates the superior effectiveness of DEMFFA compared to existing methods. Additionally, a sensitivity analysis evaluates the influence of temperature and pressure on the model, with results indicating that the proposed method achieves higher efficiency than other approaches. The sum of the square error of the proposed algorithm is 1.18E-11 followed by the parent algorithm, Fennec fox algorithm (FFA) (1.24E-09), and some of the compared algorithms. The computational time of the proposed algorithm is 1.001 s, followed by the parent algorithm FFA (1.199 s) and some of the compared algorithms. DEMFFA offers significant potential, enhancing renewable energy, minimizing SOFC&#39;s environmental impact, and improving real-world applications like distributed power generation and hydrogen integration.},
  archive      = {J_IJCIS},
  author       = {Singla, Manish Kumar and Gupta, Jyoti and Kumar, Ramesh and Jangir, Pradeep and Louzazni, Mohamed and Giri, Nimay Chandra and Al-Gburi, Ahmed Jamal Abdullah and EI-Kenawy, E. I.-Sayed M. and Alharbi, Amal H.},
  doi          = {10.1007/s44196-025-00759-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhancing solid oxide fuel cell efficiency through advanced model identification using differential evolutionary mutation fennec fox algorithm},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid LECNN architecture: A computer-assisted early
diagnosis system for lung cancer using CT images. <em>IJCIS</em>,
<em>18</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s44196-025-00761-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is one of the most common causes of cancer-related death. Therefore, early diagnosis of this cancer is crucial for planning patient treatment. This paper proposes a hybrid Lung Ensemble Convolutional Neural Network (LECNN) architecture for the computer-aided early diagnosis of lung cancer via CT images. The proposed hybrid approach integrates a transfer learning (TL) mechanism with ensemble learning (EL) on the basis of majority voting. Initially, CNN architectures (GoogLeNet, EfficientNet, DarkNet19, and ResNet18) are trained via TL, and the resulting CNN models are used as inputs in EL. The outputs from all the CNN architectures are evaluated via majority voting to identify the top-performing triple CNN combination, which is then utilized in the hybrid approach. The performance of the proposed method was assessed via the widely used IQ-OTH/NCCD dataset. Additionally, the impact of the elastic transformation method, a data augmentation technique, on performance improvement was investigated in the proposed method. The triple combination of the GoogLeNet, EfficientNet, and DarkNet19 CNN architectures, as part of the EL method in the hybrid approach, achieved superior performance on both the raw and augmented datasets according to the obtained performance results. The performance evaluations revealed that the proposed approach achieved more than a 5% improvement with the augmented dataset compared with the raw IQ-OTH/NCCD dataset, resulting in the highest performance. The proposed hybrid approach achieved 99% accuracy, 98.82% sensitivity, 99.48% specificity, 99.06% precision, and 98.94% F1 score on the augmented IQ-OTH/NCCD dataset. When compared with findings from previous studies using the same dataset, the proposed hybrid approach outperformed state-of-the-art methods. In conclusion, it demonstrates significant potential as a robust tool for computer-aided early lung cancer diagnosis systems and may also contribute to the development of future hybrid approaches in this field.},
  archive      = {J_IJCIS},
  author       = {Güraksın, Gür Emre and Kayadibi, Ismail},
  doi          = {10.1007/s44196-025-00761-3},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A hybrid LECNN architecture: A computer-assisted early diagnosis system for lung cancer using CT images},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval-valued intuitionistic fuzzy multi-attribute
decision-making based on entropy and bidirectional projection.
<em>IJCIS</em>, <em>18</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s44196-025-00763-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel arctangent-based interval-valued intuitionistic fuzzy entropy function designed to address multi-attribute group decision-making problems, particularly in situations where attribute weights are either completely unknown or only partially known. The proposed entropy function computes the objective weights of the attributes and, by integrating these with subjective weights, derives a comprehensive weight. This methodology effectively addresses uncertainties and the incomplete nature of weight information in decision-making processes. Furthermore, the paper extends the bidirectional projection method to the interval intuitionistic fuzzy context, developing a multi-attribute decision-making model that integrates the arctangent-based interval-valued intuitionistic fuzzy entropy and the bidirectional projection method. Finally, a series of comparative experiments are conducted to validate the effectiveness and robustness of the proposed entropy function and bidirectional projection method in multi-attribute decision-making.},
  archive      = {J_IJCIS},
  author       = {Zheng, Jian and Dong, Minggao},
  doi          = {10.1007/s44196-025-00763-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Interval-valued intuitionistic fuzzy multi-attribute decision-making based on entropy and bidirectional projection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization of communication transmission frequency linear
algebraic model under aerial computing architecture. <em>IJCIS</em>,
<em>18</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s44196-025-00764-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of the demand for wireless communication systems, when the existing algebraic model processes real-time data, the frequency adjustment is inflexible, it is difficult to quickly optimize the transmission parameters to cope with network load changes, and the long-term operation fails to effectively control the CPU frequency, resulting in increased energy consumption. To better promote the development of wireless communication systems, this article aimed to use aerial computing architecture to optimize the linear algebraic model of communication transmission frequency, to better meet the needs of today&#39;s wireless communication systems. The article first designed a communication frequency stabilization device structure to ensure high stability of the output spectrum. Then it introduced a dynamic frequency adjustment module to achieve real-time adjustment of communication transmission frequency. It then improved the data transmission rate through the design of the aerial computing perception module. This article used a frequency optimization algorithm based on linear algebra to adjust its linear relationship, optimize transmission energy consumption, and improve transmission efficiency. Finally, to verify the application effect of aerial computing architecture in optimizing the linear algebraic model of communication transmission frequency, this paper compared it with traditional dynamic adjustment models and parallel computational models. The research results showed that for packet 13, the round-trip time required to transmit the model in this article was 1.21 ms; the response time was 0.009 ms, and the total energy consumption was 89.6-W hours. The traditional dynamic adjustment model required a round-trip time of 4.92 ms, a response time of 0.093 ms, and a total energy consumption of 119.1-W hours for packet 13 transmissions. The parallel computational model required a round-trip time of 6.33 ms, a response time of 0.063 ms, and a total energy consumption of 131.4-W hours for packet 13 transmissions. The results showed that the optimized communication transmission frequency linear algebraic model using aerial computing architecture had shorter communication delay and response time, lower energy consumption, and better frequency control performance. This article highlighted the important impact of aerial computing architecture on the stability, real-time performance, and transmission rate of linear algebraic models of communication transmission frequencies, providing more ideas for the design and planning of wireless communication systems.},
  archive      = {J_IJCIS},
  author       = {Gao, Yufeng},
  doi          = {10.1007/s44196-025-00764-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Optimization of communication transmission frequency linear algebraic model under aerial computing architecture},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DenseNet-ABiLSTM: Revolutionizing multiclass arrhythmia
detection and classification using hybrid deep learning approach
leveraging PPG signals. <em>IJCIS</em>, <em>18</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s44196-025-00765-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arrhythmias (AM) are heart conditions that can lead to fatal cardiac arrest. Automated identification of arrhythmias is crucial for detecting cardiac diseases. Previous studies have used photoplethysmography (PPG) signals to identify arrhythmias, but there is limited research on their application for multiclass arrhythmia classification. This study introduces a Hybrid Deep Learning (HDL) model called DenseNet-ABiLSTM, which uses densely connected convolutional networks and Attention-based Bidirectional Long Short-Term Memory (ABiLSTM) to categorize various types of arrhythmias. The model uses 1D convolutional kernels to acquire multiscale conceptual features, followed by BiLSTM to understand temporal relationships among features. The Attention Mechanism layer is presented to improve detection performance. The model categorizes arrhythmia rhythms into six types: Sinus Rhythm (SR), Early Ventricular Contraction (EVC), Early Atrial Contraction (EAC), Ventricular Tachycardia (VT), Supraventricular Tachycardia (ST), and AF. Various metrics were assessed and compared with Electrocardiogram (ECG) results to determine AM rhythms. The mean performance measures showed strong overall performance, with a mean F1 score and accuracy of 87.74% and 89.14%, respectively.},
  archive      = {J_IJCIS},
  author       = {Saranya, K. and Karthikeyan, U. and Kumar, A. Saran and Salau, Ayodeji Olalekan and Tin Tin, Ting},
  doi          = {10.1007/s44196-025-00765-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {DenseNet-ABiLSTM: Revolutionizing multiclass arrhythmia detection and classification using hybrid deep learning approach leveraging PPG signals},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intrusion detection system for network security using novel
adaptive recurrent neural network-based fox optimizer concept.
<em>IJCIS</em>, <em>18</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s44196-025-00767-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of daily networks and communications rely heavily on network security. Researchers in cybersecurity emphasize the necessity of developing effective intrusion detection systems (IDS) to safeguard networks. The importance of efficient IDS escalates as attackers devise new types of attacks and network volumes expand. Furthermore, IDS aims to ensure the integrity, confidentiality, and availability of data transmitted across networked systems by preventing unauthorized access. Following numerous studies utilizing machine learning (ML) to develop effective IDS, the focus has shifted towards deep learning (DL) techniques as artificial neural networks (ANNs) and DL systems have become prevalent. ANNs are capable of generating features autonomously, eliminating the need for manual intervention. This paper introduces an innovative adaptive recurrent neural network-based fox optimizer (ARNN-FOX) method. The primary objective of the ARNN-FOX system is to efficiently detect and classify network intrusions, thereby enhancing network security. Data normalization is conducted to scale the incoming data into a usable format. The gray level co-occurrence matrix (GLCM) method is proposed for selecting the optimal subset of features for the ARNN-FOX method. In the proposed approach, the fox algorithm (FOX) is utilized for the adjustment of hyperparameters in the ARNN model. The efficacy of the ARNN-FOX approach is assessed using benchmark datasets. Based on comparative results, the ARNN-FOX method demonstrates superior performance in parameters such as accuracy, specificity, sensitivity, F1 Score, recall value, and precision values over existing models. The proposed ARNN-FOX-based IDS model for the network security in terms of accuracy is 15.12%, 8.79%, 6.45%, and 4.21% better than RNN, CNN-LSTM, DASO-RNN, and ChCSO-LSTM, respectively. Similarly, with respect to specificity, the suggested ARNN-FOX-based IDS model for network security outperforms RNN, CNN-LSTM, DASO-RNN, and ChCSO-LSTM by 32.43%, 8.89%, 3.16%, and 2.08%, respectively.},
  archive      = {J_IJCIS},
  author       = {Manivannan, R. and Senthilkumar, S.},
  doi          = {10.1007/s44196-025-00767-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Intrusion detection system for network security using novel adaptive recurrent neural network-based fox optimizer concept},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-perspective learning based on transformer for stock
price trend. <em>IJCIS</em>, <em>18</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-025-00768-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock constitutes a crucial element of the financial market, and accurately forecasting stock trends remains a significant and unresolved issue. Nonetheless, the stock’s considerable complexity renders accurate prediction of stock trends more challenging. This paper proposes a novel multi-perspective approach that converts the time series prediction challenge into an image classification problem, referred to as the Multi-perspective Denoise Transformer (MPDTransformer). We initially multi-factor features into two-dimensional images employing a multi-perspective approach to more comprehensively explain the actual market conditions and enhance the model’s practicality and adaptability; secondly, we utilize a Convolutional Autoencoder (CAE) to extract features, which effectively eliminates noise and enhances data purity; finally, to comprehensively capture the temporal relationships within the data and gain a deeper understanding of the overall time series, we employ a Transformer for prediction. Experimental results demonstrate that our method outperforms other prevalent stock trend prediction techniques.},
  archive      = {J_IJCIS},
  author       = {Li, Xiliang and Chen, Shuoru and Qiao, Xiaoyan and Zhang, Mingli and Zhang, Caiming and Zhao, Feng},
  doi          = {10.1007/s44196-025-00768-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Multi-perspective learning based on transformer for stock price trend},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid-CID: Securing IoT with mongoose optimization.
<em>IJCIS</em>, <em>18</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s44196-025-00751-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Things (IoT) technology has evolved beyond personal devices to power global deployments across a wide range of networks which has a significant impact on global commerce. However, security challenges arise due to the wide range of protocols and computational capabilities in IoT devices. To combat these issues, a novel hybrid optimization-enabled neural network for classification of intrusion data against IoT system (Hybrid-CID) is proposed particularly to identify intrusions in resource-constrained IoT devices. Initially, the incoming data are standardized by removing the irrelevant information through preprocessing to ensure the performance of detection models. After preprocessing, the Hybrid-CID framework develops a hybrid optimization algorithm to identify the intrusions from the traffic data which ensures data privacy by maintaining the reliability and integrity of IoT deployments. Finally, the combined deep learning (DL) network classifies the identified intrusions to contribute proactive threat mitigation by ensuring the confidentiality of IoT system data. The Hybrid-CID system is validated through the benchmark CSE-CIC-IDS 2018 and CICIDS 2017 datasets using accuracy, specificity, precision, F1-score, recall, execution time, communication cost, detection rate, detection time, and computational cost. The Hybrid-CID framework achieves an overall accuracy of 97.82%, whereas the WDLSTM, TLBO-IDS, and DIS-IoT techniques achieve 87.42%, 89.58%, and 94.72%, respectively, for efficiently detecting intrusions in IoT networks.},
  archive      = {J_IJCIS},
  author       = {Sheeba, S. Merlin and Shaji, R. S.},
  doi          = {10.1007/s44196-025-00751-5},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hybrid-CID: Securing IoT with mongoose optimization},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lattice-based decision models for green urban development:
Insights from <span
class="math display"><em>L</em><sub><em>q</em></sub>*</span> q-rung
orthopair multi-fuzzy soft set. <em>IJCIS</em>, <em>18</em>(1), 1–27.
(<a href="https://doi.org/10.1007/s44196-025-00755-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Location selection is a critical process in decision-making for projects that involve multiple criteria, such as urban planning, industrial site development, or green building projects. Multiple criteria decision making (MCDM) is a systematic approach that evaluates and ranks potential alternatives based on a set of often conflicting criteria. This study focuses on selecting the optimal urban location for a green building project by employing the $$L_{q}*$$ q-rung orthopair multi-fuzzy soft-MCDM( $$L_{q}*$$ q-ROMFS) techniques. The $$L_{q}*$$ q-ROMFS set combines elements from two distinct theories with lattice ordering parameters: q-rung orthopair fuzzy set and multi-fuzzy soft set. It provides a mathematical framework with multiple parameters that effectively represents problems involving multi-dimensional data within a dataset. We expand this concept by establishing the algebraic structures of $$L_{q}*$$ q-ROMFS sets, including properties like modularity and distributivity, while also analyzing their homomorphism under lattice mappings. Finally, leveraging the $$L_{q}*$$ q-ROMFS matrix, we propose both a choice matrix and a weighted choice matrix to effectively address the selection of the optimal urban location for a green building project.},
  archive      = {J_IJCIS},
  author       = {Jayakumar, Vimala and Pethaperumal, Mahalakshmi and Kausar, Nasreen and Pamucar, Dragan and Simic, Vladimir and Salman, Mohammed Abdullah},
  doi          = {10.1007/s44196-025-00755-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Lattice-based decision models for green urban development: Insights from $$L_{q}*$$ q-rung orthopair multi-fuzzy soft set},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced model for gestational diabetes mellitus prediction
using a fusion technique of multiple algorithms with explainability.
<em>IJCIS</em>, <em>18</em>(1), 1–33. (<a
href="https://doi.org/10.1007/s44196-025-00760-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High glucose levels during pregnancy cause Gestational Diabetes Mellitus (GDM). The risks include cesarean deliveries, long-term type 2 diabetes, fetal macrosomia, and infant respiratory distress syndrome. These risks highlight the need for accurate GDM prediction. This research proposes a novel fusion model for early GDM prediction. It uses conventional Machine Learning (ML) and advanced Deep Learning (DL) algorithms. Subsequently, it combines the strengths of both ML and DL algorithms using various ensemble techniques. It incorporates a meta-classifier that further reinforces its robust prediction performance. The dataset is split into training and testing sets in a 70/30 ratio. The initial steps involve exploratory analysis and data preprocessing techniques such as iterative imputation and feature engineering. Subsequently, oversampling is applied to the training set to address class imbalance which ensures the model learns effectively. The testing set remains imbalanced to maintain the credibility of the model’s performance evaluation. The fusion model achieves an accuracy of 98.21%, precision of 97.72%, specificity of 98.64%, recall of 97.47%, F1 score of 97.59%, and an Accuracy Under the Curve (AUC) of 99.91%. The model exhibits efficiency with an average processing time of 0.06 s to predict GDM. These results outperform the previous studies using the same GDM prediction dataset and demonstrate the model&#39;s superior performance. Additionally, Explainable Artificial Intelligence (XAI) techniques are utilized to interpret the model’s decisions. They highlight the most influential features in GDM prediction and ensures transparency. The proposed fusion model can facilitate proactive GDM prediction to elevate GDM management and maternal–fetal health outcomes.},
  archive      = {J_IJCIS},
  author       = {Hassan, Ahmad and Ahmad, Saima Gulzar and Iqbal, Tassawar and Munir, Ehsan Ullah and Ayyub, Kashif and Ramzan, Naeem},
  doi          = {10.1007/s44196-025-00760-4},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-33},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Enhanced model for gestational diabetes mellitus prediction using a fusion technique of multiple algorithms with explainability},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of distributionally robust optimization markov
decision-making under uncertainty in scheduling of multi-category
emergency medical materials. <em>IJCIS</em>, <em>18</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s44196-025-00762-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the preliminary stages of public health emergencies, many regional public health systems do not have enough medical resources to address the needs that arise from the emergencies. Additionally, due to the rapid development of emergency situations, it is difficult to accurately understand all medical material demands. Thus, we develop a multi-category emergency medical materials robust scheduling method for multi-period, which continuously schedules the availability of multi-category emergency medical materials during times of uncertain demand. First, we developed a single-period Distributionally Robust Optimization (DRO) model to provide a powerful strategy for scheduling multi-category emergency medical materials with little information on material demand. In the DRO model, we prioritize medical material requirements into different categories, assuming only that the means and variances of information on the demand are available to seek an optimal implementation strategy in a single period. We then combine the DRO scheduling model with the Markov Decision Process (MDP) and extend it to the multi-period Distributionally Robust Optimization Markov Decision Process scheduling model (DRO-MDP). Our DRO-MDP model provides encouraging guidelines to solve the multi-period scheduling problem of multi-category emergency medical materials in uncertain situations. A simulated experiment is used to demonstrate the effectiveness of the proposed model. The simulation uses COVID-19 data from New Delhi, India in the spring of 2021. It is important to note that the model we propose can be easily generalized as a framework for any multi-category resource allocation problem with uncertain needs.},
  archive      = {J_IJCIS},
  author       = {Liang, Zhizhen and Wang, Xiaojia and Xu, Sheng and Chen, Wei},
  doi          = {10.1007/s44196-025-00762-2},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Application of distributionally robust optimization markov decision-making under uncertainty in scheduling of multi-category emergency medical materials},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SED-NET: Real-time suspicious event detection via deep
learning-based di-stream neural network. <em>IJCIS</em>, <em>18</em>(1),
1–19. (<a href="https://doi.org/10.1007/s44196-025-00766-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Suspicious event detection (SED) identifies anomalous activities in surveillance data using computer vision and machine learning techniques. However, existing approaches have high false positive rates difficulty distinguishing suspicious from normal behaviors, and limited adaptability to dynamic environments. This research introduces a novel deep learning-based SED-NET model for detecting suspicious events in public places. Initially, input images are collected from two data for detecting Suspicious events. Surveillance camera videos are converted into frames and the suspicious images are pre-processed using a Gaussian adaptive bilateral filter (GABF) to reduce noise while preserving edges. A Sobel edge detector is used to detect the fine edges in the pre-processed frames for enhancing the structural details. Di-Stream Neural Network (DSNN) is introduced with the dual-branch EfficientNet-based feature extractor that retrieves both motion and pose features. The weighted Average Fusion method is used to combine pose and motion features to classify suspicious activities using the Simplified Spiking Neural Network (SSNN). The effectiveness of the proposed SED-NET method was evaluated using specificity, accuracy, sensitivity, and F1 score. The proposed SED-NET model attains an accuracy of 98.97% for UCSD Pedestrian and 98.84% for CUHK Avenue datasets. Moreover, the proposed SED-NET improved the overall accuracy by 7.44%, 4.18%, and 2.73% better than DenseNet121, SegAD, and 3DCNN, respectively.},
  archive      = {J_IJCIS},
  author       = {Siva Senthil, D. and Sivarani, T. S.},
  doi          = {10.1007/s44196-025-00766-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {SED-NET: Real-time suspicious event detection via deep learning-based di-stream neural network},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hesitant fuzzy <span class="math display"><em>β</em></span>
-covering <span class="math display">(ℐ,</span> <span
class="math display">𝒪)</span> rough set models and applications to
multi-attribute decision-making. <em>IJCIS</em>, <em>18</em>(1), 1–29.
(<a href="https://doi.org/10.1007/s44196-025-00769-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hesitant fuzzy $$\beta $$ -covering rough set offers stronger representational capabilities than earlier hesitant fuzzy rough sets. Its flexibility makes it more suitable for hesitant fuzzy multi-attribute decision-making (MADM). As a result, it has become a popular research focus in decision analysis and has drawn significant attention from scholars. However, the existing hesitant fuzzy $$\beta $$ -covering rough set based on t-norms cannot handle the overlap and correlation between hesitant information well. Addressing this problem, we propose the hesitant fuzzy overlap function and hesitant fuzzy $$\beta $$ -covering $$({\mathcal {I}},$$ $${\mathcal {O}})$$ rough set (HF $$\beta $$ CIORS) models based on the hesitant fuzzy overlap function. First, we establish the definition of the hesitant overlap function and representable hesitant fuzzy overlap function on a partial order relation. Based on proposed definitions, we provide examples of representable and unrepresentable hesitant fuzzy overlap functions and offer a detailed proof to explain the unrepresentable function. Second, we construct four types of HF $$\beta $$ CIORS models and prove some of its important properties. Thirdly, we integrate the HF $$\beta $$ CIORS models with the TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) method and apply them to solve MADM problems. The validity of the proposed method is demonstrated through a practical application, and its stability and effectiveness are confirmed via sensitivity and comparative analyses. Based on these validations, our method proves effective in addressing MADM problems, offering reliable decision-making support.},
  archive      = {J_IJCIS},
  author       = {Wang, Jingyi and Shao, Songtao and Mao, Xiaoyan and Zhang, Xiaohong},
  doi          = {10.1007/s44196-025-00769-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hesitant fuzzy $$\beta $$ -covering $$({\mathcal {I}},$$ $${\mathcal {O}})$$ rough set models and applications to multi-attribute decision-making},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced hybrid machine learning model for accurate
detection of cardiovascular disease. <em>IJCIS</em>, <em>18</em>(1),
1–20. (<a href="https://doi.org/10.1007/s44196-025-00771-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular disease (CVD) is one of the foremost reasons behind the death of people worldwide. Prevention and early diagnosis are the only ways to control its progression and onset. Thus, there is an urgent need for a detection model comprising intelligent technologies, including Machine Learning (ML) and deep learning, to predict the future state of an individual suffering from cardiovascular disease by effectively analyzing patient data. This study aims to propose a hybrid model that provides a deep insight into the data under consideration to enhance model accuracy for effectively detecting cardiovascular disease. This current research proposes a hybrid model comprising four stages. In the first stage of the proposed hybrid model, the data imbalance problem is solved using a hybrid sampling technique named Synthetic Minority Oversampling Technique-Edited Nearest Neighbors Rule. In the second stage, the Chi-square is applied as a feature selection method to select the highly relevant features from the records of 1190 with 11 clinical features, curated by combining the 5 most popular datasets, including Long Beach VA, Hungarian, Switzerland, and Statlog (Heart). In the third stage, the preprocessed dataset is passed to a stacking ensemble model comprising three base learners: Random Forest Tree (RFT), K-Nearest Neighbor (K-NN), and AdaBoost classifier and one meta-learner: Logistic Regression (LR), optimized with Grid Search Cross-Validation (GSCV) optimization approach, whose performance is evaluated against individual classifier. In the fourth stage, the performance is evaluated in terms of accuracy, sensitivity, specificity, F1 score, and ROC_AUC score.. The comparative results prove that the proposed hybrid model scored the highest accuracy of 97.8%, 96.15% sensitivity, and 96.75% specificity and 98.6% ROC_AUC score when compared with the existing techniques and models after applying the SMOTE–ENN (for data balancing) and Chi-square (for feature selection) methods for the efficient detection of cardiovascular disease. The implementation results demonstrate that the suggested hybrid model may accurately identify cardiovascular disease among patients. It facilitates the application of robust clinical treatment strategies.},
  archive      = {J_IJCIS},
  author       = {Navita and Mittal, Pooja and Sharma, Yogesh Kumar and Lilhore, Umesh Kumar and Simaiya, Sarita and Saleem, Kashif and Ghith, Ehab Seif},
  doi          = {10.1007/s44196-025-00771-1},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Advanced hybrid machine learning model for accurate detection of cardiovascular disease},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted hybrid random forest model for significant feature
prediction in alzheimer’s disease stages. <em>IJCIS</em>,
<em>18</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s44196-025-00780-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent studies, several machine learning and deep learning prediction models have been proposed for the early detection and classification of various stages of Alzheimer’s Disease (AD). Many years before the actual onset of AD, there occur several structural changes in the brain. These structural brain features can be utilized in learning the disease progression from an early stage of the disease. The various stages of pathology cause mild cognitive impairment (MCI) from normal cognition and AD from normal cognition. This work intends to develop a weighted and hybrid random forest learning model that utilizes a relevant subset of predictors to diagnose the progression of the disease. The conversion from normal cognition to MCI is identified at an early stage of the onset of structural brain changes. The importance of proposed research works lies in more early identification of significant feature that increase disease progression and appropriate interventions greatly improve subjects’ recovery. The Alzheimer’s Disease Neuro Imaging Initiative (ADNI) cross-sectional MRI data were analyzed in this study that utilized brain curvature, grey matter density, white matter density, the volume of cortical and sub-cortical structures, shape of hippocampus, hippocampal subfield volume, Mini-mental state exam (MMSE), Clinical Dementia Rating (CDR), Estimated Total Intracranial Volume, Normalize Whole Brain Volume, and Atlas Scaling Factor for constructing randomized trees and thus predicting the features that cause the progression of disease stages from MCI to Alzheimer’s disease that causes dementia. Based on previous studies, there is a significant shortfall in understanding Alzheimer’s disease progression from pre-MCI stages and the classification of progressive and stable MCI groups. As a consequence of this challenge discussed, whether all the mild cognitively impaired people change to AD cohorts or remain in normal cognition and identification of the structural and functional features remains underexplored. Thus, the proposed Weighted Hybrid Random Forest algorithm (WHBM) utilized the 63 features that comprise the whole brain volume. The most significant and weighted features are derived which segregate 39% of subjects with cognitively progressive MCI and 51% of subjects with normal age-related cognitive decline. This implementation model proved to give robust AD conversion probability and identify significant features with 93% accuracy and 88% sensitivity that are sufficient for future clinical inferences. The optimized model thus resulted in the prediction of disease conversion probability from Mild Cognitive Impairment to AD because of significant structural features that are key-requisite for affected geriatric cohorts.},
  archive      = {J_IJCIS},
  author       = {Rohini, M. and Surendran, D.},
  doi          = {10.1007/s44196-025-00780-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Weighted hybrid random forest model for significant feature prediction in alzheimer’s disease stages},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid android malware detection and classification using
deep neural networks. <em>IJCIS</em>, <em>18</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s44196-025-00783-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a deep learning-based framework for Android malware detection that addresses critical limitations in existing methods, particularly in handling obfuscation and scalability under rapid mobile app development cycles. Unlike prior approaches, the proposed system integrates a multi-dimensional analysis of Android permissions, intents, and API calls, enabling robust feature extraction even under reverse engineering constraints. Experimental results demonstrate state-of-the-art performance, achieving 98.2% accuracy (a 7.5% improvement over DeepAMD) on a cross-dataset evaluation spanning 15 malware families and 45,000 apps. The framework’s novel architecture enhances explainability by mapping detection outcomes to specific behavioral patterns while rigorous benchmarking across five public datasets (including Drebin, AndroZoo, and VirusShare) mitigates dataset bias and validates generalization. By outperforming existing techniques in accuracy, adaptability, and interpretability, this work advances the practicality of deep learning for real-world Android malware defense in evolving threat landscapes.},
  archive      = {J_IJCIS},
  author       = {Rashid, Muhammad Umar and Qureshi, Shahnawaz and Abid, Abdullah and Alqahtany, Saad Said and Alqazzaz, Ali and ul Hassan, Mahmood and Al Reshan, Mana Saleh and Shaikh, Asadullah},
  doi          = {10.1007/s44196-025-00783-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Hybrid android malware detection and classification using deep neural networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Book review: Multicriteria decision-making under conditions
of uncertainty: A fuzzy set perspective. John wiley &amp; sons. ISBN:
978–1-119–53,492-1. <em>IJCIS</em>, <em>18</em>(1), 1–5. (<a
href="https://doi.org/10.1007/s44196-025-00784-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This overview is focused on the book reflecting research results on the fundamentals of the theory of multicriteria (multiobjective and multiattribute) decision-making under conditions of uncertainty. The facet of uncertainty is formalized based on a possibilistic (not probabilistic) approach. These results are based on the fuzzy set theory and its fusion with other branches of mathematics of uncertainty. The overview identifies the crucial arguments behind the ultimate need for this theory, reflects the book’s primary objectives, identifies the key possibilities delivered by the presented book&#39;s results, and elaborates on real-world problems solved by applying the findings reported in the book. The thorough critical analysis summarizes the advantages and limitations of the main results covered by the book.},
  archive      = {J_IJCIS},
  author       = {Ekel, Petr Iakovlevitch and Libório, Matheus Pereira and Pedrycz, Witold},
  doi          = {10.1007/s44196-025-00784-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-5},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Book review: multicriteria decision-making under conditions of uncertainty: a fuzzy set perspective. john wiley &amp; sons. ISBN: 978–1-119–53,492-1.},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MicrobeNet: An automated approach for microbe organisms
prediction using feature fusion and weighted CNN model. <em>IJCIS</em>,
<em>18</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s44196-025-00777-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microbial organisms are everywhere, millions residing within the human body and also cover 60% of the living earth. These microbes can pose significant health risks, causing diseases such as malaria and toxoplasmosis. Toxoplasmosis is notably prevalent, with seroprevalence rates ranging from 3.6 to 84% in an African region, underscoring the necessity for automated microorganism detection techniques. This research work aims to predict the presence of microorganisms in the human body. We propose a novel approach that combines and integrates principal-component analysis, Chi-square, and analysis-of-variance features using a weighted convolutional-neural-network model called MicrobeNet. The results highlight the efficacy of the proposed method, achieving a remarkable 99.97% in accuracy, recall, precision, and F1-score. The experiments use multiple deep and machine learning models to detect ten distinct microbial forms. The results of the proposed model are compared with those of previously published research. Additionally, k-fold cross validation confirms the robustness of these findings. This research significantly advances the field of microbiology by providing a highly accurate method for microorganism identification, facilitating early disease detection and prevention.},
  archive      = {J_IJCIS},
  author       = {Alnowaiser, Khaled},
  doi          = {10.1007/s44196-025-00777-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MicrobeNet: An automated approach for microbe organisms prediction using feature fusion and weighted CNN model},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging multi-source data for local government financing
vehicles debt risk assessment via random forests. <em>IJCIS</em>,
<em>18</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-025-00778-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local government financing vehicles (LGFVs), in China, are pivotal indirect financing channels for urban development projects. However, the significant debt accumulated by these vehicles presents considerable long-term risks, including challenges to fiscal sustainability, threats to financial system stability, and disruptions to regional economic development. Timely monitoring of LGFV debt risks is essential for enabling effective interventions. This study develops a robust risk evaluation system for LGFVs by leveraging multi-source data and employing the Random Forest (RF) machine learning algorithm. We collected and analyzed a sample of 1584 Chinese LGFVs from a major state-owned bank. Through an examination of the mechanisms underlying LGFV debt risk and a review of relevant literature, we identified seven primary categories and 20 key risk indicators to construct our risk indicator system. After comparing several machine learning algorithms, we selected the RF algorithm to build the LGFV debt risk prediction model due to its superior performance. Our findings emphasize the External Guarantee Ratio, GDP growth rate, and proportion of the tertiary industry as critical risk indicators. The model evaluation demonstrates high accuracy, underscoring its significant potential for practical application. This study contributes to the management of local government debt risks and introduces a novel methodology with potential applicability in other areas of risk management.},
  archive      = {J_IJCIS},
  author       = {Li, Kejia and Chen, Zhen-Song},
  doi          = {10.1007/s44196-025-00778-8},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Leveraging multi-source data for local government financing vehicles debt risk assessment via random forests},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy decision support system for medical service quality
management in hospitals. <em>IJCIS</em>, <em>18</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s44196-025-00773-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical service quality in hospitals and clinical centres is expected to satisfy the patient’s satisfaction and the high precision diagnosis. Periodic assessment of the medical services increases the quality and the staff efficiency. Such quality assessments are analyzed using sophisticated computing techniques such as fuzzy, genetic algorithms, etc. Therefore, this article introduces a Quality Improvement Method using Fuzzy Decision Support (QIM-FDS) for periodic service enhancements in hospitals. This method acquires the diagnosis, care-taking, and environmental factors validated using the two levels of FDS. The first FDS handles the quality improvement and the second deals with recommendations. From the previous patient suggestions/complaints, the quality improvements are performed such that the varying inputs result in high service recommendations. The first FDS and the overall recommendations (from patients) towards the above considerations are accounted for in the second fuzzification process. This consideration assimilates the service demands and is the highest patient response for retaining the same level. Therefore, the fuzzification performs the different condition verification in the second decision-making. The joint FDS processes focus on delivering high-level improvements towards the considered factors.},
  archive      = {J_IJCIS},
  author       = {Cui, Hongrui and Tan, Qingli},
  doi          = {10.1007/s44196-025-00773-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A fuzzy decision support system for medical service quality management in hospitals},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction and optimization of student grades based on
genetic algorithm and graph convolutional neural networks.
<em>IJCIS</em>, <em>18</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s44196-025-00775-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to limited support in registered courses, students frequently struggle to complete their courses in higher education institutions. To combat this, educational systems are incorporating intelligent prediction tools to help students improve their academic performance by predicting their grades. Students&#39; demographic information, past performance in the subject, and course characteristics are some of the factors used by the grade prediction system to foretell how they will do in future. Complexity and non-linearity in the analysis of inter-variable connections pose problems for traditional prediction models. Our solution to these problems is a GGCNN, or Genetic Algorithm with Graph Convolutional Neural Networks. In order to improve the accuracy of predictions, GGCNN examines educational data and finds intricate linkages. Using a graph structure, the graph convolution model emphasizes the interdependencies among academic metrics, course features, and student performance. Relationships and correlations can be better predicted with the use of this dependency metric. Use of the genetic algorithm improves the grade prediction system by optimizing the network and making better use of features. Administrators and teachers alike can find ways to boost their kids&#39; grades through the optimization process. To test how well the system performs on different measures, we utilize the Student Performance Kaggle dataset. This continues until the convergence requirements are satisfied. With Python as its implementation, the system was able to get an accuracy of 0.98% after 100 epochs and 0.97% after 1000 epochs.},
  archive      = {J_IJCIS},
  author       = {Li, Ting},
  doi          = {10.1007/s44196-025-00775-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Prediction and optimization of student grades based on genetic algorithm and graph convolutional neural networks},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning model leveraging time-series system call
data to detect malware attacks in virtual machines. <em>IJCIS</em>,
<em>18</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-025-00781-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Tenant Virtual Machine (TVM) user in the cloud may misuse its computing power to launch malware attack against other tenant VMs, Host OS, Hypervisor, or any other computing devices/resources inside the cloud environment of a Cloud Service Provider. The security solutions deployed within the TVM may not be reliable, as malware can disable them or remain undetected due to its hidden nature. Therefore, security solutions deployed outside the virtual machine are necessary. This research proposes deploying an Intrusion Detection System (IDS) at the Hypervisor layer, utilizing time series system call data and employing a Convolutional Neural Network (CNN) model to accurately detect the presence of malicious (malware) computer programs within virtual machines. The raw VMM system call traces are transformed into novel Time Series System Call patterns and utilized by a deep learning algorithm for training and building the classifier model. A deep learning model, CNN, is used to build the classifier model for detecting intrusions with high accuracy. It is capable of detecting both known and unknown malware. The CNN model is compared with machine learning algorithms for the results and discussions, and it outperforms ML algorithms in terms of intrusion detection accuracy when utilizing novel time series system call data..},
  archive      = {J_IJCIS},
  author       = {Melvin, A. Alfred Raja and Kathrine, Jaspher W. and Jeyabose, Andrew and Cenitta, D.},
  doi          = {10.1007/s44196-025-00781-z},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A deep learning model leveraging time-series system call data to detect malware attacks in virtual machines},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transfer learning for cancer diagnosis in medical images: A
compendious study. <em>IJCIS</em>, <em>18</em>(1), 1–46. (<a
href="https://doi.org/10.1007/s44196-025-00772-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world, cancer stands out as one of the most perilous diseases, caused by the uncontrolled proliferation of cells within the human body. Early detection is paramount to ensuring that patients receive the necessary medical intervention in a timely manner. Recently, deep learning techniques, particularly convolutional neural networks, have proven to be incredibly effective in developing computer-aided diagnosis systems due to their remarkable accuracy in analyzing medical images. However, the process of training these neural networks from scratch is often complex and requires significant computational resources. Transfer learning has emerged as a powerful solution to overcome this challenge. This study examines the fundamental concepts of machine learning and deep learning-based computer-aided diagnostic systems. It underscores the significant role of transfer learning in enhancing diagnostic accuracy. It also illustrates the various transfer learning models employed to diagnose various cancer forms, including skin cancer, brain tumors, breast cancer, lung cancer, leukemia, prostate cancer, bladder cancer, and cervical cancer. This paper summarizes 151 studies conducted in recent years. In the end, the article offers a thorough discussion of the research findings, overall conclusions, and directions for future work.},
  archive      = {J_IJCIS},
  author       = {Kaur, Navreet and Hans, Rahul},
  doi          = {10.1007/s44196-025-00772-0},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-46},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Transfer learning for cancer diagnosis in medical images: A compendious study},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid method using grey wolf algorithm and genetic
algorithm for IoT botnet DDoS attacks detection. <em>IJCIS</em>,
<em>18</em>(1), 1–61. (<a
href="https://doi.org/10.1007/s44196-025-00774-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is a vast network of interconnected physical objects that has improved the conditions for a computer-based physical world and improved efficiency. With the increase in communication in an IoT system, Internet security has decreased, and the most dangerous and sophisticated attacks in the IoT have emerged, i.e., DDoS and Botnet attacks. DDoS attacks are a serious threat to the availability of Internet services, especially since botnets can now be launched by almost anyone. In this situation, the use of an intrusion detection system (IDS) is essential to detect intruders and maintain the security of IoT networks. In this paper, a new IDS is proposed to detect IoT-Botnet DDoS attacks. This IDS is a new three-phase system, the first phase is related to preprocessing on the dataset and the second phase includes a new hybrid method for feature selection using filter and wrapper methods based on the Grey Wolf (GW) algorithm and genetics called GW-GA. In this method, the initial population is randomly selected and then at each stage, feature selection is done by both algorithms simultaneously and the final answer is compared and the best solutions are given as a new population to both algorithms and the third phase includes the use of machine learning and metaheuristic algorithms as classifiers. In the proposed method and to verify the performance, it is evaluated using the large BOT-IoT dataset. The results show that the proposed method significantly reduces the feature and also increases the classification accuracy compared to other methods, and the RF and Bagging algorithms have achieved a maximum recognition accuracy of 0.999. The dimensions of BOT-IoT have been reduced from 46 features to 12.},
  archive      = {J_IJCIS},
  author       = {Maazalahi, Mahdieh and Hosseini, Soodeh},
  doi          = {10.1007/s44196-025-00774-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-61},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel hybrid method using grey wolf algorithm and genetic algorithm for IoT botnet DDoS attacks detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavioral patterns in micro-lending: Enhancing credit risk
assessment with collaborative filtering and federated learning.
<em>IJCIS</em>, <em>18</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s44196-025-00776-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit risk assessment uses finance-based behavioural patterns for micro-lending purposes and organizations. The repayment behaviour and credit stability patterns are analyzed across varying repayment tenures and financed amounts. Due to limited borrower data and fluctuating financial patterns, micro-lending platforms have substantial hurdles when it comes to effectively evaluating credit risk. This article introduces a Collaborative Filtering Method using Lending Pattern Analysis (CFM-LPA). The proposed method is enhanced through collaborative federated learning, enabling the analysis of these patterns. This approach evaluates the return rate, credit limit, and consumer response behaviours. Federated learning processes one or more of these factors to assess diverse lending patterns. Based on these evaluations, the behavioural factor is updated for each return period, influencing the credit risk for subsequent return periods and supporting the financial stability of micro-lending operations. The model is trained individually on the identified factors, allowing the behavioural factor to be filtered. New credit risks are identified using this filtered factor from the previous return period. These insights help define new behavioural patterns for the specified credit limit. The proposed method enhances risk detection accuracy by 14.03% and improves return rate analysis by 13.28% across financed amounts. The above abstract is also graphically presented.},
  archive      = {J_IJCIS},
  author       = {Aldrees, Asma and Shahab, Sana and Dutta, Ashit Kumar and Ahmad, Waseem and Anjum, Mohd},
  doi          = {10.1007/s44196-025-00776-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Behavioral patterns in micro-lending: Enhancing credit risk assessment with collaborative filtering and federated learning},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSegNet: A multi-view coupled cross-modal attention model
for enhanced MRI brain tumor segmentation. <em>IJCIS</em>,
<em>18</em>(1), 1–32. (<a
href="https://doi.org/10.1007/s44196-025-00787-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor incidence and mortality rates are increasing due to unique location and treatment challenges. Early detection, robust diagnosis, and prompt treatment are crucial for better clinical evaluations. However, traditional neural network-based diagnostic methods often overlook issues such as variation in multimodality information, loss of spatial information, and under-utilization of boundary information. This study presents the Multi-View Coupled Cross-Modal Attention Network (MSegNet), a novel Transformer-based segmentation framework that integrates cross-modal attention mechanisms and a multi-view architecture. MSegNet is designed to exploit multimodal MRI data’s spatial and depth dimensions, effectively capturing nuanced intermodal relationships and modeling long-range dependencies. The proposed framework also employs three data augmentation methods, which help prevent overfitting and improve the performance of segmentation network training, enhancing the model’s robustness and generalizability. The proposed model is validated using BraTS2019, BraTS2020 and Figshate brain datasets and is compared against three state-of-the-art 3D segmentation networks. Extensive experiments, including ablation studies and hyperparameter sensitivity analyses, highlight MSegNet’s robust performance. The dice scores for the whole tumor (WT), tumor core (TC) and enhancing tumor (ET) regions improved by 13. 96%, 12. 39%, and 11. 83%, respectively, while the Hausdorff distances were reduced by 3.64 mm, 2.98 mm, and 14.72 mm. These results demonstrate the model’s efficacy in enhancing segmentation precision, making it a valuable tool for clinical diagnosis and treatment planning.},
  archive      = {J_IJCIS},
  author       = {Wang, Yu and Xu, Juan and Guan, Yucheng and Ahmad, Faizan and Mahmood, Tariq and Rehman, Amjad},
  doi          = {10.1007/s44196-025-00787-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {MSegNet: A multi-view coupled cross-modal attention model for enhanced MRI brain tumor segmentation},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual feature-based intrusion detection system for IoT
network security. <em>IJCIS</em>, <em>18</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s44196-025-00790-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) has enabled widespread connectivity of smart devices but remains susceptible to cyber intrusions. In this research, a novel dual feature optimization using deep learning network for intrusion Detection (FOUND) technique has been proposed for enhancing security in IoT environments. The proposed method utilizes the bald eagle search (BES) algorithm and butterfly optimization algorithm (BOA) to capture both flow and packet level features to enhance the accuracy of the intrusion detection process. Moreover, a multi-head attention-based bidirectional gated recurrent unit (MHA-BiGRU) is utilized to classify Attack and Non-Attack classes with high precision. The efficacy of the suggested approach is measured utilizing metrics including recall (RC), accuracy, precision (PR), and f1score (F1S). Experimental outcomes utilizing BoT-IoT and UNSW-NB15 datasets demonstrate greater accuracy over existing models. In BoT-IoT, the accuracy of the FOUND approach is 1.5%, 1.1%, and 2.5% increase compared to existing GRU, RNN, and GCN methods, respectively.},
  archive      = {J_IJCIS},
  author       = {Biju, A. and Franklin, S. Wilfred},
  doi          = {10.1007/s44196-025-00790-y},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Dual feature-based intrusion detection system for IoT network security},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved transformer-based model for urban pedestrian
detection. <em>IJCIS</em>, <em>18</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s44196-025-00791-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection is a crucial task in computer vision, applicable in object tracking, video surveillance, and autonomous driving. Recent years have witnessed substantial advancements in pedestrian detection due to the fast evolution of deep learning in object detection. Nonetheless, obstacles such as inadequate detection accuracy persist, mostly because of varied pedestrian postures and intricate environments. This study proposes the RT-DETR-improved model to overcome these issues based on the real-time detection transformer (RT-DETR). First, we incorporate the high-low frequency (HiLo) attention into the encoder, therefore enhancing the model’s detection performance. Furthermore, we present a nonlinear feature fusion module that fuses information from various feature scales and contexts more successfully. We also introduce a novel loss function, InnerMPDIoU, to enhance detection efficacy in congested environments. To evaluate our model’s performance, extensive experiments are conducted on the CityPersons dataset. Compared to the baseline model, the RT-DETR-improved model attains a 4.2% enhancement in mAP50, a 2.0% improvement in mAP, a 2.2% rise in accuracy, and a 3.1% gain in recall. The results demonstrate that the proposed method exhibits superior detection accuracy and robustness.},
  archive      = {J_IJCIS},
  author       = {Wu, Tianyong and Li, Xiang and Dong, Qiuxuan},
  doi          = {10.1007/s44196-025-00791-x},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {An improved transformer-based model for urban pedestrian detection},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TraitBertGCN: Personality trait prediction using BertGCN
with data fusion technique. <em>IJCIS</em>, <em>18</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s44196-025-00792-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personality prediction via different techniques is an established and trending topic in psychology. The advancement of machine learning algorithms in multiple fields also attracted the attention of Automatic Personality Prediction (APP). This research proposes a novel TraitBertGCN method with a data fusion technique for predicting personality traits. Initially, this work integrates a pre-trained language model, Bidirectional Encoder Representations from Transformers (BERT), with a three-layer Graph Convolutional Network (GCN) to leverage large-scale language understanding and graph-based learning for personality prediction. This study fuses the two datasets (essays and myPersonality) to overcome the bias and generalize the model across different domains. We fine-tuned our TraitBertGCN model on the fused dataset and then evaluated it on both datasets individually to assess its adaptability and accuracy in varied contexts. We compared the proposed model’s results with previous studies; our model achieved better performance in personality trait prediction across multiple datasets, with an average accuracy of 77.42% on the essays dataset and 87.59% on the myPersonality dataset.},
  archive      = {J_IJCIS},
  author       = {Waqas, Muhammad and Zhang, Fengli and Laghari, Asif Ali and Almadhor, Ahmad and Petrinec, Filip and Iqbal, Asif and Khalil, Mian Muhammad Yasir},
  doi          = {10.1007/s44196-025-00792-w},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {TraitBertGCN: Personality trait prediction using BertGCN with data fusion technique},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hybrid differential evolutionary algorithm for
solving multi-objective distributed permutation flow-shop scheduling
problem. <em>IJCIS</em>, <em>18</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s44196-025-00793-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Distributed Permutation Flow-Shop Scheduling Problem (DPFSP) is a classic issue in distributed scheduling that involves job allocation and processing order within a factory, and it is known to be NP-hard. Numerous researchers have proposed various intelligent optimization algorithms to address the DPFSP; however, there are fewer studies related to the multi-objective DPFSP problem, and the algorithms for solving this problem also suffer from poor solution quality and tend to fall into local optimization and so on. To tackle the multi-objective DPFSP, this paper proposes a novel hybrid differential evolutionary algorithm aimed at minimizing both the maximum completion time and total delay time. In this algorithm, Bernoulli chaotic mapping is applied during the population initialization process to enhance the diversity of the initial population. Additionally, an adaptive mutation factor and crossover rate are designed to balance the global and local search capabilities of the algorithm. Furthermore, a novel selection strategy is constructed based on the NEH algorithm, specular reflection learning, and Pareto dominance relation to improve the quality of the solution set when solving instances of varying sizes. This strategy enhances the algorithm&#39;s optimization ability and helps it escape local optima. The effectiveness and superiority of the proposed algorithm are verified through 24 instances of different sizes. The results demonstrate that the proposed algorithm outperforms other improved algorithms in terms of convergence, and the uniformity and diversity of the solution set, making it an effective solution for the multi-objective distributed permutation flow-shop scheduling problem.},
  archive      = {J_IJCIS},
  author       = {Du, Xinzhe and Zhou, Yanping},
  doi          = {10.1007/s44196-025-00793-9},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {A novel hybrid differential evolutionary algorithm for solving multi-objective distributed permutation flow-shop scheduling problem},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research on cascade propagation of collaborative innovation
risks in industrial clusters considering entities heterogeneity.
<em>IJCIS</em>, <em>18</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s44196-025-00795-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study is to effectively mitigate the cascading propagation of collaborative innovation risks within industrial clusters and bolster the stability of their innovation networks. Drawing upon the cascade failure theory in complex networks, we employ the BA scale-free network model to construct an industrial cluster innovation network. We develop a cascade propagation model for collaborative innovation risk, addressing three dimensions: risk load, risk capacity, and load redistribution following node failures. To enhance the model, we propose a risk load distribution strategy that considers the heterogeneity among innovation entities, focusing on the similarity degree, importance degree, and cooperation degree of neighboring innovative entities. Through simulation experiments, we demonstrate that the integrated allocation strategy significantly improves the resistance to destruction of industrial cluster innovation networks. However, under intentional attacks, the resilience of these networks remains relatively weak. Further investigation reveals that the risk load capacity enhanced by the integrated allocation strategy can somewhat fortify the resistance of industrial cluster innovation networks to such attacks. The findings offer valuable insights for risk management and stability enhancement in industrial cluster innovation networks.},
  archive      = {J_IJCIS},
  author       = {Shi, Xiaowei and Wang, Jifa and Wang, Yang},
  doi          = {10.1007/s44196-025-00795-7},
  journal      = {International Journal of Computational Intelligence Systems},
  month        = {12},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Int. J. Comput. Intell. Syst.},
  title        = {Research on cascade propagation of collaborative innovation risks in industrial clusters considering entities heterogeneity},
  volume       = {18},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijcv---38">IJCV - 38</h2>
<ul>
<li><details>
<summary>
(2025). Correction: Continual face forgery detection via historical
distribution preserving. <em>IJCV</em>, <em>133</em>(4), 2246. (<a
href="https://doi.org/10.1007/s11263-024-02287-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCV},
  author       = {Sun, Ke and Chen, Shen and Yao, Taiping and Sun, Xiaoshuai and Ding, Shouhong and Ji, Rongrong},
  doi          = {10.1007/s11263-024-02287-1},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2246},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Correction: Continual face forgery detection via historical distribution preserving},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Multi-source-free domain adaptive object
detection. <em>IJCV</em>, <em>133</em>(4), 2245. (<a
href="https://doi.org/10.1007/s11263-024-02257-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCV},
  author       = {Zhao, Sicheng and Yao, Huizai and Lin, Chuang and Gao, Yue and Ding, Guiguang},
  doi          = {10.1007/s11263-024-02257-7},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2245},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Correction: Multi-source-free domain adaptive object detection},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diagnosing human-object interaction detectors.
<em>IJCV</em>, <em>133</em>(4), 2227–2244. (<a
href="https://doi.org/10.1007/s11263-025-02369-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have witnessed significant progress in human-object interaction (HOI) detection. However, relying solely on mAP (mean Average Precision) scores as a summary metric does not provide sufficient insight into the nuances of model performance (e.g., why one model outperforms another), which can hinder further innovation in this field. To address this issue, we introduce a diagnosis toolbox in this paper to offer a detailed quantitative breakdown of HOI detection models, inspired by the success of object detection diagnosis tools. We first conduct a holistic investigation into the HOI detection pipeline. By defining a set of errors and using oracles to fix each one, we quantitatively analyze the significance of different errors based on the mAP improvement gained from fixing them. Next, we explore the two key sub-tasks of HOI detection: human-object pair localization and interaction classification. For the pair localization task, we compute the coverage of ground-truth human-object pairs and assess the noisiness of the localization results. For the classification task, we measure a model’s ability to distinguish between positive and negative detection results and to classify actual interactions when human-object pairs are correctly localized. We analyze eight state-of-the-art HOI detection models, providing valuable diagnostic insights to guide future research. For instance, our diagnosis reveals that the state-of-the-art model RLIPv2 outperforms others primarily due to its significant improvement in multi-label interaction classification accuracy. Our toolbox is applicable across various methods and datasets and is available at https://neu-vi.github.io/Diag-HOI/ .},
  archive      = {J_IJCV},
  author       = {Zhu, Fangrui and Xie, Yiming and Xie, Weidi and Jiang, Huaizu},
  doi          = {10.1007/s11263-025-02369-8},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2227-2244},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Diagnosing human-object interaction detectors},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MVTN: Learning multi-view transformations for 3D
understanding. <em>IJCV</em>, <em>133</em>(4), 2197–2226. (<a
href="https://doi.org/10.1007/s11263-024-02283-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view projection techniques have shown themselves to be highly effective in achieving top-performing results in the recognition of 3D shapes. These methods involve learning how to combine information from multiple view-points. However, the camera view-points from which these views are obtained are often fixed for all shapes. To overcome the static nature of current multi-view techniques, we propose learning these view-points. Specifically, we introduce the Multi-View Transformation Network (MVTN), which uses differentiable rendering to determine optimal view-points for 3D shape recognition. As a result, MVTN can be trained end-to-end with any multi-view network for 3D shape classification. We integrate MVTN into a novel adaptive multi-view pipeline that is capable of rendering both 3D meshes and point clouds. Our approach demonstrates state-of-the-art performance in 3D classification and shape retrieval on several benchmarks (ModelNet40, ScanObjectNN, ShapeNet Core55). Further analysis indicates that our approach exhibits improved robustness to occlusion compared to other methods. We also investigate additional aspects of MVTN, such as 2D pretraining and its use for segmentation. To support further research in this area, we have released MVTorch, a PyTorch library for 3D understanding and generation using multi-view projections.},
  archive      = {J_IJCV},
  author       = {Hamdi, Abdullah and AlZahrani, Faisal and Giancola, Silvio and Ghanem, Bernard},
  doi          = {10.1007/s11263-024-02283-5},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2197-2226},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {MVTN: Learning multi-view transformations for 3D understanding},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive middle modality alignment learning for
visible-infrared person re-identification. <em>IJCV</em>,
<em>133</em>(4), 2176–2196. (<a
href="https://doi.org/10.1007/s11263-024-02276-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared person re-identification (VIReID) has attracted increasing attention due to the requirements for 24-hour intelligent surveillance systems. In this task, one of the major challenges is the modality discrepancy between the visible (VIS) and infrared (NIR) images. Most conventional methods try to design complex networks or generative models to mitigate the cross-modality discrepancy while ignoring the fact that the modality gaps differ between the different VIS and NIR images. Different from existing methods, in this paper, we propose an Adaptive Middle-modality Alignment Learning (AMML) method, which can effectively reduce the modality discrepancy via an adaptive middle modality learning strategy at both image level and feature level. The proposed AMML method enjoys several merits. First, we propose an Adaptive Middle-modality Generator (AMG) module to reduce the modality discrepancy between the VIS and NIR images from the image level, which can effectively project the VIS and NIR images into a unified middle modality image (UMMI) space to adaptively generate middle-modality (M-modality) images. Second, we propose a feature-level Adaptive Distribution Alignment (ADA) loss to force the distribution of the VIS features and NIR features adaptively align with the distribution of M-modality features. Moreover, we also propose a novel Center-based Diverse Distribution Learning (CDDL) loss, which can effectively learn diverse cross-modality knowledge from different modalities while reducing the modality discrepancy between the VIS and NIR modalities. Extensive experiments on three challenging VIReID datasets show the superiority of the proposed AMML method over the other state-of-the-art methods. More remarkably, our method achieves 77.8% in terms of Rank-1 and 74.8% in terms of mAP on the SYSU-MM01 dataset for all search mode, and 86.6% in terms of Rank-1 and 88.3% in terms of mAP on the SYSU-MM01 dataset for indoor search mode. The code is released at: https://github.com/ZYK100/MMN .},
  archive      = {J_IJCV},
  author       = {Zhang, Yukang and Yan, Yan and Lu, Yang and Wang, Hanzi},
  doi          = {10.1007/s11263-024-02276-4},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2176-2196},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Adaptive middle modality alignment learning for visible-infrared person re-identification},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking contemporary deep learning techniques for error
correction in biometric data. <em>IJCV</em>, <em>133</em>(4), 2158–2175.
(<a href="https://doi.org/10.1007/s11263-024-02280-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of cryptography, the implementation of error correction in biometric data offers many benefits, including secure data storage and key derivation. Deep learning-based decoders have emerged as a catalyst for improved error correction when decoding noisy biometric data. Although these decoders exhibit competence in approximating precise solutions, we expose the potential inadequacy of their security assurances through a minimum entropy analysis. This limitation curtails their applicability in secure biometric contexts, as the inherent complexities of their non-linear neural network architectures pose challenges in modeling the solution distribution precisely. To address this limitation, we introduce U-Sketch, a universal approach for error correction in biometrics, which converts arbitrary input random biometric source distributions into independent and identically distributed (i.i.d.) data while maintaining the pairwise distance of the data post-transformation. This method ensures interpretability within the decoder, facilitating transparent entropy analysis and a substantiated security claim. Moreover, U-Sketch employs Maximum Likelihood Decoding, which provides optimal error tolerance and a precise security guarantee.},
  archive      = {J_IJCV},
  author       = {Lai, YenLung and Dong, XingBo and Jin, Zhe and Jia, Wei and Tistarelli, Massimo and Li, XueJun},
  doi          = {10.1007/s11263-024-02280-8},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2158-2175},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Rethinking contemporary deep learning techniques for error correction in biometric data},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Day2Dark: Pseudo-supervised activity recognition beyond
silent daylight. <em>IJCV</em>, <em>133</em>(4), 2136–2157. (<a
href="https://doi.org/10.1007/s11263-024-02273-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper strives to recognize activities in the dark, as well as in the day. We first establish that state-of-the-art activity recognizers are effective during the day, but not trustworthy in the dark. The main causes are the limited availability of labeled dark videos to learn from, as well as the distribution shift towards the lower color contrast at test-time. To compensate for the lack of labeled dark videos, we introduce a pseudo-supervised learning scheme, which utilizes easy to obtain unlabeled and task-irrelevant dark videos to improve an activity recognizer in low light. As the lower color contrast results in visual information loss, we further propose to incorporate the complementary activity information within audio, which is invariant to illumination. Since the usefulness of audio and visual features differs depending on the amount of illumination, we introduce our ‘darkness-adaptive’ audio-visual recognizer. Experiments on EPIC-Kitchens, Kinetics-Sound, and Charades demonstrate our proposals are superior to image enhancement, domain adaptation and alternative audio-visual fusion methods, and can even improve robustness to local darkness caused by occlusions. Project page: https://xiaobai1217.github.io/Day2Dark/ .},
  archive      = {J_IJCV},
  author       = {Zhang, Yunhua and Doughty, Hazel and Snoek, Cees G. M.},
  doi          = {10.1007/s11263-024-02273-7},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2136-2157},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Day2Dark: Pseudo-supervised activity recognition beyond silent daylight},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EfficientDeRain+: Learning uncertainty-aware filtering via
RainMix augmentation for high-efficiency deraining. <em>IJCV</em>,
<em>133</em>(4), 2111–2135. (<a
href="https://doi.org/10.1007/s11263-024-02281-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deraining is a significant and fundamental computer vision task, aiming to remove the rain streaks and accumulations in an image or video. Existing deraining methods usually make heuristic assumptions of the rain model, which compels them to employ complex optimization or iterative refinement for high recovery quality. However, this leads to time-consuming methods and affects the effectiveness of addressing rain patterns, deviating from the assumptions. This paper proposes a simple yet efficient deraining method by formulating deraining as a predictive filtering problem without complex rain model assumptions. Specifically, we identify spatially-variant predictive filtering (SPFilt) that adaptively predicts proper kernels via a deep network to filter different individual pixels. Since the filtering can be implemented via well-accelerated convolution, our method can be significantly efficient. We further propose the EfDeRain+ that contains three main contributions to address residual rain traces, multi-scale, and diverse rain patterns without harming efficiency. First, we propose the uncertainty-aware cascaded predictive filtering (UC-PFilt) that can identify the difficulties of reconstructing clean pixels via predicted kernels and remove the residual rain traces effectively. Second, we design the weight-sharing multi-scale dilated filtering (WS-MS-DFilt) to handle multi-scale rain streaks without harming the efficiency. Third, to eliminate the gap across diverse rain patterns, we propose a novel data augmentation method (i.e., RainMix) to train our deep models. By combining all contributions with sophisticated analysis on different variants, our final method outperforms baseline methods on six single-image deraining datasets and one video-deraining dataset in terms of both recovery quality and speed. In particular, EfDeRain+ can derain within about 6.3 ms on a $$481\times 321$$ image and is over 74 times faster than the top baseline method with even better recovery quality. We release code in https://github.com/tsingqguo/efficientderainplus .},
  archive      = {J_IJCV},
  author       = {Guo, Qing and Qi, Hua and Sun, Jingyang and Juefei-Xu, Felix and Ma, Lei and Lin, Di and Feng, Wei and Wang, Song},
  doi          = {10.1007/s11263-024-02281-7},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2111-2135},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {EfficientDeRain+: Learning uncertainty-aware filtering via RainMix augmentation for high-efficiency deraining},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few annotated pixels and point cloud based weakly supervised
semantic segmentation of driving scenes. <em>IJCV</em>, <em>133</em>(4),
2096–2110. (<a
href="https://doi.org/10.1007/s11263-024-02275-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous weakly supervised semantic segmentation (WSSS) methods mainly begin with the segmentation seeds from the CAM method. Because of the high complexity of driving scene images, their framework performs not well on driving scene datasets. In this paper, we propose a new kind of WSSS annotations on the complex driving scene dataset, with only one or several labeled points per category. This annotation is more lightweight than image-level annotation and provides critical localization information for prototypes. We propose a framework to address the WSSS task under this annotation, which generates prototype feature vectors from labeled points and then produces 2D pseudo labels. Besides, we found the point cloud data is useful for distinguishing different objects. Our framework could extract rich semantic information from unlabeled point cloud data and generate instance masks, which does not require extra annotation resources. We combine the pseudo labels and the instance masks to modify the incorrect regions and thus obtain more accurate supervision for training the semantic segmentation network. We evaluated this framework on the KITTI dataset. Experiments show that the proposed method achieves state-of-the-art performance.},
  archive      = {J_IJCV},
  author       = {Ma, Huimin and Yi, Sheng and Chen, Shijie and Chen, Jiansheng and Wang, Yu},
  doi          = {10.1007/s11263-024-02275-5},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2096-2110},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Few annotated pixels and point cloud based weakly supervised semantic segmentation of driving scenes},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving procedure-aware instructional video correlation
learning under weak supervision from a collaborative perspective.
<em>IJCV</em>, <em>133</em>(4), 2070–2095. (<a
href="https://doi.org/10.1007/s11263-024-02272-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video Correlation Learning (VCL) delineates a high-level research domain that centers on analyzing the semantic and temporal correspondences between videos through a comparative paradigm. Recently, instructional video-related tasks have drawn increasing attention due to their promising potential. Compared with general videos, instructional videos possess more complex procedure information, making correlation learning quite challenging. To obtain procedural knowledge, current methods rely heavily on fine-grained step-level annotations, which are costly and non-scalable. To improve VCL on instructional videos, we introduce a weakly supervised framework named Collaborative Procedure Alignment (CPA). To be specific, our framework comprises two core components: the collaborative step mining (CSM) module and the frame-to-step alignment (FSA) module. Free of the necessity for step-level annotations, the CSM module can properly conduct temporal step segmentation and pseudo-step learning by exploring the inner procedure correspondences between paired videos. Subsequently, the FSA module efficiently yields the probability of aligning one video’s frame-level features with another video’s pseudo-step labels, which can act as a reliable correlation degree for paired videos. The two modules are inherently interconnected and can mutually enhance each other to extract the step-level knowledge and measure the video correlation distances accurately. Our framework provides an effective tool for instructional video correlation learning. We instantiate our framework on four representative tasks, including sequence verification, few-shot action recognition, temporal action segmentation, and action quality assessment. Furthermore, we extend our framework to more innovative functions to further exhibit its potential. Extensive and in-depth experiments validate CPA’s strong correlation learning capability on instructional videos. The implementation can be found at https://github.com/hotelll/Collaborative_Procedure_Alignment .},
  archive      = {J_IJCV},
  author       = {He, Tianyao and Liu, Huabin and Ni, Zelin and Li, Yuxi and Ma, Xiao and Zhong, Cheng and Zhang, Yang and Wang, Yingxue and Lin, Weiyao},
  doi          = {10.1007/s11263-024-02272-8},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2070-2095},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Achieving procedure-aware instructional video correlation learning under weak supervision from a collaborative perspective},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). APPTracker+: Displacement uncertainty for occlusion handling
in low-frame-rate multiple object tracking. <em>IJCV</em>,
<em>133</em>(4), 2044–2069. (<a
href="https://doi.org/10.1007/s11263-024-02237-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking (MOT) in the scenario of low-frame-rate videos is a promising solution to better meet the computing, storage, and transmitting bandwidth resource constraints of edge devices. Tracking with a low frame rate poses particular challenges in the association stage as objects in two successive frames typically exhibit much quicker variations in locations, velocities, appearances, and visibilities than those in normal frame rates. In this paper, we observe severe performance degeneration of many existing association strategies caused by such variations. Though optical-flow-based methods like CenterTrack can handle the large displacement to some extent due to their large receptive field, the temporally local nature makes them fail to give reliable displacement estimations of objects that newly appear in the current frame (i.e., not visible in the previous frame). To overcome the local nature of optical-flow-based methods, we propose an online tracking method by extending the CenterTrack architecture with a new head, named APP, to recognize unreliable displacement estimations. Further, to capture the fine-grained and private unreliability of each displacement estimation, we extend the binary APP predictions to displacement uncertainties. To this end, we reformulate the displacement estimation task via Bayesian deep learning tools. With APP predictions, we propose to conduct association in a multi-stage manner where vision cues or historical motion cues are leveraged in the corresponding stage. By rethinking the commonly used bipartite matching algorithms, we equip the proposed multi-stage association policy with a hybrid matching strategy conditioned on displacement uncertainties. Our method shows robustness in preserving identities in low-frame-rate video sequences. Experimental results on public datasets in various low-frame-rate settings demonstrate the advantages of the proposed method.},
  archive      = {J_IJCV},
  author       = {Zhou, Tao and Ye, Qi and Luo, Wenhan and Ran, Haizhou and Shi, Zhiguo and Chen, Jiming},
  doi          = {10.1007/s11263-024-02237-x},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2044-2069},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {APPTracker+: Displacement uncertainty for occlusion handling in low-frame-rate multiple object tracking},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anti-fake vaccine: Safeguarding privacy against face
swapping via visual-semantic dual degradation. <em>IJCV</em>,
<em>133</em>(4), 2025–2043. (<a
href="https://doi.org/10.1007/s11263-024-02259-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deepfake techniques pose a significant threat to personal privacy and social security. To mitigate these risks, various defensive techniques have been introduced, including passive methods through fake detection and proactive methods through adding invisible perturbations. Recent proactive methods mainly focus on face manipulation but perform poorly against face swapping, as face swapping involves the more complex process of identity information transfer. To address this issue, we develop a novel privacy-preserving framework, named Anti-Fake Vaccine, to protect the facial images against the malicious face swapping. This new proactive technique dynamically fuses visual corruption and content misdirection, significantly enhancing protection performance. Specifically, we first formulate constraints from two distinct perspectives: visual quality and identity semantics. The visual perceptual constraint targets image quality degradation in the visual space, while the identity similarity constraint induces erroneous alterations in the semantic space. We then introduce a multi-objective optimization solution to effectively balance the allocation of adversarial perturbations generated according to these constraints. To further improving performance, we develop an additive perturbation strategy to discover the shared adversarial perturbations across diverse face swapping models. Extensive experiments on the CelebA-HQ and FFHQ datasets demonstrate that our method exhibits superior generalization capabilities across diverse face swapping models, including commercial ones.},
  archive      = {J_IJCV},
  author       = {Li, Jingzhi and Luo, Changjiang and Zhang, Hua and Cao, Yang and Liao, Xin and Cao, Xiaochun},
  doi          = {10.1007/s11263-024-02259-5},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {2025-2043},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Anti-fake vaccine: Safeguarding privacy against face swapping via visual-semantic dual degradation},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Basis restricted elastic shape analysis on the space of
unregistered surfaces. <em>IJCV</em>, <em>133</em>(4), 1999–2024. (<a
href="https://doi.org/10.1007/s11263-024-02269-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new framework for surface analysis derived from the general setting of elastic Riemannian metrics on shape spaces. Traditionally, those metrics are defined over the infinite dimensional manifold of immersed surfaces and satisfy specific invariance properties enabling the comparison of surfaces modulo shape preserving transformations such as reparametrizations. The specificity of our approach is to restrict the space of allowable transformations to predefined finite dimensional bases of deformation fields. These are estimated in a data-driven way so as to emulate specific types of surface transformations. This allows us to simplify the representation of the corresponding shape space to a finite dimensional latent space. However, in sharp contrast with methods involving e.g. mesh autoencoders, the latent space is equipped with a non-Euclidean Riemannian metric inherited from the family of elastic metrics. We demonstrate how this model can be effectively implemented to perform a variety of tasks on surface meshes which, importantly, does not assume these to be pre-registered or to even have a consistent mesh structure. We specifically validate our approach on human body shape and pose data as well as human face and hand scans for problems such as shape registration, interpolation, motion transfer or random pose generation.},
  archive      = {J_IJCV},
  author       = {Hartman, Emmanuel and Pierson, Emery and Bauer, Martin and Daoudi, Mohamed and Charon, Nicolas},
  doi          = {10.1007/s11263-024-02269-3},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1999-2024},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Basis restricted elastic shape analysis on the space of unregistered surfaces},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving 3D finger traits recognition via generalizable
neural rendering. <em>IJCV</em>, <em>133</em>(4), 1964–1998. (<a
href="https://doi.org/10.1007/s11263-024-02248-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D biometric techniques on finger traits have become a new trend and have demonstrated a powerful ability for recognition and anti-counterfeiting. Existing methods follow an explicit 3D pipeline that reconstructs the models first and then extracts features from 3D models. However, these explicit 3D methods suffer from the following problems: 1) Inevitable information dropping during 3D reconstruction; 2) Tight coupling between specific hardware and algorithm for 3D reconstruction. It leads us to a question: Is it indispensable to reconstruct 3D information explicitly in recognition tasks? Hence, we consider this problem in an implicit manner, leaving the nerve-wracking 3D reconstruction problem for learnable neural networks with the help of neural radiance fields (NeRFs). We propose FingerNeRF, a novel generalizable NeRF for 3D finger biometrics. To handle the shape-radiance ambiguity problem that may result in incorrect 3D geometry, we aim to involve extra geometric priors based on the correspondence of binary finger traits like fingerprints or finger veins. First, we propose a novel Trait Guided Transformer (TGT) module to enhance the feature correspondence with the guidance of finger traits. Second, we involve extra geometric constraints on the volume rendering loss with the proposed Depth Distillation Loss and Trait Guided Rendering Loss. To evaluate the performance of the proposed method on different modalities, we collect two new datasets: SCUT-Finger-3D with finger images and SCUT-FingerVein-3D with finger vein images. Moreover, we also utilize the UNSW-3D dataset with fingerprint images for evaluation. In experiments, our FingerNeRF can achieve 4.37% EER on SCUT-Finger-3D dataset, 8.12% EER on SCUT-FingerVein-3D dataset, and 2.90% EER on UNSW-3D dataset, showing the superiority of the proposed implicit method in 3D finger biometrics.},
  archive      = {J_IJCV},
  author       = {Xu, Hongbin and Huang, Junduan and Ma, Yuer and Li, Zifeng and Kang, Wenxiong},
  doi          = {10.1007/s11263-024-02248-8},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1964-1998},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Improving 3D finger traits recognition via generalizable neural rendering},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A memory-assisted knowledge transferring framework with
curriculum anticipation for weakly supervised online activity detection.
<em>IJCV</em>, <em>133</em>(4), 1940–1963. (<a
href="https://doi.org/10.1007/s11263-024-02279-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial topic of high-level video understanding, weakly supervised online activity detection (WS-OAD) involves identifying the ongoing behaviors moment-to-moment in streaming videos, trained with solely cheap video-level annotations. It is essentially a challenging task, which requires addressing the entangled issues of the weakly supervised settings and online constraints. In this paper, we tackle the WS-OAD task from the knowledge-distillation (KD) perspective, which trains an online student detector to distill dual-level knowledge from a weakly supervised offline teacher model. To guarantee the completeness of knowledge transfer, we improve the vanilla KD framework from two aspects. First, we introduce an external memory bank to maintain the long-term activity prototypes, which serves as a bridge to align the activity semantics learned from the offline teacher and online student models. Second, to compensate the missing contexts of unseen near future, we leverage a curriculum learning paradigm to gradually train the online student detector to anticipate the future activity semantics. By dynamically scheduling the provided auxiliary future states, the online detector progressively distills contextual information from the offline model in an easy-to-hard course. Extensive experimental results on three public data sets demonstrate the superiority of our proposed method over the competing methods.},
  archive      = {J_IJCV},
  author       = {Liu, Tianshan and Lam, Kin-Man and Bao, Bing-Kun},
  doi          = {10.1007/s11263-024-02279-1},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1940-1963},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {A memory-assisted knowledge transferring framework with curriculum anticipation for weakly supervised online activity detection},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic attention vision-language transformer network for
person re-identification. <em>IJCV</em>, <em>133</em>(4), 1927–1939. (<a
href="https://doi.org/10.1007/s11263-024-02277-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal based person re-identification (ReID) has garnered increasing attention in recent years. However, the integration of visual and textual information encounters significant challenges. Biases in feature integration are frequently observed in existing methods, resulting in suboptimal performance and restricted generalization across a spectrum of ReID tasks. At the same time, since there is a domain gap between the datasets used by the pretraining model and the ReID datasets, it has a certain impact on the performance. In response to these challenges, we proposed a dynamic attention vision-language transformer network for the ReID task. In this network, a novel image-text dynamic attention module (ITDA) is designed to promote unbiased feature integration by dynamically assigning the importance of image and text representations. Additionally, an adapter module is adopted to address the domain gap between pretraining datasets and ReID datasets. Our network can capture complex connections between visual and textual information and achieve satisfactory performance. We conducted numerous experiments on ReID benchmarks to demonstrate the efficacy of our proposed method. The experimental results show that our method achieves state-of-the-art performance, surpassing existing integration strategies. These findings underscore the critical role of unbiased feature dynamic integration in enhancing the capabilities of multimodal based ReID models.},
  archive      = {J_IJCV},
  author       = {Zhang, Guifang and Tan, Shijun and Ji, Zhe and Fang, Yuming},
  doi          = {10.1007/s11263-024-02277-3},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1927-1939},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Dynamic attention vision-language transformer network for person re-identification},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sample correlation for fingerprinting deep face recognition.
<em>IJCV</em>, <em>133</em>(4), 1912–1926. (<a
href="https://doi.org/10.1007/s11263-024-02254-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition has witnessed remarkable advancements in recent years, thanks to the development of deep learning techniques. However, an off-the-shelf face recognition model as a commercial service could be stolen by model stealing attacks, posing great threats to the rights of the model owner. Model fingerprinting, as a model stealing detection method, aims to verify whether a suspect model is stolen from the victim model, gaining more and more attention nowadays. Previous methods always utilize transferable adversarial examples as the model fingerprint, but this method is known to be sensitive to adversarial defense and transfer learning techniques. To address this issue, we consider the pairwise relationship between samples instead and propose a novel yet simple model stealing detection method based on SAmple Correlation (SAC). Specifically, we present SAC-JC that selects JPEG compressed samples as model inputs and calculates the correlation matrix among their model outputs. Extensive results validate that SAC successfully defends against various model stealing attacks in deep face recognition, encompassing face verification and face emotion recognition, exhibiting the highest performance in terms of AUC, p-value and F1 score. Furthermore, we extend our evaluation of SAC-JC to object recognition datasets including Tiny-ImageNet and CIFAR10, which also demonstrates the superior performance of SAC-JC to previous methods. The code will be available at https://github.com/guanjiyang/SAC_JC .},
  archive      = {J_IJCV},
  author       = {Guan, Jiyang and Liang, Jian and Wang, Yanbo and He, Ran},
  doi          = {10.1007/s11263-024-02254-w},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1912-1926},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Sample correlation for fingerprinting deep face recognition},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StyleAdapter: A unified stylized image generation model.
<em>IJCV</em>, <em>133</em>(4), 1894–1911. (<a
href="https://doi.org/10.1007/s11263-024-02253-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on generating high-quality images with specific style of reference images and content of provided textual descriptions. Current leading algorithms, i.e., DreamBooth and LoRA, require fine-tuning for each style, leading to time-consuming and computationally expensive processes. In this work, we propose StyleAdapter, a unified stylized image generation model capable of producing a variety of stylized images that match both the content of a given prompt and the style of reference images, without the need for per-style fine-tuning. It introduces a two-path cross-attention (TPCA) module to separately process style information and textual prompt, which cooperate with a semantic suppressing vision model (SSVM) to suppress the semantic content of style images. In this way, it can ensure that the prompt maintains control over the content of the generated images, while also mitigating the negative impact of semantic information in style references. This results in the content of the generated image adhering to the prompt, and its style aligning with the style references. Besides, our StyleAdapter can be integrated with existing controllable synthesis methods, such as T2I-adapter and ControlNet, to attain a more controllable and stable generation process. Extensive experiments demonstrate the superiority of our method over previous works.},
  archive      = {J_IJCV},
  author       = {Wang, Zhouxia and Wang, Xintao and Xie, Liangbin and Qi, Zhongang and Shan, Ying and Wang, Wenping and Luo, Ping},
  doi          = {10.1007/s11263-024-02253-x},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1894-1911},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {StyleAdapter: A unified stylized image generation model},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Show-1: Marrying pixel and latent diffusion models for
text-to-video generation. <em>IJCV</em>, <em>133</em>(4), 1879–1893. (<a
href="https://doi.org/10.1007/s11263-024-02271-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant advancements have been achieved in the realm of large-scale pre-trained text-to-video Diffusion Models (VDMs). However, previous methods either rely solely on pixel-based VDMs, which come with high computational costs, or on latent-based VDMs, which often struggle with precise text-video alignment. In this paper, we are the first to propose a hybrid model, dubbed as Show-1, which marries pixel-based and latent-based VDMs for text-to-video generation. Our model first uses pixel-based VDMs to produce a low-resolution video of strong text-video correlation. After that, we propose a novel expert translation method that employs the latent-based VDMs to further upsample the low-resolution video to high resolution, which can also remove potential artifacts and corruptions from low-resolution videos. Compared to latent VDMs, Show-1 can produce high-quality videos of precise text-video alignment; Compared to pixel VDMs, Show-1 is much more efficient (GPU memory usage during inference is 15 G vs. 72 G). Furthermore, our Show-1 model can be readily adapted for motion customization and video stylization applications through simple temporal attention layer finetuning. Our model achieves state-of-the-art performance on standard video generation benchmarks. Code of Show-1 is publicly available and more videos can be found here .},
  archive      = {J_IJCV},
  author       = {Zhang, David Junhao and Wu, Jay Zhangjie and Liu, Jia-Wei and Zhao, Rui and Ran, Lingmin and Gu, Yuchao and Gao, Difei and Shou, Mike Zheng},
  doi          = {10.1007/s11263-024-02271-9},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1879-1893},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Show-1: Marrying pixel and latent diffusion models for text-to-video generation},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural vector fields for implicit surface representation and
inference. <em>IJCV</em>, <em>133</em>(4), 1855–1878. (<a
href="https://doi.org/10.1007/s11263-024-02251-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural implicit fields have recently shown increasing success in representing, learning and analysis of 3D shapes. Signed distance fields and occupancy fields are still the preferred choice of implicit representations with well-studied properties, despite their restriction to closed surfaces. With neural networks, unsigned distance fields as well as several other variations and training principles have been proposed with the goal to represent all classes of shapes. In this paper, we develop a novel and yet a fundamental representation considering unit vectors in 3D space and call it Vector Field (VF). At each point in $$\mathbb {R}^3$$ , VF is directed to the closest point on the surface. We theoretically demonstrate that VF can be easily transformed to surface density by computing the flux density. Unlike other standard representations, VF directly encodes an important physical property of the surface, its normal. We further show the advantages of VF representation, in learning open, closed, or multi-layered surfaces. We show that, thanks to the continuity property of the neural optimization with VF, a separate distance field becomes unnecessary for extracting surfaces from the implicit field via Marching Cubes. We compare our method on several datasets including ShapeNet where the proposed new neural implicit field shows superior accuracy in representing any type of shape, outperforming other standard methods. Codes are available at https://github.com/edomel/ImplicitVF .},
  archive      = {J_IJCV},
  author       = {Mello Rella, Edoardo and Chhatkuli, Ajad and Konukoglu, Ender and Van Gool, Luc},
  doi          = {10.1007/s11263-024-02251-z},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1855-1878},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Neural vector fields for implicit surface representation and inference},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning text-to-video retrieval from image captioning.
<em>IJCV</em>, <em>133</em>(4), 1834–1854. (<a
href="https://doi.org/10.1007/s11263-024-02202-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a protocol to study text-to-video retrieval training with unlabeled videos, where we assume (i) no access to labels for any videos, i.e., no access to the set of ground-truth captions, but (ii) access to labeled images in the form of text. Using image expert models is a realistic scenario given that annotating images is cheaper therefore scalable, in contrast to expensive video labeling schemes. Recently, zero-shot image experts such as CLIP have established a new strong baseline for video understanding tasks. In this paper, we make use of this progress and instantiate the image experts from two types of models: a text-to-image retrieval model to provide an initial backbone, and image captioning models to provide supervision signal into unlabeled videos. We show that automatically labeling video frames with image captioning allows text-to-video retrieval training. This process adapts the features to the target domain at no manual annotation cost, consequently outperforming the strong zero-shot CLIP baseline. During training, we sample captions from multiple video frames that best match the visual content, and perform a temporal pooling over frame representations by scoring frames according to their relevance to each caption. We conduct extensive ablations to provide insights and demonstrate the effectiveness of this simple framework by outperforming the CLIP zero-shot baselines on text-to-video retrieval on three standard datasets, namely ActivityNet, MSR-VTT, and MSVD. Code and models will be made publicly available.},
  archive      = {J_IJCV},
  author       = {Ventura, Lucas and Schmid, Cordelia and Varol, Gül},
  doi          = {10.1007/s11263-024-02202-8},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1834-1854},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Learning text-to-video retrieval from image captioning},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CogCartoon: Towards practical story visualization.
<em>IJCV</em>, <em>133</em>(4), 1808–1833. (<a
href="https://doi.org/10.1007/s11263-024-02267-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state-of-the-art methods for story visualization demonstrate a significant demand for training data and storage, as well as limited flexibility in story presentation, thereby rendering them impractical for real-world applications. We introduce CogCartoon, a practical story visualization method based on pre-trained diffusion models. To alleviate dependence on data and storage, we propose an innovative strategy of character-plugin generation that can represent a specific character as a compact 316 KB plugin by using a few training samples. To facilitate enhanced flexibility, we employ a strategy of plugin-guided and layout-guided inference, enabling users to seamlessly incorporate new characters and custom layouts into the generated image results at their convenience. We have conducted comprehensive qualitative and quantitative studies, providing compelling evidence for the superiority of CogCartoon over existing methodologies. Moreover, CogCartoon demonstrates its power in tackling challenging tasks, including long story visualization and realistic style story visualization.},
  archive      = {J_IJCV},
  author       = {Zhu, Zhongyang and Tang, Jie},
  doi          = {10.1007/s11263-024-02267-5},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1808-1833},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {CogCartoon: Towards practical story visualization},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AgMTR: Agent mining transformer for few-shot segmentation in
remote sensing. <em>IJCV</em>, <em>133</em>(4), 1780–1807. (<a
href="https://doi.org/10.1007/s11263-024-02252-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Segmentation aims to segment the interested objects in the query image with just a handful of labeled samples (i.e., support images). Previous schemes would leverage the similarity between support-query pixel pairs to construct the pixel-level semantic correlation. However, in remote sensing scenarios with extreme intra-class variations and cluttered backgrounds, such pixel-level correlations may produce tremendous mismatches, resulting in semantic ambiguity between the query foreground (FG) and background (BG) pixels. To tackle this problem, we propose a novel Agent Mining Transformer, which adaptively mines a set of local-aware agents to construct agent-level semantic correlation. Compared with pixel-level semantics, the given agents are equipped with local-contextual information and possess a broader receptive field. At this point, different query pixels can selectively aggregate the fine-grained local semantics of different agents, thereby enhancing the semantic clarity between query FG and BG pixels. Concretely, the Agent Learning Encoder is first proposed to erect the optimal transport plan that arranges different agents to aggregate support semantics under different local regions. Then, for further optimizing the agents, the Agent Aggregation Decoder and the Semantic Alignment Decoder are constructed to break through the limited support set for mining valuable class-specific semantics from unlabeled data sources and the query image itself, respectively. Extensive experiments on the remote sensing benchmark iSAID indicate that the proposed method achieves state-of-the-art performance. Surprisingly, our method remains quite competitive when extended to more common natural scenarios, i.e., PASCAL- $$5^i$$ and COCO- $$20^{i}$$ .},
  archive      = {J_IJCV},
  author       = {Bi, Hanbo and Feng, Yingchao and Mao, Yongqiang and Pei, Jianning and Diao, Wenhui and Wang, Hongqi and Sun, Xian},
  doi          = {10.1007/s11263-024-02252-y},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1780-1807},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {AgMTR: Agent mining transformer for few-shot segmentation in remote sensing},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interweaving insights: High-order feature interaction for
fine-grained visual recognition. <em>IJCV</em>, <em>133</em>(4),
1755–1779. (<a
href="https://doi.org/10.1007/s11263-024-02260-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach for Fine-Grained Visual Classification (FGVC) by exploring Graph Neural Networks (GNNs) to facilitate high-order feature interactions, with a specific focus on constructing both inter- and intra-region graphs. Unlike previous FGVC techniques that often isolate global and local features, our method combines both features seamlessly during learning via graphs. Inter-region graphs capture long-range dependencies to recognize global patterns, while intra-region graphs delve into finer details within specific regions of an object by exploring high-dimensional convolutional features. A key innovation is the use of shared GNNs with an attention mechanism coupled with the Approximate Personalized Propagation of Neural Predictions (APPNP) message-passing algorithm, enhancing information propagation efficiency for better discriminability and simplifying the model architecture for computational efficiency. Additionally, the introduction of residual connections improves performance and training stability. Comprehensive experiments showcase state-of-the-art results on benchmark FGVC datasets, affirming the efficacy of our approach. This work underscores the potential of GNN in modeling high-level feature interactions, distinguishing it from previous FGVC methods that typically focus on singular aspects of feature representation. Our source code is available at https://github.com/Arindam-1991/I2-HOFI .},
  archive      = {J_IJCV},
  author       = {Sikdar, Arindam and Liu, Yonghuai and Kedarisetty, Siddhardha and Zhao, Yitian and Ahmed, Amr and Behera, Ardhendu},
  doi          = {10.1007/s11263-024-02260-y},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1755-1779},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Interweaving insights: High-order feature interaction for fine-grained visual recognition},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the generalization and causal explanation in
self-supervised learning. <em>IJCV</em>, <em>133</em>(4), 1727–1754. (<a
href="https://doi.org/10.1007/s11263-024-02263-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning (SSL) methods learn from unlabeled data and achieve high generalization performance on downstream tasks. However, they may also suffer from overfitting to their training data and lose the ability to adapt to new tasks. To investigate this phenomenon, we conduct experiments on various SSL methods and datasets and make two observations: (1) Overfitting occurs abruptly in later layers and epochs, while generalizing features are learned in early layers for all epochs; (2) Coding rate reduction can be used as an indicator to measure the degree of overfitting in SSL models. Based on these observations, we propose Undoing Memorization Mechanism (UMM), a plug-and-play method that mitigates overfitting of the pre-trained feature extractor by aligning the feature distributions of the early and the last layers to maximize the coding rate reduction of the last layer output. The learning process of UMM is a bi-level optimization process. We provide a causal analysis of UMM to explain how UMM can help the pre-trained feature extractor overcome overfitting and recover generalization. We also demonstrate that UMM significantly improves the generalization performance of SSL methods on various downstream tasks. The source code is to be released at https://github.com/ZeenSong/UMM .},
  archive      = {J_IJCV},
  author       = {Qiang, Wenwen and Song, Zeen and Gu, Ziyin and Li, Jiangmeng and Zheng, Changwen and Sun, Fuchun and Xiong, Hui},
  doi          = {10.1007/s11263-024-02263-9},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1727-1754},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {On the generalization and causal explanation in self-supervised learning},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facial action unit detection by adaptively constraining
self-attention and causally deconfounding sample. <em>IJCV</em>,
<em>133</em>(4), 1711–1726. (<a
href="https://doi.org/10.1007/s11263-024-02258-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial action unit (AU) detection remains a challenging task, due to the subtlety, dynamics, and diversity of AUs. Recently, the prevailing techniques of self-attention and causal inference have been introduced to AU detection. However, most existing methods directly learn self-attention guided by AU detection, or employ common patterns for all AUs during causal intervention. The former often captures irrelevant information in a global range, and the latter ignores the specific causal characteristic of each AU. In this paper, we propose a novel AU detection framework called $$\textrm{AC}^{2}$$ D by adaptively constraining self-attention weight distribution and causally deconfounding the sample confounder. Specifically, we explore the mechanism of self-attention weight distribution, in which the self-attention weight distribution of each AU is regarded as spatial distribution and is adaptively learned under the constraint of location-predefined attention and the guidance of AU detection. Moreover, we propose a causal intervention module for each AU, in which the bias caused by training samples and the interference from irrelevant AUs are both suppressed. Extensive experiments show that our method achieves competitive performance compared to state-of-the-art AU detection approaches on challenging benchmarks, including BP4D, DISFA, GFT, and BP4D+ in constrained scenarios and Aff-Wild2 in unconstrained scenarios.},
  archive      = {J_IJCV},
  author       = {Shao, Zhiwen and Zhu, Hancheng and Zhou, Yong and Xiang, Xiang and Liu, Bing and Yao, Rui and Ma, Lizhuang},
  doi          = {10.1007/s11263-024-02258-6},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1711-1726},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Facial action unit detection by adaptively constraining self-attention and causally deconfounding sample},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards data-centric face anti-spoofing: Improving
cross-domain generalization via physics-based data synthesis.
<em>IJCV</em>, <em>133</em>(4), 1689–1710. (<a
href="https://doi.org/10.1007/s11263-024-02240-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Anti-Spoofing (FAS) research is challenged by the cross-domain problem, where there is a domain gap between the training and testing data. While recent FAS works are mainly model-centric, focusing on developing domain generalization algorithms for improving cross-domain performance, data-centric research for face anti-spoofing, improving generalization from data quality and quantity, is largely ignored. Therefore, our work starts with data-centric FAS by conducting a comprehensive investigation from the data perspective for improving cross-domain generalization of FAS models. More specifically, at first, based on physical procedures of capturing and recapturing, we propose task-specific FAS data augmentation (FAS-Aug), which increases data diversity by synthesizing data of artifacts, such as printing noise, color distortion, moiré pattern, etc. Our experiments show that using our FAS augmentation can surpass traditional image augmentation in training FAS models to achieve better cross-domain performance. Nevertheless, we observe that models may rely on the augmented artifacts, which are not environment-invariant, and using FAS-Aug may have a negative effect. As such, we propose Spoofing Attack Risk Equalization (SARE) to prevent models from relying on certain types of artifacts and improve the generalization performance. Last but not least, our proposed FAS-Aug and SARE with recent Vision Transformer backbones can achieve state-of-the-art performance on the FAS cross-domain generalization protocols. The implementation is available at https://github.com/RizhaoCai/FAS-Aug .},
  archive      = {J_IJCV},
  author       = {Cai, Rizhao and Soh, Cecelia and Yu, Zitong and Li, Haoliang and Yang, Wenhan and Kot, Alex C.},
  doi          = {10.1007/s11263-024-02240-2},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1689-1710},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Towards data-centric face anti-spoofing: Improving cross-domain generalization via physics-based data synthesis},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blind multimodal quality assessment of low-light images.
<em>IJCV</em>, <em>133</em>(4), 1665–1688. (<a
href="https://doi.org/10.1007/s11263-024-02239-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind image quality assessment (BIQA) aims at automatically and accurately forecasting objective scores for visual signals, which has been widely used to monitor product and service quality in low-light applications, covering smartphone photography, video surveillance, autonomous driving, etc. Recent developments in this field are dominated by unimodal solutions inconsistent with human subjective rating patterns, where human visual perception is simultaneously reflected by multiple sensory information. In this article, we present a unique blind multimodal quality assessment (BMQA) of low-light images from subjective evaluation to objective score. To investigate the multimodal mechanism, we first establish a multimodal low-light image quality (MLIQ) database with authentic low-light distortions, containing image-text modality pairs. Further, we specially design the key modules of BMQA, considering multimodal quality representation, latent feature alignment and fusion, and hybrid self-supervised and supervised learning. Extensive experiments show that our BMQA yields state-of-the-art accuracy on the proposed MLIQ benchmark database. In particular, we also build an independent single-image modality Dark-4K database, which is used to verify its applicability and generalization performance in mainstream unimodal applications. Qualitative and quantitative results on Dark-4K show that BMQA achieves superior performance to existing BIQA approaches as long as a pre-trained model is provided to generate text descriptions. The proposed framework and two databases as well as the collected BIQA methods and evaluation metrics are made publicly available on https://charwill.github.io/bmqa.html .},
  archive      = {J_IJCV},
  author       = {Wang, Miaohui and Xu, Zhuowei and Xu, Mai and Lin, Weisi},
  doi          = {10.1007/s11263-024-02239-9},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1665-1688},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Blind multimodal quality assessment of low-light images},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Audio-visual segmentation with semantics. <em>IJCV</em>,
<em>133</em>(4), 1644–1664. (<a
href="https://doi.org/10.1007/s11263-024-02261-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new problem called audio-visual segmentation (AVS), in which the goal is to output a pixel-level map of the object(s) that produce sound at the time of the image frame. To facilitate this research, we construct the first audio-visual segmentation benchmark, i.e., AVSBench, providing pixel-wise annotations for sounding objects in audible videos. It contains three subsets: AVSBench-object (Single-source subset, Multi-sources subset) and AVSBench-semantic (Semantic-labels subset). Accordingly, three settings are studied: 1) semi-supervised audio-visual segmentation with a single sound source; 2) fully-supervised audio-visual segmentation with multiple sound sources, and 3) fully-supervised audio-visual semantic segmentation. The first two settings need to generate binary masks of sounding objects indicating pixels corresponding to the audio, while the third setting further requires to generate semantic maps indicating the object category. To deal with these problems, we propose a new baseline method that uses a temporal pixel-wise audio-visual interaction module to inject audio semantics as guidance for the visual segmentation process. We also design a regularization loss to encourage audio-visual mapping during training. Quantitative and qualitative experiments on the AVSBench dataset compare our approach to several existing methods for related tasks, demonstrating that the proposed method is promising for building a bridge between the audio and pixel-wise visual semantics. Code can be found at https://github.com/OpenNLPLab/AVSBench .},
  archive      = {J_IJCV},
  author       = {Zhou, Jinxing and Shen, Xuyang and Wang, Jianyuan and Zhang, Jiayi and Sun, Weixuan and Zhang, Jing and Birchfield, Stan and Guo, Dan and Kong, Lingpeng and Wang, Meng and Zhong, Yiran},
  doi          = {10.1007/s11263-024-02261-x},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1644-1664},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Audio-visual segmentation with semantics},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning accurate low-bit quantization towards efficient
computational imaging. <em>IJCV</em>, <em>133</em>(4), 1611–1643. (<a
href="https://doi.org/10.1007/s11263-024-02250-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances of deep neural networks (DNNs) promote low-level vision applications in real-world scenarios, e.g., image enhancement, dehazing. Nevertheless, DNN-based methods encounter challenges in terms of high computational and memory requirements, especially when deployed on real-world devices with limited resources. Quantization is one of effective compression techniques that significantly reduces computational and memory requirements by employing low-bit parameters and bit-wise operations. However, low-bit quantization for computational imaging (Q-Imaging) remains largely unexplored and usually suffer from a significant performance drop compared with the real-valued counterparts. In this work, through empirical analysis, we identify the main factor responsible for such significant performance drop underlies in the large gradient estimation error from non-differentiable weight quantization methods, and the activation information degeneration along with the activation quantization. To address these issues, we introduce a differentiable quantization search (DQS) method to learn the quantized weights and an information boosting module (IBM) for network activation quantization. Our DQS method allows us to treat the discrete weights in a quantized neural network as variables that can be searched. We achieve this end by using a differential approach to accurately search for these weights. In specific, each weight is represented as a probability distribution across a set of discrete values. During training, these probabilities are optimized, and the values with the highest probabilities are chosen to construct the desired quantized network. Moreover, our IBM module can rectify the activation distribution before quantization to maximize the self-information entropy, which retains the maximum information during the quantization process. Extensive experiments across a range of image processing tasks, including enhancement, super-resolution, denoising and dehazing, validate the effectiveness of our Q-Imaging along with superior performances compared to a variety of state-of-the-art quantization methods. In particular, the method in Q-Imaging also achieves a strong generalization performance when composing a detection network for the dark object detection task.},
  archive      = {J_IJCV},
  author       = {Xu, Sheng and Li, Yanjing and Liu, Chuanjian and Zhang, Baochang},
  doi          = {10.1007/s11263-024-02250-0},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1611-1643},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Learning accurate low-bit quantization towards efficient computational imaging},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards ultra high-speed hyperspectral imaging by
integrating compressive and neuromorphic sampling. <em>IJCV</em>,
<em>133</em>(4), 1587–1610. (<a
href="https://doi.org/10.1007/s11263-024-02236-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral and high-speed imaging are both important for scene representation and understanding. However, simultaneously capturing both hyperspectral and high-speed data is still under-explored. In this work, we propose a high-speed hyperspectral imaging system by integrating compressive sensing sampling with bioinspired neuromorphic sampling. Our system includes a coded aperture snapshot spectral imager capturing moderate-speed hyperspectral measurement frames and a spike camera capturing high-speed grayscale dense spike streams. The two cameras provide complementary dual-modality data for reconstructing high-speed hyperspectral videos (HSV). To effectively synergize the two sampling mechanisms and obtain high-quality HSV, we propose a unified multi-modal reconstruction framework. The framework consists of a Spike Spectral Prior Network for spike-based information extraction and prior regularization, coupled with a dual-modality iterative optimization algorithm for reliable reconstruction. We finally build a hardware prototype to verify the effectiveness of our system and algorithm design. Experiments on both simulated and real data demonstrate the superiority of the proposed approach, where for the first time to our knowledge, high-speed HSV with 30 spectral bands can be captured at a frame rate of up to 20,000 FPS.},
  archive      = {J_IJCV},
  author       = {Geng, Mengyue and Wang, Lizhi and Zhu, Lin and Zhang, Wei and Xiong, Ruiqin and Tian, Yonghong},
  doi          = {10.1007/s11263-024-02236-y},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1587-1610},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Towards ultra high-speed hyperspectral imaging by integrating compressive and neuromorphic sampling},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 4Seasons: Benchmarking visual SLAM and long-term
localization for autonomous driving in challenging conditions.
<em>IJCV</em>, <em>133</em>(4), 1564–1586. (<a
href="https://doi.org/10.1007/s11263-024-02230-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel visual SLAM and long-term localization benchmark for autonomous driving in challenging conditions based on the large-scale 4Seasons dataset. The proposed benchmark provides drastic appearance variations caused by seasonal changes and diverse weather and illumination conditions. While significant progress has been made in advancing visual SLAM on small-scale datasets with similar conditions, there is still a lack of unified benchmarks representative of real-world scenarios for autonomous driving. We introduce a new unified benchmark for jointly evaluating visual odometry, global place recognition, and map-based visual localization performance which is crucial to successfully enable autonomous driving in any condition. The data has been collected for more than one year, resulting in more than 300 km of recordings in nine different environments ranging from a multi-level parking garage to urban (including tunnels) to countryside and highway. We provide globally consistent reference poses with up to centimeter-level accuracy obtained from the fusion of direct stereo-inertial odometry with RTK GNSS. We evaluate the performance of several state-of-the-art visual odometry and visual localization baseline approaches on the benchmark and analyze their properties. The experimental results provide new insights into current approaches and show promising potential for future research. Our benchmark and evaluation protocols will be available at https://go.vision.in.tum.de/4seasons .},
  archive      = {J_IJCV},
  author       = {Wenzel, Patrick and Yang, Nan and Wang, Rui and Zeller, Niclas and Cremers, Daniel},
  doi          = {10.1007/s11263-024-02230-4},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1564-1586},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {4Seasons: Benchmarking visual SLAM and long-term localization for autonomous driving in challenging conditions},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge-oriented adversarial attack for deep gait recognition.
<em>IJCV</em>, <em>133</em>(4), 1549–1563. (<a
href="https://doi.org/10.1007/s11263-024-02225-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is a non-intrusive method that captures unique walking patterns without subject cooperation, which has emerged as a promising technique across various fields. Recent studies based on Deep Neural Networks (DNNs) have notably improved the performance, however, the potential vulnerability inherent in DNNs and their resistance to interference in practical gait recognition systems remain under-explored. To fill the gap, in this paper, we focus on imperceptible adversarial attack for deep gait recognition and propose an edge-oriented attack strategy tailored for silhouette-based approaches. Specifically, we make a pioneering attempt to explore the intrinsic characteristics of binary silhouettes, with a primary focus on injecting noise perturbations into the edge area. This simple yet effective solution enables sparse attack in both the spatial and temporal dimensions, which largely ensures imperceptibility and simultaneously achieves high success rate. In particular, our solution is built on a unified framework, allowing seamless switching between untargeted and targeted attack modes. Extensive experiments conducted on in-the-lab and in-the-wild benchmarks validate the effectiveness of our attack strategy and emphasize the necessity to study adversarial attack and defense strategy in the near future.},
  archive      = {J_IJCV},
  author       = {Hou, Saihui and Wang, Zengbin and Zhang, Man and Cao, Chunshui and Liu, Xu and Huang, Yongzhen},
  doi          = {10.1007/s11263-024-02225-1},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1549-1563},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Edge-oriented adversarial attack for deep gait recognition},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining generalized multi-timescale inconsistency for
detecting deepfake videos. <em>IJCV</em>, <em>133</em>(4), 1532–1548.
(<a href="https://doi.org/10.1007/s11263-024-02249-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in face forgery techniques have continuously evolved, leading to emergent security concerns in society. Existing detection methods have poor generalization ability due to the insufficient extraction of dynamic inconsistency cues on the one hand, and their inability to deal well with the gaps between forgery techniques on the other hand. To develop a new generalized framework that emphasizes extracting generalizable multi-timescale inconsistency cues. Firstly, we capture subtle dynamic inconsistency via magnifying the multipath dynamic inconsistency from the local-consecutive short-term temporal view. Secondly, the inter-group graph learning is conducted to establish the sufficient-interactive long-term temporal view for capturing dynamic inconsistency comprehensively. Finally, we design the domain alignment module to directly reduce the distribution gaps via simultaneously disarranging inter- and intra-domain feature distributions for obtaining a more generalized framework. Extensive experiments on six large-scale datasets and the designed generalization evaluation protocols show that our framework outperforms state-of-the-art deepfake video detection methods.},
  archive      = {J_IJCV},
  author       = {Yu, Yang and Ni, Rongrong and Yang, Siyuan and Ni, Yu and Zhao, Yao and Kot, Alex C.},
  doi          = {10.1007/s11263-024-02249-7},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1532-1548},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Mining generalized multi-timescale inconsistency for detecting deepfake videos},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DLRA-net: Deep local residual attention network with
contextual refinement for spectral super-resolution. <em>IJCV</em>,
<em>133</em>(4), 1499–1531. (<a
href="https://doi.org/10.1007/s11263-024-02238-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral Images (HSIs) provide detailed scene insights using extensive spectral bands, crucial for material discrimination and earth observation with substantial costs and low spatial resolution. Recently, Convolutional Neural Networks (CNNs) are common choice for Spectral Super-Resolution (SSR) from Multispectral Images (MSIs). However, they often fail to simultaneously exploit pixel-level noise degradation of MSIs and complex contextual spatial-spectral characteristics of HSIs. In this paper, a Deep Local Residual Attention Network with Contextual Refinement Network (DLRA-Net) is proposed to integrate local low-rank spectral and global contextual priors for improved SSR. Specifically, SSR is unfolded into Contextual-attention Refinement Module (CRM) and Dual Local Residual Attention Module (DLRAM). CRM is proposed to adaptively learn complex contextual priors to guide the convolution layer weights for improved spatial restorations. While DLRAM captures deep refined texture details to enhance contextual priors representations for recovering HSIs. Moreover, lateral fusion strategy is designed to integrate the obtained priors among DLRAMs for faster network convergence. Experimental results on natural-scene datasets with practical noise patterns confirm exceptional DLRA-Net performance with relatively small model size. DLRA-Net demonstrates Maximum Relative Improvements (MRI) between 9.71 and 58.58% in Mean Relative Absolute Error (MRAE) with reduced parameters between 52.18 and 85.85%. Besides, a practical RS-HSI dataset is generated for evaluations showing MRI between 8.64 and 50.56% in MRAE. Furthermore, experiments with HSI classifiers indicate improved performance of reconstructed RS-HSIs compared to RS-MSIs, with MRI in Overall Accuracy (OA) between 7.10 and 15.27%. Lastly, a detailed ablation study assesses model complexity and runtime.},
  archive      = {J_IJCV},
  author       = {El-gabri, Ahmed R. and Aly, Hussein A. and Ghoniemy, Tarek S. and Elshafey, Mohamed A.},
  doi          = {10.1007/s11263-024-02238-w},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1499-1531},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {DLRA-net: Deep local residual attention network with contextual refinement for spectral super-resolution},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using unreliable pseudo-labels for label-efficient semantic
segmentation. <em>IJCV</em>, <em>133</em>(4), 1476–1498. (<a
href="https://doi.org/10.1007/s11263-024-02229-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The crux of label-efficient semantic segmentation is to produce high-quality pseudo-labels to leverage a large amount of unlabeled or weakly labeled data. A common practice is to select the highly confident predictions as the pseudo-ground-truths for each pixel, but it leads to a problem that most pixels may be left unused due to their unreliability. However, we argue that every pixel matters to the model training, even those unreliable and ambiguous pixels. Intuitively, an unreliable prediction may get confused among the top classes, however, it should be confident about the pixel not belonging to the remaining classes. Hence, such a pixel can be convincingly treated as a negative key to those most unlikely categories. Therefore, we develop an effective pipeline to make sufficient use of unlabeled data. Concretely, we separate reliable and unreliable pixels via the entropy of predictions, push each unreliable pixel to a category-wise queue that consists of negative keys, and manage to train the model with all candidate pixels. Considering the training evolution, we adaptively adjust the threshold for the reliable-unreliable partition. Experimental results on various benchmarks and training settings demonstrate the superiority of our approach over the state-of-the-art alternatives.},
  archive      = {J_IJCV},
  author       = {Wang, Haochen and Wang, Yuchao and Shen, Yujun and Fan, Junsong and Wang, Yuxi and Zhang, Zhaoxiang},
  doi          = {10.1007/s11263-024-02229-x},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1476-1498},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Using unreliable pseudo-labels for label-efficient semantic segmentation},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MosaicFusion: Diffusion models as data augmenters for large
vocabulary instance segmentation. <em>IJCV</em>, <em>133</em>(4),
1456–1475. (<a
href="https://doi.org/10.1007/s11263-024-02223-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present MosaicFusion, a simple yet effective diffusion-based data augmentation approach for large vocabulary instance segmentation. Our method is training-free and does not rely on any label supervision. Two key designs enable us to employ an off-the-shelf text-to-image diffusion model as a useful dataset generator for object instances and mask annotations. First, we divide an image canvas into several regions and perform a single round of diffusion process to generate multiple instances simultaneously, conditioning on different text prompts. Second, we obtain corresponding instance masks by aggregating cross-attention maps associated with object prompts across layers and diffusion time steps, followed by simple thresholding and edge-aware refinement processing. Without bells and whistles, our MosaicFusion can produce a significant amount of synthetic labeled data for both rare and novel categories. Experimental results on the challenging LVIS long-tailed and open-vocabulary benchmarks demonstrate that MosaicFusion can significantly improve the performance of existing instance segmentation models, especially for rare and novel categories. Code: https://github.com/Jiahao000/MosaicFusion .},
  archive      = {J_IJCV},
  author       = {Xie, Jiahao and Li, Wei and Li, Xiangtai and Liu, Ziwei and Ong, Yew Soon and Loy, Chen Change},
  doi          = {10.1007/s11263-024-02223-3},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1456-1475},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {MosaicFusion: Diffusion models as data augmenters for large vocabulary instance segmentation},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Group-based distinctive image captioning with memory
difference encoding and attention. <em>IJCV</em>, <em>133</em>(4),
1435–1455. (<a
href="https://doi.org/10.1007/s11263-024-02220-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in image captioning have focused on enhancing accuracy by substantially increasing the dataset and model size. While conventional captioning models exhibit high performance on established metrics such as BLEU, CIDEr, and SPICE, the capability of captions to distinguish the target image from other similar images is under-explored. To generate distinctive captions, a few pioneers employed contrastive learning or re-weighted the ground-truth captions. However, these approaches often overlook the relationships among objects in a similar image group (e.g., items or properties within the same album or fine-grained events). In this paper, we introduce a novel approach to enhance the distinctiveness of image captions, namely Group-based Differential Distinctive Captioning Method, which visually compares each image with other images in one similar group and highlights the uniqueness of each image. In particular, we introduce a Group-based Differential Memory Attention (GDMA) module, designed to identify and emphasize object features in an image that are uniquely distinguishable within its image group, i.e., those exhibiting low similarity with objects in other images. This mechanism ensures that such unique object features are prioritized during caption generation for the image, thereby enhancing the distinctiveness of the resulting captions. To further refine this process, we select distinctive words from the ground-truth captions to guide both the language decoder and the GDMA module. Additionally, we propose a new evaluation metric, the Distinctive Word Rate (DisWordRate), to quantitatively assess caption distinctiveness. Quantitative results indicate that the proposed method significantly improves the distinctiveness of several baseline models, and achieves state-of-the-art performance on distinctiveness while not excessively sacrificing accuracy. Moreover, the results of our user study are consistent with the quantitative evaluation and demonstrate the rationality of the new metric DisWordRate.},
  archive      = {J_IJCV},
  author       = {Wang, Jiuniu and Xu, Wenjia and Wang, Qingzhong and Chan, Antoni B.},
  doi          = {10.1007/s11263-024-02220-6},
  journal      = {International Journal of Computer Vision},
  month        = {4},
  number       = {4},
  pages        = {1435-1455},
  shortjournal = {Int. J. Comput. Vis.},
  title        = {Group-based distinctive image captioning with memory difference encoding and attention},
  volume       = {133},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijdar---10">IJDAR - 10</h2>
<ul>
<li><details>
<summary>
(2025). Deep learning approaches for information extraction from
visually rich documents: Datasets, challenges and methods.
<em>IJDAR</em>, <em>28</em>(1), 121–142. (<a
href="https://doi.org/10.1007/s10032-024-00493-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on Information Extraction from Visually Rich Documents, exploring how deep learning methods are applied in this field. For the purpose of comparing the performance of available resources, including datasets and methods, we first investigate an overview of the existing datasets. Then, we categorize and review published methods, highlighting their strengths and weaknesses in addressing key challenges like text recognition, layout analysis, and information fusion. This survey serves as a valuable resource for researchers and practitioners seeking to advance the field of information extraction (IE) from visually rich documents (VRD) and contribute to its real-world applications.},
  archive      = {J_IJDAR},
  author       = {Gbada, Hamza and Kalti, Karim and Mahjoub, Mohamed Ali},
  doi          = {10.1007/s10032-024-00493-8},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {121-142},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Deep learning approaches for information extraction from visually rich documents: Datasets, challenges and methods},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning-based modified-EAST scene text detector:
Insights from a novel multiscript dataset. <em>IJDAR</em>,
<em>28</em>(1), 97–119. (<a
href="https://doi.org/10.1007/s10032-024-00491-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of computer vision has seen significant transformation with the emergence and advancement of deep learning models. Deep learning waves have a significant impact on scene text detection, a vital and active area in computer vision. Numerous scientific, industrial, and academic procedures make use of text analysis. Natural scene text detection is more difficult than document image text detection owing to variations in font, size, style, brightness, etc. The National Institute of Technology Jalandhar-Text Detection dataset (NITJ-TD) is a new dataset that we have put forward in this study for various text analysis tasks including text detection, text segmentation, script identification, text recognition, etc. a deep learning model that seeks to identify the text’s location within the image,which are gathered in an unrestricted setting. The system consists of an NMS to choose the best match and prevent repeated predictions, and a modified EAST to pinpoint the exact ROI in the image. To improve the model’s performance, an enhancement module is added to the fundamental Efficient and Accurate Scene Text detector (EAST). The suggested approach is contrasted in terms of text word detection in the image. Several pre-trained models are used to assign the text word to various intersections over Union (IoU) values. We made use of our NITJ-TD dataset, which is made up of 1500 photos that were gathered from various North Indian sites. Punjabi, English, and Hindi scripts can be seen on the images. We also examined the outcomes of the ICDAR-2013 benchmark dataset. On both the suggested dataset and the benchmarked dataset, our approach performed better.},
  archive      = {J_IJDAR},
  author       = {Mahajan, Shilpa and Rani, Rajneesh and Kamboj, Aman},
  doi          = {10.1007/s10032-024-00491-w},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {97-119},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Deep learning-based modified-EAST scene text detector: Insights from a novel multiscript dataset},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A 3D scanning based image processing technique for measuring
the sequence of intersecting lines. <em>IJDAR</em>, <em>28</em>(1),
85–96. (<a href="https://doi.org/10.1007/s10032-024-00495-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The determination of the sequence of two intersecting lines is still an ongoing and important issue in questioned document examination. In literature, scanning electron microscopy, optical profilometry, laser profilometry, and video reflectance spectroscopy were used for analyzing the intersecting lines. In this study, a cheap and easy-to-operate 3D scanner was used to study this problem. Intersections of homogenous and heterogeneous strokes were drawn using different brands of 1.0 mm blue, black, and red ballpoint pens on conventional printing paper, i.e., 80 g/m2, and uncoated A4 white paper by two different handwriting examiners. The analysis of the 3D surface of the crossing lines shows that the bottom of the profile of the first line has a considerable trough, while the second line has comparably smaller fluctuations. The 3D scan analysis is not affected by the brands and colors of the pen and is independent of the substrate and the number of sheets lying underneath the paper. The effect of the pen pressure shows that if the pressure of the second line is less than the first one, the sequence determination becomes harder and sometimes impossible. As these cases can be eliminated before the 3D scan, the developed method is sensitive, cheap, and easy to operate.},
  archive      = {J_IJDAR},
  author       = {Asicioglu, Faruk and Gelir, Ali and Yilmaz, Aysegul Sen and De Kinder, Jan and Kadi, Omer F. and Ozdemir, Onur B. and Pekacar, Ilgim and Sasun, Ugur and Ciftci, Saltuk B. and Dayioglu, Nurten},
  doi          = {10.1007/s10032-024-00495-6},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {85-96},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {A 3D scanning based image processing technique for measuring the sequence of intersecting lines},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards fully automated processing and analysis of
construction diagrams: AI-powered symbol detection. <em>IJDAR</em>,
<em>28</em>(1), 71–84. (<a
href="https://doi.org/10.1007/s10032-024-00492-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Construction drawings are frequently stored in undigitised formats and consequently, their analysis requires substantial manual effort. This is true for many crucial tasks, including material takeoff where the purpose is to obtain a list of the equipment and respective amounts required for a project. Engineering drawing digitisation has recently attracted increased attention, however construction drawings have received considerably less interest compared to other types. To address these issues, this paper presents a novel framework for the automatic processing of construction drawings. Extensive experiments were performed using two state-of-the-art deep learning models for object detection in challenging high-resolution drawings sourced from industry. The results show a significant reduction in the time required for drawing analysis. Promising performance was achieved for symbol detection across various classes, with a mean average precision of 79% for the YOLO-based method and 83% for the Faster R-CNN-based method. This framework enables the digital transformation of construction drawings, improving tasks such as material takeoff and many others.},
  archive      = {J_IJDAR},
  author       = {Jamieson, Laura and Moreno-Garcia, Carlos Francisco and Elyan, Eyad},
  doi          = {10.1007/s10032-024-00492-9},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {71-84},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Towards fully automated processing and analysis of construction diagrams: AI-powered symbol detection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAN-based text line segmentation method for challenging
handwritten documents. <em>IJDAR</em>, <em>28</em>(1), 59–69. (<a
href="https://doi.org/10.1007/s10032-024-00488-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text line segmentation (TLS) is an essential step of the end-to-end document analysis systems. The main purpose of this step is to extract the individual text lines of any handwritten documents with high accuracy. Handwritten and historical documents mostly contain touching and overlapping characters, heavy diacritics, footnotes and side notes added over the years. In this work, we present a new TLS method based on generative adversarial networks (GAN). TLS problem is tackled as an image-to-image translation problem and the GAN model was trained to learn the spatial information between the individual text lines and their corresponding masks including the text lines. To evaluate the segmentation performance of the proposed GAN model, two challenging datasets, VML-AHTE and VML-MOC, were used. According to the qualitative and quantitative results, the proposed GAN model achieved the best segmentation accuracy on the VML-MOC dataset and showed competitive performance on the VML-AHTE dataset.},
  archive      = {J_IJDAR},
  author       = {Özşeker, İbrahim and Demir, Ali Alper and Özkaya, Ufuk},
  doi          = {10.1007/s10032-024-00488-5},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {59-69},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {GAN-based text line segmentation method for challenging handwritten documents},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image quality determination of palm leaf heritage documents
using integrated discrete cosine transform features with vision
transformer. <em>IJDAR</em>, <em>28</em>(1), 41–57. (<a
href="https://doi.org/10.1007/s10032-024-00490-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification of Palm leaf images into various quality categories is an important step towards the digitization of these heritage documents. Manual inspection and categorization is not only laborious, time-consuming and costly but also subject to inspector’s biases and errors. This study aims to automate the classification of palm leaf document images into three different visual quality categories. A comparative analysis between various structural and statistical features and classifiers against deep neural networks is performed. VGG16, VGG19 and ResNet152v2 architectures along with a custom CNN model are used, while Discrete Cosine Transform (DCT), Grey Level Co-occurrence Matrix (GLCM), Tamura, and Histogram of Gradient (HOG) are chosen from the traditional methods. Based on these extracted features, various classifiers, namely, k-Nearest Neighbors (k-NN), multi-layer perceptron (MLP), Support Vector Machines (SVM), Decision Tree (DT) and Logistic Regression (LR) are trained and evaluated. Accuracy, precision, recall, and F1 scores are used as performance metrics for the evaluation of various algorithms. Results demonstrate that CNN embeddings and DCT features have emerged as superior features. Based on these findings, we integrated DCT with a Vision Transformer (ViT) for the document classification task. The result illustrates that this incorporation of DCT with ViT outperforms all other methods with 96% train F1 score and a test F1 score of 90%.},
  archive      = {J_IJDAR},
  author       = {Sivan, Remya and Pati, Peeta Basa and Kesiman, Made Windu Antara},
  doi          = {10.1007/s10032-024-00490-x},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {41-57},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Image quality determination of palm leaf heritage documents using integrated discrete cosine transform features with vision transformer},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scene text recognition: An indic perspective.
<em>IJDAR</em>, <em>28</em>(1), 31–40. (<a
href="https://doi.org/10.1007/s10032-024-00489-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring Scene Text Recognition (STR) in Indian languages is an important research domain due to its wide applications. This paper proposes a spatial attention-based model (LaSA-Net) that combines visual features and language knowledge for word recognition from scene image word segments. We augment the classical cross-entropy loss with a novel language-attunement loss that enables the model to learn valid and prevalent character sequences in the word. This enhances the model’s ability to perform zero-shot word recognition. Further, to compensate for the lack of rotational invariance in CNN based feature extraction backbone, we propose a training data augmentation strategy involving the creation of glyphs: images of individual characters of different orientations. This improves LaSA-Net’s ability to recognize words in images with curved/vertically aligned text, alleviating the need for computationally expensive preprocessing modules. Our experiments with Tamil, Malayalam, and Telugu scripts on the IIIT-ILST datasets have achieved new benchmark results and outperformed other state-of-the-art STR models.},
  archive      = {J_IJDAR},
  author       = {Vijayan, Vasanthan P. and Chanda, Sukalpa and Doermann, David and Krishnan, Narayanan C.},
  doi          = {10.1007/s10032-024-00489-4},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {31-40},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Scene text recognition: An indic perspective},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic floor plan analysis using a boundary
attention-based deep network. <em>IJDAR</em>, <em>28</em>(1), 19–30. (<a
href="https://doi.org/10.1007/s10032-024-00487-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Floor plan is an important communication tool between architects, construction engineers, and clients for a building project. Estimation of building features from a floor plan image is often a time-consuming task. Automatic analysis of floor plan images can significantly improve work efficiency and accuracy. A few research works have been reported in the literature on automated floor image analysis. However, the scope and performance of the existing techniques are limited. In this paper, a CNN-based technique, referred to as FloorNet, is proposed for the multiclass semantic segmentation of a floor plan. The proposed FloorNet has five modules: Encoder, Room type decoder, Room boundary decoder, Multiscale room boundary attention model and Floor classification. The proposed technique is evaluated using simple brochure type and complex architectural type floor plan images. Experimental results show that the proposed technique provides an improvement of 5–11% mIoU for semantic segmentation (for 9–11 classes) compared to the state-of-the-art techniques.},
  archive      = {J_IJDAR},
  author       = {Xu, Zhongguo and Yang, Cheng and Alheejawi, Salah and Jha, Naresh and Mehadi, Syed and Mandal, Mrinal},
  doi          = {10.1007/s10032-024-00487-6},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {19-30},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Automatic floor plan analysis using a boundary attention-based deep network},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handwritten stenography recognition and the LION dataset.
<em>IJDAR</em>, <em>28</em>(1), 3–18. (<a
href="https://doi.org/10.1007/s10032-024-00479-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish the first baseline for handwritten stenography recognition, using the novel LION dataset, and investigate the impact of including selected aspects of stenographic theory into the recognition process. We make the LION dataset publicly available with the aim of encouraging future research in handwritten stenography recognition. A state-of-the-art text recognition model is trained to establish a baseline. Stenographic domain knowledge is integrated by transforming the target sequences into representations which approximate diplomatic transcriptions, wherein each symbol in the script is represented by its own character in the transliteration, as opposed to corresponding combinations of characters from the Swedish alphabet. Four such encoding schemes are evaluated and results are further improved by integrating a pre-training scheme, based on synthetic data. The baseline model achieves an average test character error rate (CER) of 29.81% and a word error rate (WER) of 55.14%. Test error rates are reduced significantly (p&lt; 0.01) by combining stenography-specific target sequence encodings with pre-training and fine-tuning, yielding CERs in the range of 24.5–26% and WERs of 44.8–48.2%. An analysis of selected recognition errors illustrates the challenges that the stenographic writing system poses to text recognition. This work establishes the first baseline for handwritten stenography recognition. Our proposed combination of integrating stenography-specific knowledge, in conjunction with pre-training and fine-tuning on synthetic data, yields considerable improvements. Together with our precursor study on the subject, this is the first work to apply modern handwritten text recognition to stenography. The dataset and our code are publicly available via Zenodo.},
  archive      = {J_IJDAR},
  author       = {Heil, Raphaela and Nauwerck, Malin},
  doi          = {10.1007/s10032-024-00479-6},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {3-18},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {Handwritten stenography recognition and the LION dataset},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). International journal on document analysis and recognition
editorial leadership change. <em>IJDAR</em>, <em>28</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s10032-025-00520-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJDAR},
  author       = {Lopresti, Daniel and Kise, Koichi and Marinai, Simone},
  doi          = {10.1007/s10032-025-00520-2},
  journal      = {International Journal on Document Analysis and Recognition},
  month        = {3},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Int. J. Doc. Anal. Recognit.},
  title        = {International journal on document analysis and recognition editorial leadership change},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijfs---20">IJFS - 20</h2>
<ul>
<li><details>
<summary>
(2025). Adaptive fuzzy tracking control and its application in
stochastic biological systems. <em>IJFS</em>, <em>27</em>(2), 629–640.
(<a href="https://doi.org/10.1007/s40815-024-01805-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of adaptive fuzzy control for stochastic biological systems with stage structure is studied. Firstly, considering the species itself in nature will be affected by a variety of uncertain factors, a more realistic stochastic biological model is established. Then, aiming at the unknown nonlinear functions in the stochastic biological system, the fuzzy logic system (FLS) is used to approximate the unknown nonlinear terms. Secondly, the backsteppting method and adaptive fuzzy means are applied to the prey–predator model with stage structure, and the corresponding adaptive fuzzy controller is designed. It is guaranteed that all states in the biological system are semi-globally uniformly ultimately bounded (SGUUB), the juvenile prey density can track the given desired density, and the tracking error converges to a small neighborhood near zero. Finally, a simulation experiment is carried out with reference to the real case of the significant reduction of the number of lampreys. The results show that compared with the general adaptive control method, the control strategy proposed shows higher superiority in the stochastic biological system.},
  archive      = {J_IJFS},
  author       = {Zhang, Yi and Su, Xiaotian and Song, Yue},
  doi          = {10.1007/s40815-024-01805-0},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {629-640},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Adaptive fuzzy tracking control and its application in stochastic biological systems},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy c-means clustering via slime mold and the fisher
score. <em>IJFS</em>, <em>27</em>(2), 606–628. (<a
href="https://doi.org/10.1007/s40815-024-01788-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy C-means (FCM) clustering has the virtue of simple structure and easy implementation; however, it relies on the initial cluster centers and is sensitive to noise. To overcome these problems, this paper presents a novel FCM clustering method with slime mold and a Fisher score. First, logistics chaotic mapping is introduced to initialize the slime mold population and increase the population diversity. Modifying the convergence factor of the slime mold enhances the convergence speed and accuracy of the slime mold algorithm (SMA). Second, an adaptive weight is introduced into the SMA to promote the transition between exploration and development. Then, this optimal solution for SMA initializes the cluster center of FCM to avoid initialization sensitivity. Third, when considering the influence of feature differentiation degrees on the samples, the feature evaluation criteria of the Fisher score is constructed and then the importance of the feature is ranked to identify noise. The square root error criterion selects the most effective features to improve the clustering effect. Finally, by constructing uncertainty relations and introducing information entropy, the objective function of FCM is constructed to effectively solve the issue of FCM being sensitive to noise. The experimental results on 13 benchmark test functions for optimization, and 25 datasets for clustering show that the proposed algorithm outperforms other compared algorithms in terms of several evaluation metrics.},
  archive      = {J_IJFS},
  author       = {Zhang, Yiman and Sun, Lin and Chang, Baofang and Zhang, Qianqian and Xu, Jiucheng},
  doi          = {10.1007/s40815-024-01788-y},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {606-628},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Fuzzy C-means clustering via slime mold and the fisher score},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label-specific features learning algorithm based on
label importance and fuzzy rough set. <em>IJFS</em>, <em>27</em>(2),
591–605. (<a href="https://doi.org/10.1007/s40815-024-01776-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label-specific features learning is a prominent research hotspot in the field of multi-label learning, which aims to construct a classification model based on the distinctive features of each label rather than the whole features. Existing approaches regarding label-specific features usually assume that the importance of each label to an instance is equal. However, this popular strategy might be suboptimal as the importance of labels actually is different. In this paper, a multi-label-specific features learning algorithm based on label importance and fuzzy rough set is proposed. First, the importance of labels is measured based on the similarity of instances, which not only preserves the ranking of relevant and irrelevant labels, but also follows the principles of smoothness and normalization. Second, the correlation between labels is analyzed, and label-specific features of each label are extracted through a fuzzy rough set model. Experiments on several public available data sets demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_IJFS},
  author       = {Li, Hua and Wang, Zhijie},
  doi          = {10.1007/s40815-024-01776-2},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {591-605},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Multi-label-specific features learning algorithm based on label importance and fuzzy rough set},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent sliding mode control for fuzzy time-delay
systems with periodic impulse. <em>IJFS</em>, <em>27</em>(2), 582–590.
(<a href="https://doi.org/10.1007/s40815-024-01774-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper delves into the application of integral sliding mode control (ISMC) in addressing the complexities of fuzzy time-delay systems with periodic impulses. Unlike the sliding mode control method for continuous systems, the design of ISMC for impulsive hybrid systems is much more difficult due to the presence of pulses, especially to ensure the continuity of the sliding mode surface. Initially, a sophisticated fuzzy sliding mode surface is introduced, accompanied by a purposefully crafted fuzzy ISMC scheme incorporating impulsive signals. Subsequently, by employing a piecewise time-dependent Lyapunov function, we establish the globally asymptotic stability of the closed-loop system. To enhance practical applicability, a control design algorithm is devised, determining optimal control and feedback gains. This algorithm, rooted in derived sufficient conditions and guided by linear matrix inequality (LMI) theory, ensures a systematic parameter selection process. The culmination lies in a compelling simulation example, vividly illustrating the effectiveness of the proposed fuzzy ISMC scheme in real-world scenarios.},
  archive      = {J_IJFS},
  author       = {Zhan, Tao and Liu, Shihu},
  doi          = {10.1007/s40815-024-01774-4},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {582-590},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Intelligent sliding mode control for fuzzy time-delay systems with periodic impulse},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An interval intuitionistic fuzzy characterization method
based on heterogeneous big data and its application in forest land
quality assessment. <em>IJFS</em>, <em>27</em>(2), 558–581. (<a
href="https://doi.org/10.1007/s40815-024-01765-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement and ongoing evolution of data information technology, the methods and approaches for data collection have become increasingly varied. The synthesis of heterogeneous big data to minimize information loss during the aggregation process poses a significant challenge. In practical applications, fuzzy dimensionality reduction characterization has proven to be an effective approach for handling heterogeneous big data. In this study, a novel approach is proposed for characterizing and evaluating heterogeneous big data using an interval intuitionistic fuzzy framework. We establish the interval intuitionistic fuzzy transformation method for large-scale quantitative data by defining satisfaction intervals, dissatisfaction intervals, and hesitation intervals. To integrate calculation and processing for linguistic evaluation information with different granularities, a transformation formula that handles multi-granularity uncertain linguistic information and interval intuitionistic fuzzy numbers is introduced. The proposed formula aggregates heterogeneous attribute values into interval intuitionistic fuzzy numbers. We employ interval intuitionistic fuzzy entropy to determine the objective weight of each evaluation indicator. Subsequently, the interval intuitionistic fuzzy comprehensive evaluation information for each alternative scheme, enabling effective ranking based on the information, is derived. Finally, the applicability of our proposed method is verified through a case study conducted on forest land in the county area of Fujian province. This case study comprehensively assesses and ranks the forest land quality in 16 sample plots. The evaluation serves as a theoretical framework for advancing sustainable development and conservation initiatives about forest land within the county.},
  archive      = {J_IJFS},
  author       = {Zhang, Junzhe and Lin, Jian and Wu, Tao},
  doi          = {10.1007/s40815-024-01765-5},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {558-581},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {An interval intuitionistic fuzzy characterization method based on heterogeneous big data and its application in forest land quality assessment},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy-membership-kernel learning based on takagi–sugeno
models. <em>IJFS</em>, <em>27</em>(2), 550–557. (<a
href="https://doi.org/10.1007/s40815-024-01763-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new class of kernels is constructed via incorporating fuzzy information into learning to enhance the performance of kernel-based algorithms. The fuzzy information is given in the form of Takagi–Sugeno (TS) models. First, a TS model is transformed into a structure that includes an inner product. Then an insensitive loss function is employed to identify the parameters in the consequent parts of TS fuzzy rules. By virtue of the kernel tick, the inner product is replaced with common kernels (e.g., Gaussian kernels) in the corresponding dual optimization problem. Consequently, the new kernels, called fuzzy membership kernels (FMKs), are constructed via TS models and common kernels. Note that some research focuses on transforming fuzzy rules into the weights of kernels, or simply, fuzzy weight kernels (FWK), for short. However, FWKs only consider the weights of training points and neglect the weights of test points. Compared with FWKs, the representations of FMKs show that the fuzzy information is incorporated into learning by adding weights to feature mappings of training and test points, respectively. Therefore, FMKs can overcome the shortcomings of FWKs. Finally, a function approximation problem is employed to validate the proposed approach.},
  archive      = {J_IJFS},
  author       = {Wang, Jianmin and Kang, Mingxin},
  doi          = {10.1007/s40815-024-01763-7},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {550-557},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Fuzzy-membership-kernel learning based on Takagi–Sugeno models},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fused decision rules of multi-intuitionistic fuzzy
information systems based on the d-s evidence theory and three-way
decisions. <em>IJFS</em>, <em>27</em>(2), 528–549. (<a
href="https://doi.org/10.1007/s40815-024-01764-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acquisition of decision rules in multi-intuitionistic fuzzy decision information systems is both challenging and important. To address this issue, it is necessary to combine decision rules from various systems to obtain a more reliable decision rule. Additionally, the use of three-way decisions can help determine the optimal decision value. In this research article, we explore the decision problems of multi-intuitionistic fuzzy decision information systems by utilizing the D-S evidence theory and three-way decisions. We start by providing an overview of the belief structure of intuitionistic fuzzy sets. Then, we propose a fused mass function of decision rules that assists in obtaining satisfactory or optimal decision value sets through three-way decisions. To facilitate the fusion of decision value sets, we present an algorithm that effectively integrates them. Furthermore, we provide examples to illustrate the algorithm and demonstrate the effectiveness and efficiency of our proposed approach.},
  archive      = {J_IJFS},
  author       = {Feng, Tao and Mi, Ju-Sheng and Zhang, Shao-Pu and Zhang, Xin},
  doi          = {10.1007/s40815-024-01764-6},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {528-549},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Fused decision rules of multi-intuitionistic fuzzy information systems based on the D-S evidence theory and three-way decisions},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Fuzzy big data-driven computational intelligence
models and applications. <em>IJFS</em>, <em>27</em>(2), 522–527. (<a
href="https://doi.org/10.1007/s40815-024-01821-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the contemporary era of technological revolution, the intersection of fuzzy logic, big data analytics, and computational intelligence has emerged as a vibrant and promising research frontier. This special issue on “Fuzzy Big Data-Driven Computational Intelligence Models and Applications” aims to provide a comprehensive overview of the latest advancements in this exciting field.},
  archive      = {J_IJFS},
  author       = {Li, Wentao and Fujita, Hamido and Zhang, Chao and Su, Shun-Feng},
  doi          = {10.1007/s40815-024-01821-0},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {522-527},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Editorial: Fuzzy big data-driven computational intelligence models and applications},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large group failure mode and effects analysis method
considering individual concerns and integrated consensus mechanism in
social network context: An application to mobile medical privacy risk
evaluation. <em>IJFS</em>, <em>27</em>(2), 492–521. (<a
href="https://doi.org/10.1007/s40815-024-01791-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularization and application of mobile medical applications (apps), the privacy and security of personal medical data has received widespread concerns. Given that privacy leaks can cause serious privacy violations and personal safety issues, it is particularly important to adopt failure mode and effects analysis (FMEA) in privacy risk assessment to ensure reliability and security. In particular, FMEA risk assessment requires the participation of numerous experts from different fields. Experts often express opinions with a level of individual concerns and confidence levels that needs to be considered in the risk assessment process. In this paper, a large group FMEA considering individual concerns and integrated consensus mechanism in the social network environment is developed for privacy risk assessment of mobile medical apps. Firstly, this paper constructs a complete social trust network (STN) based on the trust propagation operator proposed by the trust propagation path, which is conducive to comprehensively analyzing the social relationship among experts. Secondly, a hierarchical clustering method is proposed that considers both opinion similarity and concerns similarity between experts. This clustering method processes information from both subjective and objective perspectives to ensure a more reasonable cluster division. Next, considering that the level of consensus within a cluster affects the efficiency of consensus reaching, an integrated consensus mechanism that considers both intra-group consensus and inter-group consensus is developed to promote the unification of opinions. Additionally, this paper utilizes social trust relationships to guide the adjustment of the consensus level to reduce information loss on the premise of satisfying the expert&#39;s confidence level. Finally, a case study on assessing privacy risks of mobile medical apps illustrates the effectiveness of this approach, and the superiority and rationality of the method are confirmed by multi-angle comparative analysis, simulation analysis and parameter analysis.},
  archive      = {J_IJFS},
  author       = {Liu, Zhengmin and Zhang, Xiaohan and Wang, Wenxin and Liu, Peide},
  doi          = {10.1007/s40815-024-01791-3},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {492-521},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Large group failure mode and effects analysis method considering individual concerns and integrated consensus mechanism in social network context: An application to mobile medical privacy risk evaluation},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simplex algorithm for hesitant fuzzy linear programming
problem with hesitant decision variables and right-hand-side values.
<em>IJFS</em>, <em>27</em>(2), 481–491. (<a
href="https://doi.org/10.1007/s40815-024-01790-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to make the best decisions in real-world applications, we must deal with optimization and decision-making problems that call for the input of experts and masters. Using an optimization problem with hesitant fuzzy parameters is important in these circumstances. Few studies have been done on the problem of hesitant fuzzy linear programming (HFLP). Therefore, in this article we study HFLP problems with hesitant decision variables and right-hand-side values. In order to solve the mentioned optimization problems, we suggest the hesitant fuzzy simplex algorithm. For this, first state the optimization theorems then express the hesitant fuzzy simplex algorithm using the introduced linear ranking functions. We will finally test the implementation of the suggested strategy by solving two descriptive examples using hesitant fuzzy information.},
  archive      = {J_IJFS},
  author       = {Saghi, Samane and Nazemi, Alireza and Effati, Sohrab and Ranjbar, Mahdi},
  doi          = {10.1007/s40815-024-01790-4},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {481-491},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Simplex algorithm for hesitant fuzzy linear programming problem with hesitant decision variables and right-hand-side values},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some new concepts of interval-valued picture fuzzy graphs
and their application toward the selection criteria. <em>IJFS</em>,
<em>27</em>(2), 463–480. (<a
href="https://doi.org/10.1007/s40815-024-01789-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued picture fuzzy sets (IVPFSs) being the most advanced form of fuzzy sets (FSs) has more capacity to analyze the network state more intelligently. It is proven that IVPFS is most useful to solve many real life problems having uncertainties. In comparison with the other generalizations of fuzzy graphs (FGs), IVPFG is proven more beneficial in solving complicated problems containing uncertainties. In this study, we propose some new concepts of covering and matching in IVPFGs based on strong arcs. We begin our study by introducing the concepts of covering in IVPFGs which includes strong node covering (SNC), strong arc covering (SAC), strong arc covering number (SAC number), and strong independent set (SIS). Based on these terms, we provide several characterizations of different types of IVPFGs like complete IVPFGs and complete bipartite IVPFGs. Afterward, we introduce the terms matching, strong matching etc for IVPFGs. We also present some useful results related to some special IVPFGs with respect to these terms. Finally, we provide the utilization of strong arcs and SIS in order to arrange the meeting of the members of social network comprising players engaged in diverse games.},
  archive      = {J_IJFS},
  author       = {Rao, Yongsheng and Chen, Ruxian and Khan, Waheed Ahmad and Zahid, Alishba},
  doi          = {10.1007/s40815-024-01789-x},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {463-480},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Some new concepts of interval-valued picture fuzzy graphs and their application toward the selection criteria},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantized-states-based fuzzy adaptive course tracking
control of an unmanned surface vehicle with input and state
quantization. <em>IJFS</em>, <em>27</em>(2), 451–462. (<a
href="https://doi.org/10.1007/s40815-024-01787-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the course tracking control of unmanned surface vehicle (USV) under the restricted communication bandwidth at sea, this paper focuses on the fuzzy adaptive control scheme with input and state quantization. It alleviates the pressure on signal transmission in limited bandwidth and reduces the actuator actuation frequency while ensuring effective tracking. A fuzzy logic system is suggested for the purpose of approximating uncertainty terms in USV motion model. All state variables and control input signal are assumed to be quantized by the uniform quantizer, respectively. Then, the quantized control input signal is described linearly so that the designed fuzzy quantised controller does not need to anticipate specific information about the quantization parameters. Subsequently, the analysis of the control system without considering state quantization and the bounded nature of the quantization error within the fuzzy adaptive feedback control architecture are demonstrated through the elucidation of several pivotal theoretical lemmas. Based on these lemmas, the stability of the devised system with input and state quantization is established. Three sets of simulation experiments validate the efficacy and viability of the proposed strategy.},
  archive      = {J_IJFS},
  author       = {Ning, Jun and Ma, Yifan and Li, Tieshan and Chen, C. L. Philip},
  doi          = {10.1007/s40815-024-01787-z},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {451-462},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Quantized-states-based fuzzy adaptive course tracking control of an unmanned surface vehicle with input and state quantization},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based finite-time l2 filter design for networked
interconnected fuzzy systems under denial-of-service attacks.
<em>IJFS</em>, <em>27</em>(2), 433–450. (<a
href="https://doi.org/10.1007/s40815-024-01784-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of event-based finite-time $$L_2$$ filtering for networked interconnected fuzzy systems under denial-of-service attacks. To counter the impact of the attacks and improve the utilization of communication resources, a resilient event-triggered transmission strategy is introduced. Subsequently, a Takagi–Sugeno fuzzy filter is designed to estimate the unknown information, and an augmented fuzzy filter error system is formulated. Under this framework, a new Lyapunov–Krasovskii functional related to the membership functions is constructed to analyze the finite-time stability of the underlying error system. The filter gains and the event trigger parameters are obtained by solving the linear matrix inequality. Finally, the effectiveness of the developed method is substantiated by a numerical simulation example.},
  archive      = {J_IJFS},
  author       = {Lun, Di and Zhang, Huiyan and Liu, Yongchao and Zhao, Ning and Assawinchaichote, Wudhichai},
  doi          = {10.1007/s40815-024-01784-2},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {433-450},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Event-based finite-time l2 filter design for networked interconnected fuzzy systems under denial-of-service attacks},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Command filter-based adaptive fault-tolerant fast
finite-time control of manipulator systems with actuator faults.
<em>IJFS</em>, <em>27</em>(2), 421–432. (<a
href="https://doi.org/10.1007/s40815-024-01785-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of command filter-based fault-tolerant fast finite-time control is explored for manipulator systems with actuator faults. By using finite-time control and a finite-time command filter, all the signals in the closed-loop system are bounded and converge to the bounded regions in finite time. In addition, the problems of complicated calculation and influence of filtering errors are solved by the introduction of the finite-time command filter and a compensation mechanism. It is especially emphasized that the main contribution of this paper is as follows: (1) Several advanced control methods are integrated, which takes into account the speed, reliability, and adaptability of the controlled system. (2) In the last step of the design based on backstepping, an intermediate variable is designed which can simplify the proposed control algorithm. In the end, with the help of a numerical simulation example, it is shown that better transient/steady state performance and the fast finite-time stability of the closed-loop system can be obtained. As a result, it is concluded that our scheme is effective.},
  archive      = {J_IJFS},
  author       = {Chen, Ming and Yu, Xiao and Jiao, Xiaoxuan and Peng, Kai-Xiang and Wu, Li-Bing},
  doi          = {10.1007/s40815-024-01785-1},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {421-432},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Command filter-based adaptive fault-tolerant fast finite-time control of manipulator systems with actuator faults},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predefined-time fuzzy output feedback control for nonlinear
systems with multiple actuator constraints. <em>IJFS</em>,
<em>27</em>(2), 410–420. (<a
href="https://doi.org/10.1007/s40815-024-01786-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a predefined-time adaptive fuzzy tracking control method is proposed for uncertain nonlinear systems with multiple actuator constraints and external disturbances. The unknown dynamic part of the system is dealt with by means of the fuzzy approximation theory, and the unmeasured state in the system is approximated by the constructed fuzzy state observer. On the basis of the observer, a novel predefined-time control scheme is developed to ensure that the system can achieve the practical predefined time stable (PPTS). Combined with the stability analysis, the virtual control input with predefined time can be obtained, and its derivative can be estimated by the first-order filter. Theoretical analysis shows that the proposed controller achieves a small residual set of error convergence to the origin in a predefined time. Finally, the feasibility of the theoretical results is demonstrated through simulation examples.},
  archive      = {J_IJFS},
  author       = {Wang, Libin and Niu, Junlong and Wang, Wei},
  doi          = {10.1007/s40815-024-01786-0},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {410-420},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Predefined-time fuzzy output feedback control for nonlinear systems with multiple actuator constraints},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proposal of a compact neuro-fuzzy adaptive controller for
filling regulation of two coupled spherical tanks. <em>IJFS</em>,
<em>27</em>(2), 391–409. (<a
href="https://doi.org/10.1007/s40815-024-01782-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper displays the set up and simulation of a compact neuro-fuzzy adaptive scheme for the filling regulation of two coupled spherical tanks. The suggested scheme employs two compact neuro-fuzzy blocks: the first one to model the plant, and the second one for the controller implementation. In this scheme, the controller is trained employing the fuzzy model estimated with data of the system working in closed-loop. Thus, the controller optimization iteratively is performed when plant variations occur. The work also includes the deduction of the equations for training, showing the adaptive process employing neuro-fuzzy systems. Moreover, the training (optimization) process of the controller’s neuro-fuzzy system includes within the adjustment function the control action and the error signal. Various experimental cases are considered using statistical analysis to verify behaviors in the adaptive control system. In this order, the main contribution of this work consists of the adjustment (coupling) of two structures of compact neuro-fuzzy systems used for identification and control, as well as the deduction and adjustment of the training algorithms to implement the adaptive control system.},
  archive      = {J_IJFS},
  author       = {Espitia, Helbert and Machón, Iván and López, Hilario},
  doi          = {10.1007/s40815-024-01782-4},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {391-409},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Proposal of a compact neuro-fuzzy adaptive controller for filling regulation of two coupled spherical tanks},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of fuzzy delay compensation controller based on
amplitude compensation method for power system with communication delay.
<em>IJFS</em>, <em>27</em>(2), 368–390. (<a
href="https://doi.org/10.1007/s40815-024-01781-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a networked power system, communication delay in the feedback signal during transmission process can have a detrimental impact on the effectiveness of the power system stabilizer (PSS) in suppressing low-frequency oscillations. To address this problem, a controller design method to compensate for short constant time delays is proposed. The proposed approach utilizes Mamdani fuzzy inference system to design a fuzzy delay compensation damping controller (FDCDC) and establishes control rules based on the amplitude compensation method. The proposed FDCDC takes the delayed feedback signal as input and generates additional excitation control signal as output. The controller considers the effect of delay on the performance of PSS controller and compensates for the delay through fuzzy output. To evaluate the effectiveness of the proposed FDCDC, a networked power system model is developed using MATLAB Simulink’s SimPowerSystems library and TrueTime 2.0 toolbox. The aim of this study is to investigate the impact of short constant time delay on the performance of PSS controller in a networked environment and to assess the performance of the proposed controller. The simulation results demonstrate that the proposed FDCDC exhibits good adaptability and robustness in compensating for the effect of delay on PSS control.},
  archive      = {J_IJFS},
  author       = {Li, Jun and Gao, Hongliang and Wang, Yong},
  doi          = {10.1007/s40815-024-01781-5},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {368-390},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Design of fuzzy delay compensation controller based on amplitude compensation method for power system with communication delay},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-warehouse green inventory cloudy fuzzy model for
deteriorating items with two-level trade credit and shortages.
<em>IJFS</em>, <em>27</em>(2), 338–367. (<a
href="https://doi.org/10.1007/s40815-024-01780-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present era, the most delicate environmental issue is global warming, and because of this, countries across the globe are trying to manage the most hazardous emissions by making certain investments in projects to promote green industrial practices. In the current study, the inventory models are developed by including the emission of CO2 from transportation which is controlled by the optimum investments in green technology (GT). Here, sustainable deteriorating inventory models in both crisp and cloudy fuzzy (CF) environments with a two-level trade credit scheme are proposed to boost the demand, where a delay in payment opportunity is there for suppliers and retailers. In this credit scenario, delay in payment options is given from the supplier to the retailer, and also from the retailer to the customer. In the present research, two warehouses are considered to manage the stock-out situation. For the model problems, demand is considered to be time dependent, where a multiple prepayment option for the purchasing cost involving an installment is provided to the retailers. Here the solution processes for the proposed models suggest algorithms, and then a numerical approach is followed to test the optimality criteria. The said optimum results are also presented in graphs. Again, a comparative study of the obtained results concerning the models is also highlighted. Lastly, a sensitivity analysis is performed to study the influence of variations in input parameters, which allows drawing some managerial insights.},
  archive      = {J_IJFS},
  author       = {Parida, Subhashree and Acharya, Milu},
  doi          = {10.1007/s40815-024-01780-6},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {338-367},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Two-warehouse green inventory cloudy fuzzy model for deteriorating items with two-level trade credit and shortages},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fuzzy control of switched port-controlled
hamiltonian systems with input saturation. <em>IJFS</em>,
<em>27</em>(2), 326–337. (<a
href="https://doi.org/10.1007/s40815-024-01783-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a fuzzy control technique for switched port-controlled Hamiltonian systems, in which input saturation and completely unknown internal dynamics occur. Based on the mean-value theorem, multiple Lyapunov functions scheme, and universal approximation ability of fuzzy logic systems, a switching fuzzy adaptive controller is designed to ensure that all closed-loop signals are semiglobally uniformly ultimately bounded. Furthermore, the norm of an ideal weighting vector in fuzzy logic systems is taken as the estimation parameter instead of the elements of the weighting vector to reduce the dimension of adaptation laws. This switching controller can weaken the conservativeness brought by the application of the same controller for each subsystem. Finally, some examples are provided to verify the validity of the proposed approach.},
  archive      = {J_IJFS},
  author       = {Zhang, Qi and Sun, Weiwei and Qiao, Chaoqian},
  doi          = {10.1007/s40815-024-01783-3},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {326-337},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Adaptive fuzzy control of switched port-controlled hamiltonian systems with input saturation},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Railway transportation scheme selection based a CODAS-COPRAS
method in triangular dense fuzzy linguistic term lock environment.
<em>IJFS</em>, <em>27</em>(2), 307–325. (<a
href="https://doi.org/10.1007/s40815-024-01778-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the environment of global warming, it is very important to choose rail transport solutions with the lowest possible CO2 emissions, taking into account economic, technical and safety factors. As an important part of the modern transportation system, railway transportation appears in most transportation scenarios. Therefore, choosing an eco-friendly railway transport selection scheme is conducive to further reducing pollution emissions and preventing the further deterioration of the ecological environment. Triangular Dense Fuzzy Linguistic Term Lock Set (TDFLTS) is a tool for describing uncertain information. CODAS-COPRAS is a method to solve the multi-attribute group decision-making problem. This paper first introduces TDFLTS to describe uncertain information. Secondly, the distance measure and similarity measure between TDFLTS are proposed. Then, MEREC and DEMATEL methods are used to obtain attribute weights. Finally, CODAS-COPRAS method is used to solve the multi-attribute decision-making problem under TDFLTS environment, and it is applied to the research of railway transportation scheme selection.},
  archive      = {J_IJFS},
  author       = {Fan, Jianping and Yuan, Yali and Wu, Meiqin},
  doi          = {10.1007/s40815-024-01778-0},
  journal      = {International Journal of Fuzzy Systems},
  month        = {3},
  number       = {2},
  pages        = {307-325},
  shortjournal = {Int. J. Fuzzy Syst.},
  title        = {Railway transportation scheme selection based a CODAS-COPRAS method in triangular dense fuzzy linguistic term lock environment},
  volume       = {27},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijmir---3">IJMIR - 3</h2>
<ul>
<li><details>
<summary>
(2025). Cross-modal alignment with synthetic caption for text-based
person search. <em>IJMIR</em>, <em>14</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s13735-025-00356-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based person search aims to retrieve target person from a large gallery based on natural language description. Existing methods take it as one-to-one embedding or many-to-many embedding matching problem. The former approach relies on the assumption of the existence of strong alignment between text and images, while the latter inevitably leads to issues of intra-class variation. Rather than being confined to these two approaches, we propose a new strategy that achieves cross-modal alignment with synthetic caption for joint image-text-caption optimization, named CASC. The core of this strategy lies in generating fine-grained captions that are informative for multimodal alignment. To realize this, we introduce two novel components: Granularity Awareness Sensor (GAS) and Conditional Contrastive Learning (CCL). GAS selects relative features through an innovative adaptive masking strategy, endowing the model with an enhanced perception of discriminative features. CCL aligns different modalities through further constraints on the synthetic captions by comparing the similarity of hard negative samples, protecting the disruption from noisy contents. With the incorporation of extra caption supervision, the model has access to learn more comprehensive feature representation, which in turn boosts the retrieval performance during inference. Experiments demonstrate that CASC outperforms existing state-of-the-art methods by 1.20%, 2.35% and 2.29% in terms of Rank@1 on CUHK-PEDES, ICFG-PEDES and RSTPReid datasets, respectively.},
  archive      = {J_IJMIR},
  author       = {Zhao, Weichen and Lu, Yuxing and Liu, Zhiyuan and Yang, Yuan and Jiao, Ge},
  doi          = {10.1007/s13735-025-00356-w},
  journal      = {International Journal of Multimedia Information Retrieval},
  month        = {6},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Int. J. Multimed. Inf. Retr.},
  title        = {Cross-modal alignment with synthetic caption for text-based person search},
  volume       = {14},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMFNet: Geometric multi-scale pixel-level contrastive
learning for video salient object detection. <em>IJMIR</em>,
<em>14</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s13735-025-00361-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For video salient object detection (VSOD) tasks, the geometric variations of object foregrounds and backgrounds across multiple scales pose significant challenges for deep learning models in extracting and integrating semantic features from video streams. Current deep learning approaches, such as recurrent neural networks and transformers, struggle to capture both short- and long-term temporal dependencies at a global level due to their fixed kernel structures. Additionally, these methods are computationally intensive, limiting their practical application. To address these challenges and achieve a balance between accuracy and computational efficiency, a novel lightweight Deformable Multi-scale Fusion Network is proposed, which extracts both attention-based multi-scale features and geometric features together to generate the efficient saliency map. Further, the Geometric Multi-Scale Pixel-level Contrastive Learning (GMPCL) approach, which enhances the geometric representation of features is proposed using GMPCL loss and separates the geometric representations of foreground and background features of objects at the pixel level. The performance evaluation is done on six benchmark datasets and compared with twenty-two state-of-the-art (SOTA) models. The main highlight of this work is that it performs well on most challenging datasets DAVSOD-Difficult as compared to SOTA models and has 6.2 million network parameters, 5.6 G FLOPS, and 90 FPS inference speed.},
  archive      = {J_IJMIR},
  author       = {Singh, Hemraj and Verma, Mridula and Cheruku, Ramalingaswamy},
  doi          = {10.1007/s13735-025-00361-z},
  journal      = {International Journal of Multimedia Information Retrieval},
  month        = {6},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Int. J. Multimed. Inf. Retr.},
  title        = {DMFNet: Geometric multi-scale pixel-level contrastive learning for video salient object detection},
  volume       = {14},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Concept-based and embedding-based models in lifelog
retrieval: An empirical comparison of performance. <em>IJMIR</em>,
<em>14</em>(2), 1–9. (<a
href="https://doi.org/10.1007/s13735-025-00359-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many lifelog retrieval systems have been introduced that apply various approaches to their search engines. The traditional method was to match concepts, which are visual objects detected in images and semantic queries. This concept-based approach has been applied in many retrieval systems, achieving the top performance in lifelog search challenges. Many novel embedding-based cross-modality retrieval models, such as CLIP, BLIP, or HADA, have been developed recently and obtained state-of-the-art (SOTA) results in the image-text retrieval task. These models have recently been applied in several lifelog search challenges. However, there is no comprehensive comparison between them since many benchmarking evaluations contain bias factors such as different user interfaces of participated lifelog retrieval systems. In this paper, we conducted non-biased experiments in both automatic (non-interactive) and interactive configurations to evaluate the performance of many SOTA retrieval models, including the traditional concept-based approach, in the lifelog retrieval task. Furthermore, we retrained the models in a lifelog Q&amp;A dataset to assess whether retraining on a small lifelog dataset could improve the performance. The result showed that embedding-based search engines outperformed the concept-based approach by a large margin in both settings. The finding opens the opportunity to apply the embedding-based models as a new generation of lifelog retrieval models instead of the conventional concept-based approach. The source code and detailed result are available online https://github.com/m2man/Comparing-models-in-Lifelog-Retrieval-Task .},
  archive      = {J_IJMIR},
  author       = {Nguyen, Manh-Duy and Nguyen, Binh T. and Gurrin, Cathal},
  doi          = {10.1007/s13735-025-00359-7},
  journal      = {International Journal of Multimedia Information Retrieval},
  month        = {6},
  number       = {2},
  pages        = {1-9},
  shortjournal = {Int. J. Multimed. Inf. Retr.},
  title        = {Concept-based and embedding-based models in lifelog retrieval: An empirical comparison of performance},
  volume       = {14},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijmlc---38">IJMLC - 38</h2>
<ul>
<li><details>
<summary>
(2025). Reinforced multi-modal cyberbullying detection with subgraph
neural networks. <em>IJMLC</em>, <em>16</em>(3), 2161–2180. (<a
href="https://doi.org/10.1007/s13042-024-02384-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks have become an indispensable part of contemporary life, and the widespread occurrence of cyberbullying among young people on these sites has sparked serious societal issues. Information on social media often encompasses various heterogeneous elements, such as locations, individuals, organizations, and more. Despite this complexity, text analysis has dominated most studies on cyberbullying detection, ignoring the variety of media data present in social networks. This paper proposes a novel framework for tackling this gap: RSBully is a multi-agent Reinforced Guided Weighted Multi-relational Subgraph Neural Network that is intended to detect cyberbullying effectively. It organizes elements of different types using heterogeneous information networks (HINs) and then transforms them into a weighted multi-relation graph to model the relationship between social media sessions. Second, RSBully uses a reinforced subgraph neural network to eliminate redundant information in social media data by extracting the prominent subgraphs of the graph and capturing intrinsic correlation between modalities and bullying behaviors with interpretability. Comprehensive experimental assessments on real-world social media datasets show that the performance of the RSBully framework outperforms various current state-of-the-art models.},
  archive      = {J_IJMLC},
  author       = {Luo, Kai and Zheng, Ce and Guan, Zhenyu},
  doi          = {10.1007/s13042-024-02384-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2161-2180},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Reinforced multi-modal cyberbullying detection with subgraph neural networks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced and lightweight design of small object detector
based on YOLOv5s model. <em>IJMLC</em>, <em>16</em>(3), 2139–2159. (<a
href="https://doi.org/10.1007/s13042-024-02383-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the challenges of dense target distribution and complex backgrounds in small detection targets, existing small object detection algorithms suffer from poor performance and high model complexity, which is extremely difficult to deploy on embedded platforms. To address above issues, we optimized the YOLOv5s model structure to enhance detection accuracy. To avoid incurring extra computational expenses, we introduced a local pruning strategy to reduce redundancy, which enables the detection model more suitable for embedded systems. Considering pruning may cause accuracy degradation, we employ knowledge distillation techniques combining feature distillation and output distillation. Specifically, we transfer the knowledge from a high-precision teacher model to a student model, enabling exceptional real-time performance. The experimental results on the VisDrone2019 dataset show that compared to the original algorithm, our model has reduced the parameter count by 50.38%, computation by 51.81%, and model size by 52.94%, totaling just 8 M. The average precision (mAP@0.5) improved to 42.2%. Our proposed model outperforms the current state-of-the-art methods for small object detection in terms of both accuracy and computational efficiency.},
  archive      = {J_IJMLC},
  author       = {Jiang, Hui and Ma, Yongjie and Hong, Tiansong and Gong, Tao},
  doi          = {10.1007/s13042-024-02383-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2139-2159},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhanced and lightweight design of small object detector based on YOLOv5s model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning based magnet design for arm MRI
system. <em>IJMLC</em>, <em>16</em>(3), 2127–2138. (<a
href="https://doi.org/10.1007/s13042-024-02382-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throwing elbow is a common sports injury that can be diagnosed more promptly by portable magnetic resonance imaging (MRI) than by conventional superconducting MRI. The main magnet of portable MRI systems typically consists of permanent magnets. However, the limited length of the main magnet can lead to poor magnetic field homogeneity, resulting in image distortion. Therefore, it is essential to optimize the permanent magnets arrangement. The traditional genetic algorithm (GA) lacks a timely feedback mechanism during the search process, and there is no gradual interaction with the magnetic field map in a single iteration, which has potential for improvement. To address this problem, a deep reinforcement learning (DRL) based magnet design algorithm for an arm MRI system is proposed. Based on the magnetic field map, the method is performed to design a high homogeneity magnet under the weight constraint on the main magnet, significantly better than the multi-objective method NSGA-II. The results indicate that the proposed method achieves a 26.7% gain in homogeneity at a higher average magnetic field strength compared to the GA. In a scenario where the volume of the main magnet is uniform and without weight constraint, an adaptive search mechanism is proposed that enables the method to achieve a 62.90% improvement in homogeneity compared to the GA.},
  archive      = {J_IJMLC},
  author       = {Pang, Yanwei and Guo, Yishun and Liu, Yiming and Song, Zhanjie and Wang, Zhenchang},
  doi          = {10.1007/s13042-024-02382-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2127-2138},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Deep reinforcement learning based magnet design for arm MRI system},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual insurance for generalized zero-shot learning.
<em>IJMLC</em>, <em>16</em>(3), 2111–2125. (<a
href="https://doi.org/10.1007/s13042-024-02381-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional zero-shot learning aims to use the trained model to accurately classify samples from unseen classes, while for the more difficult task of generalized zero-shot learning, the trained model needs to classify samples from both seen and unseen classes into the correct classes. Because only seen class samples are available during training, generalized zero-shot learning meets great challenges in classification. Generative model is one of the good methods to solve this problem. However, the samples generated by the generative model are often of poor quality. In addition, there are semantic redundancies in the generated samples that are not conducive to classification. To solve these problems, we proposed the dual insurance model (DI-GAN) for generalized zero-shot learning in this paper, including a feature generation module and a semantic separation module. They guarantee the high quality of generated features and the good classification performance respectively. Specifically, the first insurance is based on generative adversarial network, whose generator is constrained by a clustering method to make the generated samples close to the real samples. The second insurance is based on variational autoencoder, including semantic separation, instance network and classification network. Semantic separation is designed to extract the semantically related parts which are beneficial to classification, while instance network acting on the semantically related parts is used to ensure the classification performance. Extensive experiments on four benchmark datasets show the competitiveness of the proposed DI-GAN.},
  archive      = {J_IJMLC},
  author       = {Liang, Jiahao and Fang, Xiaozhao and Kang, Peipei and Han, Na and Li, Chuang},
  doi          = {10.1007/s13042-024-02381-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2111-2125},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dual insurance for generalized zero-shot learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultra-high-definition underwater image enhancement via
dual-domain interactive transformer network. <em>IJMLC</em>,
<em>16</em>(3), 2093–2109. (<a
href="https://doi.org/10.1007/s13042-024-02379-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of ultra-high-definition (UHD) imaging device is increasingly being used for underwater image acquisition. However, due to light scattering and underwater impurities, UHD underwater images often suffer from color deviations and edge blurriness. Many studies have attempted to enhance underwater images by integrating frequency domain and spatial domain information. Nonetheless, these approaches often interactively fuse dual-domain features only in the final fusion module, neglecting the complementary and guiding roles of frequency domain and spatial domain features. Additionally, the extraction of dual-domain features is independent of each other, which leads to the sharp advantages and disadvantages of the dual-domain features extracted by these methods. Consequently, these methods impose high demands on the feature fusion capabilities of the fusion module. But in order to handle UHD underwater images, the fusion modules in these methods often stack only a limited number of convolution and activation function operations. This limitation results in insufficient fusion capability, leading to defects in the restoration of edges and colors in the images. To address these issues, we develop a dual-domain interaction network for enhancing UHD underwater images. The network takes into account both frequency domain and spatial domain features to complement and guide each other’s feature extraction patterns, and fully integrates the dual-domain features in the model to better recover image details and colors. Specifically, the network consists of a U-shaped structure, where each layer is composed of dual-domain interaction transformer blocks containing interactive multi-head attention and interactive simple gate feed-forward networks. The interactive multi-head attention captures local interaction features of frequency domain and spatial domain information using convolution operation, followed by multi-head attention operation to extract global information of the mixed features. The interactive simple gate feed-forward network further enhances the model’s dual-domain interaction capability and cross-dimensional feature extraction ability, resulting in clearer edges and more realistic colors in the images. Experimental results demonstrate that the performance of our proposal in enhancing underwater images is significantly better than existing methods.},
  archive      = {J_IJMLC},
  author       = {Li, Weiwei and Cao, Feiyuan and Wei, Yiwen and Shi, Zhenghao and Jia, Xiuyi},
  doi          = {10.1007/s13042-024-02379-x},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2093-2109},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Ultra-high-definition underwater image enhancement via dual-domain interactive transformer network},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Triple confidence-aware encoder–decoder model for
commonsense knowledge graph completion. <em>IJMLC</em>, <em>16</em>(3),
2073–2091. (<a
href="https://doi.org/10.1007/s13042-024-02378-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commonsense knowledge is essential for performing inference and retrieval in many artificial intelligence applications, including those in natural language processing and expert system. However, a large amount of valuable commonsense knowledge exists implicitly or is missing in commonsense knowledge graphs (KGs). In this case, commonsense knowledge graph completion (CKGC) is proposed to solve this incomplete problem by inferring missing parts of commonsense triples, e.g., (?, HasPrerequisite, turn computer on) or (get onto web, HasPrerequisite, ?). Some existing methods attempt to learn as much entity semantic information as possible by exploiting the structural and semantic context of entities for improving the performance of CKGC. However, we found that the existing models only pay attention to entities and relations of the commonsense triples and ignore the important confidence (weight) information related to the commonsense triples. In this paper we innovatively introduce commonsense triple confidence into CKGC and propose a confidence-aware encoder–decoder CKGC model. In the encoding stage, we propose a method to incorporate the commonsense triple confidence into RGCN (relational graph convolutional network), so that the encoder can learn a more accurate semantic representation of a triple by considering the triple confidence constraints. Moreover, the commonsense KGs are usually sparse, because there are a large number of entities with an in-degree of 1 in the commonsense triples. Therefore, we propose to add a new relation (called similar edge) between two similar entities for compensating the sparsity of commonsense KGs. In the decoding stage, considering that entities in the commonsense triples are sentence-level entities (e.g., the tail entity turn computer on mentioned above), we propose a joint decoding model by fusing effectively the existing InteractE and ConvTransE models. Experiments show that our new model achieves better performance compared to the previous competitive models. In particular, the incorporating of the confidence of triples actually brings significant improvements to CKGC.},
  archive      = {J_IJMLC},
  author       = {Chen, Hongzhi and Zhang, Fu and Li, Qinghui and Li, Xiang and Ding, Yifan and Zhang, Daqing and Cheng, Jingwei and Wang, Xing},
  doi          = {10.1007/s13042-024-02378-y},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2073-2091},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Triple confidence-aware encoder–decoder model for commonsense knowledge graph completion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic path planning fusion algorithm with improved a*
algorithm and dynamic window approach. <em>IJMLC</em>, <em>16</em>(3),
2057–2071. (<a
href="https://doi.org/10.1007/s13042-024-02377-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of robotics, path planning in complex dynamic environments has become a significant research hotspot. Existing methods often suffer from inadequate dynamic obstacle avoidance capabilities and low exploration efficiency. These issues primarily arise from inconsistencies caused by insufficient utilization of environmental maps in actual path planning. To address these challenges, we propose an improved algorithm that integrates the enhanced A* algorithm with the optimized dynamic window approach (DWA). The enhanced A* algorithm improves the robot’s path smoothness and accelerates global exploration efficiency, while the optimized DWA enhances local static and dynamic obstacle avoidance capabilities. We performed simulation experiments using MATLAB and conducted experiments in real dynamic environments simulated with Gazebo. Simulation results indicate that, compared to the traditional A* algorithm, our method optimizes traversed grids by 25% and reduces time by 23% in global planning. In dynamic obstacle avoidance, our approach improves path length by 2.7% and reduces time by 19.2% compared to the traditional DWA, demonstrating significant performance enhancements.},
  archive      = {J_IJMLC},
  author       = {Zhang, Jianfeng and Guo, Jielong and Zhu, Daxin and Xie, Yufang},
  doi          = {10.1007/s13042-024-02377-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2057-2071},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Dynamic path planning fusion algorithm with improved a* algorithm and dynamic window approach},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LSSMSD: Defending against black-box DNN model stealing based
on localized stochastic sensitivity. <em>IJMLC</em>, <em>16</em>(3),
2041–2056. (<a
href="https://doi.org/10.1007/s13042-024-02376-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning as a service (MLaaS) has become a widely adopted approach, allowing customers to access even the most complex machine learning models through a pay-per-query model. Black-box distribution has been widely used to keep models secret in MLaaS. However, even with black-box distribution alleviating certain risks, the functionality of a model can still be compromised when customers gain access to their model’s predictions. To protect the intellectual property of model owners, we propose an effective defense method against model stealing attacks with the localized stochastic sensitivity (LSS), namely LSSMSD. First, suspicious queries are detected by employing an out-of-distribution (OOD) detector. Addressing a critical issue with many existing defense methods that overly rely on OOD detection results, thus affecting the model’s fidelity, we innovatively introduce LSS to solve this problem. By calculating the LSS of suspicious queries, we can selectively output misleading predictions for queries with high LSS using an misinformation mechanism. Extensive experiments demonstrate that LSSMSD offers robust protections for victim models against black-box proxy attacks such as Jacobian-based dataset augmentation and Knockoff Nets. It significantly reduces accuracies of attackers’ substitute models (up to 77.94%) while yields minimal impact to benign user accuracies (average $$-2.72\%$$ ), thereby maintaining the fidelity of the victim model.},
  archive      = {J_IJMLC},
  author       = {Zhang, Xueli and Chen, Jiale and Li, Qihua and Zhang, Jianjun and Ng, Wing W. Y. and Wang, Ting},
  doi          = {10.1007/s13042-024-02376-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2041-2056},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {LSSMSD: Defending against black-box DNN model stealing based on localized stochastic sensitivity},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CHNSCDA: CircRNA-disease association prediction based on
strongly correlated heterogeneous neighbor sampling. <em>IJMLC</em>,
<em>16</em>(3), 2023–2039. (<a
href="https://doi.org/10.1007/s13042-024-02375-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular RNAs (circRNAs) are a special class of endogenous non-coding RNA molecules with a closed circular structure. Numerous studies have demonstrated that exploring the association between circRNAs and diseases is beneficial in revealing the pathogenesis of diseases. However, traditional biological experimental methods are time-consuming. Although some methods have explored the circRNA associated with diseases from different perspectives, how to effectively integrate the multi-perspective data of circRNAs has not been well studied, and the feature aggregation between heterogeneous nodes has not been fully considered. Based on these considerations, a novel computational framework, called CHNSCDA, is proposed to efficiently forecast unknown circRNA-disease associations(CDAs). Specifically, we calculate the sequence similarity and functional similarity for circRNAs, as well as the semantic similarity for diseases. Then the similarities of circRNAs and diseases are combined with Gaussian interaction profile kernels (GIPs) similarity, respectively. These similarities are fused by taking the maximum values. Moreover, circRNA-circRNA associations and disease-disease associations with strong correlations are selectively combined to construct a heterogeneous network. Subsequently, we predict the potential CDAs based on the multi-head dynamic attention mechanism and multi-layer convolutional neural network. The experimental results show that CHNSCDA outperforms the other four state-of-the-art methods and achieves an area under the ROC curve of 0.9803 in 5-fold cross validation (5-fold CV). In addition, extensive ablation comparison experiments were conducted to confirm the validity of different similarity feature aggregation methods, feature aggregation methods, and dynamic attention. Case studies further demonstrate the outstanding performance of CHNSCDA in predicting potential CDAs.},
  archive      = {J_IJMLC},
  author       = {Lin, Yuanyuan and Wang, Nianrui and Liu, Jiangyan and Zhang, Fangqin and Wei, Zhouchao and Yi, Ming},
  doi          = {10.1007/s13042-024-02375-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2023-2039},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {CHNSCDA: CircRNA-disease association prediction based on strongly correlated heterogeneous neighbor sampling},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-agent collaborative algorithm for task-oriented
dialogue systems. <em>IJMLC</em>, <em>16</em>(3), 2009–2022. (<a
href="https://doi.org/10.1007/s13042-024-02374-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, reinforcement learning has found successful applications in dialogue systems. However, when confronted with task-oriented dialogue systems, optimizing the strategy becomes challenging due to difficulties in state tracking and the complexity of multitasking. Task-oriented dialogue systems based on reinforcement learning encounter issues such as poor collaboration, non-unique learning goals, and non-staticity arising from the absence of agent cooperation. To address these challenges, this paper introduces a novel multi-agent cooperative dialogue (MACD) algorithm for task-oriented dialogue systems. In MACD, a deep neural network framework is employed to facilitate information exchange among multiple agents within task-oriented dialogue systems. This integration enables the consolidation of observations from individual agents, leading to the derivation of joint observations and fostering information sharing among the agents. Consequently, MACD aims to mitigate the problem of non-stationarity resulting from the lack of shared information among multiple agents. In the context of multi-agent strategy learning within task-oriented dialogue systems, we employ the MADDPG architecture to address the challenge of inadequate joint strategy learning among multiple agents. By integrating single-agent observations and multi-agent strategy learning, we aim to alleviate the collaborative deficiencies inherent in task-oriented dialogue systems involving multiple agents. Through experimentation with reinforcement learning algorithms such as MACD, DQN, OPPA, JOIE, and QMIX on the MultiWOZ 2.0 corpus, our results demonstrate significant enhancements. Specifically, the proposed algorithm effectively elevates the success rate of multi-agent collaboration in accomplishing dialogue tasks in composite task scenarios. Furthermore, it mitigates the occurrence of ineffective dialogues during the dialogue rounds. Comparative analysis reveals that our approach surpasses conventional reinforcement learning algorithms in facilitating agent information interaction and joint strategy learning within the task-oriented dialogue context.},
  archive      = {J_IJMLC},
  author       = {Sun, Jingtao and Kou, Jiayin and Shi, Weipeng and Hou, Wenyan},
  doi          = {10.1007/s13042-024-02374-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {2009-2022},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A multi-agent collaborative algorithm for task-oriented dialogue systems},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant control design for nonlinear multilateral
teleoperation system with unreliable communication channels and actuator
constraints. <em>IJMLC</em>, <em>16</em>(3), 1991–2007. (<a
href="https://doi.org/10.1007/s13042-024-02373-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For nonlinear multilateral teleoperation systems, unreliable communication channels and actuator constraints are the main challenging issues to achieve the stability condition and satisfy the required performance. In this paper, a novel fault-tolerant control algorithm is proposed for a class of multi-degree-of-freedom nonlinear multilateral teleoperation systems with the aforementioned problems and unknown environmental forces. The time-varying delays and packet dropouts are incorporated in the unreliable communication channels, and the considered systems are modeled as a kind of T-S fuzzy systems with multiple time-varying delays. For actuator constraints, both the actuator failures and the unknown control directions are investigated in such research, by designing a novel fault-tolerant control scheme, the failures and control directions can be estimated simultaneously. Next, the radial basis function neural network (RBFNN) is introduced to estimate the unknown environmental force, and the estimated results are incorporated in the controller design and the mean-square stability of the closed-loop system with disturbance attenuation level is guaranteed. Finally, a numerical simulation example is given to show the effectiveness of the proposed method.},
  archive      = {J_IJMLC},
  author       = {Ke, Huan-Yu and Chen, Yang-Jie and Li, Ming and Li, Jian-Ning},
  doi          = {10.1007/s13042-024-02373-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1991-2007},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Fault-tolerant control design for nonlinear multilateral teleoperation system with unreliable communication channels and actuator constraints},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating global semantics and enhanced local subgraph for
inductive link prediction. <em>IJMLC</em>, <em>16</em>(3), 1971–1990.
(<a href="https://doi.org/10.1007/s13042-024-02372-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inductive link prediction (ILP) predicts missing triplets involving unseen entities in knowledge graphs (KGs). Existing ILP research mainly addresses seen-unseen entities in the original KG (semi-inductive link prediction) and unseen-unseen entities in emerging KGs (fully-inductive link prediction). Bridging-inductive link prediction, which focuses on unseen entities that carry evolutionary information from the original KG to the emerging KG, has not been extensively studied so far. This study introduces a novel model called GSELI (integrating global semantics and enhanced local subgraph for inductive link prediction), which comprises three components. (1) The contrastive learning-based global semantic features (CLSF) module extracts relation-specific semantic features between the original and emerging KGs and employs semantic-aware contrastive learning to optimize these features. (2) The GNN-based enhanced local subgraph (GELS) module employs personalized PageRank (PPR)-based local clustering to sample tightly-related subgraphs and incorporates complete neighboring relations to enhance the topological information of subgraphs. (3) Joint contrastive learning and supervised learning training. Experimental results on various benchmark datasets demonstrate that GSELI outperforms the baseline models in both fully-inductive and bridging-inductive link predictions.},
  archive      = {J_IJMLC},
  author       = {Liang, Xinyu and Si, Guannan and Li, Jianxin and An, Zhaoliang and Tian, Pengxin and Zhou, Fengyu and Wang, Xiaoliang},
  doi          = {10.1007/s13042-024-02372-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1971-1990},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Integrating global semantics and enhanced local subgraph for inductive link prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative filter pruning with combined feature maps and
knowledge distillation. <em>IJMLC</em>, <em>16</em>(3), 1955–1969. (<a
href="https://doi.org/10.1007/s13042-024-02371-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been successfully implemented in various computer vision tasks. However, the remarkable achievements are accompanied by high memory and high computation, which hinder the deployment and application of CNNs on resource-constrained mobile devices. Filter pruning is proposed as an effective method to solve the above problems. In this paper, we propose an iterative filter pruning method that combines feature map properties and knowledge distillation. This method can maximize the important feature information (e.g., spatial features) in the feature map by calculating the information capacity and feature relevance of the feature map, and then pruning based on the set criteria. Then, the pruned network learns the complete feature information of the standard CNN architecture in order to quickly and completely recover the lost accuracy before the next pruning operation. The alternating operation of pruning and knowledge distillation can effectively and comprehensively achieve network compression. Experiments on image classification datasets via mainstream CNN architectures indicate the effectiveness of our approach. For example, on CIFAR-10, our method reduces Floating Point Operations (FLOPs) by 71.8% and parameters by 71.0% with an accuracy improvement of 0.24% over the ResNet-110 benchmark. On ImageNet, our method achieves 55.6% reduction in FLOPs and 52.5% reduction in model memory at the cost of losing only 0.17% of Top-5 on ResNet-50.},
  archive      = {J_IJMLC},
  author       = {Liu, Yajun and Fan, Kefeng and Zhou, Wenju},
  doi          = {10.1007/s13042-024-02371-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1955-1969},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Iterative filter pruning with combined feature maps and knowledge distillation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting complex copy-move forgery using KeyPoint-siamese
capsule network against adversarial attacks. <em>IJMLC</em>,
<em>16</em>(3), 1927–1953. (<a
href="https://doi.org/10.1007/s13042-024-02370-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital image forensics, particularly in the realm of detecting Copy-Move Forgery (CMF), is exposed to significant challenges, especially in the face of intricate adversarial attacks. In response to these challenges, this paper presents a robust approach for detecting complex CMFs in digital images using the KeyPoint-Siamese Capsule Network (KP-SCN) and evaluates its resilience against adversarial attacks. The KP-SCN architecture incorporates keypoint detection, a Siamese network for feature extraction, and a capsule network for forgery detection. The method showcases enhanced robustness against adversarial attacks, specifically addressing image perturbation, patch removal, patch replacement, and spatial transformation attacks. By using hierarchical feature representations and dynamic routing in capsule networks, the model effectively handles complex CMF, including rotation, scaling, and non-linear transformations. The proposed KP-SCN approach employs a large dataset for training the KP-SCN, enabling it to identify copy-move forgeries by comparing extracted keypoints and their spatial relationships. KP-SCN demonstrates superior performance compared to the state-of-the-art on the CoMoFoD dataset, achieving precision, recall, and F1-score values of 95.62%, 93.78%, and 94.69%, respectively, and shows strong results on other datasets. For CASIA v2.0, the precision, recall, and F1-score are 90.45%, 88.97%, and 89.70%; for MICC-F2000, they are 91.32%, 90.27%, and 90.79%; for MICC-F600, they are 92.21%, 91.10%, and 91.65%; for MICC-F8multi, they are 89.75%, 87.92%, and 88.83%; and for IMD, they are 93.14%, 92.58%, and 92.86%. The KP-SCN framework maintains high detection rates under various manipulations, including JPEG compression, rotation, scaling, noise, blurring, brightness changes, contrast adjustment, and zoom motion blur compared to the other methods. For instance, it achieves an 80.657% detection rate for CoMoFoD under JPEG compression and 97.883% for IMD under a 10-degree rotation. These findings validate the robustness and adaptability of KP-SCN, making it a reliable solution for real-world forensic applications.},
  archive      = {J_IJMLC},
  author       = {Aiswerya, S. B. and Jawhar, S. Joseph},
  doi          = {10.1007/s13042-024-02370-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1927-1953},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Detecting complex copy-move forgery using KeyPoint-siamese capsule network against adversarial attacks},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-low frequency features fusion and integrated
classification SCNs for intelligent fault diagnosis of rolling bearing.
<em>IJMLC</em>, <em>16</em>(3), 1889–1926. (<a
href="https://doi.org/10.1007/s13042-024-02369-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For fault diagnosis of the rolling bearing, it is difficult to accurately extract and recognize fault features of the vibration signal. In this paper, a novel feature extraction method based on optimized Maximum Correlated Kurtosis Deconvolution (MCKD) by an improved Black Widow Optimization Algorithm (IBWOA) and Singular Value Decomposition (SVD) method was proposed, and an integrated classification Stochastic Configuration Networks (ISCNs) model was designed for fault recognition. Firstly, SVD was used to denoise and reconstruct the signal, in which fault features of the reconstructed signal were highlighted by MCKD; however, the filtering effect of MCKD was seriously affected by accurate value of some parameters, so IBWOA was proposed to realize optimized selection of them. Then, Wavelet Packet Decomposition (WPD) was used to deal with the signal after the feature enhancement, and the high-frequency and low-frequency singular values were extracted as the feature vectors. Finally, the ISCNs model was designed to train and classify the low-frequency and high-frequency feature vectors several times, which were then decided by the principle of ”minority obeying majority”. Simulation experiments show that the proposed method can effectively highlight and extract bearing fault features, and the average diagnostic accuracy can maximum reach 99.66% according to multiple experiments.},
  archive      = {J_IJMLC},
  author       = {Li, Kun and Wu, Hao and Han, Ying},
  doi          = {10.1007/s13042-024-02369-z},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1889-1926},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {High-low frequency features fusion and integrated classification SCNs for intelligent fault diagnosis of rolling bearing},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video anomaly detection based on multi-scale optical flow
spatio-temporal enhancement and normality mining. <em>IJMLC</em>,
<em>16</em>(3), 1873–1888. (<a
href="https://doi.org/10.1007/s13042-024-02368-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection aims to detect anomaly scores in video frames, and it is a challenging research area since the types of anomalies are limitless. In response to the fact that abnormal behavior is likely to be misidentified as normal and anomalies are typically generated by the fast motion of foreground objects, this paper proposes a novel model called the Multi-scale Optical Flow Spatio-Temporal Enhancement and Normality Mining Network (MOFSTE-NM). It contains the Spatio-temporal Information Attention Enhancement Module (SIAEM) that incorporates reconstructed optical flows at multiple scales and considers spatial and temporal aspects. This strategy reduces the influence of the background and normal objects, enhancing the model’s ability to focus on anomalous fast moving objects in the foreground. Additionally, we propose a Normality Mining Convolution (NMC) module embedded in the decoder to refine the boundary between normality and abnormality. The NMC uses a multihead attention mechanism for dynamic weight adjustment, enabling the precise extraction of normal information. We compute the final anomaly score by fusing two components: (1) the reconstruction error of the optical flows and (2) the peak signal-to-noise ratio between the predicted frame and its ground truth. We evaluate our model on three well-established video anomaly detection datasets. A comparison of different models indicates that the proposed model achieves superior performance compared to state-of-the-art approaches, with area under the receiver operating characteristic curve (AUROC) values of 99.23 $$\%$$ on UCSD Ped2, 88.84 $$\%$$ on CUHK Avenue, and 74.80 $$\%$$ on Shanghaitech.},
  archive      = {J_IJMLC},
  author       = {He, Qiang and Shi, Ruinian and Chen, Linlin and Huo, Lianzhi},
  doi          = {10.1007/s13042-024-02368-0},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1873-1888},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Video anomaly detection based on multi-scale optical flow spatio-temporal enhancement and normality mining},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PTEKC: Pre-training with event knowledge of ConceptNet for
cross-lingual event causality identification. <em>IJMLC</em>,
<em>16</em>(3), 1859–1872. (<a
href="https://doi.org/10.1007/s13042-024-02367-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event causality identification (ECI) aims to identify causal relations between events in texts. Although existing event causality identification works based on fine-tuning pre-trained language models (PLMs) have achieved promising results, they suffer from prohibitive computation costs, catastrophic forgetting of distributional knowledge, as well as poor interpretability. Particularly in low-resource and cross-linguistic scenarios, existing multi-lingual models are generally confronted with the so-called curse of multilinguality, language bias, and hence result in low accuracy and generalization ability. In this paper, we propose a paradigm, termed Pre-training with Event Knowledge of ConceptNet (PTEKC), to couple Multi-lingual Pre-trained Language Models (mPLMs) with event knowledge for cross-lingual event causality identification. Specifically, we have develop a parameter-sharing adapter plugin that facilitates the integration of event knowledge into the frozen PLMs. This approach significantly diminishes the number of trainable parameters and greatly reduces the risk of catastrophic forgetting. Our Adapter integrates multi-lingual alignment event knowledge into the mPLMs through two designed pre-training tasks, namely event masking and self-supervised link prediction. Extensive experiments on the benchmark dataset MECI show that PTEKC is parameter-efficient and can effectively incorporate multi-lingual alignment event knowledge for improving cross-lingual event causality identification.},
  archive      = {J_IJMLC},
  author       = {Zhu, Enchang and Yu, Zhengtao and Huang, Yuxin and Gao, Shengxiang and Xian, Yantuan},
  doi          = {10.1007/s13042-024-02367-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1859-1872},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {PTEKC: Pre-training with event knowledge of ConceptNet for cross-lingual event causality identification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stock closing price prediction based on
ICEEMDAN-FA-BiLSTM–GM combined model. <em>IJMLC</em>, <em>16</em>(3),
1833–1857. (<a
href="https://doi.org/10.1007/s13042-024-02366-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accuracy of stock price forecasting is of great significance in investment decision-making and risk management. However, the complexity and fluctuation of stock prices challenge the traditional forecasting methods to achieve the best accuracy. To improve the accuracy of stock price prediction, a sophisticated combination prediction method based on ICEEMDAN-FA-BiLSTM–GM has been proposed in this article. In this paper, a comprehensive and effective indicator system is constructed, covering 60 indicators such as traditional factors, market sentiment, macroeconomic indicators and company financial data, which affect stock prices. In the data preprocessing stage, in order to eliminate the influence of noise, the stock closing price series is first decomposed by using the ICEEMDAN method, which effectively divides them into high-frequency and low-frequency components according to their respective frequencies. Subsequently, LLE technique is used to narrow down the remaining indicators to obtain 9 narrowed features. Finally, each high-frequency subsequence is combined with all the dimensionality reduction features respectively to construct new indicator sets for input to the model. In the prediction stage, the hyperparameters of the prediction model for each subseries have been determined using the FA algorithm. The prediction has been carried out separately for the high-frequency and low-frequency components, employing the BiLSTM and GM prediction methods. Ultimately, the prediction results of each subseries have been superimposed to obtain the final stock price prediction value. In this paper, an empirical study was conducted using stock price data such as Shanghai composite index. The experimental results show that the established stock price prediction model based on ICEEMDAN-FA-BiLSTM–GM has obvious advantages in terms of prediction accuracy and stability compared with traditional methods and other combined prediction methods. This model can provide more accurate stock price prediction and promote the rationalization of investment decision and the accuracy of risk control.},
  archive      = {J_IJMLC},
  author       = {Xie, Lewei and Wan, Ruibo and Wang, Yuxin and Li, Fangjian},
  doi          = {10.1007/s13042-024-02366-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1833-1857},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Stock closing price prediction based on ICEEMDAN-FA-BiLSTM–GM combined model},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from high-dimensional cyber-physical data streams:
A case of large-scale smart grid. <em>IJMLC</em>, <em>16</em>(3),
1819–1831. (<a
href="https://doi.org/10.1007/s13042-024-02365-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality of data and complexity of decision boundaries in high-dimensional data streams that are collected from cyber-physical power systems can greatly influence the process of learning from data and diagnosing faults in such critical systems. These systems generate massive amounts of data that overburden the system with excessive computational costs. Another issue is the presence of noise in recorded measurements that poses a challenge to the learning process, leading to a degradation in the performance of fault diagnosis. Furthermore, the diagnostic model is often provided with a mixture of redundant measurements that may deviate it from learning normal and fault distributions. This paper presents the effect of feature engineering on mitigating the aforementioned challenges in learning from data streams collected from cyber-physical systems. A data-driven fault diagnosis framework for a 118-bus power system is constructed by integrating feature selection, dimensionality reduction methods, and decision models. A comparative study is enabled accordingly to compare several advanced techniques in both domains. Dimensionality reduction and feature selection methods are compared both jointly and separately. Finally, experiments are concluded, and a setting is suggested that enhances data quality for fault diagnosis.},
  archive      = {J_IJMLC},
  author       = {Hassani, Hossein and Hallaji, Ehsan and Razavi-Far, Roozbeh and Saif, Mehrdad},
  doi          = {10.1007/s13042-024-02365-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1819-1831},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Learning from high-dimensional cyber-physical data streams: A case of large-scale smart grid},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A traffic flow forecasting method based on hybrid
spatial–temporal gated convolution. <em>IJMLC</em>, <em>16</em>(3),
1805–1817. (<a
href="https://doi.org/10.1007/s13042-024-02364-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influenced by the urban road network, traffic flow has complex temporal and spatial correlation characteristics. Traffic flow forecasting is an important problem in the intelligent transportation system, which is related to the safety and stability of the transportation system. At present, many researchers ignore the research need for traffic flow forecasting beyond one hour. To address the issue of long-term traffic flow prediction, this paper proposes a traffic flow prediction model (HSTGCNN) based on a hybrid spatial–temporal gated convolution. Spatial–temporal attention mechanism and Gated convolution are the main components of HSTGCNN. The spatial–temporal attention mechanism can effectively obtain the spatial–temporal features of traffic flow, and gated convolution plays an important role in extracting longer-term features. The usage of dilated causal convolution effectively improves the long-term prediction ability of the model. HSTGCNN predicts the traffic conditions of 1 h, 1.5 h, and 2 h on two general traffic flow datasets. Experimental results show that the prediction accuracy of HSTGCNN is generally better than that of Temporal Graph Convolutional Network (T-GCN), Graph WaveNet, and other baselines.},
  archive      = {J_IJMLC},
  author       = {Zhang, Ying and Yang, Songhao and Wang, Hongchao and Cheng, Yongqiang and Wang, Jinyu and Cao, Liping and An, Ziying},
  doi          = {10.1007/s13042-024-02364-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1805-1817},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {A traffic flow forecasting method based on hybrid spatial–temporal gated convolution},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Backdoor learning curves: Explaining backdoor poisoning
beyond influence functions. <em>IJMLC</em>, <em>16</em>(3), 1779–1804.
(<a href="https://doi.org/10.1007/s13042-024-02363-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Backdoor attacks inject poisoning samples during training, with the goal of forcing a machine learning model to output an attacker-chosen class when presented with a specific trigger at test time. Although backdoor attacks have been demonstrated in a variety of settings and against different models, the factors affecting their effectiveness are still not well understood. In this work, we provide a unifying framework to study the process of backdoor learning under the lens of incremental learning and influence functions. We show that the effectiveness of backdoor attacks depends on (i) the complexity of the learning algorithm, controlled by its hyperparameters; (ii) the fraction of backdoor samples injected into the training set; and (iii) the size and visibility of the backdoor trigger. These factors affect how fast a model learns to correlate the presence of the backdoor trigger with the target class. Our analysis unveils the intriguing existence of a region in the hyperparameter space in which the accuracy of clean test samples is still high while backdoor attacks are ineffective, thereby suggesting novel criteria to improve existing defenses.},
  archive      = {J_IJMLC},
  author       = {Cinà, Antonio Emanuele and Grosse, Kathrin and Vascon, Sebastiano and Demontis, Ambra and Biggio, Battista and Roli, Fabio and Pelillo, Marcello},
  doi          = {10.1007/s13042-024-02363-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1779-1804},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Backdoor learning curves: Explaining backdoor poisoning beyond influence functions},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature correlation fusion and feature selection under
adaptive neighborhood group approximation space. <em>IJMLC</em>,
<em>16</em>(3), 1761–1778. (<a
href="https://doi.org/10.1007/s13042-024-02362-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, features often exhibit dynamic interdependence and interaction. While neighborhood rough sets in feature selection have been extensively studied, approaches focusing on searching over feature groups have received less attention. Drawing inspiration from this premise, a feature fusion method grounded in minimum redundancy is proposed to integrate fragmented features. Maximizing Jeffrey divergence constructs a metric function, facilitating the inscription of knowledge granules on the feature groups. This distance function effectively coordinates the importance of feature groups by mapping samples into an adaptive approximation space. Subsequently, traditional uncertainty measures are extended to the neighborhood granules formed by the feature groups. An objective function based on these metrics of neighborhood uncertainty measures is designed to ascertain the importance of feature groups, presenting a novel feature selection algorithm based on this function. Empirical evaluations of the proposed algorithms are conducted using various datasets sourced from the University of California, Irvine (UCI), providing a comprehensive assessment of the efficacy and performance. The experimental results demonstrate the effectiveness of the algorithm.},
  archive      = {J_IJMLC},
  author       = {Li, Gengsen and Sang, Binbin and Cui, Shaoguo and Chen, Hongmei},
  doi          = {10.1007/s13042-024-02362-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1761-1778},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Feature correlation fusion and feature selection under adaptive neighborhood group approximation space},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving numerical and engineering optimization problems
using a dynamic dual-population differential evolution algorithm.
<em>IJMLC</em>, <em>16</em>(3), 1701–1760. (<a
href="https://doi.org/10.1007/s13042-024-02361-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) is a cutting-edge meta-heuristic algorithm known for its simplicity and low computational overhead. But the traditional DE cannot effectively balance between exploration and exploitation. To solve this problem, in this paper, a dynamic dual-population DE variant (ADPDE) is proposed. Firstly, the dynamic population division mechanism based on individual potential value is presented to divide the population into two subgroups, effectively improving the population diversity. Secondly, a nonlinear reduction mechanism is designed to dynamically adjust the size of potential subgroup to allocate computing resources reasonably. Thirdly, two unique mutation strategies are adopted for two subgroups respectively to better utilise the effective information of potential individuals and ensure fast convergence speed. Finally, adaptive parameter setting methods of two subgroups further achieve the balance between exploration and exploitation. The effectiveness of improved strategies is verified on 21 classical benchmark functions. Then, to verify the overall performance of ADPDE, it is compared with three standard DE algorithms, eight excellent DE variants and seven advanced evolutionary algorithms on CEC2013, CEC2017 and CEC2020 test suites, respectively, and the results show that ADPDE has higher accuracy and faster convergence speed. Furthermore, ADPDE is compared with eight well-known optimizers and CEC2020 winner algorithms on nine real-world engineering optimization problems, and the results indicate ADPDE has the development potential for constrained optimization problems as well.},
  archive      = {J_IJMLC},
  author       = {Zuo, Wenlu and Gao, Yuelin},
  doi          = {10.1007/s13042-024-02361-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1701-1760},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Solving numerical and engineering optimization problems using a dynamic dual-population differential evolution algorithm},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image recoloring for multiple types of color vision
deficiency. <em>IJMLC</em>, <em>16</em>(3), 1691–1700. (<a
href="https://doi.org/10.1007/s13042-024-02360-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many techniques for recoloring images with different effects and improving color discrimination in patients with color vision defects. However, certain issues still persist, such as the unnatural and discordant colors of objects in the converted image. To address these problems, we have explored a comprehensive set of methods to achieve image recoloration. Our approach enables the resulting images to possess three essential characteristics: naturalness, harmonization, and distinguishability, thereby fulfilling the requirements of Color Vision Deficiency individuals. The method comprises two components: recommended palette generation and image recoloring. The former can learn the color distribution of different objects in nature, while the latter can recolor the image in conjunction with the recommended palette. Our experimental findings demonstrate that our approach is feasible and provides a direction for future research.},
  archive      = {J_IJMLC},
  author       = {Jin, Xin and Li, Dandan and Rong, Yiqing and Zou, Dongqing and Zhou, Wu and Zhang, Xiaokun},
  doi          = {10.1007/s13042-024-02360-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1691-1700},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Image recoloring for multiple types of color vision deficiency},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scnet: Shape-aware convolution with KFNN for point clouds
completion. <em>IJMLC</em>, <em>16</em>(3), 1671–1690. (<a
href="https://doi.org/10.1007/s13042-024-02359-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scanned 3D point cloud data is typically noisy and incomplete. Existing point cloud completion methods tend to learn a mapping of available parts to the complete one but ignore the structural relationships in local regions. They are less competent in learning point distributions and recovering the details of the object. This paper proposes a shape-aware point cloud completion network (SCNet) that employs multi-scale features and a coarse-to-fine strategy to generate detailed, complete point clouds. Firstly, we introduce a K-feature nearest neighbor algorithm to explore local geometric structure and design a novel shape-aware graph convolution that utilizes multiple learnable filters to perceive local shape changes in different directions. Secondly, we adopt non-local feature expansion to generate a coarse point cloud as the rough shape and merge it with the input data to preserve the original structure. Finally, we employ a residual network to fine-tune the point coordinates to smooth the merged point cloud, which is then optimized to a fine point cloud using a refinement module with shape-aware graph convolution and local attention mechanisms. Extensive experiments demonstrate that our SCNet outperforms other methods on the same point cloud completion benchmark and is more stable and robust.},
  archive      = {J_IJMLC},
  author       = {Wu, Xiangyang and Lu, Ziyuan and Qu, Chongchong and Zhou, Haixin and Miao, Yongwei},
  doi          = {10.1007/s13042-024-02359-1},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1671-1690},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Scnet: Shape-aware convolution with KFNN for point clouds completion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing ocular diseases recognition with domain adaptive
framework: Leveraging domain confusion. <em>IJMLC</em>, <em>16</em>(3),
1661–1669. (<a
href="https://doi.org/10.1007/s13042-024-02358-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual health and optimal eyesight hold immense importance in our lives. However, ocular diseases can inflict emotional and financial hardships on patients and families. While various clinical methods exist for diagnosing ocular conditions, early screening of retinal images offers not only a cost-effective approach but also the detection of potential ocular diseases at earlier stages. Simultaneously, many studies have harnessed Convolutional Neural Networks (CNNs) for image recognition, capitalizing on their potential. Nevertheless, the applicability of most networks tends to be limited across different domains. When well-trained models from a domain are applied to another domain, a significant decline in accuracy might occur, thereby constraining the networks’ practical implementation and wider adoption. In this research endeavor, we present a domain adaptive framework, ResNet-50 with Maximum Mean Discrepancy (RMMD). Initially, we employed ResNet-50 architecture as a foundational network, a popular network used for modification and experimenting with whether a module could improve the accuracy. Additionally, we introduce the concept of Maximum Mean Discrepancy (MMD), a metric for quantifying domain differences. Subsequently, we integrate MMD into the loss function, inducing a state of confusion within the network concerning domain disparities. The outcomes derived from the OIA-ODIR dataset substantiate the efficacy of our proposed network. Our framework attains an impressive accuracy of 40.51% (F1) and 81.06% (AUC, Area Under the Receiver Operating Characteristic Curve), marking a notable enhancement of 9.52% and 7.18% respectively when juxtaposed with the fundamental ResNet-50 model, compared with raw ResNet-50 30.99% (F1) and 73.88% (AUC).},
  archive      = {J_IJMLC},
  author       = {Wang, Zayn},
  doi          = {10.1007/s13042-024-02358-2},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1661-1669},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Enhancing ocular diseases recognition with domain adaptive framework: Leveraging domain confusion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-SDH: Improved YOLOv5 using scaled decoupled head for
object detection. <em>IJMLC</em>, <em>16</em>(3), 1643–1660. (<a
href="https://doi.org/10.1007/s13042-024-02357-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a crucial component of computer vision tasks, object detection serves a significant role in a variety of fields, including autonomous driving, defect detection, and remote sensing image recognition. However, the majority of current object detection networks fail to achieve a decent balance between detection accuracy and detection efficiency, and there is room for improvement in terms of detection accuracy. In response, to improve detection accuracy, a more efficient network framework, YOLO-SDH, was proposed in this paper based on You Only Look Once v5 (YOLOv5). In addition, a decoupled head that automatically adjusts the number of channels according to the model size was proposed, which can enhance the network’s detection effect by separating the classification and regression tasks.On the premise of requiring less computation, a lightweight deformable convolution module is proposed so that the convolution can extract ROI over a wider range, thereby enhancing the accuracy of the object detection network. Experiments were run on the datasets of PASCAL VOC2012, NEU-DET, AW, and RSOD. In comparison to the original YOLOv5, the mAP 0.5 of YOLO-SDH improved by 1.29–3.03%, the F1-score improved by 1.2–3.2%, the Precision improved by 0.7–4.2%, demonstrating the algorithm’s efficacy and superiority.},
  archive      = {J_IJMLC},
  author       = {Ren, Zhijie and Yao, Kang and Sheng, Silong and Wang, Beibei and Lang, Xianli and Wan, Dahang and Fu, Weiwei},
  doi          = {10.1007/s13042-024-02357-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1643-1660},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {YOLO-SDH: Improved YOLOv5 using scaled decoupled head for object detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight graph neural network architecture search based
on heuristic algorithms. <em>IJMLC</em>, <em>16</em>(3), 1625–1641. (<a
href="https://doi.org/10.1007/s13042-024-02356-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A graph neural network is a deep learning model for processing graph data. In recent years, graph neural network architectures have become more and more complex as the research progresses, thus the design of graph neural networks has become an important task. Graph Neural Architecture Search aims to automate the design of graph neural network architectures. However, current methods require large computational resources, cannot be applied in lightweight scenarios, and the search process is not transparent. To address these challenges, this paper proposes a graph neural network architecture search method based on a heuristic algorithm combining tabu search and evolutionary strategies (Gnas-Te). Gnas-Te mainly consists of a tabu search algorithm module and an evolutionary strategy algorithm module. The tabu Search Algorithm Module designs and implements for the first time the tabu Search Algorithm suitable for the search of graph neural network architectures, and uses the maintenance of the tabu table to guide the search process. The evolutionary strategy Algorithm Module implements the evolutionary strategy Algorithm for the search of architectures with the design goal of being light-weight. After the reflection and implementation of Gnas-Te, in order to provide an accurate evaluation of the neural architecture search process, a new metric EASI is proposed. Gnas-Te searched architecture is comparable to the excellent human-designed graph neural network architecture. Experimental results on three real datasets show that Gnas-Te has a 1.37% improvement in search accuracy and a 37.7% reduction in search time to the state-of-the-art graph neural network architecture search method for an graph node classification task and can find high allround-performance architectures which are comparable to the excellent human-designed graph neural network architecture. Gnas-Te implements a lightweight and efficient search method that reduces the need of computational resources for searching graph neural network structures and meets the need for high-accuracy architecture search in the case of insufficient computational resources.},
  archive      = {J_IJMLC},
  author       = {Zhao, ZiHao and Tang, XiangHong and Lu, JianGuang and Huang, Yong},
  doi          = {10.1007/s13042-024-02356-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1625-1641},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Lightweight graph neural network architecture search based on heuristic algorithms},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-refined variational transformer for image-conditioned
layout generation. <em>IJMLC</em>, <em>16</em>(3), 1607–1624. (<a
href="https://doi.org/10.1007/s13042-024-02355-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Layout generation is an emerging computer vision task that incorporates the challenges of object localization and aesthetic evaluation, widely used in advertisements, posters, and slides design. An ideal layout should consider both the intra-domain relationship within layout elements and the inter-domain relationship between layout elements and the image. However, most previous methods simply focus on image-content-agnostic layout generation without leveraging the complex visual information from the image. To address this limitation, we propose a novel paradigm called image-conditioned layout generation, which aims to add text overlays to an image in a semantically coherent manner. Specifically, we introduce the Image-Conditioned Variational Transformer (ICVT) that autoregressively generates diverse layouts in an image. Firstly, the self-attention mechanism is adopted to model the contextual relationship within layout elements, while the cross-attention mechanism is used to fuse the visual information of conditional images. Subsequently, we take them as building blocks of the conditional variational autoencoder (CVAE), which demonstrates attractive diversity. Secondly, to alleviate the gap between the layout elements domain and the visual domain, we design a Geometry Alignment module, in which the geometric information of the image is aligned with the layout representation. Thirdly, we present a self-refinement mechanism to automatically refine the failure case of generated layout, effectively improving the quality of generation. Experimental results show that our model can adaptively generate layouts in the non-intrusive area of the image, resulting in a harmonious layout design.},
  archive      = {J_IJMLC},
  author       = {Cao, Yunning and Liu, Chuanbin and Ma, Ye and Zhou, Min and Ge, Tiezheng and Jiang, Yuning and Xie, Hongtao},
  doi          = {10.1007/s13042-024-02355-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1607-1624},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-refined variational transformer for image-conditioned layout generation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Propagation tree says: Dynamic evolution characteristics
learning approach for rumor detection. <em>IJMLC</em>, <em>16</em>(3),
1589–1605. (<a
href="https://doi.org/10.1007/s13042-024-02354-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rapid spread of rumors on social media, which has a detrimental effect on our lives, it is becoming increasingly important to detect rumors. It has been proved that the study of dynamic graphs is helpful to capture the temporal change of information transmission and understand the evolution trend and pattern change of events. However, the dynamic learning methods currently studied do not fully consider the interaction characteristics of the evolutionary process. Therefore, it is difficult to fully capture the structural and semantic differences between them. In order to fully exploit the potential correlations of such temporal information, we propose a novel model named dynamic evolution characteristics learning (DECL) method for rumor detection. First, we partition the temporal snapshot sequences based on the propagation structure of rumors. Secondly, a multi-task graph contrastive learning method is adopted to enable the graph encoder to capture the essential features of rumors, and to fully explore the temporal structural differences and semantic similarities between true rumor and false rumor events. Experimental results on three real-world social media datasets confirm the effectiveness of our model for rumor detection tasks.},
  archive      = {J_IJMLC},
  author       = {Zhao, Shouhao and Ji, Shujuan and Lv, Jiandong and Fang, Xianwen},
  doi          = {10.1007/s13042-024-02354-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1589-1605},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Propagation tree says: Dynamic evolution characteristics learning approach for rumor detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised progressive graph neural network for
enhanced multi-behavior recommendation. <em>IJMLC</em>, <em>16</em>(3),
1573–1588. (<a
href="https://doi.org/10.1007/s13042-024-02353-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-behavior recommendation (MBR) aims to enhance the accuracy of predicting target behavior by considering multiple behaviors simultaneously. Recent researches have attempted to capture the dependencies within behavioral sequences to improve recommendation outcomes, exemplified by the sequential pattern “click $$\rightarrow $$ cart $$\rightarrow $$ buy”. However, their performances are still limited due to the following two problems. Firstly, potential leapfrogging relations among behaviors are underexplored, notably in cases where users purchase directly post-click, bypassing the cart stage. Skipping intermediate behavior allows for better modeling of real-world realities. Secondly, the uneven distribution of user behaviors and item popularity presents a challenge for model training, resulting in prevalence bias and over-reliance issues. To this end, we propose a self-supervised progressive graph neural network model, namely SSPGNN. The model can capture a broader range of behavioral dependencies by using a dual-behavior chain. In addition, we design a self-supervised learning mechanism, including intra- and inter-behavioral self-supervised learning, the former within a single behavior and the latter across multiple behaviors, to address the problems of prevalence bias and overdependence. Extensive experiments on real-world datasets and comparative analyses with state-of-the-art algorithms demonstrate the effectiveness of the proposed SSPGNN. The source codes of this work are available at https://github.com/ZZY-GraphMiningLab/SSPGNN .},
  archive      = {J_IJMLC},
  author       = {Liu, Tianhang and Zhou, Hui and Li, Chao and Zhao, Zhongying},
  doi          = {10.1007/s13042-024-02353-7},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1573-1588},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Self-supervised progressive graph neural network for enhanced multi-behavior recommendation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GRPIC: An end-to-end image captioning model using three
visual features. <em>IJMLC</em>, <em>16</em>(3), 1559–1572. (<a
href="https://doi.org/10.1007/s13042-024-02352-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {lmage captioning is a multimodal task involving both computer vision and natural language processing. Recently, there has been a substantial improvement in the performance of image captioning with the introduction of multi-feature extraction methods. However, existing single-feature and multi-feature methods still face challenges such as a low refinement degree, weak feature complementarity, and lack of an end-to-end model. To tackle these issues, we propose an end-to-end image captioning model called GRPIC (Grid-Region-Pixel Image Captioning), which integrates three types of image features: region features, grid features, and pixel features. Our model utilizes the Swin Transformer for extracting grid features, DETR for extracting region features, and Deeplab for extracting pixel features. We merge pixel-level features with region and grid features to extract more refined contextual and detailed information. Additionally, we incorporate absolute position information and pairwise align the three features to fully leverage their complementarity. Qualitative and quantitative experiments conducted on the MSCOCO dataset demonstrate that our model achieved a 2.3% improvement in CIDEr, reaching 136.1 CIDEr compared to traditional dual-feature methods on the Karpathy test split. Furthermore, observation of the actual generated descriptions shows that the model also produced more refined captions.},
  archive      = {J_IJMLC},
  author       = {Peng, Shixin and Xiong, Can and Liu, Leyuan and Yang, Laurence T. and Chen, Jingying},
  doi          = {10.1007/s13042-024-02352-8},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1559-1572},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {GRPIC: An end-to-end image captioning model using three visual features},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label distribution learning by utilizing common and
label-specific feature fusion space. <em>IJMLC</em>, <em>16</em>(3),
1545–1558. (<a
href="https://doi.org/10.1007/s13042-024-02351-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Distribution Learning (LDL) is a novel machine learning paradigm that focuses on the description degrees of labels to a particular instance. Existing LDL algorithms generally learn with the original input space, that is, all features are simply employed in the discrimination processes of all class labels. However, this common-used data representation strategy ignores that each label is supposed to possess some specific characteristics of its own and therefore, may lead to sub-optimal performance. We propose label distribution learning by utilizing common and label-specific feature fusion space (LDL-CLSFS) in this paper. It first partitions all instances by label-value rankings. Second, it constructs label-specific features of each label by conducting clustering analysis on different instance categories. Third, it performs training and testing by querying the clustering results. Comprehensive experiments on several real-world label distribution data sets validate the superiority of our method against other LDL algorithms as well as the effectiveness of label-specific features.},
  archive      = {J_IJMLC},
  author       = {Zhang, Ziyun and Wang, Jing and Geng, Xin},
  doi          = {10.1007/s13042-024-02351-9},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1545-1558},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Label distribution learning by utilizing common and label-specific feature fusion space},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An ordered subsets orthogonal nonnegative matrix
factorization framework with application to image clustering.
<em>IJMLC</em>, <em>16</em>(3), 1531–1543. (<a
href="https://doi.org/10.1007/s13042-024-02350-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonnegative matrix factorization (NMF) for image clustering attains impressive machine learning performances. However, the current iterative methods for optimizing NMF problems involve numerous matrix calculations and suffer from high computational costs in large-scale images. To address this issue, this paper presents an ordered subsets orthogonal NMF framework (OS-ONMF) that divides the data matrix in an orderly manner into several subsets and performs NMF on each subset. It balances clustering performance and computational efficiency. After decomposition, each ordered subset still contains the core information of the original data. That is, blocking does not reduce image resolutions but can greatly shorten running time. This framework is a general model that can be applied to various existing iterative update algorithms. We also provide a subset selection method and a convergence analysis of the algorithm. Finally, we conducted clustering experiments on seven real-world image datasets. The experimental results showed that the proposed method can greatly shorten the running time without reducing clustering accuracy.},
  archive      = {J_IJMLC},
  author       = {Ma, Limin and Tong, Can and Qi, Shouliang and Yao, Yudong and Teng, Yueyang},
  doi          = {10.1007/s13042-024-02350-w},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1531-1543},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {An ordered subsets orthogonal nonnegative matrix factorization framework with application to image clustering},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clustered automated machine learning (CAML) model for
clinical coding multi-label classification. <em>IJMLC</em>,
<em>16</em>(3), 1507–1529. (<a
href="https://doi.org/10.1007/s13042-024-02349-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical coding is a time-consuming task that involves manually identifying and classifying patients’ diseases. This task becomes even more challenging when classifying across multiple diagnoses and performing multi-label classification. Automated Machine Learning (AutoML) techniques can improve this classification process. However, no previous study has developed an AutoML-based approach for multi-label clinical coding. To address this gap, a novel approach, called Clustered Automated Machine Learning (CAML), is introduced in this paper. CAML utilizes the AutoML library Auto-Sklearn and cTAKES feature extraction method. CAML clusters binary diagnosis labels using Hamming distance and employs the AutoML library to select the best algorithm for each cluster. The effectiveness of CAML is evaluated by comparing its performance with that of the Auto-Sklearn model on five different datasets from the Medical Information Mart for Intensive Care (MIMIC III) database of reports. These datasets vary in size, label set, and related diseases. The results demonstrate that CAML outperforms Auto-Sklearn in terms of Micro F1-score and Weighted F1-score, with an overall improvement ratio of 35.15% and 40.56%, respectively. The CAML approach offers the potential to improve healthcare quality by facilitating more accurate diagnoses and treatment decisions, ultimately enhancing patient outcomes.},
  archive      = {J_IJMLC},
  author       = {Mustafa, Akram and Rahimi Azghadi, Mostafa},
  doi          = {10.1007/s13042-024-02349-3},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1507-1529},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Clustered automated machine learning (CAML) model for clinical coding multi-label classification},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual feature fusion and refinement network for
camouflaged object detection. <em>IJMLC</em>, <em>16</em>(3), 1489–1505.
(<a href="https://doi.org/10.1007/s13042-024-02348-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) is a challenging task due to its irregular shape and color similarity or even blending into the surrounding environment. It is difficult to achieve satisfactory results by directly using salient object detection methods due to the low contrast with the surrounding environment and obscure object boundary in camouflaged object detection. To determine the location of the camouflaged objects and achieve accurate segmentation, the interaction between features is essential. Similarly, an effective feature aggregation method is also very important. In this paper, we propose a contextual fusion and feature refinement network (CFNet). Specifically, we propose a multiple-receptive-fields-based feature extraction module (MFM) that obtains features from multiple scales of receptive fields. Then, the features are input to an attention-based information interaction module (AIM), which establishes the information flow between adjacent layers through an attention mechanism. Finally, the features are fused and optimized layer by layer using a feature fusion module (FFM). We validate the proposed CFNet as an effective COD model on four benchmark datasets, and the generalization ability of our proposed model is verified in the salient object detection task.},
  archive      = {J_IJMLC},
  author       = {Yang, Jinyu and Shi, Yanjiao and Jiang, Ying and Lu, Zixuan and Yi, Yugen},
  doi          = {10.1007/s13042-024-02348-4},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1489-1505},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Contextual feature fusion and refinement network for camouflaged object detection},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight skeleton-based action recognition model based on
global–local feature extraction and fusion. <em>IJMLC</em>,
<em>16</em>(3), 1477–1488. (<a
href="https://doi.org/10.1007/s13042-024-02347-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition has become a research hotspot in the field of computer vision because of its lightweight and strong anti-interference. However, there are disadvantages such as single feature extraction, limited expression ability, and low recognition accuracy. To solve these problems, we propose a lightweight Skeleton-based action recognition model based on global–local feature extraction and fusion (GLF-GCN). GLF-GCN includes a Feature extraction of non-connected nodes Module (Global-GCN), a Feature extraction of adjacent nodes Module (Local-GCN), and a Dynamic Fusion module. More specifically, Global-GCN combines one-dimensional convolution and shift operations to capture spatio-temporal dependencies across global nodes, using shift operations as a replacement for spatio-temporal graph convolution to reduce computational complexity. Meanwhile, Local-GCN captures temporal and spatial local information from first-order neighboring nodes. On this basis, Dynamic Fusion integrates global information based on joint hierarchy and local information based on body parts to discern the varying dependency relationships among different body parts and joints, improving the model’s ability to interpret different skeleton action sequences. The experimental results on single stream and multi-stream data show that the proposed model has higher accuracy, which attains the state-of-the-art performance.},
  archive      = {J_IJMLC},
  author       = {Deng, Zhe and Wang, Yulin and Wei, Xing and Yang, Fan and Zhao, Chong and Lu, Yang},
  doi          = {10.1007/s13042-024-02347-5},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1477-1488},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Lightweight skeleton-based action recognition model based on global–local feature extraction and fusion},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual tracking with screening region enrichment and target
validation. <em>IJMLC</em>, <em>16</em>(3), 1461–1475. (<a
href="https://doi.org/10.1007/s13042-024-02346-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of the one-stream one-stage framework has led to remarkable advances in visual object tracking, resulting in exceptional tracking performance. Most existing one-stream one-stage tracking pipelines have achieved a relative balance between accuracy and speed. However, they focus solely on integrating feature learning and relational modelling. In complex scenes, the tracking performance often falls short due to confounding factors such as changes in target scale, occlusion, and fast motion. In these cases, numerous trackers cannot sufficiently exploit the target feature information and face the dilemma of information loss. To address these challenges, we propose a screening enrichment for transformer-based tracking. Our method incorporates a screening enrichment module as an additional processing operation in the integration of feature learning and relational modelling. The module effectively distinguishes target areas within the search regions. It also enriches the associations between tokens of target area information. In addition, we introduce our box validation module. This module uses the target position information from the previous frame to validate and revise the target position in the current frame. This process enables more accurate target localization. Through these innovations, we have developed a powerful and efficient tracker. It achieves state-of-the-art performance on six benchmark datasets, including GOT-10K, LaSOT, TrackingNet, UAV123, TNL2K and VOT2020. On the GOT-10K benchmarks, Specifically, on the GOT-10K benchmarks, our proposed tracker reaches an impressive Success Rate ( $$S{{R}_{0.5}}$$ ) of 85.4 and an Average Overlap (AO) of 75.3. Experimental results show that our proposed tracker outperforms other state-of-the-art trackers in terms of tracking accuracy.},
  archive      = {J_IJMLC},
  author       = {Sun, Yiqiu and Zhou, Dongming and Yan, Kaixiang},
  doi          = {10.1007/s13042-024-02346-6},
  journal      = {International Journal of Machine Learning and Cybernetics},
  month        = {3},
  number       = {3},
  pages        = {1461-1475},
  shortjournal = {Int. J. Mach. Learn. Cybern.},
  title        = {Visual tracking with screening region enrichment and target validation},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="invent---6">INVENT - 6</h2>
<ul>
<li><details>
<summary>
(2025). The metamathematics of separated determinacy.
<em>INVENT</em>, <em>240</em>(1), 313–457. (<a
href="https://doi.org/10.1007/s00222-025-01322-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determinacy axioms are mathematical principles which assert that various infinite games are determined. In this article, we prove three general meta-theorems on the logical strength of determinacy axioms. These allow us to reduce a metamathematical analysis of the principle of $\Gamma $ -determinacy over a weak base theory to an analysis of a principle $\Gamma &#39;$ -determinacy, where $\Gamma &#39;$ is a strictly smaller complexity class than $\Gamma $ . The meta-theorems are proved in the weak theory ${\mathsf{RCA_{0}}}$ . However, they are formulated in a general way and also have applications in the context of ${\mathsf{ZFC}}$ , eventually leading to an optimal generalization of Martin’s Borel determinacy theorem and optimal strengthenings of the transfer theorems of Martin-Harrington, Kechris-Woodin, and Neeman. As the main application of the meta-theorems, we carry out all the reverse-mathematical analyses of theories of determinacy below $T = \boldsymbol{\Pi }^{1}_{1}{-}{\mathsf{CA_{0}}}+ \Pi ^{1}_{4}{-}{ \mathsf{CA_{0}}}$ which are missing from the literature. More precisely, let $\Gamma \subset \mathcal{P}(\mathbb{R})$ be called a Wadge class if $\Gamma $ is closed under continuous preimages. For each Wadge class $\Gamma $ such that the consistency of $\Gamma $ -Determinacy is provable in $T$ , we reduce the principle of $\Gamma $ -Determinacy to a combination of Comprehension, Monotone Induction, and $\beta $ -Reflection axioms. It follows from our results that these classes $\Gamma $ are precisely those which satisfy $$ o(\Gamma ) &lt; \omega _{1}^{\omega _{1}^{2}} \text{ and $T\vdash $``$\Gamma $ is a Wadge class.&#39;&#39;} $$ Our work extends and generalizes results of Friedman, Hachtman, Heinatsch, Martin, MedSalem, Montalbán, Möllerfeld, Nemoto, Shore, Steel, Tanaka, Welch, and others, and concludes the project of metamathematical analysis of determinacy principles (cf. e.g., Montalbán’s “Open Questions in Reverse Mathematics”, Bull. Symb. Log. 16:431–454, 2011), as far as subsystems of $T$ are concerned.},
  archive      = {J_INVENT},
  author       = {Aguilera, J. P.},
  doi          = {10.1007/s00222-025-01322-3},
  journal      = {Inventiones Mathematicae},
  month        = {4},
  number       = {1},
  pages        = {313-457},
  shortjournal = {Invent. Math.},
  title        = {The metamathematics of separated determinacy},
  volume       = {240},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A <span class="math inline"><em>p</em></span> -adic simpson
correspondence for smooth proper rigid varieties. <em>INVENT</em>,
<em>240</em>(1), 261–312. (<a
href="https://doi.org/10.1007/s00222-025-01321-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For any smooth proper rigid analytic space $X$ over a complete algebraically closed extension of $\mathbb{Q}_{p}$ , we construct a $p$ -adic Simpson correspondence: an equivalence of categories between vector bundles on Scholze’s pro-étale site of $X$ and Higgs bundles on $X$ . This generalises a result of Faltings from smooth projective curves to any higher dimension, and further to the rigid analytic setup. The strategy is new, and is based on the study of rigid analytic moduli spaces of pro-étale invertible sheaves on spectral varieties.},
  archive      = {J_INVENT},
  author       = {Heuer, Ben},
  doi          = {10.1007/s00222-025-01321-4},
  journal      = {Inventiones Mathematicae},
  month        = {4},
  number       = {1},
  pages        = {261-312},
  shortjournal = {Invent. Math.},
  title        = {A $p$ -adic simpson correspondence for smooth proper rigid varieties},
  volume       = {240},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). <span class="math inline">W<sup>*</sup></span>
-superrigidity for cocycle twisted group von neumann algebras.
<em>INVENT</em>, <em>240</em>(1), 193–260. (<a
href="https://doi.org/10.1007/s00222-025-01320-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We construct countable groups $G$ with the following new degree of $\mathrm{W}^{*}$ -superrigidity: if $L(G)$ is virtually isomorphic, in the sense of admitting a bifinite bimodule, with any other group von Neumann algebra $L(\Lambda )$ , then the groups $G$ and $\Lambda $ must be virtually isomorphic. Moreover, we allow both group von Neumann algebras to be twisted by an arbitrary 2-cocycle. We also give examples of $\mathrm{II}_{1}$ factors $N$ that are indecomposable in every sense: they are not virtually isomorphic to any cocycle twisted groupoid von Neumann algebra.},
  archive      = {J_INVENT},
  author       = {Donvil, Milan and Vaes, Stefaan},
  doi          = {10.1007/s00222-025-01320-5},
  journal      = {Inventiones Mathematicae},
  month        = {4},
  number       = {1},
  pages        = {193-260},
  shortjournal = {Invent. Math.},
  title        = {$\mathrm{W}^{*}$ -superrigidity for cocycle twisted group von neumann algebras},
  volume       = {240},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cohomological milnor formula and saito’s conjecture on
characteristic classes. <em>INVENT</em>, <em>240</em>(1), 123–191. (<a
href="https://doi.org/10.1007/s00222-025-01319-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We confirm the quasi-projective case of Saito’s conjecture (Invent. Math. 207:597–695, 2017), namely that the cohomological characteristic classes defined by Abbes and Saito can be computed in terms of the characteristic cycles. We construct a cohomological characteristic class supported on the non-acyclicity locus of a separated morphism relatively to a constructible sheaf. As applications of the functorial properties of this class, we prove cohomological analogs of the Milnor formula and the conductor formula for constructible sheaves on (not necessarily smooth) varieties.},
  archive      = {J_INVENT},
  author       = {Yang, Enlin and Zhao, Yigeng},
  doi          = {10.1007/s00222-025-01319-y},
  journal      = {Inventiones Mathematicae},
  month        = {4},
  number       = {1},
  pages        = {123-191},
  shortjournal = {Invent. Math.},
  title        = {Cohomological milnor formula and saito’s conjecture on characteristic classes},
  volume       = {240},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Logarithmic double ramification cycles. <em>INVENT</em>,
<em>240</em>(1), 35–121. (<a
href="https://doi.org/10.1007/s00222-025-01318-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $A=(a_{1},\ldots , a_{n})$ be a vector of integers which sum to $k(2g-2+n)$ . The double ramification cycle $\mathsf{DR}_{g,A}\in \mathsf{CH}^{g}(\overline{\mathcal{M}}_{g,n})$ on the moduli space of curves is the virtual class of an Abel-Jacobi locus of pointed curves $(C,x_{1},\ldots ,x_{n})$ satisfying $$ \mathcal{O}_{C}\Big(\sum _{i=1}^{n} a_{i} x_{i}\Big) \, \simeq \, \big(\omega ^{\mathsf{log}}_{C}\big)^{k}\, . $$ The Abel-Jacobi construction requires log blow-ups of $\overline{\mathcal{M}}_{g,n}$ to resolve the indeterminacies of the Abel-Jacobi map. Holmes (J. Inst. Math. Jussieu 2019) has shown that $\mathsf{DR}_{g,A}$ admits a canonical lift $\mathsf{logDR}_{g,A} \in \mathsf{logCH}^{g}(\overline{\mathcal{M}}_{g,n})$ to the logarithmic Chow ring, which is the limit of the intersection theories of all such blow-ups. The main result of the paper is an explicit formula for $\mathsf{logDR}_{g,A}$ which lifts Pixton’s formula for $\mathsf{DR}_{g,A}$ . The central idea is to study the universal Jacobian over the moduli space of curves (following Caporaso (Am. Math. Soc. 7(3):589–660 1994), Kass-Pagani (Trans. Am. Math. Soc. 372:4851–4887 2019), and Abreu-Pacini (Adv. Math. 378:107520 2021)) for certain stability conditions. Using the criterion of Holmes-Schwarz (Algebr. Geom. 9(5):574–605 2022), the universal double ramification theory of Bae-Holmes-Pandharipande-Schmitt-Schwarz (Acta Math. 230(2):205–319 2023) applied to the universal line bundle determines the logarithmic double ramification cycle. The resulting formula, written in the language of piecewise polynomials, depends upon the stability condition (and admits a wall-crossing study). Several examples of logarithmic and higher double ramification cycles are computed.},
  archive      = {J_INVENT},
  author       = {Holmes, D. and Molcho, S. and Pandharipande, R. and Pixton, A. and Schmitt, J.},
  doi          = {10.1007/s00222-025-01318-z},
  journal      = {Inventiones Mathematicae},
  month        = {4},
  number       = {1},
  pages        = {35-121},
  shortjournal = {Invent. Math.},
  title        = {Logarithmic double ramification cycles},
  volume       = {240},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extensions of schoen–simon–yau and schoen–simon theorems via
iteration à la de giorgi. <em>INVENT</em>, <em>240</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s00222-025-01317-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give an alternative proof of the Schoen–Simon–Yau curvature estimates and associated Bernstein-type theorems (Schoen et al. in Acta Math. 134:275–288, 1975), and extend the original result by including the case of 6-dimensional (stable minimal) immersions. The key step is an ε-regularity theorem, that assumes smallness of the scale-invariant $L^{2}$ norm of the second fundamental form. Further, we obtain a graph description, in the Lipschitz multi-valued sense, for any stable minimal immersion of dimension $n\geq 2$ , that may have a singular set $\Sigma $ of locally finite $\mathcal{H}^{n-2}$ -measure, and that is weakly close to a hyperplane. (In fact, if the $\mathcal{H}^{n-2}$ -measure of the singular set vanishes, the conclusion is strengthened to a union of smooth graphs.) This follows directly from an ε-regularity theorem, that assumes smallness of the scale-invariant $L^{2}$ tilt-excess (verified when the hypersurface is weakly close to a hyperplane). Specialising the multi-valued decomposition to the case of embeddings, we recover the Schoen–Simon theorem (Schoen and Simon 34:741–797, 1981). In both ε-regularity theorems the relevant quantity (respectively, length of the second fundamental form and tilt function) solves a non-linear PDE on the immersed minimal hypersurface. The proof is carried out intrinsically (without linearising the PDE) by implementing an iteration method à la De Giorgi (from the linear De Giorgi–Nash–Moser theory). Stability implies estimates (intrinsic weak Caccioppoli inequalities) that make the iteration effective despite the non-linear framework. (In both ε-regularity theorems the method gives explicit constants that quantify the required smallness.)},
  archive      = {J_INVENT},
  author       = {Bellettini, Costante},
  doi          = {10.1007/s00222-025-01317-0},
  journal      = {Inventiones Mathematicae},
  month        = {4},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Invent. Math.},
  title        = {Extensions of Schoen–Simon–Yau and Schoen–Simon theorems via iteration à la de giorgi},
  volume       = {240},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jamc---50">JAMC - 50</h2>
<ul>
<li><details>
<summary>
(2025). Unveiling the dynamics of plasma dilution in medical science
through analytical and numerical approaches via fractional
integro-differential equations. <em>JAMC</em>, <em>71</em>(1),
1219–1245. (<a
href="https://doi.org/10.1007/s12190-024-02279-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a rigorous mathematical analysis utilizing a fractional integro-differential equation model to depict the intricate dynamics of plasma dilution and provide a comprehensive understanding of its implications in various biomedical and clinical contexts. The integro-differential equation governing plasma dilution is formulated by employing Caputo fractional operators and it is addressed and examined using analytical and numerical techniques, Laplace transform which gives an accurate results for the proposed equation and the composite trapezoidal rule with finite difference method as a numerical approach to validate the proposed model, offering a practical tool for predicting plasma dilution under divers. We also discussed the existence and the uniqueness of solutions. Whereas this model has effectively been utilized with real data obtained from a previous human investigation of thyroid surgery, the graphical illustrations are being presented to clarify the results obtained during two time periods, the infusion and postinfusion periods, the two periods are considered a sequential events the infusion phase transpired within the initial 30 min of the surgical procedure following this, the postinfusion phase extended from 30 min to a limited time.},
  archive      = {J_JAMC},
  author       = {Ali, Khalid K. and Mohamed, Mohamed S. and Maneea, M.},
  doi          = {10.1007/s12190-024-02279-x},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1219-1245},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Unveiling the dynamics of plasma dilution in medical science through analytical and numerical approaches via fractional integro-differential equations},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian approach for identifying fractional order and
time-dependent source in a fractional pseudo-parabolic equation.
<em>JAMC</em>, <em>71</em>(1), 1189–1218. (<a
href="https://doi.org/10.1007/s12190-024-02237-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the inverse problem of identifying fractional order and time-dependent source term for fractional pseudo-parabolic equation is investigated. We prove that the simultaneous recovery of the fractional order and the source term is unique, and then give the estimate of measurement data. Such problem is formulated into Bayesian inverse problem, and the continuity of forward mapping is proved. Moreover, the iterative regularizing ensemble Kalman method is applied to solve Bayesian inverse problem and two numerical examples are conducted to show its efficiency.},
  archive      = {J_JAMC},
  author       = {Lyu, Kaiyu and Cheng, Hao},
  doi          = {10.1007/s12190-024-02237-7},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1189-1218},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Bayesian approach for identifying fractional order and time-dependent source in a fractional pseudo-parabolic equation},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced numerical resolution of the duffing and van der pol
equations via the spectral homotopy analysis method employing chebyshev
polynomials of the first kind. <em>JAMC</em>, <em>71</em>(1), 1159–1187.
(<a href="https://doi.org/10.1007/s12190-024-02271-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our investigation, we apply the spectral homotopy analysis method (SHAM) to tackle the numerical resolution of the Duffing and Van Der Pol equations. We compute the numerical solution using Chebyshev polynomials of the first kind as our foundational framework. We optimize the computation of derivative matrices by employing Gauss–Lobatto collocation points. To underscore the practicality and efficiency of our proposed SHAM, we validate our numerical solution against the exact solution and present the error behavior. Furthermore, we demonstrate the superior efficacy of our approach, supported by suitable graphical representations and tables.},
  archive      = {J_JAMC},
  author       = {Bouakkaz, Mouaad and Arar, Nouria and Meflah, Mabrouk},
  doi          = {10.1007/s12190-024-02271-5},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1159-1187},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Enhanced numerical resolution of the duffing and van der pol equations via the spectral homotopy analysis method employing chebyshev polynomials of the first kind},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deferred riesz statistical convergence via power series
method. <em>JAMC</em>, <em>71</em>(1), 1141–1158. (<a
href="https://doi.org/10.1007/s12190-024-02283-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, deferred Riesz statistical convergence as well as $$\hslash $$ -deferred Riesz statistical convergence in terms of power series method for real or complex sequences are introduced and studied. Their interconnection with Riesz statistical convergence is explored and illustrative examples in support of our results are presented. Applications of these convergences in the form of a Korovkin-type approximation theorem are established and illustrations demonstrating the superiority of our proven theorem over the classical Korovkin theorem are offered. Finally, the rate of convergence is computed.},
  archive      = {J_JAMC},
  author       = {Cai, Qing-Bo and Gorka, Samrati and Raj, Kuldip},
  doi          = {10.1007/s12190-024-02283-1},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1141-1158},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Deferred riesz statistical convergence via power series method},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synchronization of fuzzy reaction–diffusion neural networks
via semi-intermittent hybrid control. <em>JAMC</em>, <em>71</em>(1),
1109–1139. (<a
href="https://doi.org/10.1007/s12190-024-02234-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of synchronizing fuzzy reaction–diffusion neural networks (FRDNNs) with time-varying transmission delays using aperiodic semi-intermittent hybrid controls and explores its application within the realm of image encryption. The main challenge in analyzing the dynamics of FRDNNs included diffusion terms with uncertainty, and the inclusion of fuzzy logic operations further increases the system’s complexity. We propose a new concept called the average control width (ACW) for aperiodic semi-intermittent control (ASIC) systems; it is used in conjunction with the idea of average dwell time (ADT) for switched systems. A sufficient flexible condition for master–slave synchronization of neural networks using average-width semi-intermittent hybrid control assures ADT and ACW conditions. By utilizing these concepts, the proposed synchronization method can overcome the challenges posed by the diffusion terms and fuzzy logic operations in FRDNNs with time-varying transmission delays. Finally, the paper presents a theoretical framework for synchronizing FRDNNs with time-varying transmission delays using semi-intermittent hybrid control via LMI and suitable Lyapunov functional, validated through simulations. The proposed synchronization method is also applied to develop a novel chaos-based elliptic curve cryptography algorithm for medical image encryption.},
  archive      = {J_JAMC},
  author       = {Kathiresan, S. and Kashkynbayev, Ardak and Mohanrasu, S. S. and Rajan, Rakkiyappan},
  doi          = {10.1007/s12190-024-02234-w},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1109-1139},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Synchronization of fuzzy reaction–diffusion neural networks via semi-intermittent hybrid control},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parameter uniform orthogonal spline collocation method for
time delay singularly perturbed semilinear reaction–diffusion problems.
<em>JAMC</em>, <em>71</em>(1), 1077–1107. (<a
href="https://doi.org/10.1007/s12190-024-02253-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of singularly perturbed semilinear time-dependent problems with a delay term in time is considered. A numerical approach is formulated and analysed to unravel the complexity for such problems due to the presence of a small perturbation parameter and a semilinear term simultaneously. We use Shishkin mesh to capture the boundary layer. We estimate errors in the energy and balanced norms occurred in orthogonal spline collocation discretization for the spatial direction. For the full discretization an extrapolated Crank–Nicolson formula is used in time direction. Some numerical results are presented to confirm the effectiveness of the method. The computed convergence corroborated the predicted theory in different norms.},
  archive      = {J_JAMC},
  author       = {Howlader, Jewel and Mishra, Pankaj and Sharma, Kapil K.},
  doi          = {10.1007/s12190-024-02253-7},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1077-1107},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {A parameter uniform orthogonal spline collocation method for time delay singularly perturbed semilinear reaction–diffusion problems},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel supply chain decision making model under m-polar
quadripartitioned neutrosophic environment. <em>JAMC</em>,
<em>71</em>(1), 1051–1076. (<a
href="https://doi.org/10.1007/s12190-024-02256-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current state of the universe is shifting towards multi-polarity, a well-established phenomenon that plays a crucial role across various scientific and technological fields, particularly in information and data domains. In this study, we propose the concept of m-polar quadripartitioned neutrosophic sets and explore their graphical representations, presenting key findings. We introduce novel operations on m-polar quadripartitioned neutrosophic graphs, such as the strong product and direct product. Additionally, we discuss concepts like complement, homomorphism, isomorphism, weak and co-weak isomorphism within the context of m-polar neutrosophic graphs. Furthermore, we elucidate several associated properties and theorems concerning m-polar quadripartitioned neutrosophic graphs. Finally, we demonstrate the practical application of our findings in a supply chain management model.},
  archive      = {J_JAMC},
  author       = {Satham Hussain, S. and Nagarajan, Durga and Rashmanlou, Hossein and Mofidnakhaei, Farshid},
  doi          = {10.1007/s12190-024-02256-4},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1051-1076},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Novel supply chain decision making model under m-polar quadripartitioned neutrosophic environment},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On trees of a fixed maximum degree with extremal general
atom-bond sum-connectivity index. <em>JAMC</em>, <em>71</em>(1),
1035–1049. (<a
href="https://doi.org/10.1007/s12190-024-02275-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider general atom-bond sum-connectivity indices $$\mathcal {ABS}_{\ell }$$ for $$1/2 \le \ell \le 1$$ and study their values over all trees on a given number of vertices with a fixed maximum degree $$\Delta $$ . We obtain both the minimum and the maximum values and characterize the corresponding trees. The obtained results recover previously known results for the atom-bond sum-connectivity index and imply analogous results for the well-known harmonic index. The results remain valid when the class of considered graphs is restricted to the class of molecular trees.},
  archive      = {J_JAMC},
  author       = {Ali, Akbar and Došlić, Tomislav and Raza, Zahid},
  doi          = {10.1007/s12190-024-02275-1},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1035-1049},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {On trees of a fixed maximum degree with extremal general atom-bond sum-connectivity index},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical simulations of rosenau–burgers equations via
crank–nicolson spectral pell matrix algorithm. <em>JAMC</em>,
<em>71</em>(1), 1009–1033. (<a
href="https://doi.org/10.1007/s12190-024-02273-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current work addresses the use of the numerical Crank–Nicolson technique along with spectral collocation to seek the approximate solution of a class of high-order nonlinear partial differential equations known as the Rosenau–Burgers equation. First, the Crank–Nicolson approach is applied to reduce the Rosenau–Burgers equation to a set of linear equations. The solvability and uniqueness of the semi-discretized form is established. Then, the spectral based collocation method by using the Pell functions is employed to approximate the derived system of linearized equations in terms of unknown coefficients. The theoretical part and error analysis are comprehensively studied in the weighted $$L^2$$ -norm. Finally, four illustrative test cases are conducted to showcase the efficiency of the suggested combined technique. The results are well compared with existing results and exact solutions in the literature to demonstrate the advantages of the applied novel approach.},
  archive      = {J_JAMC},
  author       = {Izadi, Mohammad and Srivastava, Hari Mohan and Mamehrashi, Kamal},
  doi          = {10.1007/s12190-024-02273-3},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1009-1033},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Numerical simulations of Rosenau–Burgers equations via Crank–Nicolson spectral pell matrix algorithm},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach to determine the sombor-type indices via
m-polynomial. <em>JAMC</em>, <em>71</em>(1), 983–1007. (<a
href="https://doi.org/10.1007/s12190-024-02272-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological indices can be interpreted as the mathematical characterizations of a molecular compound and are significantly employed to forecast its physical, chemical and biological information. Computation of topological indices of a graph through its associated graph polynomial is a modern and optimal approach. One such method is to determine the degree-based topological indices of a graph using its M-polynomial. Among the class of degree-based topological indices, the Sombor indices are one of the most investigated indices in recent times. In this article, the M-polynomial-based derivation formulas are derived to compute the different Sombor-type indices, namely the Sombor index, modified Sombor index, first and second Banhatti–Sombor indices, and their reduced form of the Sombor indices. Furthermore, our proposed derivation formulas are applied to compute the Sombor-type indices of the jagged-rectangle benzenoid system $$B_{m,n}$$ . Additionally, the comparison among the Sombor-type indices of $$B_{m,n}$$ is presented through numerical and graphical representations.},
  archive      = {J_JAMC},
  author       = {Kumar, Virendra and Das, Shibsankar},
  doi          = {10.1007/s12190-024-02272-4},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {983-1007},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {A novel approach to determine the sombor-type indices via M-polynomial},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vulnerability assessment of a new class of cayley graph.
<em>JAMC</em>, <em>71</em>(1), 969–982. (<a
href="https://doi.org/10.1007/s12190-024-02270-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the number of links and processors in an interconnection network increases, faulty links and processors are constantly emerging. When a network fails, how to evaluate the state of the network and mitigate the vulnerability of the network itself is the focus of attention in recent years. Therefore, the parameters for assessing network vulnerability have received considerable attention. In general, we use connectivity and diagnosability to reflect the vulnerability of the network. At present, the connectivity and diagnosability of most networks have been determined. In this paper, we mainly analyze Cayley graphs $$EC_m$$ , which are generated by disjoint paths with length 2. We explain that connectivity and super connectivity of $$EC_m$$ are uniformly 2m, the 1-extra and 3-component connectivity of $$EC_m$$ are uniformly $$4m-2$$ . In addition, we also analyze the local diagnosability of $$EC_m$$ under the PMC and $$\hbox {MM}^*$$ models is 2m.},
  archive      = {J_JAMC},
  author       = {Zhang, Hong and Bian, Hong},
  doi          = {10.1007/s12190-024-02270-6},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {969-982},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Vulnerability assessment of a new class of cayley graph},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the zero-divisor graph over commutative ring:
Topological examine of algebraic structure. <em>JAMC</em>,
<em>71</em>(1), 945–967. (<a
href="https://doi.org/10.1007/s12190-024-02260-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A commutative ring over a graph was first studied by Beck in 1988. The properties of zero-divisor graphs of commutative and non-commutative rings were then studied extensively. The commutative ring over graph is also widely used in robotics, communication theory, and elliptic curve cryptography. In this paper, we derive a few degree-based topological expressions namely, the first Zagreb index and the forgotten index of zero-divisor graphs of $${\mathbb {Z}}_p^n$$ , $${\mathbb {Z}}_q\times {\mathbb {Z}}_p^n$$ and $${\mathbb {Z}}_{q^2}\times {\mathbb {Z}}_p^n$$ where p and q are primes. The numerical expression of the zero-divisor graphs is analysed and compared the indices graphically and numerically.},
  archive      = {J_JAMC},
  author       = {Akhila, S. and Al-Shamiri, Mohammed M. Ali and Alsinai, Ammar and Xavier, D. Antony},
  doi          = {10.1007/s12190-024-02260-8},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {945-967},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Exploring the zero-divisor graph over commutative ring: Topological examine of algebraic structure},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The multiplicity of radial p-k-convex solutions for the
p-k-hessian equation. <em>JAMC</em>, <em>71</em>(1), 927–943. (<a
href="https://doi.org/10.1007/s12190-024-02262-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on radial p-k-convex solutions for the following p-k-Hessian equation $$\begin{aligned} \left\{ \begin{array}{ll} S_{k}(\xi (D_{i}(|Dv|^{p-2}D_{j}v)))=M(|z|){(|v|+1)}^{m}(ln (|v|+1))^{\mu }, z\in E,\\ v=+\infty , ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~z\in \partial E, \end{array} \right. \end{aligned}$$ where $$p\ge 2$$ , $$k\in \{1,2,...,n\}$$ , $$E\subset \mathbb {R}^{n}(n\ge 2)$$ denotes a ball. For the case of $$0&lt;m&lt;(p-1)k$$ , $$\mu =0$$ , the multiplicity of radial p-k-convex solutions of the above p-k-Hessian equation is established by the sub-supersolutions method. For the case of $$m=(p-1)k$$ , $$\mu &gt;(p-1)k$$ , we construct a new supporting function to overcome the difficulty caused by logarithmic nonlinearity, which ensures that the above p-k-Hessian equation has infinitely many radial p-k-convex solutions.}},
  archive      = {J_JAMC},
  author       = {Wang, Guotao and Guo, Mengjie},
  doi          = {10.1007/s12190-024-02262-6},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {927-943},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {The multiplicity of radial p-k-convex solutions for the p-k-hessian equation},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modelling and analysis of a fractional-order epidemic model
incorporating genetic algorithm-based optimization. <em>JAMC</em>,
<em>71</em>(1), 901–925. (<a
href="https://doi.org/10.1007/s12190-024-02224-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infectious diseases have always been a threat to the smooth running of our daily activities. To regulate the disease’s devastating outcome, we have performed a qualitative study of infectious disease using an SIR model. While formulating the model, we have taken into account the saturated incidence function with three controls, namely, treatment control, vaccination control, and media awareness. To make the model more robust, we have updated the model using Caputo fractional-order differential equation. We have determined the existence and uniqueness of the solution along with all possible equilibrium points. We have also obtained the basic reproduction number and the criteria of asymptotic local and global stability, taking the basic reproduction number as the threshold parameter. Finally, to control the disease, we have performed the optimization using a metaheuristic search and optimization technique, genetic algorithm (GA).},
  archive      = {J_JAMC},
  author       = {Adak, Sayani and Barman, Snehasis and Jana, Soovoojeet and Majee, Suvankar and Kar, T. K.},
  doi          = {10.1007/s12190-024-02224-y},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {901-925},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Modelling and analysis of a fractional-order epidemic model incorporating genetic algorithm-based optimization},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overlapping containment rough neighborhoods and their
generalized approximation spaces with applications. <em>JAMC</em>,
<em>71</em>(1), 869–900. (<a
href="https://doi.org/10.1007/s12190-024-02261-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In rough set theory, we distinguish confirmed and possible data, extracted through subsets utilizing lower and upper approximations, respectively. Earlier studies have presented several rough approximation models, drawing inspiration from neighborhood systems, aimed at enhancing accuracy degree and satisfying the axioms of standard approximation space, introduced by Pawlak. In this article, we first introduce novel rough neighborhoods so-called overlapping containment rough neighborhoods, denoted by $$\widetilde{\textrm{C}}_k$$ -neighborhoods, using inclusion relations between $$\mathcal {D}_r$$ -neighborhoods and $$\mathcal {D}_l$$ -neighborhoods, as well as $$\mathcal {D}_{\langle r\rangle }$$ -neighborhoods and $$\mathcal {D}_{\langle l\rangle }$$ -neighborhoods, all defined under an arbitrary relation. We explore their main characterizations and reveal the relationships between them under specific types of binary relations, such as symmetric, transitive, and partial order relations. As a unique contribution, we successfully derive an indicator inspired by $$\widetilde{\textrm{C}}_k$$ -neighborhoods for $$k\in \{r,l,i\}$$ to determine whether a relation is symmetric. Additionally, we describe the behavior of $$\widetilde{\textrm{C}}_k$$ -neighborhoods as they navigate between two generalized approximation spaces, where the relations are reflexive and transitive, and one is a subset of the other. Then, we exploit $$\widetilde{\textrm{C}}_k$$ -neighborhoods to present fresh rough set models. We examine their main properties and demonstrate that they keep most characterizations of Pawlak’s paradigm while reducing the uncertainty in the data compared to some previous studies, also, we show that they satisfy the monstrosity property under quasi-order relations. To elucidate the superiority and accuracy of the present approach, we apply it to analyze the information systems related to the authorship of articles and books by selected authors and conduct a comparative analysis with several preceding approaches. Finally, a summary of the obtained results and relationships and suggestion for some forthcoming work are offered.},
  archive      = {J_JAMC},
  author       = {Al-shami, Tareq M. and Mhemdi, Abdelwaheb},
  doi          = {10.1007/s12190-024-02261-7},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {869-900},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Overlapping containment rough neighborhoods and their generalized approximation spaces with applications},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some basic mathematical properties of the misbalance hadeg
index of graphs. <em>JAMC</em>, <em>71</em>(1), 851–867. (<a
href="https://doi.org/10.1007/s12190-024-02250-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In 2010, Vukičević and Gašperov proposed a group of 148 discrete Adriatic indices which have represented good predictive characteristics on the testing sets conducted by the International Academy of Mathematical Chemistry (IAMC). One of such indices was the misbalance Hadeg ( $$\mathcal{M}\mathcal{H}$$ ) index which showed good ability in predicting the enthalpy of vaporization and standard enthalpy of vaporization for octane isomers. For a simple graph G with the edge set $$E_G$$ , the $$\mathcal{M}\mathcal{H}$$ index is expressed by $$\mathcal{M}\mathcal{H}(G)=\sum _{\alpha \beta \in E_G} \Big |\Big (\frac{1}{2}\Big )^{d^{G}_{\alpha }}-\Big (\frac{1}{2}\Big )^{d^{G}_{\beta }}\Big |$$ , where $$d^{G}_{\beta }$$ stands for the degree of the vertex $$\beta $$ in G. Despite passing almost 14 years since the introduction of the $$\mathcal{M}\mathcal{H}$$ index, it has been relatively less investigated and left into oblivion. A main purpose of this research is to attract the attention of the mathematical chemistry community towards this molecular structure descriptor by studying some of its basic mathematical properties over trees, molecular trees, unicyclic graphs, bicyclic graphs and, in general, over c-cyclic graphs. More specifically, we give the minimum values of the $$\mathcal{M}\mathcal{H}$$ index over trees, unicyclic graphs and bicyclic graphs of a given number of vertices and with a fixed maximum degree and characterize the corresponding minimal graphs. The special case when the class of considered trees is restricted to the class of molecular trees and the general case when the class of considered unicyclic and bicyclic graphs is extended to the class of c-cyclic graphs are also examined.},
  archive      = {J_JAMC},
  author       = {Azari, Mahdieh and Dehgardi, Nasrin},
  doi          = {10.1007/s12190-024-02250-w},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {851-867},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Some basic mathematical properties of the misbalance hadeg index of graphs},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical solution for third order singularly perturbed
turning point problems with integral boundary condition. <em>JAMC</em>,
<em>71</em>(1), 829–849. (<a
href="https://doi.org/10.1007/s12190-024-02266-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a third-order singularly perturbed differential equation with integral boundary condition (IBC) is considered. The problem is reduced into system of differential equation, one compromises initial value problem and another one is second order singularly perturbed differential equation with integral boundary condition. Due to the presence of turning point at $$r=0,$$ the problem exhibit boundary layer at $$r=-1$$ and $$r=1.$$ To tackle this type of problem, a thorough study is required to obtain a priori estimations on the solution and its derivatives of the considered problem. We present a numerical technique adopting an upwind finite difference scheme on a dense piece-wise uniform mesh at the boundary layers. The proposed method is almost first-order convergent. Some numerical examples are provided to validate the theoretical findings.},
  archive      = {J_JAMC},
  author       = {Raja, V. and Geetha, N. and Mahendran, R. and Senthilkumar, L. S.},
  doi          = {10.1007/s12190-024-02266-2},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {829-849},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Numerical solution for third order singularly perturbed turning point problems with integral boundary condition},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust dissipativity analysis for stochastic markov jump
competitive neural networks with mixed delays. <em>JAMC</em>,
<em>71</em>(1), 801–828. (<a
href="https://doi.org/10.1007/s12190-024-02257-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research addresses the critical issue of dissipativity in Markovian jump stochastic competitive neural networks, particularly focusing on the complex challenges posed by mixed time delays and parameter uncertainties. The primary objective of this study is to derive adequate conditions for dissipativity by constructing suitable Lyapunov–Krasovskii functionals (LKFs) that incorporates triple integral terms, thereby providing a rigorous mathematical framework for analysis. To achieve this, a generalized delay-dependent reciprocal convex inequality is employed, which enables us to effectively calculate the derivative of the LKFs and derive a linear matrix polynomial. Our findings extend the conventional dissipativity criteria to include passivity, which is articulated in terms of linear matrix inequalities (LMIs). This enhancement significantly simplifies the computational process and allows for practical implementation using standard numerical software. Further, Numerical examples demonstrate that the proposed strategy outperforms existing findings.},
  archive      = {J_JAMC},
  author       = {Subhashri, A. R. and Radhika, T.},
  doi          = {10.1007/s12190-024-02257-3},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {801-828},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Robust dissipativity analysis for stochastic markov jump competitive neural networks with mixed delays},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster approximate synchronization for probabilistic
asynchronous finite field networks. <em>JAMC</em>, <em>71</em>(1),
783–800. (<a href="https://doi.org/10.1007/s12190-024-02255-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we have established probabilistic asynchronous finite field networks (PAFFNs) and investigated the cluster approximate synchronization of it. Firstly, using the semi-tensor product, the dynamics of PAFFNs are transformed into algebraic form. Secondly, based on algebraic form, cluster approximate synchronization with probabilistic asynchronous update scheme is converted into the set stability of the probabilistic systems, and sufficient and necessary conditions of PAFFNs cluster approximate synchronization are obtained. Finally, an example is given to illustrate the correctness of theorems.},
  archive      = {J_JAMC},
  author       = {Zhang, Hao and Xu, Lunshi and Luo, Chao and Zhang, Chuan and Su, Xianghui},
  doi          = {10.1007/s12190-024-02255-5},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {783-800},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Cluster approximate synchronization for probabilistic asynchronous finite field networks},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new method for converting impulsive riemann–liouville
fractional order system into the integral equation. <em>JAMC</em>,
<em>71</em>(1), 765–782. (<a
href="https://doi.org/10.1007/s12190-024-02258-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For impulsive fractional order system (IFOS), its equivalent integral equation (EIE) is an important process tool for discussing the IFOS’s properties (such as existence of solution, numerical solution, stability and controllability etc). However, there appeared three incorrect EIEs for the same IFOS in existing papers due to misunderstandings about the segmented calculation for the fractional calculus of piecewise function. Hence, we re-study the EIEs of two impulsive Riemann–Liouville fractional order systems (IRFOSs) in this paper. For one IRFOS, we find the linear additivity of the impulsive effects by two limit properties, and construct the EIE for the IRFOS of one impulse by fractional order property of piecewise function, which derive the EIE’s structure of the IRFOS. Next, we apply the EIE’s structure of the IRFOS and a limit property to obtain the IRFOS’s EIE with an arbitrary constant and confirm the nonuniqueness of the IRFOS’s solution. And then, we combine the EIE of the IRFOS and the relation of two IRFOSs to deduce the EIE of the other IRFOS. Finally, we offer two numerical examples to show the computation of the EIEs and the nonuniqueness of the solutions for two IRFOSs.},
  archive      = {J_JAMC},
  author       = {Zhang, Xianmin},
  doi          = {10.1007/s12190-024-02258-2},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {765-782},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {A new method for converting impulsive Riemann–Liouville fractional order system into the integral equation},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical solution of nonlinear equations of traffic flow
density using spectral methods by filter. <em>JAMC</em>, <em>71</em>(1),
743–763. (<a href="https://doi.org/10.1007/s12190-024-02252-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an innovative approach that marries the spectral method with a time-dependent partial differential equation filter to tackle the phenomenon of shock waves in traffic flow modeling. Through the strategic application of Discrete low-pass filters, this method effectively mitigates shock-induced deviations, leading to significantly more accurate results compared to conventional spectral techniques. We conduct a thorough examination of the stability conditions inherent to this approach, providing valuable insights into its robustness. To substantiate its effectiveness, we present a series of numerical examples illustrating the method’s prowess in delivering precise solutions. Comparative analysis against established methods such as Lax and Cu reveals a marked superiority in accuracy. This work not only contributes a novel numerical technique to the field of traffic flow modeling but also addresses a persistent challenge, offering a promising avenue for further research and practical applications.},
  archive      = {J_JAMC},
  author       = {Najafi, Seyed Esmaeil Sadat and Allahviranloo, Tofigh and Abbasbandy, Saeid and Malkhalifeh, Mohsen Rostamy},
  doi          = {10.1007/s12190-024-02252-8},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {743-763},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Numerical solution of nonlinear equations of traffic flow density using spectral methods by filter},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wiener index of inverse fuzzy mixed graphs with application
in education system. <em>JAMC</em>, <em>71</em>(1), 725–742. (<a
href="https://doi.org/10.1007/s12190-024-02263-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of Wiener index has a wide range of application in chemical science and in network science. In this research article, the idea of connectivity index and Wiener index have been introduced in an inverse fuzzy mixed graph (IFMG) with the help of the idea of geodesic. Throughout the article, we have explored the Wiener index of various inverse fuzzy mixed graph structures. Most importantly the relation between connectivity index and inverse fuzzy mixed Wiener index (IFMWI) have been established. It has been shown that connectivity index is less than or equal to the IFMWI for an inverse fuzzy mixed tree containing at-least three vertices. The idea of IFMWI has been also discussed for the inverse fuzzy mixed cycles and investigated some of the important properties. At the end of our discussion, an application is presented to assess teaching and learning outcomes based on specific parameters.},
  archive      = {J_JAMC},
  author       = {Mondal, Rahul and Ghorai, Ganesh},
  doi          = {10.1007/s12190-024-02263-5},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {725-742},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Wiener index of inverse fuzzy mixed graphs with application in education system},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effective nonmonotone trust region method based on a simple
cubic model for unconstrained optimization problems. <em>JAMC</em>,
<em>71</em>(1), 707–723. (<a
href="https://doi.org/10.1007/s12190-024-02241-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we introduce a new nonmonotone trust region method with a simple cubic model to solve the unconstrained optimization problems (UCM). We improved the adaptive cubic regularization method by using a real positive definite scalar matrix instead of the exact Hessian and combining it with the nonmonotone technique. In addition, under some proper assumptions, the global convergence of the introduced method is established. Numerical tests on a set of standard minimization problems are reported and show that the proposed algorithm is efficient and robust compared to the other given methods.},
  archive      = {J_JAMC},
  author       = {Niri, T. Dehghan and Amini, K.},
  doi          = {10.1007/s12190-024-02241-x},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {707-723},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Effective nonmonotone trust region method based on a simple cubic model for unconstrained optimization problems},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability and hopf bifurcation analysis of a networked SIR
epidemic model with two delays. <em>JAMC</em>, <em>71</em>(1), 669–706.
(<a href="https://doi.org/10.1007/s12190-024-02240-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Population migration within spatial structures significantly influences disease spread. Given the typically uneven environment, individuals randomly interact with various others, facilitating disease transmission over time. Complex networks are integrated into infectious disease models and effectively capture these contact dynamics. In this paper, we propose a two-delay networked SIR epidemic model featuring a Crowley-Martin type incidence rate and Holling III type treatment rate. The stability of three equilibria of the model is proved by analyzing the distribution of characteristic roots. When two delays change at the same time, the stable region of the equilibrium on delays plane and the existence of Hopf bifurcation are obtained by the method of stability switching curves. Furthermore, we calculate the normal form of Hopf bifurcation to obtain the direction of Hopf bifurcation and the stability of bifurcation periodic solutions. Finally, numerical simulation on a small-world Watts-Strogatz network is performed to illustrate the theoretical results.},
  archive      = {J_JAMC},
  author       = {Zhou, Shumin and Dai, Yunxian and Wang, Hongyan},
  doi          = {10.1007/s12190-024-02240-y},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {669-706},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Stability and hopf bifurcation analysis of a networked SIR epidemic model with two delays},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel optimal fourth-order iteration scheme for solving
nonlinear problems in applied sciences. <em>JAMC</em>, <em>71</em>(1),
643–667. (<a href="https://doi.org/10.1007/s12190-024-02259-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous real life models in applied sciences and engineering commonly deal with nonlinear equations that have to be solved using reliable numerical methods. The computational science research is continuously growing, which is a marked by either introduction of new iteration algorithms or improvement of the existing ones. Nevertheless, these numerical methods may have high computational cost, but they do have a faster rate of convergence. Hence, the aim of this paper is create new two-step fourth order iteration algorithms for finding simple roots of nonlinear equations. To achieve this goal we have taken Steffensen’s method in the first sub-step and a general quadratic interpolation polynomial in the second sub-step of a two-step iterative scheme. The main theorem demonstrates the fourth-order convergence of the proposed scheme. The proposed scheme is derivative free and achieves optimal fourth order convergence by using only three function evaluations per iteration satisfying the conjecture of Kung and Traub. To validate the theoretical results and to demonstrate the effectiveness of the presented methods, we explore some nonlinear models in medical sciences such as the law of blood flow, blood rheology, fluid permeability in biogels, and thermal regulation of the human body. The numerical results of the proposed scheme are presented in terms of number of iterations, errors in consecutive iterations, computational convergence order (CCO) and CPU time (sec). Several researchers have investigated basins of attraction on simple polynomials of the form $$z^n-1$$ in the complex plan. However, we have studied the fractal behavior of different methods on real world problems stated above in terms of basins of attraction for comparison of their convergence regions. The proposed scheme generate the basins of attraction in less time with wider regions of convergence in comparison with the existing methods of similar kind. Dynamical analysis of the proposed derivative free scheme illustrate its superiority in comparison with some existing optimal fourth order methods involving derivatives.},
  archive      = {J_JAMC},
  author       = {Kumar, Sunil and Ishwariya, R. and Junjua, Moin-ud-Din and Akram, Saima},
  doi          = {10.1007/s12190-024-02259-1},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {643-667},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {A novel optimal fourth-order iteration scheme for solving nonlinear problems in applied sciences},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer-based impulsive control for finite-time
synchronization of delayed neural networks on time scales.
<em>JAMC</em>, <em>71</em>(1), 627–642. (<a
href="https://doi.org/10.1007/s12190-024-02268-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the finite-time synchronization (FTS) of delayed neural networks on time scales via impulsive control. First, an impulsive controller is designed when system states are accessible. Based on the time scale theory and mathematical induction method, a sufficient condition for FTS is presented. Then, an observer is provided to estimate system states when partial states can not be available. An observer-based impulsive controller is devised to ensure that both the observer error system and the synchronization error system converges to zero in finite time. Furthermore, the explicit expression for settling time of the FTS is given. Finally, the validity of our methods is verified by a numerical simulation.},
  archive      = {J_JAMC},
  author       = {Zhang, Chuan and Liu, Ruihong and Zhang, Xianfu and Guo, Yingxin},
  doi          = {10.1007/s12190-024-02268-0},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {627-642},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Observer-based impulsive control for finite-time synchronization of delayed neural networks on time scales},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mathematical modeling of zika virus with vertical
transmission in the presence of wolbachia-infected mosquitoes.
<em>JAMC</em>, <em>71</em>(1), 605–625. (<a
href="https://doi.org/10.1007/s12190-024-02236-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Zika virus, a notorious flavivirus, infiltrates human populations via infected Aedes mosquitoes or sexual transmission, often resulting in devastating birth defects like microcephaly. Our study delves into Zika’s transmission dynamics, revealing the role of Wolbachia-infected mosquitoes and the impact of asymptomatic carriers. Central factors such as mosquito mortality rates and transmission dynamics steer Zika’s trajectory. Meticulous simulations show Wolbachia-infected mosquitoes effectively reducing new cases. Navigating through scenarios of pregnancy delays, we seamlessly integrate them into our mathematical tapestry, enhancing our understanding of Zika’s dynamics. While postponing conception holds promise in mitigating microcephaly, its impact on overall transmission remains marginal, a sobering reality amidst progress. Embracing a unified approach, combining Wolbachia-infected mosquitoes and personal protective measures, we forge a formidable defense against Zika’s onslaught. As the specters of microcephaly and Zika recede, our quest for solutions offers a glimmer of hope in the battle against this formidable adversary.},
  archive      = {J_JAMC},
  author       = {Jamal, Muhammad and Batool, Sadia and Ahmed, Iftikhar and Azhar, Ehtsham and Nawaz, Tayyab},
  doi          = {10.1007/s12190-024-02236-8},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {605-625},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Mathematical modeling of zika virus with vertical transmission in the presence of wolbachia-infected mosquitoes},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deterministic SAIR model with vaccination and treatment:
Dynamical behaviors and control strategies. <em>JAMC</em>,
<em>71</em>(1), 573–604. (<a
href="https://doi.org/10.1007/s12190-024-02238-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to provide valuable information for the timely design and determination of public health measures during epidemic outbreaks, a deterministic SAIR model with vaccination programs and saturated treatment is established in this paper, as they have been demonstrated to be effective ways to change the evolution and prevent the spread of infectious diseases. The dynamical behaviors of the proposed model is analyzed theoretically and numerically. It is found that multiple endemic equilibria occur under certain conditions, suggesting that decreasing the basic reproduction number $$\mathcal {R}_0$$ is insufficient for disease eradication and improving the efficiency of vaccination and treatment can have a significant impact on disease progression. Furthermore, sensitivity analysis is conducted to quantify how changes in concerned parameters impact $$\mathcal {R}_0$$ , and the proposed model is applied to the pandemic wave of COVID-19. Finally, optimal control problem with time-varying vaccination and treatment is studied and cost-effectiveness analysis is examined under different scenarios.},
  archive      = {J_JAMC},
  author       = {Ouyang, Yun and Zhang, Suxia and Xu, Jinhu},
  doi          = {10.1007/s12190-024-02238-6},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {573-604},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {A deterministic SAIR model with vaccination and treatment: Dynamical behaviors and control strategies},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A projected hybridization of the hestenes–stiefel and
dai–yuan conjugate gradient methods with application to nonnegative
matrix factorization. <em>JAMC</em>, <em>71</em>(1), 551–571. (<a
href="https://doi.org/10.1007/s12190-024-02245-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid conjugate gradient methods are considered as an efficient family of conjugate gradient methods to solve unconstrained optimization problems. In this work, based on the memoryless BFGS update, a convex hybridization of the Hestenes–Stiefel and Dai–Yuan conjugate parameters is presented. To put in place safeguards to protect the sufficient descent property, the given search direction is projected to the orthogonal subspace to the gradient of the objective function. The convergence analysis of the proposed method is addressed under standard assumptions for general functions. The practical merits of the proposed method are computationally demonstrated on a set of CUTEr test functions as well as the well-known nonnegative matrix factorization problem.},
  archive      = {J_JAMC},
  author       = {Khoshsimaye-Bargard, Maryam and Ashrafi, Ali},
  doi          = {10.1007/s12190-024-02245-7},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {551-571},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {A projected hybridization of the Hestenes–Stiefel and Dai–Yuan conjugate gradient methods with application to nonnegative matrix factorization},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On computational analysis via fibonacci wavelet method for
investigating some physical problems. <em>JAMC</em>, <em>71</em>(1),
531–550. (<a href="https://doi.org/10.1007/s12190-024-02251-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we considered wavelet analysis and the application of the Fibonacci wavelet collocation method (FWCM) for solving partial differential equations (PDEs). The proposed technique starts with formulating Fibonacci wavelets using Fibonacci polynomials. Subsequently, the spectral collocation technique is applied to convert the given problem into a system of algebraic equations, which are then solved using the Newton method. Error estimation and convergence analysis of the proposed scheme are also investigated. The effectiveness and precision of the FWCM are demonstrated through a comparative analysis with exact solutions and other existing methods in the literature. The obtained results demonstrate that the proposed technique is an efficient tool for solving PDEs and is also applicable for numerically examining similar types of physical problems.},
  archive      = {J_JAMC},
  author       = {Ahmed, Shahid and Jahan, Shah and Shah, Kamal and Abdeljawad, Thabet},
  doi          = {10.1007/s12190-024-02251-9},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {531-550},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {On computational analysis via fibonacci wavelet method for investigating some physical problems},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laplace transform method for a coupled system of (p,
q)-caputo fractional differential equations. <em>JAMC</em>,
<em>71</em>(1), 511–530. (<a
href="https://doi.org/10.1007/s12190-024-02254-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research uses the Laplace transform method to analyze a coupled system of (p, q)-Caputo fractional differential equations, employing the (p, q)-generalized Caputo derivative. This system includes a function with a Volterra integral operator and integral kernel. By applying the Laplace transform method, we transform the differential equations into algebraic equations in the Laplace domain, which facilitates a systematic analysis of the system’s dynamics and stability properties. Furthermore, we examine the existence and uniqueness of solutions with initial conditions using Shaefer’s fixed point theorem and the Banach fixed point theorem in Banach space. Additionally, we explore the stability of the relevant solutions of the Ulam–Hyers (UH) type. An illustrative example will be presented to demonstrate the theoretical findings.},
  archive      = {J_JAMC},
  author       = {Baihi, Asmaa and Kajouni, Ahmed and Hilal, Khalid and Lmou, Hamid},
  doi          = {10.1007/s12190-024-02254-6},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {511-530},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Laplace transform method for a coupled system of (p, q)-caputo fractional differential equations},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic behaviors for fractional epidemiological model
featuring vaccination and quarantine compartments. <em>JAMC</em>,
<em>71</em>(1), 489–509. (<a
href="https://doi.org/10.1007/s12190-024-02249-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans have been affected by various epidemic diseases, mostly are airborne and exhibit high transmission rates. Given these nature properties, quarantine measures are essential to control the spread of the diseases effectively. Motivated by this fact, and due to the successful use of mathematical modeling, we investigate a SIR model with quarantine and vaccination compartments. This model uses a system of fractional differential equations (SIQVR-based) with specific parameters to track the dynamics of model variables. We examine the well-posedness and boundedness results via standard tools. An effective threshold parameter $$\mathcal {R}_0$$ is determined using a generation matrix and equilibrium points of the model are obtained. To effectively manage the transmission of infection within the outlined model, we employ the strategy of optimal control. This approach involves implementing control measures and interventions guided by mathematical optimization techniques to minimize the spread of disease. These control strategies may encompass vaccination campaigns, quarantine protocols, social distancing measures and other preventive actions. Further, to evaluate the effectiveness of proposed model and the applied optimal control strategy, we conduct a series of numerical simulations. Computational results involve running the model under different scenarios, considering a range of parameters and meticulously analyzing the resulting outcomes.},
  archive      = {J_JAMC},
  author       = {Hariharan, S. and Shangerganesh, L. and Debbouche, A. and Antonov, V.},
  doi          = {10.1007/s12190-024-02249-3},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {489-509},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Dynamic behaviors for fractional epidemiological model featuring vaccination and quarantine compartments},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-step projected forward–backward algorithms for
constrained minimization problem. <em>JAMC</em>, <em>71</em>(1),
465–487. (<a href="https://doi.org/10.1007/s12190-024-02248-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design new projective forward–backward algorithms for constrained minimization problems. We then discuss its weak convergence via a new linesearch that the hypothesis on the Lipschitz constant of the gradient of functions is avoided. We provide its applications to solve image deblurring and image inpainting. Finally, we discuss the optimal selection of parameters that are proposed in algorithms in terms of PSNR and SSIM. It reveals that our new algorithm outperforms some recent methods introduced in the literature.},
  archive      = {J_JAMC},
  author       = {Kankam, Kunrada and Noor, Muhammad Aslam and Cholamjiak, Prasit},
  doi          = {10.1007/s12190-024-02248-4},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {465-487},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Three-step projected forward–backward algorithms for constrained minimization problem},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the rule of trajectory structure for a third-order
nonlinear difference equation using semi-cycle analysis method.
<em>JAMC</em>, <em>71</em>(1), 453–463. (<a
href="https://doi.org/10.1007/s12190-024-02247-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is concerned with the rule of trajectory structure and global asymptotical stability of the positive equilibrium for the following third-order nonlinear difference equation $$\begin{aligned} w_{m+1}=\frac{w_{m-1}^{\alpha }w_{m-2}+1+c}{w_{m-1}^{\alpha }+w_{m-2}+c},\ \ \ m\in N, \end{aligned}$$ where $$\alpha \in [0,1], c\in [0,\infty )$$ , the initial values $$w_{j}\in (0,\infty ), j=0,-1,-2.$$ By virtue of semi-cycle analysis method, the rules of trajectory structure are tested in prime period 7. The continuous length of positive and negative semi-cycles of any nontrivial solution appears periodically and the rule is $$3^{-},2^{+},1^{-},1^{+}$$ . Also, the positive equilibrium is globally asymptotically stable. Finally, two examples are given to show effectiveness of our theoretic analysis.},
  archive      = {J_JAMC},
  author       = {Shen, Liqin and Zhang, Qianhong},
  doi          = {10.1007/s12190-024-02247-5},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {453-463},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {On the rule of trajectory structure for a third-order nonlinear difference equation using semi-cycle analysis method},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a higher order fuzzy difference equation with a quadratic
term. <em>JAMC</em>, <em>71</em>(1), 429–452. (<a
href="https://doi.org/10.1007/s12190-024-02243-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A qualitative analysis of a second-order fuzzy difference equation featuring a quadratic term was recently explored in this journal. The study presented was limited to a second-order equation. Here, we generalize the study to a higher-order fuzzy difference equation with a quadratic component. Furthermore, we establish adequate conditions on the qualitative dynamics involving boundedness, persistence, and the convergence of positive fuzzy solutions to the equation. In addition, we provide two simulation instances to validate our theoretical examination.},
  archive      = {J_JAMC},
  author       = {Redjam, Ibtissem and Halim, Yacine and Fečkan, Michal},
  doi          = {10.1007/s12190-024-02243-9},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {429-452},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {On a higher order fuzzy difference equation with a quadratic term},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient numerical solution of linear fredholm
integro-differential equations via backward finite difference and
nyström methods. <em>JAMC</em>, <em>71</em>(1), 415–428. (<a
href="https://doi.org/10.1007/s12190-024-02246-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel numerical approach for solving linear Fredholm integro-differential equations. We integrate the backward finite difference method with the Nyström method to reduce the system size by half compared to the method proposed by Tair et al. (J. Appl. Math. Comput. Mech. 20(3):53-64, 2021). This reduction enhances computational efficiency and is particularly advantageous for large integration intervals. Our method ensures convergence by constructing a new norm for $$\mathbb {R}^{N+1}$$ . Numerical tests demonstrate the superiority of our method in terms of execution time and accuracy. The results contribute to the ongoing efforts in solving integro-differential equations more effectively, offering a robust tool for applications in various scientific and engineering domains.},
  archive      = {J_JAMC},
  author       = {Dida, Ridha and Guebbai, Hamza and Segni, Sami},
  doi          = {10.1007/s12190-024-02246-6},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {415-428},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Efficient numerical solution of linear fredholm integro-differential equations via backward finite difference and nyström methods},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stable higher-order numerical method for solving a system
of third-order singular emden-fowler type equations. <em>JAMC</em>,
<em>71</em>(1), 387–414. (<a
href="https://doi.org/10.1007/s12190-024-02233-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new higher-order numerical method based on a difference scheme with uniform steps to solve a strongly nonlinear system of third-order singular Emden-Fowler-type equations. These problems are challenging to solve because of their singularity or strong nonlinearity. To handle the singularity of the problem, we approximate the derivatives at the endpoints and develop a new difference scheme. This scheme provides a system of nonlinear equations solved by an iterative method. Also, we mathematically establish the method’s stability, consistency, and convergence analysis using a matrix analysis approach. We also verify the presented technique’s efficiency, accuracy and applicability by solving different examples from the literature. We also show that the theoretical order of the technique is consistent with the numerical convergence rates. Additionally, our method easily achieves higher-order accuracy with minimal grid points, unlike most methods that typically require modifying the equation into an equivalent integral equation or using L’Hospital’s rule to remove singularities, resulting in lower-order accuracy approaches.},
  archive      = {J_JAMC},
  author       = {Sahoo, Nirupam and Singh, Randhir},
  doi          = {10.1007/s12190-024-02233-x},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {387-414},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {A stable higher-order numerical method for solving a system of third-order singular emden-fowler type equations},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel global algorithm for solving linear multiplicative
problem by integrating linear combination rule and branch-and-bound
framework. <em>JAMC</em>, <em>71</em>(1), 365–386. (<a
href="https://doi.org/10.1007/s12190-024-02244-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel global algorithm to solve linear multiplicative problem (LMP) by integrating branch-and-bound framework with convex relaxation problem, linear combination rule and region reduction technique. Firstly, LMP is reformulated via D.C. form, and the reformulated LMP is converted into one of its equivalent problems. Secondly, a convex relaxation problem is constructed based on the characteristics of the equivalent problem and utilizing convex relaxation method. Thirdly, the linear combination rule and the region reduction technique are utilized to enhance efficiency of the algorithm and to reduce its computational time, respectively. Finally, numerical experiments validate that the new algorithm can solve LMP efficiently.},
  archive      = {J_JAMC},
  author       = {Zhang, Yanzhen and Shen, Peiping},
  doi          = {10.1007/s12190-024-02244-8},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {365-386},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {A novel global algorithm for solving linear multiplicative problem by integrating linear combination rule and branch-and-bound framework},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal error estimates of second-order semi-discrete
stabilized scheme for the incompressible MHD equations. <em>JAMC</em>,
<em>71</em>(1), 323–363. (<a
href="https://doi.org/10.1007/s12190-024-02242-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to construct optimal error estimates of second-order stabilized scheme for the incompressible magnetohydrodynamic(MHD) system. For this purpose, we first construct first- and second-order semi-discrete schemes in which the time derivative term is treated by the first-order backward Euler method and the second-order backward difference formulation, respectively. Moreover, the nonlinear terms are treated by semi-implicit method, and the coupling of velocity and pressure is decoupled by a Gauge–Uzawa method. Thus, the schemes achieve decoupling of velocity, magnetic field and pressure. Most importantly, the proposed schemes do not need to deal with the artificial boundary conditions on pressure and do not need to give an initial value of pressure. Then, the unconditional stability of the two schemes is demonstrated. Furthermore, through rigorous error analysis, we provide optimal convergence orders for all unknowns. Finally, some numerical experiments demonstrate the accuracy and effectiveness of the proposed schemes.},
  archive      = {J_JAMC},
  author       = {Wang, Zhaowei and Wang, Danxia and Zhang, Jun and Jia, Hongen},
  doi          = {10.1007/s12190-024-02242-w},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {323-363},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Optimal error estimates of second-order semi-discrete stabilized scheme for the incompressible MHD equations},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge resolvability of generalized honeycomb rhombic torus.
<em>JAMC</em>, <em>71</em>(1), 303–322. (<a
href="https://doi.org/10.1007/s12190-024-02231-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimum resolving sets (edge or vertex) have become integral to computer science, molecular topology, and combinatorial chemistry. Resolving sets for a specific network provide crucial information required for uniquely identifying each item in the network. The metric(respectively edge metric) dimension of a graph is the smallest number of the nodes needed to determine all other nodes (resp. edges) based on shortest path distances uniquely. Metric and edge metric dimensions as graph invariants have numerous applications, including robot navigation, pharmaceutical chemistry, canonically labeling graphs, and embedding symbolic data in low-dimensional Euclidean spaces. A honeycomb torus network can be obtained by joining pairs of nodes of degree two of the honeycomb mesh. Honeycomb torus has recently gained recognition as an attractive alternative to existing torus interconnection networks in parallel and distributed applications. In this article, we will discuss the Honeycomb Rhombic torus graph on the basis of edge metric dimension.},
  archive      = {J_JAMC},
  author       = {Kiran, Ayesha Andalib and Shaker, Hani and Saputro, Suhadi Wido},
  doi          = {10.1007/s12190-024-02231-z},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {303-322},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Edge resolvability of generalized honeycomb rhombic torus},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global stabilization and boundary control of coupled
fisher–stream equation and application to SIS–stream model.
<em>JAMC</em>, <em>71</em>(1), 279–302. (<a
href="https://doi.org/10.1007/s12190-024-02226-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the global stabilization of solutions to the initial-boundary value problem for the coupled model of the Fisher equation and Stream temperature equation (i.e., Fisher–Stream model) is studied. It is shown that under the non-homogeneous Dirichlet condition, the large time behavior of model analytical solutions is controlled by boundary conditions. Promoting to application, we establish similar conclusions in the coupled equation of the SIS model and Stream temperature equation.},
  archive      = {J_JAMC},
  author       = {Wang, Fang and Liu, Yuting and Chen, Yuxue},
  doi          = {10.1007/s12190-024-02226-w},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {279-302},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Global stabilization and boundary control of coupled Fisher–Stream equation and application to SIS–Stream model},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized rough approximation spaces inspired by
cardinality neighborhoods and ideals with application to dengue disease.
<em>JAMC</em>, <em>71</em>(1), 247–277. (<a
href="https://doi.org/10.1007/s12190-024-02235-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims to define four new kinds of rough set models based on cardinality neighborhoods and two ideals. The significance of these methods lies in their foundation on ideals, which serve as topological tools. Furthermore, the use of two ideals offers two perspectives instead of just one, thereby reducing the boundary region and increasing the accuracy, which is the primary objective of rough set theory. The concepts of lower and upper approximations based on ideals are presented for the four types. Additionally, we establish essential properties and results for these approximations and construct counterexamples to demonstrate how some of Pawlak’s properties have dissipated in the proposed models. The relationships between the current and previous approximations are discussed, and algorithms to classify whether a subset is exact or rough are introduced. Furthermore, we demonstrate how one combination of ideals is applied to address rough paradigms from a topological perspective. Practically, we apply the proposed paradigms to dengue disease management and elucidate two key points: first, our models are distinguished compared to previous ones by retaining most properties of the original approximation operators proposed by Pawlak; and second, we identify which of the proposed models is better at increasing the accuracy of subsets. In conclusion, we debate the advantages of the suggested models and the motivations behind each type, while also highlighting some of their shortcomings.},
  archive      = {J_JAMC},
  author       = {Al-shami, Tareq M. and Hosny, M. and Arar, Murad and Hosny, Rodyna A.},
  doi          = {10.1007/s12190-024-02235-9},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {247-277},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Generalized rough approximation spaces inspired by cardinality neighborhoods and ideals with application to dengue disease},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mathematical analysis for interacting multi functional
extreme learning machines. <em>JAMC</em>, <em>71</em>(1), 203–246. (<a
href="https://doi.org/10.1007/s12190-024-02225-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze interacting multi functional extreme learning machines by applying graph theory, groupoid theory, representation theory, operator theory, operator algebra theory and free probability.},
  archive      = {J_JAMC},
  author       = {Cho, Ilwoo and Jorgensen, Palle E. T.},
  doi          = {10.1007/s12190-024-02225-x},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {203-246},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Mathematical analysis for interacting multi functional extreme learning machines},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mathematical modeling and stability of SARS-CoV-2
transmission dynamics among domestic tourists in thailand.
<em>JAMC</em>, <em>71</em>(1), 173–202. (<a
href="https://doi.org/10.1007/s12190-024-02228-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The defined epidemiological model system explaining the spread of infectious diseases characterized with SARS-CoV-2 is analysed. The resulting SEIQR model is analysed in a closed system. It considers the basic reproductive value, the equilibrium point, local subclinical stability of the disease-free equilibrium point and local subclinical stability of the endemic equilibrium point. This is examined and the asymptotic dynamics of the appropriate model system are investigated. Further, a sensitivity analysis supplemented by simulations is prepared in advance to impose how changes in parameters involve the dynamic behaviours of the model.},
  archive      = {J_JAMC},
  author       = {Sungchasit, Rattiya and Pongsumpun, Puntani},
  doi          = {10.1007/s12190-024-02228-8},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {173-202},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Mathematical modeling and stability of SARS-CoV-2 transmission dynamics among domestic tourists in thailand},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-resolution numerical method for the time-fractional
fourth-order diffusion problems via improved quintic b-spline function.
<em>JAMC</em>, <em>71</em>(1), 133–171. (<a
href="https://doi.org/10.1007/s12190-024-02229-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we design and analyse a high-order numerical algorithm based on the improvised quintic B-spline collocation method for solving the fourth-order fractional diffusion equation. The time-fractional derivative is approximated by Caputo’s time derivative. The space derivative is approximated by the collocation method based on improvised quintic B-spline functions. It is shown that the proposed algorithm is unconditionally stable. Through rigorous convergence analysis, the method is shown $$(2-\beta )$$ order convergent in time and almost sixth-order convergent in space direction. It is also shown that the theoretical rate of convergence is the same as that acquired experimentally. To confirm the theoretical results and to test the efficiency and robustness, the method is tested on three problems. The main contribution of the developed algorithm is that the order of convergence and numerical results obtained are better than the existing methods, like the sextic B-spline collocation method (Roul and Goura in Appl Math Comput 366:124727, 2020), the quintic B-spline method (Siddiqi and Arshed in Int J Comput Math 92(7):1496–1518, 2015), and the quintic spline method (Tariq and Akram in Numer Methods Part Differ Equ 33(2):445–466, 2017). It has been proved that the order of convergence of the proposed method is six, which is two orders of magnitude higher than the other spline collocation methods.},
  archive      = {J_JAMC},
  author       = {Alam, Mohammad Prawesh and Khan, Arshad and Roul, Pradip},
  doi          = {10.1007/s12190-024-02229-7},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {133-171},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {High-resolution numerical method for the time-fractional fourth-order diffusion problems via improved quintic B-spline function},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extension of the subgradient extragradient algorithm for
solving variational inequalities without monotonicity. <em>JAMC</em>,
<em>71</em>(1), 103–131. (<a
href="https://doi.org/10.1007/s12190-024-02219-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two improved subgradient extragradient algorithms are proposed for solving nonmonotone variational inequalities under the nonempty assumption of the solution set of the dual variational inequalities. First, when the mapping is Lipschitz continuous, we propose an improved subgradient extragradient algorithm with self-adaptive step-size (ISEGS for short). In ISEGS, the next iteration point is obtained by projecting sequentially the current iteration point onto two different half-spaces, and only one projection onto the feasible set is required in the process of constructing the half-spaces per iteration. The self-adaptive technique allows us to determine the step-size without using the Lipschitz constant. Second, we extend our algorithm into the case where the mapping is merely continuous. The Armijo line search approach is used to handle the non-Lipschitz continuity of the mapping. The global convergence of both algorithms is established without monotonicity assumption of the mapping. The computational complexity of the two proposed algorithms is analyzed. Some numerical examples are given to show the efficiency of the new algorithms.},
  archive      = {J_JAMC},
  author       = {Chen, Jiaxin and Huang, Zunjie and Zhang, Yongle},
  doi          = {10.1007/s12190-024-02219-9},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {103-131},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Extension of the subgradient extragradient algorithm for solving variational inequalities without monotonicity},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). P,q-quasirung orthopair fuzzy multi-criteria group
decision-making algorithm based on generalized dombi aggregation
operators. <em>JAMC</em>, <em>71</em>(1), 69–102. (<a
href="https://doi.org/10.1007/s12190-024-02227-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The p,q-quasirung orthopair fuzzy (p,q-ROF) sets offer a superior approach to describing fuzzy and uncertain information compared to q-rung orthopair fuzzy sets. This paper first introduces generalized Dombi operational laws for p,q-ROF numbers. Utilizing these laws, we develop the p,q-ROF generalized Dombi weighted average (p,q-ROFGDWA) operator, the p,q-ROF generalized Dombi weighted geometric (p,q-ROFGDWG) operator, and their ordered weighted forms. We thoroughly examine the desirable properties and special cases of these new aggregation operators. Subsequently, we devise a multiple-criteria group decision-making method based on the p,q-ROFGDWA and p,q-ROFGDWG operators. Also an example regarding the selection of infectious medical waste treatment technology in Lahore, Pakistan is provided to exemplify the practicality and effectiveness of the developed model. The obtained results are then compared with other relevant methods, highlighting the efficacy and authenticity of the propound approach. Additionally, sensitivity analysis is performed to verify the suggested method’s stability. The findings indicate that the framed approach delivers robust and credible results for determining the ideal healthcare waste treatment technology.},
  archive      = {J_JAMC},
  author       = {Ali, Jawad and Mehmood, Zahid},
  doi          = {10.1007/s12190-024-02227-9},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {69-102},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {P,q-quasirung orthopair fuzzy multi-criteria group decision-making algorithm based on generalized dombi aggregation operators},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Different wave structures in water wave mechanics with two
conformable models. <em>JAMC</em>, <em>71</em>(1), 49–68. (<a
href="https://doi.org/10.1007/s12190-024-02222-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the exact wave solutions of the time-fractional modified Liouville equation (mLE) and time-fractional modified regularized long wave equation (mRLWE) which arise in water wave mechanics, via a new version of trial equation method (NVTEM). The present nonlinear models are reduced to nonlinear ordinary differential equations (NLODEs) by the traveling wave transform and the proposed solution by the NVTEM is used to evaluate the solutions of mLE and mRLWE. This analytical method is not applied before to these equations and novel wave solutions are acquired in the form of rational, exponential, hyperbolic, and Jacobi elliptic types. The solitary solutions of the equations under consideration make them essential models in shallow water dynamics, in liquids and gas bubbles, in magneto-hydrodynamics, and in plasma. This fact has become a motivation for this research.},
  archive      = {J_JAMC},
  author       = {Kırcı, Özlem and Pandır, Yusuf and Bulut, Hasan},
  doi          = {10.1007/s12190-024-02222-0},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {49-68},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Different wave structures in water wave mechanics with two conformable models},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the modulus-based methods without auxiliary variable for
vertical linear complementarity problems. <em>JAMC</em>, <em>71</em>(1),
31–48. (<a href="https://doi.org/10.1007/s12190-024-02218-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we conduct a further analysis of the modulus-based matrix splitting iteration method proposed in J-W He, S Vong. (Appl Math Lett 134: 108344, 2022) for vertical linear complementarity problems. Our study extends and enhances the existing theoretical theorems, which are also validated through numerical examples.},
  archive      = {J_JAMC},
  author       = {Zheng, Hua and Vong, Seakweng},
  doi          = {10.1007/s12190-024-02218-w},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {31-48},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {On the modulus-based methods without auxiliary variable for vertical linear complementarity problems},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Higher-order predictor–corrector methods for fractional
benjamin–bona–mahony–burgers’ equations. <em>JAMC</em>, <em>71</em>(1),
1–30. (<a href="https://doi.org/10.1007/s12190-024-02223-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we construct a higher order predictor–corrector technique for time fractional Benjamin–Bona–Mahony–Burgers’ equations. Instead of directly using an explicit scheme as the predictor in traditional predictor–corrector methods, we employ a new predictor scheme based on the author’s previous work ([24] https://doi.org/10.1007/s10910-024-01589-6 ), in which the given nonlinear equation is linearized by several linearization techniques and solved by Adams–Moulton scheme for the temporal direction and fourth order finite difference scheme for the spatial direction. Once the predictor solution is obtained, the higher order Adams–Moulton method is used as the corrector. Moreover, to make much higher order technique, a multiple correction technique is introduced by repeatedly correcting the results induced from the predictor. Numerical results demonstrate the efficiency of the proposed schemes.},
  archive      = {J_JAMC},
  author       = {Bu, Sunyoung and Jeon, Yonghyeon},
  doi          = {10.1007/s12190-024-02223-z},
  journal      = {Journal of Applied Mathematics and Computing},
  month        = {2},
  number       = {1},
  pages        = {1-30},
  shortjournal = {J. Appl. Math. Comput.},
  title        = {Higher-order predictor–corrector methods for fractional Benjamin–Bona–Mahony–Burgers’ equations},
  volume       = {71},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jar---8">JAR - 8</h2>
<ul>
<li><details>
<summary>
(2025). Use and abuse of instance parameters in the lean
mathematical library. <em>JAR</em>, <em>69</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s10817-024-09712-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Lean mathematical library Mathlib features extensive use of the typeclass pattern for organising mathematical structures, based on Lean’s mechanism of instance parameters. Related mechanisms for typeclasses are available in other provers including Agda, Coq and Isabelle with varying degrees of adoption. This paper analyses representative examples of design patterns involving instance parameters in the finalized Lean 3 version of Mathlib, focussing on complications arising at scale and how the Mathlib community deals with them.},
  archive      = {J_JAR},
  author       = {Baanen, Anne},
  doi          = {10.1007/s10817-024-09712-7},
  journal      = {Journal of Automated Reasoning},
  month        = {3},
  number       = {1},
  pages        = {1-30},
  shortjournal = {J. Auto. Reasoning},
  title        = {Use and abuse of instance parameters in the lean mathematical library},
  volume       = {69},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpolation and SAT-based model checking revisited:
Adoption to software verification. <em>JAR</em>, <em>69</em>(1), 1–29.
(<a href="https://doi.org/10.1007/s10817-024-09702-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The article Interpolation and SAT-Based Model Checking (McMillan in: Proc. CAV 2003, LNCS, Springer [56]) describes a formal-verification algorithm, which was originally devised to verify safety properties of finite-state transition systems. It derives interpolants from unsatisfiable BMC queries and collects them to construct an overapproximation of the set of reachable states. Although 20 years old, the algorithm is still state-of-the-art in hardware model checking. Unlike other formal-verification algorithms, such as or PDR, which have been extended to handle infinite-state systems and investigated for program analysis, McMillan’s interpolation-based model-checking algorithm from 2003 has not been used to verify programs so far. Our contribution is to close this significant, two decades old gap in knowledge by adopting the algorithm to software verification. We implemented it in the verification framework CPAchecker and evaluated the implementation against other state-of-the-art software-verification techniques on the largest publicly available benchmark suite of C safety-verification tasks. The evaluation demonstrates that McMillan’s interpolation-based model-checking algorithm from 2003 is competitive among other algorithms in terms of both the number of solved verification tasks and the run-time efficiency. Our results are important for the area of software verification, because researchers and developers now have one more approach to choose from.},
  archive      = {J_JAR},
  author       = {Beyer, Dirk and Lee, Nian-Ze and Wendler, Philipp},
  doi          = {10.1007/s10817-024-09702-9},
  journal      = {Journal of Automated Reasoning},
  month        = {3},
  number       = {1},
  pages        = {1-29},
  shortjournal = {J. Auto. Reasoning},
  title        = {Interpolation and SAT-based model checking revisited: Adoption to software verification},
  volume       = {69},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Satisfiability of non-linear transcendental arithmetic as a
certificate search problem. <em>JAR</em>, <em>69</em>(1), 1–35. (<a
href="https://doi.org/10.1007/s10817-024-09716-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For typical first-order logical theories, satisfying assignments have a straightforward finite representation that can directly serve as a certificate that a given assignment satisfies the given formula. For non-linear real arithmetic augmented with trigonometric and exponential functions ( $$\mathcal {N\hspace{-0.55542pt}T\hspace{-2.22214pt}A}$$ ), however, there is no known direct representation of satisfying assignments that allows for a simple independent check of whether the represented numbers exist and satisfy the given formula. Hence, in this paper, we introduce a different form of satisfiability certificate for $$\mathcal {N\hspace{-0.55542pt}T\hspace{-2.22214pt}A}$$ , and formulate the satisfiability problem as the problem of searching for such a certificate. This does not only ease the independent verification of satisfiability, but also allows the design of new algorithms that show satisfiability by systematically searching for such certificates. Computational experiments document that the resulting algorithms are able to prove satisfiability of a substantially higher number of benchmark problems than existing methods. We also characterize the formulas whose satisfiability can be demonstrated by such a certificate, by providing lower and upper bounds in terms of relevant well-known classes. Finally we show the existence of a procedure for checking the satisfiability of $$\mathcal {N\hspace{-0.55542pt}T\hspace{-2.22214pt}A}$$ -formulas that terminates for formulas that satisfy certain robustness assumptions.},
  archive      = {J_JAR},
  author       = {Lipparini, Enrico and Ratschan, Stefan},
  doi          = {10.1007/s10817-024-09716-3},
  journal      = {Journal of Automated Reasoning},
  month        = {3},
  number       = {1},
  pages        = {1-35},
  shortjournal = {J. Auto. Reasoning},
  title        = {Satisfiability of non-linear transcendental arithmetic as a certificate search problem},
  volume       = {69},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computer-assisted proofs for lyapunov stability via sums of
squares certificates and constructive analysis. <em>JAR</em>,
<em>69</em>(1), 1–33. (<a
href="https://doi.org/10.1007/s10817-024-09717-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a computer-assisted approach to ensure that a given discrete-time polynomial system is (asymptotically) stable. Our framework relies on constructive analysis together with formally certified sums of squares Lyapunov functions. The crucial steps are formalized within the proof assistant $$\texttt {Minlog}$$ . We illustrate our approach with an example issued from the control system literature.},
  archive      = {J_JAR},
  author       = {Devadze, Grigory and Magron, Victor and Streif, Stefan},
  doi          = {10.1007/s10817-024-09717-2},
  journal      = {Journal of Automated Reasoning},
  month        = {3},
  number       = {1},
  pages        = {1-33},
  shortjournal = {J. Auto. Reasoning},
  title        = {Computer-assisted proofs for lyapunov stability via sums of squares certificates and constructive analysis},
  volume       = {69},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Formalization of the prime number theorem with a remainder
term. <em>JAR</em>, <em>69</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s10817-025-09718-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes the formalization of the prime number theorem with a remainder term in the Isabelle/HOL proof assistant. First, we formalized several lemmas in complex analysis that were not available in the library, such as the Borel–Carathéodory theorem and the factorization of an analytic function on a compact region. Then, we use these results to formalize a zero-free region of the Riemann zeta function with an explicitly computed constant and deduce the asymptotic growth order of $$\zeta &#39;(s) / \zeta (s)$$ near $$\textrm{Re}(s) = 1$$ . Finally, using a specific form of Perron’s formula, we prove the prime number theorem with the classical remainder term, expressed in terms of $$\psi (x)$$ . We also formalized the result that the prime number theorem stated using $$\psi (x)$$ can imply the version stated using $$\pi (x)$$ . Thus, we can achieve the main result of this paper. Our work extensively utilizes the rich libraries of complex analysis and asymptotic analysis in Isabelle/HOL, including concepts such as the winding number, the residue theorem, and proof automation tools such as the tactic. This is why we chose Isabelle to formalize analytic number theory instead of using other interactive provers.},
  archive      = {J_JAR},
  author       = {Song, Shuhao and Yao, Bowen},
  doi          = {10.1007/s10817-025-09718-9},
  journal      = {Journal of Automated Reasoning},
  month        = {3},
  number       = {1},
  pages        = {1-23},
  shortjournal = {J. Auto. Reasoning},
  title        = {Formalization of the prime number theorem with a remainder term},
  volume       = {69},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Certified first-order AC-unification and
applications. <em>JAR</em>, <em>69</em>(1), 1. (<a
href="https://doi.org/10.1007/s10817-024-09715-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JAR},
  author       = {Ayala-Rincón, Mauricio and Fernández, Maribel and Ferreira Silva, Gabriel and Kutsia, Temur and Nantes-Sobrinho, Daniele},
  doi          = {10.1007/s10817-024-09715-4},
  journal      = {Journal of Automated Reasoning},
  month        = {3},
  number       = {1},
  pages        = {1},
  shortjournal = {J. Auto. Reasoning},
  title        = {Correction to: Certified first-order AC-unification and applications},
  volume       = {69},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast, verified computation for HOL ITPs. <em>JAR</em>,
<em>69</em>(1), 1–40. (<a
href="https://doi.org/10.1007/s10817-025-09719-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We add an efficient function for computation to the kernels of higher-order logic interactive theorem provers. First, we develop and prove sound our approach for Candle. Candle is a port of HOL Light which has been proved sound with respect to the inference rules of its higher-order logic; we extend its implementation and soundness proof. Second, we replicate our now-verified implementation for HOL4 with only minor changes, and build additional automation for ease of use. The automation exists outside of the HOL4 kernel, and requires no additional trust. We exercise our new computation function and associated automation on the evaluation of the CakeML compiler backend within HOL4’s logic, demonstrating an order of magnitude speedup. This is an extended version of our previous conference paper [2], which described implementation and soundness proofs for Candle. Our HOL4 implementation and automation are new, as are the CakeML benchmarks.},
  archive      = {J_JAR},
  author       = {Abrahamsson, Oskar and Myreen, Magnus O. and Norrish, Michael and Kanabar, Hrutvik and Pohjola, Johannes Åman},
  doi          = {10.1007/s10817-025-09719-8},
  journal      = {Journal of Automated Reasoning},
  month        = {3},
  number       = {1},
  pages        = {1-40},
  shortjournal = {J. Auto. Reasoning},
  title        = {Fast, verified computation for HOL ITPs},
  volume       = {69},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lessons for interactive theorem proving researchers from a
survey of coq users. <em>JAR</em>, <em>69</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10817-025-09720-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Coq Community Survey 2022 was an online public survey of users of the Coq proof assistant conducted during February 2022. Broadly, the survey asked about use of Coq features, user interfaces, libraries, plugins, and tools, views on renaming Coq and Coq improvements, and also demographic data such as education and experience with Coq and other proof assistants and programming languages. The survey received 466 submitted responses, making it the largest survey of users of an interactive theorem prover (ITP) so far. We present the design of the survey, a summary of key results, and analysis of answers relevant to ITP technology development and usage. In particular, we analyze user characteristics associated with adoption of tools and libraries and make comparisons to adjacent software communities. Notably, we find that experience has significant impact on Coq user behavior, including on usage of tools, libraries, and integrated development environments (IDEs).},
  archive      = {J_JAR},
  author       = {de Almeida Borges, Ana and Casanueva Artís, Annalí and Falleri, Jean-Rémy and Gallego Arias, Emilio Jesús and Martin-Dorel, Érik and Palmskog, Karl and Serebrenik, Alexander and Zimmermann, Théo},
  doi          = {10.1007/s10817-025-09720-1},
  journal      = {Journal of Automated Reasoning},
  month        = {3},
  number       = {1},
  pages        = {1-29},
  shortjournal = {J. Auto. Reasoning},
  title        = {Lessons for interactive theorem proving researchers from a survey of coq users},
  volume       = {69},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jgo---10">JGO - 10</h2>
<ul>
<li><details>
<summary>
(2025). On a tractable single-level reformulation of a multilevel
model of the european entry-exit gas market with market power.
<em>JGO</em>, <em>91</em>(4), 953–985. (<a
href="https://doi.org/10.1007/s10898-025-01475-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a framework that allows to quantitatively analyze the interplay of the different agents involved in gas trade and transport in the context of the European entry-exit system. Previous contributions have focused on the case of perfectly competitive buyers and sellers of gas, which allows to replace the respective market equilibrium problem by a single welfare maximization problem. Our novel framework considers the mathematically more challenging case of a monopolistic and thus strategic gas seller. In this framework, the objective functions of the gas sellers and buyers cannot be aggregated into a common objective function, which is why a multilevel formulation is necessary to accurately capture the sequential nature of the decisions taken. For this setup, we derive sufficient conditions that allow for reformulating the challenging four-level model as a computationally tractable single-level reformulation. We prove the correctness of this reformulation and use it for solving several test instances to illustrate the applicability of our approach.},
  archive      = {J_JGO},
  author       = {Grimm, Veronika and Grübel, Julia and Schmidt, Martin and Schwartz, Alexandra and Wiertz, Ann-Kathrin and Zöttl, Gregor},
  doi          = {10.1007/s10898-025-01475-8},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {953-985},
  shortjournal = {J. Glob. Optim.},
  title        = {On a tractable single-level reformulation of a multilevel model of the european entry-exit gas market with market power},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic red-blue set covering: A decomposition approach.
<em>JGO</em>, <em>91</em>(4), 923–951. (<a
href="https://doi.org/10.1007/s10898-025-01472-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents the two-stage stochastic red-blue set covering problem (2S-SRBSC). The red-blue set covering problem (RBSC) selects a subcollection of sets to cover all the blue elements while minimizing the number of red elements covered. Although RBSC has many application areas, such as classification and fraud detection, it does not capture randomness related to set membership and color uncertainty or any sense of recourse in response to the uncertainty. This work motivates these considerations via a fraud-prevention problem mortgage lenders face in practice. 2S-SRBSC is introduced to address this. In the proposed problem, uncertainty is represented via scenarios, and the decision-maker pays for sets in the first stage and has recourse to cover blue elements in the second stage that remain uncovered post-uncertainty. Different variants of 2S-SRBSC are considered, highlighting how they can model the real-life problem mortgage lenders face. In the case of 2S-SRBSC with simple recourse, a Benders decomposition (BD) and Benders dual decomposition (BDD) are presented and implemented in a commercial branch-and-cut solver. The resulting BDD subproblems yield cuts that are significantly tighter than those BD produces. The decompositions are tested and offer improvements in terms of solution quality and time for large-scale instances relative to the extensive form. Furthermore, the BDD exhibits desirable performance for instances where the commercial solver can quickly solve the mixed-binary subproblems. This work presents the first computational experience with decomposition algorithms applied to 2S-SRBSC problems.},
  archive      = {J_JGO},
  author       = {Islip, David and Kwon, Roy H.},
  doi          = {10.1007/s10898-025-01472-x},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {923-951},
  shortjournal = {J. Glob. Optim.},
  title        = {Stochastic red-blue set covering: A decomposition approach},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained optimization in simulation: Efficient global
optimization and karush-kuhn-tucker conditions. <em>JGO</em>,
<em>91</em>(4), 897–922. (<a
href="https://doi.org/10.1007/s10898-024-01448-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a novel methodology for solving constrained optimization problems in deterministic simulation. In these problems, the goal (or objective) output is to be minimized, subject to one or more constraints for the other outputs and for the inputs. Our methododology combines the“Karush-Kuhn-Tucker”(KKT) conditions with“efficient global optimization”(EGO).These KKT conditions are well-known first-order necessary optimality conditions in white-box mathematical optimization, but our method is the first EGO method that uses these conditions. EGO is a popular type of algorithm that is closely related to“Bayesian optimization” and“active machine learning”, as they all use Gaussian processes or Kriging to approximate the input/output behavior of black-box models. We numerically compare the performance of our KKT-EGO algorithm and two alternative EGO algorithms, in several popular examples. In some examples our algorithm converges faster to the true optimum, so our algorithm may provide a suitable alternative.},
  archive      = {J_JGO},
  author       = {Kleijnen, Jack P. C. and Angün, Ebru and van Nieuwenhuyse, Inneke and van Beers, Wim C. M.},
  doi          = {10.1007/s10898-024-01448-3},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {897-922},
  shortjournal = {J. Glob. Optim.},
  title        = {Constrained optimization in simulation: Efficient global optimization and karush-kuhn-tucker conditions},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System architecture optimization strategies: Dealing with
expensive hierarchical problems. <em>JGO</em>, <em>91</em>(4), 851–895.
(<a href="https://doi.org/10.1007/s10898-024-01443-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing the right system architecture for the problem at hand is challenging due to the large design space and high uncertainty in the early stage of the design process. Formulating the architecting process as an optimization problem may mitigate some of these challenges. This work investigates strategies for solving system architecture optimization (SAO) problems: expensive, black-box, hierarchical, mixed-discrete, constrained, multi-objective problems that may be subject to hidden constraints. Imputation ratio, correction ratio, correction fraction, and max rate diversity metrics are defined for characterizing hierarchical design spaces. This work considers two classes of optimization algorithms for SAO: multi-objective evolutionary algorithms such as NSGA-II, and Bayesian optimization (BO) algorithms. A new Gaussian process kernel is presented that enables modeling hierarchical categorical variables, extending previous work on modeling continuous and integer hierarchical variables. Next, a hierarchical sampling algorithm that uses design space hierarchy to group design vectors by active design variables is developed. Then, it is demonstrated that integrating more hierarchy information in the optimization algorithms yields better optimization results for BO algorithms. Several realistic single-objective and multi-objective test problems are used for investigations. Finally, the BO algorithm is applied to a jet engine architecture optimization problem. This work shows that the developed BO algorithm can effectively solve the problem with one order of magnitude less function evaluations than NSGA-II. The algorithms and problems used in this work are implemented in the open-source Python library SBArchOpt.},
  archive      = {J_JGO},
  author       = {Bussemaker, Jasper H. and Saves, Paul and Bartoli, Nathalie and Lefebvre, Thierry and Lafage, Rémi},
  doi          = {10.1007/s10898-024-01443-8},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {851-895},
  shortjournal = {J. Glob. Optim.},
  title        = {System architecture optimization strategies: Dealing with expensive hierarchical problems},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic golden ratio algorithm to non-convex stochastic
mixed variational inequality problem. <em>JGO</em>, <em>91</em>(4),
829–850. (<a href="https://doi.org/10.1007/s10898-024-01445-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In [Grad and Lara, J. Optim. Theory Appl. 190(2), 565–580 (2021)], the authors proposed a golden ratio algorithm for solving the deterministic mixed variational inequality problem with prox-convex function. In this paper, we study a new class of stochastic mixed variational inequality problems with the expectation of a prox-convex stochastic function and present a stochastic golden ratio algorithm for solving the proposed problem. The convergence and the convergence rate of our algorithm are shown under some simple and necessary conditions. Finally, we present some numerical examples to illustrate the efficiency of the proposed algorithm.},
  archive      = {J_JGO},
  author       = {Wang, Shenghua and Zhu, Ziqi and Yu, Lanxiang},
  doi          = {10.1007/s10898-024-01445-6},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {829-850},
  shortjournal = {J. Glob. Optim.},
  title        = {Stochastic golden ratio algorithm to non-convex stochastic mixed variational inequality problem},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximizing the smallest eigenvalue of grounded laplacian
matrix. <em>JGO</em>, <em>91</em>(4), 807–828. (<a
href="https://doi.org/10.1007/s10898-025-01470-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a connected graph $$\mathcal {G}=(V,E)$$ with n nodes, m edges, and Laplacian matrix $${\varvec{ L }}$$ , a grounded Laplacian matrix $${\varvec{ L }}(S)$$ of $$\mathcal {G}$$ is a $$(n-k) \times (n-k)$$ principal submatrix of $${\varvec{ L }}$$ , obtained from $${\varvec{ L }}$$ by deleting k rows and columns corresponding to k selected nodes forming a set $$S\subseteq V$$ . The smallest eigenvalue $$\lambda (S)$$ of $${\varvec{ L }}(S)$$ plays a pivotal role in various dynamics defined on $$\mathcal {G}$$ . For example, $$\lambda (S)$$ characterizes the convergence rate of leader-follower consensus, as well as the effectiveness of a pinning scheme for the pinning control problem, with larger $$\lambda (S)$$ corresponding to smaller convergence time or better effectiveness of a pinning scheme. In this paper, we focus on the problem of optimally selecting a subset S of fixed $$k \ll n$$ nodes, in order to maximize the smallest eigenvalue $$\lambda (S)$$ of the grounded Laplacian matrix $${\varvec{ L }}(S)$$ . We show that this optimization problem is NP-hard and that the objective function is non-submodular but monotone. Due to the difficulty of obtaining the optimal solution, we first propose a naïve heuristic algorithm selecting one optimal node at each time for k iterations. Then we propose a fast heuristic scalable algorithm to solve this problem, using the derivative matrix, matrix perturbations, and Laplacian solvers as tools. Our naïve heuristic algorithm takes $$\tilde{O}(knm)$$ time, while the fast greedy heuristic has a nearly linear time complexity of $$\tilde{O}(km)$$ , where $$\tilde{O}(\cdot )$$ notation suppresses the $$\textrm{poly} (\log n)$$ factors. We also conduct numerous experiments on different networks sized up to one million nodes, demonstrating the superiority of our algorithm in terms of efficiency and effectiveness compared to baseline methods.},
  archive      = {J_JGO},
  author       = {Zhou, Xiaotian and Wang, Run and Li, Wei and Zhang, Zhongzhi},
  doi          = {10.1007/s10898-025-01470-z},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {807-828},
  shortjournal = {J. Glob. Optim.},
  title        = {Maximizing the smallest eigenvalue of grounded laplacian matrix},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximations of unbounded convex projections and unbounded
convex sets. <em>JGO</em>, <em>91</em>(4), 787–805. (<a
href="https://doi.org/10.1007/s10898-024-01461-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of projecting a convex set onto a subspace or, equivalently formulated, the problem of computing a set obtained by applying a linear mapping to a convex feasible set. This includes the problem of approximating convex sets by polyhedrons. The existing literature on convex projections provides methods for bounded convex sets only, in this paper we propose a method that can handle both bounded and unbounded problems. The algorithms we propose build on the ideas of inner and outer approximation. In particular, we adapt the recently proposed methods for solving unbounded convex vector optimization problems to handle also the class of projection problems.},
  archive      = {J_JGO},
  author       = {Kováčová, Gabriela and Rudloff, Birgit},
  doi          = {10.1007/s10898-024-01461-6},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {787-805},
  shortjournal = {J. Glob. Optim.},
  title        = {Approximations of unbounded convex projections and unbounded convex sets},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applying augmented weak subdifferentials and normal cones
for nonconvex mathematical programming problems. <em>JGO</em>,
<em>91</em>(4), 765–786. (<a
href="https://doi.org/10.1007/s10898-025-01474-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper is devoted to the study of some necessary and sufficient optimality conditions for a nonconvex extended-real-valued function having a global minimum/and a vector-valued mapping having a weakly efficient solution at a given point in terms of the augmented weak subdifferentials and the augmented normal cones in reflexive Banach spaces without any convexity assumption. By applying a special separation theorem for the nonconvex sets in reflexive Banach spaces, some necessary optimality conditions for a nonconvex (scalar/vector) function having a global minimum/and a (weakly) efficient solution concern the existence of a weakly subgradient pair are derived. Under some suitable assumptions, one of such conditions becomes the sufficient optimality condition respectively. An application of the obtained result for the nonsmooth nonconvex multiobjective mathematical programming problem having set, inequality and equality constraints is presented accordingly.},
  archive      = {J_JGO},
  author       = {Su, Tran Van and Tiep, Chu Van},
  doi          = {10.1007/s10898-025-01474-9},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {765-786},
  shortjournal = {J. Glob. Optim.},
  title        = {Applying augmented weak subdifferentials and normal cones for nonconvex mathematical programming problems},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conic relaxations for conic minimax convex polynomial
programs with extensions and applications. <em>JGO</em>, <em>91</em>(4),
743–763. (<a href="https://doi.org/10.1007/s10898-025-01465-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze conic minimax convex polynomial optimization problems. Under a suitable regularity condition, an exact conic programming relaxation is established based on a positivity characterization of a max function over a conic convex system. Further, we consider a general conic minimax $$\rho $$ -convex polynomial optimization problem, which is defined by appropriately extending the notion of conic convexity of a vector-valued mapping. For this problem, it is shown that a Karush-Kuhn-Tucker condition at a global minimizer is necessary and sufficient for ensuring an exact relaxation with attainment of the conic programming relaxation. The exact conic programming relaxations are applied to SOS-convex polynomial programs, where appropriate choices of the data allow the associated conic programming relaxation to be reformulated as a semidefinite programming problem. In this way, we can further elaborate the obtained results for other special settings including conic robust SOS-convex polynomial problems and difference of SOS-convex polynomial programs.},
  archive      = {J_JGO},
  author       = {Doan Chuong, Thai and Vicente-Pérez, José},
  doi          = {10.1007/s10898-025-01465-w},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {743-763},
  shortjournal = {J. Glob. Optim.},
  title        = {Conic relaxations for conic minimax convex polynomial programs with extensions and applications},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the convergence order of value function relaxations used
in decomposition-based global optimization of nonconvex stochastic
programs. <em>JGO</em>, <em>91</em>(4), 701–742. (<a
href="https://doi.org/10.1007/s10898-024-01458-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the convergence rate of decomposition algorithms for globally solving nonconvex stochastic programming problems. We focus on two recent algorithms, termed CZ (Cao and Zavala in J Glob Optim 75:393–416, 2019) and LG (Li and Grossmann in J Glob Optim 75:247–272, 2019), that guarantee global optimality while achieving a favorable decomposed scaling with respect to the number of scenarios. Both methods project the problem into the space of first-stage decisions and apply a spatial-B&amp;B search in this reduced space. Consequently, we observe that they are subject to the results of prior studies on the efficiency of general spatial-B&amp;B algorithms. Such studies have concluded that, to avoid very slow convergence due to the cluster problem, it is necessary (but not sufficient) for the B&amp;B lower bounding problems to have a sufficiently high Hausdorff convergence order. We apply this concept to the CZ and LG decomposition algorithms by first arguing that their lower bounding procedures can be interpreted as defining relaxations in the reduced space of first-stage decisions, and then analyzing the Hausdorff convergence of these relaxations in detail. The results are found to depend strongly on the regularity of the recourse optimal value functions. The relaxations used by CZ are found to be first-order convergent or less, while second order is generally necessary to avoid clustering. In contrast, the relaxations used by LG achieve the highest order possible within the decomposition framework we consider, which is second order when the value functions are smooth, but first order or less otherwise. Unfortunately, these functions are only guaranteed to be lower semi-continuous under standard assumptions. This alludes to a larger limitation of the projection-based decomposition approach, which is discussed at length.},
  archive      = {J_JGO},
  author       = {Robertson, Dillard and Cheng, Pengfei and Scott, Joseph K.},
  doi          = {10.1007/s10898-024-01458-1},
  journal      = {Journal of Global Optimization},
  month        = {4},
  number       = {4},
  pages        = {701-742},
  shortjournal = {J. Glob. Optim.},
  title        = {On the convergence order of value function relaxations used in decomposition-based global optimization of nonconvex stochastic programs},
  volume       = {91},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jiis---15">JIIS - 15</h2>
<ul>
<li><details>
<summary>
(2025). A self-supervised seed-driven approach to topic modelling
and clustering. <em>JIIS</em>, <em>63</em>(1), 333–353. (<a
href="https://doi.org/10.1007/s10844-024-00891-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic models are useful tools for extracting the most salient themes within a collection of documents, grouping them to construct clusters representative of each specific topic. These clusters summarize and represent the semantic contents of the documents for better document interpretation. In this work, we present a light approach able to learn topic representations in a Self-Supervised fashion. More specifically, we propose a lightweight and scalable architecture using a seed-word driven approach to simultaneously co-learn a representation from a document and its corresponding word embeddings. The results obtained on a variety of datasets of different sizes and natures show that our model is capable of extracting meaningful topics. Furthermore, our experiments on five benchmark datasets illustrate that our model outperforms both traditional and neural topic modelling baseline models in terms of different coherence and clustering accuracy measures.},
  archive      = {J_JIIS},
  author       = {Ravenda, Federico and Bahrainian, Seyed Ali and Raballo, Andrea and Mira, Antonietta and Crestani, Fabio},
  doi          = {10.1007/s10844-024-00891-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {333-353},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {A self-supervised seed-driven approach to topic modelling and clustering},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement negative sampling recommendation based on
collaborative knowledge graph. <em>JIIS</em>, <em>63</em>(1), 313–332.
(<a href="https://doi.org/10.1007/s10844-024-00892-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sampling high-quality negative samples and training together with positive samples can help improve the performance and generalization ability of the recommendation model. However, traditional negative sampling methods, such as random sampling or heuristic rules, often fail to adequately capture negative samples that reflect the user’s true taste. To provide interpretability and diversity of negative samples, we propose a collaborative knowledge graph-based reinforcement negative sampling recommendation model called KGRec-RNS that formalizes the problem of finding negative signals into a Markov decision process (MDP). Firstly, user interaction data and external knowledge are integrated into a collaborative Bipartite-Knowledge graph (BKG) as MDP context information environment. Then, an Actor based sampler including graph learning module, neighbor attention module and neighbor pruning module is designed. The graph learning module utilizes graph convolutional neural network (GCN) to extract high-order information of each node, the neighbor attention module is adopted to distinguish the influence of different nodes, and the user conditional action pruning strategy is integrated. Thus, negative samples with interpretability can be screened out. Finally, a Critic based recommender was designed to evaluate the current state and the action reward to guide the policy update of the Actor network, thereby matching high-quality negative samples with positive samples. The experimental results on three real datasets demonstrate that our KGRec-RNS has significant advantages in providing more accurate and diverse recommendations.},
  archive      = {J_JIIS},
  author       = {Zhao, Mengjie and Xun, Yaling and Zhang, Jifu and Li, Yanfeng},
  doi          = {10.1007/s10844-024-00892-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {313-332},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Reinforcement negative sampling recommendation based on collaborative knowledge graph},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph attention networks with adaptive neighbor graph
aggregation for cold-start recommendation. <em>JIIS</em>,
<em>63</em>(1), 293–312. (<a
href="https://doi.org/10.1007/s10844-024-00888-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cold-start problem is a long-standing problem in recommender systems, i.e., lack of historical interaction information hinders effective recommendations for new users and items. Existing methods typically incorporate attribute information of users and items to address the strict cold-start problem. Most existing recommendation methods overlook the sparsity of user attributes in cold start recommendation systems. In this paper, we develop a novel framework, Graph Attention Networks with Adaptive Neighbor Graph Aggregation for cold-start Recommendation (A-GAR), which utilizes the user/item relationship information in cold-start recommendation systems to alleviate the sparsity of attributes. we can achieve more accurate recommendations in cold-start scenarios by fully exploring the complex relations between users/items using graph structures. Specifically, to learn the complex relationships between user/item attributes, we utilize SENet (Squeeze and Excitation Network) and MLP (Multilayer Perceptron) networks to adaptively fuse the embeddings of user/item and their second-order interaction vectors, achieving high-order feature aggregation. To address the issue of lacking preference information in cold-start recommendations, we extend the variational autoencoder to reconstruct missing user preferences (item characteristics) from higher-order attribute features of users/items. In order to learn the potential semantic relationships of nodes in the neighbor graph structure, an attribute graph attention network is used to aggregate the neighbor information of users and the interaction information between neighbors. In this way, the high-order relationships between nodes and the potential semantics of adjacent graphs can be fully explored. Extensive experiments on three real-word datasets with various cold-start scenarios demonstrate that A-GAR yields significant improvements for strict cold-start recommendations.},
  archive      = {J_JIIS},
  author       = {Hu, Qian and Tan, Lei and Gong, Daofu and Li, Yan and Bu, Wenjuan},
  doi          = {10.1007/s10844-024-00888-3},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {293-312},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Graph attention networks with adaptive neighbor graph aggregation for cold-start recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nirdizati: An advanced predictive process monitoring
toolkit. <em>JIIS</em>, <em>63</em>(1), 259–291. (<a
href="https://doi.org/10.1007/s10844-024-00890-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive Process Monitoring (PPM) is a field of Process Mining that aims at predicting how an ongoing execution of a business process will develop in the future using past process executions recorded in event logs. The recent stream of publications in this field shows the need for tools able to support researchers and users in comparing and selecting the techniques that are the most suitable for them. In this paper, we present Nirdizati , a dedicated tool for supporting users in building, comparing and explaining the PPM models that can then be used to perform predictions on the future of an ongoing case. Nirdizati has been constructed by carefully considering the necessary capabilities of a PPM tool and by implementing them in a client-server architecture able to support modularity and scalability. The features of Nirdizati support researchers and practitioners within the entire pipeline for constructing reliable PPM models. The assessment using reactive design patterns and load tests provides an evaluation of the interaction among the architectural elements, and of the scalability with multiple users accessing the prototype in a concurrent manner, respectively. By providing a rich set of different state-of-the-art approaches, Nirdizati offers to Process Mining researchers and practitioners a useful and flexible instrument for comparing and selecting PPM techniques.},
  archive      = {J_JIIS},
  author       = {Rizzi, Williams and Di Francescomarino, Chiara and Ghidini, Chiara and Maggi, Fabrizio Maria},
  doi          = {10.1007/s10844-024-00890-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {259-291},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Nirdizati: An advanced predictive process monitoring toolkit},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedGR: Cross-platform federated group recommendation system
with hypergraph neural networks. <em>JIIS</em>, <em>63</em>(1), 227–257.
(<a href="https://doi.org/10.1007/s10844-024-00887-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group recommendation systems are widely applied in social media, e-commerce, and diverse platforms. These systems face challenges associated with data privacy constraints and protection regulations, impeding the sharing of user data for model improvement. To address the issue of data silos, federated learning emerges as a viable solution. However, difficulties arise due to the non-independent and non-identically distributed nature of data across different platforms, affecting performance. Furthermore, conventional federated learning often overlooks individual differences among stakeholders. In response to these challenges, we propose a pioneering cross-platform federated group recommendation system named FedGR. FedGR integrates hypergraph convolution, attention aggregation, and fully connected fusion components with federated learning to ensure exceptional model performance while preserving the confidentiality of private data. Additionally, we introduce a novel federated model aggregation strategy that prioritizes models with high training effectiveness, thereby improving overall model performance. To address individual differences, we design a temporal personalization update strategy for updating item representations, allowing local models to focus more on their individual characteristics. To evaluate FedGR, we apply our approach to three real-world datasets, demonstrating the robust capabilities of our cross-platform group recommendation system.},
  archive      = {J_JIIS},
  author       = {Zeng, Junlong and Huang, Zhenhua and Wu, Zhengyang and Chen, Zonggan and Chen, Yunwen},
  doi          = {10.1007/s10844-024-00887-4},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {227-257},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {FedGR: Cross-platform federated group recommendation system with hypergraph neural networks},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DA-BAG: A multi-model fusion text classification method
combining BERT and GCN using self-domain adversarial training.
<em>JIIS</em>, <em>63</em>(1), 205–225. (<a
href="https://doi.org/10.1007/s10844-024-00889-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-training-based methods are considered some of the most advanced techniques in natural language processing tasks, particularly in text classification. However, these methods often overlook global semantic information. In contrast, traditional graph learning methods focus solely on structured information from text to graph, neglecting the hidden local information within the syntactic structure of the text. When combined, these approaches may introduce new noise and training biases. To tackle these challenges, we introduce DA-BAG, a novel approach that co-trains BERT and graph convolution models. Utilizing a self-domain adversarial training method on a single dataset, DA-BAG extracts multi-domain distribution features across multiple models, enabling self-adversarial domain adaptation training without the need for additional data, thereby enhancing model generalization and robustness. Furthermore, by incorporating an attention mechanism in multiple models, DA-BAG effectively combines the structural semantics of the graph with the token-level semantics of the pre-trained model, leveraging hidden information within the text’s syntactic structure. Additionally, a sequential multi-layer graph convolutional neural(GCN) connection structure based on a residual pre-activation variant is employed to stabilize the feature distribution of graph data and adjust the graph data structure accordingly. Extensive evaluations on 5 datasets(20NG, R8, R52, Ohsumed, MR) demonstrate that DA-BAG achieves state-of-the-art performance across a diverse range of datasets.},
  archive      = {J_JIIS},
  author       = {Shao, Dangguo and Su, Shun and Ma, Lei and Yi, Sanli and Lai, Hua},
  doi          = {10.1007/s10844-024-00889-2},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {205-225},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {DA-BAG: A multi-model fusion text classification method combining BERT and GCN using self-domain adversarial training},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing user experience: A content-based recommendation
approach for addressing cold start in music recommendation.
<em>JIIS</em>, <em>63</em>(1), 183–204. (<a
href="https://doi.org/10.1007/s10844-024-00872-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems play a major role in modern music streaming platforms, assisting consumers in finding new music that suits their tastes. However, a significant challenge persists when it comes to recommending new songs that lack historical data. This study introduces a Content based Attentive Sequential Recommendation Model (CASRM) that deals with item cold start issue and recommends relevant and fresh music using Gated Graph Neural Networks (GNNs). Music metadata such as artists, albums, genres, and tags are included in the content information, along with context data incorporating user behaviour such as sessions, listening logs, and music playing sequences. By representing the music data as a graph, we can effectively capture the intricate relationships between songs and users. To capture users’ music preferences, we analyse their interactions with songs within the sessions. We incorporate content-based item embeddings for newly added items, enabling personalized recommendations for new songs based on their characteristics and similarities to the songs listened by users in the past. Specifically, we examined the proposed model on three distinct datasets, and the experimental outcomes show its efficacy in predicting music ratings for new songs. Compared to other baseline methods, the CASRM model achieves superior performance in providing accurate and diverse music recommendations in cold-start scenarios.},
  archive      = {J_JIIS},
  author       = {Jangid, Manisha and Kumar, Rakesh},
  doi          = {10.1007/s10844-024-00872-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {183-204},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Enhancing user experience: A content-based recommendation approach for addressing cold start in music recommendation},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting bipolar disorder on social media by post grouping
and interpretable deep learning. <em>JIIS</em>, <em>63</em>(1), 161–182.
(<a href="https://doi.org/10.1007/s10844-024-00884-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipolar disorder is a disorder in which a person expresses manic and depressed emotions repeatedly. Diagnosing bipolar disorder accurately can be difficult because other mood disorders or even regular mood changes may have similar symptoms. Therefore, psychiatrists need to spend a long time observing and interviewing clients to make the diagnosis. Recent studies have trained machine learning models for detecting bipolar disorder on social media. However, most of these studies focused on increasing the accuracy of the model without explaining the classification results. Although the posts of a bipolar disorder user can be observed manually, doing so is not practical since a user can have many posts which may not depict any signs of bipolar disorder. Without any explanations, the trustworthiness of the model decreases. We propose a deep learning model that not only detects and classifies bipolar disorder users but also explains how the model generates the classification results. The posts are first grouped using Latent Dirichlet Allocation, a method commonly used to classify the topic of a text. These groups are then input into the model, and attention mechanisms are utilized to determine which groups have more attention weights and are considered more heavily. Finally, an explanation of the classification results is obtained by visualizing the attention weights. Several case studies are presented to demonstrate the explanations generated through our proposed model. Our model is also compared to other models, achieving the best performance with an F1-Score of 0.92.},
  archive      = {J_JIIS},
  author       = {Thamrin, Syauki Aulia and Chen, Eva E. and Chen, Arbee L. P.},
  doi          = {10.1007/s10844-024-00884-7},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {161-182},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Detecting bipolar disorder on social media by post grouping and interpretable deep learning},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pathways to success: A machine learning approach to
predicting investor dynamics in equity and lending crowdfunding
campaigns. <em>JIIS</em>, <em>63</em>(1), 135–159. (<a
href="https://doi.org/10.1007/s10844-024-00883-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdfunding has evolved into a formidable mechanism for collective financing, challenging traditional funding sources such as bank loans, venture capital, and private equity with its global reach and versatile applications across various sectors. This paper explores the complex dynamics of crowdfunding platforms, particularly focusing on investor behaviour and investment patterns within equity and lending campaigns in Italy. By leveraging advanced machine learning techniques, including XGBoost and LSTM networks, we develop predictive models that dynamically analyze real-time and historical data to accurately forecast the success or failure of crowdfunding campaigns. To address the existing gaps in crowdfunding analysis tools, we introduce two novel datasets—one for equity crowdfunding and another for lending. Moreover, our approach extends beyond traditional binary success metrics, proposing novel measures. The insights gained from this study could support crowdfunding strategies, significantly improving project selection and promotional tactics on platforms. By enhancing decision-making processes and providing forward-looking guidance to investors, our computational model aims to empower both campaign creators and platform administrators, ultimately improving the overall efficacy and sustainability of crowdfunding as a financing tool.},
  archive      = {J_JIIS},
  author       = {Porro, Rosa and Ercole, Thomas and Pipitò, Giuseppe and Vessio, Gennaro and Loglisci, Corrado},
  doi          = {10.1007/s10844-024-00883-8},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {135-159},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Pathways to success: A machine learning approach to predicting investor dynamics in equity and lending crowdfunding campaigns},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning approaches to lexical simplification: A
survey. <em>JIIS</em>, <em>63</em>(1), 111–134. (<a
href="https://doi.org/10.1007/s10844-024-00882-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lexical Simplification (LS) is the task of substituting complex words within a sentence for simpler alternatives while maintaining the sentence’s original meaning. LS is the lexical component of Text Simplification (TS) systems with the aim of improving accessibility to various target populations such as individuals with low literacy or reading disabilities. Prior surveys have been published several years before the introduction of transformers, transformer-based large language models (LLMs), and prompt learning that have drastically changed the field of NLP. The high performance of these models has sparked renewed interest in LS. To reflect these recent advances, we present a comprehensive survey of papers published since 2017 on LS and its sub-tasks focusing on deep learning. Finally, we describe available benchmark datasets for the future development of LS systems.},
  archive      = {J_JIIS},
  author       = {North, Kai and Ranasinghe, Tharindu and Shardlow, Matthew and Zampieri, Marcos},
  doi          = {10.1007/s10844-024-00882-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {111-134},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Deep learning approaches to lexical simplification: A survey},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning approaches to predict the execution time of
the meteorological simulation software COSMO. <em>JIIS</em>,
<em>63</em>(1), 85–109. (<a
href="https://doi.org/10.1007/s10844-024-00880-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting the execution time of weather forecast models is a complex task, since these models are usually performed on High Performance Computing systems that require large computing capabilities. Indeed, a reliable prediction can imply several benefits, by allowing for an improved planning of the model execution, a better allocation of available resources, and the identification of possible anomalies. However, to make such predictions is usually hard, since there is a scarcity of datasets that benchmark the existing meteorological simulation models. In this work, we focus on the runtime predictions of the execution of the COSMO (COnsortium for SMall-scale MOdeling) weather forecasting model used at the Hydro-Meteo-Climate Structure of the Regional Agency for the Environment and Energy Prevention Emilia-Romagna. We show how a plethora of Machine Learning approaches can obtain accurate runtime predictions of this complex model, by designing a new well-defined benchmark for this application task. Indeed, our contribution is twofold: 1) the creation of a large public dataset reporting the runtime of COSMO run under a variety of different configurations; 2) a comparative study of ML models, which greatly outperform the current state-of-practice used by the domain experts. This data collection represents an essential initial benchmark for this application field, and a useful resource for analyzing the model performance: better accuracy in runtime predictions could help facility owners to improve job scheduling and resource allocation of the entire system; while for a final user, a posteriori analysis could help to identify anomalous runs.},
  archive      = {J_JIIS},
  author       = {De Filippo, Allegra and Di Giacomo, Emanuele and Borghesi, Andrea},
  doi          = {10.1007/s10844-024-00880-x},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {85-109},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Machine learning approaches to predict the execution time of the meteorological simulation software COSMO},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Span-based semantic syntactic dual enhancement for aspect
sentiment triplet extraction. <em>JIIS</em>, <em>63</em>(1), 63–83. (<a
href="https://doi.org/10.1007/s10844-024-00881-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-Based Sentiment Triple Extraction (ASTE), a critical sub-task of Aspect-Based Sentiment Analysis (ABSA), has received extensive attention in recent years. ASTE aims to extract structured sentiment triples from texts, with most existing studies focusing on designing new strategic frameworks. Nonetheless, these methods often overlook the complex characteristics of linguistic expression and the deeper semantic nuances, leading to deficiencies in extracting the semantic representations of triples and effectively utilizing syntactic relationships in texts. To address these challenges, this paper introduces a span-based semantic and syntactic Dual-Enhanced model that deeply integrates rich syntactic information, such as part-of-speech tagging, constituent syntax, and dependency syntax structures. Specifically, we designed a semantic encoder and a syntactic encoder to capture the semantic-syntactic information closely related to the sentence’s underlying intent. Through a Feature Interaction Module, we effectively integrate information across different dimensions and promote a more comprehensive understanding of the relationships between aspects and opinions. We also adopted a span-based tagging scheme that generates more precise aspect sentiment triple extractions by exploring cross-level information and constraints. Experimental results on benchmark datasets derived from the SemEval challenge prove that our model significantly outperforms existing baselines.},
  archive      = {J_JIIS},
  author       = {Ren, Shuxia and Guo, Zewei and Li, Xiaohan and Zhong, Ruikun},
  doi          = {10.1007/s10844-024-00881-w},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {63-83},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Span-based semantic syntactic dual enhancement for aspect sentiment triplet extraction},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal knowledge completion enhanced self-supervised
entity alignment. <em>JIIS</em>, <em>63</em>(1), 43–62. (<a
href="https://doi.org/10.1007/s10844-024-00878-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal graph entity alignment aims at finding the equivalent entity pairs across different temporal knowledge graphs (TKGs). Primarily methods mainly utilize a time-aware and relationship-aware approach to embed and align. However, the existence of long-tail entities in TKGs still restricts the accuracy of alignment, as the limited neighborhood information may restrict the available neighborhood information for obtaining high-quality embeddings, and hence would impact the efficiency of entity alignment in representation space. Moreover, most previous researches are supervised, with heavy dependence on seed labels for alignment, restricting their applicability in scenarios with limited resources. To tackle these challenges, we propose a Temporal Knowledge Completion enhanced Self-supervised Entity Alignment (TSEA). We argue that, with high-quality embeddings, the entities would be aligned in a self-supervised manner. To this end, TSEA is constituted of two modules: A graph completion module to predict the missing links for the long-tailed entities. With the improved graph, TSEA further incorporates a self-supervised entity alignment module to achieve unsupervised alignment. Experimental results on widely adopted benchmarks demonstrate improved performance compared to several recent baseline methods. Additional ablation experiments further corroborate the efficacy of the proposed modules.},
  archive      = {J_JIIS},
  author       = {Fu, Teng and Zhou, Gang},
  doi          = {10.1007/s10844-024-00878-5},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {43-62},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Temporal knowledge completion enhanced self-supervised entity alignment},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint entity and relation extraction with fusion of
multi-feature semantics. <em>JIIS</em>, <em>63</em>(1), 21–42. (<a
href="https://doi.org/10.1007/s10844-024-00871-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity relation extraction is a key technology for extracting structured information from unstructured text and serves as the foundation for building large-scale knowledge graphs. Current joint entity relation extraction methods primarily focus on improving the recognition of overlapping triplets to enhance the overall performance of the model. However, the model still faces numerous challenges in managing intra-triplet and inter-triplet interactions, expanding the breadth of semantic encoding, and reducing information redundancy during the extraction process. These issues make it challenging for the model to achieve satisfactory performance in both normal and overlapping triple extraction. To address these challenges, this study proposes a comprehensive prediction network that includes multi-feature semantic fusion. We have developed a semantic fusion module that integrates entity mask embedding sequences, which enhance connections between entities, and context embedding sequences that provide richer semantic information, to enhance inter-triplet interactions and expand semantic encoding. Subsequently, using a parallel decoder to simultaneously generate a set of triplets, improving the interaction between them. Additionally, we utilize an entity mask sequence to finely prune these triplets, optimizing the final set of triplets. Experimental results on the publicly available datasets NYT and WebNLG demonstrate that, with BERT as the encoder, our model outperforms the baseline model in terms of accuracy and F1 score.},
  archive      = {J_JIIS},
  author       = {Wang, Ting and Yang, Wenjie and Wu, Tao and Yang, Chuan and Liang, Jiaying and Wang, Hongyang and Li, Jia and Xiang, Dong and Zhou, Zheng},
  doi          = {10.1007/s10844-024-00871-y},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {21-42},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Joint entity and relation extraction with fusion of multi-feature semantics},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task learning and mutual information maximization with
crossmodal transformer for multimodal sentiment analysis. <em>JIIS</em>,
<em>63</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10844-024-00858-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effectiveness of multimodal sentiment analysis hinges on the seamless integration of information from diverse modalities, where the quality of modality fusion directly influences sentiment analysis accuracy. Prior methods often rely on intricate fusion strategies, elevating computational costs and potentially yielding inaccurate multimodal representations due to distribution gaps and information redundancy across heterogeneous modalities. This paper centers on the backpropagation of loss and introduces a Transformer-based model called Multi-Task Learning and Mutual Information Maximization with Crossmodal Transformer (MMMT). Addressing the issue of inaccurate multimodal representation for MSA, MMMT effectively combines mutual information maximization with crossmodal Transformer to convey more modality-invariant information to multimodal representation, fully exploring modal commonalities. Notably, it utilizes multi-modal labels for uni-modal training, presenting a fresh perspective on multi-task learning in MSA. Comparative experiments on the CMU-MOSI and CMU-MOSEI datasets demonstrate that MMMT improves model accuracy while reducing computational burden, making it suitable for resource-constrained and real-time performance-requiring application scenarios. Additionally, ablation experiments validate the efficacy of multi-task learning and probe the specific impact of combining mutual information maximization with Transformer in MSA.},
  archive      = {J_JIIS},
  author       = {Shi, Yang and Cai, Jinglang and Liao, Lei},
  doi          = {10.1007/s10844-024-00858-9},
  journal      = {Journal of Intelligent Information Systems},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Inf. Syst.},
  title        = {Multi-task learning and mutual information maximization with crossmodal transformer for multimodal sentiment analysis},
  volume       = {63},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jim---35">JIM - 35</h2>
<ul>
<li><details>
<summary>
(2025). Manifold learning-assisted uncertainty quantification of
system parameters in the fiber metal laminates hot forming process.
<em>JIM</em>, <em>36</em>(3), 2193–2219. (<a
href="https://doi.org/10.1007/s10845-024-02343-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The forming quality of Fiber metal laminates (FMLs) heavily depends on the material properties, fiber placing angles, blank holder force, and other process parameters. In some circumstances, the numerical perturbation of the key parameters has a potential impact on the mechanical properties of final products. To efficiently design a set of available system parameters to ensure the forming quality, a manifold learning-assisted approximate Bayesian computation (ABC) method is proposed to identify system parameters with uncertainties. In this study, the nonlinear manifold learning approach is employed to extract the feature vector of physical field information of sheet metal and composite core after hot forming. Furthermore, the mapping transformation of system parameters based on different modeling techniques is performed to shorten the time of obtaining feature vectors of new samples. The nested sampling method involving the wavelet mutation strategy is proposed to improve the sampling efficiency of the posterior distribution of system parameters while the tolerance criterion is guaranteed. Two hot stamp-forming cases are employed to validate the feasibility of the proposed approach. The numerical results show that the proposed method is effective in obtaining the system parameters necessary for achieving the high-quality forming of FMLs.},
  archive      = {J_JIM},
  author       = {Wang, Xin and Jiang, Xinchao and Wang, Hu and Li, Guangyao},
  doi          = {10.1007/s10845-024-02343-0},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2193-2219},
  shortjournal = {J. Intell. Manuf.},
  title        = {Manifold learning-assisted uncertainty quantification of system parameters in the fiber metal laminates hot forming process},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation-based information sharing for online
process monitoring in decentralized manufacturing system. <em>JIM</em>,
<em>36</em>(3), 2177–2192. (<a
href="https://doi.org/10.1007/s10845-024-02348-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In advanced manufacturing, the incorporation of sensing technology provides an opportunity to achieve efficient in situ process monitoring using machine learning methods. Meanwhile, the advances of information technologies also enable a connected and decentralized environment for manufacturing systems, making different manufacturing units in the system collaborate more closely. In a decentralized manufacturing system, the involved units may fabricate same or similar products and deploy their own machine learning model for online process monitoring. However, due to the possible inconsistency of task progress during the operation, it is also common that some units have more informative data while some have less informative data. Thus, the monitoring performance of machine learning model for each unit may highly vary. Therefore, it is extremely valuable to achieve efficient and secured knowledge sharing among the units in a decentralized manufacturing system for enhancement of poorly performed models. To realize this goal, this paper proposes a novel knowledge distillation-based information sharing (KD-IS) framework, which could distill informative knowledge from well performed models to improve the monitoring performance of poorly performed models. To validate the effectiveness of this method, a real-world case study is conducted in a connected fused filament fabrication (FFF)-based additive manufacturing (AM) platform. The experimental results show that the developed method is very efficient in improving model monitoring performance at poorly performed models, with solid protection on potential data privacy.},
  archive      = {J_JIM},
  author       = {Shi, Zhangyue and Li, Yuxuan and Liu, Chenang},
  doi          = {10.1007/s10845-024-02348-9},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2177-2192},
  shortjournal = {J. Intell. Manuf.},
  title        = {Knowledge distillation-based information sharing for online process monitoring in decentralized manufacturing system},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CowSSL: Contrastive open-world semi-supervised learning for
wafer bin map. <em>JIM</em>, <em>36</em>(3), 2163–2175. (<a
href="https://doi.org/10.1007/s10845-024-02351-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the semiconductor industry, wafer bin maps (WBMs) refer to image data that reveal the defect of each chip positioned on that wafer. The WBMs provide crucial information that can facilitate the identification of underlying causes for any defects present on a wafer. With the advent of artificial intelligence (AI), a significant amount of research has been conducted leveraging machine learning and deep learning techniques to automatically classify wafer bin map defects. Although there have been various attempts to enhance performance by using both unlabeled and labeled data, current research is constrained by its narrow focus on improving the detection of known defect patterns. However, in the real world, multiple novel patterns frequently arise that have not been previously encountered. Hence, AI models must exhibit the capacity to detect not only existing known defect patterns but also newly emerging defect patterns, while ensuring effective classification of these new patterns among themselves. In this study, we propose the contrastive open-world semi-supervised learning that can classify multiple novel patterns in WBMs simultaneously. We introduce a contrastive loss function to address the challenges associated with the existence of significantly fewer new defect patterns than existing patterns in the WBM problem. We confirm that the proposed methodology effectively detects and classifies diverse new patterns separately in real-world open data, WM-811 K. Moreover, we demonstrate that the proposed method outperforms other existing open-world semi-supervised learning in WBM classification.},
  archive      = {J_JIM},
  author       = {Baek, Insung and Hwang, Sung Jin and Kim, Seoung Bum},
  doi          = {10.1007/s10845-024-02351-0},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2163-2175},
  shortjournal = {J. Intell. Manuf.},
  title        = {CowSSL: Contrastive open-world semi-supervised learning for wafer bin map},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monocrystalline silicon crystal line detection based on the
improved YoloX-tiny algorithm. <em>JIM</em>, <em>36</em>(3), 2141–2162.
(<a href="https://doi.org/10.1007/s10845-023-02312-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Monocrystalline silicon is an essential raw material for the photovoltaic industry, and industrial production requires keeping monocrystalline silicon crystals free of defects. Monocrystalline silicon production requires the staff to adjust the monocrystalline furnace parameters according to the state of the monocrystalline silicon to control the crystal growth process. The high-temperature environment inside the furnace causes the staff to observe the status of the crystal lines only through the industrial camera. The crystallization process is based on the generation of crystal lines to determine if the crystal is in a stable state. The isometric growth process determines whether dislocations have occurred in the crystal by crystal line characteristics. Therefore, it is necessary to automatically detect the status of the crystal lines through algorithms. We have built a monocrystal silicon crystal line dataset by analyzing the image features of the crystallization process and the isometry process of monocrystal silicon. Then we propose an improved YoloX-tinys model based on the YoloX-tiny model, which can detect crystal line features accurately and quickly at low arithmetic power. The backbone network is replaced with ShufferNetV2 lightweight network and the internal 3*3 convolutional kernel is replaced with a 5*5 size to improve the computational power of the model. DFC(Decoupled Fully Connected Attention) attention mechanism is added to the Neck network to enhance the feature processing capability. We also optimize the Neck network by replacing the depthwise separable convolution and applying the h-swish activation function. The improved model achieves 99.53% mAP on the proposed dataset. Meanwhile, the number of parameters of the model decreases from 5.03M to 2.35M, and the FPS(Frames Per Second) increase from 45.34 to 59.41. The results demonstrate that our model is able to achieve accurate crystal line detection with less computational consumption compared to other models, while achieving higher detection accuracy and speed.},
  archive      = {J_JIM},
  author       = {She, Yuting and Li, Hongxin},
  doi          = {10.1007/s10845-023-02312-z},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2141-2162},
  shortjournal = {J. Intell. Manuf.},
  title        = {Monocrystalline silicon crystal line detection based on the improved YoloX-tiny algorithm},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Engineering and evaluating an unsupervised predictive
maintenance solution: A cold-forming press case-study. <em>JIM</em>,
<em>36</em>(3), 2121–2139. (<a
href="https://doi.org/10.1007/s10845-024-02352-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world industries, production line assets may be affected by several factors, both known and unknown, which dynamically and unpredictably evolve so that past data are of little value for present ones. In addition, data is collected without assigned labels. How can someone use run-to-failure data to develop a suitable solution toward achieving predictive maintenance (PdM) in this case? These issues arise in our case, which refers to a cold-forming press. Such a setting calls for an unsupervised solution that can predict upcoming failures investigating a wide spectrum of approaches, namely similarity-based, forecasting-based and deep-learning ones. But before we decide on the best solution, we first need to understand which key performance indicators are appropriate to evaluate the impact of each such solution. A comprehensive study of available evaluation methods is presented, highlighting misconceptions and limitations of broadly used evaluation metrics concerning run-to-failure data, while proposing an extension of state-of-the-art range-based anomaly detection evaluation metrics to serve PdM purposes. Finally, an investigation of pre-processing, distance metrics, incorporation of domain expertise, and the role of deep learning shows how to engineer an unsupervised solution for predictive maintenance providing insightful answers to all these problems. Our experimental evaluation showed that judicious design choices can improve efficiency of solutions up to two times.},
  archive      = {J_JIM},
  author       = {Giannoulidis, Apostolos and Gounaris, Anastasios and Naskos, Athanasios and Nikolaidis, Nikodimos and Caljouw, Daniel},
  doi          = {10.1007/s10845-024-02352-z},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2121-2139},
  shortjournal = {J. Intell. Manuf.},
  title        = {Engineering and evaluating an unsupervised predictive maintenance solution: A cold-forming press case-study},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-enabled real-time anomaly detection for
electron beam powder bed fusion additive manufacturing. <em>JIM</em>,
<em>36</em>(3), 2105–2119. (<a
href="https://doi.org/10.1007/s10845-024-02359-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the many advantages and increasing adoption of Electron Beam Powder Bed Fusion (PBF-EB) additive manufacturing by industry, current PBF-EB systems remain largely unstable and prone to unpredictable anomalous behaviours. Additionally, although featuring in-situ process monitoring, PBF-EB systems show limited capabilities in terms of timely identification of process failures, which may result into considerable wastage of production time and materials. These aspects are commonly recognized as barriers for the industrial breakthrough of PBF-EB technologies. On top of these considerations, in our research we aim at introducing real-time anomaly detection capabilities into the PBF-EB process. To do so, we build our case-study on top of a Arcam EBM A2X system, one of the most diffused PBF-EB machines in industry, and make access to the most relevant variables made available by this machine during the layering process. Thus, seeking a proficient interpretation of such data, we introduce a deep learning autoencoder-based anomaly detection framework. We demonstrate that this framework is able not only to early identify anomalous patterns from such data in real-time during the process with a F1 score around 90%, but also to anticipate the failure of the current job by 6 h, on average, and in one case by almost 20 h. This avoids waste of production time and opens the way to a more controllable PBF-EB process.},
  archive      = {J_JIM},
  author       = {Cannizzaro, Davide and Antonioni, Paolo and Ponzio, Francesco and Galati, Manuela and Patti, Edoardo and Di Cataldo, Santa},
  doi          = {10.1007/s10845-024-02359-6},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2105-2119},
  shortjournal = {J. Intell. Manuf.},
  title        = {Machine learning-enabled real-time anomaly detection for electron beam powder bed fusion additive manufacturing},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traditional machine learning and deep learning for
predicting melt-pool cross-sectional morphology of laser powder bed
fusion additive manufacturing with thermographic monitoring.
<em>JIM</em>, <em>36</em>(3), 2079–2104. (<a
href="https://doi.org/10.1007/s10845-024-02356-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate non-equilibrium and rapid solidification behavior inherent in laser powder bed fusion (LPBF) additive manufacturing affects the quality and performance of as-built parts. To evaluate and predict the quality of LPBF-built parts, engaging in real-time monitoring of the LPBF process by leveraging thermal information derived from the melt pool becomes significant. In this work, the insights conveyed by near-infrared (NIR) thermal-imaging on melt pools during the LPBF process were explored, with the assistance of machine learning (ML) and deep learning (DL) methods, aiming to develop ML and DL models capable of recognizing NIR melt-pool monitoring images and predicting invisible geometries of laser-tracks. Traditional ML models, including support vector machines, were used to establish a non-linear mapping relationship between NIR thermal images and cross-sectional geometries of solidified laser-tracks. That was achieved by extracting melt-pool NIR image features based on prior knowledge while analyzing the influence of laser parameters on the melt pools. Then, DL models such as convolutional neural networks were improved to extract multi-scale features from the melt-pool thermal images through self-learning mechanisms. By comprehensively merging multi-scale features, these DL models effectively captured and reflected vital NIR image information from the melt pool. The various methodologies collectively provided real-time insights for monitoring and controlling the LPBF processes, thereby facilitating reasoning about and predicting imperceptible geometries of the cross-sectional solidified laser-tracks within the as-built parts.},
  archive      = {J_JIM},
  author       = {Wang, Haijie and Li, Bo and Zhang, Saifan and Xuan, Fuzhen},
  doi          = {10.1007/s10845-024-02356-9},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2079-2104},
  shortjournal = {J. Intell. Manuf.},
  title        = {Traditional machine learning and deep learning for predicting melt-pool cross-sectional morphology of laser powder bed fusion additive manufacturing with thermographic monitoring},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel curved surface profile monitoring approach based on
geometrical-spatial joint feature. <em>JIM</em>, <em>36</em>(3),
2055–2077. (<a
href="https://doi.org/10.1007/s10845-024-02349-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of high-end manufacturing, a variety of sophisticated parts with complex curved surfaces have emerged, and curved surface profile monitoring is of great importance for achieving the higher performance of a part. Benefiting from the recent advancements in non-contact measurement systems, millions of high-density point clouds are rapidly collected to represent the entire curved surface, which can reflect the geometrical and spatial features. The traditional discrete key quality characteristics-based monitoring approaches are not capable of handling complex curved surfaces. A novel curved surface profile monitoring approach based on geometrical-spatial joint features is proposed, which consists of point cloud data preprocessing, Laplace–Beltrami spectrum calculation, spatial geodesic clustering degree definition, and multivariate control chart construction. It takes full advantage of the entire wealth information on complex curved surfaces and can detect the small shifts of geometrical shape and spatial distribution information of non-Euclidean surfaces. Two real-world engineering surfaces case studies illustrate the proposed approach is effective and feasible.},
  archive      = {J_JIM},
  author       = {Shao, Yiping and Chen, Jun and Gu, Xiaoli and Lu, Jiansha and Du, Shichang},
  doi          = {10.1007/s10845-024-02349-8},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2055-2077},
  shortjournal = {J. Intell. Manuf.},
  title        = {A novel curved surface profile monitoring approach based on geometrical-spatial joint feature},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-process surface quality monitoring of the slender
workpiece machining with digital twin approach. <em>JIM</em>,
<em>36</em>(3), 2039–2053. (<a
href="https://doi.org/10.1007/s10845-024-02353-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In-process monitoring of production quality plays a significant role in intelligent manufacturing. Both part deformation and vibration happen simultaneously in machining processes. They are two prominent issues that can affect the surface quality of machined parts, especially those with low rigidity. The purpose of this study is to explore a hybrid modeling solution to simultaneously monitor the diametrical errors and early chatter vibrations when turning a slender workpiece. A generic analytical model of the slender workpiece turning is formulated based on dynamics of machining. It is proved that the system complies with the principle of superposition. Accordingly, the explicit expressions free from cutting force modeling that is widely used in literature are derived for characterizing the finished surface quality with analytical and finite element methods, respectively. A data-driven model is also developed using the wavelet packet transform to the displacement signals. The independent decompositions of the displacement signals are then correlated with both the dimensional error model and the turning chatter model. Interconnecting the dynamics-based model and the data-driven model contributes to a digital-twin prototype, which allows for in-process detection of the geometrical distortion and the onset of chatter on the part surface. Finally, two different machining cases were performed to verify the proposed methodology. The results show that the developed model consisting of the formulated deflection correlation and chatter indicator is capable of simultaneously evaluating and detecting the dimensional error prediction and the early-onset chatter. By comparison with the analytical modeling, the high fidelity digital twin using the finite element modeling could exhibit higher prediction accuracy. The proposed monitoring strategy could provide a pragmatic approach to online quality control for intelligent machining of flexible workpieces on the shop floor.},
  archive      = {J_JIM},
  author       = {Lu, Kaibo and Li, Zhen and Longstaff, Andrew},
  doi          = {10.1007/s10845-024-02353-y},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2039-2053},
  shortjournal = {J. Intell. Manuf.},
  title        = {In-process surface quality monitoring of the slender workpiece machining with digital twin approach},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of a melt pool characteristics detection
platform based on multi-information fusion of temperature fields and
photodiode signals in plasma arc welding. <em>JIM</em>, <em>36</em>(3),
2017–2037. (<a
href="https://doi.org/10.1007/s10845-024-02342-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Melt pool characteristics reflect the formation mechanisms and potential issues of flaws. Long-term, high-precision, and real-time detection of melt pool characteristics is one of the major challenges in the industrial application of additive manufacturing technology. This work proposes, for the first time, the melt pool characteristics detection platform based on multi-information fusion in the plasma arc welding (PAW) process, which fully utilizes real-time photodiode signals and high-precision, information-rich melt pool temperature fields. By optimizing the detection area and wavelength selection of the platform, particularly through the unique photodiode signal acquisition system capable of detecting the high-sensitivity area of the melt pool, we effectively mitigate the influences of intense arc light and welding wire obstruction on the temperature signals and photodiode signals. Through applying machine learning, the trained model integrates photodiode signals with temperature signals from the high-sensitivity area, thereby achieving real-time acquisition of high-precision average temperature. By combining the fused signals collected from the platform and the scanning results from micro-computed tomography (CT), we evaluate and verify the influence of flaws and droplets on the melt pool characteristics, realizing the determination of flaw occurrence based on the abnormal variations of average temperature. The experimental results demonstrated that the platform fully utilized the advantages of long-term and real-time acquisition of the photodiode signal and the high-precision and information-rich of the melt pool temperature field, achieving long-term, high-precision, and real-time detection of melt pool characteristics.},
  archive      = {J_JIM},
  author       = {Mao, Zhuangzhuang and Feng, Wei and Han, Xiao and Ma, Heng and Hao, Ce and Liu, Changmeng and Liu, Zhanwei},
  doi          = {10.1007/s10845-024-02342-1},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {2017-2037},
  shortjournal = {J. Intell. Manuf.},
  title        = {Development of a melt pool characteristics detection platform based on multi-information fusion of temperature fields and photodiode signals in plasma arc welding},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoML-driven diagnostics of the feeder motor in fused
filament fabrication machines from direct current signals. <em>JIM</em>,
<em>36</em>(3), 1999–2016. (<a
href="https://doi.org/10.1007/s10845-024-02332-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Part defects in additive manufacturing are more frequent compared to machining or molding. Failures can go unnoticed for hours, wasting resources and extending process cycle times. This paper describes a Machine Learning based method for automated sensing of onset failure in additive manufacturing machinery. Investigations are conducted on a Fused Filament Fabrication (FFF) 3D printer, and the same methods are then applied to a digital light processing 3D printer. The investigation focuses on signal-based analysis, specifically passive sensing of stepper motors relating DC current measurements to the torque on a stepper, as opposed to any active acoustic interrogation of the part. Passive methods are used to characterize the loading on a feeder stepper in an FFF machine, forming a model that can identify early signs of filament-based failure with 85.65% 10-fold cross-validation accuracy. Efforts show filament breakage can be detected minutes before material runout would cause a defect, allowing ample time to pause, correct, or control the print. The machine learning pipeline was not naively conceived but optimized through automated machine learning.},
  archive      = {J_JIM},
  author       = {Rooney, Sean and Pitz, Emil and Pochiraju, Kishore},
  doi          = {10.1007/s10845-024-02332-3},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1999-2016},
  shortjournal = {J. Intell. Manuf.},
  title        = {AutoML-driven diagnostics of the feeder motor in fused filament fabrication machines from direct current signals},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sheet resistance prediction of laser induced graphitic
carbon with transformer encoder-enabled contrastive learning.
<em>JIM</em>, <em>36</em>(3), 1983–1997. (<a
href="https://doi.org/10.1007/s10845-024-02333-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting the sheet resistance of laser-induced graphitic carbon (LIGC) is crucial for optimizing process conditions and designing high-performance LIGC-based devices. However, identifying the most significant process parameter for predicting the sheet resistance of LIGC is challenging. In addition, training an accurate model with a small dataset remains a challenge. To address the first issue, a novel transformer encoder with a self-attention mechanism is introduced to determine the most and least significant process parameters affecting the sheet resistance of LIGC. To address the second issue, a contrastive learning method is developed to augment a small training dataset. Unlike conventional deep learning approaches that establish a direct relationship between process parameters and sheet resistance, the proposed method can learn the relationship between the difference in features extracted from process parameter settings and the difference in the corresponding sheet resistances. Experimental results have demonstrated that the proposed transformer encoder-enabled contrastive learning method accurately predicted the sheet resistance of LIGC and outperformed other machine learning methods.},
  archive      = {J_JIM},
  author       = {Wei, Yupeng and Grau, Gerd and Wu, Dazhong},
  doi          = {10.1007/s10845-024-02333-2},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1983-1997},
  shortjournal = {J. Intell. Manuf.},
  title        = {Sheet resistance prediction of laser induced graphitic carbon with transformer encoder-enabled contrastive learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple operational mode prediction at milling tool-tip
based on transfer learning. <em>JIM</em>, <em>36</em>(3), 1959–1982. (<a
href="https://doi.org/10.1007/s10845-024-02364-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the tool-tip dynamics is crucial for evaluating the performance in milling and essential for chatter prediction; obtaining and predicting tool-tip modes efficiently and accurately is thus essential, especially when the milling parameters or tool-holder assembly change. However, there is currently no such efficient and explainable method with high generalization ability for obtaining and predicting the tool-tip modes considering the above change. To address this issue, the stochastic subspace identification (SSI) method is initially used to acquire multiple operational modes more efficient and cost-effective than traditional methods under varying milling parameters. Subsequently, machine learning (ML) models are trained to predict the above modes under varying spindle speeds and axial cutting depth. Moreover, when changes occur in the tool-holder assembly, a transfer learning (TL) model based on receptance coupling substructure analysis (RCSA) theory is proposed to re-establish the modes prediction model efficiently with the above data. The TL model has a modal frequency prediction error below 2% and a damping ratio prediction error below 10%, thereby demonstrating robust generalization capabilities. Finally, predicting milling stability with the above modes prediction model, which can provide a stability lobe diagram with higher accuracy than the traditional method, is introduced. In conclusion, the multiple operational modes are acquired more efficiently with the SSI method, and the ML model or TL model with RCSA theory is thus established efficiently when milling parameters or tool-holder assembly change. The obtained model is used for chatter prediction as follows and performs better in prediction accuracy.},
  archive      = {J_JIM},
  author       = {Zhou, Kai and Feng, Feng and Wang, Jianjian and Feng, Pingfa},
  doi          = {10.1007/s10845-024-02364-9},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1959-1982},
  shortjournal = {J. Intell. Manuf.},
  title        = {Multiple operational mode prediction at milling tool-tip based on transfer learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian inference for multi-label classification for root
cause analysis and probe card maintenance decision support and an
empirical study. <em>JIM</em>, <em>36</em>(3), 1943–1958. (<a
href="https://doi.org/10.1007/s10845-024-02336-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probe cards have been employed as intermediary tools between the wafers and automatic test equipment to prevent defect dies from entering the packaging stage to reduce the consumer risk and extra losses. To enhance the partnership, probe card manufacturer is responsible for troubleshooting of the sold probe cards in short time as part of after-sales maintenance to enhance the productivity. In practice, maintenance engineers relied on domain knowledge for probe card maintenance. However, owing the continuously migration of advanced technologies for semiconductor manufacturing and exponentially increasing product complexity, probe card maintenance has become challenging and time-consuming. Most of the existing studies have not addressed the root cause analysis problem for identifying corrective actions for abnormal symptoms, nor considered the effectiveness of maintenance. The selection of appropriate maintenance actions is crucial in root cause analysis. To fill the gaps, this study integrates domain knowledge and data-driven approaches to develop a smart maintenance solution based on Bayesian inference for multi-label classification to derive effective suggestions to enhance after-sales service quality for probe cards. An empirical study was conducted in a leading probe card company for validation. The results have shown practical viability of the developed solution to effectively and efficiently generate a number of maintenance recommendations for the engineers to improving troubleshooting efficiency and service quality while reducing maintenance time and machine downtime.},
  archive      = {J_JIM},
  author       = {Chien, Chen-Fu and Peng, Jia-Yu},
  doi          = {10.1007/s10845-024-02336-z},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1943-1958},
  shortjournal = {J. Intell. Manuf.},
  title        = {Bayesian inference for multi-label classification for root cause analysis and probe card maintenance decision support and an empirical study},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual metrology for chemical mechanical planarization of
semiconductor wafers. <em>JIM</em>, <em>36</em>(3), 1923–1942. (<a
href="https://doi.org/10.1007/s10845-024-02335-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chemical mechanical planarization (CMP) is an important operation for surface modification of wafers in semiconductor manufacturing. Productivity and quality of wafers depends strongly on the efficiency of CMP and virtual metrology (VM) is a promising tool not only to facilitate wafer-to-wafer control but also to reduce cycle time. Development of VM tools for CMP is still not a reality due to the complexity of CMP and unavailability of critical process measurements such as slurry temperature and abrasive particle size distribution in real-time. To overcome these challenges, a novel hybrid modeling framework is proposed for creating a VM solution for CMP. Physics-based models are utilized for estimating slurry temperature and mean abrasive particle size (MAPS) from sensor data. They supplement other sensor data for developing soft sensors to predict slurry temperature, MAPS, and the material removal rate (MRR). This hybrid framework is tested with about 3000 sets of published industrial sensor data. Exploratory analysis indicated two distinct regimes of operation, low and high MRR, and a strong relationship of MRR with slurry temperature and MAPS. Several machine learning (ML) algorithms such as random forest, Lasso regression and support vector machine are explored and XGBoost is found to be the best amongst them. The optimum operating conditions are determined through model-based optimization using the hybrid modeling framework and particle swarm optimization. These results suggested CMP to be carried out at the smallest MAPS to maximize MRR. This framework would be useful for building a digital twin system of CMP.},
  archive      = {J_JIM},
  author       = {Deivendran, Balamurugan and Masampally, Vishnu Swaroopji and Nadimpalli, Naga Ravikumar Varma and Runkana, Venkataramana},
  doi          = {10.1007/s10845-024-02335-0},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1923-1942},
  shortjournal = {J. Intell. Manuf.},
  title        = {Virtual metrology for chemical mechanical planarization of semiconductor wafers},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel joint segmentation approach for wafer surface defect
classification based on blended network structure. <em>JIM</em>,
<em>36</em>(3), 1907–1921. (<a
href="https://doi.org/10.1007/s10845-024-02324-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient management and control of wafer defects are paramount in enhancing yield in IC chip manufacturing. Scanning Electron Microscope imagery of wafer surfaces, however, presents a challenge due to complex backgrounds and a minimal presence of actual defects. This complexity often hampers traditional convolutional neural networks tasked with defect classification and segmentation, making them prone to disturbances from background elements. To address this issue, we introduce a novel interwoven network architecture that synergizes convolution and Transformer models. This integrated approach is specifically designed to surmount the dual challenges of classification and joint segmentation in wafer defects, achieving a balance between computational efficiency and prediction accuracy. Our research, grounded in real-world production line data from IC chip manufacturing, demonstrates that our network attains a segmentation accuracy of 83.15% and a classification accuracy of 96.88%. The proposed method for automatic defect information extraction is shown to be viable for industrial application. The merger of convolutional neural networks with Transformer models in this innovative architecture shows considerable promise for enhancing wafer defect analysis, thereby improving the precision of defect classification and segmentation in semiconductor manufacturing processes.},
  archive      = {J_JIM},
  author       = {Mei, Zhouzhouzhou and Luo, Yuening and Qiao, Yibo and Chen, Yining},
  doi          = {10.1007/s10845-024-02324-3},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1907-1921},
  shortjournal = {J. Intell. Manuf.},
  title        = {A novel joint segmentation approach for wafer surface defect classification based on blended network structure},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthetic data generation using finite element method to
pre-train an image segmentation model for defect detection using
infrared thermography. <em>JIM</em>, <em>36</em>(3), 1879–1905. (<a
href="https://doi.org/10.1007/s10845-024-02326-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vision of a deep learning-empowered non-destructive evaluation technique aligns perfectly with the goal of zero-defect manufacturing, enabling manufacturers to detect and repair defects actively. However, the dearth of data in manufacturing is one of the biggest obstacles to realizing an intelligent defect detection system. This work presents a framework for bridging the data gap in manufacturing using the potential of synthetic datasets generated using the finite element method-based digital twin. The non-destructive technique under consideration is pulse infrared thermography. A large number of synthetic thermographic measurements were generated using 2D axisymmetric transient thermal simulations. The representativeness of synthetic data was thoroughly investigated at various steps of the framework, and the image segmentation model was trained separately on experimental and synthetic datasets. The study results reveal that when carefully rendered, synthetic datasets represent the experimental data well. When evaluated on real-world experimental samples, the segmentation model pre-trained on synthetic datasets generalizes well to the experimental samples. Furthermore, another advantage of synthetic datasets is the ease of labelling a large amount of data. Finally, the robustness assessment of the model was done on two new datasets: one where the complete experimental setup was changed, and the other was an open-source infrared thermography dataset},
  archive      = {J_JIM},
  author       = {Pareek, Kaushal Arun and May, Daniel and Meszmer, Peter and Ras, Mohamad Abo and Wunderle, Bernhard},
  doi          = {10.1007/s10845-024-02326-1},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1879-1905},
  shortjournal = {J. Intell. Manuf.},
  title        = {Synthetic data generation using finite element method to pre-train an image segmentation model for defect detection using infrared thermography},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BCTMSSF: A blockchain consensus-based traceability method
for supply chain in smart factory. <em>JIM</em>, <em>36</em>(3),
1861–1877. (<a
href="https://doi.org/10.1007/s10845-024-02334-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encountering the problems of diverse sources, opaque information, and difficult collaboration among nodes in a smart factory supply chain, we proposed a traceability model based on blockchain consensus technology. It can realize accurate traceability, transparent transmission, and trusted storage of supply chain information. First, we proposed a blockchain-based smart factory supply chain traceability model (BCTMSSF). It makes the donation process open and transparent using a decentralized, traceable, and tamper-proof blockchain. Second, we proposed a verifiable delegated proof of stake (VDPoS) scheme to solve the problems of centralization and security. It integrates a dynamic random probability mechanism and fuse mechanism. Finally, we conducted experiments on a blockchain platform and verified the proposed model. The results revealed that our model can solve the problems of real-time, reliable, and transparent traceability of supply chain information, alleviate the problem of centralization, and improve security.},
  archive      = {J_JIM},
  author       = {Zhao, Hang and Hu, Kai and Yuan, Zehui and Yao, Shaowen and Feng, Libo},
  doi          = {10.1007/s10845-024-02334-1},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1861-1877},
  shortjournal = {J. Intell. Manuf.},
  title        = {BCTMSSF: A blockchain consensus-based traceability method for supply chain in smart factory},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A predictive modelling strategy for warpage and shrinkage
defects in plastic injection molding using fuzzy logic and pattern
search optimization. <em>JIM</em>, <em>36</em>(3), 1835–1859. (<a
href="https://doi.org/10.1007/s10845-024-02331-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality control through defect minimization has been the central theme in plastic injection molding research. This study contributes to this course through the introduction of an alternative predictive modelling strategy for injection molding defects. Through multi-stage design of experiments, Computer Aided Engineering simulations, and intelligent algorithms, the study developed a warpage and shrinkage defects predictive model based on processing parameters. In the factorial design of experiment stage, the mains effect sizes, interaction effect sizes, and ANOVA were used for process parameter screening. Next, a Taguchi L25 design was used for the generation of predictive model training data. Fuzzy logic models were then developed to predict warpage and shrinkage defects based on given process parameters and the predictive capability of triangular and Gaussian membership functions was investigated. A pattern search algorithm was utilized to tune the developed predictive models. The resulting predictive model had root mean square error (RMSE) of 0.04, standard error of regression (S) of 9.6, and coefficient of determination (R2) of 98.7% for shrinkage prediction. The respective model metrics for warpage prediction were 0.005, 1.2, and 96.3%. The triangular membership function model had lower RMSE indicating a higher predictive accuracy whereas the Gaussian membership function model had lower S indicating a higher model reliability. Tuning of the predictive models using a pattern search algorithm reduced the RMSE and S and increased the models’ R2. The approach can be adopted by plastic processing industries to predict and control such (and related) defects for quality products and maximum productivity.},
  archive      = {J_JIM},
  author       = {Otieno, Steven O. and Wambua, Job M. and Mwema, Fredrick M. and Mharakurwa, Edwell T. and Jen, Tien-Chien and Akinlabi, Esther T.},
  doi          = {10.1007/s10845-024-02331-4},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1835-1859},
  shortjournal = {J. Intell. Manuf.},
  title        = {A predictive modelling strategy for warpage and shrinkage defects in plastic injection molding using fuzzy logic and pattern search optimization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart process mapping of powder bed fusion additively
manufactured metallic wicks using surrogate modeling. <em>JIM</em>,
<em>36</em>(3), 1819–1833. (<a
href="https://doi.org/10.1007/s10845-024-02330-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Powder bed fusion is an innovative additive manufacturing (AM) technique to achieve metallic wick structures for efficient two-phase thermal management systems. However, a technical challenge lies in the lack of standard process maps as it currently relies on an expensive trial and error approach. In this study, five types of surrogate models for classification analysis (i.e., naïve Bayes, logistic regression, random forest, support vector machine, and Gaussian process classification) were constructed and compared to efficiently unlock the relations between five process parameters (i.e., laser power, scan speed, hatch spacing, spot diameter, and effective laser energy) and wick manufacturability. The models were trained using data from a total of 187 AM wick manufacturability experiments. Using four process parameter (PP) model (five PP model without effective laser energy), the Gaussian process classification (GPC) showed the maximum median prediction accuracy (PA) of 93%, while it further improved to 99.7% using support vector machine (SVM) and five process parameter model. Also, the median PAs of the SVM and GPC remains above 98.5% with only 60% of the total experimental data using five PP model. The sensitivity analysis showed that the hatch spacing was the most sensitive parameter for the wick manufacturability using four PP model, while the effective laser energy is the most sensitive one using five PP model. This study provides insights into the smart selection of optimal process parameters for the desired metallic AM wicks.},
  archive      = {J_JIM},
  author       = {Borumand, Mohammad and Nannapaneni, Saideep and Madiraddy, Gurucharan and Sealy, Michael P. and Esfandiarpour Borujeni, Sima and Hwang, Gisuk},
  doi          = {10.1007/s10845-024-02330-5},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1819-1833},
  shortjournal = {J. Intell. Manuf.},
  title        = {Smart process mapping of powder bed fusion additively manufactured metallic wicks using surrogate modeling},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A kind of intelligent dynamic industrial event knowledge
graph and its application in process stability evaluation. <em>JIM</em>,
<em>36</em>(3), 1801–1818. (<a
href="https://doi.org/10.1007/s10845-024-02325-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event knowledge graph (EKG) is a method of representing real-world entities, events, their attributes, and the relations between them in a graph structure. The EKG has been applied in manufacturing industry to empower intelligence manufacturing. But there are limitations of generic EKG in addressing manufacturing issues. Because in the manufacturing industry, there is not only text-type knowledge but also signals, images, videos, etc. In particular, some of the relations between entities/events of the knowledge are in the form of formulas, functions, and even trained artificial intelligence models. This kind of knowledge is called Functional Knowledge in this paper. The generic EKG is suitable for representing text-type knowledge but not Functional Knowledge. Thus, the research aims to present a new kind of EKG that has the ability to represent various types of knowledge, especially Functional Knowledge. In this regard, an intelligent dynamic Industrial Event Knowledge Graph (IEKG) is proposed. Firstly, Functional Relation, Functional Triple, and a knowledge representation model based on property graphs for the schema layer of IEKG are proposed for representing Functional Knowledge. Secondly, a dynamic construction method of the instance layer of IEKG based on the event triggering mechanism is proposed, which enables the IEKG to be constructed dynamically with the production operation. Third, the constructed IEKG is applied in production monitoring using a novel graph similarity-based process stability evaluation method. Finally, a web application encapsulating our theory was developed and applied on a kneading machine in a prebaked carbon anode factory. The result shows that our proposed method has the ability to represent Functional Knowledge. Compared to the existing EKG, it has a better and broader ability of knowledge representation. The application of process stability evaluation demonstrates the potential of IEKG in addressing manufacturing issues.},
  archive      = {J_JIM},
  author       = {Li, Qingzong and Jiang, Pingyu and Wang, Jianwei and Yang, Maolin and Yang, Yuqian},
  doi          = {10.1007/s10845-024-02325-2},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1801-1818},
  shortjournal = {J. Intell. Manuf.},
  title        = {A kind of intelligent dynamic industrial event knowledge graph and its application in process stability evaluation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fidelity-adaptive evolutionary optimization algorithm for 2D
irregular cutting and packing problem. <em>JIM</em>, <em>36</em>(3),
1781–1799. (<a
href="https://doi.org/10.1007/s10845-024-02329-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cutting and packing problems (CPP) widely appear in various industrial fields, such as additive manufacturing (AM) and the fashion industry. The evolutionary optimization (EO) algorithms inspired by biological evolution are popular to solve such combinatorial optimization problems these years. Most of the research focused on the improvement of nesting strategies (NS) and EO algorithms, while the relationship between NSs and evolutionary optimization stages is the neglected crucial point. In this paper, a fidelity-adaptive evolution optimization (FAEO) method is proposed to speed up the optimization process by using different nesting strategies at the appropriate optimization stages. In FAEO methods, two switching methods are designed to convert NSs. The neighbourhood-elite evaluation (NEE) and staged-archive (S-A) methods are developed to accelerate individual internal assessment. The experimental results and relevant analysis of the cases from ESICUP by the combination of genetic algorithm (GA) and skyline-derived NSs prove the effectiveness, rapidity, and industrial value of the FAEO algorithm compared with the benchmark algorithms.},
  archive      = {J_JIM},
  author       = {Yang, Yizhe and Liu, Bingshan and Li, Xin and Jia, Qingfeng and Duan, Wenyan and Wang, Gong},
  doi          = {10.1007/s10845-024-02329-y},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1781-1799},
  shortjournal = {J. Intell. Manuf.},
  title        = {Fidelity-adaptive evolutionary optimization algorithm for 2D irregular cutting and packing problem},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collaborative optimization of manufacturing service
allocation via multi-task transfer learning evolutionary approach.
<em>JIM</em>, <em>36</em>(3), 1761–1779. (<a
href="https://doi.org/10.1007/s10845-024-02339-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial internet platforms are regarded as an emerging fashion for the flexible integration of production resources located in multiple sites to complete complicated tasks submitted by users. Manufacturing Service Composition (MSC) is an essential technique that supports the optimal construction of value-added services. Evolutionary computation approaches are frequently employed to resolve MSC issues and have achieved great accomplishments. These evolutionary solvers, however, require massive computational resources for objective evaluation and face cold-start problem. Recent advances in transfer learning field provide a new means for extracting knowledge across tasks to enhance the problem-solving efficiency. In light of above, this article is intended to devise a Multi-task Transfer Evolutionary Search (MTES) approach for MSC considering the occurrence of multiple user requests, with which each corresponds to a MSC task, optimization experiences from constructing distinct MSC tasks can be learned to promote the search of arrival tasks at hand jointly. The MTES can adapt the helper task selection and the intensity of knowledge transfer from a synergistic perspective, such that it can be suitable for many-task scenario. Numerical studies on different scales of MSC tasks demonstrate that, compared to the prevalent peers, our proposed MTES needs far less computational resources to achieve the convergence performance and the solution quality is higher, which verifies the applicability and effectiveness of the proposed approach for dealing with MSC problem.},
  archive      = {J_JIM},
  author       = {Zhou, Jiajun and Gao, Liang and Lu, Chao and Yao, Xifan},
  doi          = {10.1007/s10845-024-02339-w},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1761-1779},
  shortjournal = {J. Intell. Manuf.},
  title        = {Collaborative optimization of manufacturing service allocation via multi-task transfer learning evolutionary approach},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach to enhance defect detection in wire arc
additive manufacturing parts using radiographic testing without surface
milling. <em>JIM</em>, <em>36</em>(3), 1743–1760. (<a
href="https://doi.org/10.1007/s10845-024-02328-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wire arc additive manufacturing (WAAM) process is gaining popularity in industrial production due to its ability to manufacture large, customized, and complex shapes. However, because of the lack of quality assurance standards in this field, non-destructive testing (NDT) methods are required to evaluate the quality of the produced parts. Radiography testing is a good candidate for that purpose, but the surface roughness of the product being tested can lead to difficulties in the interpretation of the obtained image, which could result in unseen defects. To overcome this challenge, we propose, in this study, a novel approach for improving defect detectability using 3D laser scanning and an appropriate mathematical formulation. We first tested this approach on a weld bead and then verified it on different healthy and defective WAAM parts. In all cases, the created defects were successfully detected. Besides, the effect of surface roughness was significantly reduced. A special attention should, however, be paid to the scattering noise in the radiographic image.},
  archive      = {J_JIM},
  author       = {El Mountassir, Mahjoub and Flotte, Didier and Yaacoubi, Slah and Riff, Eric and Ferrari, Morgan and Chauveau, Daniel and Bourlet, Clément and Bernet, Sacha},
  doi          = {10.1007/s10845-024-02328-z},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1743-1760},
  shortjournal = {J. Intell. Manuf.},
  title        = {A novel approach to enhance defect detection in wire arc additive manufacturing parts using radiographic testing without surface milling},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human–machine knowledge hybrid augmentation method for
surface defect detection based few-data learning. <em>JIM</em>,
<em>36</em>(3), 1723–1742. (<a
href="https://doi.org/10.1007/s10845-023-02270-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual-based defect detection is a crucial but challenging task in industrial quality control. Most mainstream methods rely on large amounts of existing or related domain data as auxiliary information. However, in actual industrial production, there are often multi-batch, low-volume manufacturing scenarios with rapidly changing task demands, making it difficult to obtain sufficient and diverse defect data. This paper proposes a parallel solution that uses a human–machine knowledge hybrid augmentation method to help the model extract unknown important features. Specifically, by incorporating experts&#39; knowledge of abnormality to create data with rich features, positions, sizes, and backgrounds, we can quickly accumulate an amount of data from scratch and provide it to the model as prior knowledge for few-data learning. The proposed method was evaluated on the magnetic tile dataset and achieved F1-scores of 60.73%, 70.82%, 77.09%, and 82.81% when using 2, 5, 10, and 15 training images, respectively. Compared to the traditional augmentation method&#39;s F1-score of 64.59%, the proposed method achieved an 18.22% increase in the best result, demonstrating its feasibility and effectiveness in few-data industrial defect detection.},
  archive      = {J_JIM},
  author       = {Gong, Yu and Wang, Xiaoqiao and Zhou, Chichun and Ge, Maogen and Liu, Conghu and Zhang, Xi},
  doi          = {10.1007/s10845-023-02270-6},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1723-1742},
  shortjournal = {J. Intell. Manuf.},
  title        = {Human–machine knowledge hybrid augmentation method for surface defect detection based few-data learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision based process monitoring in wire arc additive
manufacturing (WAAM). <em>JIM</em>, <em>36</em>(3), 1711–1721. (<a
href="https://doi.org/10.1007/s10845-023-02287-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A stable welding process is crucial to obtain high quality parts in wire arc additive manufacturing. The complexity of the process makes it inherently unstable, which can cause various defects, resulting in poor geometric accuracy and material properties. This demands for in-process monitoring and control mechanisms to industrialize the technology. In this work, process monitoring algorithms based on welding camera image analysis are presented. A neural network for semantic segmentation of the welding wire is used to monitor the working distance as well as the horizontal position of the wire during welding and classic image processing techniques are applied to capture spatter formation. Using these algorithms, the process stability is evaluated in real time and the analysis results enable the direction independent closed-loop-control of the manufacturing process. This significantly improves geometric fidelity as well as mechanical properties of the fabricated part and allows the automated production of parts with complex deposition paths including weld bead crossings, curvatures and overhang structures.},
  archive      = {J_JIM},
  author       = {Franke, Jan and Heinrich, Florian and Reisch, Raven T.},
  doi          = {10.1007/s10845-023-02287-x},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1711-1721},
  shortjournal = {J. Intell. Manuf.},
  title        = {Vision based process monitoring in wire arc additive manufacturing (WAAM)},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation-based metaheuristic optimization algorithm for
material handling. <em>JIM</em>, <em>36</em>(3), 1689–1709. (<a
href="https://doi.org/10.1007/s10845-024-02327-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern technologies and the emergent Industry 4.0 paradigm have empowered the emergence of flexible production systems suitable to cope with custom product demands, typical in this era of competitive marketplaces. However, production flexibility claims periodic changes in the setup of production facilities. The level of flexibility of a production process increases as the reconfiguration capacity of its facilities increases. Nevertheless, doing that efficiently requires accurate coordination between productive resources, task planning, and decision-making systems aiming to maximize value for the client, minimizing non-added-value production tasks, and continuous process improvement. In a manufacturing system, material handling within manufacturing facilities is one of the major non-value-added tasks strongly affected by changes in plant floor layouts and demands for producing customized products. This work proposes a metaheuristic simulation-based optimization methodology to address the material handling problem in dynamic environments. Our proposed approach integrates optimization, discrete event simulation, and artificial intelligence methods. Our proposed optimization algorithm is mainly based on the ideas of the novel population-based optimization algorithm called Q-learning embedded Sine Cosine Algorithm, inspired by the Sine Cosine Algorithm. Unlike those, our proposed approach can deal with discrete optimization problems. It includes in its formulation a reinforcement learning embedded algorithm for the self-learning of the parameters of the metaheuristic optimization algorithm, and discrete event simulation is used for simulating the shop floor operations. The performance of the proposed approach is evaluated through an exhaustive analysis of simple to complex cases. In addition, a comparison is made with other comparable optimization methodologies.},
  archive      = {J_JIM},
  author       = {Saavedra Sueldo, Carolina and Perez Colo, Ivo and De Paula, Mariano and Villar, Sebastián A. and Acosta, Gerardo G.},
  doi          = {10.1007/s10845-024-02327-0},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1689-1709},
  shortjournal = {J. Intell. Manuf.},
  title        = {Simulation-based metaheuristic optimization algorithm for material handling},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A digital twin-assisted deep transfer learning method
towards intelligent thermal error modeling of electric spindles.
<em>JIM</em>, <em>36</em>(3), 1659–1688. (<a
href="https://doi.org/10.1007/s10845-023-02283-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thermal error modeling (TEM) is essential for preserving machining accuracy and enhancing the reliability of electric spindle systems. However, the major challenges in TEM lie in the limited or unavailable labeled thermal error samples due to the difficulties in data acquisition, as well as the problem of large distribution discrepancy between training and testing data under variable working conditions. Recently, digital twin (DT) has emerged as a promising tool in intelligent manufacturing. The DT model of the electric spindle can simulate system thermal behavior data that closely resembles real working conditions, providing a remarkable opportunity for TEM. Additionally, deep transfer learning (DTL) leverages existing knowledge to minimize data distribution discrepancies, bridging the gap between virtual and real data, and ultimately enhancing the generalization and adaptation ability of the model. Thus, this paper proposes a DT-assisted DTL method for TEM of electric spindles. Firstly, the DT model for the electric spindle is built by establishing a high-fidelity simulation model based on the physical system’s thermal behavior mechanism. Furthermore, temperature field information for all interested working conditions can be simulated from the constructed DT model. Subsequently, the distance-guided domain adversarial network (DGDAN) is developed, with data generated by the DT model constructed as the training data in the source domain, while partially collected data from the physical system is used as the target domain for training. To validate the effectiveness of the proposed method, a case study is conducted using datasets from both the DT model and the physical system. The experimental results demonstrate that the proposed method successfully achieves TEM in scenarios where the thermal error data is limited or unavailable from the physical system, and the goodness of fit is higher than the state-of-the-art methods by 11.73%.},
  archive      = {J_JIM},
  author       = {Ma, Shuai and Leng, Jiewu and Zheng, Pai and Chen, Zhuyun and Li, Bo and Li, Weihua and Liu, Qiang and Chen, Xin},
  doi          = {10.1007/s10845-023-02283-1},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1659-1688},
  shortjournal = {J. Intell. Manuf.},
  title        = {A digital twin-assisted deep transfer learning method towards intelligent thermal error modeling of electric spindles},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical language processing for prognostics and health
management: Applying text similarity and topic modeling to maintenance
work orders. <em>JIM</em>, <em>36</em>(3), 1637–1657. (<a
href="https://doi.org/10.1007/s10845-024-02323-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern manufacturing paradigms have incorporated Prognostics and Health Management (PHM) to implement data-driven methods for fault detection, failure prediction, and assessment of system health. The maintenance operation has similarly benefitted from these advancements, and predictive maintenance is now being used across the industry. Despite these developments, most of the approaches in maintenance rely on numerical data from sensors and field devices for any sort of analysis. Text data from Maintenance Work Orders (MWOs) contain some of the most crucial information pertaining to the functioning of systems and components, but are still regarded as ‘black holes’, i.e., they store valuable data without being used in decision-making. The analysis of this data can help save time and costs in maintenance. While Natural Language Processing (NLP) methods have been very successful in understanding and examining text data from non-technical sources, progress in the analysis of technical text data has been limited. Non-technical text data are usually structured and consist of standardized vocabularies allowing the use of out-of-the-box language processing methods in their analysis. On the other hand, records from MWOs are often semi-structured or unstructured; and consist of complicated terminologies, technical jargon, and industry-specific abbreviations. Deploying traditional NLP to such data can result in an imprecise and flawed analysis which can be very costly. Owing to these challenges, we propose a Technical Language Processing (TLP) framework for PHM. To illustrate its capabilities, we use text data from MWOs of aircraft to address two scenarios. First, we predict corrective actions for new maintenance problems by comparing them with existing problems using syntactic and semantic textual similarity matching and evaluate the results with cosine similarity scores. In the second scenario, we identify and extract the most dominant topics and salient terms from the data using Latent Dirichlet Allocation (LDA). Using the results, we are able to successfully link maintenance problems to standardized maintenance codes used in the aviation industry.},
  archive      = {J_JIM},
  author       = {Sundaram, Sarvesh and Zeid, Abe},
  doi          = {10.1007/s10845-024-02323-4},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1637-1657},
  shortjournal = {J. Intell. Manuf.},
  title        = {Technical language processing for prognostics and health management: Applying text similarity and topic modeling to maintenance work orders},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An embedded TensorFlow lite model for classification of chip
images with respect to chip morphology depending on varying feed.
<em>JIM</em>, <em>36</em>(3), 1623–1635. (<a
href="https://doi.org/10.1007/s10845-023-02320-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Turning is one of the fundamental machining processes used to produce superior machine parts. It is critical to manage the machining conditions to maintain the desired properties of the final product. Chip morphology and chip control are crucial factors to be monitored. In particular, the selection of an appropriate feed has one of the most significant effects. On the other hand, machine learning is an advanced approach that is continuously evolving and helping many industries. Moreover, mobile applications with learning models have been deployed in the field, recently. Taking these motivations into account, in this study, we propose a practical mobile application that includes an embedded learning model to provide chip classification based on chip morphology. For this purpose, a dataset of chips with different morphological properties is obtained and manually labeled according to ISO 3685 standards by using 20 different feeds on AISI 4140 material. Accordingly, TensorFlow Lite is used to train a learning model, and the model is embedded into a real-time Android mobile application. Eventually, the final software is evaluated through experiments conducted on the dataset and in the field, respectively. According to the evaluation results, it can be stated that the learning model is able to predict chip morphology with a test accuracy of 85.4%. Moreover, the findings obtained from the real-time mobile application satisfy the success rate by practical usage. As a result, it can be concluded that such attempts can be utilized in the turning process to adjust the relevant feed conditions.},
  archive      = {J_JIM},
  author       = {Özçevik, Yusuf and Sönmez, Fikret},
  doi          = {10.1007/s10845-023-02320-z},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1623-1635},
  shortjournal = {J. Intell. Manuf.},
  title        = {An embedded TensorFlow lite model for classification of chip images with respect to chip morphology depending on varying feed},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing spatiotemporal predictive learning: An approach
with nested attention module. <em>JIM</em>, <em>36</em>(3), 1603–1621.
(<a href="https://doi.org/10.1007/s10845-023-02318-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal predictive learning is a deep learning method that generates future frames from historical frames in a self-supervised manner. Existing studies face the challenges in capturing long-term dependencies and producing accurate predictions over extended time horizons. To address these limitations, this paper introduces a nested attention module as a special attention mechanism to capture spatiotemporal correlations of input historical frames. Nested attention module decomposes temporal attention into inter-frame channel attention and spatiotemporal attention and uses a nested attention mechanism to capture long-term temporal dependencies, which improves the model’s performance and generalization ability. Furthermore, to prevent overfitting in models, a new regularization method is proposed which considers both the intra-frame spatial error and the inter-frame temporal evolution error of sequence frames, and enhances the robustness of the reinforcement learning model to dropout operations. The proposed model achieves state-of-the-art performance on four baseline datasets, including moving MNIST handwritten digit dataset, human 3.6 million dataset, sea surface temperature dataset, and karlsruhe institute of technology and Toyota technological institute dataset. Extended experiments demonstrate the generalization and extensibility of nested attention module on real-world datasets. A dramatic 31.7% mean squared error/26.9% mean absolute error reduction is achieved when predicting 10 frames on moving MNIST. Our proposed model provides a new baseline for future research in spatiotemporal predictive learning tasks.},
  archive      = {J_JIM},
  author       = {Wang, Shaoping and Han, Ren},
  doi          = {10.1007/s10845-023-02318-7},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1603-1621},
  shortjournal = {J. Intell. Manuf.},
  title        = {Enhancing spatiotemporal predictive learning: An approach with nested attention module},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Union channel pruning-based U2Net for online surface defect
segmentation of aluminum strips in production processes. <em>JIM</em>,
<em>36</em>(3), 1579–1602. (<a
href="https://doi.org/10.1007/s10845-023-02317-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automated defect inspection (ADI) of aluminum strip surfaces encounters several issues in the practical production process, such as the challenge of achieving precise defect boundary identification and the high demands for model volume and real-time inference. To solve these problems, the inference process of Input-Conv-BN-ReLU-Output in every layer of the high-precision segmentation model U2Net is fully analyzed and a novel union channel pruning (UCP) algorithm based on the U2Net is designed to significantly simplify the model structure. The absolute values of the convolution weights in the channel are first added up as the first indicator. Then the expectation of the truncated Gaussian distribution that processed by the batch normalization (BN) layer and ReLU activation layer is calculated as the second indicator because it makes reasonable use of the scale factor, shift factor, and interval information. The two indicators are multiplied as the final evaluation indicator, which realizes the comprehensive consideration of the Input-Conv-BN-ReLU-Output in U2Net. Additionally, we collect the surface images of aluminum strips from the online inspection platform and create a new dataset with seven common defects. Experimental findings obtained on the dataset demonstrate that the UCP performs better than other network slimming approaches, especially at high pruning ratios. The U2Net with 62.5% of channels pruned by the UCP method surpasses other cutting-edge and lightweight segmentation models in segmentation accuracy and speed, which may serve as a valuable theoretical guidance for the automated online defect segmentation of aluminum strips on embedded devices.},
  archive      = {J_JIM},
  author       = {Lv, Zehua and Li, Yibo and Qian, Siying and Wu, Liuqing and Yang, Yi},
  doi          = {10.1007/s10845-023-02317-8},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1579-1602},
  shortjournal = {J. Intell. Manuf.},
  title        = {Union channel pruning-based U2Net for online surface defect segmentation of aluminum strips in production processes},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-domain fusion and embedded refinement-based 6D object
pose tracking on textureless objects. <em>JIM</em>, <em>36</em>(3),
1563–1577. (<a
href="https://doi.org/10.1007/s10845-023-02316-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial production, the ability to accurately perceive the location and orientation information of target objects enables the generalization of certain production processes to unstructured scenarios, thereby facilitating intelligent manufacturing. 6D object pose tracking aims to achieve real-time, accurate and long-term pose estimation given a video sequence. In this paper, we introduce a novel RGB-based 6D object pose tracking method that leverages temporal information. Our approach mainly involves building a network to predict the pose residual between two consecutive image frames. Given industrial objects with weak textures and complex shapes, we incorporate a cross-domain attention fusion module during the feature fusion phase, enabling the capture of pixel-level correspondences between different feature representations. This module enhances robustness to illumination variations and occlusion challenges. Additionally, we propose a simple yet effective pose regression module, referred to as the embedded refinement module, which considers the deviation of previous pose estimations. This module mitigates the cumulative pose estimation deviation due to large movements to some extent. We conduct comparative experiments on the YCB dataset, Fast-YCB dataset and a customized dataset specifically designed for the manipulation of industrial parts by a robotic arm. The results demonstrate that our proposed method surpasses state-of-the-art techniques, achieving robust and long-term tracking capabilities.},
  archive      = {J_JIM},
  author       = {Wang, Jichun and Duan, Guifang and Wang, Yang and Yi, Guodong and Dong, Liangyu and Wang, Zili and Zhang, Xuewei and Zhang, Shuyou},
  doi          = {10.1007/s10845-023-02316-9},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1563-1577},
  shortjournal = {J. Intell. Manuf.},
  title        = {Cross-domain fusion and embedded refinement-based 6D object pose tracking on textureless objects},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent factory layout design framework through
collaboration between optimization, simulation, and digital twin.
<em>JIM</em>, <em>36</em>(3), 1547–1561. (<a
href="https://doi.org/10.1007/s10845-024-02340-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of the fourth industrial revolution, various internet and communications technologies (ICTs) are being applied to manufacturing systems. Based on these technologies, many companies utilize smart manufacturing systems to optimize the design and operation of their lines and to diagnose failures. To build and/or improve production lines, various computer-aided engineering (CAE) tools such as optimization solvers and simulation tools for validation are required. In addition, experts depend on their experience or utilize numerous trial and error processes, implying that a large time investment is required obtain the best layout design, without any guarantee that the result is in fact the best. Therefore, the paper proposes an integrated intelligent layout design framework that automatically derives an optimal layout according the requirements of the layout. The proposed framework uses mixed integer linear programming, simulation-based optimization, and digital twin to perform processes such as assembly line balancing, cell/buffer optimization, and layout planning sequentially and repeatedly to derive an optimal layout. By applying this, it is possible to automatically derive the optimal layout design considering limited resources and physical constraints. In addition, it can contribute to improving productivity and work efficiency at manufacturing sites.},
  archive      = {J_JIM},
  author       = {Choi, Seon Han and Kim, Byeong Soo},
  doi          = {10.1007/s10845-024-02340-3},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1547-1561},
  shortjournal = {J. Intell. Manuf.},
  title        = {Intelligent factory layout design framework through collaboration between optimization, simulation, and digital twin},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relational network of innovation ecosystems generated by
digital innovation hubs: A conceptual framework for the interaction
processes of DIHs from the perspective of collaboration within and
between their relationship levels. <em>JIM</em>, <em>36</em>(3),
1505–1545. (<a
href="https://doi.org/10.1007/s10845-024-02322-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaboration plays a key role in the success attained to date by networks of innovation ecosystems generated around entities known as Digital Innovation Hubs (DIHs), recently created following European Commission initiatives to boost the digitisation of the European economic fabric. This article proposes a conceptual framework that brings together, defines, structures and relates the concepts involved in the collaborative interaction processes within and between these innovation ecosystems to allow comprehensive conceptualisation. The developed framework also provides an approach that helps to tangibilise collaboration as a management process. Here the goal is to ultimately move towards not only qualitative, but also quantitative modelling to bridge the research gap in the state of the art in this respect. The data-driven business-ecosystem-skills-technology (D-BEST) model, devised to configure DIHs service portfolios in a collaborative context, provides the reference basis for the interorganisational asset transfer methodology (IOATM). This is the keystone that structures the framework and constitutes its main contribution. Through the IOATM, this conceptual framework points out collaboration quantification, and serves as a lever for its modelling to deal with collaboration accounting by: turning it into a more controllable management element; guiding practitioners&#39; efforts to improve collaborative processes efficiency with an approach that pursues objectivity and maximises synergies.},
  archive      = {J_JIM},
  author       = {Serrano-Ruiz, Julio C. and Ferreira, José and Jardim-Goncalves, Ricardo and Ortiz, Ángel},
  doi          = {10.1007/s10845-024-02322-5},
  journal      = {Journal of Intelligent Manufacturing},
  month        = {3},
  number       = {3},
  pages        = {1505-1545},
  shortjournal = {J. Intell. Manuf.},
  title        = {Relational network of innovation ecosystems generated by digital innovation hubs: A conceptual framework for the interaction processes of DIHs from the perspective of collaboration within and between their relationship levels},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jirs---42">JIRS - 42</h2>
<ul>
<li><details>
<summary>
(2025). Monocular depth estimation applied to global localization
over 2D floor plans using free space density. <em>JIRS</em>,
<em>111</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-024-02131-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Indoor global localization is a critical aspect of autonomous robotic navigation. The increasing demand for service consumer-grade robots that require self-localization calls for research on methods that work with easy setup and low-cost sensors. In this paper, we propose a monocular camera-based localization of a motorized wheeled robot using a 2D floor plan as a reference map. The innovation of our method lies in using depth maps estimated from monocular images to compute the free space around the robot to be used as a measurement model in a particle filter strategy. The estimated free space density is compared to the free space density extracted from particles in the 2D floor plan. Due to the inherent imperfections of estimated depth maps, we also propose a new particle weighting approach to account for uncertainties in the depth estimation from the monocular camera. Experiments performed using real-world scenario sequences of images comparing the proposed method with RGB-D camera-based approaches demonstrate the effectiveness of the method, even for imperfect depth maps obtained with the monocular depth estimation model.},
  archive      = {J_JIRS},
  author       = {Lopes, Cristian and Maffei, Renan and Kolberg, Mariana},
  doi          = {10.1007/s10846-024-02131-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Monocular depth estimation applied to global localization over 2D floor plans using free space density},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Human factors and AI in UAV systems: Enhancing operational
efficiency through AHP and real-time physiological monitoring.
<em>JIRS</em>, <em>111</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s10846-024-02188-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating Artificial Intelligence (AI) into Unmanned Aerial Vehicle (UAV) operations has advanced efficiency, safety, and decision-making. This study addresses critical gaps in UAV methods, including insufficient integration of human factors, operator variability, and the lack of systematic error analysis. To overcome these challenges, a novel approach combines the Analytic Hierarchy Process (AHP) with three core human factors models: the Observe-Orient-Decide-Act (OODA) loop, the Human Factors Analysis and Classification System (HFACS), and the SHELL model. An online survey was conducted across diverse UAV operator groups to prioritize critical factors within each model. Additionally, real-time monitoring of heart rate (HR), heart rate variability (HRV), and respiratory rate (RR) was conducted during UAV operations at various automation levels with different experience levels. Visualization through boxplots and percentage change matrices provided insights into operator stress and workload across automation levels. Integrating AHP findings and physiological data revealed significant differences in operator prioritization, highlighting the need for tailored AI-UAV strategies. This research combines survey data with real-time physiological monitoring, offering visions into optimizing human-AI interaction in UAV operations and providing a foundation for improving AI integration and operator strategies.},
  archive      = {J_JIRS},
  author       = {Alharasees, Omar and Kale, Utku},
  doi          = {10.1007/s10846-024-02188-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-34},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Human factors and AI in UAV systems: Enhancing operational efficiency through AHP and real-time physiological monitoring},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling and dynamic analysis of fish robot with soft
fluidic actuation. <em>JIRS</em>, <em>111</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s10846-024-02196-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A biomimetic robotic fish tailored for environmental monitoring and hydrographic exploration is examined in this study. Traditional fish robots, driven by tail oscillations, often grapple with constrained maneuverability in a single plane. This article focuses on mitigating these limitations through an exploration of the dynamic behavior of a bioinspired soft robotic fish. Unlike prior designs that employed similar actuators for the robot&#39;s tail, which either lacked the ability for out-of-plane motion or relied on other propulsion systems, the single propulsion design proposed in our model enables movement along three-dimensional trajectories, leading to improved efficiency and maneuverability due to tail oscillation dynamics. The proposed design integrates strategically positioned nozzles for out-of-plane movements, alongside parallel fluid channels on the tail&#39;s neutral plate. Actuation is achieved by manipulating the internal fluid pressure within these channels. To precisely model tail deflection, we introduce a novel method utilizing Euler–Bernoulli beam theory considering nonlinear characteristics arising from internal fluid stress. For instance, following the proposed approximate analytical method, we optimize the fluidic actuator, considering that the soft tail deformation increases by 65% as the channel shape transitions from a semicircular to a square cross-section. The comprehensive comparison with analytical nonlinear method, finite element method, and experimental-driven analytical method extends our approach as an effective tool in terms of accuracy and computation time, demonstrating the effectiveness of validation processes. This study unveils a simplified and robust fish robot design, outperforming traditional mechanisms in efficacy. Despite its simplicity, the proposed design delivers comparable performance, presenting an effective alternative for achieving requisite functionality in fish robots.},
  archive      = {J_JIRS},
  author       = {Bamdad, Mahdi and Karimi, Ahmad and Sina, Seyedali and Cruz, Francisco},
  doi          = {10.1007/s10846-024-02196-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-21},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Modeling and dynamic analysis of fish robot with soft fluidic actuation},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path planning for the robotic manipulator in dynamic
environments based on a deep reinforcement learning method.
<em>JIRS</em>, <em>111</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02205-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative and autonomous robots are increasingly important in meeting the demands of a faster and more cost-effective market. To ensure production efficiency and safety, robots must swiftly respond to the presence of human operators or other dynamic obstacles, avoiding potential collisions by quickly planning alternative paths. Deep Reinforcement Learning (DRL) based methods have shown great potential in path planning due to their rapid response capabilities. However, existing DRL-based planners lack a safety verification system to evaluate the feasibility of actions generated by neural models, and they cannot guarantee 100% collision-free paths. This paper presents an enhanced DRL-based path planning system incorporating a robust safety verification mechanism. This system predicts potential collisions and generates alternative collision-free paths as necessary. We analyzed the essential elements of trajectory planning using the DRL method and proposed improvements to accelerate planning speed. The results demonstrate that our planner consistently generates paths for typical reaching tasks with an average planning time of 12.1 ms, a notable improvement over traditional algorithms. Moreover, the paths produced by our method are nearly optimal, akin to those generated by Optimization-based algorithms.},
  archive      = {J_JIRS},
  author       = {Liu, Jie and Yap, Hwa Jen and Khairuddin, Anis Salwa Mohd},
  doi          = {10.1007/s10846-024-02205-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Path planning for the robotic manipulator in dynamic environments based on a deep reinforcement learning method},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). JIRS editorial, 4th quarter 2024. <em>JIRS</em>,
<em>111</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s10846-024-02208-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIRS},
  author       = {Valavanis, Kimon P.},
  doi          = {10.1007/s10846-024-02208-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-2},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {JIRS editorial, 4th quarter 2024},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive velocity control for UAV boat landing: A neural
network and particle swarm optimization approach. <em>JIRS</em>,
<em>111</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10846-024-02201-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving precise landing of Unmanned Aerial Vehicles (UAVs) onto moving platforms, such as Autonomous Surface Vehicles (ASVs), is challenging, particularly in GPS-denied environments with dynamic disturbances. Conventional methods often rely on high-level waypoint navigation, extensive manual tuning, and expensive sensors. In this work, we propose an adaptive Proportional-Integral-Derivative (PID) controller optimization using a Neural Network-Particle Swarm Optimization (NN-PSO) algorithm. The algorithm dynamically tunes the PID controller, significantly reducing manual tuning effort, while relying solely on a low-cost camera and altitude sensor. The NN-PSO algorithm allows the UAV to land with an average error of 5 cm on static platforms and 10 cm on moving boats, based on multiple test flights. Our method also increases the maximum landing speed to 80.9% of the UAV’s top flight speed, a considerable improvement over existing systems. Our approach not only optimizes landing precision but also introduces techniques for ensuring soft landings, reducing oscillations, and preventing target misses. These enhancements make the method robust across varying flight altitudes and ASV speeds. Furthermore, this approach is applicable to a variety of GPS-denied scenarios, including rescue missions, package deliveries, and workspace inspections, without requiring costly equipment or extensive parameter tuning. Field experiments confirm the precision and stability of the proposed system, validating its performance in real-world conditions. [Video]},
  archive      = {J_JIRS},
  author       = {Wu, Li-Fan and Wang, Zihan and Rastgaar, Mo and Mahmoudian, Nina},
  doi          = {10.1007/s10846-024-02201-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Adaptive velocity control for UAV boat landing: A neural network and particle swarm optimization approach},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe multi-agent reinforcement learning via approximate
hamilton-jacobi reachability. <em>JIRS</em>, <em>111</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s10846-024-02156-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Reinforcement Learning (MARL) promises to address the challenges of cooperation and competition among multiple agents, often involving safety-critical scenarios. However, realizing safe MARL remains a domain of limited progress. Current works extend single-agent safe learning approaches, employing shielding or backup policies to ensure safety satisfaction. Nevertheless, these approaches require good cooperation among multiple agents, and weakly distributed approaches with centralized shielding become infeasible when agents encounter complex situations such as non-cooperative agents and coordination failures. In this paper, we integrate the Hamilton-Jacobi (HJ) reachability theory and present a Centralized Training and Decentralized Execution (CTDE) framework for Safe MARL. Our framework enables the learning of safety policies without the need for system model or shielding layer pre-training. Additionally, we enhance adaptability to varying levels of cooperation through a conservative approximation estimation of the value function. Experimental results validate the efficacy of our proposed method, demonstrating its ability to ensure safety while successfully achieving target tasks under cooperative conditions. Furthermore, our approach exhibits robustness in the face of non-cooperative behaviors induced by complex disturbance factors.},
  archive      = {J_JIRS},
  author       = {Zhu, Kai and Lan, Fengbo and Zhao, Wenbo and Zhang, Tao},
  doi          = {10.1007/s10846-024-02156-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Safe multi-agent reinforcement learning via approximate hamilton-jacobi reachability},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RDynaSLAM: Fusing 4D radar point clouds to visual SLAM in
dynamic environments. <em>JIRS</em>, <em>111</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02204-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of visual SLAM systems, in terms of both robustness and accuracy, can be affected by the presence of dynamic objects in dynamic environments. The utilization of learning-based dynamic SLAM algorithms introduces additional challenges, such as increased power consumption and computing requirements, particularly on mobile platforms. Millimeter wave radar has the capability to directly detect and measure the relative velocity between objects and the radar system. Therefore, this paper presents a novel SLAM system that aims to integrate millimeter wave radar point clouds into visual SLAM in a dynamic environment. First, a real-time dynamic cluster extraction method was developed using Doppler information obtained from 4D radar. It effectively distinguishes between static background points and dynamic points by employing the RANSAC algorithm. The dynamic radar points are subsequently grouped together to create dynamic clusters. Then, the clusters are projected onto the image and expand to produce dynamic masks, taking into account the distribution characteristics. Finally, dynamic masks are employed to eliminate dynamic keypoints during the camera pose estimation, allowing for the estimation to be based solely on static keypoints. Experiments conducted in various daily dynamic scenarios have demonstrated the robustness of RDynaSLAM in operating effectively within dynamic environments. In comparison to ORBSLAM3, RDynaSLAM exhibits a notable reduction in the Root Mean Square Error (RMSE) of Absolute Pose Error (APE) and Relative Pose Error (RPE) in high dynamic environments. The method proposed in this paper has the capability to operate in real-time, without the need for GPU utilization.},
  archive      = {J_JIRS},
  author       = {Zhu, Dongying and Yang, Guanci},
  doi          = {10.1007/s10846-024-02204-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {RDynaSLAM: Fusing 4D radar point clouds to visual SLAM in dynamic environments},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of unmanned vehicle control with adaptive dynamic
programming implementations. <em>JIRS</em>, <em>111</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10846-024-02207-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this review, the optimal control designs via adaptive dynamic programming (ADP) of unmanned vehicles are investigated. Various complex tasks in unmanned systems are addressed as fundamental optimal regulation and tracking control problems related to the position and attitude of vehicles. The optimal control can be obtained by solving the Hamilton-Jacobi-Bellman equation using ADP-based control methods. Neural network implementations and policy iterative ADP algorithms are common approaches in ADP-based control methods, enabling online updates and partially model-free control for unmanned vehicles with various structures. For complexities and uncertain disturbances in unmanned vehicle dynamics, robust ADP-based control methods are proposed, including robust ADP control for matched and unmatched uncertainties, robust guaranteed cost control with ADP, and ADP-based $$H_\infty $$ control. In order to reduce communication and computational costs in unmanned vehicle operations, a preliminary discussion on event-triggered optimal control using ADP-based control methods is presented.},
  archive      = {J_JIRS},
  author       = {Liu, Hao and Yi, Xinning and Liu, Deyuan and Valavanis, Kimon P.},
  doi          = {10.1007/s10846-024-02207-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A review of unmanned vehicle control with adaptive dynamic programming implementations},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous drone detection and classification using computer
vision and prony algorithm-based frequency feature extraction.
<em>JIRS</em>, <em>111</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s10846-024-02216-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a practical and automated system for high-accuracy drone detection and classification using acoustic signals. Our approach leverages a novel frequency feature extraction method based on the Prony algorithm, which enables efficient detection and classification of drones. To assess the effectiveness of our proposed method, we conducted experiments on a new suitable database of recorded drone audio in natural environments and under different conditions, which we meticulously prepared. Furthermore, we compared the performance of our proposed method against conventional audio features, such as Mel Frequency Cepstral Coefficients (MFCCs), Gamma Tone Cepstral Coefficients (GTCCs), and Fast Fourier Transform (FFT). Our experimental results demonstrate that our proposed method achieves a remarkable accuracy of more than 97.7% for detection and 93.6% for classification, outperforming traditional audio features, which provide less than 80% accuracy for classification. This classification accuracy is crucial for designing a suitable system to manage drones. Additionally, we highlight the crucial advantage and efficiency of our proposed method for an unknown drone, which is particularly valuable in practical applications where the drone type is not known in advance. Notably, our method also exhibits suitable time for drone detection in practical applications, making it an effective solution for real-world scenarios.},
  archive      = {J_JIRS},
  author       = {Najafi, Jafar and Mirzakuchaki, Sattar and Shamaghdari, Saeed},
  doi          = {10.1007/s10846-024-02216-x},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-21},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Autonomous drone detection and classification using computer vision and prony algorithm-based frequency feature extraction},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive tracking control for a class of uncertain MIMO
nonlinear systems with input constraints. <em>JIRS</em>,
<em>111</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s10846-024-02218-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of adaptive tracking control for a class of uncertain multi-input and multi-output nonlinear systems in the presence of asymmetric input constraints and external disturbance. In order to address the different action ranges of input signals in asymmetric dead-zone and saturation models, an adaptive backstepping control method related to asymmetric parameters is designed. A state-dependent upper bound of uncertainty is proposed instead of a constant upper bound. This avoids the problem of state constraints caused by the boundness of uncertainty before obtaining closed-loop characteristics. Certain positive results are emerged in this paper where an innovative adaptive control methodology is demonstrated to cope with system uncertainty. The proposed controller does not require a priori knowledge on the bound of them. By means of the Lyapunov stability theory, the close-loop system is proven to be uniformly ultimately bounded, the system states converge to a domain containing the origin, and the output tracks the reference signal commendably. Simulation examples are presented to show the effectiveness of the proposed control method.},
  archive      = {J_JIRS},
  author       = {Feng, Xingkai and Wang, Congqing},
  doi          = {10.1007/s10846-024-02218-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-12},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Adaptive tracking control for a class of uncertain MIMO nonlinear systems with input constraints},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nezha-d: Dynamic characteristics and design of a ducted
HAUV. <em>JIRS</em>, <em>111</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10846-024-02133-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybrid aerial underwater vehicles (HAUVs) can operate in water and air and are qualified for complex missions on the air-water interfaces. The unique working conditions put forward higher requirements for the propulsion systems of the vehicles. Present HAUVs’ propulsion systems mostly use propellers, but normal aerial propellers work inefficiently underwater, constraining the underwater applications of HAUVs. Besides, in-depth research of the thrusters, especially during the water-crossing process, is limited. These are two major factors that affect the further development of HAUVs. This paper aims to evaluate the feasibility of the ducted fan propulsion system and design a ducted HAUV with better underwater working capacity. Ducted fans have promising applications on HAUVs for higher underwater efficiency, but the outer ducts can lead to significant thrust loss during the water-crossing process. A novel experimental platform is firstly developed with the capability of collecting dynamic data of the thruster during water- air transition. The new water-crossing strategy and overall design of the HAUV are proposed based on the test results. The ducted HAUV is supposed to accelerate underwater and rush out with a certain speed to overcome thrust loss. A centroid adjustment mechanism has also been designed to realize the underwater motion switch for better efficiency. A prototype named “Nezha-D” is fabricated, and outfield tests are conducted to verify the feasibility of the new design.},
  archive      = {J_JIRS},
  author       = {Xie, Hongfei and Jin, Yufei and Bi, Yuanbo and Zeng, Zheng},
  doi          = {10.1007/s10846-024-02133-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Nezha-D: Dynamic characteristics and design of a ducted HAUV},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative multi-agent planning framework for fuel
constrained UAV-UGV routing problem. <em>JIRS</em>, <em>111</em>(1),
1–17. (<a href="https://doi.org/10.1007/s10846-024-02209-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs), adept at aerial surveillance, are often constrained by their limited battery capacity. Refueling on slow-moving Unmanned Ground Vehicles (UGVs) can significantly enhance UAVs’ operational endurance. This paper explores the computationally complex problem of cooperative UAV-UGV routing for vast area surveillance, considering speed and fuel constraints. It presents a sequential multi-agent planning framework aimed at achieving feasible and optimally satisfactory solutions. By considering the UAV fuel limit and utilizing a minimum set cover algorithm, we determine UGV refueling stops. This, in turn, facilitates UGV route planning as the first step. Through a task allocation technique and energy-constrained vehicle routing problem modeling with time windows (E-VRPTW), we then achieve the UAV route in the second step of the framework. The effectiveness of our multi-agent strategy is demonstrated through the implementation on 30 different task scenarios across three different scales. This work provides significant insight into the collaborative advantages of UAV-UGV systems and introduces heuristic approaches to bypass computational challenges and swiftly reach high-quality solutions.},
  archive      = {J_JIRS},
  author       = {Mondal, Md Safwan and Ramasamy, Subramanian and Humann, James D. and Dotterweich, James M. and Reddinger, Jean-Paul F. and Childers, Marshal A. and Bhounsule, Pranav A.},
  doi          = {10.1007/s10846-024-02209-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Cooperative multi-agent planning framework for fuel constrained UAV-UGV routing problem},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent saturation power limit load distribution
algorithm (ISPLLDA) for cooperative manipulators applications.
<em>JIRS</em>, <em>111</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10846-024-02210-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative manipulators face challenges related to an inadequate distribution of external loads and a decrease in Dynamic Load Carrying Capacity (DLCC). Understanding the impact of optimal load distribution on power consumption, load carrying capacity, and gripper error is crucial. This paper presents the Intelligent Saturation Power Limit Load Distribution Algorithm (ISPLLDA), a novel method that achieves optimal external load distribution. ISPLLDA dynamically distributes the external load among manipulators based on torque-bearing capacity and actuator position. Additionally, nonlinearity in system dynamics introduces uncertainties, leading to incorrect DLCC evaluation, increased error, and higher actuator power consumption. To address this, a Radial Basis Function Neural Network (RBFNN) accurately determines actuator saturation limits in the presence of uncertainty, enabling correct estimation of system dynamics and external disturbances. ISPLLDA ensures near-simultaneous saturation of all manipulators&#39; actuators, maximizing their capacity utilization. The proposed method is validated through simulations and experimental tests on cooperative manipulators. Results demonstrate a 17% increase in load-carrying capacity, as well as more than 35% improvement in error and torque indexes compared to the Lagrange multipliers method.},
  archive      = {J_JIRS},
  author       = {Korayem, Moharam Habibnejad and Kia, Ali Parsai and Lademakhi, Naeim Yousefi},
  doi          = {10.1007/s10846-024-02210-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-24},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Intelligent saturation power limit load distribution algorithm (ISPLLDA) for cooperative manipulators applications},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance comparison of ROS2 middlewares for multi-robot
mesh networks in planetary exploration. <em>JIRS</em>, <em>111</em>(1),
1–20. (<a href="https://doi.org/10.1007/s10846-024-02211-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Multi-Robot Systems (MRS) and mesh network technologies pave the way for innovative approaches to explore extreme environments. The Artemis Accords, a series of international agreements, have further catalyzed this progress by fostering cooperation in space exploration, emphasizing the use of cutting-edge technologies. In parallel, companies across various sectors’ widespread adoption of the Robot Operating System 2 (ROS 2) underscores its robustness and versatility. This paper evaluates the performances of available ROS 2 MiddleWare (RMW), such as FastRTPS, CycloneDDS and Zenoh, over a mesh network with a dynamic topology. The final choice of RMW is determined by the one that would most fit the scenario: an exploration of the extreme extra-terrestrial environment using a Multi-Robot Systems (MRS). The conducted study in a real environment highlights Zenoh as a potential solution for future applications, showing a reduced delay, reachability, data overhead and CPU usage while being competitive on the RAM usage over a dynamic mesh topology.},
  archive      = {J_JIRS},
  author       = {Chovet, Loïck Pierre and Garcia, Gabriel Manuel and Bera, Abhishek and Richard, Antoine and Yoshida, Kazuya and Olivares-Mendez, Miguel Angel},
  doi          = {10.1007/s10846-024-02211-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Performance comparison of ROS2 middlewares for multi-robot mesh networks in planetary exploration},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards planning urban air mobility (UAM) landing
trajectories in emergencies. <em>JIRS</em>, <em>111</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s10846-024-02213-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ground transportation in dense urban environments has been facing challenges for many years (e.g., congestion and resilience) and the problem of congestion in urban environments will become more significant with the growth of populations and urbanization. In the past few years, the industry and the scientific communities have invested resources towards creating new ideas to improve urban transportation performance, such as the Urban Air Mobility (UAM) concept. Therefore, emergencies are considered a pivotal aspect to be managed appropriately to ensure safe UAM operations. Although normal operations represent a challenge nowadays (e.g., performance and social acceptance), emergencies are even more challenging due to the safety-critical risks. Thereupon, the main goal of this research is to propose the Landing Trajectory Planner for Emergencies in UAM Operations (LTPE), using Parallel Metaheuristics and considering autonomous vehicles’ presence. This trajectory planning method aims to design landing trajectories for multiple Electrical Vertical Take-off and Landing (eVTOL) vehicles in normal conditions and in emergencies. LTPE considers different eVTOL configurations in piloting systems (i.e., piloted vehicles, remotely piloted vehicles, and fully autonomous vehicles) as well as different vehicle priorities. Three landing modes are used for vehicles in emergency conditions: (i) land at the originally designed skyport; (ii) land at the nearest skyport; and (iii) land on the ground) and all metaheuristics include an early stopping feature. The experiments showed that LTPE can propose safe and efficient solutions for several scenarios with a short response time.},
  archive      = {J_JIRS},
  author       = {Pinto Neto, Euclides Carlos and Baum, Derick and Almeida Jr., Jorge Rady de and Camargo Jr., João Batista and Cugnasca, Paulo Sergio},
  doi          = {10.1007/s10846-024-02213-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-23},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Towards planning urban air mobility (UAM) landing trajectories in emergencies},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Planning aggressive drone manoeuvres: A geometric backwards
integration approach. <em>JIRS</em>, <em>111</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s10846-024-02214-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of performing aggressive manoeuvres by using multirotor vehicles that include passing through any specific point within the full state space of the vehicle. To this end, the design of optimal trajectories considers the dynamical model of the vehicles by numerically integrating it backwards in time, in the manifold where the dynamics evolve, and dividing the manoeuvres into three distinct phases to accommodate any combination of initial, desired, and final states. In the first phase, the vehicles fly from an initial to a launch configuration to achieve the necessary momenta to reach the desired one in the second phase. To ensure the feasibility of executing the second phase, the relation between snap and body torques is exploited by commanding the vehicles to track geodesic curves on SO(3) during the backwards integration. The vehicles are then driven to a final configuration in the third phase. Most existing solutions to execute aggressive and precise manoeuvres with these rotorcraft focus either on the attitude control problem, leaving the position in open-loop, or use different controllers for different sections of the manoeuvre. In this work, a single tracking controller is considered to validate the proposed trajectory planning strategy in a realistic simulation environment, which involves the PX4 firmware, and in a controlled experimental setup. The results demonstrate that accurate tracking of the designed trajectories enables the vehicles to perform 360-degree loops at great speed and manoeuvres that facilitate the exchange of a parcel between two multirotor vehicles during flight.},
  archive      = {J_JIRS},
  author       = {Pinto, João and Guerreiro, Bruno J. and Cunha, Rita},
  doi          = {10.1007/s10846-024-02214-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-23},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Planning aggressive drone manoeuvres: A geometric backwards integration approach},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-bandwidth contact state estimation with only joint
angle feedback for legged robots. <em>JIRS</em>, <em>111</em>(1), 1–14.
(<a href="https://doi.org/10.1007/s10846-024-02215-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the contact between robot feet and the ground is unpredictable in unstructured terrains, robots require fast and accurate contact detection capability. This paper presents a contact detection method through estimating external force that benefits from compensating friction torque and driving torque effectively. For estimating external force, a new estimation method for joint angular velocity/acceleration is proposed. Furthermore, filter parameters are selected theoretically based on the leg control model, which achieves the optimal solution of the parameters. A control compensation strategy of the low-velocity zone of the motor is also implemented for optimizing the estimation of contact force. In contrast to the classic generalized momentum method, the proposed method allows high bandwidth estimation. The proposed contact detection method and the angular velocity/acceleration estimation method using only discrete position feedback information are verified on the developed quadruped robot platform SCIT Dog.},
  archive      = {J_JIRS},
  author       = {Yang, Junjie and Sun, Hao and Jia, Yinghao and Wang, Changhong},
  doi          = {10.1007/s10846-024-02215-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {High-bandwidth contact state estimation with only joint angle feedback for legged robots},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-sum differential games guidance law accounting for
impact-angle-constrained using adaptive dynamic programming.
<em>JIRS</em>, <em>111</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s10846-024-02217-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To intercept a maneuvering target with a predetermined impact angle, a computational intelligence guidance law was proposed in this paper. Based on the theory of two-player zero-sum differential games, this problem is resolved efficiently by solving the Hamilton–Jacobi–Isaacs (HJI) equation. The Nash equilibrium solution of HJI equation can be solved with a policy iteration (PI) algorithm. Instead of using the offline PI algorithm, an online PI algorithm is introduced, in which the disturbance and control policies can be updated simultaneously. It can be proved that the online PI algorithm is a replacement for Newton’s iterative algorithm, the convergence of which is ensured by Kantorovich’s theorem. In the scenario of missiles intercepting targets, an adaptive critic structure based on a neural network (NN) is proposed to implement the online PI algorithm. Only one critic NN approximator is used in the PI algorithm to calculate a value function and the approximate Nash equilibrium solution. It is not necessary to acquire the exact internal dynamics information of nonlinear systems on the basis of online data sampling. The effectiveness of the computational intelligence guidance law is proven by simulation results.},
  archive      = {J_JIRS},
  author       = {Zhang, Xue and Wang, Qi},
  doi          = {10.1007/s10846-024-02217-w},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-12},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Zero-sum differential games guidance law accounting for impact-angle-constrained using adaptive dynamic programming},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theoretical foundation for erroneous behavior in
human–robot interaction. <em>JIRS</em>, <em>111</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10846-025-02221-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of mass customization has precipitated a need within the industry for the implementation of collaborative robots, which facilitate the integration of human cognitive capabilities with the speed and repeatability of robots. This coupling, however, engenders a closer collaboration between the partners, thereby necessitating collective synergy to achieve optimal scheduling while circumventing musculoskeletal disorders. It is imperative to study and analyze the behavior of humans and robots in interaction, as the current paradigm strives to achieve an optimal interaction between the two partners with the objective of ensuring productivity, safety, cognitive ergonomics and preventing musculoskeletal disorders. However, human behavior is variable and can, on occasion, give rise to anomalies in the interaction. Consequently, it is imperative that the robot partner exhibits precise behavior, whether proactive or reactive. This paper puts forth a unified perspective on robot behavior when confronted with human abnormal behavior during interaction on the factory floor. This systematic literature review and meta-analysis employs the PRISMA methodology to examine the literature on human and robot behavior in human–robot interaction in an industrial context, with a particular focus on robot behavior when confronted with human abnormal behavior during interaction. A systematic search of nearly 2,609 papers yielded 133 for inclusion in this systematic review. In light of the findings presented in this review, it can be concluded that the selection of robot actions based on human behavior represents a novel area of research that requires further investigation, particularly with regard to proactive online behavioral approaches. Indeed, there is a vast array of robot behavior modalities in response to typical human behavior (e.g., command input). However, there is currently no prescribed robot reaction based on atypical human behavior (e.g., misplacement in the factory floor, repetition of tasks, etc.). This lack of definition complicates the deployment of such technology in the smart factory. Consequently, it is essential to define new decision strategies based, for instance, on artificial intelligence approaches.},
  archive      = {J_JIRS},
  author       = {Tchane Djogdom, Gilde Vanel and Otis, Martin J.-D. and Meziane, Ramy},
  doi          = {10.1007/s10846-025-02221-8},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-24},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A theoretical foundation for erroneous behavior in Human–Robot interaction},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative study of rapidly-exploring random tree
algorithms applied to ship trajectory planning and behavior generation.
<em>JIRS</em>, <em>111</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10846-025-02222-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rapidly Exploring Random Tree (RRT) algorithms, notably used for nonholonomic vehicle navigation in complex environments, are often not thoroughly evaluated for their specific challenges. This paper presents a first such comparison study of the variants Potential-Quick RRT* (PQ-RRT*), Informed RRT* (IRRT*), RRT*, and RRT, in maritime single-query nonholonomic motion planning. Additionally, the practicalities of using these algorithms in maritime environments are discussed and outlined. We also contend that these algorithms are beneficial not only for trajectory planning in Collision Avoidance Systems (CAS) but also for CAS verification when used as vessel behavior generators. Optimal RRT variants tend to produce more distance-optimal paths but require more computational time due to complex tree wiring and nearest neighbor searches. Our findings, supported by Welch’s t-test at a significance level of $$\alpha =0.05$$ , indicate that PQ-RRT* slightly outperform IRRT* and RRT* in achieving shorter trajectory length but at the expense of higher tuning complexity and longer run-times. Based on the results, we argue that these RRT algorithms are better suited for smaller-scale problems or environments with low obstacle congestion ratio. This is attributed to the curse of dimensionality, and trade-off with available memory and computational resources.},
  archive      = {J_JIRS},
  author       = {Tengesdal, Trym and Pedersen, Tom Arne and Johansen, Tor Arne},
  doi          = {10.1007/s10846-025-02222-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A comparative study of rapidly-exploring random tree algorithms applied to ship trajectory planning and behavior generation},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LiDAR loop closure detection using semantic graphs with
graph attention networks. <em>JIRS</em>, <em>111</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10846-025-02223-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel loop closure detection algorithm that uses graph attention neural networks to encode semantic graphs to perform place recognition and then use semantic registration to estimate the 6 DoF relative pose constraint. Our place recognition algorithm has two key modules, namely, a semantic graph encoder module and a graph comparison module. The semantic graph encoder employs graph attention networks to efficiently encode spatial, semantic and geometric information from the semantic graph of the input point cloud. We then use self-attention mechanism in both node-embedding and graph-embedding steps to create distinctive graph vectors. The graph vectors of the current scan and a keyframe scan are then compared in the graph comparison module to identify a possible loop closure. Specifically, employing the difference of the two graph vectors showed a significant improvement in performance, as shown in ablation studies. Lastly, we implemented a semantic registration algorithm that takes in loop closure candidate scans and estimates the relative 6 DoF pose constraint for the LiDAR SLAM system. Extensive evaluation on public datasets shows that our model is more accurate and robust, achieving 13% improvement in maximum F1 score on the SemanticKITTI dataset, when compared to the baseline semantic graph algorithm. For the benefit of the community, we open-source the complete implementation of our proposed algorithm and custom implementation of semantic registration at https://github.com/crepuscularlight/SemanticLoopClosure .},
  archive      = {J_JIRS},
  author       = {Yang, Liudi and Mascaro, Ruben and Alzugaray, Ignacio and Prakhya, Sai Manoj and Karrer, Marco and Liu, Ziyuan and Chli, Margarita},
  doi          = {10.1007/s10846-025-02223-6},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {LiDAR loop closure detection using semantic graphs with graph attention networks},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image-based mapless navigation of a hybrid aerial-underwater
vehicle using prioritized deep reinforcement learning. <em>JIRS</em>,
<em>111</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10846-024-02206-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Reinforcement Learning (RL) has made promising progress in several areas, such as control tasks and video games, by using simple, low-dimensional data. However, it struggles when it needs to process more complex, high-dimensional inputs like raw pixel images, offering results that are not as good as those that use information from laser sensors, as many robotics applications demand. This paper introduces a new technique called Contrastive Unsupervised Prioritized Representations in Reinforcement Learning (CUPRL) for mobile robotics. This innovative approach combines RL and Contrastive Learning to effectively handle high-dimensional observations, an area not fully explored. This is crucial for navigating complex environments, especially for hybrid robots, such as the Hybrid Unmanned Aerial-Underwater Vehicles (HUAUVs) that experience strong changes in light when moving between air and water. Our approach excels in taking important information from depth maps and RGB images during training, aiming to improve the ability of RL agents to navigate without a map in the context of HUAUVs. This field has much to be explored. Our tests in a robot simulator show that CUPRL, which uses learning from both RGB and depth images, performs better than current methods that rely only on pixel data. This is especially true for 3D navigation without maps, where we use only RGB images during tests. This proves that CUPRL could be useful for making decisions in HUAUVs. We believe our work not only offers improved solutions for navigation but also encourages further research into the use of high-dimensional data in RL, presenting a more efficient and adaptable method in complex environments compared to earlier strategies.},
  archive      = {J_JIRS},
  author       = {Costa de Jesus, Junior and Kich, Victor Augusto and Kolling, Alisson Henrique and Grando, Ricardo Bedin and da Silva Guerra, Rodrigo and Drews-Jr, Paulo Lilles Jorge},
  doi          = {10.1007/s10846-024-02206-z},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-13},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Image-based mapless navigation of a hybrid aerial-underwater vehicle using prioritized deep reinforcement learning},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CROW: A self-supervised crop row navigation algorithm for
agricultural fields. <em>JIRS</em>, <em>111</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10846-025-02219-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compact robots operating beneath the crop canopy present great potential for a range of autonomous and remote tasks, including phenotyping, soil analysis, and cover cropping. Under-canopy navigation presents unique challenges, such as the need for a navigation system that can traverse diverse crop types, navigate despite sensory obstructions, and manage sensory noise effectively. Aiming to solve this problem in a scalable manner, we present a novel navigation method that uses a self-supervised neural network tailored for row-following in under-canopy plantations for mobile robots. Our method, termed CROW (Crop-ROW navigation), integrates perception, waypoint generator, and control components, and is capable of handling variations in luminosity, topology, types of plantations, and plant growth stages. By using a Deep Learning-based approach to interpret LiDAR scans, we convert the detected rows of crops into lines, establishing waypoints for the controller based on fundamental geometric principles. To address the computational complexity inherent in standard Model Predictive Controller solvers, we employ a Constrained Iterative Linear Quadratic approach. Our system has been validated in both simulated and real-world environments, demonstrating successful navigation through 115-meter corn rows with little to no intervention, i.e., requiring only $$3 \pm 3$$ interventions per row experiment.},
  archive      = {J_JIRS},
  author       = {Affonso, Francisco and Tommaselli, Felipe Andrade G. and Capezzuto, Gianluca and Gasparino, Mateus V. and Chowdhary, Girish and Becker, Marcelo},
  doi          = {10.1007/s10846-025-02219-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {CROW: A self-supervised crop row navigation algorithm for agricultural fields},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic model-based stationing: Robust total station
localization without known control points. <em>JIRS</em>,
<em>111</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-025-02224-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based stationing refers to the process of registering a set of measurements to a model. Specifically, in the surveying context, this refers to the process of determining the station, i.e., the position and orientation, of a total station given a user-provided building floor plan and a series of polar measurements. Traditional methods compute the station using a set of known control points. We propose an automatic workflow which uses a novel registration method that does not require any known control points in order to find the station with high accuracy. Our registration algorithm relies on angle and distance measurements only; therefore, it is not limited to modern image-assisted total stations. In addition, the proposed workflow comprises a modeling phase to deal with model inaccuracies and produces reliable and accurate results. Quantitative and qualitative tests on synthetic and real-world scenarios demonstrate the performance and robustness of our automatic workflow and registration method.},
  archive      = {J_JIRS},
  author       = {Reyes-Aviles, Fernando and Gloor, Thomas and Arth, Clemens},
  doi          = {10.1007/s10846-025-02224-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Automatic model-based stationing: Robust total station localization without known control points},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large workspace frontal human following for mobile robots
utilizing 2D LiDAR. <em>JIRS</em>, <em>111</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-025-02225-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots following humans is an efficient and practical feature, particularly in the context of service robotics. However, the majority of existing research has focused on the robot following the human from behind, with relatively little attention given to the robot operating in front of the human. This following-in-front approach, where the robot remains within the user’s field of view, is more reassuring and facilitates further human-robot interaction. Unlike traditional following methods, frontal following requires awareness of the user’s orientation and intentions. New challenges will arise in developing a tracker that can accurately estimate a user’s pose based on a knee height 2D LiDAR, especially when the legs frequently occlude each other. There is also a need to ensure the safety of the user while addressing how the robot can keep up with the user in situations where it falls behind. Our contribution lies in proposing a novel 2D LiDAR-based frontal human following method that accommodates various motion patterns of the target user. Specifically, inspired by human walking gait, we develop an accurate and robust human pose tracker that takes into account leg occlusion and the data association problem. We build a large workspace velocity field that enables a holonomic mobile robot to follow and come gradually and safely in front of the user regardless of their relative position. We evaluate the performance of our approach through a rich set of experimental scenarios, and demonstrate its effectiveness in achieving reliable frontal human following. Our studies suggest this approach has potential applications in warehouses, industrial factories or for visually impaired persons.},
  archive      = {J_JIRS},
  author       = {Gao, Zhenyu and Wang, Ze and Saint-Bauzel, Ludovic and Ben Amar, Faïz},
  doi          = {10.1007/s10846-025-02225-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Large workspace frontal human following for mobile robots utilizing 2D LiDAR},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of a microcontroller-based recurrent neural
network predictive system for lower limb exoskeletons. <em>JIRS</em>,
<em>111</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s10846-025-02226-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practical deployments of exoskeletons can often be limited by cost, limiting access to their usage by those that would benefit from them. Minimising cost whilst not harming effectiveness is therefore desirable for exoskeleton development. For Control Systems governing assistive and rehabilitative exoskeletons that react to the wearer’s movements, there will inevitably be some delay between when their wearer intends to move and when the exoskeleton can assist with this movement. This can lead to situations where a user may be limited by their own assistive exoskeleton, reducing their ability to move freely. A potential solution to this is to provide a proactive method of control, where the most likely path of the wearer’s movement is predicted ahead of the wearer making the motion themselves. This can be used to give the user assistance immediately as they are walking, as well as potentially pre-emptively adjust their gait if they suffer from predictable gait deficiencies. The purpose of this paper is to investigate the Data Collection, Implementation, and Effectiveness of an LSTM Recurrent Neural Network dynamically predicting future movement based off of prior movement. These methods were developed to use off the shelf, Low-Cost Microcontrollers as to minimise their Financial, Weight, and Power Impact on an overall Low-Cost exoskeleton design, as well as to evaluate how effective such an implementation would be when compared to running such a Neural Network on a more powerful processor. The created model was capable of achieving similar accuracies to far more powerful models on High-Powered Laptops.},
  archive      = {J_JIRS},
  author       = {Slucock, T. and Howells, G. and Hoque, S. and Sirlantzis, K.},
  doi          = {10.1007/s10846-025-02226-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Development of a microcontroller-based recurrent neural network predictive system for lower limb exoskeletons},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design optimisation of fully actuated UAVs using hybrid
optimisation. <em>JIRS</em>, <em>111</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s10846-025-02227-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past few years, there has been a rise in novel fully actuated multirotor UAV configurations, each customised to perform a different task. These configurations must be optimised to extract their full potential for the different use cases. The main issue with existing optimisation methods is the computational cost required to produce a design when the optimisation includes both continuous and discrete variables, such as off-the-shelf components. We propose a hybrid optimisation method using continuous surrogate methods with localised parameter sweep. The continuous stage aims at finding the optimal value for the continuous design variables and reduces the search space for the discrete design variables. Empirical models for the off-the-shelf components are used to reduce the size of the continuous stage of the optimisation. The localised search method consists of a parameter sweep of the discrete design variables within a certain threshold of the optimal parameters from the first stage. Three case studies confirm the method’s capabilities with different configurations and optimisation setups, comparing optimality, success rate and computational cost. The optimal design from the hybrid method is consistent with the baseline methods used for comparison within each case study, with a minimum success rate of 30% while reducing cost by 98%. Compared to specialised discrete methods, the improvement in computational cost is inconsistent; however, it achieves a reduction of 99.3% with certain design requirements. A comparison to another hybrid method was also performed, with the proposed method maintaining its cost, optimality and success rate better than the SQP-DSS method when increasing method complexity.},
  archive      = {J_JIRS},
  author       = {Al-zubaidi, Salim and Stol, Karl},
  doi          = {10.1007/s10846-025-02227-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-21},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Design optimisation of fully actuated UAVs using hybrid optimisation},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Motor speed control of four-wheel differential drive robots
using a new hybrid moth-flame particle swarm optimization (MFPSO)
algorithm. <em>JIRS</em>, <em>111</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10846-025-02228-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speed control of DC motors is essential for automated vehicles and four-wheel differential drive (4WD) cars, which are distinct by their high level of maneuverability. The PID controller is one of the most popular techniques for controlling speed, but tuning its parameters is challenging. This paper presents a novel hybrid algorithm, the Moth-Flame Particle Swarm Optimization (MFPSO), which combines moth-flame optimization (MFO) and particle swarm optimization (PSO) to address the slow convergence of MFO and the premature convergence of PSO. The MFPSO is deployed for real-time interactive tuning of the PID controller to control the speed of DC motors in a 4WD car. Additionally, a novel practical procedure is proposed to build a robust four-wheel differential drive and maintain the synchronization of the four DC motors. Simulation results and statistical analysis demonstrate the superior performance of the MFPSO compared with the PSO, MFO, and other hybrid variants (HMFPSO and HyMFPSO), with MFPSO ranking first in the Friedman test on CEC2020/2021 and engineering optimization benchmark problems. Practical results and the transient response analysis of the speed control revealed that MFPSO significantly outperformed the traditional Ziegler-Nichols (ZN) method, MFO, PSO, HMFPSO, and HyMFPSO algorithms. Specifically, the MFPSO algorithm reduced settling time by 34.83%, 21.20%, 20.75%, 22.97%, and 31.59%, and overshoot by 86.11%, 64.99%, 71.02%, 74.37%, and 60.58% compared to the ZN, MFO, PSO, HMFPSO, and HyMFPSO algorithms, respectively. The source code of the proposed algorithm is available at https://github.com/MohamedRedaMu/MFPSO-Algorithm .},
  archive      = {J_JIRS},
  author       = {Reda, Mohamed and Onsy, Ahmed and Haikal, Amira Y. and Ghanbari, Ali},
  doi          = {10.1007/s10846-025-02228-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-37},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Motor speed control of four-wheel differential drive robots using a new hybrid moth-flame particle swarm optimization (MFPSO) algorithm},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent path planning based on conflict-based search
(CBS) variations for heterogeneous robots. <em>JIRS</em>,
<em>111</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s10846-025-02229-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel Multi-agent path planning scheme based on Conflict Based Search (CBS) for heterogeneous holonomic and non-holonomic agents, designated as Heterogeneous CBS (HCBS). The proposed methodology employs a hybrid $$A^*$$ algorithm for non-holonomic car-like robots and a conventional $$A^*$$ algorithm for holonomic robots. Following this, a body conflict detection strategy is utilized to construct the conflict tree, bridging the initial path planning with the resolution of conflicts among agents. Moreover, we present two variants of HCBS: the Enhanced Conflict-Based Search (EHCBS) and the Depth-First Conflict-Based Search (DFHCBS). We evaluate the efficacy of our proposed algorithms—HCBS, EHCBS, and DFHCBS—against a standard prioritized planning algorithm, focusing on success rates and computational efficiency in environments with varying numbers of agents and obstacles. The empirical results demonstrate that EHCBS exhibits superior computational efficiency in small, dense environments, while DFHCBS performs well in larger-scale environments. This highlights the adaptability of our proposed approaches in various settings, proving the computational advantage of EHCBS and DFHCBS over traditional methods.},
  archive      = {J_JIRS},
  author       = {Bai, Yifan and Kotpalliwar, Shruti and Kanellakis, Christoforos and Nikolakopoulos, George},
  doi          = {10.1007/s10846-025-02229-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-12},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Multi-agent path planning based on conflict-based search (CBS) variations for heterogeneous robots},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lower limb exoskeleton adaptive control method based on
model-free reinforcement learning and improved dynamic movement
primitives. <em>JIRS</em>, <em>111</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s10846-025-02230-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in lower limb exoskeleton control have predominantly focused on enhancing walking capabilities across diverse terrains, such as level ground, stairs, and ramps. However, achieving seamless transitions between these terrains remains a significant challenge due to the unpredictability of the environment, which hampers adaptive control. In this paper, we propose a Hierarchical Interactive Learning (HIL) control method based on gait phase and locomotion pattern recognition. The method comprises two layers: high-level learning and low-level control. The high-level learning is based on gait phase and locomotion pattern recognition, utilizing the Dynamic Movement Primitives (DMP) to piecewise learn the desired joint torque curves. The low-level control utilizes the learned DMP to output torque based on the gait phase and locomotion pattern, while reinforcement learning is employed to dynamically adjust the control parameters of DMP in real-time with the goal of minimizing human-exoskeleton interaction forces. The experiments collected gait data of lower limb movement from active exoskeletons. The results show that our method significantly reduces human-exoskeleton interaction forces across diverse terrains. In order to verify the feasibility and effectiveness of the proposed method, 15 healthy subjects were tested with the lower limb exoskeleton of these 3 generations. The experimental results show that the proposed HIL control method gives a valuable tool for smooth transitions among different terrains, reduces the reliance on accurate dynamic models and the average oxygen consumption decreased by about 12%, underscoring its potential to improve exoskeleton-assisted mobility.},
  archive      = {J_JIRS},
  author       = {Huang, Liping and Zheng, Jianbin and Gao, Yifan and Song, Qiuzhi and Liu, Yali},
  doi          = {10.1007/s10846-025-02230-7},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A lower limb exoskeleton adaptive control method based on model-free reinforcement learning and improved dynamic movement primitives},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technologies and applications of robots in dementia care: A
systematic review. <em>JIRS</em>, <em>111</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10846-025-02232-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Socially assistive robotics (SARs) can provide social interventions for people living with dementia. Although several SARs have been introduced, the absence of their evaluation and discussion has restricted the development and use of robots in dementia care. This paper systematically reviews robot technologies, explores their applications, and provides systematic information for technology development, selection, and implementation for robots in dementia care. Following the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, articles from January 1990 to May 2023 were retrieved from seven databases and 38 eligible articles were identified. Nineteen SARs were identified and reviewed, encompassing physical features, sensing capabilities, perception, user modeling, and interaction technologies. The robot personality framework, which classified SARs as animal-like, human-like, and artificial-being, was employed to compare technologies, applications, and clinical outcomes. In addition, the experimental methodologies and study quality of existing studies were compared and discussed. This study found that technologies shape the robot’s personality and contribute to its applications. Future studies could be based on their application purpose, which could guide the selection, development, and implementation of robot technologies, thereby promoting SAR applications in dementia care. In addition, studies with large sample sizes, rigorous study designs, and detailed intervention descriptions are recommended, which could enhance study quality and promote robot technologies and applications in dementia care.},
  archive      = {J_JIRS},
  author       = {Wu, Dongjun and Pu, Lihui and Jo, Jun and Moyle, Wendy},
  doi          = {10.1007/s10846-025-02232-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Technologies and applications of robots in dementia care: A systematic review},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new vertical plane motion control method based on the
framework consisting of control law and control allocation for
underwater vehicle with bow and stern elevators. <em>JIRS</em>,
<em>111</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10846-025-02233-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the vertical plane motion performance of an underwater vehicle with bow and stern elevators under actuator saturation and external disturbance conditions, a new control method is proposed in this paper. Firstly, for simplifying the analysis of the coupled kinetics equation of the underwater vehicle, virtual control variables are introduced to decompose the kinetics equation into two cascaded components. Then, a framework consisting of control law and control allocation is presented according to the cascaded components. In the aspect of control law, a double closed-loop control scheme is designed. The outer loop realizes the depth control by adjusting the expected heave velocity and pitch of the underwater vehicle with an S-plane regulator and a subsection function. Meanwhile, an Augmented Linear Quadratic Regulator (ALQR) is employed in the inner loop to control the heave velocity and pitch without steady-state error. Considering the physical constraints of elevators, a pitching-priority idea is adopted in the design of the control allocation to prioritize the pitch control requirement of the underwater vehicle. Finally, based on the framework, disturbances are estimated and compensated to enhance the anti-interference performance, as well as, auxiliary functions are constructed for reducing the adverse effect caused by saturation. Simulation results show that the new control method performs perfectly under various conditions, it is also conducive to the navigation safety of the underwater vehicle because of its superior pitch control capability.},
  archive      = {J_JIRS},
  author       = {Sun, Gongwu and Sima, Can and Yuan, Shouzheng and Ma, Xiangneng and Zhang, Wanyuan and Jiao, Huifeng},
  doi          = {10.1007/s10846-025-02233-4},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {A new vertical plane motion control method based on the framework consisting of control law and control allocation for underwater vehicle with bow and stern elevators},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An inpainting SLAM approach for detecting and recovering
regions with dynamic objects. <em>JIRS</em>, <em>111</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10846-025-02234-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is a cornerstone capability for intelligent mobile robots, enabling them to accurately estimate their positions in unknown environments. However, most of the state-of-the-art visual SLAM systems rely on the assumption of static scenes, leading to significantly reduced accuracy and robustness in dynamic environments. In this paper, a novel RGB-D SLAM system termed Inpainting SLAM is proposed in the ORB-SLAM2 framework. Our Inpainting SLAM defines two new modules: one is the dynamic objects detection module, which combines segmentation and depth information to segment dynamic objects. Additionally, a new method is also proposed to determine whether movable objects are classified as dynamic. The other is an image inpainting module to restore static regions that are occluded by dynamic objects, with a new rectified approach introduced to determine the inpainting regions that can enhance the performance of the SLAM system. With these two modules, the accuracy and robustness of the SLAM system in dynamic scenes are expected to be improved. Our method is tested on the public TUM dataset, demonstrating its effectiveness and reliability. The improvements on ORB-SLAM2 in RTE, RRE, and ATE are 97.45%, 99.88%, and 97.90%, respectively. In comparison with other advanced dynamic SLAM methods, our approach also demonstrates superiority.},
  archive      = {J_JIRS},
  author       = {Zhang, Longxin and Xu, Benlian and Chen, Siwen and Nener, Brett and Zhou, Xu and Lu, Mingli and Li, Xinya and Le, Shuting},
  doi          = {10.1007/s10846-025-02234-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-18},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {An inpainting SLAM approach for detecting and recovering regions with dynamic objects},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Genetic algorithm-based control of a two-wheeled
self-balancing robot. <em>JIRS</em>, <em>111</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s10846-025-02236-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile robots are becoming increasingly popular in a wide array of applications: industrial, item delivery, search and rescue, space, social, and entertainment. A two-wheeled self-balancing mobile robot is a statically unstable non-linear system with strong coupling dynamics. Common practices in the development of control systems for such robots are either to linearise the region of application to be used with linear controllers or to use complex nonlinear controllers such as fuzzy logic, sliding mode, and neural networks. However, self-balancing robots are still restricted by the travelling distance needed to regain an upright stance, the length of settling time, high overshoot and lack of resilience to external disturbance. In this paper, we are proposing a novel genetic algorithm-based switching control to evolve more effective control parameters and increase autonomy. Differently from previous work a genetic algorithm has been used to select the parameters in a sliding mode control and a switching-algorithm-based controller of a two-wheeled self-balancing mobile robot. The performance of the proposed controllers is assessed in simulations using the CoppeliaSim environment. The tests used dynamic criteria (distance travelled, maximum angular deviation), control criteria (settling time, % overshoot). The results showed that the genetic algorithm-based control has better performance in the 55 degree recovery, impulse response and variable inclination tests and that switching algorithm-based control shows better performance in step response tests. The results produced by the evolutionary algorithm are often able to perform better than their analytic counterparts. This shows the potential of meta-heuristic algorithms to obtain solutions for optimization problems encountered by statically unstable non-linear systems in unstructured and fast-changing environments.},
  archive      = {J_JIRS},
  author       = {Papadimitriou, Kleon Dimitrios and Murasovs, Nikita and Giannaccini, Maria Elena and Aphale, Sumeet},
  doi          = {10.1007/s10846-025-02236-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Genetic algorithm-based control of a two-wheeled self-balancing robot},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk-sensitive autonomous exploration of unknown
environments: A deep reinforcement learning perspective. <em>JIRS</em>,
<em>111</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s10846-025-02235-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study provides a thorough investigation into autonomous exploration within unknown environments, with a focus on minimizing exploration time and so fuel consumption. This research utilizes a 2D simulation environment to collect training data efficiently, facilitating the evaluation of the proposed methods’ efficiency, adaptability, and generalizability through various experiments. Single-robot autonomous exploration policies using advanced Deep Reinforcement Learning (DRL) algorithms are developed. The main novelty of this paper is the development of risk-sensitive policies, in contrast to traditional risk-neutral approaches in DRL, to enhance exploration efficiency. Additionally, this research presents the development of an adaptive autonomous exploration policy that dynamically adjusts the Conditional Value-at-Risk (CVaR) based on the exploration percentage. The results demonstrate a significant improvement in autonomous exploration efficiency compared to well-known traditional RL and classical single-robot exploration policies, validating the effectiveness of the suggested novel autonomous exploration strategies.},
  archive      = {J_JIRS},
  author       = {Sarfi, Mohammad Hossein and Bisheban, Mahdis},
  doi          = {10.1007/s10846-025-02235-2},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-20},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Risk-sensitive autonomous exploration of unknown environments: A deep reinforcement learning perspective},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal consistency as pretext task in unsupervised domain
adaptation for semantic segmentation. <em>JIRS</em>, <em>111</em>(1),
1–15. (<a href="https://doi.org/10.1007/s10846-025-02220-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent and autonomous robots (and vehicles) largely adopt computer vision systems to help in localization, navigation and obstacle avoidance tasks. By integrating different deep learning techniques, such as Object Detection and Image Semantic Segmentation, these systems achieve high accuracy in the domain they were trained on. Nonetheless, robustly operating in different domains still poses a major challenge to vision-based perception. In this sense, Unsupervised Domain Adaptation (UDA) has recently gained momentum due to its importance to real-world applications. Specifically, it leverages the prompt availability of unlabeled data to design auxiliary sources of supervision to guide the knowledge transfer between domains. The advantages of such an approach are two-fold: avoiding going through exhaustive labeling processes, and enhancing adaptation performance. In this scenario, exploring temporal correlations in unlabeled video data stands as an interesting alternative, which has not yet been explored to its full potential. In this work, we propose a Self-supervised learning framework that employs Temporal Consistency from unlabeled video sequences as a pretext task for improving UDA for Semantic Segmentation (UDASS). A simple yet effective strategy, it has shown promising results in a real-to-real adaptation setting. Our results and discussions are expected to benefit both new and experienced researchers on the subject.},
  archive      = {J_JIRS},
  author       = {Barbosa, Felipe and Osório, Fernando},
  doi          = {10.1007/s10846-025-02220-9},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Temporal consistency as pretext task in unsupervised domain adaptation for semantic segmentation},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid physics-infused deep learning for enhanced real-time
prediction of human upper limb movements in collaborative robotics.
<em>JIRS</em>, <em>111</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-025-02237-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human–robot collaboration is crucial in various industries, making accurate prediction of human arm movements essential for seamless interaction. This paper presents a significant advancement in collaborative robotics by developing a hybrid model that enhances the accuracy and interpretability of human motion predictions. By integrating a Physics-Infused Model with Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) networks, our approach effectively captures intricate temporal dependencies while incorporating physical constraints, leading to more robust and realistic predictions. The hybrid model was successfully implemented on an ABB IRB 120 robot, demonstrating its practical applicability in real-world scenarios. Our results show that this model outperforms conventional methods, particularly in predicting human arm positions during collaborative tasks. The key contribution of this work lies in the integration of deep learning with physics-based principles, setting a new benchmark for predictive accuracy in human–robot collaboration. This research not only enhances the performance of collaborative robots but also opens the door for similar hybrid models to be applied in other fields where accurate motion prediction is critical.},
  archive      = {J_JIRS},
  author       = {Halim, Mina Yousry and Awad, Mohammed Ibrahim and Maged, Shady A.},
  doi          = {10.1007/s10846-025-02237-0},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Hybrid physics-infused deep learning for enhanced real-time prediction of human upper limb movements in collaborative robotics},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of GMDH and perceptron controllers for mobile
robot obstacle following/avoidance with hardware-in-the-loop validation.
<em>JIRS</em>, <em>111</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s10846-025-02239-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the effectiveness of using the Group Method of Data Handling (GMDH) and Perceptron neural controllers for a mobile robot obstacle/following avoidance application. The paper evaluates the performance of these controllers in different scenarios, analyzing parameters such as settling time, steady-state error, and overshoot. In addition, we investigate different hardware implementations of the proposed controllers using SoC FPGAs, tailored for small mobile robot platforms, offering high computational performance and low power consumption. To train the neural controllers, four bio-inspired optimization algorithms were used, and hypothesis tests were conducted to select the best neural controller. A Hardware-in-the-Loop (HIL) simulation was conducted in an AMD-Xilinx SoC FPGA Zynq 7020 to attain the best compromise between the controllers’ performance, numerical precision, hardware resources consumption, and power dissipation. The findings underscored the effectiveness of both GMDH and Perceptron controllers in stabilizing the robot amidst disturbances and adeptly navigating obstacle-following and avoidance tasks across various unknown scenarios. However, the Perceptron controller exhibits several advantages in terms of hardware resources and power consumption.},
  archive      = {J_JIRS},
  author       = {Pastrana Triana, Mario Andrés and Santana, Mateus Souza and Mendoza Peñaloza, Jose Alfredo and Nunes de Oliveira, Luiz Henrique and Muñoz Arboleda, Daniel Mauricio},
  doi          = {10.1007/s10846-025-02239-y},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-23},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Comparison of GMDH and perceptron controllers for mobile robot obstacle Following/Avoidance with hardware-in-the-loop validation},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian network-based threat assessment and TARAPSO
algorithm for UUV path planning in complex environments. <em>JIRS</em>,
<em>111</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10846-025-02240-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is crucial for unmanned underwater vehicles (UUVs) navigating in complex marine environments, which are often affected by multiple threat factors. Traditional path planning methods often fail to account for these factors, suffer from local optimal solutions, and lack adequate exploration and exploitation capabilities. To overcome these limitations, this paper proposes a target attraction rule-based adaptive particle swarm optimization (TARAPSO) algorithm, driven by threat assessment. Firstly, a 3D model of the complex marine environment is established, incorporating multiple threat factors. Secondly, a Bayesian network (BN)-based threat assessment model is developed to perform probabilistic inference on the states of potential threats encountered by the UUV. Based on the results of this assessment, a cost function incorporating the threat degree index is designed to evaluate the impact of various threat factors on the UUV’s path. Finally, the TARAPSO algorithm is introduced and applied to solve the multi-objective optimization problem of path planning, incorporating the threat assessment-driven cost function. Simulation results show that the TARAPSO algorithm, when combined with the BN-based threat assessment strategy, demonstrates superior efficiency in evaluating multiple threat factors, generates competitive paths with shorter lengths, and effectively ensures safe navigation of the UUV.},
  archive      = {J_JIRS},
  author       = {Zhang, Xun and Li, Wenguo and Wang, Ziqi},
  doi          = {10.1007/s10846-025-02240-5},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Bayesian network-based threat assessment and TARAPSO algorithm for UUV path planning in complex environments},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). JIRS editorial, 1st quarter 2025. <em>JIRS</em>,
<em>111</em>(1), 1. (<a
href="https://doi.org/10.1007/s10846-025-02242-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JIRS},
  author       = {Valavanis, Kimon P.},
  doi          = {10.1007/s10846-025-02242-3},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {JIRS editorial, 1st quarter 2025},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parameter identification of a flexible-joint robot axis
using sinusoidal position tracking. <em>JIRS</em>, <em>111</em>(1),
1–19. (<a href="https://doi.org/10.1007/s10846-025-02244-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel method for identifying the mechanical parameters of flexible-joint robot axes using sinusoidal position tracking control. Accurate knowledge of mechanical parameters, such as inertia, coupling stiffness, and friction components, is important for designing effective controllers in robotic systems. These parameters are determined from integral values derived from the torque, speed, and position measurements of both the motor and load sides, leveraging the 90 $$^{\circ }$$ phase relationship between position, velocity, and acceleration terms. A robust sinusoidal position controller was developed, and the speed and position measurements of both the motor and load sides were utilized to implement the proposed method. When compared with parameters identified using standard methods, the proposed method shows an absolute percentage error ranging from 3.55% to 14.6% for the inertias and coupling stiffness, and 10.76% to 19% for the friction coefficients. The straightforward implementation and effectiveness of this method make it suitable for applications in industrial robotic arms, where precise control is essential for enhancing performance and operational efficiency.},
  archive      = {J_JIRS},
  author       = {Hafez, Ishaq and Dhaouadi, Rached},
  doi          = {10.1007/s10846-025-02244-1},
  journal      = {Journal of Intelligent &amp; Robotic Systems},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Intell. Robot. Syst.},
  title        = {Parameter identification of a flexible-joint robot axis using sinusoidal position tracking},
  volume       = {111},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jmiv---10">JMIV - 10</h2>
<ul>
<li><details>
<summary>
(2025). Wavelet-based multiscale flow for realistic image
deformation in the large diffeomorphic deformation model framework.
<em>JMIV</em>, <em>67</em>(2), 1–28. (<a
href="https://doi.org/10.1007/s10851-024-01219-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating accurate high-dimensional transformations remains very challenging, especially in a clinical setting. In this paper, we introduce a multiscale parameterization of deformations to enhance registration and atlas estimation in the large deformation diffeomorphic metric mapping framework. Using the Haar wavelet transform, a multiscale representation of the initial velocity fields is computed to optimize transformations in a coarse-to-fine fashion. This additional layer of spatial regularization does not modify the underlying model of deformations. As such, it preserves the original kernel Hilbert space structure of the velocity fields, enabling the algorithm to perform efficient gradient descent. Numerical experiments on several datasets, including abnormal fetal brain images, show that compared to the original algorithm, the coarse-to-fine strategy reaches higher performance and yields template images that preserve important details while avoiding unrealistic features. This highly versatile strategy can easily be applied to other mathematical frameworks for almost no additional computational cost.},
  archive      = {J_JMIV},
  author       = {Gaudfernau, Fleur and Blondiaux, Eléonore and Allassonnière, Stéphanie and Le Pennec, Erwan},
  doi          = {10.1007/s10851-024-01219-5},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-28},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Wavelet-based multiscale flow for realistic image deformation in the large diffeomorphic deformation model framework},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the deltoid phenomenon in the perspective
3-point (P3P) problem. <em>JMIV</em>, <em>67</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s10851-024-01228-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concerning the perspective 3-point (P3P) problem, Grunert’s system of three quadratic equations has a repeated solution if and only if the cubic polynomial introduced by Finsterwalder has a repeated root. This polynomial is here shown to be obtainable from a particularly simple cubic polynomial with complex coefficients via a simple Möbius transformation. This provides surprising geometric insight into the P3P problem. In particular, (1) the discriminant of Finsterwalder’s polynomial can be written using the formula for the standard deltoid curve, and (2) this discriminant, when regarded as a function of camera position, vanishes on a surface that approaches a deltoid shape when the camera is moved infinitely far from the control points in a direction perpendicular to the control points plane (the “limit case&quot;). These two facts have been previously reported, but obscure reasoning was required to establish them. In contrast, the present article uses the newly discovered cubic polynomial to easily produce the first fact, which then provides a basis for better understanding the second fact. Also presented are quartic polynomials whose real roots are the P3P solution point coordinates. A detailed geometric description of the P3P solution points in the “limit case&quot; is also supplied.},
  archive      = {J_JMIV},
  author       = {Rieck, Michael Q.},
  doi          = {10.1007/s10851-024-01228-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Understanding the deltoid phenomenon in the perspective 3-point (P3P) problem},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDE-CNNs: Axiomatic derivations and applications.
<em>JMIV</em>, <em>67</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s10851-025-01230-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PDE-based group convolutional neural networks (PDE-G-CNNs) use solvers of evolution PDEs as substitutes for the conventional components in G-CNNs. PDE-G-CNNs can offer several benefits simultaneously: fewer parameters, inherent equivariance, better accuracy, and data efficiency. In this article, we focus on Euclidean equivariant PDE-G-CNNs where the feature maps are two-dimensional throughout. We call this variant of the framework a PDE-CNN. From a machine learning perspective, we list several practically desirable axioms and derive from these which PDEs should be used in a PDE-CNN, this being our main contribution. Our approach to geometric learning via PDEs is inspired by the axioms of scale-space theory, which we generalize by introducing semifield-valued signals. Our theory reveals new PDEs that can be used in PDE-CNNs and we experimentally examine what impact these have on the accuracy of PDE-CNNs. We also confirm for small networks that PDE-CNNs offer fewer parameters, increased accuracy, and better data efficiency when compared to CNNs.},
  archive      = {J_JMIV},
  author       = {Bellaard, Gijs and Sakata, Sei and Smets, Bart M. N. and Duits, Remco},
  doi          = {10.1007/s10851-025-01230-4},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-25},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {PDE-CNNs: Axiomatic derivations and applications},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiscale hierarchical decomposition methods for images
corrupted by multiplicative noise. <em>JMIV</em>, <em>67</em>(2), 1–27.
(<a href="https://doi.org/10.1007/s10851-024-01220-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recovering images corrupted by multiplicative noise is a well-known challenging task. Motivated by the success of multiscale hierarchical decomposition methods (MHDM) in image processing, we adapt a variety of both classical and new multiplicative noise removing models to the MHDM form. On the basis of previous work, we further present a tight and a refined version of the corresponding multiplicative MHDM. We discuss existence and uniqueness of solutions for the proposed models and, additionally, provide convergence properties. Moreover, we present a discrepancy principle stopping criterion which prevents recovering excess noise in the multiscale reconstruction. Through comprehensive numerical experiments and comparisons, we qualitatively and quantitatively evaluate the validity of all proposed models for denoising and deblurring images degraded by multiplicative noise. By construction, these multiplicative multiscale hierarchical decomposition methods have the added benefit of recovering many scales of an image, which can provide features of interest beyond image denoising.},
  archive      = {J_JMIV},
  author       = {Barnett, Joel and Li, Wen and Resmerita, Elena and Vese, Luminita},
  doi          = {10.1007/s10851-024-01220-y},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-27},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Multiscale hierarchical decomposition methods for images corrupted by multiplicative noise},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrected laplace–beltrami operators for digital surfaces.
<em>JMIV</em>, <em>67</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s10851-024-01226-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defining consistent calculus frameworks on discrete meshes is useful for processing the geometry of meshes or model numerical simulations and variational problems onto them. However, digital surfaces (boundary of voxels) cannot benefit directly from the classical mesh calculus frameworks, since their vertex and face geometry is too poor to capture the geometry of the underlying smooth Euclidean surface well enough. This paper proposes three new calculus frameworks dedicated to digital surfaces, which exploit a corrected normal field, in a manner similar to the recent digital calculus of Coeurjolly and Lachaud (IAPR second international conference on discrete geometry and mathematical morphology, Springer, Berlin 2022). First, we build a corrected interpolated calculus by defining inner products with position and normal interpolation in the Grassmannian. Second, we present a corrected finite element method which adapts the standard Finite Element Method with a corrected metric per element. Third, we present a corrected virtual refinement method adapting the method of Bunge et al. (Comput Graph Forum 39(2):303–313, 2020, https://doi.org/10.1111/cgf.13931 ). Experiments show that these digital calculus frameworks seem to converge toward the continuous calculus, offer a valid alternative to classical mesh calculus, and induce effective tools for digital surface processing tasks. We then use these corrected Laplace–Beltrami operators in order to build a regularization method for digital surface, using geometric information given by discrete normal and curvature estimators.},
  archive      = {J_JMIV},
  author       = {Weill–Duflos, Colin and Coeurjolly, David and Lachaud, Jacques-Olivier},
  doi          = {10.1007/s10851-024-01226-6},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Corrected Laplace–Beltrami operators for digital surfaces},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recognition of pieces of arithmetic hyperplanes using the
stern–brocot tree. <em>JMIV</em>, <em>67</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s10851-025-01229-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical problem of discrete structure recognition is revisited in this paper. We focus on pieces of naive lines and, more generally, naive arithmetic hyperplanes, and present a new approach to recognising these discrete structures based on the Stern–Brocot tree. The algorithm for pieces of lines in dimension 2 proposes an alternative method to the state of the art, retaining linear complexity and incrementality for the segments. While most of the concepts can be generalised to planes in dimension 3 and hyperplanes in higher dimensions, certain points in the management of the descent in the Stern–Brocot tree merit further study. The proposed algorithm calculates separating chords characterising the membership of planes to cones generated by the branch of the Stern–Brocot tree. This generalisation shows the close link between arithmetic hyperplanes and the generalised Stern–Brocot tree and opens up interesting prospects for recognising pieces of arithmetic hyperplanes. Finally, we propose a geometric interpretation of separating chords and an interpretation of plane probing algorithms in the Stern–Brocot tree, showing both the links and the differences with our approach.},
  archive      = {J_JMIV},
  author       = {Laboureix, Bastien and Mattei, Alban and Lachaud, Jacques-Olivier and Debled-Rennesson, Isabelle},
  doi          = {10.1007/s10851-025-01229-x},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Recognition of pieces of arithmetic hyperplanes using the Stern–Brocot tree},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Morse sequences: A simple approach to discrete morse theory.
<em>JMIV</em>, <em>67</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s10851-025-01232-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop the notion of a Morse sequence, offering an alternative approach to discrete Morse theory that is both simple and effective. A Morse sequence on a finite simplicial complex consists solely of two elementary operations: expansions (the inverse of collapses) and fillings (the inverse of perforations). Alternatively, a Morse sequence can be constructed using only collapses and perforations, providing a dual perspective. Such sequences serve as another representation of the gradient vector field of an arbitrary discrete Morse function. To each Morse sequence, we associate a reference map and an extension map. The reference map assigns a set of critical simplices to each simplex in the complex, while the extension map assigns a set of simplices to each critical simplex. By considering the boundary of each critical simplex, these maps yield a chain complex that corresponds exactly to the Morse complex. We demonstrate that, when restricted to homology, the extension map is the inverse of the reference map. Furthermore, these maps enable a direct derivation of the isomorphism theorem, which establishes the equivalence between the homology of a given object and that of its Morse complex. Finally, we introduce the notion of an extension complex, defined exclusively in terms of extension maps. We prove that this concept is equivalent to the classical flow complex.},
  archive      = {J_JMIV},
  author       = {Bertrand, Gilles},
  doi          = {10.1007/s10851-025-01232-2},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Morse sequences: A simple approach to discrete morse theory},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing a kernel method for shape analysis in kendall
space. <em>JMIV</em>, <em>67</em>(2), 1–10. (<a
href="https://doi.org/10.1007/s10851-025-01235-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In learning methods defined on a manifold, it is often important to embed the manifold into a Hilbert space to apply kernel methods, as it enables the utilization of linear techniques in the transformed space, thereby facilitating complex data analysis and classification tasks with nonlinear structures [10]. In [6], the authors define an embedding of the $$\textit{m}$$ -dimensional Kendall shape space into an $$\mathbb {R}^{\textit{N}}$$ space, from which kernel methods are introduced in the Kendall shape space. In this paper, we significantly simplify this result by achieving an embedding of the Kendall shape space into a Euclidean space $$\mathbb {R}^{\textit{n}}$$ of much lower dimension $$\textit{n}$$ than $$\textit{N}$$ , greatly simplifying calculations and computational costs of applications. Additionally, we characterize the image of the Kendall shape space in $$\mathbb {R}^{\textit{n}}$$ , allowing us to define a new extrinsic mean of shapes in the Kendall shape space.},
  archive      = {J_JMIV},
  author       = {Gual-Arnau, Ximo and Monterde, Juan},
  doi          = {10.1007/s10851-025-01235-z},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-10},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Enhancing a kernel method for shape analysis in kendall space},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out-of-core algorithms for binary partition hierarchies.
<em>JMIV</em>, <em>67</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s10851-025-01234-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary partition hierarchies (BPH) and minimum spanning trees are essential data structures for hierarchical analysis, such as quasi-flat zones and watershed segmentation. Traditional BPH construction algorithms are limited by their requirement to load the data entirely into memory, making them impractical for processing large images whose processing exceeds the capacity of the computer’s main memory. To overcome this limitation, an algebraic framework was introduced, enabling the out-of-core computation of BPH leveraging three key operations: select, join, and insert. In this publication, we present two distinct calculi based on these operations: one designed for general spatial partitions and another optimized for causal partitioning. The second calculus is specifically tailored to meet out-of-core constraints, ensuring efficient processing of large-scale data. We provide detailed algorithms, including pseudo-code and complexity analysis, and conduct experimental comparisons between the two approaches.},
  archive      = {J_JMIV},
  author       = {Lefèvre, Josselin and Cousty, Jean and Perret, Benjamin and Phelippeau, Harold},
  doi          = {10.1007/s10851-025-01234-0},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Out-of-core algorithms for binary partition hierarchies},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical modeling of deep features to reduce false alarms
in video change detection. <em>JMIV</em>, <em>67</em>(2), 1–40. (<a
href="https://doi.org/10.1007/s10851-025-01238-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting relevant changes is a fundamental problem of video surveillance. Because of the high variability of data and the difficulty of properly annotating changes, unsupervised methods dominate the field. Arguably one of the most critical issues to make them practical is to reduce their false alarm rate. In this work, we develop a non-semantic, method-agnostic, weakly supervised a-contrario validation process, based on high-dimensional statistical modeling of deep features using a Gaussian mixture model, that can reduce the number of false alarms of any change detection algorithm. We also raise the insufficiency of the conventionally used pixel-wise evaluation, as it fails to precisely capture the performance needs of most real applications. For this reason, we complement pixel-wise metrics with component-wise metrics and evaluate the impact of our approach at both pixel and object levels, on six methods and several sequences from different datasets. Our experimental results reveal that the a-contrario theory can be applied to a statistical model of the background of a scene and largely reduce the number of false positives at both pixel and component levels.},
  archive      = {J_JMIV},
  author       = {Bou, Xavier and Artola, Aitor and Ehret, Thibaud and Facciolo, Gabriele and Morel, Jean-Michel and Gioi, Rafael Grompone von},
  doi          = {10.1007/s10851-025-01238-w},
  journal      = {Journal of Mathematical Imaging and Vision},
  month        = {4},
  number       = {2},
  pages        = {1-40},
  shortjournal = {J. Math. Imaging Vis.},
  title        = {Statistical modeling of deep features to reduce false alarms in video change detection},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jmui---7">JMUI - 7</h2>
<ul>
<li><details>
<summary>
(2025). Impact of communication modalities on social presence and
regulation processes in a collaborative game. <em>JMUI</em>,
<em>19</em>(1), 101–118. (<a
href="https://doi.org/10.1007/s12193-024-00450-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the digital era, leveraging communication technologies to foster collaborative learning is of utmost importance. This study explores the impact of different communication modalities, such as text, audio and video, on social presence and regulation processes within a computer-supported collaborative learning (CSCL) environment. Using learning analytics, we examine the influences of these modalities on collaboration and derive recommendations for their optimized use in the design of future CSCL environments. Our findings reveal a significant impact of communication modalities on the sense of social presence and regulation of collaborative activities. Audio communication results in enhanced co-presence, psychobehavioral accessibility, and better regulation processes compared to video and text modalities, indicating that audio is the most suitable modality in collaborative virtual environments for decision-making tasks. Conversely, video communication still facilitated strategic planning and enhanced self-regulation. Chat communication showed the lowest sense of social presence, yet improvements over time suggest that participants adapt to this modality, enhancing their collaborative efficiency.},
  archive      = {J_JMUI},
  author       = {Basille, Anthony and Lavoué, Élise and Serna, Audrey},
  doi          = {10.1007/s12193-024-00450-z},
  journal      = {Journal on Multimodal User Interfaces},
  month        = {3},
  number       = {1},
  pages        = {101-118},
  shortjournal = {J. Multimodal User Interfaces},
  title        = {Impact of communication modalities on social presence and regulation processes in a collaborative game},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vibration feedback reduces perceived difficulty of
virtualized fine motor task. <em>JMUI</em>, <em>19</em>(1), 93–99. (<a
href="https://doi.org/10.1007/s12193-024-00449-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Virtual Reality (VR) has been increasingly used in the development or rehabilitation of sensorimotor skills as it provides a safe, personalized, repeatable, realistic, and interactive environment. However, the use of VR technology to simulate fine motor interactions is still rather limited. This study evaluated the performance and user experience of a virtualized fine motor task and the potential impact of vibration feedback to complement the VR simulation. The Nine Hole Peg test (NHPT), which is widely used in health care to assess hand motor functions, was considered. 100 healthy subjects were recruited to compare the performance of the conventional, VR-based, and VR-based with vibration feedback (VR+vibration) implementation of the NHPT. Results demonstrated a significant increase in the task execution time (about 50% increase) in VR-based and VR+vibration conditions as compared to the conventional condition (Kruskal Wallis test, Bonferroni correction, p &lt; 0.0001). Participants reported a significant decrease in perceived difficulty of the VR+vibration condition as compared to the VR-based condition (Wilcoxon signed-rank test, p &lt; 0.05). Another interesting finding was the gender effect - female participants spent significantly more time completing the task in VR as compared to their male counterparts. These results indicate that vibration feedback enhances the usability of virtualized fine motor tasks.},
  archive      = {J_JMUI},
  author       = {Park, Wanjoo and Jamil, Muhammad Hassan and Eid, Mohamad},
  doi          = {10.1007/s12193-024-00449-6},
  journal      = {Journal on Multimodal User Interfaces},
  month        = {3},
  number       = {1},
  pages        = {93-99},
  shortjournal = {J. Multimodal User Interfaces},
  title        = {Vibration feedback reduces perceived difficulty of virtualized fine motor task},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pointing gestures accelerate collaborative problem-solving
on tangible user interfaces. <em>JMUI</em>, <em>19</em>(1), 75–92. (<a
href="https://doi.org/10.1007/s12193-024-00448-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaboration is included in the Learning and Innovation skills of the 21st Century. Collaborative problem-solving represents the interaction of two dimensions i) complex problem-solving and ii) collaboration. Technology-based assessment of collaborative problem-solving should focus on both dimensions. We ran user studies with 66 participants at three secondary schools in Luxembourg and Belgium to observe the gestural user behaviour of triads while solving a collaborative problem on a tangible user interface (TUI). Social interactions and embodiment by using gestures are important collaboration channels. Our main objective is the relation between the usage of gestures with collaboration and complex problem-solving performance. Our apparatus to test collaborative problem-solving is a tangible tabletop and a micro-world about power plants. We analysed the videos manually and found correlations between gestures, complex problem-solving performance, and user experience. The results showed that pointing gestures and adaptors significantly correlate with response time of problem-solving. Our results on user experience showed that the use of a TUI was regarded as a novel and straightforward solution that many people could learn to use very quickly. We suggest gesture performance to be considered as one indicator of collaboration.},
  archive      = {J_JMUI},
  author       = {Anastasiou, Dimitra and Maquil, Valérie},
  doi          = {10.1007/s12193-024-00448-7},
  journal      = {Journal on Multimodal User Interfaces},
  month        = {3},
  number       = {1},
  pages        = {75-92},
  shortjournal = {J. Multimodal User Interfaces},
  title        = {Pointing gestures accelerate collaborative problem-solving on tangible user interfaces},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmented conversations: AR face filters for facilitating
comfortable in-person interactions. <em>JMUI</em>, <em>19</em>(1),
57–74. (<a href="https://doi.org/10.1007/s12193-024-00446-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals with social anxiety often experience heightened anxiety during face-to-face conversations due to their fear of negative judgments when perceiving neutral facial expressions from others. This research aims to alleviate this anxiety by introducing a novel approach that involves overlaying visual effects onto the conversation partner via an augmented reality head-mounted display. We developed an AR application for HoloLens 2, allowing users to overlay either an anime-style avatar or a smiling face photo during in-person interactions. We conducted a user study where participants engaged in dyadic conversations using our AR application. 29 participants compared three conditions: control, anime-style avatar, and smiling face photo. The findings reveal two significant outcomes: (1) overlaying an anime-style avatar onto the conversation partner enhances conversational comfort, and (2) individuals with pronounced social interaction anxiety and intense fear of negative evaluation benefit from our AR-based system. This research presents possibilities for practical solutions that could improve the well-being of individuals with social anxiety during in-person conversations.},
  archive      = {J_JMUI},
  author       = {Yoneyama, Juri and Fujimoto, Yuichiro and Okazaki, Kosuke and Sawabe, Taishi and Kanbara, Masayuki and Kato, Hirokazu},
  doi          = {10.1007/s12193-024-00446-9},
  journal      = {Journal on Multimodal User Interfaces},
  month        = {3},
  number       = {1},
  pages        = {57-74},
  shortjournal = {J. Multimodal User Interfaces},
  title        = {Augmented conversations: AR face filters for facilitating comfortable in-person interactions},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effects of haptic, visual and olfactory augmentations on
food consumed while wearing an extended reality headset. <em>JMUI</em>,
<em>19</em>(1), 37–55. (<a
href="https://doi.org/10.1007/s12193-024-00447-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current food production system is unsustainable, necessitating a shift towards plant-based diets. Nutritious options fulfill basic needs but may not satisfy hedonic ones. Our novel approach is to promote healthier eating habits without compromising on the pleasantness of eating by using extended reality technologies and multimodal interaction. We present a multisensory augmentation system integrating augmentations in olfaction, touch, and vision. We studied the experience of eating plant-based balls and meatballs. In an experiment with 40 participants, haptic and visual augmentations were found to have significant effects: augmented meatballs and plant-based balls were perceived as bigger and heavier compared to non-augmented versions. However, olfactory augmentation did not produce a similar effect: participants did not notice a stronger aroma with augmented balls compared to non-augmented balls, and the augmented plant-based version had a less appealing scent than its non-augmented counterpart. Moreover, the findings of the study indicate that our multisensory augmentation system had no significant effect on taste perception.},
  archive      = {J_JMUI},
  author       = {Karhu, Natalia and Rantala, Jussi and Farooq, Ahmed and Sand, Antti and Pennanen, Kyösti and Lappi, Jenni and Nayak, Mohit and Sozer, Nesli and Raisamo, Roope},
  doi          = {10.1007/s12193-024-00447-8},
  journal      = {Journal on Multimodal User Interfaces},
  month        = {3},
  number       = {1},
  pages        = {37-55},
  shortjournal = {J. Multimodal User Interfaces},
  title        = {The effects of haptic, visual and olfactory augmentations on food consumed while wearing an extended reality headset},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and testing of (a)MICO: A multimodal feedback system
to facilitate the interaction between cobot and human operator.
<em>JMUI</em>, <em>19</em>(1), 21–36. (<a
href="https://doi.org/10.1007/s12193-024-00444-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present work describes the design, development and testing of a multimodal feedback system, named (A)MICO, with visual and acoustic feedback designed to facilitate the interaction of workers with collaborative robots (cobots) in production lines. The feedback is designed to make the human operator more aware of the cobot’s ongoing and future activities, and therefore gain more control over the situation. The ultimate goal is to obtain a new intuitive mode for transferring information through the combination of lights and sounds, not only to facilitate the flow of communication from the cobot to the operator, but also to make the interaction more accessible to neurodivergent groups, such as people with autism spectrum disorders. The design process focused on the evaluation of the human–robot interaction to select the situations where additional information is needed, and which is the best way to transfer messages as intuitively as possible. Potential end-users were actively involved during all stages of the design and development process. Five volunteers with high functioning autism participated in a preliminary co-design to identify the issues related to the interaction with the cobot and the logic of the multimodal signals. Then, to assess the system’s adaptability to several needs and the level of usability in providing information, validation tests were carried out involving a wider group of participants with ASD. The results suggest that the adoption of a multimodal communication strategy can be useful for making the workplace accessible and improving the well-being of all workers.},
  archive      = {J_JMUI},
  author       = {Dei, Carla and Meregalli Falerni, Matteo and Cilsal, Turgut and Redaelli, Davide Felice and Lavit Nicora, Matteo and Chiappini, Mattia and Storm, Fabio Alexander and Malosio, Matteo},
  doi          = {10.1007/s12193-024-00444-x},
  journal      = {Journal on Multimodal User Interfaces},
  month        = {3},
  number       = {1},
  pages        = {21-36},
  shortjournal = {J. Multimodal User Interfaces},
  title        = {Design and testing of (A)MICO: A multimodal feedback system to facilitate the interaction between cobot and human operator},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessment of comparative evaluation techniques for signing
agents: A study with deaf adults. <em>JMUI</em>, <em>19</em>(1), 1–19.
(<a href="https://doi.org/10.1007/s12193-024-00442-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign languages are considered fully-fledged and complete natural languages that are utilized by individuals who are deaf or hard of hearing as a means of communication within the visual-gestural modality. The utilization of virtual avatars as virtual assistants has witnessed a notable surge over the course of the previous fifteen years. Research on sign language recognition has already shown significant potential in achieving reliable and efficient automatic sign language recognition. Nevertheless, the development of physiologically believable (naturally looking) sign language synthesis and generation techniques is currently in its nascent stages. Moreover, traditional models often are rule-based, rely on manually programmed commands, and require the expertise of proficient interpreters, whereas data-driven approaches have the potential to offer more advanced solutions. In addition to the advancement of sign language systems, scholarly investigations indicate a notable lack in the signing systems evaluation by individuals who utilize sign language (deaf signers and interpreters). In this study, we introduce a sign language interpreting avatar based on data-driven techniques. Additionally, we conduct a subjective evaluation of the avatar’s performance. This paper presents the findings of a study conducted with deaf signers, which aimed to compare three different signing agents to a highly skilled sign language human interpreter. The study utilized well-known metrics that are considered to provide valuable insights into participants’ perceptions of signing agents, also their respective advantages and limitations.},
  archive      = {J_JMUI},
  author       = {Imashev, Alfarabi and Oralbayeva, Nurziya and Baizhanova, Gulmira and Sandygulova, Anara},
  doi          = {10.1007/s12193-024-00442-z},
  journal      = {Journal on Multimodal User Interfaces},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {J. Multimodal User Interfaces},
  title        = {Assessment of comparative evaluation techniques for signing agents: A study with deaf adults},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="joh---1">JOH - 1</h2>
<ul>
<li><details>
<summary>
(2025). An adaptive variable neighborhood search for the traveling
salesman problem with job-times. <em>JOH</em>, <em>31</em>(2), 1–65. (<a
href="https://doi.org/10.1007/s10732-025-09553-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Traveling Salesman Problem with Job-times (TSPJ) is an extension problem that integrates the Traveling Salesman Problem and the Job Scheduling Problem. TSPJ refers to finding the optimal route for a salesman to visit each location exactly once while assigning one job to each location. Each job can only be assigned once, and its completion time depends on the assigned location. The objective of the TSPJ is to minimize the maximum completion time of all jobs. This paper studies the problem from a new perspective and illustrates the realistic application scenarios of TSPJ. To solve the problem efficiently, we propose a Variable Neighborhood Search algorithm embedded in an adaptive shaking strategy and an intensive local search procedure. The adaptive shaking strategy invokes the small-perturbation or large-perturbation strategy according to the searching states and results during the searching procedure. In the proposed local search procedure, the first improvement strategy is adopted and the parameter of perturbation strength is updated for the following procedures. Experimental results on 310 benchmark instances demonstrate that the proposed algorithm outperforms the state-of-the-art heuristic methods. In particular, the best-known solutions are improved in 241 instances and the proposed algorithm can obtain the same results as the best-known solutions in 60 instances. Two statistical tests show that the results obtained by the proposed algorithm have significant differences from those of the compared methods and therefore verify the superiority of our method.},
  archive      = {J_JOH},
  author       = {Lan, Shaowen and Lu, Yongliang and Fan, Wenjuan},
  doi          = {10.1007/s10732-025-09553-6},
  journal      = {Journal of Heuristics},
  month        = {6},
  number       = {2},
  pages        = {1-65},
  shortjournal = {J. Heuristics},
  title        = {An adaptive variable neighborhood search for the traveling salesman problem with job-times},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jota---19">JOTA - 19</h2>
<ul>
<li><details>
<summary>
(2025). Constrained cubic grid rigidity decision with directed graph
and applications. <em>JOTA</em>, <em>205</em>(2), 1–23. (<a
href="https://doi.org/10.1007/s10957-025-02609-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a rigidity decision problem of constrained cubic grids in any given bracing pattern. The cubic grid bar and joint frameworks are not rigid. Additional constraints are required for rigidity. These constraints can be pinned down joints and additional bracing elements. Scaffoldings are not rigid cubic grid structures whose specific joints are pinned down. Inserting cable, strut, or rod bracing elements makes the framework rigid. Our model, which provides a linearly complex algorithm, has practical implications in testing the strong connectedness of a corresponding directed graph, contributing to the field of rigidity in structural engineering and motions of cable controlled pinned down cubic mechanisms.},
  archive      = {J_JOTA},
  author       = {Takács, Anna Mária and Katona, János and Baják, Szabolcs and Nagy Kem, Gyula},
  doi          = {10.1007/s10957-025-02609-4},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-23},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Constrained cubic grid rigidity decision with directed graph and applications},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strict efficiency in set optimization studied with the set
approach. <em>JOTA</em>, <em>205</em>(2), 1–20. (<a
href="https://doi.org/10.1007/s10957-025-02617-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to strict efficiency in set optimization studied with the set approach. Strict efficient solutions are defined with respect to the l-type less order relation and the possibly less order relation. Scalar characterization and necessary and/or sufficient conditions for such solutions are obtained. In particular, we establish some conditions expressed in terms of a high-order directional derivative of set-valued maps and the (convex or limiting) subdifferentials, normal cones and coderivatives. Various illustrating examples are presented.},
  archive      = {J_JOTA},
  author       = {Ha, Truong Xuan Duc},
  doi          = {10.1007/s10957-025-02617-4},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-20},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Strict efficiency in set optimization studied with the set approach},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved convergence rates for the multiobjective
frank–wolfe method. <em>JOTA</em>, <em>205</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s10957-025-02630-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the convergence rates of the Frank–Wolfe method for solving convex constrained multiobjective optimization. We establish improved convergence rates under different assumptions on the objective function, the feasible set, and the localization of the limit point of the sequence generated by the method. Notably, we demonstrate that the method can achieve linear convergence rates in terms of a merit function whenever the objectives are strongly convex and the limit point is in the relative interior of the feasible set, or when the feasible set is strongly convex and it does not contain an unconstrained weak Pareto point. Moreover, improved sublinear convergence rates can also be obtained in other scenarios where the feasible set is uniformly convex. Additionally, we explore enhanced convergence rates with respect to an optimality measure. Finally, we provide some simple examples to illustrate the convergence rates and the set of assumptions.},
  archive      = {J_JOTA},
  author       = {Gonçalves, Douglas S. and Gonçalves, Max L. N. and Melo, Jefferson G.},
  doi          = {10.1007/s10957-025-02630-7},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-25},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Improved convergence rates for the multiobjective Frank–Wolfe method},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Granularity for mixed-integer polynomial optimization
problems. <em>JOTA</em>, <em>205</em>(2), 1–24. (<a
href="https://doi.org/10.1007/s10957-025-02631-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding good feasible points is crucial in mixed-integer programming. For this purpose we combine a sufficient condition for consistency, called granularity, with the moment-/sum-of-squares-hierarchy from polynomial optimization. If the mixed-integer problem is granular, we obtain feasible points by solving continuous polynomial problems and rounding their optimal points. The moment-/sum-of-squares-hierarchy is hereby used to solve those continuous polynomial problems, which generalizes known methods from the literature. Numerical examples from the MINLPLib illustrate our approach.},
  archive      = {J_JOTA},
  author       = {Eggen, Carl and Stein, Oliver and Volkwein, Stefan},
  doi          = {10.1007/s10957-025-02631-6},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-24},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Granularity for mixed-integer polynomial optimization problems},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An extended c&amp;CG algorithm for solving two-stage robust
optimization of economic and feasible scheduling. <em>JOTA</em>,
<em>205</em>(2), 1–29. (<a
href="https://doi.org/10.1007/s10957-025-02642-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extensively researched column-and-constraint-generation (C&amp;CG) algorithm, which utilizes the KKT (Karush–Kuhn–Tucker) condition or duality theory to reformulate the subproblem, encounters challenges when solving two-stage robust optimization (TSRO) problems with extreme parameters that could adversely affect the feasibility of the second-stage decision. After the analysis of the original C&amp;CG algorithm, an extended C&amp;CG algorithm with multiple subproblems is proposed to overcome the challenges, which decompose a TSRO model into the master problem and several subproblems searching for the worst-case scenarios. A simple linear case is given to show the shortcoming of the traditional C&amp;CG algorithm and the advantage of the extended C&amp;CG algorithm. Then, a TSRO model for the scheduling optimization of electricity system considering the optimal power flow (OPF) is proposed, in order to explore the effectiveness of the extended C&amp;CG algorithm in handling the general optimization problem while considering the feasibility. Finally, the proposed solving method is validated by case studies.},
  archive      = {J_JOTA},
  author       = {Chen, Ruibin and Bao, Zhejing and Lu, Lingxia and Yu, Miao},
  doi          = {10.1007/s10957-025-02642-3},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-29},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {An extended C&amp;CG algorithm for solving two-stage robust optimization of economic and feasible scheduling},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Implementation of an optimization algorithm for a new
general class of two-dimensional fractional PDEs. <em>JOTA</em>,
<em>205</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s10957-025-02643-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the inherent numerical difficulties in the study of two-dimensional fractional differential equations (T-FDEs) make them challenging for investigation. In the present contribution, we introduce a new general class of T-FDEs to be solved. Their solution is addressed by the use of unique polynomials of the generalized shifted Legendre functions. For this purpose, we evaluate the association of new fractional and ordinary operational matrices using the Lagrange multipliers algorithm. The analysis of the convergence is done and the existence of a unique solution for the T-FDEs is proved. Three problems are considered to test the proposed methodology. It is pointed out that our methodology can be considered as a promising strategy to solve two-dimensional variable-order fractional differential equations and 2D variable-order fractional optimal control problems.},
  archive      = {J_JOTA},
  author       = {Avazzadeh, Zakieh and Hassani, Hossein and Ebadi, Mohammad Javad and Bayati Eshkaftaki, Ali and Hendy, Ahmed},
  doi          = {10.1007/s10957-025-02643-2},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Implementation of an optimization algorithm for a new general class of two-dimensional fractional PDEs},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Duality-based single-level reformulations of bilevel
optimization problems. <em>JOTA</em>, <em>205</em>(2), 1–39. (<a
href="https://doi.org/10.1007/s10957-025-02627-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Usually, bilevel optimization problems need to be transformed into single-level ones in order to derive optimality conditions and solution algorithms. Among the available approaches, the replacement of the lower-level problem by means of duality relations became popular quite recently. We revisit three realizations of this idea which are based on the lower-level Lagrange, Wolfe, and Mond–Weir dual problem. The resulting single-level surrogate problems are equivalent to the original bilevel optimization problem from the viewpoint of global minimizers under mild assumptions. However, all these reformulations suffer from the appearance of so-called implicit variables, i.e., surrogate variables which do not enter the objective function but appear in the feasible set for modeling purposes. Treating implicit variables as explicit ones has been shown to be problematic when locally optimal solutions, stationary points, and applicable constraint qualifications are compared to the original problem. Indeed, we illustrate that the same difficulties have to be faced when using these duality-based reformulations. Furthermore, we show that the Mangasarian–Fromovitz constraint qualification is likely to be violated at each feasible point of these reformulations, contrasting assertions in some recently published papers.},
  archive      = {J_JOTA},
  author       = {Dempe, Stephan and Mehlitz, Patrick},
  doi          = {10.1007/s10957-025-02627-2},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-39},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Duality-based single-level reformulations of bilevel optimization problems},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical shape optimization of an isothermal compressible
navier–stokes flow. <em>JOTA</em>, <em>205</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s10957-025-02634-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider numerical shape optimization of a compressible isothermal fluid model. The constrained system involves regularized compressible isothermal Navier–Stokes equations. The distributed and boundary type of shape gradients for objective functions (such as inverse problem, and energy dissipation power type) are derived via the adjoint method. The regularized Navier–Stokes equations are discretized with mixed finite element method and solved by the Leray-Schauder fixed point iterative scheme. Numerical results are presented to illustrate the effectiveness of the optimization algorithm proposed.},
  archive      = {J_JOTA},
  author       = {Zhang, Keyang and Li, Jiajie and Zhu, Shengfeng},
  doi          = {10.1007/s10957-025-02634-3},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-25},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Numerical shape optimization of an isothermal compressible Navier–Stokes flow},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regular subgradients of marginal functions with applications
to calculus and bilevel programming. <em>JOTA</em>, <em>205</em>(2),
1–30. (<a href="https://doi.org/10.1007/s10957-025-02635-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the study and applications of a broad class of extended-real-valued functions, known as optimal value or marginal functions, which frequently appear in variational analysis, parametric optimization, and a variety of applications. Functions of this type are intrinsically nonsmooth and require the usage of tools of generalized differentiation. The main results of this paper provide novel evaluations and exact calculations of regular/Fréchet subgradients and their singular counterparts for general classes of marginal functions via their given data. The obtained results are applied to establishing new calculus rules for such subgradients and necessary optimality conditions in bilevel programming.},
  archive      = {J_JOTA},
  author       = {Phuoc Hai, Le and Lara, Felipe and Mordukhovich, Boris S.},
  doi          = {10.1007/s10957-025-02635-2},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-30},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Regular subgradients of marginal functions with applications to calculus and bilevel programming},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical approximation of riccati-based hyperbolic-like
feedback controls. <em>JOTA</em>, <em>205</em>(2), 1–45. (<a
href="https://doi.org/10.1007/s10957-025-02640-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a (rigorous) theoretical framework for the numerical approximation of Riccati-based feedback control problems of hyperbolic-like dynamics over a finite-time horizon, with emphasis on genuine unbounded control action. Both continuous and approximation theories are illustrated by specific canonical hyperbolic-like equations with boundary control, where the abstract assumptions are actually sharp regularity properties of the hyperbolic dynamics under discussion. Assumptions are divided in two groups. A first group of dynamical assumptions (actually dynamic properties) imply some preliminary critical properties of the control problem, including the definition of the would-be Riccati operator, in terms of the original data. However, in order to guarantee that such an operator is moreover the unique solution (within a specific class) of the corresponding Differential/Integral Riccati Equation, additional smoothing assumptions on the operators defining the performance index are required. The ultimate goal is to show that the the discrete finite dimensional Riccati based feedback operator, when inserted into the original PDE dynamics, provides near optimal performance.},
  archive      = {J_JOTA},
  author       = {Lasiecka, Irena and Triggiani, Roberto and Wan, Xiang},
  doi          = {10.1007/s10957-025-02640-5},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-45},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Numerical approximation of riccati-based hyperbolic-like feedback controls},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strongly quasiconvex functions: What we know (so far).
<em>JOTA</em>, <em>205</em>(2), 1–41. (<a
href="https://doi.org/10.1007/s10957-025-02641-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduced by Polyak in 1966, the class of strongly quasiconvex functions includes some interesting nonconvex members, like the square root of the Euclidean norm or ratios with a nonnegative strongly convex numerator and a concave and positive denominator. This survey collects the vast majority of the results involving strongly quasiconvex functions available in the literature at the moment, presenting, in particular, algorithms for minimizing such functions, and suggests some directions where additional investigations would be welcome.},
  archive      = {J_JOTA},
  author       = {Grad, Sorin-Mihai and Lara, Felipe and Marcavillaca, Raúl T.},
  doi          = {10.1007/s10957-025-02641-4},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-41},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Strongly quasiconvex functions: What we know (So far)},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New penalized stochastic gradient methods for linearly
constrained strongly convex optimization. <em>JOTA</em>,
<em>205</em>(2), 1–40. (<a
href="https://doi.org/10.1007/s10957-025-02646-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For minimizing a strongly convex objective function subject to linear inequality constraints, we consider a penalty approach that allows one to utilize stochastic methods for problems with a moderate to large number of constraints and/or objective function terms. We provide upper bounds on the distance between the solutions to the original constrained problem and the penalty reformulations, guaranteeing the convergence of the proposed approach. We consider a static method that uses a fixed smoothness parameter for the penalty function as well as a dynamic nested method with a novel way for updating the smoothness parameter of the penalty function and the step-size. In both cases, we apply accelerated stochastic gradient methods and study the expected incremental/stochastic gradient iteration complexity to produce a solution within an expected distance of $$\epsilon $$ to the optimal solution of the original problem. We show that this complexity is proportional to $$m\sqrt{\frac{m}{\mu \epsilon }}$$ , where m is the number of constraints and $$\mu $$ is the strong convexity parameter of the objective function, which improves upon existing results when m is not too large. We also show how to query an approximate dual solution after stochastically solving the penalty reformulations, leading to results on the convergence of the duality gap. Moreover, the nested structure of the algorithm and upper bounds on the distance to the optimal solutions allows one to safely eliminate constraints that are inactive at an optimal solution throughout the algorithm, which leads to improved complexity results. Finally, we present computational results that demonstrate the effectiveness and robustness of our algorithm.},
  archive      = {J_JOTA},
  author       = {Li, Meng and Grigas, Paul and Atamtürk, Alper},
  doi          = {10.1007/s10957-025-02646-z},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-40},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {New penalized stochastic gradient methods for linearly constrained strongly convex optimization},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully zeroth-order bilevel programming via gaussian
smoothing. <em>JOTA</em>, <em>205</em>(2), 1–39. (<a
href="https://doi.org/10.1007/s10957-025-02647-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study and analyze zeroth-order stochastic approximation algorithms for solving bilevel problems when neither the upper/lower objective values nor their unbiased gradient estimates are available. In particular, exploiting Stein’s identity, we first use Gaussian smoothing to estimate first- and second-order partial derivatives of functions with two independent block of variables. We then use these estimates in the framework of a stochastic approximation algorithm for solving bilevel optimization problems and establish its non-asymptotic convergence analysis. To the best of our knowledge, this is the first time that sample complexity bounds are established for a fully stochastic zeroth-order bilevel optimization algorithm.},
  archive      = {J_JOTA},
  author       = {Aghasi, Alireza and Ghadimi, Saeed},
  doi          = {10.1007/s10957-025-02647-y},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-39},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Fully zeroth-order bilevel programming via gaussian smoothing},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex representation matrix of third-order quaternion
tensors with application to video inpainting. <em>JOTA</em>,
<em>205</em>(2), 1–33. (<a
href="https://doi.org/10.1007/s10957-025-02648-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternion tensors are currently applied widely across various scientific and engineering fields. However, the inherent multiple imaginary components of quaternions and their non-commutative multiplication pose significant challenges to the computational efficiency of quaternion tensors. In this paper, we introduce a complex representation matrix (CRM) for third-order quaternion tensors based on the specific algebraic structure. With the discrete Fourier transform, the novel CRM framework demonstrates distinctive advantages through its advantageous algebraic characteristics, which not only establish its theoretical uniqueness but also enable effective transformation of quaternion tensor optimization problems into the complex domain for efficient solution. The proposed CRM features a block-diagonal structure, enabling efficient large-scale computations and enhancing its suitability for high-dimensional problems. To evaluate its advantages in video inpainting, two CRM-based quaternion tensor completion methods are introduced. Simulation studies and example analyses confirm their effectiveness and efficiency.},
  archive      = {J_JOTA},
  author       = {Wu, Fengsheng and Li, Chaoqian and Li, Yaotang and Tang, Niansheng},
  doi          = {10.1007/s10957-025-02648-x},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-33},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Complex representation matrix of third-order quaternion tensors with application to video inpainting},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimality conditions at infinity for nonsmooth minimax
programming problems with some applications. <em>JOTA</em>,
<em>205</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s10957-025-02652-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the study of optimality conditions at infinity in nonsmooth minimax programming problems and their applications. By means of the limiting subdifferential and the normal cone at infinity, we derive necessary and sufficient optimality conditions of the Karush–Kuhn–Tucker type for nonsmooth minimax programming problems with constraints. The obtained results are applied to nonsmooth vector optimization problems and robust minimax optimization ones.},
  archive      = {J_JOTA},
  author       = {Van Tuyen, Nguyen and Bae, Kwan Deok and Kim, Do Sang},
  doi          = {10.1007/s10957-025-02652-1},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-22},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Optimality conditions at infinity for nonsmooth minimax programming problems with some applications},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Galerkin-like method for integro-differential inclusions
with applications to volterra sweeping processes. <em>JOTA</em>,
<em>205</em>(2), 1–30. (<a
href="https://doi.org/10.1007/s10957-025-02653-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop the Galerkin-like method to address first-order integro-differential inclusions. Under compactness or monotonicity conditions, we obtain new results for the existence of solutions for this class of problems, which generalize existing results in the literature and provide new insights for differential inclusions with an unbounded right-hand side. The effectiveness of the proposed approach is illustrated by presenting new existence results for nonconvex state-dependent Volterra sweeping processes, where the right-hand side is unbounded, and the classical theory of differential inclusions is not applicable. This is the first result of its kind. The paper concludes with an application to the existence of an optimal control problem governed by nonconvex state-dependent Volterra sweeping processes in finite dimensions.},
  archive      = {J_JOTA},
  author       = {Pérez-Aros, Pedro and Torres-Valdebenito, Manuel and Vilches, Emilio},
  doi          = {10.1007/s10957-025-02653-0},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-30},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Galerkin-like method for integro-differential inclusions with applications to volterra sweeping processes},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Horizon and recession asymptotic notions for sets and
mappings: A unified approach. <em>JOTA</em>, <em>205</em>(2), 1–31. (<a
href="https://doi.org/10.1007/s10957-025-02655-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to develop a unified theory of horizon and recession asymptotic notions for sets, functions, and multifunctions. This unified approach allows to exploit both the algebraic and topological features of these objects. We study the notion of regular set defined as a set for which its horizon and recession cones coincide. This notion plays an important role in the theory. Regular functions and multifunctions are defined and studied as well. By using the unified approach, we obtain properties, formulas, calculus rules, and relationships for horizon and recession notions. Finally, we study the horizon and recession mappings of various important functions and multifunctions from variational analysis.},
  archive      = {J_JOTA},
  author       = {García, Yboon and Goicochea, Bruno and López, Rubén and Martínez, Javier},
  doi          = {10.1007/s10957-025-02655-y},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-31},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Horizon and recession asymptotic notions for sets and mappings: A unified approach},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A jacobian-free method for the nearest doubly stochastic
matrix problem. <em>JOTA</em>, <em>205</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s10957-025-02656-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the nearest doubly stochastic matrix problem, which encompasses many important real-world applications. Theoretically, we show that the problem under consideration can be equivalently reformulated as the system of nonsmooth monotone equations, the mapping of which is Lipschitz continuous. To the best of our knowledge, this is the first theoretical result, showing that the underlying mapping owns the Lipschitz continuity and monotonicity. Moreover, the scale of the system is significantly smaller than that of the KKT optimality conditions for the original problem. Based on a scaling memoryless DFP formula, a Jacobian-free method with a modified Armijo line search is proposed for solving such a system. By the aid of the Lipschitz continuity and monotonicity of the underlying mapping, the global convergence and iteration complexity for the proposed method are established. Importantly, we illustrate for the first time that the Armijo line search mentioned above is superior to the original one in terms of iteration complexity. This also opens the door to improve the iteration complexity of Jacobian-free methods by designing an appropriate line search. Furthermore, the local linear rate of convergence established in this paper is new compared with existing Jacobian-free methods for solving nonsmooth monotone equations. Finally, numerical results illustrating the practical behavior of the presented method are reported.},
  archive      = {J_JOTA},
  author       = {Yin, Jianghua and Li, Yaobiao and Tang, Chunming},
  doi          = {10.1007/s10957-025-02656-x},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-25},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {A jacobian-free method for the nearest doubly stochastic matrix problem},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal synthesis control for evolution equations subject to
nonlocal inputs. <em>JOTA</em>, <em>205</em>(2), 1–32. (<a
href="https://doi.org/10.1007/s10957-025-02661-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the linear quadratic (LQ) optimal control problem for a class of evolution equations in infinite dimensions, in the presence of distributed and nonlocal inputs. Following a perspective akin to the one taken in our previous research work on the LQ problem for integro-differential equations—which combines a variational approach to the minimization problem with the consideration of a suitably enlarged state space—we offer a full (closed-loop, Riccati-based) solution to the optimization problem.},
  archive      = {J_JOTA},
  author       = {Acquistapace, Paolo and Bucci, Francesca},
  doi          = {10.1007/s10957-025-02661-0},
  journal      = {Journal of Optimization Theory and Applications},
  month        = {5},
  number       = {2},
  pages        = {1-32},
  shortjournal = {J. Optim. Theory Appl.},
  title        = {Optimal synthesis control for evolution equations subject to nonlocal inputs},
  volume       = {205},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jrtip---37">JRTIP - 37</h2>
<ul>
<li><details>
<summary>
(2025). Real-time detection method of intelligent classification and
defect of transmission line insulator based on LightWeight-YOLOv8n
network. <em>JRTIP</em>, <em>22</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s11554-025-01627-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the difficulty in distinguishing different types of insulators in transmission lines and the need for intelligent identification of insulator defects, a real-time detection method for intelligent classification and defect identification of transmission line insulators based on a LightWeight-YOLOv8n network is proposed. This method is used to efficiently detect isolator defects in complex environments and to quickly identify isolator classes. The LightWeight network model MobileNetV3 is used as the backbone network and is based on the YOLOv8n model. The feature extraction ability of the model is enhanced, the redundancy of model parameters is reduced, and the detection speed is improved by adding the SimAM attention mechanism at the end of the backbone network. The LightWeight CSPPC module is used to enhance the feature fusion component of YOLOv8n, reducing the computation load and network complexity while maintaining the accuracy of the model. To further improve the performance of the algorithm, the WIoUv3 bounding box regression loss function is used to replace the original CIoU loss function, and the SlideLoss is used to replace ClsLoss as the category loss function. The experimental results show that the detection accuracy reaches 92.4%, the recall rate reaches 86.6%, and the mAP50 reaches 90.6%. Meanwhile, the training speed is increased by 40.54%, floating-point operation is reduced by 28.57%, and the model parameters are reduced by 34%. Heatmap visualization analysis also showed that the improved models exhibited greater concentration and confidence than the baseline models. Compared to other algorithms, LightWeight-YOLOv8n showed significant advantages in overall performance, accuracy, and real-time target detection. After a random test of 100 images from the test set, the LightWeight-YOLOv8n model exhibited the lowest detection speed and was able to achieve real-time detection.},
  archive      = {J_JRTIP},
  author       = {Tan, Guoguang and Ye, Yongsheng and Chu, Jiawei and Liu, Qiang and Xu, Li and Wen, Bin and Li, Lili},
  doi          = {10.1007/s11554-025-01627-9},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Real-time detection method of intelligent classification and defect of transmission line insulator based on LightWeight-YOLOv8n network},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight YOLOv7 for bushing surface defects detection.
<em>JRTIP</em>, <em>22</em>(2), 1–12. (<a
href="https://doi.org/10.1007/s11554-025-01630-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bushings have a wide range of applications in industry. Once the surface of the bushing is defective, it will affect the assembly between bearings resulting in mechanical inefficiency. At present, due to the different target sizes of the different types of defects on the bushing surface, it is difficult to balance inspection accuracy and speed. This paper proposes lightweight You Only Look Once (YOLO) v7 networks to cope with this problem. In this paper, we use a lightweight network, MobileNetv3, as the backbone network, in which a Residual edges CBAM block (RC-block) is designed to retain feature information while focusing on small-scale targets; finally, we use a bi-directional feature pyramid network (BiFPN) to perform feature fusion to further improve the detection accuracy. The experimental results show that the improved model reduces the Mean Average Precision (mAP) by only $$0.7\%$$ compared with the traditional YOLOv7 model, but the detection speed is increased by $$29.4\%$$ , and the model volume is reduced by $$29.9\%$$ , effectively improves the detection accuracy and speed of all kinds of defects on the surface of the bushings. The improved model was trained under the publicly available dataset NEU-DET, and the results showed the generalisability of the model.},
  archive      = {J_JRTIP},
  author       = {Cheng, Wenjun and Zeng, Pengfei and Hao, Yongping},
  doi          = {10.1007/s11554-025-01630-0},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-12},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Lightweight YOLOv7 for bushing surface defects detection},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ESF-DETR: A real-time and high-precision detection model for
cigarette appearance. <em>JRTIP</em>, <em>22</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s11554-025-01632-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality of cigarettes is greatly affected by appearance defects. Achieving automatic detection of these defects with high precision and speed has been a critical concern for cigarette factories. To meet the needs of manufacturers in detecting appearance defects in cigarettes, this paper proposes a model based on DETR (DEtection TRansformer) for detecting cigarette appearance defects. The model integrates EfficientViT, SENetV2, and FuNet (Full-scale Feature Fusion Network), called ESF-DETR. First, EfficientViT serves as the backbone feature extraction network, substantially reducing model parameters and enhancing feature extraction efficiency. Second, SENetV2 is introduced at the end of the backbone network to improve feature expression accuracy and global information integration capability. Third, the Full-scale Feature Fusion Network (FuNet) is proposed as the encoder, further reducing model parameters while increasing spatial location and high-level semantic information across each feature layer. The proposed ESF-DETR model achieves a mAP of 96.0% with a parameter count of 10.1M. Compared to the original model, the mAP has increased by 4.4%, while the number of parameters has decreased by 49.8%. Additionally, the detection speed reaches 500 FPS, satisfying cigarette production lines’ accuracy and speed requirements.},
  archive      = {J_JRTIP},
  author       = {Ding, Yingchao and Yuan, Guowu and Zhou, Hao and Wu, Hao},
  doi          = {10.1007/s11554-025-01632-y},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-13},
  shortjournal = {J. Real-Time Image Process.},
  title        = {ESF-DETR: A real-time and high-precision detection model for cigarette appearance},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Drone object detection incorporating multi-head mixed
self-attention and dynamic regression mapping loss function.
<em>JRTIP</em>, <em>22</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s11554-025-01633-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drone object detection is a critical area within computer vision, facing challenges such as low accuracy in detecting large occluded objects and high rates of missed detection for small objects. These issues arise from inadequate emphasis on the distinctive features of the target area during detection and the regression enhancement of low-quality training examples. To tackle these challenges, this paper introduces a novel method for drone object detection that integrates multi-head mixed self-attention with a dynamic regression mAPping loss function. Initially, a Multi-head Mixed Self-Attention mechanism (MMSA) is developed, tailored to the characteristics of occluded object images. This mechanism is embedded into the backbone and neck components of YOLOv8n to bolster feature extraction and fusion. Subsequently, a dedicated layer for small object detection is incorporated into YOLOv8n to enhance its capability in detecting small objects. A new loss function, Focaler-WIoU, is formulated by merging Focaler-IoU and WIoU, aiming to improve detection across various object scales and accelerate the convergence of bounding box regression loss while enhancing localization accuracy. Additionally, Soft NMS is employed to refine candidate bounding boxes, mitigating missed detections in scenarios with overlapping similar targets. Evaluations on the public dataset VisDrone2019 using standard metrics, including ablation and model comparison experiments, reveal an average precision (mAP @0.5) improvement of 10.2% over the baseline YOLOv8n. The proposed method outperforms other algorithms such as Drone-YOLO (nano), YOLOv11n, Faster RCNN, and FE-YOLOv5 in detection accuracy. Further validation on datasets like CityPersons and CrowdHuman underscores the versatility of the improved algorithm. The experimental outcomes confirm that the MMSA attention mechanism significantly enhances the detection of occluded objects, achieving superior accuracy compared to established object detection algorithms. This suggests that the proposed method holds substantial practical and general applicability for drone image detection in natural settings. Detailed code is available at https://github.com/CodeSworder/MMSA .},
  archive      = {J_JRTIP},
  author       = {Su, Qinghua and Mu, Jianhong and Xu, Sheng and Wan, Kaizheng and Qi, Xiangyu and Zhang, Zhichao and Li, Juntao},
  doi          = {10.1007/s11554-025-01633-x},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Drone object detection incorporating multi-head mixed self-attention and dynamic regression mapping loss function},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time dynamic scale-aware fusion detection network: Take
road damage detection as an example. <em>JRTIP</em>, <em>22</em>(2),
1–12. (<a href="https://doi.org/10.1007/s11554-025-01634-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicle (UAV)-based Road Damage Detection (RDD) is important for daily maintenance and safety in cities, especially in terms of significantly reducing labor costs. However, current UAV-based RDD research still faces many challenges. For example, the damage with irregular size and direction, the masking of damage by the background, and the difficulty of distinguishing damage from the background significantly affect the ability of UAV to detect road damage in daily inspection. To solve these problems and improve the performance of UAV in real-time road damage detection, we design and propose three corresponding modules: a feature extraction module that flexibly adapts to shape and background; a module that fuses multiscale perception and adapts to shape and background; an efficient downsampling module. Based on these modules, we designed a multi-scale, adaptive road damage detection model with the ability to automatically remove background interference, called Dynamic Scale-Aware Fusion Detection Model (RT-DSAFDet). Experimental results on the UAV-PDD2023 public dataset show that our model RT-DSAFDet achieves a mAP50 of 54.2%, which is 11.1% higher than that of YOLOv10-m, an efficient variant of the latest real-time object detection model YOLOv10, while the amount of parameters is reduced to 1.8M and FLOPs to 4.6G, with a decrease by 88% and 93%, respectively. Furthermore, on the large generalized object detection public dataset MS COCO2017 also shows the superiority of our model with mAP50–95 is the same as YOLOv9-t, but with 0.5% higher mAP50, 10% less parameters volume, and 40% less FLOPs.},
  archive      = {J_JRTIP},
  author       = {Pan, Weichao and Wang, Xu and Huan, Wenqing},
  doi          = {10.1007/s11554-025-01634-w},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-12},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Real-time dynamic scale-aware fusion detection network: Take road damage detection as an example},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced underwater object detection with YOLO-LDFE: A model
for improved accuracy with balanced efficiency. <em>JRTIP</em>,
<em>22</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s11554-025-01628-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In underwater image analysis, challenges such as complex environments, low model performance, and slow processing efficiency hinder effective object detection, which is crucial for real-time monitoring. To address these issues, we propose a high-precision underwater object detection model named YOLO-LDFE. To overcome the limitations of existing datasets, we have developed a comprehensive multi-species underwater biological dataset, MCUA, containing 9327 labeled images across 14 categories. The primary contributions of this work are as follows: (1) SPPF_SCSA, which integrates multi-semantic information with channel-space attention mechanisms to enhance performance; (2) the substitution of traditional convolutions with GSConv in C2f, reducing model size while maintaining feature extraction; (3) LEDF, which improves performance through multi-level, dense connections. YOLO-LDFE achieves exceptional results, with an average precision of 93% on the URPC2021 dataset, outperforming existing algorithms while maintaining high detection speed, demonstrating its potential for real-time underwater monitoring.},
  archive      = {J_JRTIP},
  author       = {Liu, JiaXin and Zhou, RiGui and Li, YaoChong and Ren, PengJu},
  doi          = {10.1007/s11554-025-01628-8},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Enhanced underwater object detection with YOLO-LDFE: A model for improved accuracy with balanced efficiency},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive receptive field and attention-guided feature
enhancement for ceramic tile surface defect detection. <em>JRTIP</em>,
<em>22</em>(2), 1–12. (<a
href="https://doi.org/10.1007/s11554-025-01636-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the challenges of diverse defect shapes, small defect sizes, and real-time detection on ceramic tile surfaces, this paper proposes an efficient anchor-free detector that integrates adaptive receptive fields and feature enhancement. First, the anchor-free YOLOv8 is proposed as the detection framework to eliminate the need for setting anchor-related hyperparameters, thus avoiding their impact on performance. Second, an adaptive receptive field module (ARFM) is introduced, which extracts defect features from multiple scales through constructing several parallel branches and fuses the feature maps from different receptive fields, thereby dynamically adjusting the receptive field to detect various defects. Finally, a feature enhancement module (FEM) is added to the neck part, enhancing feature representation from both global and spatial dimensions to reduce feature information loss and improve defect detection performance. Experiments show that our detector achieves a mean average precision of 70.4%, an improvement of 6.1% over YOLOv8, while maintaining a high detection speed of 121.2 frames per second. This performance surpasses the state-of-the-art detection methods. These results indicate that our proposed model can achieve satisfactory defect detection performance, meeting the industry’s real-time detection needs.},
  archive      = {J_JRTIP},
  author       = {Yu, Songsen and Wang, Zhemeng},
  doi          = {10.1007/s11554-025-01636-8},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-12},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Adaptive receptive field and attention-guided feature enhancement for ceramic tile surface defect detection},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCR-YOLOv8: An enhanced algorithm for target detection in
sonar images. <em>JRTIP</em>, <em>22</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s11554-025-01637-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sonar imaging plays a pivotal role in the detection of targets underwater. However, the performance of most sonar detection methods is suboptimal due to the complexity of the underwater environment and its susceptibility to noise interference. To address these issues, this paper proposes a SCR-YOLOv8 algorithm based on an enhanced YOLOv8 architecture. This algorithm aims to overcome the challenges associated with traditional sonar target detection. The proposed approach involves two primary modifications: first, the Conv module in the trunk and neck networks is replaced with the more efficient SPDConv. Second, the CCFM module is introduced to reduce the model size and number of parameters. Subsequently, the Spatial Channel Reconstruction Module (SCRM) is employed. The design of the feature extraction and fusion stage of the model is intended to enhance the model’s efficiency in extracting contextual information from both spatial and channel dimensions. Finally, the Inner-CIoU is employed in lieu of the CIoU to achieve regression results that are both faster and more effective. The experimental results demonstrate that, in comparison with the baseline model, SCR-YOLOv8 enhances precision, recall, and mAP50 by 2.9%, 5.8%, and 2.3%, respectively. Concurrently, the model size and the computational complexity are diminished by 40.2% and 21.4%, respectively.Moreover, a frame rate of 91 FPS is attained, meeting the criteria for real-time detection.},
  archive      = {J_JRTIP},
  author       = {Weng, Youlei and Xiang, Xiaodong and Ma, Linghang},
  doi          = {10.1007/s11554-025-01637-7},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Real-Time Image Process.},
  title        = {SCR-YOLOv8: An enhanced algorithm for target detection in sonar images},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight outdoor drowning detection based on improved
YOLOv8. <em>JRTIP</em>, <em>22</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s11554-025-01638-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite abundant global water resources, drowning remains one of the complex challenges to tackle worldwide. To solve the problem of complicated outdoor remote water environments, where people in the water have different morphologies and scale variations, and the existing detection models are highly complex and computationally intensive, we propose a lightweight drowning detection model, YOLOv8-REH, based on YOLOv8n. First, the C2f-RVB-ELA feature extraction module (effective fusion of C2f and RVB-ELA) is designed to improve the C2f module of the YOLOv8n backbone network, reducing the model’s parameters and computation effectively. Second, in the Neck section, we incorporate the ELA-HSFPN feature fusion module, which consists of the Hierarchical Scale-based Feature Pyramid Network (HSFPN) module and the Efficient Local Attention (ELA) mechanism. This helps us gather multi-scale and spatial information perception more comprehensively and efficiently, enhancing the feature fusion capability of the model. Then, we introduce the Powerful-IoUv2 loss function to enhance bounding box regression along the effective path, consequently improving the model’s convergence speed and detection performance. Finally, we use a pruning method based on layer-adaptive magnitude-based pruning scoring to prune and remove unimportant redundant parameters from the improved model, further compressing the model complexity and achieving a better lightweight effect. The final compressed YOLOv8-REH model is compared with the current mainstream algorithms for comparison experiments as well as ablation experiments. The experimental results indicate that the YOLOv8-REH model sustains an average detection accuracy while the computational volume, parameter count, and model size reach 3.7GFLOPs, 0.72 M, and 1.8 MB, and the FPS is improved by 22.9, which achieves a significant improvement in the model’s lightweight performance compared with the existing methods.},
  archive      = {J_JRTIP},
  author       = {Liu, Xiangju and Shuai, Tao and Liu, Dezeng},
  doi          = {10.1007/s11554-025-01638-6},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Lightweight outdoor drowning detection based on improved YOLOv8},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMC-net: A lightweight network for real-time surface defect
segmentation. <em>JRTIP</em>, <em>22</em>(2), 1–11. (<a
href="https://doi.org/10.1007/s11554-025-01639-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In industrial applications, surface defect segmentation is a critical task. However, facing challenges such as diverse defect scales, low contrast between defects and background, high interclass similarity and real-time detection in defect inspection, we propose an efficient lightweight network, named DMC-Net, for real-time surface defect segmentation. The structural optimization of DMC-Net includes the following components: (1) depthwise separable convolution attention module, a lightweight and efficient feature extraction module for extracting multi-scale defect features. (2) Multi-scale feature enhancement module, providing long-range information capture and local information focusing to enhance defect localization capability. (3) Channel shuffle group convolution, enhancing feature interaction and information propagation while reducing the parameter quantity. Based on the experimental results, DMC-Net achieved an mIoU of 73.74% on the NEU-SEG dataset, while achieving an FPS of 211.7. This indicates that we have successfully reduced the complexity and computational cost of the model while improving performance, providing a feasible solution for industrial applications. The relevant code can be obtained at https://github.com/Michaelzyb/DMC-Net.git.},
  archive      = {J_JRTIP},
  author       = {Zuo, Haiqiang and Zheng, Yubo and Huang, Qizhou and Du, Zehao and Wang, Hao},
  doi          = {10.1007/s11554-025-01639-5},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-11},
  shortjournal = {J. Real-Time Image Process.},
  title        = {DMC-net: A lightweight network for real-time surface defect segmentation},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time recognition research for an automated egg-picking
robot in free-range duck sheds. <em>JRTIP</em>, <em>22</em>(2), 1–15.
(<a href="https://doi.org/10.1007/s11554-025-01640-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving efficient and accurate detection and localization of duck eggs in the unstructured environment of free-range duck sheds is crucial for developing automated egg-picking robots. This paper proposes an improved YOLOv5s-based model (YOLOv5s-MNKS) designed to enhance detection performance, reduce model complexity, and improve the robot’s adaptability and operational efficiency in complex environments. The model utilizes MobileNetV3 as the backbone network, reducing the number of parameters and increasing detection speed. The Squeeze-and-Excitation Module is replaced with a Normalization-based Attention Module to improve feature extraction capability. Group Shuffle Convolution and Bidirectional Feature Pyramid Network are introduced in the Neck layer, enhancing multi-scale feature fusion while reducing parameter count. A Soft-CIoU-NMS loss function is also designed, which improves detection accuracy in scenarios involving dense stacking and occlusion by lowering the confidence of overlapping bounding boxes instead of directly eliminating them. Experimental results demonstrate that the mAP of YOLOv5s-MNKS reaches 95.6%, representing a 0.3% improvement over the original model, while the model size is reduced to 5.7 MB, approximately 40% of the original size. When deployed on the Jetson Nano embedded platform with TensorRT acceleration, the model achieves a detection frame rate of 22.3 frames per second. In simulated and real-world duck shed scenarios, the improved model accurately and quickly identifies and locates duck eggs in complex environments, including occlusion, stacking, and low lighting, demonstrating strong robustness and applicability. This research provides technical support for the future development of duck egg-picking robots.},
  archive      = {J_JRTIP},
  author       = {Jie, Dengfei and Wang, Jun and Wang, Hao and Lv, Huifang and He, Jincheng and Wei, Xuan},
  doi          = {10.1007/s11554-025-01640-y},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Real-time recognition research for an automated egg-picking robot in free-range duck sheds},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EF-RT-DETR: A efficient focused real-time DETR model for
pavement distress detection. <em>JRTIP</em>, <em>22</em>(2), 1–12. (<a
href="https://doi.org/10.1007/s11554-025-01641-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification and localization of road distress play a crucial role in intelligent road health monitoring systems. To address the challenges of complex road backgrounds, diverse shapes of distress objects, and high computational resource requirements, this paper proposes an efficient focusing real-time road distress detection model (EF-RT-DETR). Based on RT-DETR, the model designs a new backbone network aimed at accurately capturing fine features and optimizes the attention mechanism to effectively reduce interference from complex backgrounds while enhancing the processing of detailed information. Additionally, an innovative fusion module is introduced in the feature fusion stage to further enhance the interaction between local and global features, while also reducing computational costs. Experiments conducted on the China_Motorbike subset of the RDD2022 dataset include ablation studies to validate the effectiveness of the proposed modules. The experimental results show that EF-RT-DETR reduced background false positives compared to the baseline model, with $${\hbox {mAP}}_{50}$$ and $${\hbox {mAP}}_{50:95}$$ improving by 9.5 and 7.1%, respectively, while reducing computation by 35.4% and the number of parameters by 25.7%.},
  archive      = {J_JRTIP},
  author       = {Han, Tao and Hou, Shuainan and Gao, Can and Xu, Shanyong and Pang, Jiale and Gu, Hai and Huang, Yourui},
  doi          = {10.1007/s11554-025-01641-x},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-12},
  shortjournal = {J. Real-Time Image Process.},
  title        = {EF-RT-DETR: A efficient focused real-time DETR model for pavement distress detection},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FPGA-based 1D-CNN accelerator for real-time arrhythmia
classification. <em>JRTIP</em>, <em>22</em>(2), 1–12. (<a
href="https://doi.org/10.1007/s11554-025-01642-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, cardiovascular diseases are prevalent, real-time arrhythmia detection through electrocardiogram (ECG) is a vital aspect of health monitoring. Consequently, there has been growing interest in wearable edge devices capable of real-time ECG classification. Current convolutional neural networks (CNN) for arrhythmia classification often involve a large number of parameters and have high computational complexity. This work introduces a one-dimensional lightweight convolutional neural network model (LW-CNN), which leverages residual connections and one-dimensional depthwise separable convolution (DSC). The proposed network shows accuracy achieving 99.59% on software-implementation with fewer parameters and lower computational complexity. A model compression method combining unstructured pruning and incremental network quantization (INQ) is implemented to further reduce the model complexity. Additionally, a neural network accelerator based on multiplication-free convolutional processing unit is designed with high level synthesis (HLS) to reduce resource consumption and achieve real-time ECG classification. The entire system is implemented on Xilinx Zynq 7Z020 board leveraging PS-PL synergy design and achieves classification accuracy of 96.55%, a latency of 63 ms under 50-MHZ and a power consumption of 1.78W with resource consumption of 13726 LUT, 9 DSP, and 5.5 BRAM, which improves resource efficiency.},
  archive      = {J_JRTIP},
  author       = {Liu, Zheming and Ling, Xiaofeng and Zhu, Yu and Wang, Nan},
  doi          = {10.1007/s11554-025-01642-w},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-12},
  shortjournal = {J. Real-Time Image Process.},
  title        = {FPGA-based 1D-CNN accelerator for real-time arrhythmia classification},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Egc-yolo: Strip steel surface defect detection method based
on edge detail enhancement and multiscale feature fusion.
<em>JRTIP</em>, <em>22</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s11554-025-01644-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to imperfect manufacturing crafts and external factors, steel often produces surface defects during manufacturing, seriously influencing its lifespan and availability. It is therefore crucial that surface defects are detected in industrial production. Nevertheless, conventional detection techniques are vulnerable to background interference and feature scale variations when employed to identify defects on strip surfaces. Therefore, we propose an EGC-YOLO model based on YOLOv8 for steel surface defect detection. First, an edge detail enhancement module (EDEM), based on Sobel convolution (SobelConv), is designed and embedded into C2f to capture defective edges and texture better. Second, the generalized dynamic feature pyramid network (GDFPN) is introduced in the neck structure to enhance the multiscale feature fusion. This enables the model to adapt to defects of different sizes and shapes. Finally, the content-guided attention fusion (CGA Fusion) module is employed to optimize the fusion of shallow and deep features for more detection precision. The extensive experimental results illustrate that the accuracy of EGC-YOLO reaches 80.2% mAP on NEU-DET and improves by 3.7% over YOLOv8. The model’s inference speed reached 136.4 frames per second (FPS). EGC-YOLO outperforms other models in accuracy and speed for detecting steel surface defects, showcasing its industrial application potential.},
  archive      = {J_JRTIP},
  author       = {Ni, Yunfeng and Zi, Dexing and Chen, Wei and Wang, Shouhua and Xue, Xinyi},
  doi          = {10.1007/s11554-025-01644-8},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Egc-yolo: Strip steel surface defect detection method based on edge detail enhancement and multiscale feature fusion},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight real-time object detection method for complex
scenes based on YOLOv4. <em>JRTIP</em>, <em>22</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s11554-025-01645-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The object detection network can achieve real-time performance on high-performance computers with ease, but the large number of parameters and limited computational resources of mobile devices pose significant challenges, leading to suboptimal detection performance. As application scenarios expand to embedded devices, such as autonomous vehicles and unmanned aerial vehicles, higher requirements on the real-time performance and resource consumption of object detection algorithms have been proposed. The traditional YOLOv4 model has huge parameters and computations, resulting in low detection efficiency in complex environments. To address it, we propose an improved YOLOv4-lite lightweight network based on depthwise over-parameterized convolutional layer (DO-Conv). Firstly, we replace CSPDarknet53 backbone network in YOLOv4 with MobileNetV3. The parameter quantity of YOLOv4-lite is only 62.4 $$\%$$ of YOLOv4. Secondly, we use DO-Conv to replace the traditional convolution network in YOLOv4 to promote feature extraction effectiveness without extending layers. Meanwhile, we use ReLU6 to replace original Leaky ReLU to improve detection efficiency and obtain good numerical resolution. Our method achieved 70.38 $$\%$$ mean average precision (mAP) on Pascal VOC07+12 dataset and 27.63 $$\%$$ average precision (AP) on MS COCO 2017 dataset. Its model size is only 34MB. The running speed on Titan X reaches 41.82 frames per second (fps), which is 1.7 times that of YOLOv4. The experimental results demonstrate that the proposed method achieves a well-balanced trade-off between speed and accuracy, thereby meeting the real-time requirements for object detection in practical applications.},
  archive      = {J_JRTIP},
  author       = {Ding, Peng and Li, Tong and Qian, Huaming and Ma, Lin and Chen, Zhongfei},
  doi          = {10.1007/s11554-025-01645-7},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-13},
  shortjournal = {J. Real-Time Image Process.},
  title        = {A lightweight real-time object detection method for complex scenes based on YOLOv4},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective geometrical feature extraction method for scale
and rotational invariant multi-lingual character recognition.
<em>JRTIP</em>, <em>22</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s11554-025-01646-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new feature extraction technique for Optical Character Recognition (OCR) that achieves state-of-the-art results in the recognition of multilingual characters, overcoming scale, rotation, and distortion challenges. Our method leverages polar coordinates to incorporate two innovative features: Extended Ellipse-Based Features (EEB) and Crossing Count Measure (CCM), which provide inherent scale and rotational invariance. From the benchmark datasets, the proposed technique was tested on character datasets such as ISI Bengali and Chars74K, yielding accuracy rates of 98.82% and 98.69% respectively. These statistics also depict high precision and recall values coupled with a high F1-score, indicating that the method has been sound and robust. Interestingly, our approach exhibits far less computational overhead compared to traditional CNN-based methods and is, therefore, a good candidate to be deployed on resource-constrained edge devices. This work fills the gap between high-performance OCR systems and practical deployment needs by providing a scalable and efficient solution for multilingual character recognition in diverse and challenging contexts.},
  archive      = {J_JRTIP},
  author       = {Mohammed, Sharfuddin Waseem and Murugan, Brindha},
  doi          = {10.1007/s11554-025-01646-6},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Real-Time Image Process.},
  title        = {An effective geometrical feature extraction method for scale and rotational invariant multi-lingual character recognition},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating convolutional neural networks on FPGA
platforms: A high-performance design methodology using OpenCL.
<em>JRTIP</em>, <em>22</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s11554-025-01647-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) are among the most promising algorithms, outperforming traditional methods in classification tasks with superior accuracy. They have been widely applied across various deep learning domains, including computer vision, speech recognition, image processing, and object detection. However, many CNNs require substantial computational resources, particularly within their convolutional layers. As high-performance CNNs continue to evolve, their processing and memory requirements are also increasing. To address these challenges, this paper proposes an effective design methodology for accelerating CNN algorithms on Field-Programmable Gate Array (FPGA) hardware architectures. The proposed methodology introduces a novel approach for accelerating CNN algorithms using FPGAs, addressing the significant processing and memory demands associated with CNNs. The implementation is based on Open Computing Language (OpenCL), which provides rapid implementation flows. This approach was chosen for its efficiency in reducing development time and eliminating the need to manually write hardware description language (HDL) code. The MNIST and the CIFAR-10 datasets on the Xilinx ZYNQ 7000 device were used to evaluate our approach. Our method achieved a 97% recognition rate on MNIST and an 86% recognition rate on CIFAR-10. We compared the execution time of our accelerated CNN kernel on the FPGA with that of a single-core Central Processing Unit (CPU). The experimental results demonstrate that our proposed design is 10 times faster than a standard CPU, validating its effectiveness. Our model optimizes power consumption and performance, exceeding previous studies in accuracy and efficiency. It is well suited for real-world applications that demand both precision and energy efficiency.},
  archive      = {J_JRTIP},
  author       = {Gdaim, Soufien and Mtibaa, Abdellatif},
  doi          = {10.1007/s11554-025-01647-5},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Accelerating convolutional neural networks on FPGA platforms: A high-performance design methodology using OpenCL},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ship detection algorithm based on structural reparameterize
dilated large-kernel convolution and spatial selective kernel mechanism.
<em>JRTIP</em>, <em>22</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s11554-025-01649-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the issues of large target scale variations and complex background environments in ship detection, this paper presents a single-stage ship detection algorithm named DrbLSK, which is an improvement on YOLOv5. First, to enhance the model’s ability to model the context of targets with different scales, a kernel selection module is introduced into the backbone network. By dynamically selecting the receptive field, environmental interference is reduced. Simultaneously, the combination of large-kernel dilated convolution and structural reparameterization is employed to reduce model parameters and enhance the feature expression capability of the backbone network. Next, a decoupled detection head is utilized to alleviate the conflict between classification and regression tasks in the target detection task. Moreover, CIoU is used in the detection head to replace the original loss function, thereby accelerating the convergence of the network. Experimental results show that, on the ABOships dataset, the improved model reduces the number of parameters while increasing accuracy by 2.5% compared to YOLOv5, with a mean average precision of 63.9.},
  archive      = {J_JRTIP},
  author       = {Shi, Yujing and Wang, Haicheng and Li, Shanqiang},
  doi          = {10.1007/s11554-025-01649-3},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-13},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Ship detection algorithm based on structural reparameterize dilated large-kernel convolution and spatial selective kernel mechanism},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ES-YOLOv8: A real-time defect detection algorithm in
transmission line insulators. <em>JRTIP</em>, <em>22</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s11554-025-01651-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insulators are essential components for protecting transmission lines, yet they are vulnerable to defects caused by harsh environments, which can compromise their performance and transmission stability. Regular inspections are therefore crucial. However, traditional manual inspection methods are time-consuming, error-prone, and pose safety risks when working under adverse conditions. In contrast, the combination of drone inspections and image processing technology enables the safe and efficient detection of insulator defects. In this study, the YOLOv8 model was used to detect insulators. Although YOLOv8 exhibits strong detection performance, it encounters challenges in terms of detection speed and computational efficiency in real-time tasks. To address these challenges, this study introduces EfficientViT from the Transformer framework to enhance feature extraction and improve the model’s computational efficiency. Additionally, a spatial context pyramid was incorporated into the model’s header module to bolster its feature analysis capabilities, particularly for small targets and intricate background details, yielding notable results. After several enhancements, the proposed network is named ES-YOLOv8s. The experimental results reveal that compared with YOLOv8, ES-YOLOv8s improved the precision, recall, mean average precision, and harmonic mean of the precision and recall scores on the Insulator Defect Image Dataset by 2%, 3%, 2.7%, and 3%, respectively. Furthermore, the ES-YOLOv8s exhibited notable advantages in terms of giga floating point operations per second and frames per second, highlighting substantial improvements in both detection performance and computational efficiency. The study findings show that the improved model can perform better in real-time detection tasks.},
  archive      = {J_JRTIP},
  author       = {Song, Xiaoyang and Sun, Qianlai and Liu, Jiayao and Liu, Ruizhen},
  doi          = {10.1007/s11554-025-01651-9},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-13},
  shortjournal = {J. Real-Time Image Process.},
  title        = {ES-YOLOv8: A real-time defect detection algorithm in transmission line insulators},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced YOLOv5 for micro-defect detection on KDP crystal
surfaces: A fusion of EfficientNetV2 and normalized wasserstein
distance. <em>JRTIP</em>, <em>22</em>(2), 1–12. (<a
href="https://doi.org/10.1007/s11554-025-01654-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate detection of micro-defects on potassium dihydrogen phosphate (KDP) crystal surfaces is crucial for the efficient operation of high-energy laser equipment. However, traditional defect detection methods suffer from low accuracy and efficiency. To address this, we propose an enhanced YOLOv5 model specifically tailored for micro-defect detection on KDP crystals. Our approach integrates EfficientNetV2 as the backbone for feature extraction, reducing parameters by 12.68% and computational cost by 10.8%. Furthermore, we introduce the XIoU loss function and incorporate the normalized Wasserstein distance (NWD) theory, forming a novel loss function that improves the smoothness of bounding boxes and enhances the model&#39;s ability to learn and distinguish micro-defect features. We created a dataset comprising micro-defect images of KDP crystal surfaces. Experimental results on this dataset show that our method achieves a mean average precision (mAP) of 96.9% and an F1 score of 0.944, outperforming other mainstream models. This study presents a novel and effective approach for micro-defect detection on KDP crystal surfaces, contributing to advancements in ultra-precision machining technology. For further details and to access the dataset and model, please visit our repository: https://github.com/Good-he/EXN-yolo/tree/master .},
  archive      = {J_JRTIP},
  author       = {Feng, Kai and He, Shuhao and Wu, Xinlong and Jiang, Peidong and Huang, Shuai},
  doi          = {10.1007/s11554-025-01654-6},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-12},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Enhanced YOLOv5 for micro-defect detection on KDP crystal surfaces: A fusion of EfficientNetV2 and normalized wasserstein distance},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low brightness PCB image enhancement algorithm for FPGA.
<em>JRTIP</em>, <em>22</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s11554-025-01635-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem of low defect detection rate of PCB images captured by cameras in industrial scenarios under low-light environments, an MGIE (Mean–Gamma Image Enhancement) image brightness enhancement algorithm and the corresponding FPGA design scheme are proposed. Firstly, the RGB image is converted into the YCrCb color space, and the illumination component Y is separated. Then, the illumination component Y is enhanced by the MSR (Multi-Scale Retinex) algorithm based on multi-scale mean filtering, and the Gamma correction algorithm is used to adjust the brightness. Subsequently, the processed Y channel is fused with the Cr and Cb channels to obtain the final output. Secondly, after algorithm research, this paper elaborates on the algorithm design and deployment scheme based on FPGA. The MGIE IP core is designed in the HLS (High-Level Synthesis) environment, and optimization and acceleration are carried out by means of creating look-up tables and constructing PIPELINE. Significantly, this research is capable of real-time processing of images in video. Specifically, images are captured in real time by the OV5640 camera, and the processed images are immediately displayed on the LCD screen. The experimental results show that the MGIE algorithm has remarkable effectiveness in processing low-light PCB images, with a PSNR (Peak Signal-to-Noise Ratio) reaching 17.34 and an SSIM (Structural Similarity Index Measure) reaching 0.79. After the end-to-end deployment, the processing speed of 1280 × 720 and 640 × 640 pixel images reaches 30fps/s and 70fps/s, respectively, meeting the needs of real-time processing.},
  archive      = {J_JRTIP},
  author       = {Han, Jin and Zheng, Meijuan and Dong, Jianye},
  doi          = {10.1007/s11554-025-01635-9},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Low brightness PCB image enhancement algorithm for FPGA},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FPGA architecture-based front-end processing for SLAM
applications. <em>JRTIP</em>, <em>22</em>(2), 1–11. (<a
href="https://doi.org/10.1007/s11554-025-01650-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping is intended for robotic and autonomous vehicle applications. These targets require an optimal embedded implementation that respects real-time constraints, limited hardware resources, and energy consumption. SLAM algorithms are computationally intensive to run on embedded targets, and often, the algorithms are deployed on CPUs or CPU–GPGPU architectures. With the growth of embedded heterogeneous computing systems, research work is increasingly interested in the algorithm–architecture mapping of existing SLAM algorithms. The latest trend is pushing processing closer to the sensor. FPGAs constitute the perfect architecture for designing smart sensors by providing low latency suitable for real-time applications, such as video streaming, as they supply data directly into the FPGA without needing a CPU. In this work, we propose the implementation of the HOOFR-SLAM front end on a CPU–FPGA architecture, including both feature extraction and matching processing blocks. A high-level synthesis (HLS) approach based on OpenCL paradigm has been used to design a new system architecture. The performance of the FPGA-based architecture was compared to a high-performance CPU. This innovative architecture delivers superior performance compared to existing state-of-the-art systems.},
  archive      = {J_JRTIP},
  author       = {El Bouazzaoui, Imad and Rodríguez Flórez, Sergio and El Ouardi, Abdelhafid},
  doi          = {10.1007/s11554-025-01650-w},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-11},
  shortjournal = {J. Real-Time Image Process.},
  title        = {FPGA architecture-based front-end processing for SLAM applications},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UAV inspection insulator defect detection method based on
dynamic adaptation improved YOLOv8. <em>JRTIP</em>, <em>22</em>(2),
1–17. (<a href="https://doi.org/10.1007/s11554-025-01660-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insulators play an important role in ensuring the electrical stability of transmission systems, and timely detection of insulator status can effectively guarantee the safe and stable operation of power systems. However, the generalized YOLOv8 model still faces two challenges in the complex application scenario of power inspection by Unmanned Aerial Vehicles (UAVs) for high-altitude insulator defects: one is the standard convolution’s inability to efficiently extract insulator edge features, which leads to a large number of convolution operations and results in parameter redundancy; the other is the distortion of feature spatial information fusion due to complex background interference. To solve these challenges, this paper proposes a lightweight and dynamically adaptive model named DVW-YOLO (Dynamic VoV Wise YOLO, based on YOLOv8). First, a Dynamic Elliptic Convolution is designed to make the model more efficient in focusing on elliptic features, significantly reducing redundant feature extraction and multi-size fusion, and thus significantly reducing the model parameters. Then, a VoV-DE-GSCSP module is designed, and a Dynamic Adaptive Fusion Network is developed in combination with GSConv. This network restricts the cross-fusion of complex background interference information and enhances the effective feature fusion range. Finally, Wise-IoU is used to balance the performance between lightweight and average accuracy. Experimental results demonstrate that, compared with the standard YOLOv8 model, the lightweight performance of the model proposed in this paper has been greatly improved, with a reduction of 11.87% in parameter quantity and a 2.3% increase in $$\hbox {mAP}_{0.75}$$ . Meanwhile, compared with the same level lightweight model (YOLOv5), the F1-score increased by 4%, and $$\hbox {mAP}_{0.75}$$ increased by 7.4%, with a significant improvement in detection performance.},
  archive      = {J_JRTIP},
  author       = {Hu, Cong and Lv, Lingfeng and Zhou, Tian},
  doi          = {10.1007/s11554-025-01660-8},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {J. Real-Time Image Process.},
  title        = {UAV inspection insulator defect detection method based on dynamic adaptation improved YOLOv8},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification of rice disease based on MFAC-YOLOv8.
<em>JRTIP</em>, <em>22</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s11554-025-01661-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rice has an important place as food for more than half of the world’s population, but its yield and stability are severely affected by rice diseases. Current rice disease detection methods are inefficient and costly. To address this issue, this study collected 1505 data points and images from rice fields and the web and annotated them for training frameworks. After that, this study developed a new rice detection framework, MFAC-YOLOv8, based on the YOLOv8 network. The framework integrates the MobileNetv4 network and the Focal Modulation module and uses them as the backbone network of the improved YOLOv8 to improve the detection accuracy of the network. In addition, AKConv and the Context Guided block are introduced and used to further improve the neck network of YOLOv8, which simplifies the framework and further enhances the detection. The experimental results show that the MFAC-YOLOv8 framework exhibits excellent performance in all evaluation metrics, with 8.1 $$\%$$ , 2.2 $$\%$$ , and 3.4 $$\%$$ improvements in accuracy, recall, and mean average precision, respectively, compared with the baseline framework. In addition, the framework achieves a high frame rate of 166 frames per second (FPS) and a relatively compact parameter size of 18.4 million. These results suggest that the proposed method has great potential for effective rice disease detection.},
  archive      = {J_JRTIP},
  author       = {Wang, Bingyang and Zhou, Huibo and Xie, Hui and Chen, Ruolan},
  doi          = {10.1007/s11554-025-01661-7},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Identification of rice disease based on MFAC-YOLOv8},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vaccine-YOLOv10: Real-time QR code detection model for
complex light condition. <em>JRTIP</em>, <em>22</em>(2), 1–12. (<a
href="https://doi.org/10.1007/s11554-025-01631-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {QR code is not only an information storage approach, but also a spatial localization sign. Compared to other spatial localization signs, QR code is more accurate and more efficient to be detected. To achieve spatial localization by QR code, detection is the essential procedure. Existing approaches perform well in regular light condition, but perform badly in complex light condition, because frame quality is extremely damaged by complex light condition. In the real world, complex light condition is very common but always unavoidable. Therefore, it is necessary and worthwhile to improve the under-complex-light QR code detection. In this paper, Vaccine-YOLOv10 (VCY) is proposed to enhance QR code detection capability in complex light condition. First, GhostConv and FasterC2f are introduced to replace the corresponding original modules of YOLOv10n. Second, Simulative Data Augment Algorithm (SDA) is proposed to simulate 5 types of complex light condition. Third, self-built Multi-Scene QR Code Dataset (MSQ) is augmented by SDA for VCY training. Compared to the baseline model YOLOv10n, VCY is improved on both lightweight and accuracy. Specifically, FPS reaches 150; GFLOPs reduces from 8.2 to 5.3; mAP50 increases from 0.877 to 0.905. Code: https://github.com/AlexTraveling/Vaccine-YOLOv10 .},
  archive      = {J_JRTIP},
  author       = {Zhao, Xiaobei and Li, Xiang},
  doi          = {10.1007/s11554-025-01631-z},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-12},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Vaccine-YOLOv10: Real-time QR code detection model for complex light condition},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FPGA implementation of double-head SalsaNext: A CNN-based
model for LiDAR point cloud segmentation. <em>JRTIP</em>,
<em>22</em>(2), 1–11. (<a
href="https://doi.org/10.1007/s11554-025-01643-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study details the adaptation and deployment of a customized SalsaNext model for semantic segmentation of LiDAR point clouds on edge devices, benchmarked using the SemanticKITTI and Waymo Open datasets. We introduce an innovative multi-dataset training framework designed specifically for range image-based segmentation models. Central to this approach is our double-head SalsaNext model, which features two output heads to facilitate simultaneous training and inference on the Waymo and SemanticKITTI datasets. Following training, the model is streamlined by removing the head dedicated to Waymo, resulting in a compact, single-headed version optimized for SemanticKITTI. This simplified model is then quantized to employ fixed-point arithmetic, significantly enhancing computational efficiency and enabling real-time operation on the Xilinx Kria KV260 board. The quantization process markedly reduces resource consumption while preserving competitive accuracy. Our deployment on this low-power, FPGA-based platform underscores the potential of energy-efficient systems for advanced 3D semantic segmentation, with promising applications in autonomous systems and robotics. Experimental results validate the effectiveness of our training schema and the success of the optimized implementation of the double-head model on resource-constrained hardware.},
  archive      = {J_JRTIP},
  author       = {Adiyaman, Muhammed Yasin and Baskaya, Faik},
  doi          = {10.1007/s11554-025-01643-9},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-11},
  shortjournal = {J. Real-Time Image Process.},
  title        = {FPGA implementation of double-head SalsaNext: A CNN-based model for LiDAR point cloud segmentation},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-VG: An efficient real-time recyclable waste detection
network. <em>JRTIP</em>, <em>22</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s11554-025-01655-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the task of sorting waste using robots, it is necessary to determine the location and category information of waste. The key to the efficient work of the waste sorting robot lies in the accuracy of the target recognition. Traditional waste detection algorithms suffer from high computational cost, low detection accuracy, and poor adaptability, which cannot meet the actual detection needs. Therefore, this paper proposes an efficient and lightweight algorithm YOLO-VG based on the current mainstream algorithm YOLOv8s for waste detection and classification. The algorithm replaces the conventional convolution in the backbone network with GSConv to reduce redundant information and improve the model’s inference process. ODConv replaces the regular convolution in the neck network to enhance the model’s adaptability and generalization ability, thereby reducing the risk of overfitting. Additionally, the VoV-Ghost structure is introduced in the neck network to replace the original C2f, making the model more lightweight and efficient, meeting the requirements of real-time object detection in embedded devices or resource-constrained environments. Finally, the ECA attention mechanism is introduced to improve the ability of information interaction between feature channels in the model, thereby better capturing important information between images or features. Experimental results on the recyclable waste dataset demonstrate that the proposed YOLO-VG achieves a 24.6% improvement in computational efficiency, a 20.4% reduction in model size, and an mAP0.5 of 88.4%, surpassing the performance of the original YOLOv8s. These results indicate that YOLO-VG not only demonstrates excellent detection performance and stability, but also exhibits significant potential for widespread application in the field of waste sorting.},
  archive      = {J_JRTIP},
  author       = {Song, Limei and Yu, Haibo and Yang, Yangang and Tong, Yu and Ren, Siyuan and Ye, Chenchao},
  doi          = {10.1007/s11554-025-01655-5},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Real-Time Image Process.},
  title        = {YOLO-VG: An efficient real-time recyclable waste detection network},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Study on end-to-end detection method for surface defects of
automotive sheet metal parts. <em>JRTIP</em>, <em>22</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s11554-025-01656-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sheet metal parts account for more than 60% of the total automotive parts, and their defects can seriously affect the safety of automobile operations. Therefore, it is very important to detect defects in sheet metal parts during the production process. Due to the small size of defects in sheet metal parts, and high detection precision required, the traditional detection method cannot meet the requirements. And the factory production speed is fast, if the detection speed is low, it will cause defects to escape. Therefore, we propose an end-to-end detection method for automotive sheet metal parts surface defects. To effectively improve the detection speed, the dual regression classification strategy is proposed, which removes the NMS post-processing. Gradient information branch is added to provide rich gradient information for the model and mitigate the information loss during long convolution. Use the SPD-Conv module, optimized for small-size defects detection, to retain complete space information. Finally, the model is evaluated on the automotive sheet metal parts defect dataset. The experimental results show that the proposed method is superior to the benchmark methods in precision and speed, with mAP of 92.32% and FPS of 39.06, which achieves end-to-end detection.},
  archive      = {J_JRTIP},
  author       = {Dai, Wei and lv, Juncheng and Xiang, Rui and Jin, Sun},
  doi          = {10.1007/s11554-025-01656-4},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Study on end-to-end detection method for surface defects of automotive sheet metal parts},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LR-DETR: A lightweight real-time traffic sign detection
model based on improved RT-DETR. <em>JRTIP</em>, <em>22</em>(2), 1–16.
(<a href="https://doi.org/10.1007/s11554-025-01659-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time detection of traffic signs is crucial for safe autonomous driving and intelligent transportation systems. The current key challenge in the field of traffic sign detection is to achieve model lightweighting and improve real-time performance while maintaining effectiveness. To address these challenges, this paper proposes a lightweight real-time traffic sign detection model called LR-DETR. LR-DETR is based on the end-to-end object detection model of RT-DETR. By redesigning the core modules in RT-DETR, LR-DETR significantly improves the lightweighting level of the model while maintaining high detection accuracy. A PCIR-Block module based on Partial Convolution and Inverted Residual Structure is proposed to more fully extract multi-scale features in the backbone network. A Context-Guided Feature Fusion Module (CGFFM) is proposed to utilize contextual information between features of different scales to enhance the effectiveness of feature representation and subsequently improve the fusion performance of multi-scale features. In addition, with the help of dilated convolution and reparameterization techniques, LR-DETR designed a DRBC3 module for feature re-extraction to further enhance the model’s ability to capture features at different scales, while effectively reducing the number of parameters and floating-point operations. The experimental results on the CCTSDB 2021 dataset show that compared with the state-of-the-art baseline models, LR-DETR performs better in increasing the value of mAP@0.5 by 0.5%, decreasing the value of FLOPs by 28.1%, decreasing the value of Params by 23.7%, and decreasing the value of Latency by 11.6%. The experimental results on the TT100K traffic sign dataset show that the precision and recall of the LR-DETR model are 87.1% and 81.6%, respectively, outperforming other baseline models. LR-DETR significantly reduces the number of parameters and floating-point operations while maintaining high detection performance, improving the detection speed of the model. This will provide a constructive contribution to achieving real-time detection of traffic signs.},
  archive      = {J_JRTIP},
  author       = {Zhang, Longzhen and Wang, Mingyang and Zhao, Xianhao and Wang, Xianjie},
  doi          = {10.1007/s11554-025-01659-1},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Real-Time Image Process.},
  title        = {LR-DETR: A lightweight real-time traffic sign detection model based on improved RT-DETR},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time traffic light detection based on lightweight
improved RT-DETR. <em>JRTIP</em>, <em>22</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s11554-025-01652-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing traffic light detection algorithms suffer from high computational overhead and low detection speeds, making it difficult to meet the real-time demands. Therefore, reducing computational overhead and increasing detection speed, while maintaining accuracy, becomes a critical challenge. To tackle these, this paper proposes GAD-DETR, an enhanced RT-DETR-based network. First, inspired by the approach of GhostNet to minimize computational redundancy and integrate reparameterized convolution (RepConv), the GRELAN module is developed to restructure the backbone network which significantly decreases model size and parameters while enhancing detection speed. To improve the recognition of small objects, whose features tend to be diluted as the network deepens, ADown is introduced to replace standard convolution for downsampling. Finally, a lightweight feature fusion module, DGSFM, is designed to further reduce computational costs and enhance efficiency. Experimental results indicate that GAD-DETR achieves a detection precision of 95.9% while significantly optimizing efficiency. The model size is reduced by 50.3%, with parameters and computations decreased by 50.8% and 51.2%, respectively. FPS increases from 76.7 to 117.8, demonstrating that the proposed algorithm achieves lightweight, real-time traffic light detection.},
  archive      = {J_JRTIP},
  author       = {Tang, Chaoli and Li, Yun and Wang, Lei and Li, Wenyan},
  doi          = {10.1007/s11554-025-01652-8},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-15},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Real-time traffic light detection based on lightweight improved RT-DETR},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FDDC-YOLO: An efficient detection algorithm for dense
small-target solder joint defects in PCB inspection. <em>JRTIP</em>,
<em>22</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s11554-025-01664-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays printed circuit board plays a vital role in communication, computer, electronics and other industries. Existing PCB welding defect detection algorithms have the problems of low accuracy and poor real-time performance in identifying small or irregular targets and dense solder joints. This is due to the limited receptive field of standard convolutional kernels, which hinder global feature extraction and focus on local details. Moreover, the effects of kernel count and feature extraction dimensions are often overlooked, leading to the loss of important features. Conventional upsampling methods, such as nearest-neighbor interpolation, can further degrade critical information. To address these challenges, we propose FDDC-YOLO, a novel defect detection network. First, we introduce a new full-dimensional dynamic convolution module FDDC, which integrates full-dimensional dynamic convolution with the newly designed od_ottleneck structure to enhance the feature extraction ability by using the four dimensions of the convolution kernel. Secondly, the CECA attention module in the neck improves the ability of the model to detect small defects by enhancing the local interaction between channels. Third, the Dy-Up module is used to improve image resolution and prevent the loss of detailed information during the detection process. Finally, we replace the CIoU loss with IShapeIoU to reduce the overlap of detection boxes in densely packed solder joints, improving both localization accuracy and convergence speed.The mAP of FDDC-YOLO is improved by 5.4% on the PCBSP_dataset, and a Frame Per Second (FPS) of 189. It improves by 3.8% on the public PCB Defect-Augmented dataset, which proves its good generalization ability.},
  archive      = {J_JRTIP},
  author       = {Zheng, Haoyu and Peng, Jinmin and Yu, Xinyi and Wu, Meishun and Huang, Qiufang and Chen, Liangshen},
  doi          = {10.1007/s11554-025-01664-4},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-16},
  shortjournal = {J. Real-Time Image Process.},
  title        = {FDDC-YOLO: An efficient detection algorithm for dense small-target solder joint defects in PCB inspection},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved YOLOv8 model for prohibited item detection with
deformable convolution and dynamic head. <em>JRTIP</em>, <em>22</em>(2),
1–17. (<a href="https://doi.org/10.1007/s11554-025-01665-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X-ray security inspection is critical for maintaining public safety and transportation security. However, traditional manual inspection methods are often ineffective due to the challenges posed by complex backgrounds and severe occlusions in X-ray images, resulting in false positives and negatives. This study proposes an enhanced object detection framework based on the YOLOv8 model to address these challenges. Key improvements include the integration of the ADown downsampling module to reduce computational complexity while enhancing detection accuracy and the incorporation of Deformable Convolutional Networks v2 (DCNv2) to improve deformable feature extraction. To strengthen feature representation, the Spatial Pyramid Pooling-Fast with ReLU and Efficient Local Attention (SPPF_RE) module is introduced to effectively integrate global and local features. Additionally, the Dynamic Head (DyHead) module is employed to enhance detection in complex backgrounds, while the Pixels-IOU (PIoU) loss function improves the detection accuracy of rotated objects. Experimental results on the OPIXray and HIXray datasets demonstrate that the proposed framework significantly outperforms the baseline model, achieving notable improvements in detection accuracy. The code can be accessed via the following link: https://github.com/Guanfj2024/x-ray-detection.git},
  archive      = {J_JRTIP},
  author       = {Guan, Fangjing and Zhang, Heng and Wang, Xiaoming},
  doi          = {10.1007/s11554-025-01665-3},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {J. Real-Time Image Process.},
  title        = {An improved YOLOv8 model for prohibited item detection with deformable convolution and dynamic head},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-branch evidential framework fusing hard example mining
for abdominal organ segmentation. <em>JRTIP</em>, <em>22</em>(2), 1–14.
(<a href="https://doi.org/10.1007/s11554-025-01648-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {U-Net variants commonly encounter limitations due to overconfidence in predictions, impeding their clinical applicability. Quantifying model uncertainty accurately is vital, but obtaining sufficient and reliable evidence remains challenging. This paper introduces the $$\textbf{D}$$ ual-Branch $$\textbf{Evi}$$ dential Framework Fusing $$\textbf{H}$$ ard $$\textbf{E}$$ xample $$\textbf{M}$$ ining for Abdominal Organ Segmentation (DEvi-HEM). It is a novel dual-branch framework integrating hard example mining (HEM) at region and pixel levels. By applying higher penalty weights to hard examples, HEM improves fine-grained prediction. The dual-branch structure enhances the model’s expressiveness by learning from both region-level and pixel-level representations. Furthermore, the introduction of dual-branch consistency learning and adversarial learning-based variational distributions captures the cognitive variability across branches. This ensures precise segmentation and reliable uncertainty estimation. DEvi-HEM improves segmentation performance, cuts computational cost, and outperforms uncertainty-based methods, with 3.292 GFLOPs on FLARE22 and 2.486 GFLOPs on Synapse.},
  archive      = {J_JRTIP},
  author       = {Yu, Xiangchun and Wu, Tianqi and Zhang, Dingwen and Liang, Miaomiao and Yu, Lingjuan and Zheng, Jian},
  doi          = {10.1007/s11554-025-01648-4},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Dual-branch evidential framework fusing hard example mining for abdominal organ segmentation},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-PDC: Algorithm for aluminum surface defect detection
based on multiscale enhanced model of YOLOv7. <em>JRTIP</em>,
<em>22</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s11554-025-01658-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address challenges multi-scale variability, category imbalance, and high background similarity in aluminum surface defect detection, this paper proposes a YOLO-PDC model. First, Partial Convolution (PConv) and Deformable ConvNetsv2 (DCNv2) replace traditional convolution in the ELAN and MaxPool modules of the YOLOv7 backbone. This configuration forms the PD-ME module, which mitigates the issue of non-uniform scale variations among different defect types in aluminum dataset. It also reduces computational redundancy and memory access, enabling efficient extraction of spatial features and improving inference speed. Next, a 3D attention module (SimAM) is incorporated into YOLOv7 detection head after two up-sample steps and within two MaxPool structures, creating the Sim-CM Attention Mechanism. This addition enhances detection accuracy without introducing additional parameters. Additionally, during training, the Focal loss function replaces CIoU loss function. Focal loss dynamically decreases the weight of easily distinguishable samples through a scaling factor, allowing the model to focus on hard-to-distinguish samples and addressing low detection accuracy caused by sample imbalance. Experimental results demonstrate that the proposed YOLO-PDC model achieves a high mean Average Precision (mAP) of 87.7% and a real-time detection speed of 114 frames per second. Compared to the original YOLOv7, mAP50 and mAP50:90 improve by 5.2% and 12.2%, respectively, while the number of parameters and computations decrease by 2.18 million and 22.2 billion, respectively. Furthermore, compared to the latest defect detection models DETR, Swin-T, and ConvNeXt-T, the mAP50 of YOLO-PDC is higher by 15.2%, 17.9%, 16.2%, respectively. YOLO-PDC also surpasses existing state-of-the-art detection methods in terms of detection accuracy.},
  archive      = {J_JRTIP},
  author       = {Li, Na and Wang, Zhiwen and Zhao, Runxing and Yang, Kaiqi and Ouyang, Rongyi},
  doi          = {10.1007/s11554-025-01658-2},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-18},
  shortjournal = {J. Real-Time Image Process.},
  title        = {YOLO-PDC: Algorithm for aluminum surface defect detection based on multiscale enhanced model of YOLOv7},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-cost real-time traffic situational awareness system
based on modified YOLO v8 and GWO-LSTM for edge deployment.
<em>JRTIP</em>, <em>22</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s11554-025-01657-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a traditional traffic situational awareness system (TSAS), its “Road-side unit (RSU) + cloud-based analysis” structure is difficult to meet the demands of rapidly expanding urban areas. Relatively high costs of microwave speed detection modules and bandwidth requirements of information systems significantly increase construction costs. By computer vision (CV) and edge computing technologies, traffic situational awareness tasks can be integrated into cheaper edge devices (roadside surveillance, RSS), effectively addressing such challenges. In this study, we present a low-cost TSAS developed based on YOLO v8 and grey wolf optimizer-long short-term memory (GWO-LSTM) neural network. Proposed system can automatically perform vehicle and license plate recognition, speed measurement, and data recording within the field of view of RSSs. Additionally, it accurately predicts the future traffic conditions of monitored roads using recorded information. Experimental results demonstrate that the proposed TSAS achieves a license plate recognition accuracy of 97.7%, vehicle type recognition accuracy of 98.1%, and speed measurement error of less than 0.45 km/h, with R2 of 0.8971 for GWO-LSTM predictions. This system is sufficiently effective for traffic monitoring and situational awareness tasks but enforcement forensic applications.},
  archive      = {J_JRTIP},
  author       = {Liu, Jianwen and Gong, Ruyue and Gong, Yi and Li, Zeqin and Chen, Zhiwei},
  doi          = {10.1007/s11554-025-01657-3},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Low-cost real-time traffic situational awareness system based on modified YOLO v8 and GWO-LSTM for edge deployment},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stme-net: Spatio-temporal motion excitation network for
action recognition. <em>JRTIP</em>, <em>22</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s11554-025-01662-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action recognition, as one of the fundamental tasks in video understanding, relies crucially on accurate temporal modeling. However, accurately modeling the temporal information of videos remains a challenging task. To address this problem, we design two new modules: the Spatial Motion Extraction (SME) module and the Spatio-temporal Motion Excitation (STME) module. The SME module features two branches for extracting motion and spatial features. The motion branch refines pixel differences between neighboring frames through a channel attention module, enhancing detailed motion features. These features are fused with spatial information to yield fine-grained local spatio-temporal features. The STME module, comprising the multi-motion excitation (MME), temporal excitation (TE), and spatio-temporal excitation (STE) sub-modules, efficiently captures long-range motion, temporal, and global spatio-temporal features. The MME introduces a bi-directional, multi-scale structure for effective long-range motion extraction, while the TE module employs a hierarchical pyramid with residual connectivity for fine-grained long-range temporal extraction. The STE module utilizes 3D convolutional layers for global spatio-temporal feature extraction. The seamless integration of these sub-modules within a standard ResNet network forms the Spatio-temporal Motion Excitation Network. Extensive evaluations on Something V1 and V2 and HMDB51 datasets against state-of-the-art methods demonstrate the effectiveness of our approach in achieving accurate recognition of both simple and complex video actions.},
  archive      = {J_JRTIP},
  author       = {Zhao, Qian and Su, Yanxiong and Zhang, Hui},
  doi          = {10.1007/s11554-025-01662-6},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-13},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Stme-net: Spatio-temporal motion excitation network for action recognition},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dilated-convolutional feature modulation network for
efficient image super-resolution. <em>JRTIP</em>, <em>22</em>(2), 1–14.
(<a href="https://doi.org/10.1007/s11554-025-01663-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of image super-resolution (SR), deep learning-based models have achieved remarkable success. However, these models often face compatibility issues with low-power devices due to their computational and memory constraints. To address this challenge, numerous lightweight and efficient models have been proposed. While these models typically employ smaller convolutional kernels and shallower architectures to reduce parameter counts and computational complexity, they often neglect the importance of capturing global receptive fields. In this paper, we propose a simple yet effective deep network, termed the dilated-convolutional feature modulation network (DCFMN), to tackle these limitations. Specifically, we introduce a dilated separable modulation unit (DSMU) to aggregate spatial information from diverse large receptive fields. To complement the DSMU, which processes features from a long-range perspective, we further design a local feature enhancement module (LFEM) to extract local contextual information for effective channel fusion. Additionally, by leveraging reparameterization techniques, we ensure that the model incurs no additional computational overhead during inference. Extensive experimental results demonstrate that our DCFMN achieves competitive performance among existing efficient SR methods, while maintaining a compact model size and low computational complexity.},
  archive      = {J_JRTIP},
  author       = {Wu, Lijun and Li, Shan and Chen, Zhicong},
  doi          = {10.1007/s11554-025-01663-5},
  journal      = {Journal of Real-Time Image Processing},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {J. Real-Time Image Process.},
  title        = {Dilated-convolutional feature modulation network for efficient image super-resolution},
  volume       = {22},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="kis---32">KIS - 32</h2>
<ul>
<li><details>
<summary>
(2025). Correction: A new hybrid reasoning model based on rules,
cases and processes: Application to care of individuals facing autism
spectrum disorders. <em>KIS</em>, <em>67</em>(3), 3047–3048. (<a
href="https://doi.org/10.1007/s10115-024-02278-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_KIS},
  author       = {Kaoura, Georgia and Kovas, Konstantinos and Boutsinas, Basilis and Hatzilygeroudis, Ioannis},
  doi          = {10.1007/s10115-024-02278-1},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {3047-3048},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Correction: a new hybrid reasoning model based on rules, cases and processes: application to care of individuals facing autism spectrum disorders},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EDMIX: An entropy-based dissimilarity measure to cluster
mixed data comprising of numerical–nominal–ordinal attributes.
<em>KIS</em>, <em>67</em>(3), 3023–3045. (<a
href="https://doi.org/10.1007/s10115-024-02319-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing (dis)similarity measures for mixed data often ignore data distribution and ordering information along numerical and categorical features, respectively, during distance computation. Additionally, combining numerical and categorical (dis)similarities is often done naively, failing to judiciously assign relative weights. This work introduces a unified dissimilarity measure for mixed data (EDMIX) that addresses these challenges. It employs an entropy-based measure (SEND) for numerical attributes which utilizes intra-attribute inhomogeneity efficiently. A Boltzmann’s entropy-based measure (EDMD) is adopted for categorical features, which effectively handles both nominal and ordinal attributes. Decay of attribute weight is analyzed to determine the threshold weights for numerical and categorical parts. Number of attributes whose weights are above the threshold value in each part decides the mixing proportion of the respective parts. Notably, EDMIX requires no input parameters and is adaptable to diversified mixed data. Experimental results highlight its superiority in terms of cluster quality, accuracy, discrimination ability, and execution time across diverse mixed datasets for clustering applications.},
  archive      = {J_KIS},
  author       = {Kar, Amit Kumar and Mishra, Amaresh Chandra and Mohanty, Sraban Kumar},
  doi          = {10.1007/s10115-024-02319-9},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {3023-3045},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {EDMIX: An entropy-based dissimilarity measure to cluster mixed data comprising of numerical–nominal–ordinal attributes},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large language models: A survey of their development,
capabilities, and applications. <em>KIS</em>, <em>67</em>(3), 2967–3022.
(<a href="https://doi.org/10.1007/s10115-024-02310-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models can generate text, respond to queries, and translate between languages, as recent research demonstrates. As a new and essential part of computational linguistics, LLMs can understand complex speech patterns and respond appropriately and rationally in the given context. Research contributions have significantly increased as a result of LLMs growing popularity. Nevertheless, the rate of increase has been so quick that evaluating the cumulative impact of these developments is challenging. Keeping abreast with all the LLM research that has surfaced in such a short time and gaining a thorough understanding of the present state of the field’s study has become challenging. The scientific community would gain from a succinct but thorough LLM summary covering their history, architecture, applications, issues, influence, and resources. This paper covers many model types while reviewing LLMs’ fundamental principles and notions. It summarizes earlier research, the evolution of LLMs throughout time, transformer history, and the range of tools and training methods applied to these models. The study also looks at the many fields in which LLMs are used, including business, social work, education, healthcare, and agriculture. Furthermore, it illustrates how LLMs impact society, mold AI’s future, and find valuable uses in problem-solving. This review article aims to provide a comprehensive overview of the history of LLMs, pre-trained architectures, applications, problems, and future directions for practitioners, researchers, and experts.},
  archive      = {J_KIS},
  author       = {Annepaka, Yadagiri and Pakray, Partha},
  doi          = {10.1007/s10115-024-02310-4},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2967-3022},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Large language models: A survey of their development, capabilities, and applications},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated cross-domain recommendation system based on bias
eliminator and personalized extractor. <em>KIS</em>, <em>67</em>(3),
2935–2965. (<a
href="https://doi.org/10.1007/s10115-024-02316-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of big data is driven by advancements in Internet of Things technology. The cross-domain recommendation system is a highly successful approach for obtaining user-interested items from massive data. However, implementing a cross-domain recommendation system on distributed IoT devices faces three challenges. On the one hand, item embeddings used in existing cross-domain recommendation models often lead to an unavoidable popularity bias. On the other hand, to convey user preference information, most existing methods utilize common interest channels. However, it stands to reason that the interest channels for different users should be distinct, as each person has their own unique preferences. Furthermore, collecting raw data from distributed IoT devices may lead to user privacy concerns. Given these challenges, we propose a federated cross-domain recommendation system based on bias eliminator and personalized extractor (FedBP) in this paper to achieve precise recommendations in cold-start scenarios. Firstly, we employ a bias eliminator to unfold all embedding directions during training, ensuring that each direction captures only specific features while maintaining neutrality in popularity. Secondly, personalized extractor is utilized to individualize the distinct preference information of each user from the source domain to the target domain. Then, we utilize a federated framework to collaboratively train the cross-domain recommendation system model, where local differential privacy is employed to ensure data privacy. Experimental results on public benchmarks show that FedBP consistently outperforms baseline models across three cold-start cross-domain recommendation scenarios, with improvements of at least 3.02%, 5.08%, and 3.08%.},
  archive      = {J_KIS},
  author       = {Di, Yicheng and Shi, Hongjian and Wang, Qi and Jia, Shunyuan and Bao, Jiayu and Liu, Yuan},
  doi          = {10.1007/s10115-024-02316-y},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2935-2965},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Federated cross-domain recommendation system based on bias eliminator and personalized extractor},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-aware user multi-interest modeling method for news
recommendation. <em>KIS</em>, <em>67</em>(3), 2911–2933. (<a
href="https://doi.org/10.1007/s10115-024-02290-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {News recommendation can filter massive news and provide personalized information services, and the key is to better portray news and users. Current news recommendation methods try to integrate the knowledge graph to introduce background knowledge for news features modeling and have achieved good performance. However, when modeling users’ interest features, these methods only consider the personalized information of the interacted news and ignore the fact that some typical entities can help depict multiple topics that users are interested in. In this paper, we propose a method called KMRec (knowledge-aware user multi-interest modeling method for news recommendation) to realize the fine-grained portrayal of users’ multi-interest based on knowledge graph. Specifically, we represent user multi-interest features through four modules: historical text encoder, individual entity encoder, common entity encoder and user encoder. The historical text encoder is for the text modeling of each news and information aggregation. The individual entity encoder achieves the entity feature modeling of each news and information aggregation based on knowledge graph. The common entity encoder realizes the common entity information extraction of users’ historical interacted news based on knowledge graph. The user encoder integrates the text feature, individual entity feature and common entity feature to comprehensively depict the multi-interest of each user. Offline experimental results on both MIND-small and MIND-large datasets show that leveraging KMRec for users’ interest modeling can effectively improve the performance of news recommendation. The idea of introducing the user multi-interest feature is also verified to be effective by comparative experiments with existing news feature representations.},
  archive      = {J_KIS},
  author       = {Zuo, Zong and Lu, Jicang and Tan, Lei and Gong, Daofu and Chen, Jing and Liu, Fenlin},
  doi          = {10.1007/s10115-024-02290-5},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2911-2933},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Knowledge-aware user multi-interest modeling method for news recommendation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential uncertainty quantification with contextual
tensors for social targeting. <em>KIS</em>, <em>67</em>(3), 2881–2910.
(<a href="https://doi.org/10.1007/s10115-024-02304-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common question that an online marketer asks is, given a social network, how one decides which users to target with their limited advertisement resources (such as coupon offers). The key technical task toward answering this question is the estimation of the user–user activation probability that quantifies the influence one user may have on another toward their purchasing decisions. In this paper, we propose a novel targeting strategy with sequential uncertainty quantification via probabilistic tensor regression. The proposed framework is designed to capture the heterogeneity in user preferences, product types, campaign strategies, etc. in the form of contextual tensor. For uncertainty quantification, we derive a closed-form online predictive distribution for the user response score, which is used in a bandit-style sequential decision-making on who to receive marketing offers. We empirically confirm that the proposed algorithm achieves significant improvement in influence maximization tasks over benchmarks, which is attributable to its capability of capturing the user–product heterogeneity.},
  archive      = {J_KIS},
  author       = {Idé, Tsuyoshi and Murugesan, Keerthiram and Bouneffouf, Djallel and Abe, Naoki},
  doi          = {10.1007/s10115-024-02304-2},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2881-2910},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Sequential uncertainty quantification with contextual tensors for social targeting},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient parallel algorithm for finding strongly connected
components based on granulation strategy. <em>KIS</em>, <em>67</em>(3),
2855–2879. (<a
href="https://doi.org/10.1007/s10115-024-02299-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strongly connected components (SCCs) are a significant subgraph structure in digraphs. In the previous work, an algorithm based on rough set theory (RST) called KGRSCC was proposed, which can compute SCCs with high efficiency. Notably, KGRSCC utilized a granulation strategy, which was designed based on SCC correlations between vertices. These SCC correlations are confined to the situations that R-related set or upper approximation set only contains one vertex. However, the situations of ’only one’ cannot fully deduce SCCs correlations, which may limit the computation efficiency of SCCs. In this paper, firstly, the graph concept of SCCs is further analyzed in the framework of RST, and then, four ’not only one’ SCC correlations between vertices can be concluded. Secondly, the four SCC correlations can be divided two classes: trivial and nontrivial. Then, two new granulation strategies are proposed based on the two classes of SCC correlations. They can granulate the vertex set to construct two types of vertex granules. Thirdly, with combination of two types of vertex granules, a parallel algorithm named P@KGS is proposed based on KGRSCC. Finally, experimental results show that the P@KGS algorithm performs higher computational efficiency than compared algorithms.},
  archive      = {J_KIS},
  author       = {Xu, Taihua and He, Huixing and Yang, Xibei and Yang, Jie and Song, Jingjing and Cui, Yun},
  doi          = {10.1007/s10115-024-02299-w},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2855-2879},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Efficient parallel algorithm for finding strongly connected components based on granulation strategy},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Factors influencing open science participation through
research data sharing and reuse among researchers: A systematic
literature review. <em>KIS</em>, <em>67</em>(3), 2801–2853. (<a
href="https://doi.org/10.1007/s10115-024-02284-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This systematic literature review investigates the influential factors guiding researchers’ active engagement in open science through research data sharing and subsequent reuse, spanning various scientific disciplines. The review addresses key objectives and questions, including identifying distinct sample types, data collection methods, critical factors, and existing gaps within the body of literature concerning data sharing and reuse in open science. The methodology employed in the review was detailed, outlining a series of systematic steps. These steps encompass the systematic search and selection of relevant studies, rigorous data extraction and analysis, comprehensive evaluation of selected studies, and transparent reporting of the resulting findings. The review’s evaluation process was governed by well-defined inclusion and exclusion criteria, encompassing publication dates, language, study design, and research outcomes. Furthermore, it adheres to the PRISMA 2020 flow diagram, effectively illustrating the progression of records through the review stages, highlighting the number of records identified, screened, included, and excluded. The findings include a concise tabular representation summarizing data extracted from the 51 carefully selected studies incorporated within the review. The table provides essential details, including study citations, sample sizes, data collection methodologies, and key factors influencing open science data sharing and reuse. Additionally, common themes and categories among these influential factors are identified, shedding light on overarching trends in the field. In conclusion, this systematic literature review offers valuable insights into the multifaceted landscape of open science participation, emphasizing the critical role of research data sharing and reuse. It is a comprehensive resource for researchers and practitioners interested in further understanding the dynamics and factors shaping the open science ecosystem.},
  archive      = {J_KIS},
  author       = {Ahmed, Mahfooz and Othman, Roslina and Noordin, Mohamad Fauzan and Ibrahim, Adamu Abubakar and Al-Hussaini, Abulfathi Ibrahim Saleh},
  doi          = {10.1007/s10115-024-02284-3},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2801-2853},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Factors influencing open science participation through research data sharing and reuse among researchers: A systematic literature review},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sarcasm detection using optimized bi-directional long
short-term memory. <em>KIS</em>, <em>67</em>(3), 2771–2799. (<a
href="https://doi.org/10.1007/s10115-024-02210-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current era, the number of social network users continues to increase day by day due to the vast usage of interactive social networking sites like Twitter, Facebook, Instagram, etc. On these sites, users generate posts, whereas the attitude of followers towards factor utilization like situation, sound, feeling, and so on can be analysed. But most people feel difficult to analyse feelings accurately, which is one of the most difficult problems in natural language processing. Some people expose their opinions with different sole meanings, and this sophisticated form of expressing sentiments through irony or mockery is termed sarcasm. The sarcastic comments, tweets or feedback can mislead data mining activities and may result in inaccurate predictions. Several existing models are used for sarcasm detection, but they have resulted in inaccuracy issues, huge time consumption, less training ability, high overfitting issues, etc. To overcome these limitations, an effective model is introduced in this research to detect sarcasm. Initially, the data are collected from publicly available sarcasmania and Generic sarcasm-Not sarcasm (Gen-Sarc-Notsarc) datasets. The collected data are pre-processed using stemming and stop word removal procedures. The features are extracted using the inverse filtering (IF) model through hash index creation, keyword matching and ranking. The optimal features are selected using adaptive search and rescue (ASAR) optimization algorithm. To enhance the accuracy of sarcasm detection, an optimized Bi-LSTM-based deep learning model is proposed by integrating Bi-directional long short-term memory (Bi-LSTM) with group teaching optimization (GTO). Also, the LSTM + GTO model is proposed to compare its performance with the Bi-LSTM + GTO model. The proposed models are compared with existing classifier approaches to prove the model’s superiority using PYTHON. The accuracy of 98.24% and 98.36% are attained for sarcasmania and Gen-Sarc-Notsarc datasets.},
  archive      = {J_KIS},
  author       = {Sukhavasi, Vidyullatha and Sistla, Venkatrama Phani kumar and Dondeti, Venkatesulu},
  doi          = {10.1007/s10115-024-02210-7},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2771-2799},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Sarcasm detection using optimized bi-directional long short-term memory},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new way of search query like knowledge graph and its
interpretability. <em>KIS</em>, <em>67</em>(3), 2745–2770. (<a
href="https://doi.org/10.1007/s10115-024-02242-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online search, it has always been a challenge to provide a way of search query that can help users accurately express search intentions and encourage them to type easily. This paper studies a knowledge graph-like search query and its interpretability. Inspired by the excellent expressive capabilities of the knowledge graph in knowledge reasoning and explainable artificial intelligence, we propose a new way of search query named search query knowledge graph, which can help users express their search requests using concepts such as entities, relationships, and facts. Therefore, people can draw a graph simply and interactively as a search query in a drag-and-drop manner. Compared with traditional search query keyword, the search query knowledge graph is not only fully compatible with it but also enriches and expands it. The search query keyword is a special case of the search query knowledge graph. We take the search query knowledge graph as the search input, obtain the corresponding search results in an online search, and then generate another knowledge graph named search result knowledge graph. According to the structural mapping relationship and the semantic matching relationship between the above two knowledge graphs, we innovatively discuss the structural interpretability and semantic interpretability for the search query knowledge graph. Some judgments or criteria about structural interpretability and semantic interpretability are given, and the sufficiency and necessity of the two interpretabilities are addressed. Extensive experimental results show that the search query knowledge graph proposed in this paper is a more effective and accurate way to express users’ search intentions and can provide help for online search.},
  archive      = {J_KIS},
  author       = {Xie, Ying-jie and Zeng, Guo-sun},
  doi          = {10.1007/s10115-024-02242-z},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2745-2770},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A new way of search query like knowledge graph and its interpretability},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-graph-driven environmental monitoring with
cross-regions knowledge transfer. <em>KIS</em>, <em>67</em>(3),
2721–2744. (<a
href="https://doi.org/10.1007/s10115-024-02294-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is a critical task in intelligent transportation systems. However, cross-city data-driven prediction models encounter numerous challenges. A principal issue is data scarcity in underdeveloped cities, resulting from inadequate data collection mechanisms. Additionally, these models frequently rely exclusively on direct spatio-temporal traffic data, often deficient in thorough extraction and lateral exploration of external information from source cities, thereby introducing risks of negative transfer. This paper presents KGD-Transfer, a knowledge graph-driven cross-city traffic flow prediction framework that utilizes the extensive semantic information embedded within knowledge graphs. To address the challenge of data scarcity, we advocate for the construction of Fused Meta-Knowledge ( $${{\textbf {FM}}_k}$$ ) from multiple source cities to facilitate precise traffic prediction. Our knowledge fusion network (Ka-net) deeply integrates heterogeneous knowledge graphs with traffic data. Following this, we apply Neural Controlled Differential Equations (NCDEs) to extract intricate spatio-temporal features from the integrated knowledge. Furthermore, the Model-Agnostic Meta-Learning (MAML) framework is utilized to efficiently minimize the risk of negative transfer in cross-city learning. This approach enables the transfer of fused source knowledge by employing non-shared parameters to perform deep feature matching across cities, capitalizing on the spatio-temporal commonalities within the $${{\textbf {FM}}_k}$$ . Experimental results from four real datasets illustrate that the inclusion of contextual information from knowledge graphs markedly enhances the prediction model’s understanding and reasoning capabilities. KGD-Transfer outperforms advanced baseline methods in both short-term (10 min) and long-term (60 min) predictions, demonstrating superior accuracy and generalizability.},
  archive      = {J_KIS},
  author       = {Liu, Xiuwen and Xiao, Yang and Zhou, Shaoheng},
  doi          = {10.1007/s10115-024-02294-1},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2721-2744},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Knowledge-graph-driven environmental monitoring with cross-regions knowledge transfer},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient rumor detection model based on deep learning
and flower pollination algorithm. <em>KIS</em>, <em>67</em>(3),
2691–2719. (<a
href="https://doi.org/10.1007/s10115-024-02305-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spite of the growing popularity of social media (Twitter, Facebook, etc.) as a source of news and data, its unfiltered nature often facilitates the spread of rumors or pieces of information that cannot be validated at the time they are shared. It is possible for false or unconfirmed information to spread like wildfire on the internet, influencing public opinion and policy in the same way that reliable news would. Some of the most pervasive examples of incorrect and dubious information are fake news and rumors, both need to be identified as soon as possible to prevent potentially destabilizing outcomes such as loss of life, reputation, or financial loss. This paper presents a pioneering study that integrates the flower pollination algorithm (FPA) with convolutional neural networks (CNNs) for enhanced rumor detection on social media platforms. We develop and test a model that leverages FPA to optimize the architecture and hyperparameters of CNNs, which significantly improves the accuracy and efficiency of detecting rumors. Using data from Twitter, the proposed model achieves a benchmark accuracy of 91.24%, outperforming existing state-of-the-art approaches. The novelty of this research lies in the application of a nature-inspired optimization algorithm to automate the fine-tuning of deep learning models, addressing the challenges of manual parameter selection and model scalability in dynamic information environments. This study contributes to the fields of misinformation detection and machine learning by providing a robust framework for real-time, adaptable rumor analysis.},
  archive      = {J_KIS},
  author       = {Ahsan, Mohammad and Sinha, Bam Bahadur},
  doi          = {10.1007/s10115-024-02305-1},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2691-2719},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {An efficient rumor detection model based on deep learning and flower pollination algorithm},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A clustering algorithm for detecting differential deviations
in the multivariate time-series IoT data based on sensor relationship.
<em>KIS</em>, <em>67</em>(3), 2641–2690. (<a
href="https://doi.org/10.1007/s10115-024-02303-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet-of-things (IoT) applications involve a large number of sensors reporting data as a set of time series. Often these data are related to each other based on the relationship of the sensors in the actual application. Any small deviations could indicate a change in the operation of the IoT system and potential problems with the IoT application’s goals. It is often difficult to detect such deviations with respect to the relationship between the sensors. This paper presents the clustering algorithm that can efficiently detect all the deviations small or large in the complex and evolving IoT data streams with the help of sensor relationships. We have demonstrated with the help of experiments that our algorithm can efficiently handle high-dimensional data and accurately detect all the deviations. In this paper, we have presented two more algorithms, anomaly detection and outlier detection, that can efficiently categorize the deviations detected by our proposed clustering algorithm into anomalous or normal deviations. We have evaluated the performance and accuracy of our proposed algorithms on synthetic and real-world datasets. Furthermore, to check the effectiveness of our algorithms in terms of efficiency, we have prepared synthetic datasets in which we have increased the complexity of the deviations to show that our algorithm can handle complex IoT data streams efficiently.},
  archive      = {J_KIS},
  author       = {Idrees, Rabbia and Maiti, Ananda and Garg, Saurabh},
  doi          = {10.1007/s10115-024-02303-3},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2641-2690},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A clustering algorithm for detecting differential deviations in the multivariate time-series IoT data based on sensor relationship},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing graph structural information with pre-trained
generative model for knowledge graph-to-text generation. <em>KIS</em>,
<em>67</em>(3), 2619–2640. (<a
href="https://doi.org/10.1007/s10115-024-02235-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph-to-text generation (KG-to-Text) is a task that involves generating accurate textual descriptions based on a given knowledge graph. Previous efforts have often enhanced pre-trained generative models by incorporating additional auxiliary pre-training tasks to supplement the missing graph structural information. However, such tasks not only require substantial computational resources, but also yield limited improvements. To address this issue, we propose a novel approach that effectively combines the graph structural information from knowledge graphs with pre-trained generative models without altering their fundamental architecture. Our approach involves inputting the original knowledge graph data into a graph convolutional network to acquire graph feature representations enriched with node characteristics. Additionally, the linearized sequence of the knowledge graph is inputted into the pre-trained generative model to exploit its inherent semantic richness. After computing multi-head attention mechanisms, we fuse the acquired graph feature representations into the pre-trained generative model to supplement the missing graph structural information. Experimental results on the WebNLG and EventNarrative datasets show that our approach achieves improved performance while reducing computational overhead.},
  archive      = {J_KIS},
  author       = {Shi, Xiayang and Xia, Zhenlin and Li, Yinlin and Wang, Xuhui and Niu, Yufeng},
  doi          = {10.1007/s10115-024-02235-y},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2619-2640},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Fusing graph structural information with pre-trained generative model for knowledge graph-to-text generation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stream mining with integrity constraint learning for event
extraction in evolving data streams. <em>KIS</em>, <em>67</em>(3),
2595–2618. (<a
href="https://doi.org/10.1007/s10115-024-02300-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An event is a structured interaction of objects, generally involving an agent (actor) who acts on target entities, possibly with associated instruments. The problem of event extraction is to identify events of interest from a variety of information sources to be stored in a knowledge base for subsequent retrieval and analysis. Two major problems in event extraction are (1) adapting to concept drift and (2) maintaining the consistency of the event knowledge base. In this paper, we address these problems in a stream mining framework, making use of an ontology for events that represents background knowledge and integrity constraints derived empirically from an evolving data stream. We introduce a first-order language FLORE (Formal Language for Ontologies and Representing Events), which is used to encode an ontology of event types and objects, and to represent individual events categorized using concepts from the ontology. We present a multi-layered stream mining method for event extraction, where the first layer consists of a pool of simple learners, and the second layer learns an evolving set of integrity constraints to ensure the ongoing consistency of the extracted events. One intended application of this approach is conflict monitoring, and the domain of the Afghanistan conflict is used to illustrate the approach. Experimental results confirm that our multi-layered approach achieves higher recall and F1 than event extraction baselines on the event extraction task and on the subtasks of event detection and argument detection and classification.},
  archive      = {J_KIS},
  author       = {Calvo Martinez, John and Wobcke, Wayne},
  doi          = {10.1007/s10115-024-02300-6},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2595-2618},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Stream mining with integrity constraint learning for event extraction in evolving data streams},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-layer topic interaction propagation model and
simulation considering opinion interaction. <em>KIS</em>,
<em>67</em>(3), 2571–2594. (<a
href="https://doi.org/10.1007/s10115-024-02295-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research on the dissemination and evolution of online public opinion focuses more on a single original or derivative topic or on treating the evolution process of user opinions and information dissemination as independent research objects. However, the evolution of opinions also affects the process of public opinion dissemination. When multiple derivative topics exist, the dissemination of public opinion will have new dynamic evolution characteristics. Thus, we propose a multi-layer topic interaction propagation model (OI-SEIRI model) considering opinion interaction. When multiple derivative topics appear, we divide the public opinion propagation of multiple topics into multiple independent propagation topic layers and construct opinion interaction rules and topic information transmission mechanisms within and between layers. By dynamically setting the probability of state transition and solving the propagation equilibrium point and propagation threshold, we clarified the impact of different factors on the trend of public opinion dissemination. Finally, the experimental results show that the OI-SEIRI model can effectively and more accurately describe the interactive information dissemination of multiple topics. The number of derivative topics, topic correlation relationships, opinion interaction behavior, and social roles can all impact the dissemination process.},
  archive      = {J_KIS},
  author       = {Yao, Cuiyou and Yu, Lin and Wang, Dong and Fu, Dongpu},
  doi          = {10.1007/s10115-024-02295-0},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2571-2594},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Multi-layer topic interaction propagation model and simulation considering opinion interaction},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time topic-based sentiment analysis for movie tweets
using hybrid approach. <em>KIS</em>, <em>67</em>(3), 2543–2569. (<a
href="https://doi.org/10.1007/s10115-024-02298-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to perform sentiment analysis (SA), which deals with dissecting and then extracting the hidden insights from the sentences said or written by a person. The proposed methodology for SA uses a combined and novel framework involving a Lexicon-based approach (LBA) and a deep learning (DL) technique to predict the overall sentiment of the text. Firstly, the LBA segregates the neutral tweets from the polar tweets. Later, a variant of CNN, namely a BERT-based bidirectional long short-term memory-temporal convolutional network (BiLSTM-TCN) grounded by the residual module and the dilated convolutions, is used to identify the type of polarity of the text. The paper also investigates various other BERT-based models like CNN, LSTM, and BiLSTM on the IMDB Movie Review dataset containing 50k movie reviews to show that the suggested model achieves a mean validation accuracy of 0.932 and a mean validation loss of 0.238 for the last three epochs for the polar reviews. After that, the trained model is used to forecast the sentiment of the live-streaming tweets about a particular movie of interest. The Twitter API, Tweepy, fetches tweets crawling over Twitter. The study obtains test accuracy, F1, and ROC–AUC scores of 92.94%, 0.929, and 0.98, respectively, in the least number of epochs, which is better than other models mentioned above, running in the same environment.},
  archive      = {J_KIS},
  author       = {Madan, Anjum and Kumar, Devender},
  doi          = {10.1007/s10115-024-02298-x},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2543-2569},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Real-time topic-based sentiment analysis for movie tweets using hybrid approach},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel ensemble label propagation with hierarchical
weighting for semi-supervised learning. <em>KIS</em>, <em>67</em>(3),
2521–2542. (<a
href="https://doi.org/10.1007/s10115-024-02245-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, semi-supervised learning is one of the research sports to solve the problem of labeled data. Label propagation (LP) is a popular method to classify graph data by utilizing the characterization of data nodes. However, LP has randomness and cannot effectively employ node attributes. In this paper, to solve the above problem, we propose a novel LP method based on hierarchical weighting (HWLP). Firstly, attribute aggregation and attribute update are executed for each node. Secondly, in the process of LP, for each unlabeled node, the label owned by its neighbors with the highest similarity is selected to avoid arbitrary LP. Finally, maximum voting is adopted to enhance the stability of the results. Experimental results show that the proposed method has better performance and stability than others.},
  archive      = {J_KIS},
  author       = {Zheng, Yifeng and Liu, Yafen and Qing, Depeng and Zhang, Wenjie and Pan, Xueling and Li, Guohe},
  doi          = {10.1007/s10115-024-02245-w},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2521-2542},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A novel ensemble label propagation with hierarchical weighting for semi-supervised learning},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E-learning app selection multi-criteria group
decision-making problem using einstein operator in linguistic
trapezoidal neutrosophic environment. <em>KIS</em>, <em>67</em>(3),
2481–2519. (<a
href="https://doi.org/10.1007/s10115-024-02265-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we have defined linguistic trapezoidal neutrosophic numbers (LTNNs) which are a combination of trapezoidal neutrosophic numbers and linguistic variable numbers. Then, we introduced the Einstein sum, product and exponentiation operations for LTNNs and discussed the relationship among these operations. Moreover, two new kinds of aggregation operators, namely Einstein weighted-average operator and Einstein weighted-geometric operator for LTNNs, have been constructed. Based on the above aggregation operators, a multi-criteria group decision-making technique has been designed, which is demonstrated through numerical examples. Finally, sensitivity analysis and comparative study have been accomplished to exhibit the effectiveness and feasibility of the newly developed technique in the linguistic environment.},
  archive      = {J_KIS},
  author       = {Haque, Tipu Sultan and Chakraborty, Avishek and Alam, Shariful},
  doi          = {10.1007/s10115-024-02265-6},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2481-2519},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {E-learning app selection multi-criteria group decision-making problem using einstein operator in linguistic trapezoidal neutrosophic environment},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for community architectural
layout generation. <em>KIS</em>, <em>67</em>(3), 2453–2480. (<a
href="https://doi.org/10.1007/s10115-024-02291-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Architectural layout design is of considerable importance in urban design, yet it can be a time-consuming and labor-intensive task for architects. Thus, a highly automated approach would benefit the profession. Different from recently studied methods for indoor floorplan generation, community architectural layout generation faces more challenges due to constraints such as building interval and volume rate while also considering architectural aesthetics. Existing algorithms that rely on predefined rules or heuristic search have difficulties balancing these factors. In addition, a dataset for evaluating the generated plans is lacking. In this paper, we formulate the community architectural layout task as a Markov game by defining the state, action space and reward function. We then propose a multi-agent reinforcement learning method with curriculum learning to generate layouts for the formulation. Besides, we propose a set of metrics for the evaluation of architectural layouts especially for residential area planning. We conduct our experiments on the real-world scene. The results have demonstrated our approach’s superiority in comparison to baseline methods.},
  archive      = {J_KIS},
  author       = {Sheng, Tao and Xiong, Yun and Wang, Haofen and Zhang, Yao and Wang, Siqi and Zhang, Weinan},
  doi          = {10.1007/s10115-024-02291-4},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2453-2480},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Deep reinforcement learning for community architectural layout generation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of corn futures prices with decomposition and
hybrid deep learning models. <em>KIS</em>, <em>67</em>(3), 2427–2452.
(<a href="https://doi.org/10.1007/s10115-024-02301-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting corn futures prices is crucial for market participants, policymakers, and agricultural enterprises to manage risks and make informed decisions. Therefore, it is necessary to improve the accuracy and stability of corn futures price predictions. This study proposes a deep mixed model that integrates variational mode decomposition (VMD), particle swarm optimization (PSO), convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and an attention mechanism. First, VMD is used to decompose the corn futures closing price series, thereby reducing data complexity. Then, principal component analysis (PCA) is performed on 21 influencing factors to extract key components affecting price fluctuations. The proposed model combines CNN for local feature extraction, LSTM for time series processing, and an attention mechanism to focus on critical information. In addition, the PSO algorithm optimizes the LSTM hyperparameters, further enhancing the model’s performance. To verify the model’s effectiveness, comprehensive experiments were conducted using historical data on corn futures. The results of four comparative experiments show that, based on multiple metrics such as RMSE, MAE, and $$\text {R}^2$$ , the proposed model significantly outperforms 14 existing models in terms of prediction accuracy and stability. These findings indicate that the model has practical application potential in financial forecasting and decision-making.},
  archive      = {J_KIS},
  author       = {Li, Feng and Tang, Menghe},
  doi          = {10.1007/s10115-024-02301-5},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2427-2452},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Prediction of corn futures prices with decomposition and hybrid deep learning models},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Digital twin: Securing IoT networks using integrated ECC
with blockchain for healthcare ecosystem. <em>KIS</em>, <em>67</em>(3),
2395–2426. (<a
href="https://doi.org/10.1007/s10115-024-02273-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital twin (DT) innovation is becoming increasingly prevalent in numerous areas. This is often particularly genuine in healthcare, which depends increasingly on Internet of Things (IoT) systems. But this combination brings up enormous issues with safety, security, and being able to develop. Since information is private, it is exceptionally critical to keep it secure from individuals who shouldn&#39;t have gotten to it and from being stolen. This consideration proposes a modern framework that combines elliptic curve cryptography (ECC) with blockchain innovation to bargain with these issues. The system is implied to ensure IoT systems by making demonstrative apparatuses in healthcare more secure. A genetic algorithm-based random forest (GAO-RF) demonstration is additionally utilized to form include choice work way better, which makes it beyond any doubt that information taking care of and analysis go easily. The GAO-RF show includes the body of unused thoughts by progressing the method of choosing highlights, which is exceptionally critical for proficiently overseeing colossal sums of private information. The show that was put into activity works exceptionally well, as appeared by its execution measurements as F1-score of 97.3%, an exactness of 98.4%, an exactness of 97.3%, a review of 97.4%, an MCC of 97.69%, and a kappa measurement (KS) of 97.31%. These results show an exceptionally strong framework that can handle and protect private health data. The safety and security of understanding information in IoT systems have enormously progressed by including ECC and blockchain in the DT system. A genetic algorithm has been shown to work well in the random forest model for feature selection, which has led to better security methods. This study has big effects on the healthcare field because it gives us a strong way to keep patient information safe. This method creates trust in the healthcare system by making sure that private data are handled in an honest and safe way. It could change how patient data are protected in this digital age.},
  archive      = {J_KIS},
  author       = {Sharma, Vikas and Kumar, Akshi and Sharma, Kapil},
  doi          = {10.1007/s10115-024-02273-6},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2395-2426},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Digital twin: Securing IoT networks using integrated ECC with blockchain for healthcare ecosystem},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High utility itemset mining in data stream using elephant
herding optimization. <em>KIS</em>, <em>67</em>(3), 2357–2394. (<a
href="https://doi.org/10.1007/s10115-024-02288-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining high utility itemsets from data stream within limited time and space is a challenging task. Traditional algorithms typically require multiple scans and complex data structures for data connection, storage and update. Moreover, the evaluation of duplicate itemsets generated by overlapping batches leads to low efficiency of the algorithm in terms of time and space. To address these issues, this paper proposes a heuristic-based data stream high utility itemset mining algorithm, termed SHUIM-EHO, designed to effectively solve limited storage space. The SHUIM-EHO algorithm designs a new clan updating strategy, which effectively enhances the convergence speed and reduces itemset loss. Additionally, a hash storage strategy is proposed to avoid the evaluation of duplicate itemsets, thereby further improving the execution efficiency of the algorithm. Experiments on real and synthetic datasets demonstrate the effectiveness of the algorithm, significantly reducing memory consumption and maintaining strong scalability.},
  archive      = {J_KIS},
  author       = {Han, Meng and He, Feifei and Zhang, Ruihua and Li, Chunpeng and Meng, Fanxing},
  doi          = {10.1007/s10115-024-02288-z},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2357-2394},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {High utility itemset mining in data stream using elephant herding optimization},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trustworthy federated learning: Privacy, security, and
beyond. <em>KIS</em>, <em>67</em>(3), 2321–2356. (<a
href="https://doi.org/10.1007/s10115-024-02285-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While recent years have witnessed the advancement in big data and artificial intelligence, it is of much importance to safeguard data privacy and security. As an innovative approach, federated learning (FL) addresses these concerns by facilitating collaborative model training across distributed data sources without transferring raw data. However, the challenges of robust security and privacy across decentralized networks catch significant attention in dealing with the distributed data in FL. In this paper, we conduct an extensive survey of the security and privacy issues prevalent in FL, underscoring the vulnerability of communication links and the potential for cyber threats. We delve into various defensive strategies to mitigate these risks, explore the applications of FL across different sectors, and propose research directions. We identify the intricate security challenges that arise within the FL frameworks, aiming to contribute to the development of secure and efficient FL systems.},
  archive      = {J_KIS},
  author       = {Chen, Chunlu and Liu, Ji and Tan, Haowen and Li, Xingjian and Wang, Kevin I-Kai and Li, Peng and Sakurai, Kouichi and Dou, Dejing},
  doi          = {10.1007/s10115-024-02285-2},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2321-2356},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Trustworthy federated learning: Privacy, security, and beyond},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partially ordered stochastic conformance checking.
<em>KIS</em>, <em>67</em>(3), 2291–2319. (<a
href="https://doi.org/10.1007/s10115-024-02280-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining aids organisations in improving their operational processes by providing visualisations and algorithms that turn event data into insights. How often behaviour occurs in a process—the stochastic perspective—is important for simulation, recommendation, enhancement and other types of analysis. Although the stochastic perspective is important, the focus is often on control flow. Stochastic conformance checking techniques assess the quality of stochastic process models and/or event logs with one another. In this paper, we address three limitations of existing stochastic conformance checking techniques: inability to handle uncertain event data (e.g. events having only a date), exponential blow-up in computation time due to the analysis of all interleavings of concurrent behaviour and the problem that loops that can be unfolded infinitely often. To address these challenges, we provide bounds for conformance measures and use partial orders to encode behaviour. An open-source implementation is provided, which we use to illustrate and evaluate the practical feasibility of the approach.},
  archive      = {J_KIS},
  author       = {Leemans, Sander J. J. and Brockhoff, Tobias and van der Aalst, Wil M. P. and Polyvyanyy, Artem},
  doi          = {10.1007/s10115-024-02280-7},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2291-2319},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Partially ordered stochastic conformance checking},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid sampling algorithm for imbalanced and class-overlap
data based on natural neighbors and density estimation. <em>KIS</em>,
<em>67</em>(3), 2259–2290. (<a
href="https://doi.org/10.1007/s10115-024-02281-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data classification poses a significant challenge in machine learning and data mining, exacerbated by class overlap which adversely affects model performance. Resampling is widely used to tackle imbalanced data. However, most resampling algorithms overlook the complexity of overlapping region samples, resulting in excessive removal of majority class samples and insufficient representation of minority class information. To tackle these issues, this paper proposes a novel approach, namely natural neighbors and density estimation-based hybrid sampling algorithm (NaNDS). NaNDS fully considers the varying impacts of overlapping samples with different characteristics on subsequent classification tasks. First, the density of minority class samples is estimated using a Gaussian kernel function, and high-density minority class samples are selected to construct a set of hyper-spherical structures. These structures facilitate the geometric identification and removal of overlapping majority class samples that negatively impact classification. Then, oversampling weights for minority samples are determined by combining density and information entropy estimates derived from natural neighbors. Afterward, an adaptive oversampling strategy is developed, using differentiation-based generation guided by natural neighbor information. This process appropriately corrects decision boundary by enhancing information in both overlapping and minority class-dominated regions. Experimental validation on the KEEL dataset demonstrates NaNDS outperforming eight state-of-the-art algorithms, highlighting its superior competitiveness and robustness in handling class-overlap imbalanced datasets.},
  archive      = {J_KIS},
  author       = {Li, Xinqi and Liu, Qicheng},
  doi          = {10.1007/s10115-024-02281-6},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2259-2290},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {A hybrid sampling algorithm for imbalanced and class-overlap data based on natural neighbors and density estimation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). User-based clustering deep model for the sequential
point-of-interest recommendation. <em>KIS</em>, <em>67</em>(3),
2233–2258. (<a
href="https://doi.org/10.1007/s10115-024-02277-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The point-of-interest (POI) recommendation is a key function of location-based social networks that can help users exploit unfamiliar areas. Due to the massive check-in records accumulated in these location-based applications, the sequential POI recommendation has evolved quickly in the research community. Although the existing sequential POI recommendation models have reached an encouraging performance in predicting the next-N POIs to users, the data sparsity problem is still severe in the sequential POI recommendation task. It is challenging to learn the users’ preferences of POIs under the highly sparse dataset. Meanwhile, many sequential models focus on exploiting users’ interests from the entire dataset, ignoring the effect of collaborative information from similar users. To this end, we propose a user-based clustering deep model (UCDM) for the sequential POI recommendation to deal with these issues. UCDM extracts collaborative information via a user-based intent clustering module and uses a binary self-attention layer to both learn the general preference from the entire dataset and the local preference from the collaborative information. In addition, our proposed model uses a POI candidate filter to control the size of the POI candidate set to reduce the sparsity of the dataset. In the model learning phase, we adopt the Bayesian personalized ranking to train our model. The experiment verifies that our proposed UCDM outperforms the selected baseline models for the sequential POI recommendation on two real-world check-in datasets.},
  archive      = {J_KIS},
  author       = {Wang, Tianxing and Wang, Can and Tian, Hui and Liew, Alan Wee-Chung},
  doi          = {10.1007/s10115-024-02277-2},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2233-2258},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {User-based clustering deep model for the sequential point-of-interest recommendation},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Audio meets text: A loss-enhanced journey with manifold
mixup and re-ranking. <em>KIS</em>, <em>67</em>(3), 2195–2231. (<a
href="https://doi.org/10.1007/s10115-024-02283-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio–text retrieval is the task of aligning natural language and audio such that instances from different modalities can be compared with a similarity metric. Contrastive representation learning is a popular way to address this problem by finetuning a dual encoder backbone. However, finetuning incurs a heavy computational burden and requires multiple graphics processing units. The main objective of this study is thus to drive enhanced retrieval performance in audio–text retrieval with lower computational burden and resources. Thus, a series of plug-and-play modules are introduced to elicit knowledge from pretrained audio and text encoders. From creating a competitive baseline with early and late fusion first, the study endeavors to improve the performance further by adapting deep metric Circle and Ranked List losses. This study utilizes Manifold Mixup as a strong regularizer and a novel post-processing step of re-ranking to refine the results further. These changes work in symphony to obtain superior performance than other models without the need to finetune encoders. Particularly, an improvement of 1–3% is obtained on the AudioCaps dataset, establishing a new state of the art. The results on the Clotho dataset remain competitive with other finetuning approaches utilizing heavy resources. Also, the model emerges as the best among the frozen encoder models across all the metrics. Moreover, the proposed modules are modality agnostic and hold great potential for other retrieval tasks beyond the domain of audio–text. Overall, this study establishes a strong and competitive baseline for future approaches in audio–text retrieval.},
  archive      = {J_KIS},
  author       = {Suryawanshi, Yash and Shah, Vedanshi and Randar, Shyam and Joshi, Amit},
  doi          = {10.1007/s10115-024-02283-4},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2195-2231},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Audio meets text: A loss-enhanced journey with manifold mixup and re-ranking},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MuLoR: A multi-graph contrastive network for logical
reasoning. <em>KIS</em>, <em>67</em>(3), 2171–2193. (<a
href="https://doi.org/10.1007/s10115-024-02286-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Logical reasoning tasks are more challenging than traditional machine reading comprehension tasks. The machine must recognize the logical relationships implicit in the text and use logical reasoning to derive an answer. Logical reasoning tasks currently face two major challenges. The first challenge is the difficulty of capturing the logical relationships implicit in the text. The second involves connecting the divide between distinct logical structures and the continuous space of text embeddings. In this study, we present a contrastive network based on multiple graphs designed to tackle these issues through the combination of both implicit and explicit logical connections, thereby enhancing reasoning capabilities. We use different construction strategies to create logical relationship graphs and logical hypergraph graphs. These graphs are integrated into a multi-graph contrastive network to learn higher-order logical representations, which are then used as inputs to a decoder for final prediction. The evaluation of our designed models was performed on datasets designed to assess reasoning ability, including ReClor, LogiQA and the extended iteration LogiQA 2.0. The experimental results show that our proposed method outperforms the state-of-the-art models. In particular, the results obtained on the LogiQA 2.0 dataset, which contains a larger number of samples, are particularly outstanding. Our model achieved an accuracy rate of 59.16%, outperforming most of the baseline comparisons by at least one percentage point, demonstrating its superior potential in complex reasoning tasks.},
  archive      = {J_KIS},
  author       = {Xiao, Jing and Lin, Guijin and Xiao, Yu and Li, Ping},
  doi          = {10.1007/s10115-024-02286-1},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2171-2193},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {MuLoR: A multi-graph contrastive network for logical reasoning},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resource allocation in fog computing: A survey on current
state and research challenges. <em>KIS</em>, <em>67</em>(3), 2091–2170.
(<a href="https://doi.org/10.1007/s10115-024-02274-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With fog computing, new services and applications are enabled on the internet of things by providing computational services at the network edge. Fog computing is emerging as a transformative paradigm, linking edge devices with centralized cloud resources. It improves network efficiency, lowers latency, and increases computing power. Resource allocation and optimization are critical for fog computing to achieve optimal system performance, efficient resource usage, and smooth user experiences. Throughout the presentation, we discussed the architecture, framework, comparison of fog computing with cloud computing, resource allocation strategies, and the relevance of resource allocation to fog computing. Various methods of optimization and allocation are discussed, along with their application to fog-enhanced vehicle services and vehicular fog computing. For the purpose of allocating resources, minimizing latency, and optimizing quality of service (QoS), a variety of techniques have been applied, including game theory, convex optimization, reinforcement learning, and genetic algorithms. Additionally, we discuss how fog computing environment resource allocation works using game theory. The purpose of this paper is to review several articles in the field of fog environments and to provide a detailed comparison of each from a variety of perspectives. An overview of the main features of the reviewed articles was also presented in the form of a table. This study highlights the effectiveness of these strategies for improving system performance, reducing latency, optimizing resources, and reducing energy consumption. Lastly, we highlight future research directions and potential contributions in fog computing. Management of heterogeneity, ensuring real-time optimization, ensuring QoS and security concerns, promoting energy-efficient computing and sustainability, managing mobility, scheduling and self-adaptive scheduling, load balancing, offloading, reliability, sensor lifetime, multiagent reinforcement learning, optimal resource allocation, and quality of experience are discussed. The purpose of this survey is to give readers a detailed understanding of state-of-the-art methods, challenges, and possible future directions in resource allocation and optimization in fog computing. The aim of this research is to synthesize insights from the literature in order to provide valuable insight for researchers, practitioners, and stakeholders interested in advancing the field of fog computing.},
  archive      = {J_KIS},
  author       = {Nemati, Amir Mohammad and Mansouri, Najme},
  doi          = {10.1007/s10115-024-02274-5},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2091-2170},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Resource allocation in fog computing: A survey on current state and research challenges},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recommender systems in smart campus: A systematic mapping.
<em>KIS</em>, <em>67</em>(3), 2063–2089. (<a
href="https://doi.org/10.1007/s10115-024-02240-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are extremely useful tools to provide the user with information that may be of interest. These systems are responsible for performing a series of procedures to filter items from massive databases and return only what the user would be looking for, which can be a product, a song, a movie or series, a website, news, or educational resources. Recommender systems are also intended for educational purposes, returning items such as teaching materials, video classes, books, courses, and short courses, for example. The environments in universities that aggregate these systems are called smart university campus. Sites that make use of multiple technologies, able to relate the virtual environment with the real and provide users with a fully integrated system. From this context, there was a systematic mapping of smart campus areas and recommendation systems. A study was conducted to investigate the relationship between these areas, through the search in four databases, between the years 2017 and 2024, identifying 894 papers, of which 101 were selected for analysis. We also identified some key documents in the area of recommender systems, as well as the technologies applied in each of them. The analysis conducted in this paper identified several research opportunities in the area. However, it was observed that many of the studies do not make clear the information that their applications will be used in conjunction with smart campus.},
  archive      = {J_KIS},
  author       = {Hideki Mensch Maruyama, Martin and Willig Silveira, Luan and da Silva Júnior, Elvandi and Casanova, Gabriel and Palazzo M. de Oliveira, José and Maran, Vinícius},
  doi          = {10.1007/s10115-024-02240-1},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2063-2089},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Recommender systems in smart campus: A systematic mapping},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum computing and quantum-inspired techniques for
feature subset selection: A review. <em>KIS</em>, <em>67</em>(3),
2019–2061. (<a
href="https://doi.org/10.1007/s10115-024-02282-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature subset selection is essential for identifying relevant and non-redundant features, which enhances classification accuracy and simplifies machine learning models. Given the computational difficulties of determining optimal feature subsets, heuristic and metaheuristic algorithms have been widely used. Recently, the rise of quantum computing has led to the exploration of quantum-inspired metaheuristics and quantum-based approaches for this task. Although various studies have explored quantum-inspired and quantum-based approaches for feature subset selection, a comprehensive review that critically examines their significance, limitations, underlying mechanisms, and future directions remains lacking in the literature. This paper addresses this gap by presenting the first in-depth survey of these approaches. We systematically selected and analyzed relevant studies from prominent research databases, providing a detailed evaluation of quantum-inspired metaheuristics and quantum computing paradigms applied to feature subset selection. Our findings indicate that quantum-inspired metaheuristic approaches often deliver superior performance compared to traditional metaheuristic methods for feature subset selection. Nevertheless, their reliance on classical computing limits their ability to fully realize the advantages offered by quantum computing. The quantum-based feature subset selection methods, on the other hand, show considerable promise but are frequently constrained by the current limitations of quantum hardware, making large-scale feature subset selection challenging. Given the rapid evolution of quantum computing, research on both quantum-inspired and quantum-based feature subset selection remains insufficient to draw definitive conclusions. We are optimistic that this review will provide a foundation for future advancements in feature subset selection as quantum computing resources become more accessible.},
  archive      = {J_KIS},
  author       = {Mandal, Ashis Kumar and Chakraborty, Basabi},
  doi          = {10.1007/s10115-024-02282-5},
  journal      = {Knowledge and Information Systems},
  month        = {3},
  number       = {3},
  pages        = {2019-2061},
  shortjournal = {Knowl. Inf. Syst.},
  title        = {Quantum computing and quantum-inspired techniques for feature subset selection: A review},
  volume       = {67},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="mam---9">MAM - 9</h2>
<ul>
<li><details>
<summary>
(2025). Physical programmability. <em>MAM</em>, <em>35</em>(2),
1–29. (<a href="https://doi.org/10.1007/s11023-025-09714-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article delivers an account of what it is for a physical system to be programmable. Despite its significance in computing and beyond, today’s philosophical discourse on programmability is impoverished. This contribution offers a novel definition of physical programmability as the degree to which the selected operations of an automaton can be reconfigured in a controlled way. The framework highlights several key insights: the constrained applicability of physical programmability to material automata, the characterization of selected operations within the neo-mechanistic framework, the understanding of controlled reconfiguration through the causal theory of interventionism, and the recognition of physical programmability as a gradual notion. The account can be used to individuate programmable (computing) systems and taxonomize concrete systems based on their programmability. The article closes by posing some open questions and offering avenues for future research in this domain.},
  archive      = {J_MAM},
  author       = {Wiggershaus, Nick},
  doi          = {10.1007/s11023-025-09714-3},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Minds Mach.},
  title        = {Physical programmability},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Persons, unique value and avatars. <em>MAM</em>,
<em>35</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s11023-025-09715-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An individual human has value partly in virtue of their uniqueness. Personal avatar technology—technology which creates a digital replication of a real person—appears to have the potential to undermine that value. Here I explore if and how avatars might make humans less valuable by undermining the value that a human gains from being unique. Ultimately, I conclude that, while avatars cannot make humans no longer unique, they could significantly undermine the value that we place on human uniqueness. First, I argue that a qualitative model of uniqueness cannot account for the unique value that a person has. This leads to the significant and surprising claim that necessarily unique properties of humans cannot accommodate the value arising from human uniqueness: humans have unique value in virtue of being contingently irreplaceable. I explore how the use of personal avatars might undermine or even destroy that value. Finally, I consider further applications of the theory of unique human value, including how it might explain and accommodate our attachment to personal avatars themselves.},
  archive      = {J_MAM},
  author       = {Sweeney, Paula},
  doi          = {10.1007/s11023-025-09715-2},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Minds Mach.},
  title        = {Persons, unique value and avatars},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How do social media algorithms appear? A phenomenological
response to the black box metaphor. <em>MAM</em>, <em>35</em>(2), 1–21.
(<a href="https://doi.org/10.1007/s11023-025-09716-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article challenges the dominant ‘black box’ metaphor in critical algorithm studies by proposing a phenomenological framework for understanding how social media algorithms manifest themselves in user experience. While the black box paradigm treats algorithms as opaque, self-contained entities that exist only ‘behind the scenes’, this article argues that algorithms are better understood as genetic phenomena that unfold temporally through user-platform interactions. Recent scholarship in critical algorithm studies has already identified various ways in which algorithms manifest in user experience: through affective responses, algorithmic self-reflexivity, disruptions of normal experience, points of contention, and folk theories. Yet, while these studies gesture toward a phenomenological understanding of algorithms, they do so without explicitly drawing on phenomenological theory. This article demonstrates how phenomenology, particularly a Husserlian genetic approach, can further conceptualize these already-documented algorithmic encounters. Moving beyond both the paradigm of artifacts and static phenomenological approaches, the analysis shows how algorithms emerge as inherently relational processes that co-constitute user experience over time. By reconceptualizing algorithms as genetic phenomena rather than black boxes, this paper provides a theoretical framework for understanding how algorithmic awareness develops from pre-reflective affective encounters to explicit folk theories, while remaining inextricably linked to users’ self-understanding. This phenomenological framework contributes to a more nuanced understanding of algorithmic mediation in contemporary social media environments and opens new pathways for investigating digital technologies.},
  archive      = {J_MAM},
  author       = {Longo, Anthony},
  doi          = {10.1007/s11023-025-09716-1},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Minds Mach.},
  title        = {How do social media algorithms appear? a phenomenological response to the black box metaphor},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In honor of james moor: A grateful retrospective.
<em>MAM</em>, <em>35</em>(2), 1–6. (<a
href="https://doi.org/10.1007/s11023-025-09718-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MAM},
  author       = {Ess, Charles M.},
  doi          = {10.1007/s11023-025-09718-z},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-6},
  shortjournal = {Minds Mach.},
  title        = {In honor of james moor: A grateful retrospective},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The quantum panopticon: A theory of surveillance for the
quantum era. <em>MAM</em>, <em>35</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s11023-025-09723-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of quantum computing will compromise current asymmetric cryptography. Awaiting this moment, global superpowers are routinely collecting and storing encrypted data, so as to later decrypt it once sufficiently strong quantum computers are in place. We argue that this situation gives rise to a new mode of global surveillance that we refer to as a quantum panopticon. Unlike traditional forms of panoptic surveillance, the quantum panopticon introduces a temporal axis, whereby data subjects’ future pasts can be monitored from an unknown “superposition” in the quantum future. It also introduces a new level of uncertainty, in that the future watchman’s very existence becomes a function of data subjects’ efforts to protect themselves from being monitored in the present. Encryption may work as a momentary protection, but increases the likelihood of long-term preservation for future decryption, because encrypted data is stored longer than plaintext data. To illustrate the political and ethical aspects of these features, we draw on cryptographic as well as theoretical surveillance literature and call for urgent consideration of the wider implications of quantum computing for the global surveillance landscape.},
  archive      = {J_MAM},
  author       = {Olsson, Erik and Öhman, Carl},
  doi          = {10.1007/s11023-025-09723-2},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Minds Mach.},
  title        = {The quantum panopticon: A theory of surveillance for the quantum era},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Moor’s “are there decisions computers should never make?”
<em>MAM</em>, <em>35</em>(2), 1–8. (<a
href="https://doi.org/10.1007/s11023-025-09719-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {‘Are There Decisions Computers Should Never Make?’ is one of James H. Moor’s many groundbreaking papers in computer ethics, and it is one that I have thought a good deal about since its publication in 1979 and especially in recent years in relation to current discourse on AI. In this paper, I describe Jim’s analysis, reflect on its relevance to current thinking about AI, and take issue with several of his arguments. The conclusion of Jim’s paper is that computers should never choose human values and goals. I suggest that this is not possible because of the nature of values and how they are intertwined in computer decision making.},
  archive      = {J_MAM},
  author       = {Johnson, Deborah G.},
  doi          = {10.1007/s11023-025-09719-y},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-8},
  shortjournal = {Minds Mach.},
  title        = {Moor’s ‘Are there decisions computers should never make?’},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Moor on ethics for emerging technologies: Some environmental
considerations. <em>MAM</em>, <em>35</em>(2), 1–7. (<a
href="https://doi.org/10.1007/s11023-025-09721-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Around the turn of this century a number of emerging technologies were in the news, raising some potentially significant ethical questions. Given that they were emerging they as yet had no, or very few, impacts, so it was not obvious how best to assess them ethically. Jim Moor addressed this issue and offered three suggestions for a better ethics for emerging technologies. His first was that ethics should be dynamic, that is, it should be an ongoing process before, during and after the technological development. Second, there should be close collaboration between the researchers and developers on the one hand, and ethicists and social scientists on the other. Finally, ethical analyses should be more sophisticated. In this paper I argue that environmental issues and the questioning of core ethical values should be a central part of the ethics of emerging technologies, using AI examples. Given the kind of beings that we are, technology and the environment are closely connected for human flourishing.},
  archive      = {J_MAM},
  author       = {Weckert, John},
  doi          = {10.1007/s11023-025-09721-4},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-7},
  shortjournal = {Minds Mach.},
  title        = {Moor on ethics for emerging technologies: Some environmental considerations},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). James moor’s privacy framework: A theory in need of further
exploration. <em>MAM</em>, <em>35</em>(2), 1–7. (<a
href="https://doi.org/10.1007/s11023-025-09717-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is intended as a tribute to the late James Moor. An esteemed Dartmouth professor, who published in many areas of philosophy, including logic, Moor is perhaps best remembered today for his pioneering work in the field of computer ethics. His seminal (and award-winning) article, “What Is Computer Ethics?” (Metaphilosophy, 1985) was highly influential both in defining and shaping the then nascent field of computer ethics. Many other computer-ethics-related papers followed over the next quarter century, in which Moor examined a range of topics – from moral responsibility to autonomy to privacy in the context of computing and emerging technologies, including nanotechnology and AI. And while the insights and frameworks put forth in many of his published works have received the acclaim they deserve, Moor’s contribution to the privacy literature remains, in my view, underappreciated. In trying to show why his privacy theory deserves much more attention than received to date, I also briefly describe the evolution of Moor’s position on privacy – from his earlier publications on that topic to a comprehensive and systematic privacy framework. I then suggest that a further exploration of his privacy theory would benefit researchers working in technology ethics in general, and AI ethics in particular. Finally, I encourage privacy scholars to take a closer look at Moor’s privacy framework to see whether they might be able to tease out and disclose some potential insights and features that may still be embedded in that robust theory of privacy.},
  archive      = {J_MAM},
  author       = {Tavani, Herman T.},
  doi          = {10.1007/s11023-025-09717-0},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-7},
  shortjournal = {Minds Mach.},
  title        = {James moor’s privacy framework: A theory in need of further exploration},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The historical development of ethics of emerging
technologies. <em>MAM</em>, <em>35</em>(2), 1–9. (<a
href="https://doi.org/10.1007/s11023-025-09720-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article traces the historical development of the ethics of emerging technologies. It argues that during the late 2000s and 2010s, the field of ethics of technology transformed from a fragmented, reactive, and methodologically underdeveloped discipline focused on mature technologies and lacking policy orientation into a more cohesive, proactive, methodologically sophisticated, and policy-focused field with a strong emphasis on emerging technologies. An agenda for this transition was set in Jim Moor’s seminal publication “Why We Need Better Ethics for Emerging Technologies”.},
  archive      = {J_MAM},
  author       = {Brey, Philip A. E.},
  doi          = {10.1007/s11023-025-09720-5},
  journal      = {Minds and Machines},
  month        = {6},
  number       = {2},
  pages        = {1-9},
  shortjournal = {Minds Mach.},
  title        = {The historical development of ethics of emerging technologies},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="meco---7">MECO - 7</h2>
<ul>
<li><details>
<summary>
(2025). Reordering-enhanced grad-CAM for unveiling hidden patterns
in multi-source financial data. <em>MECO</em>, <em>17</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s12293-025-00443-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) excel in feature extraction and pattern recognition in areas like image classification and speech processing. However, their application in the financial sector has been limited due to the complexity, high dimensionality, and temporal nature of financial data, as well as the need for model interpretability. This study, based on CNN technology, proposes a Reordering-Enhanced Grad-CAM algorithm to improve model interpretability and reliability, offering transparent and dependable tools for financial decision-making. The innovation of this study lies in two key aspects: firstly, it replaces the traditional manual variable selection approach with automatic feature extraction and fusion using CNNs, demonstrating the effectiveness of deep learning in handling large-scale financial data. Secondly, we propose a novel reordering-based iterative algorithm that adapts Grad-CAM, originally designed for image classification, to multi-source financial time series data, treating sliding window data segments as pseudo-images to improve interpretability and identify critical features. Using data from Shanghai and Shenzhen A-shares (1990–2020), the Reordering-Enhanced Grad-CAM technique generated heatmaps that identified key predictive indicators, leading to improved model performance. Robustness analysis demonstrated that over 70% of important variables were consistently identified, with some models reaching up to 100%, confirming the reliability and stability of our method in financial distress prediction.},
  archive      = {J_MECO},
  author       = {Zhang, Zhigang and Liu, Kehui and Lei, Junli},
  doi          = {10.1007/s12293-025-00443-9},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Memet. Comput.},
  title        = {Reordering-enhanced grad-CAM for unveiling hidden patterns in multi-source financial data},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AIM: An accurate and explainable model for ATAC to GEX
translation and pathway analysis. <em>MECO</em>, <em>17</em>(2), 1–21.
(<a href="https://doi.org/10.1007/s12293-025-00442-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of multimodal technologies has enabled the simultaneous measurement of various cellular modalities, such as chromatin accessibility (ATAC), gene expression (GEX), and surface protein abundance in single cells. However, the lack of multimodal datasets requires the development of robust algorithms that can translate data between different modalities. In this study, we present AIM, a framework for accurate and interpretive multimodal translation, specifically designed for the conversion of ATAC data into GEX profiles. AIM introduces a novel two-tier modeling architecture. The upper tier captures the global relationships between ATAC and GEX, generating an initial estimate of gene expression. The lower tier performs a finer-grained analysis by modeling inter-chromosomal interactions to refine the generated GEX representation. This modular structure enhances both the accuracy and adaptability of AIM. Additionally, an integrated attention mechanism provides interpretability by highlighting critical chromatin regions influencing specific gene expressions. Our experimental results demonstrate that AIM achieves state-of-the-art performance, with a per-chromosome RMSE of 0.2206, outperforming existing approaches (0.2232). Furthermore, the attention maps generated by AIM offer a pathway analysis capability, uncovering biologically significant gene-gene interactions such as ARHGAP24-ARAP2 and SYK-PAX5. These findings validate AIM’s effectiveness not only as a data translation tool but also as a platform for deriving mechanistic insights into gene regulatory dynamics.},
  archive      = {J_MECO},
  author       = {Nguyen, Quang H. and Tran, Hoang V. and Nguyen, Huu Tien and Le, Phuong T. M. and Nguyen, Phi Le and Nguyen, Binh P.},
  doi          = {10.1007/s12293-025-00442-w},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Memet. Comput.},
  title        = {AIM: An accurate and explainable model for ATAC to GEX translation and pathway analysis},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bagging-based ensemble classifiers using multi-objective
genetic programming. <em>MECO</em>, <em>17</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s12293-025-00444-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective evolutionary computation algorithm, genetic programming (GP) can be designed as effective classifiers due to its flexible representation method. However, the classification performance of GP classifiers can be degraded due to imbalanced data and weak generalization ability. Precision-recall curve (PRC) has been proven to be an effective evaluation metric for dealing with imbalanced data. However, PRC may result in classifiers with the same PRC value being completely different classifiers. Moreover, controlling the complexity of GP individuals can improve their generalization ability. Therefore, in this paper, multi-objective GP (MOGP) is used to optimize three objectives including recall, precision and model complexity to reduce the impact of imbalanced data and improve the generalization of GP individuals. MOGP-based ensemble classifier construction methods can improve the generalization ability of classification models. However, this strategy needs to address the issues of how to improve the diversity of GP solutions and select optimal solutions from Pareto fronts. Therefore, in this paper, a bagging-based ensemble classifier construction method is proposed to improve the generalization of GP classifiers, which uses non-repeated sampling to generate multiple training subsets and runs MOGP multiple times on these training subsets to construct ensembles. Experiments on ten datasets show that our MOGP-based classifier construction method can achieve better classification performance than single-objective GP classifier construction methods, and our bagging-based ensemble classifier construction methods can further improve the classification performance compared to only using MOGP. Comparisons with six state-of-the-art GP classifier construction methods and six traditional machine learning algorithms show that our proposed approach can achieve significantly better classification performance in most cases.},
  archive      = {J_MECO},
  author       = {Zheng, Yang and Zhang, Fan and Gao, Xiaoying and Ma, Jianbin},
  doi          = {10.1007/s12293-025-00444-8},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Memet. Comput.},
  title        = {Bagging-based ensemble classifiers using multi-objective genetic programming},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multifactorial memetic algorithm with adaptive auxiliary
tasks for service migration optimization in mobile edge computing.
<em>MECO</em>, <em>17</em>(2), 1–23. (<a
href="https://doi.org/10.1007/s12293-025-00448-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In high-speed mobile networks, mobile edge computing is tasked with service migration optimization, i.e., assigning mobile users to the right servers to minimize the response time. Service migration optimization is a complex problem posing significant challenges to conventional optimization methods. To tackle this problem, we develop a multifactorial memetic algorithm with adaptive auxiliary tasks or MFMA-AAT for short. MFMA-AAT solves the target service migration optimization problem and an adaptively selected auxiliary task simultaneously, where the auxiliary task is a simplified version of the target problem to guide the search towards promising regions faster via knowledge transfer. Multiple auxiliary tasks are pre-constructed based on the distribution of the mobile users and the one with the best improvement at each generation is selected for knowledge transfer. A community detection-based memetic operator is also introduced to accelerate the local convergence of the proposed algorithm. Experimental results on test problems demonstrate that MFMA-AAT is more efficient than traditional service migration approaches and other state-of-the-art multifactorial evolutionary algorithms.},
  archive      = {J_MECO},
  author       = {Li, Guo and Liu, Zhaobo and Liu, Ling and Zhu, Zexuan},
  doi          = {10.1007/s12293-025-00448-4},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Memet. Comput.},
  title        = {Multifactorial memetic algorithm with adaptive auxiliary tasks for service migration optimization in mobile edge computing},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving multi-objective energy-efficient flexible job shop
problems by a dual-level NSGA-II algorithm. <em>MECO</em>,
<em>17</em>(2), 1–29. (<a
href="https://doi.org/10.1007/s12293-025-00449-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incorporating energy consumption into optimization has attracted increasing attention in both academia and industry. Nevertheless, the integration of green, flexible, and dynamic manufacturing in literature remains underexplored. To this end, we focus on a dynamic flexible job shop scheduling problem (dFJSP) relevant to aerospace structural components. The following challenging issues are considered, such as processing route flexibility, limited machine and tool resources, transportation time, setup time, new job arrivals, machine breakdowns, and various machine processing speeds. To address this complex problem, a dual-level multi-objective algorithm based on the nondominated sorting genetic algorithm II (hereafter called DLNSGAII) is developed. The first level incorporates a dynamic diffusion-based strategy (D-DBS), which aims to balance exploration and exploitation effectively. This is achieved by quickly identifying high-quality solutions and discarding inferior ones while also ensuring ample computational resources allocated for exploration to avoid convergence on local optima. At the second level, a static convergence-based search strategy (S-CBS) is conducted to allocate resources according to the potential of solutions to achieve faster convergence. Additionally, to tackle the disruptions, two sets of rescheduling mechanisms have been designed: one includes five strategies for integrating new job arrivals, and another encompasses two strategies for responding to machine breakdowns. Furthermore, to enhance the search capabilities toward different objectives, two critical-path-based neighborhood structures have been incorporated. Utilizing hypervolume (HV) and inverted generational distance (IGD) as evaluation metrics, a comparative analysis of algorithmic performance was conducted. Among the 35 experiments, DLNSGAII exhibited superiority in 88.57% and 63% of the total experiments based on the HV and IGD metrics, respectively, emphasizing its advantages in terms of convergence and generalizability.},
  archive      = {J_MECO},
  author       = {Li, Junqing and Zhang, Weimeng and Li, Jiake},
  doi          = {10.1007/s12293-025-00449-3},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1-29},
  shortjournal = {Memet. Comput.},
  title        = {Solving multi-objective energy-efficient flexible job shop problems by a dual-level NSGA-II algorithm},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage memetic algorithm for green flexible job shop
scheduling problem considering machine deterioration and maintenance.
<em>MECO</em>, <em>17</em>(2), 1–33. (<a
href="https://doi.org/10.1007/s12293-025-00450-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The green flexible job shop scheduling problem (GFJSP) has received widespread attention in the context of Industry 5.0. However, the often-overlooked machine deterioration and maintenance during production result in a gap between scheduling plans and their practical applications. This study develops a model for green flexible job shop scheduling that considers machine deterioration and maintenance (GFJSP-DM) and proposes an enhanced two-stage memetic algorithm (ETMA) for its resolution. In the exploration stage, a heuristic hybrid initialization strategy is employed to generate diverse, high-quality individuals; in addition, a potential solution selection strategy aids the model-driven variable neighborhood local search to conduct a more detailed and effective exploration of the objective space. During the optimization stage, the algorithm presents a right-shift energy-saving strategy, designed based on inverse decoding, to evaluate four scenarios of delayed processing, further reducing the total energy consumption of the scheduling plans. Finally, extensive experimental results on test instances demonstrate that ETMA can effectively solve the GFJSP-DM problem.},
  archive      = {J_MECO},
  author       = {Zhu, Guoqiang and Liu, Jianfeng and Gong, Wenyin},
  doi          = {10.1007/s12293-025-00450-w},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1-33},
  shortjournal = {Memet. Comput.},
  title        = {Two-stage memetic algorithm for green flexible job shop scheduling problem considering machine deterioration and maintenance},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bi-objective influence maximization with consideration of
node burden. <em>MECO</em>, <em>17</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s12293-025-00452-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximization of influence seeks to identify a set of nodes with the greatest influence within a network. While influence has been the primary focus, the burden of nodes defined as their capacity to serve influenced nodes, such as the storage capacity in device-to-device networks has been overlooked in the literature. In this paper, we introduce a novel bi-objective influence maximization problem, termed Influence Maximization with Burden, which aims to simultaneously maximize the influence of seed nodes and minimize the variance in the burden of these nodes. We provide both intuitive and empirical evidence to support the feasibility and necessity of this problem. We provide both intuitive and empirical evidence to support the feasibility and necessity of this problem. Furthermore, we develop two algorithms to solve the proposed problem. The first is a fast, suboptimal algorithm utilizing the reverse reachable sampling method. The second is a memetic algorithm featuring a novel meme operator designed to identify promising nodes. Experimental results on both synthetic and real-world networks demonstrate that our proposed algorithms outperform existing methods in terms of effectiveness and efficiency. Our code is available on GitHub: https://github.com/fmyzckj.},
  archive      = {J_MECO},
  author       = {Feng, Mingyang and Zhao, Qi and He, Shan and Shi, Yuhui},
  doi          = {10.1007/s12293-025-00452-8},
  journal      = {Memetic Computing},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Memet. Comput.},
  title        = {Bi-objective influence maximization with consideration of node burden},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ml---13">ML - 13</h2>
<ul>
<li><details>
<summary>
(2025). Minimum discrepancy principle strategy for choosing k in
k-NN regression. <em>ML</em>, <em>114</em>(5), 1–33. (<a
href="https://doi.org/10.1007/s10994-024-06645-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel data-driven strategy to choose the hyperparameter k in the k-NN regression estimator without using any hold-out data. We treat the problem of choosing the hyperparameter as an iterative procedure (over k) and propose using an easily implemented in practice strategy based on the idea of early stopping and the minimum discrepancy principle. This model selection strategy is proven to be minimax-optimal, under the fixed-design assumption on covariates, over some smoothness function classes, for instance, the Lipschitz functions class on a bounded domain. The novel method often improves statistical performance on artificial and real-world data sets in comparison to other model selection strategies, such as the Hold-out method, 5–fold cross-validation, and AIC criterion. The novelty of the strategy comes from reducing the computational time of the model selection procedure while preserving the statistical (minimax) optimality of the resulting estimator. More precisely, given a sample of size n, if one should choose k among $$\left\{ 1, \ldots , n \right\}$$ , and $$\left\{ f^1, \ldots , f^n \right\}$$ are the estimators of the regression function, the minimum discrepancy principle requires calculation of a fraction of the estimators, while this is not the case for the generalized cross-validation, Akaike’s AIC criteria or Lepskii principle.},
  archive      = {J_ML},
  author       = {Averyanov, Yaroslav and Celisse, Alain},
  doi          = {10.1007/s10994-024-06645-5},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-33},
  shortjournal = {Mach. Learn.},
  title        = {Minimum discrepancy principle strategy for choosing k in k-NN regression},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical guarantees for domain adaptation with
hierarchical optimal transport. <em>ML</em>, <em>114</em>(5), 1–27. (<a
href="https://doi.org/10.1007/s10994-025-06749-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation arises as an important problem in statistical learning theory, arising when the data-generating processes differ between the training and test samples, respectively called source and target domains. Recent theoretical advances have demonstrated that the success of domain adaptation algorithms heavily relies on their ability to minimize the divergence between the probability distributions of the source and target domains. However, minimizing this divergence cannot be achieved independently of other key ingredients, such as the source risk or the combined error of the ideal joint hypothesis. The trade-off between these terms is often ensured through algorithmic solutions that remain implicit and are not directly reflected by the theoretical guarantees. To get to the bottom of this issue, we propose in this paper a new theoretical framework for domain adaptation through hierarchical optimal transport. This framework provides more explicit generalization bounds and enables us to consider the natural hierarchical organization of samples in both domains into structures, i.e. classes or clusters. Additionally, we provide a new divergence measure between the source and target domains called Hierarchical Wasserstein distance that indicates under mild assumptions, which structures need to be aligned to achieve successful adaptation.},
  archive      = {J_ML},
  author       = {El Hamri, Mourad and Bennani, Younès and Falih, Issam},
  doi          = {10.1007/s10994-025-06749-6},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-27},
  shortjournal = {Mach. Learn.},
  title        = {Theoretical guarantees for domain adaptation with hierarchical optimal transport},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic instance dependent label refinement for noisy
label learning. <em>ML</em>, <em>114</em>(5), 1–20. (<a
href="https://doi.org/10.1007/s10994-024-06668-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label refinement methods are designed to improve the quality of training labels by incorporating model predictions into the original training labels. By adjusting the combination coefficient of the noisy label, the impact of noise is reduced, which in turn makes the training process more robust. However, previous label refinement methods are unable to model instance-dependent noise, which is the most realistic type of noise. To address this limitation, we propose a simple approach, probabilistic instance-dependent label refinement (referred to as $$\pi$$ -LR). Inspired by the fact that humans are more likely to make mistakes when annotating confusing instances, we propose to estimate the probability of whether a sample is confusing, which can be useful for modeling noise generation. Our approach exploits this concept by assigning a confusing probability $$\eta _i$$ to each instance $$\varvec{x}_i$$ from a probabilistic perspective. This provides a clear understanding of how instance-dependent noise affects true labels. Empirical evaluations show that $$\pi$$ -LR improves the robustness of the model in the presence of label noise and outperforms all compared methods on both realistic and synthetic label noise, while maintaining high efficiency in time and space.},
  archive      = {J_ML},
  author       = {He, Hao-Yuan and Liu, Yu and Liu, Ren-Biao and Xie, Zheng and Li, Ming},
  doi          = {10.1007/s10994-024-06668-y},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-20},
  shortjournal = {Mach. Learn.},
  title        = {Probabilistic instance dependent label refinement for noisy label learning},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gender disentangled representation learning in neural
rankers. <em>ML</em>, <em>114</em>(5), 1–33. (<a
href="https://doi.org/10.1007/s10994-024-06664-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have demonstrated that while neural ranking methods excel in retrieval effectiveness, they also tend to amplify stereotypical biases, especially those related to gender. Current mitigation strategies often focus on adjusting training methods, like adversarial techniques or data balancing, but typically overlook explicit consideration of gender as an attribute. In this paper, we introduce a systematic approach that treats gender as a distinct component within neural ranker representations. Our neural disentanglement method separates content semantics from gender information, enabling the neural ranker to evaluate document relevance based on content alone, without the interference of gender-related information during retrieval. Our extensive experiments demonstrate that: (1) our disentanglement approach matches the effectiveness of baseline models and offers more consistent performance across queries of different gender affiliations; (2) isolating gender within the representations allows the neural ranker to produce an unbiased list of documents, not favoring any specific gender; and (3) the disentangled gender component effectively and concisely captures gender information independently from the semantic content.},
  archive      = {J_ML},
  author       = {Seyedsalehi, Shirin and Salamat, Sara and Arabzadeh, Negar and Ebrahimi, Sajad and Zihayat, Morteza and Bagheri, Ebrahim},
  doi          = {10.1007/s10994-024-06664-2},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-33},
  shortjournal = {Mach. Learn.},
  title        = {Gender disentangled representation learning in neural rankers},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Conformal load prediction with transductive
graph autoencoders. <em>ML</em>, <em>114</em>(5), 1. (<a
href="https://doi.org/10.1007/s10994-025-06762-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ML},
  author       = {Luo, Rui and Colombo, Nicolo},
  doi          = {10.1007/s10994-025-06762-9},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1},
  shortjournal = {Mach. Learn.},
  title        = {Correction to: Conformal load prediction with transductive graph autoencoders},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced route planning with calibrated uncertainty set.
<em>ML</em>, <em>114</em>(5), 1–16. (<a
href="https://doi.org/10.1007/s10994-024-06697-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the application of probabilistic prediction methodologies in route planning within a road network context. Specifically, we introduce the Conformalized Quantile Regression for Graph Autoencoders (CQR-GAE), which leverages the conformal prediction technique to offer a coverage guarantee, thus improving the reliability and robustness of our predictions. By incorporating uncertainty sets derived from CQR-GAE, we substantially improve the decision-making process in route planning under a robust optimization framework. We demonstrate the effectiveness of our approach by applying the CQR-GAE model to a real-world traffic scenario. The results indicate that our model significantly outperforms baseline methods, offering a promising avenue for advancing intelligent transportation systems.},
  archive      = {J_ML},
  author       = {Tang, Lingxuan and Luo, Rui and Zhou, Zhixin and Colombo, Nicolo},
  doi          = {10.1007/s10994-024-06697-7},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-16},
  shortjournal = {Mach. Learn.},
  title        = {Enhanced route planning with calibrated uncertainty set},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online dimensionality reduction through stacked
generalization of spectral methods with deep networks. <em>ML</em>,
<em>114</em>(5), 1–40. (<a
href="https://doi.org/10.1007/s10994-024-06715-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing large volumes of high-dimensional data poses significant challenges. Dimensionality reduction aims to reveal the most prominent properties of data by embedding them into a low-dimensional representation. Spectral dimensionality reduction methods using kernel matrices have been proven to yield optimal results. Online versions of those methods are desirable to incrementally project new data without recomputing the whole embedding from the complete dataset. In addition, integrating different spectral methods may have a synergistic effect. This paper presents an online dimensionality reduction method based on deep neural networks that integrates embeddings optimized by statistical approximation of neighborhoods and induced by different spectral methods through stacking ensemble learning. In particular, the proposed method first applies a self-supervised stage in order to train a set of deep encoders based on the embeddings induced by different spectral methods applied to a given input dataset. Those basis encoders are optimized and then integrated through a metamodel constituted by a fully connected network. A supervised and an unsupervised approach have been designed depending on whether the final aim is to enforce topological preservation or cluster induction. The proposed method has been experimentally validated on well-known image datasets and compared to some of the most relevant dimensionality reduction techniques by using widely-used quality measures.},
  archive      = {J_ML},
  author       = {Alvarado-Pérez, Juan Carlos and Garcia, Miguel Angel and Puig, Domènec},
  doi          = {10.1007/s10994-024-06715-8},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-40},
  shortjournal = {Mach. Learn.},
  title        = {Online dimensionality reduction through stacked generalization of spectral methods with deep networks},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural RELAGGS. <em>ML</em>, <em>114</em>(5), 1–26. (<a
href="https://doi.org/10.1007/s10994-025-06753-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-relational databases are the basis of most consolidated data collections in science and industry today. Most learning and mining algorithms, however, require data to be represented in a propositional form. While there is a variety of specialized machine learning algorithms that can operate directly on multi-relational data sets, propositionalization algorithms transform multi-relational databases into propositional data sets, thereby allowing the application of traditional machine learning and data mining algorithms without their modification. One prominent propositionalization algorithm is RELAGGS by Krogel and Wrobel, which transforms the data by nested aggregations. We propose a new neural network based algorithm in the spirit of RELAGGS that employs trainable composite aggregate functions instead of the static aggregate functions used in the original approach. In this way, we can jointly train the propositionalization with the prediction model, or, alternatively, use the learned aggegrations as embeddings in other algorithms. We demonstrate the increased predictive performance by comparing N-RELAGGS with RELAGGS and multiple other state-of-the-art algorithms.},
  archive      = {J_ML},
  author       = {Pensel, Lukas and Kramer, Stefan},
  doi          = {10.1007/s10994-025-06753-w},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-26},
  shortjournal = {Mach. Learn.},
  title        = {Neural RELAGGS},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DatRel: A noise-tolerant data relocation approach for
effective synthetic data generation in imbalanced classifiers.
<em>ML</em>, <em>114</em>(5), 1–45. (<a
href="https://doi.org/10.1007/s10994-025-06755-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most machine learning algorithms tend to bias towards the majority class when a dataset exhibits a skewed distribution in the class variable. This is called the class imbalance problem and is frequently encountered in real-life applications. One of the most prevalent methods for addressing class imbalance is data resampling, which generates or removes samples to balance the dataset. A well-known issue with oversampling is noise generation. Noise removal or hybrid resampling is used to deal with noise. However, these methods cause imbalance to re-emerge. In this study, a data relocation approach named DatRel is proposed to address the noise generation problem of oversampling without causing imbalance. The proposed approach utilizes pure and proper class cover catch digraphs (P-CCCD) to determine dominant points and cover areas for minority class. Then, new samples from oversampling are drawn to the dominant points until they are covered. This process ensures that newly generated samples never overlap with a negative sample. Imbalance is not affected since no sample is removed by undersampling. The proposed DatRel approach is applied to commonly used oversampling methods, namely SMOTE, ADASYN, and BLSMOTE. Moreover, the performance of the DatRel approach is compared to noise filtering methods such as Tomeklink, ENN, NEATER, and NearMiss after SMOTE. Several baseline classification algorithms are employed, and comparisons are made using various metrics. Results using 49 imbalanced datasets show that DatRel improves classifier performance in oversampling methods and demonstrates its value in comparison to other noise removal techniques according to AUC, BACC, F1, GMEAN, and MCC.},
  archive      = {J_ML},
  author       = {Sağlam, Fatih},
  doi          = {10.1007/s10994-025-06755-8},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-45},
  shortjournal = {Mach. Learn.},
  title        = {DatRel: A noise-tolerant data relocation approach for effective synthetic data generation in imbalanced classifiers},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Temporal ensemble of multiple patterns’ instances for
continuous prediction of events. <em>ML</em>, <em>114</em>(5), 1–42. (<a
href="https://doi.org/10.1007/s10994-025-06756-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-life data of various domains, such as traffic, meteorology, or healthcare data, events may have varying durations. Moreover, heterogeneous multivariate temporal data may consist of varying samplings, including regular sampling in different frequencies or irregular, as well as events data of different types, having fixed or varying duration. We propose to uniformly represent heterogeneous multivariate temporal data using symbolic time-intervals, from which a model that predicts an occurrence of events early can be learned. We introduce a novel use of time-interval-related patterns (TIRPs), in which patterns that end with an event of interest can be used to continuously estimate the event’s occurrence probability in real-time. Recently, we introduced a model that allows continuous prediction of the completion of a pattern, which is extended in this work, to also predict the expected completion time. This work focuses on predicting the probability and time occurrence of an event based on multiple different instances of patterns that end with the event, for which we propose and evaluate aggregation functions. A rigorous evaluation was conducted on four real-life datasets to assess the effectiveness of the proposed model and the aggregation functions. The proposed model performed better than the baseline models (ResNet, LSTM-FCN, ROCKET, and XGBoost) for all datasets.},
  archive      = {J_ML},
  author       = {Itzhak, Nevo and Jaroszewicz, Szymon and Moskovitch, Robert},
  doi          = {10.1007/s10994-025-06756-7},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-42},
  shortjournal = {Mach. Learn.},
  title        = {Temporal ensemble of multiple patterns’ instances for continuous prediction of events},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive optimization for prediction with missing data.
<em>ML</em>, <em>114</em>(5), 1–37. (<a
href="https://doi.org/10.1007/s10994-025-06757-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When training predictive models on data with missing entries, the most widely used and versatile approach is a pipeline technique where we first impute missing entries and then compute predictions. In this paper, we view prediction with missing data as a two-stage adaptive optimization problem and propose a new class of models, adaptive linear regression models, where the regression coefficients adapt to the set of observed features. We show that some adaptive linear regression models are equivalent to learning an imputation rule and a downstream linear regression model simultaneously instead of sequentially. We leverage this joint-impute-then-regress interpretation to generalize our framework to non-linear models. In settings where data is strongly not missing at random, our methods achieve a 2–10% improvement in out-of-sample accuracy.},
  archive      = {J_ML},
  author       = {Bertsimas, Dimitris and Delarue, Arthur and Pauphilet, Jean},
  doi          = {10.1007/s10994-025-06757-6},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-37},
  shortjournal = {Mach. Learn.},
  title        = {Adaptive optimization for prediction with missing data},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An unsupervised adversarial domain adaptation based on
variational auto-encoder. <em>ML</em>, <em>114</em>(5), 1–26. (<a
href="https://doi.org/10.1007/s10994-025-06760-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting a large amount of labeled data in machine learning is always challenging. Often, even with sufficient data, domain differences can cause a shift or bias in data distribution, affecting model performance during testing. Domain adaptation methods, especially adversarial techniques, are effective solutions for these challenges. The goal is to learn a classifier for an unlabeled target dataset using a labeled source dataset, enhancing resistance to domain shifts. However, existing methods sometimes struggle with adapting the joint feature distribution across domains, resulting in negative transfer. To address this, we propose a method that forms class-specific clusters to prevent negative transfer. This method is encapsulated in an unsupervised adversarial domain adaptation framework based on a variational auto-encoder. Our structure is designed to enhance invariant and discriminative feature representation. We process source and target data through a VAE to establish a smooth latent representation. In our method, source and target data are fed into a variational auto-encoder, which produces a smooth latent representation. The feature extractor then plays an adversarial minimax game with the discriminator to learn domain-invariant features, while the feature extractor is shared between the reconstructed source and reconstructed target data. In addition, we proposed a second structure in which the domain discriminator part of the prior structure is eliminated to demonstrate the influence of the variational auto-encoder in domain adaptation. On numerous unsupervised domain adaptation benchmarks, our results indicate that our proposed model outperforms or is comparable to state-of-the-art outcomes.},
  archive      = {J_ML},
  author       = {Hassan Pour Zonoozi, Mahta and Seydi, Vahid and Deypir, Mahmood},
  doi          = {10.1007/s10994-025-06760-x},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1-26},
  shortjournal = {Mach. Learn.},
  title        = {An unsupervised adversarial domain adaptation based on variational auto-encoder},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Nettop: A lightweight-network of
orthogonal-plane features for image recognition. <em>ML</em>,
<em>114</em>(5), 1. (<a
href="https://doi.org/10.1007/s10994-025-06765-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ML},
  author       = {Nguyen, Thanh Tuan and Nguyen, Thanh Phuong},
  doi          = {10.1007/s10994-025-06765-6},
  journal      = {Machine Learning},
  month        = {5},
  number       = {5},
  pages        = {1},
  shortjournal = {Mach. Learn.},
  title        = {Correction to: nettop: a lightweight-network of orthogonal-plane features for image recognition},
  volume       = {114},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="mp---30">MP - 30</h2>
<ul>
<li><details>
<summary>
(2025). Multiplicative auction algorithm for approximate maximum
weight bipartite matching. <em>MP</em>, <em>210</em>(1), 881–894. (<a
href="https://doi.org/10.1007/s10107-024-02066-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an auction algorithm using multiplicative instead of constant weight updates to compute a $$(1-\varepsilon )$$ -approximate maximum weight matching (MWM) in a bipartite graph with n vertices and m edges in time $$O(m\varepsilon ^{-1})$$ , beating the running time of the fastest known approximation algorithm of Duan and Pettie [JACM ’14] that runs in $$O(m\varepsilon ^{-1}\log \varepsilon ^{-1})$$ . Our algorithm is very simple and it can be extended to give a dynamic data structure that maintains a $$(1-\varepsilon )$$ -approximate maximum weight matching under (1) one-sided vertex deletions (with incident edges) and (2) one-sided vertex insertions (with incident edges sorted by weight) to the other side. The total time time used is $$O(m\varepsilon ^{-1})$$ , where m is the sum of the number of initially existing and inserted edges.},
  archive      = {J_MP},
  author       = {Zheng, Da Wei and Henzinger, Monika},
  doi          = {10.1007/s10107-024-02066-3},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {881-894},
  shortjournal = {Math. Program.},
  title        = {Multiplicative auction algorithm for approximate maximum weight bipartite matching},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast combinatorial algorithm for the bilevel knapsack
problem with interdiction constraints. <em>MP</em>, <em>210</em>(1),
847–879. (<a href="https://doi.org/10.1007/s10107-024-02133-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the bilevel knapsack problem with interdiction constraints, a fundamental bilevel integer programming problem which generalizes the 0–1 knapsack problem. In this problem, there are two knapsacks and n items. The objective is to select some items to pack into the first knapsack such that the maximum profit attainable from packing some of the remaining items into the second knapsack is minimized. We present a combinatorial branch-and-bound algorithm which outperforms the current state-of-the-art solution method in computational experiments for 99% of the instances reported in the literature. On many of the harder instances, our algorithm is orders of magnitude faster, which enabled it to solve 53 of the 72 previously unsolved instances. Our result relies fundamentally on a new dynamic programming algorithm which computes very strong lower bounds. This dynamic program solves a relaxation of the problem from bilevel to 2n-level where the items are processed in an online fashion. The relaxation is easier to solve but approximates the original problem surprisingly well in practice. We believe that this same technique may be useful for other interdiction problems.},
  archive      = {J_MP},
  author       = {Weninger, Noah and Fukasawa, Ricardo},
  doi          = {10.1007/s10107-024-02133-9},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {847-879},
  shortjournal = {Math. Program.},
  title        = {A fast combinatorial algorithm for the bilevel knapsack problem with interdiction constraints},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constant-competitiveness for random assignment matroid
secretary without knowing the matroid. <em>MP</em>, <em>210</em>(1),
815–846. (<a href="https://doi.org/10.1007/s10107-024-02177-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Matroid Secretary Conjecture is a notorious open problem in online optimization. It claims the existence of an O(1)-competitive algorithm for the Matroid Secretary Problem (MSP). Here, the elements of a weighted matroid appear one-by-one, revealing their weight at appearance, and the task is to select elements online with the goal to get an independent set of largest possible weight. O(1)-competitive MSP algorithms have so far only been obtained for restricted matroid classes and for MSP variations, including Random-Assignment MSP (RA-MSP), where an adversary fixes a number of weights equal to the ground set size of the matroid, which then get assigned randomly to the elements of the ground set. Unfortunately, these approaches heavily rely on knowing the full matroid upfront. This is an arguably undesirable requirement, and there are good reasons to believe that an approach towards resolving the MSP Conjecture should not rely on it. Thus, both Soto (SIAM Journal on Computing 42(1): 178-211, 2013.) and Oveis Gharan and Vondrák (Algorithmica 67(4): 472-497, 2013.) raised as an open question whether RA-MSP admits an O(1)-competitive algorithm even without knowing the matroid upfront. In this work, we answer this question affirmatively. Our result makes RA-MSP the first well-known MSP variant with an O(1)-competitive algorithm that does not need to know the underlying matroid upfront and without any restriction on the underlying matroid. Our approach is based on first approximately learning the rank-density curve of the matroid, which we then exploit algorithmically.},
  archive      = {J_MP},
  author       = {Santiago, Richard and Sergeev, Ivan and Zenklusen, Rico},
  doi          = {10.1007/s10107-024-02177-x},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {815-846},
  shortjournal = {Math. Program.},
  title        = {Constant-competitiveness for random assignment matroid secretary without knowing the matroid},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cut-sufficient directed 2-commodity multiflow topologies.
<em>MP</em>, <em>210</em>(1), 793–814. (<a
href="https://doi.org/10.1007/s10107-025-02195-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multicommodity network flows, a supply–demand graph pair (G, H) (called a multiflow topology) is cut-sufficient if, for all capacity and demand weights, the cut condition is enough to guarantee the existence of a feasible multiflow. We characterize cut-sufficiency for two classes of directed 2-commodity flows: roundtrip demands, where H is a 2-cycle, and 2-path demands, where H is a directed path of length two. We then extend these characterizations to some larger demand graphs, namely directed stars and directed triangles. To obtain such characterizations, we introduce a theory of relevant minors. Unlike the undirected setting, for directed graphs the cut-sufficient topologies are not minor-closed. They are however relevant-minor-closed. A single forbidden relevant minor characterizes roundtrip cut-sufficiency, and two suffice for the other classes. We also provide a partial characterization in the case of two independent demands (2-matching demands), showing that one of two relevant minors exists if the weights that break cut-sufficiency have unit demand values. As an application of our results, we show that recognizing cut-sufficiency for directed multiflow topologies is co-NP-hard, even for roundtrip demands. This is in contrast to undirected 2-commodity flows, for which topologies are always cut-sufficient.},
  archive      = {J_MP},
  author       = {Poremba, Joseph and Shepherd, F. Bruce},
  doi          = {10.1007/s10107-025-02195-3},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {793-814},
  shortjournal = {Math. Program.},
  title        = {Cut-sufficient directed 2-commodity multiflow topologies},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards an optimal contention resolution scheme for
matchings. <em>MP</em>, <em>210</em>(1), 761–792. (<a
href="https://doi.org/10.1007/s10107-024-02178-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study contention resolution schemes for matchings. Given a fractional matching x and a random set R(x) where each edge e appears independently with probability $$x_e$$ , we want to select a matching $$M \subseteq R(x)$$ such that $$\Pr [e \in M \mid e \in R(x)] \ge c$$ , for c as large as possible. We call such a selection method a c-balanced contention resolution scheme. Our main results are (i) an asymptotically optimal $$\simeq 0.544$$ -balanced contention resolution scheme for general matchings when $$\Vert x\Vert _\infty \rightarrow 0$$ , and (ii) a 0.509-balanced contention resolution scheme for bipartite matchings (without any restriction on x). To the best of our knowledge, this result establishes for the first time, in any natural relaxation of a combinatorial optimization problem, a separation between (i) offline and random order online contention resolution schemes, and (ii) monotone and non-monotone contention resolution schemes.},
  archive      = {J_MP},
  author       = {Nuti, Pranav and Vondrák, Jan},
  doi          = {10.1007/s10107-024-02178-w},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {761-792},
  shortjournal = {Math. Program.},
  title        = {Towards an optimal contention resolution scheme for matchings},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advances on strictly <span
class="math display"><em>Δ</em></span> -modular IPs. <em>MP</em>,
<em>210</em>(1), 731–760. (<a
href="https://doi.org/10.1007/s10107-024-02148-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There has been significant work recently on integer programs (IPs) $$\min \{c^\top x :Ax\le b,\,x\in \mathbb {Z}^n\}$$ with a constraint marix A with bounded subdeterminants. This is motivated by a well-known conjecture claiming that, for any constant $$\Delta \in \mathbb {Z}_{&gt;0}$$ , $$\Delta $$ -modular IPs are efficiently solvable, which are IPs where the constraint matrix $$A\in \mathbb {Z}^{m\times n}$$ has full column rank and all $$n\times n$$ minors of A are within $$\{-\Delta , \dots , \Delta \}$$ . Previous progress on this question, in particular for $$\Delta =2$$ , relies on algorithms that solve an important special case, namely strictly $$\Delta $$ -modular IPs, which further restrict the $$n\times n$$ minors of A to be within $$\{-\Delta , 0, \Delta \}$$ . Even for $$\Delta =2$$ , such problems include well-known combinatorial optimization problems like the minimum odd/even cut problem. The conjecture remains open even for strictly $$\Delta $$ -modular IPs. Prior advances were restricted to prime $$\Delta $$ , which allows for employing strong number-theoretic results. In this work, we make first progress beyond the prime case by presenting techniques not relying on such strong number-theoretic prime results. In particular, our approach implies that there is a randomized algorithm to check feasibility of strictly $$\Delta $$ -modular IPs in strongly polynomial time if $$\Delta \le 4$$ .},
  archive      = {J_MP},
  author       = {Nägele, Martin and Nöbel, Christian and Santiago, Richard and Zenklusen, Rico},
  doi          = {10.1007/s10107-024-02148-2},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {731-760},
  shortjournal = {Math. Program.},
  title        = {Advances on strictly $$\Delta $$ -modular IPs},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting the polyhedral geometry of stochastic linear
bilevel programming. <em>MP</em>, <em>210</em>(1), 695–730. (<a
href="https://doi.org/10.1007/s10107-024-02097-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study linear bilevel programming problems whose lower-level objective is given by a random cost vector with known distribution. We consider the case where this distribution is nonatomic, allowing to reformulate the problem of the leader using the Bayesian approach in the sense of Salas and Svensson (SIAM J Optim 33(3):2311–2340, 2023), with a decision-dependent distribution that concentrates on the vertices of the feasible set of the follower’s problem. We call this a vertex-supported belief. We prove that this formulation is piecewise affine over the so-called chamber complex of the feasible set of the high-point relaxation. We propose two algorithmic approaches to solve general problems enjoying this last property. The first one is based on enumerating the vertices of the chamber complex. This approach is not scalable, but we present it as a computational baseline and for its theoretical interest. The second one is a Monte-Carlo approximation scheme based on the fact that randomly drawn points of the domain lie, with probability 1, in the interior of full-dimensional chambers, where the problem (restricted to this chamber) can be reduced to a linear program. Finally, we evaluate these methods through computational experiments showing both approaches’ advantages and challenges.},
  archive      = {J_MP},
  author       = {Muñoz, Gonzalo and Salas, David and Svensson, Anton},
  doi          = {10.1007/s10107-024-02097-w},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {695-730},
  shortjournal = {Math. Program.},
  title        = {Exploiting the polyhedral geometry of stochastic linear bilevel programming},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compressing branch-and-bound trees. <em>MP</em>,
<em>210</em>(1), 669–694. (<a
href="https://doi.org/10.1007/s10107-024-02080-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A branch-and-bound (BB) tree certifies a dual bound on the value of an integer program. In this work, we introduce the tree compression problem (TCP): Given a BB tree T that certifies a dual bound, can we obtain a smaller tree with the same (or stronger) bound by either (1) applying a different disjunction at some node in T or (2) removing leaves from T? We believe such post-hoc analysis of BB trees may assist in identifying helpful general disjunctions in BB algorithms. We initiate our study by considering computational complexity and limitations of TCP. We then conduct experiments to evaluate the compressibility of realistic branch-and-bound trees generated by commonly-used branching strategies, using both an exact and a heuristic compression algorithm.},
  archive      = {J_MP},
  author       = {Muñoz, Gonzalo and Paat, Joseph and Xavier, Álinson S.},
  doi          = {10.1007/s10107-024-02080-5},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {669-694},
  shortjournal = {Math. Program.},
  title        = {Compressing branch-and-bound trees},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A characterization of maximal homogeneous-quadratic-free
sets. <em>MP</em>, <em>210</em>(1), 641–668. (<a
href="https://doi.org/10.1007/s10107-024-02092-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intersection cut framework was introduced by Balas in 1971 as a method for generating cutting planes in integer optimization. In this framework, one uses a full-dimensional convex S-free set, where S is the feasible region of the integer program, to derive a cut separating S from a non-integral vertex of a linear relaxation of S. Among all S-free sets, it is the inclusion-wise maximal ones that yield the strongest cuts. Recently, this framework has been extended beyond the integer case in order to obtain cutting planes in non-linear settings. In this work, we consider the specific setting when S is defined by a homogeneous quadratic inequality. In this ‘quadratic-free’ setting, every function $$\Gamma : D^m \rightarrow D^n$$ , where $$D^k$$ is the unit sphere in $$\mathbb {R}^k$$ , generates a representation of a quadratic-free set. While not every $$\Gamma $$ generates a maximal quadratic free set, it is the case that every full-dimensional maximal quadratic free set is generated by some $$\Gamma $$ . Our main result shows that the corresponding quadratic-free set is full-dimensional and maximal if and only if $$\Gamma $$ is non-expansive and satisfies a technical condition. This result yields a broader class of maximal S-free sets than previously known. Our result stems from a new characterization of maximal S-free sets (for general S beyond the quadratic setting) based on sequences that ‘expose’ inequalities defining the S-free set.},
  archive      = {J_MP},
  author       = {Muñoz, Gonzalo and Paat, Joseph and Serrano, Felipe},
  doi          = {10.1007/s10107-024-02092-1},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {641-668},
  shortjournal = {Math. Program.},
  title        = {A characterization of maximal homogeneous-quadratic-free sets},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition of probability marginals for security games in
max-flow/min-cut systems. <em>MP</em>, <em>210</em>(1), 611–640. (<a
href="https://doi.org/10.1007/s10107-024-02144-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a set system $$(E, \mathcal {P})$$ with $$\rho \in [0, 1]^E$$ and $$\pi \in [0,1]^{\mathcal {P}}$$ , our goal is to find a probability distribution for a random set $$S \subseteq E$$ such that $$\textbf{Pr}\left[ e \in S\right] = \rho _e$$ for all $$e \in E$$ and $$\textbf{Pr}\left[ P \cap S \ne \emptyset \right] \ge \pi _P$$ for all $$P \in \mathcal {P}$$ . We extend the results of Dahan, Amin, and Jaillet [6] who studied this problem motivated by a security game in a directed acyclic graph (DAG). We focus on the setting where $$\pi $$ is of the affine form $$\pi _P = 1 - \sum _{e \in P} \mu _e$$ for $$\mu \in [0, 1]^E$$ . A necessary condition for the existence of the desired distribution is that $$\sum _{e \in P} \rho _e \ge \pi _P$$ for all $$P \in \mathcal {P}$$ . We show that this condition is sufficient if and only if $$\mathcal {P}$$ has the weak max-flow/min-cut property. We further provide an efficient combinatorial algorithm for computing the corresponding distribution in the special case where $$(E, \mathcal {P})$$ is an abstract network. As a consequence, equilibria for the security game in [6] can be efficiently computed in a wide variety of settings (including arbitrary digraphs). As a subroutine of our algorithm, we provide a combinatorial algorithm for computing shortest paths in abstract networks, partially answering an open question by McCormick [20]. We further show that a conservation law proposed in [6] for the requirement vector $$\pi $$ in DAGs can be reduced to the setting of affine requirements described above.},
  archive      = {J_MP},
  author       = {Matuschke, Jannik},
  doi          = {10.1007/s10107-024-02144-6},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {611-640},
  shortjournal = {Math. Program.},
  title        = {Decomposition of probability marginals for security games in max-flow/min-cut systems},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal general factor problem and jump system intersection.
<em>MP</em>, <em>210</em>(1), 591–610. (<a
href="https://doi.org/10.1007/s10107-024-02098-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the optimal general factor problem, given a graph $$G=(V, E)$$ and a set $$B(v) \subseteq {\mathbb {Z}}$$ of integers for each $$v \in V$$ , we seek for an edge subset F of maximum cardinality subject to $$d_F(v) \in B(v)$$ for $$v \in V$$ , where $$d_F(v)$$ denotes the number of edges in F incident to v. A recent crucial work by Dudycz and Paluch shows that this problem can be solved in polynomial time if each B(v) has no gap of length more than one. While their algorithm is very simple, its correctness proof is quite complicated. In this paper, we formulate the optimal general factor problem as the jump system intersection, and reveal when the algorithm by Dudycz and Paluch can be applied to this abstract form of the problem. By using this abstraction, we give another correctness proof of the algorithm, which is simpler than the original one. We also extend our result to the valuated case.},
  archive      = {J_MP},
  author       = {Kobayashi, Yusuke},
  doi          = {10.1007/s10107-024-02098-9},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {591-610},
  shortjournal = {Math. Program.},
  title        = {Optimal general factor problem and jump system intersection},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monoidal strengthening of simple <span
class="math display">𝒱</span> -polyhedral disjunctive cuts. <em>MP</em>,
<em>210</em>(1), 567–590. (<a
href="https://doi.org/10.1007/s10107-024-02185-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disjunctive cutting planes can tighten a relaxation of a mixed-integer linear program. Traditionally, such cuts are obtained by solving a higher-dimensional linear program, whose additional variables cause the procedure to be computationally prohibitive. Adopting a $$\mathcal {V}$$ -polyhedral perspective is a practical alternative that enables the separation of disjunctive cuts via a linear program with only as many variables as the original problem. The drawback is that the classical approach of monoidal strengthening cannot be directly employed without the values of the extra variables appearing in the extended formulation, which constitute a certificate of validity of the cut. We derive how to compute this certificate from a solution to the linear program generating $$\mathcal {V}$$ -polyhedral disjunctive cuts. We then present computational experiments with monoidal strengthening of cuts from disjunctions with as many as 64 terms. Some instances are dramatically impacted, with strengthening increasing the gap closed by the cuts from 0 to 100%. However, for larger disjunctions, monoidal strengthening appears to be less effective, for which we identify a potential cause. Lastly, the certificates of validity also enable us to verify which disjunctive cuts are equivalent to intersection cuts, which happens increasingly rarely for larger disjunctions.},
  archive      = {J_MP},
  author       = {Kazachkov, Aleksandr M. and Balas, Egon},
  doi          = {10.1007/s10107-024-02185-x},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {567-590},
  shortjournal = {Math. Program.},
  title        = {Monoidal strengthening of simple $$\mathcal {V}$$ -polyhedral disjunctive cuts},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The polyhedral geometry of truthful auctions. <em>MP</em>,
<em>210</em>(1), 539–566. (<a
href="https://doi.org/10.1007/s10107-024-02168-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The difference set of an outcome in an auction is the set of types that the auction mechanism maps to the outcome. We give a complete characterization of the geometry of the difference sets that can appear for a dominant strategy incentive compatible multi-unit auction showing that they correspond to regular subdivisions of the unit cube. Similarly, we describe the geometry for affine maximizers for n players and m items, showing that they correspond to regular subdivisions of the m-fold product of $$(n-1)$$ -dimensional simplices. These observations are then used to construct mechanisms that are robust in the sense that the sets of items allocated to the players change only slightly when the players’ reported types are changed slightly.},
  archive      = {J_MP},
  author       = {Joswig, Michael and Klimm, Max and Spitz, Sylvain},
  doi          = {10.1007/s10107-024-02168-y},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {539-566},
  shortjournal = {Math. Program.},
  title        = {The polyhedral geometry of truthful auctions},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A <span class="math display">$$\frac{4}{3}$$</span>
-approximation algorithm for half-integral cycle cut instances of the
TSP. <em>MP</em>, <em>210</em>(1), 511–538. (<a
href="https://doi.org/10.1007/s10107-025-02193-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long-standing conjecture for the traveling salesman problem (TSP) states that the integrality gap of the standard linear programming relaxation of the TSP (sometimes called the Subtour LP or the Held-Karp bound) is at most 4/3 for symmetric instances of the TSP obeying the triangle inequality; that is, the cost of an optimal tour is at most 4/3 times the value of the value of the corresponding linear program. There is a variety of evidence in support of the conjecture (see, for instance, Goemans in Math Program 69:335–349, 1995; Benoit and Boyd in Math Oper Res 33:921–931, 2008). It has long been known that the integrality gap is at most 3/2 (Wolsey in Math Program Study 13:121–134, 1980; Shmoys and Williamson in Inf Process Lett 35:281–285, 1990). Despite significant efforts by the community, the conjecture remains open. In this paper we consider the half-integral case, in which a feasible solution to the LP has solution values in $$\{0, 1/2, 1\}$$ . Such instances have been conjectured to be the most difficult instances for the overall four-thirds conjecture (Schalekamp et al. in Math Oper Res 39(2):403–417, 2014). Karlin et al. (in: Proceedings of the 52nd Annual ACM Symposium on the the Theory of Computing, ACM, New York, 2020), in a breakthrough result, were able to show that in the half-integral case, the integrality gap is at most 1.49993; Gupta et al. (in: Integer Programming and Combinatorial Optimization. Lecture Notes in Computer Science, 2022. https://arxiv.org/abs/2111.09290 ) showed a slight improvement of this result to 1.4983. Additionally, this result led to the first significant progress on the overall conjecture in decades; the same authors showed the integrality gap of the Subtour LP is at most $$1.5-\epsilon $$ for some $$\epsilon &gt;10^{-36}$$ Karlin et al. in 2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS). https://doi.org/10.1109/FOCS54457.2022.00084 . With the improvements on the 3/2 bound remaining very incremental, even in the half-integral case, we turn the question around and look for a large class of half-integral instances for which we can prove that the 4/3 conjecture is correct, preferably one containing the known worst-case instances. In Karlin et al.’s work on the half-integral case, they perform induction on a hierarchy of critical tight sets in the support graph of the LP solution, in which some of the sets correspond to cycle cuts and the others to degree cuts. Here we show that if all the sets in the hierarchy correspond to cycle cuts, then we can find a distribution of tours whose expected cost is at most 4/3 times the value of the half-integral LP solution; sampling from the distribution gives us a randomized 4/3-approximation algorithm. We note that two important bad cases with an integrality gap of 4/3 have a half-integral LP solution in which all the critical tight sets in the hierarchy are cycle cuts; thus our result is tight. Our overall approach is novel. Most recent work has focused on showing that some variation of the Christofides-Serdyukov algorithm (Christofides in “Worst case analysis of a new heuristic for the traveling salesman problem”. Report 388, Graduate School of Industrial Administration, Carnegie Mellon University, Pittsburgh, 1976; Serdyukov in Upravlyaemye Sistemy 17:76–79, 1978) that combines a randomly sampled spanning tree plus a T-join (or a matching) can be shown to give a bound better than 1.5. Here we show that for any point in a region of “patterns” of edges incident to each cycle cut, we can give a distribution of patterns connecting all the child cycle cuts such that the distribution of patterns for each child also falls in the region. This region gives rise to a distribution on Eulerian tours in which each edge in the support of the LP is used at most four-thirds of its LP value of the time, which then gives the result.},
  archive      = {J_MP},
  author       = {Jin, Billy and Klein, Nathan and Williamson, David P.},
  doi          = {10.1007/s10107-025-02193-5},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {511-538},
  shortjournal = {Math. Program.},
  title        = {A $$\frac{4}{3}$$ -approximation algorithm for half-integral cycle cut instances of the TSP},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competitive kill-and-restart and preemptive strategies for
non-clairvoyant scheduling. <em>MP</em>, <em>210</em>(1), 457–509. (<a
href="https://doi.org/10.1007/s10107-024-02118-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study kill-and-restart and preemptive strategies for the fundamental scheduling problem of minimizing the sum of weighted completion times on a single machine in the non-clairvoyant setting. First, we show a lower bound of 3 for any deterministic non-clairvoyant kill-and-restart strategy. Then, we give for any $$b &gt; 1$$ a tight analysis for the natural b-scaling kill-and-restart strategy as well as for a randomized variant of it. In particular, we show a competitive ratio of $$(1+3\sqrt{3})\approx 6.197$$ for the deterministic and of $$\approx 3.032$$ for the randomized strategy, by making use of the largest eigenvalue of a Toeplitz matrix. In addition, we show that the preemptive Weighted Shortest Elapsed Time First (WSETF) rule is 2-competitive when jobs are released online, matching the lower bound for the unit weight case with trivial release dates for any non-clairvoyant algorithm. Using this result as well as the competitiveness of round-robin for multiple machines, we prove performance guarantees smaller than 10 for adaptions of the b-scaling strategy to online release dates and unweighted jobs on identical parallel machines.},
  archive      = {J_MP},
  author       = {Jäger, Sven and Sagnol, Guillaume and Schmidt genannt Waldschmidt, Daniel and Warode, Philipp},
  doi          = {10.1007/s10107-024-02118-8},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {457-509},
  shortjournal = {Math. Program.},
  title        = {Competitive kill-and-restart and preemptive strategies for non-clairvoyant scheduling},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the correlation gap of matroids. <em>MP</em>,
<em>210</em>(1), 407–456. (<a
href="https://doi.org/10.1007/s10107-024-02116-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A set function can be extended to the unit cube in various ways; the correlation gap measures the ratio between two natural extensions. This quantity has been identified as the performance guarantee in a range of approximation algorithms and mechanism design settings. It is known that the correlation gap of a monotone submodular function is at least $$1-1/e$$ , and this is tight for simple matroid rank functions. We initiate a fine-grained study of the correlation gap of matroid rank functions. In particular, we present an improved lower bound on the correlation gap as parametrized by the rank and girth of the matroid. We also show that for any matroid, the correlation gap of its weighted rank function is minimized under uniform weights. Such improved lower bounds have direct applications for submodular maximization under matroid constraints, mechanism design, and contention resolution schemes.},
  archive      = {J_MP},
  author       = {Husić, Edin and Koh, Zhuan Khye and Loho, Georg and Végh, László A.},
  doi          = {10.1007/s10107-024-02116-w},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {407-456},
  shortjournal = {Math. Program.},
  title        = {On the correlation gap of matroids},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReLU neural networks of polynomial size for exact maximum
flow computation. <em>MP</em>, <em>210</em>(1), 377–406. (<a
href="https://doi.org/10.1007/s10107-024-02096-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the expressive power of artificial neural networks with rectified linear units. In order to study them as a model of real-valued computation, we introduce the concept of Max-Affine Arithmetic Programs and show equivalence between them and neural networks concerning natural complexity measures. We then use this result to show that two fundamental combinatorial optimization problems can be solved with polynomial-size neural networks. First, we show that for any undirected graph with n nodes, there is a neural network (with fixed weights and biases) of size $$\mathcal {O}(n^3)$$ that takes the edge weights as input and computes the value of a minimum spanning tree of the graph. Second, we show that for any directed graph with n nodes and m arcs, there is a neural network of size $$\mathcal {O}(m^2n^2)$$ that takes the arc capacities as input and computes a maximum flow. Our results imply that these two problems can be solved with strongly polynomial time algorithms that solely use affine transformations and maxima computations, but no comparison-based branchings.},
  archive      = {J_MP},
  author       = {Hertrich, Christoph and Sering, Leon},
  doi          = {10.1007/s10107-024-02096-x},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {377-406},
  shortjournal = {Math. Program.},
  title        = {ReLU neural networks of polynomial size for exact maximum flow computation},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing for strategy diversity in the design of video
games. <em>MP</em>, <em>210</em>(1), 335–376. (<a
href="https://doi.org/10.1007/s10107-024-02126-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of designing a linear program that has diverse solutions as the right-hand side varies. This problem arises in video game settings where designers aim to have players use different “weapons” or “tactics” as they progress. We model this design question as a choice over the constraint matrix A and cost vector c to maximize the number of possible supports of unique optimal solutions (what we call “loadouts”) of Linear Programs $$\max \{c^\top x \mid Ax \le b, x \ge 0\}$$ with nonnegative data considered over all resource vectors b. We provide an upper bound on the optimal number of loadouts and provide a family of constructions that have an asymptotically optimal number of loadouts. The upper bound is based on a connection between our problem and the study of triangulations of point sets arising from polyhedral combinatorics, and specifically the combinatorics of the cyclic polytope. Our asymptotically optimal construction also draws inspiration from the properties of the cyclic polytope.},
  archive      = {J_MP},
  author       = {Hanguir, Oussama and Ma, Will and Han, Jiangze and Ryan, Christopher Thomas},
  doi          = {10.1007/s10107-024-02126-8},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {335-376},
  shortjournal = {Math. Program.},
  title        = {Optimizing for strategy diversity in the design of video games},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stabilization of capacitated matching games. <em>MP</em>,
<em>210</em>(1), 313–334. (<a
href="https://doi.org/10.1007/s10107-024-02169-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An edge-weighted, vertex-capacitated graph $$G$$ is called stable if the value of a maximum-weight capacity-matching equals the value of a maximum-weight fractional capacity-matching. Stable graphs play a key role in characterizing the existence of stable solutions for popular combinatorial games that involve the structure of matchings in graphs, such as network bargaining games and cooperative matching games. The vertex-stabilizer problem asks to compute a minimum number of players to block (i.e., vertices of $$G$$ to remove) in order to ensure stability for such games. The problem has been shown to be solvable in polynomial-time, for unit-capacity graphs. This stays true also if we impose the restriction that the set of players to block must not intersect with a given specified maximum matching of $$G$$ . In this work, we investigate these algorithmic problems in the more general setting of arbitrary capacities. We show that the vertex-stabilizer problem with the additional restriction of avoiding a given maximum matching remains polynomial-time solvable. Differently, without this restriction, the vertex-stabilizer problem becomes NP-hard and even hard to approximate, in contrast to the unit-capacity case.},
  archive      = {J_MP},
  author       = {Gerstbrein, Matthew and Sanità, Laura and Verberk, Lucy},
  doi          = {10.1007/s10107-024-02169-x},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {313-334},
  shortjournal = {Math. Program.},
  title        = {Stabilization of capacitated matching games},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An update-and-stabilize framework for the minimum-norm-point
problem. <em>MP</em>, <em>210</em>(1), 281–311. (<a
href="https://doi.org/10.1007/s10107-024-02077-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the minimum-norm-point (MNP) problem over polyhedra, a well-studied problem that encompasses linear programming. We present a general algorithmic framework that combines two fundamental approaches for this problem: active set methods and first order methods. Our algorithm performs first order update steps, followed by iterations that aim to ‘stabilize’ the current iterate with additional projections, i.e., find a locally optimal solution whilst keeping the current tight inequalities. Such steps have been previously used in active set methods for the nonnegative least squares (NNLS) problem. We bound on the number of iterations polynomially in the dimension and in the associated circuit imbalance measure. In particular, the algorithm is strongly polynomial for network flow instances. Classical NNLS algorithms such as the Lawson–Hanson algorithm are special instantiations of our framework; as a consequence, we obtain convergence bounds for these algorithms. Our preliminary computational experiments show promising practical performance.},
  archive      = {J_MP},
  author       = {Fujishige, Satoru and Kitahara, Tomonari and Végh, László A.},
  doi          = {10.1007/s10107-024-02077-0},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {281-311},
  shortjournal = {Math. Program.},
  title        = {An update-and-stabilize framework for the minimum-norm-point problem},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Configuration balancing for stochastic requests.
<em>MP</em>, <em>210</em>(1), 243–279. (<a
href="https://doi.org/10.1007/s10107-024-02132-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The configuration balancing problem with stochastic requests generalizes well-studied resource allocation problems such as load balancing and virtual circuit routing. There are given m resources and n requests; each request has multiple possible configurations, each of which increases the load of each resource by some amount. The goal is to select one configuration for each request to minimize the makespan: the load of the most-loaded resource. In the stochastic setting, the amount by which a configuration increases the resource load is uncertain until the configuration is chosen, but we are given a probability distribution. We develop both offline and online algorithms for configuration balancing with stochastic requests. When the requests are known offline, we give a non-adaptive policy for configuration balancing with stochastic requests that $$O(\frac{\log m}{\log \log m})$$ -approximates the optimal adaptive policy, which matches a known lower bound for the special case of load balancing on identical machines. When requests arrive online in a list, we give a non-adaptive policy that is $$O(\log m)$$ competitive. Again, this result is asymptotically tight due to information-theoretic lower bounds for special cases (e.g., for load balancing on unrelated machines). Finally, we show how to leverage adaptivity in the special case of load balancing on related machines to obtain a constant-factor approximation offline and an $$O(\log \log m)$$ -approximation online. A crucial technical ingredient in all of our results is a new structural characterization of the optimal adaptive policy that allows us to limit the correlations between its decisions.},
  archive      = {J_MP},
  author       = {Eberle, Franziska and Gupta, Anupam and Megow, Nicole and Moseley, Benjamin and Zhou, Rudy},
  doi          = {10.1007/s10107-024-02132-w},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {243-279},
  shortjournal = {Math. Program.},
  title        = {Configuration balancing for stochastic requests},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From approximate to exact integer programming. <em>MP</em>,
<em>210</em>(1), 223–241. (<a
href="https://doi.org/10.1007/s10107-024-02084-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate integer programming is the following: For a given convex body $$K \subseteq {\mathbb {R}}^n$$ , either determine whether $$K \cap {\mathbb {Z}}^n$$ is empty, or find an integer point in the convex body $$2\cdot (K - c) +c$$ which is K, scaled by 2 from its center of gravity c. Approximate integer programming can be solved in time $$2^{O(n)}$$ while the fastest known methods for exact integer programming run in time $$2^{O(n)} \cdot n^n$$ . So far, there are no efficient methods for integer programming known that are based on approximate integer programming. Our main contribution are two such methods, each yielding novel complexity results. First, we show that an integer point $$x^* \in (K \cap {\mathbb {Z}}^n)$$ can be found in time $$2^{O(n)}$$ , provided that the remainders of each component $$x_i^* \mod \ell $$ for some arbitrarily fixed $$\ell \ge 5(n+1)$$ of $$x^*$$ are given. The algorithm is based on a cutting-plane technique, iteratively halving the volume of the feasible set. The cutting planes are determined via approximate integer programming. Enumeration of the possible remainders gives a $$2^{O(n)}n^n$$ algorithm for general integer programming. This matches the current best bound of an algorithm by Dadush (Integer programming, lattice algorithms, and deterministic, vol. Estimation. Georgia Institute of Technology, Atlanta, 2012) that is considerably more involved. Our algorithm also relies on a new asymmetric approximate Carathéodory theorem that might be of interest on its own. Our second method concerns integer programming problems in equation-standard form $$Ax = b, 0 \le x \le u, \, x \in {\mathbb {Z}}^n$$ . Such a problem can be reduced to the solution of $$\prod _i O(\log u_i +1)$$ approximate integer programming problems. This implies, for example that knapsack or subset-sum problems with polynomial variable range $$0 \le x_i \le p(n)$$ can be solved in time $$(\log n)^{O(n)}$$ . For these problems, the best running time so far was $$n^n \cdot 2^{O(n)}$$ .},
  archive      = {J_MP},
  author       = {Dadush, Daniel and Eisenbrand, Friedrich and Rothvoss, Thomas},
  doi          = {10.1007/s10107-024-02084-1},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {223-241},
  shortjournal = {Math. Program.},
  title        = {From approximate to exact integer programming},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monoidal strengthening and unique lifting in MIQCPs.
<em>MP</em>, <em>210</em>(1), 189–222. (<a
href="https://doi.org/10.1007/s10107-024-02112-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using the recently proposed maximal quadratic-free sets and the well-known monoidal strengthening procedure, we show how to improve intersection cuts for quadratically-constrained optimization problems by exploiting integrality requirements. We provide an explicit construction that allows an efficient implementation of the strengthened cuts along with computational results showing their improvements over the standard intersection cuts. We also show that, in our setting, there is unique lifting which implies that our strengthening procedure is generating the best possible cut coefficients for the integer variables.},
  archive      = {J_MP},
  author       = {Chmiela, Antonia and Muñoz, Gonzalo and Serrano, Felipe},
  doi          = {10.1007/s10107-024-02112-0},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {189-222},
  shortjournal = {Math. Program.},
  title        = {Monoidal strengthening and unique lifting in MIQCPs},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A linear time algorithm for linearizing quadratic and
higher-order shortest path problems. <em>MP</em>, <em>210</em>(1),
165–188. (<a href="https://doi.org/10.1007/s10107-024-02086-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An instance of the NP-hard Quadratic Shortest Path Problem (QSPP) is called linearizable iff it is equivalent to an instance of the classic Shortest Path Problem (SPP) on the same input digraph. The linearization problem for the QSPP (LinQSPP) decides whether a given QSPP instance is linearizable and determines the corresponding SPP instance in the positive case. We provide a novel linear time algorithm for the LinQSPP on acyclic digraphs which runs considerably faster than the previously best algorithm. The algorithm is based on a new insight revealing that the linearizability of the QSPP for acyclic digraphs can be seen as a local property. Our approach extends to the more general higher-order shortest path problem.},
  archive      = {J_MP},
  author       = {Çela, Eranda and Klinz, Bettina and Lendl, Stefan and Woeginger, Gerhard J. and Wulf, Lasse},
  doi          = {10.1007/s10107-024-02086-z},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {165-188},
  shortjournal = {Math. Program.},
  title        = {A linear time algorithm for linearizing quadratic and higher-order shortest path problems},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inapproximability of shortest paths on perfect matching
polytopes. <em>MP</em>, <em>210</em>(1), 147–163. (<a
href="https://doi.org/10.1007/s10107-023-02025-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the computational problem of finding short paths in the skeleton of the perfect matching polytope of a bipartite graph. We prove that unless $${\textsf {P}}={\textsf {NP}}$$ , there is no polynomial-time algorithm that computes a path of constant length between two vertices at distance two of the perfect matching polytope of a bipartite graph. Conditioned on $${\textsf {P}}\ne {\textsf {NP}}$$ , this disproves a conjecture by Ito et al. (SIAM J Discrete Math 36(2):1102–1123, 2022). Assuming the Exponential Time Hypothesis we prove the stronger result that there exists no polynomial-time algorithm computing a path of length at most $$\left( \frac{1}{4}-o(1)\right) \log N / \log \log N$$ between two vertices at distance two of the perfect matching polytope of an N-vertex bipartite graph. These results remain true if the bipartite graph is restricted to be of maximum degree three. The above has the following interesting implication for the performance of pivot rules for the simplex algorithm on simply-structured combinatorial polytopes: If $${\textsf {P}}\ne {\textsf {NP}}$$ , then for every simplex pivot rule executable in polynomial time and every constant $$k \in {\mathbb {N}}$$ there exists a linear program on a perfect matching polytope and a starting vertex of the polytope such that the optimal solution can be reached in two monotone non-degenerate steps from the starting vertex, yet the pivot rule will require at least k non-degenerate steps to reach the optimal solution. This result remains true in the more general setting of pivot rules for so-called circuit-augmentation algorithms.},
  archive      = {J_MP},
  author       = {Cardinal, Jean and Steiner, Raphael},
  doi          = {10.1007/s10107-023-02025-4},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {147-163},
  shortjournal = {Math. Program.},
  title        = {Inapproximability of shortest paths on perfect matching polytopes},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recycling valid inequalities for robust combinatorial
optimization with budgeted uncertainty. <em>MP</em>, <em>210</em>(1),
97–146. (<a href="https://doi.org/10.1007/s10107-024-02135-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust combinatorial optimization with budgeted uncertainty is one of the most popular approaches for integrating uncertainty into optimization problems. The existence of a compact reformulation for (mixed-integer) linear programs and positive complexity results give the impression that these problems are relatively easy to solve. However, the practical performance of the reformulation is quite poor when solving robust integer problems, in particular due to its weak linear relaxation. To overcome this issue, we propose procedures to derive new classes of valid inequalities for robust combinatorial optimization problems. For this, we recycle valid inequalities of the underlying deterministic problem such that the additional variables from the robust formulation are incorporated. The valid inequalities to be recycled may either be readily available model constraints or actual cutting planes, where we can benefit from decades of research on valid inequalities for classical optimization problems. We first demonstrate the strength of the inequalities theoretically, by proving that recycling yields a facet-defining inequality in many cases, even if the original valid inequality was not facet-defining. Afterwards, we show in an extensive computational study that using recycled inequalities can lead to a significant improvement of the computation time when solving robust optimization problems.},
  archive      = {J_MP},
  author       = {Büsing, Christina and Gersing, Timo and Koster, Arie M. C. A.},
  doi          = {10.1007/s10107-024-02135-7},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {97-146},
  shortjournal = {Math. Program.},
  title        = {Recycling valid inequalities for robust combinatorial optimization with budgeted uncertainty},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nearly optimal randomized algorithm for explorable heap
selection. <em>MP</em>, <em>210</em>(1), 75–96. (<a
href="https://doi.org/10.1007/s10107-024-02145-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explorable heap selection is the problem of selecting the nth smallest value in a binary heap. The key values can only be accessed by traversing through the underlying infinite binary tree, and the complexity of the algorithm is measured by the total distance traveled in the tree (each edge has unit cost). This problem was originally proposed as a model to study search strategies for the branch-and-bound algorithm with storage restrictions by Karp, Saks and Widgerson (FOCS ’86), who gave deterministic and randomized $$n\cdot \exp (O(\sqrt{\log {n}}))$$ time algorithms using $$O(\log (n)^{2.5})$$ and $$O(\sqrt{\log n})$$ space respectively. We present a new randomized algorithm with running time $$O(n\log (n)^3)$$ against an oblivious adversary using $$O(\log n)$$ space, substantially improving the previous best randomized running time at the expense of slightly increased space usage. We also show an $$\Omega (\log (n)n/\log (\log (n)))$$ lower bound for any algorithm that solves the problem in the same amount of space, indicating that our algorithm is nearly optimal.},
  archive      = {J_MP},
  author       = {Borst, Sander and Dadush, Daniel and Huiberts, Sophie and Kashaev, Danish},
  doi          = {10.1007/s10107-024-02145-5},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {75-96},
  shortjournal = {Math. Program.},
  title        = {A nearly optimal randomized algorithm for explorable heap selection},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient separation of RLT cuts for implicit and explicit
bilinear terms. <em>MP</em>, <em>210</em>(1), 47–74. (<a
href="https://doi.org/10.1007/s10107-024-02104-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reformulation–linearization technique (RLT) is a prominent approach to constructing tight linear relaxations of non-convex continuous and mixed-integer optimization problems. The goal of this paper is to extend the applicability and improve the performance of RLT for bilinear product relations. First, we present a method for detecting bilinear product relations implicitly contained in mixed-integer linear programs, which is based on analyzing linear constraints with binary variables, thus enabling the application of bilinear RLT to a new class of problems. Strategies for filtering product relations are discussed and tested. Our second contribution addresses the high computational cost of RLT cut separation, which presents one of the major difficulties in applying RLT efficiently in practice. We propose a new RLT cutting plane separation algorithm which identifies combinations of linear constraints and bound factors that are expected to yield an inequality that is violated by the current relaxation solution. This algorithm is applicable to RLT cuts generated for all types of bilinear terms, including but not limited to the detected implicit products. A detailed computational study based on independent implementations in two solvers evaluates the performance impact of the proposed methods.},
  archive      = {J_MP},
  author       = {Bestuzheva, Ksenia and Gleixner, Ambros and Achterberg, Tobias},
  doi          = {10.1007/s10107-024-02104-0},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {47-74},
  shortjournal = {Math. Program.},
  title        = {Efficient separation of RLT cuts for implicit and explicit bilinear terms},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information complexity of mixed-integer convex optimization.
<em>MP</em>, <em>210</em>(1), 3–45. (<a
href="https://doi.org/10.1007/s10107-024-02099-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the information complexity of mixed-integer convex optimization under different types of oracles. We establish new lower bounds for the standard first-order oracle, improving upon the previous best known lower bound. This leaves only a lower order linear term (in the dimension) as the gap between the lower and upper bounds. This is derived as a corollary of a more fundamental “transfer” result that shows how lower bounds on information complexity of continuous convex optimization under different oracles can be transferred to the mixed-integer setting in a black-box manner. Further, we (to the best of our knowledge) initiate the study of, and obtain the first set of results on, information complexity under oracles that only reveal partial first-order information, e.g., where one can only make a binary query over the function value or subgradient at a given point. We give algorithms for (mixed-integer) convex optimization that work under these less informative oracles. We also give lower bounds showing that, for some of these oracles, every algorithm requires more iterations to achieve a target error compared to when complete first-order information is available. That is, these oracles are provably less informative than full first-order oracles for the purpose of optimization.},
  archive      = {J_MP},
  author       = {Basu, Amitabh and Jiang, Hongyi and Kerger, Phillip and Molinaro, Marco},
  doi          = {10.1007/s10107-024-02099-8},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {3-45},
  shortjournal = {Math. Program.},
  title        = {Information complexity of mixed-integer convex optimization},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Special issue: Integer programming and combinatorial
optimization (IPCO) 2023. <em>MP</em>, <em>210</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s10107-025-02205-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MP},
  author       = {Del Pia, Alberto and Kaibel, Volker},
  doi          = {10.1007/s10107-025-02205-4},
  journal      = {Mathematical Programming},
  month        = {3},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Math. Program.},
  title        = {Special issue: Integer programming and combinatorial optimization (IPCO) 2023},
  volume       = {210},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="mpc---5">MPC - 5</h2>
<ul>
<li><details>
<summary>
(2025). Minimizing total tardiness for the single-machine
identical-jobs order scheduling problem with a learning effect.
<em>MPC</em>, <em>17</em>(1), 141–171. (<a
href="https://doi.org/10.1007/s12532-024-00271-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a single machine identical-jobs order scheduling problem with a position-dependent learning effect (SIOSLE) to minimize the total tardiness. A learning effect is common in the identical-jobs order manufacturing, such as clothing, bicycles, shoes, and so on, but its impact on the order scheduling problem has not been studied, especially for orders with different numbers of the same type of jobs. A mixed integer programming (MIP) model is first formulated for SIOSLE and serves as a benchmark. A new branch-and-bound algorithm was developed to handle computational complexity based on the Dominance, Split, Elimination, and Decomposition rules revised from the traditional job scheduling problem and new lower and upper bounds. Numerical experiments demonstrate that the proposed branch-and-bound algorithm is computationally better than the performance of using Gurobi, a popular commercial solver, to solve the MIP. The experiments for large-sized problems found that the proposed branch-and-bound algorithm can solve instances with up to 120 orders. The algorithm is more efficient for instances with a strong or weak learning effect, with tight or loose due dates, or with heterogeneous due dates. The effectiveness of the Dominance, Split, Elimination, and Decomposition rules varies with parameter settings. In addition, the proposed branch-and-bound algorithm can yield better solutions than traditional meta-heuristic algorithms but may require longer run time for large instances.},
  archive      = {J_MPC},
  author       = {Hu, Jinchang and Jin, Mingzhou},
  doi          = {10.1007/s12532-024-00271-x},
  journal      = {Mathematical Programming Computation},
  month        = {3},
  number       = {1},
  pages        = {141-171},
  shortjournal = {Math. Program. Comput.},
  title        = {Minimizing total tardiness for the single-machine identical-jobs order scheduling problem with a learning effect},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fix-propagate-repair heuristic for mixed integer
programming. <em>MPC</em>, <em>17</em>(1), 111–139. (<a
href="https://doi.org/10.1007/s12532-024-00269-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a diving heuristic framework based on constraint propagation for mixed integer linear programs. The proposed approach is an extension of the common fix-and-propagate scheme, with the addition of solution repairing after each step. The repair logic is loosely based on the WalkSAT strategy for boolean satisfiability. Different strategies for variable ranking and value selection, as well as other options, yield different diving heuristics. The overall method is relatively inexpensive, as it is basically LP-free: the full linear programming relaxation is solved only at the beginning (and only for the ranking strategies that make use of it), while additional, typically much smaller, LPs are only used to compute values for the continuous variables (if any), once at the bottom of a dive. While individual strategies are not very robust in finding feasible solutions on a heterogeneous testbed, a portfolio approach proved quite effective. In particular, it could consistently find feasible solutions in 189 out of 240 instances from the public MIPLIB 2017 benchmark testbed, in a matter of a few seconds of runtime. The framework has also been implemented inside the commercial MIP solver Xpress and shown to give a small performance improvement in time to optimality on a large internal heterogeneous testbed.},
  archive      = {J_MPC},
  author       = {Salvagnin, Domenico and Roberti, Roberto and Fischetti, Matteo},
  doi          = {10.1007/s12532-024-00269-5},
  journal      = {Mathematical Programming Computation},
  month        = {3},
  number       = {1},
  pages        = {111-139},
  shortjournal = {Math. Program. Comput.},
  title        = {A fix-propagate-repair heuristic for mixed integer programming},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LCQPow: A solver for linear complementarity quadratic
programs. <em>MPC</em>, <em>17</em>(1), 81–109. (<a
href="https://doi.org/10.1007/s12532-024-00272-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce an open-source software package written in C++ for efficiently finding solutions to quadratic programming problems with linear complementarity constraints. These problems arise in a wide range of applications in engineering and economics, and they are challenging to solve due to their structural violation of standard constraint qualifications, and highly nonconvex, nonsmooth feasible sets. This work extends a previously presented algorithm based on a sequential convex programming approach applied to a standard penalty reformulation. We examine the behavior of local convergence and introduce new algorithmic features. Competitive performance profiles are presented in comparison to state-of-the-art solvers and solution variants in both existing and new benchmarks.},
  archive      = {J_MPC},
  author       = {Hall, Jonas and Nurkanović, Armin and Messerer, Florian and Diehl, Moritz},
  doi          = {10.1007/s12532-024-00272-w},
  journal      = {Mathematical Programming Computation},
  month        = {3},
  number       = {1},
  pages        = {81-109},
  shortjournal = {Math. Program. Comput.},
  title        = {LCQPow: A solver for linear complementarity quadratic programs},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate maximum likelihood estimators for linear
regression with independent component-wise design matrix uncertainty.
<em>MPC</em>, <em>17</em>(1), 53–79. (<a
href="https://doi.org/10.1007/s12532-024-00268-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we consider regression problems subject to noise in the operator or design matrix. This characterization appropriately models many physical phenomena with uncertainty in the regressors. Although the problem has been studied extensively for ordinary/total least squares, and via models that implicitly or explicitly assume Gaussianity, less attention has been paid to improving estimation for regression problems under general independent component-wise uncertainty in the design matrix. To address difficulties encountered when dealing with distributions of sums of random variables, we rely on the saddle point method to estimate densities and form an approximate log-likelihood to maximize. We show that the proposed method performs favorably against other classical methods.},
  archive      = {J_MPC},
  author       = {Clancy, Richard J. and Becker, Stephen},
  doi          = {10.1007/s12532-024-00268-6},
  journal      = {Mathematical Programming Computation},
  month        = {3},
  number       = {1},
  pages        = {53-79},
  shortjournal = {Math. Program. Comput.},
  title        = {Approximate maximum likelihood estimators for linear regression with independent component-wise design matrix uncertainty},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the b-differential of the componentwise minimum of two
affine vector functions. <em>MPC</em>, <em>17</em>(1), 1–52. (<a
href="https://doi.org/10.1007/s12532-024-00266-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the description and computation of the B-differential of the componentwise minimum of two affine vector functions. This issue arises in the reformulation of the linear complementarity problem with the Min C-function. The question has many equivalent formulations and we identify some of them in linear algebra, convex analysis and discrete geometry. These formulations are used to state some properties of the B-differential, like its symmetry, condition for its completeness, its connectivity, bounds on its cardinality, etc. The set to specify has a finite number of elements, which may grow exponentially with the range space dimension of the functions, so that its description is most often algorithmic. We first present an incremental-recursive approach avoiding to solve any optimization subproblem, unlike several previous approaches. It is based on the notion of matroid circuit and the related introduced concept of stem vector. Next, we propose modifications, adapted to the problem at stake, of an algorithm introduced by Rada and Černý (SIAM J Discret Math 32(1):455-473, 2018, https://doi.org/10.1137/15M1027930 ) to determine the cells of an arrangement in the space of hyperplanes having a point in common. Measured in CPU time on the considered test-problems, the mean acceleration ratios of the proposed algorithms, with respect to the one of Rada and Černý, are in the range 15..31, and this speed-up can exceed 100, depending on the problem, the approach and the chosen linear optimization and matroid solvers.},
  archive      = {J_MPC},
  author       = {Dussault, Jean-Pierre and Gilbert, Jean Charles and Plaquevent-Jourdain, Baptiste},
  doi          = {10.1007/s12532-024-00266-8},
  journal      = {Mathematical Programming Computation},
  month        = {3},
  number       = {1},
  pages        = {1-52},
  shortjournal = {Math. Program. Comput.},
  title        = {On the B-differential of the componentwise minimum of two affine vector functions},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="mva---9">MVA - 9</h2>
<ul>
<li><details>
<summary>
(2025). Enforced clustering for zero-to-one-shot texture anomaly
detection. <em>MVA</em>, <em>36</em>(3), 1–19. (<a
href="https://doi.org/10.1007/s00138-025-01670-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies on anomaly detection (AD) for industrial products typically address the problem in an unsupervised manner, requiring only normal data for training. This approach alleviates the need for anomalous data but still requires a set of normal samples and often involves demanding computations. More recent methods aim to solve this problem in zero-, one-, or few-shot settings but suffer from performance drops or rely on additional contexts, such as language guidance and text encoding, which add overhead. This paper focuses on homogeneous textures and demonstrates how the problem can be addressed without any training samples or additional training (zero-shot), only requiring one normal sample (one-shot) for hyperparameter selection, which is an additional challenge in unsupervised settings. This is achieved by enforcing K-means clustering with $${K}=2$$ on each of the testing samples independently, distinguishing it from the typical use of clustering methods in outlier detection, which are applied to a set of samples. The confidence score of each locality belonging to the smaller cluster, considered the potential anomalous cluster for evaluation, forms the anomaly map used in anomaly localization, and the maximum values in this map are used in AD. Competitive performance is achieved through the careful selection of the distance metric, feature layers, and clustering method. Experiments show that this zero-to-one-shot method, which facilitates deployment by reducing data dependency, maintains performance comparable to, or even higher than, conventional many-shot methods, all with relatively high speed.},
  archive      = {J_MVA},
  author       = {Amirian Varnousefaderani, Bahar and Rakhmonov, Akhrorjon Akhmadjon Ugli and Kim, Jae-Soo and Kim, Jeonghong},
  doi          = {10.1007/s00138-025-01670-3},
  journal      = {Machine Vision and Applications},
  month        = {5},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Mach. Vis. Appl.},
  title        = {Enforced clustering for zero-to-one-shot texture anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring filter placement in convolutional layer topologies
based on ResNet for image classification. <em>MVA</em>, <em>36</em>(3),
1–11. (<a href="https://doi.org/10.1007/s00138-025-01674-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we investigate the impact that altering the convolutional layer topology has upon the performance of computer vision tasks using a variety of widely used benchmark image datasets. Despite the widespread convention in convolutional neural networks, of incrementally doubling the filter count at each layer, there is little evidence substantiating the superiority of this method over other possible topologies. Our research reveals that a contrarian strategy—reducing the filters by half—can achieve performance on par with, if not superior to, this usual approach. We have extended our investigation to include a variety of novel topological structures. These empirical results challenge the prevailing assumption, that the sequential doubling of number of filters in the network configuration will always yield the best results with all datasets. Our findings advocate for a more nuanced approach to neural network design, incorporating a flexible approach to filter topologies into workflows. This could potentially have a significant impact upon the architectural standards in deep learning for visual recognition tasks.},
  archive      = {J_MVA},
  author       = {Liu, Haixia and Brailsford, Tim and Bull, Larry},
  doi          = {10.1007/s00138-025-01674-z},
  journal      = {Machine Vision and Applications},
  month        = {5},
  number       = {3},
  pages        = {1-11},
  shortjournal = {Mach. Vis. Appl.},
  title        = {Exploring filter placement in convolutional layer topologies based on ResNet for image classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on SLAM and machine learning
approaches for indoor autonomous navigation of mobile robots.
<em>MVA</em>, <em>36</em>(3), 1–21. (<a
href="https://doi.org/10.1007/s00138-025-01673-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex and dynamic nature of indoor environments presents significant challenges for mobile robots autonomous navigation. Traditional navigation methods, reliant on handcrafted features and algorithms, often struggle to adapt to these challenges. Recently, machine learning techniques have emerged as a promising approach for indoor autonomous navigation, offering the ability to learn from data to extract features and develop robust navigation strategies. This survey presents recent strategies for indoor autonomous navigation of mobile robots, providing a comprehensive overview of traditional methods for indoor autonomous mobile robots simultaneous localization and mapping mapping (SLAM), path planning and obstacle avoidance, and machine learning approaches, including deep learning and reinforcement learning. Furthermore, the paper discusses the specific challenges of indoor autonomous navigation for mobile robots and examines the advantages, challenges, and limitations of applying machine learning techniques in this context. Since performance evaluation is crucial for proving the efficiency of each novel developed algorithm and method, the most important performance evaluation metrics are described and mathematically presented with formulas. A systematic review on recent advances in indoor autonomous mobile robot navigation is further supported by presenting relevant patents on the topic of the paper and the field. Additionally, the survey identifies promising future research directions in machine learning-based indoor autonomous navigation. Last but not least, this survey aims to serve as a valuable resource for researchers and engineers interested in developing advanced and machine learning-based indoor autonomous navigation systems for mobile robots.},
  archive      = {J_MVA},
  author       = {Damjanović, Davor and Biočić, Petar and Prakljačić, Stjepan and Činčurak, Dorian and Balen, Josip},
  doi          = {10.1007/s00138-025-01673-0},
  journal      = {Machine Vision and Applications},
  month        = {5},
  number       = {3},
  pages        = {1-21},
  shortjournal = {Mach. Vis. Appl.},
  title        = {A comprehensive survey on SLAM and machine learning approaches for indoor autonomous navigation of mobile robots},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive fusion attention for enhanced classification and
interpretability in medical imaging. <em>MVA</em>, <em>36</em>(3), 1–23.
(<a href="https://doi.org/10.1007/s00138-025-01665-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate medical image classification is crucial for effective clinical decision support, improving patient outcomes and reducing healthcare costs. However, developing expert Computer-Aided Diagnosis systems for accurate medical image classification remains a challenging task. Recent advancements in attention mechanisms have revolutionized deep learning-based approaches, leading to improved performance even in applications with limited labeled data. Despite these advances, challenges such as overfitting and poor generalization persist. This work introduces a novel deep learning-based model that incorporates Adaptive Fusion Attention to enhance medical image analysis. The proposed attention module employs a hierarchical fusion of spatial and temporal attention mechanisms, complemented by adaptive refinement. This enables the model to focus on the most discriminative features in medical images, improving its ability to detect abnormalities. Additionally, GRAD-CAM visualizations demonstrate that the model effectively highlights pathological regions while minimizing attention on non-relevant areas. The model is evaluated on three benchmark datasets-APTOS-2019, Figshare, and SARS-CoV-2-demonstrating its effectiveness in Diabetic Retinopathy grading, Brain Tumor Classification, and COVID-19 detection. Experimental results show substantial improvements, achieving 84.56% accuracy for retinopathy grading, 99.60% accuracy for tumor classification, and 99.35% accuracy for COVID-19 detection. These results, along with superior performance across other metrics such as ROC-AUC, and F1-scores, demonstrate the effectiveness of the proposed model with Adaptive Fusion Attention over existing approaches.},
  archive      = {J_MVA},
  author       = {Shaik, Nagur Shareef and Veeranjaneulu, N. and Bodapati, Jyostna Devi},
  doi          = {10.1007/s00138-025-01665-0},
  journal      = {Machine Vision and Applications},
  month        = {5},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Mach. Vis. Appl.},
  title        = {Adaptive fusion attention for enhanced classification and interpretability in medical imaging},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cigarette defect detection algorithm based on attention
mechanism and multi-gradient feature fusion. <em>MVA</em>,
<em>36</em>(3), 1–14. (<a
href="https://doi.org/10.1007/s00138-025-01681-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surface defect detection remains a persistent and challenging task. Aiming at the detection of surface defects in cigarettes, we propose an enhanced YOLOX-S model. Firstly, an improved attention mechanism named MS-GCT (Multi-Spectral Gaussian Context Transformer) is introduced into the model’s backbone to enhance the model’s ability of capturing the global context information within images and improve its comprehension of semantic feature information; secondly, we propose the DMG (Dynamic convolution and MS-GCT) module, and combined with the C2f (CSPLayer with 2 convolutions) module to construct the C2f-DMG module,which is introduced into the model to enhance feature interaction and feature extraction ability, to strengthen long-distance dependency ability of global features; finally, we replace the loss function with SIoU to enhance model performance and accelerate model convergence. To validate the effectiveness of our model, we conduct experiments on both the self-made cigarette dataset and the public dataset. The experimental results indicate that the improved model not only ensures the lightweight of the model, but also boosts the model’s mAP by 2.02, while achieving a detection speed of 73.17 frames−1. Furthermore, the proposed algorithm fulfills the real-time detection requirements for cigarette appearance defects.},
  archive      = {J_MVA},
  author       = {Shi, Weiya and Zhang, Shiqiang and Zhang, Shaowen},
  doi          = {10.1007/s00138-025-01681-0},
  journal      = {Machine Vision and Applications},
  month        = {5},
  number       = {3},
  pages        = {1-14},
  shortjournal = {Mach. Vis. Appl.},
  title        = {Cigarette defect detection algorithm based on attention mechanism and multi-gradient feature fusion},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D multi-object tracking based on parallel multimodal data
association. <em>MVA</em>, <em>36</em>(3), 1–15. (<a
href="https://doi.org/10.1007/s00138-025-01675-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel 3D multi-object tracker based on tracking-by-detection (TBD) framework. The system leverages parallel feature extraction and data association methods to process 2D appearance features and 3D spatial information, respectively, to achieve accurate tracking of targets in autonomous vehicles and intelligent transportation systems. By combining the Siamese network-based image feature extractor to extract image appearance features and the kinematic model established using Kalman filtering, our tracker effectively utilizes the appearance and spatial information of the object, thus improving tracker accuracy and reliability. Experimental results demonstrate the competitiveness of our tracker on the KITTI tracking benchmark. Compared to previous methods, A parallel feature extraction algorithm is proposed that can independently extract the spatial and appearance information of the object. A novel data association algorithm is designed that makes full use of the spatial information of the object from the point cloud and the appearance information from the image. This work provides substantial technical underpinnings for the advancement of autonomous driving and intelligent transportation technology. https://github.com/TanShiyu2022/PMTrack .},
  archive      = {J_MVA},
  author       = {Tan, Shiyu and Li, Xu and Xu, QiMin and Zhu, Jianxiao},
  doi          = {10.1007/s00138-025-01675-y},
  journal      = {Machine Vision and Applications},
  month        = {5},
  number       = {3},
  pages        = {1-15},
  shortjournal = {Mach. Vis. Appl.},
  title        = {3D multi-object tracking based on parallel multimodal data association},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature distribution statistics as a loss objective for
robust white balance correction. <em>MVA</em>, <em>36</em>(3), 1–20. (<a
href="https://doi.org/10.1007/s00138-025-01680-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {White balance (WB) correction is critical for accurate color reproduction in digital images, especially under complex, multi-illuminant lighting conditions. Traditional methods, such as the Gray-World assumption, rely on global statistics and struggle in real-world, non-uniform lighting scenarios. Modern deep learning approaches, including convolutional and attention-based architectures, have significantly advanced WB correction but often fail to explicitly account for higher-order feature distribution statistics, which may limit their robustness in challenging environments. This study introduces a novel framework that leverages Exact Feature Distribution Matching (EFDM) as a loss objective to align feature distributions across multiple moments, including mean, variance, skewness, and kurtosis. By modeling lighting as a style factor, the method explicitly addresses distributional shifts caused by complex illumination, offering a robust solution for WB correction. The framework integrates EFDM with a Vision Transformer architecture, enabling precise handling of global and local lighting variations. Extensive experiments on the large-scale multi-illuminant (LSMI) dataset demonstrate the superiority of the proposed approach over state-of-the-art methods and commonly used loss functions when applied to the same architecture. Qualitative and quantitative evaluations highlight its effectiveness in achieving perceptually accurate WB correction, particularly in multi-illuminant environments. By bridging statistical modeling with modern deep learning, this work establishes the critical role of feature distribution alignment in advancing WB correction and sets a new benchmark for robustness and generalization in complex lighting scenarios.},
  archive      = {J_MVA},
  author       = {Kınlı, Furkan and Kıraç, Furkan},
  doi          = {10.1007/s00138-025-01680-1},
  journal      = {Machine Vision and Applications},
  month        = {5},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Mach. Vis. Appl.},
  title        = {Feature distribution statistics as a loss objective for robust white balance correction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ViCap-AD: Video caption-based weakly supervised video
anomaly detection. <em>MVA</em>, <em>36</em>(3), 1–12. (<a
href="https://doi.org/10.1007/s00138-025-01676-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection becomes increasingly critical amidst rising crime rates and concerns for public safety. Traditional unsupervised video anomaly detection methods primarily focused on normal data, limiting their ability to achieve optimal performance due to their inability to effectively utilize abnormal data. Weakly supervised video anomaly detection methods addressed some of these limitations but still struggled to leverage anomalous video labels effectively, often being susceptible to noise in classification scores. In this paper, we propose a novel approach named Video Caption Anomaly Detector (ViCap-AD), which leverages video captions alongside a combination of BERT and the multiple instance learning (MIL) framework for anomaly detection. ViCap-AD integrates video captions generated using CLIP4Clip with video features within the MIL framework augmented by BERT. In our experimental evaluations on the UCF-Crime and XD-Violence datasets, ViCap-AD achieves state-of-the-art performance, achieving AUC scores of 87.20% and 85.02%, respectively. These results underscore the robustness and effectiveness of our approach across different datasets, demonstrating its powerful performance and stability. This paper contributes a significant advancement in anomaly detection methodologies, highlighting the potential of ViCap-AD to enhance anomaly detection accuracy and reliability in real-world applications.},
  archive      = {J_MVA},
  author       = {Lim, Junwoo and Lee, Juyeob and Kim, Hyunji and Park, Eunil},
  doi          = {10.1007/s00138-025-01676-x},
  journal      = {Machine Vision and Applications},
  month        = {5},
  number       = {3},
  pages        = {1-12},
  shortjournal = {Mach. Vis. Appl.},
  title        = {ViCap-AD: Video caption-based weakly supervised video anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep representation learning for license plate recognition
in low quality video images. <em>MVA</em>, <em>36</em>(3), 1–14. (<a
href="https://doi.org/10.1007/s00138-025-01678-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {License plate recognition is an important technology in many application scenarios such as traffic monitoring and vehicle management. Due to variations in viewpoint, illumination, motion-blur, and degradation during the imaging process, it is still a challenging problem to detect and recognize license plates in low quality video images. In this paper, we focus on efficient deep representation learning for license plate recognition, detection and tracking. For license plate recognition, we mainly investigate the configuration of different network structures. We design a novel backbone network structure called SACNN, which combines convolutional neural network (CNN) and self-attention mechanism to learn non-linear representations for the structural patterns of characters in low quality video images. The proposed license plate recognition model employs the SACNN backbone network, a Long Short-Term Memory (LSTM) encoder and a Transformer decoder. For license plate detection, a Transformer encoder–decoder based method is adopted. To tackle the variations in license plate appearances and perspectives, an image rectification method is incorporated by using a spatial transformer network. For license plate tracking, a multi-object tracking method is incorporated by using Kalman filtering and temporal matching to associate detected license plates in video frames. Experiments are mainly carried out on the public large-scale video-based license plate dataset (LSV-LP) to validate the proposed methods.},
  archive      = {J_MVA},
  author       = {Zhao, Kemeng and Peng, Liangrui and Ding, Ning and Yao, Gang and Tang, Pei and Wang, Shengjin},
  doi          = {10.1007/s00138-025-01678-9},
  journal      = {Machine Vision and Applications},
  month        = {5},
  number       = {3},
  pages        = {1-14},
  shortjournal = {Mach. Vis. Appl.},
  title        = {Deep representation learning for license plate recognition in low quality video images},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="naco---11">NACO - 11</h2>
<ul>
<li><details>
<summary>
(2025). Self-organizing nest migration dynamics synthesis for ant
colony systems. <em>NACO</em>, <em>24</em>(1), 163–172. (<a
href="https://doi.org/10.1007/s11047-022-09923-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we synthesize a novel dynamical approach for ant colonies enabling them to migrate to new nest sites in a self-organizing fashion. In other words, we realize ant colony migration as a self-organizing phenotype-level collective behavior. For this purpose, we first segment the edges of the graph of ants’ pathways. Then, each segment, attributed to its own pheromone profile, may host an ant. So, multiple ants may occupy an edge at the same time. Thanks to this segment-wise edge formulation, ants have more selection options in the course of their pathway determination, thereby increasing the diversity of their colony’s emergent behaviors. In light of the continuous pheromone dynamics of segments, each edge owns a spatio-temporal piece-wise continuous pheromone profile in which both deposit and evaporation processes are unified. The passive dynamics of the proposed migration mechanism is sufficiently rich so that an ant colony can migrate to the vicinity of a new nest site in a self-organizing manner without any external supervision. In particular, we perform extensive simulations to test our migration dynamics applied to a colony including 500 ants traversing a pathway graph comprising 200 nodes and 4000 edges which are segmented based on various resolutions. The obtained results exhibit the effectiveness of our strategy.},
  archive      = {J_NACO},
  author       = {Macktoobian, Matin},
  doi          = {10.1007/s11047-022-09923-0},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {163-172},
  shortjournal = {Nat. Comput.},
  title        = {Self-organizing nest migration dynamics synthesis for ant colony systems},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modelling and evaluating restricted ESNs on single- and
multi-timescale problems. <em>NACO</em>, <em>24</em>(1), 149–161. (<a
href="https://doi.org/10.1007/s11047-024-10004-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir Computing is a computing model ideal for performing computation on varied physical substrates. However, these physical reservoirs can be difficult to scale up. We propose joining various reservoirs together as an approach to solving this problem, simulating physical reservoirs with Echo State Networks (ESNs). We investigate various methods of combining ESNs to form larger reservoirs, including a method that we dub Restricted ESNs. We provide a notation for describing Restricted ESNs, and use it to benchmark a standard ESN against restricted ones. We investigate two methods to keep the weight matrix density consistent when comparing a Restricted ESN to a standard one, which we call overall consistency and patch consistency. We benchmark restricted ESNs on NARMA10 and the sunspot prediction benchmark, and find that restricted ESNs perform similarly to standard ones. We present some application scenarios in which restricted ESNs may offer advantages over standard ESNs. We then test restricted ESNs on a version of the multi-timescale Multiple Superimposed Sines tasks, in order to establish a baseline performance that can be improved upon in further work. We conclude that we can scale up reservoir performance by linking small homogeneous subreservoirs together without significant loss in performance over a single large reservoir, justifying future work on using heterogeneous subreservoirs for greater flexibility.},
  archive      = {J_NACO},
  author       = {Wringe, Chester and Stepney, Susan and Trefzer, Martin A.},
  doi          = {10.1007/s11047-024-10004-7},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {149-161},
  shortjournal = {Nat. Comput.},
  title        = {Modelling and evaluating restricted ESNs on single- and multi-timescale problems},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-shuffle card-based protocol with eight cards per gate
and its extensions. <em>NACO</em>, <em>24</em>(1), 131–147. (<a
href="https://doi.org/10.1007/s11047-024-10006-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Card-based cryptography allows us to securely compute arbitrary functions using a deck of physical cards. Its performance is mainly measured by the number of used cards and shuffles, and there is a line of work that aims to reduce either of them. One seminal work is the card-based garbled circuit technique by Shinagawa and Nuida (Discret Appl Math 289:248–261, 2021, https://doi.org/10.1016/j.dam.2020.10.013 ), which allows the construction of a card-based protocol for any Boolean function with a single shuffle. Their construction requires $$2n + 24g$$ cards for an n-input Boolean function that is represented by g logical gates. In this paper, we reduce the number of cards to $$2n + 8g$$ for arbitrary functions while keeping it working with only one shuffle. In addition, we propose two types of extensions to support numerical encoding and multi-input gates. In the extended scheme, the free-ADD technique, obtained by generalizing the free-XOR technique by Manabe and Shinagawa (Deng J, Kolesnikov V, Schwarzmann AA (eds) CANS 2023, LNCS, vol 14342. Springer, Singapore, pp 232–248, 2023, https://doi.org/10.1007/978-981-99-7563-1-11 ), is available. The free-ADD technique allows our scheme to evaluate any n-input symmetric Boolean function using $$2n^2+6n+2$$ cards.},
  archive      = {J_NACO},
  author       = {Tozawa, Kazunari and Morita, Hiraku and Mizuki, Takaaki},
  doi          = {10.1007/s11047-024-10006-5},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {131-147},
  shortjournal = {Nat. Comput.},
  title        = {Single-shuffle card-based protocol with eight cards per gate and its extensions},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analysis of the relative effects of connectivity and
coupling interactions on spin networks emulating the d-wave 2000Q
quantum annealer. <em>NACO</em>, <em>24</em>(1), 113–129. (<a
href="https://doi.org/10.1007/s11047-024-10001-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From available data, we show strong positive spatial correlations in the qubits of a D-Wave 2000Q quantum annealing chip that are connected to qubits outside their own unit cell. Then, by simulating the dynamics of three different spin networks and two different initial conditions, we then show that correlation between nodes is affected by a number of factors. The different connectivity of qubits within the network means that information transfer is not straightforward even when all the qubit-qubit couplings have equal weighting. Connected nodes behave even more dissimilarly when the couplings’ strength is scaled according to the physical length of the connections (here to simulate dipole-dipole interactions). This highlights the importance of understanding the architectural features and potentially unprogrammed interactions/connections that can divert the performance of a quantum system away from the idealised model of identical qubits and couplings across the chip.},
  archive      = {J_NACO},
  author       = {Park, Jessica and Stepney, Susan and D’Amico, Irene},
  doi          = {10.1007/s11047-024-10001-w},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {113-129},
  shortjournal = {Nat. Comput.},
  title        = {An analysis of the relative effects of connectivity and coupling interactions on spin networks emulating the D-wave 2000Q quantum annealer},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating particle swarm optimization and various
mobility algorithms for autonomous navigation in flying ad-hoc networks.
<em>NACO</em>, <em>24</em>(1), 95–112. (<a
href="https://doi.org/10.1007/s11047-024-10009-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flying ad-hoc networks (FANETs) have gained significant attention within the research community due to the widespread availability of unmanned aerial vehicles (UAVs) and the electronic components required for their control and connectivity. Various applications, such as 3D mapping, construction inspection, and emergency response operations, stand to benefit from leveraging a swarm of UAVs instead of a single UAV. This necessitates the establishment of an ad-hoc network for communication and coordination. An important aspect of implementing FANETs involves autonomously determining the optimal position of the UAVs to ensure communications with the ground nodes while maximizing coverage and connectivity to a remote server. In this research, an application of particle swarm optimization (PSO) algorithm is proposed to achieve optimal positioning of the UAVs facilitating air-to-ground communications to several ground nodes whose positions within the grid are unknown. The performance of the PSO algorithm is compared with fixed and hybrid models across varying grid sizes (1000 × 1000 and 1500 × 1500), numbers of UAVs (N = 3, …, 9), and numbers of sensor nodes (n = 10, 20, and 30). The log-normal propagation model is considered to account for channel fading effects resulting from multipath propagation.},
  archive      = {J_NACO},
  author       = {Paredes, W. D. and Kaushal, Hemani and Prodanoff, Z. and Vakilinia, I.},
  doi          = {10.1007/s11047-024-10009-2},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {95-112},
  shortjournal = {Nat. Comput.},
  title        = {Investigating particle swarm optimization and various mobility algorithms for autonomous navigation in flying ad-hoc networks},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proving new directed tile complexity lower bounds at
temperature 1 by folding between 2D and just-barely 3D self-assembly.
<em>NACO</em>, <em>24</em>(1), 79–93. (<a
href="https://doi.org/10.1007/s11047-024-09979-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of determining the size of the smallest tile set that uniquely self-assembles into a given target shape in Winfree’s abstract Tile Assembly Model (aTAM), an elegant theoretical model of DNA tile self-assembly. This problem is also known as the “directed tile complexity” problem. We prove two main results related to the directed tile complexity problem within a variant of the aTAM in which the minimum binding strength threshold (temperature) is set to 1. For our first result, self-assembly happens in a “just-barely 3D” setting, where self-assembling unit cubes are allowed to be placed in the $$z=0$$ and $$z=1$$ planes. This is the same setting in which Furcy, Summers and Withers (DNA 2021) recently proved lower and upper bounds on the directed tile complexity of a just-barely 3D $$k \times N$$ rectangle at temperature 1 of $$\Omega \left( N^{\frac{1}{k}}\right) $$ and $$O\left( N^{\frac{1}{k-1}}+\log N\right) $$ , respectively, the latter of which does not hold for $$k=2$$ . Our first result closes this gap for $$k=2$$ by proving an asymptotically tight bound of $$\Theta (N)$$ on the directed tile complexity of a just-barely 3D $$2 \times N$$ rectangle at temperature 1. Our proof uses a novel process by which a just-barely 3D assembly sequence is “unfolded” to an equivalent 2D assembly sequence. For our second result, we use the aforementioned lower bound by Furcy, Summers and Withers and a novel process that is complementary-in-spirit to our 3D-to-2D unfolding process, by which we “fold” a 2D tile assembly to an equivalent just-barely 3D assembly to prove a new lower bound on the directed tile complexity of a 2D $$k \times N$$ rectangle at temperature 1 of $$\Omega \left( \frac{N^{\frac{2}{k + (k \bmod 2)}}}{k} \right) $$ . For fixed k, our new bound gives a nearly quadratic improvement over, and matches for general even values of $$k &lt; \frac{\log N}{\log \log N - \log \log \log N}$$ the state of the art lower bound on the directed tile complexity of a $$k \times N$$ rectangle at temperature 1 by Furcy, Summers and Wendlandt (DNA 2019) of $$\Omega \left( N^{\frac{1}{k}}\right) $$ . While both of our results represent improvements over previous corresponding state of the art results, the proofs thereof are facilitated by novel examples of reasoning about tile self-assembly happening in 2D (just-barely 3D) as though it is happening in just-barely 3D (2D).},
  archive      = {J_NACO},
  author       = {Furcy, David and Summers, Scott M. and Vadnais, Hailey},
  doi          = {10.1007/s11047-024-09979-0},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {79-93},
  shortjournal = {Nat. Comput.},
  title        = {Proving new directed tile complexity lower bounds at temperature 1 by folding between 2D and just-barely 3D self-assembly},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Abstract geometrical computation 12: Generating
representation of infinite countable linear orderings. <em>NACO</em>,
<em>24</em>(1), 67–78. (<a
href="https://doi.org/10.1007/s11047-024-10005-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Any countable (infinite or not) linear (total) ordering can be represented by displaying all its elements on an axis in increasing order. Such a representation can be generated using only geometrical constructions based on coloured line segment extensions and rules to handle segment intersections. After a bounded time, the construction segments disappear and only the representation remains. The process starts with finitely many segments, so that unbounded acceleration effects are used to generate infinitely many segments for the representation. There is no outside machinery nor operator: any needed computation has to be carried out through the drawing. After providing some illustrative examples with ad hoc constructions, we prove our main results. One rational signal machine (bounded to use only rational coordinates) can generate the representation of any decidable linear ordering (i.e. the order between two elements is decidable by a Turing machine). In the general case, there is a signal machine able to generate the representation of any countable linear ordering (encoded in a real number).},
  archive      = {J_NACO},
  author       = {Durand-Lose, Jérôme},
  doi          = {10.1007/s11047-024-10005-6},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {67-78},
  shortjournal = {Nat. Comput.},
  title        = {Abstract geometrical computation 12: Generating representation of infinite countable linear orderings},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sandpiles prediction and crossover on <span
class="math display">ℤ<sup>2</sup></span> within moore neighborhood.
<em>NACO</em>, <em>24</em>(1), 29–66. (<a
href="https://doi.org/10.1007/s11047-024-10002-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational complexity of predicting sandpiles on $$\mathbb {Z}^2$$ is not settled yet, neither for von Neumann nor for Moore neighborhood (is it in $${\textsf{NC}}$$ ? is it $${\textsf{P}}$$ -complete?). In this work we study the sandpile model considering all the 256 possible sub-neighborhoods within the Moore neighborhood. Surprisingly, we found that 12 of them have a $${\textsf{P}}$$ -complete prediction problem, while for the remaining 244 neighborhoods, we prove that they do not admit a crossover gate, i.e., for them, it is impossible to cross information, if the bit of information is the presence (or absence) of an avalanche.},
  archive      = {J_NACO},
  author       = {Concha-Vega, Pablo and Goles, Eric and Montealegre, Pedro and Perrot, Kévin},
  doi          = {10.1007/s11047-024-10002-9},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {29-66},
  shortjournal = {Nat. Comput.},
  title        = {Sandpiles prediction and crossover on $$\mathbb {Z}^2$$ within moore neighborhood},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extraction rates of algorithmically random continuous
functionals. <em>NACO</em>, <em>24</em>(1), 17–28. (<a
href="https://doi.org/10.1007/s11047-024-10000-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we study the extraction rate, or output/input rate, of continuous functionals on the Cantor space $$2^\omega$$ , in particular for algorithmically random functionals. It is shown that random functionals have an average extraction rate over all inputs corresponding to the rate of producing a single bit of output, and that this average rate is attained for any sufficiently random input. We also examine functionals computed by discrete distribution generating trees, where we calculate the expected extraction rate and show that this rate is attained for any sufficiently random input.},
  archive      = {J_NACO},
  author       = {Cenzer, Douglas and Fraize, Cameron and Porter, Christopher},
  doi          = {10.1007/s11047-024-10000-x},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {17-28},
  shortjournal = {Nat. Comput.},
  title        = {Extraction rates of algorithmically random continuous functionals},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uniform robot relocation is hard in only two directions even
without obstacles. <em>NACO</em>, <em>24</em>(1), 3–16. (<a
href="https://doi.org/10.1007/s11047-024-10007-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given n unit-sized robots contained within a square grid surrounded by four walls, we ask the question of whether it is possible to move a particular robot a to a specific grid location b by performing a sequence of global step operations in which all robots move one grid step in the same cardinal direction (if not blocked by a wall or other blocked robots). We show this problem is NP-complete when restricted to just two directions (south and west). This answers the simplest fundamental problem in uniform global unit tilt swarm robotics. We then consider a relaxed version of this problem called row relocation in which the goal is to move a robot a to a specific row regardless of its horizontal placement. We show that if asking about the first row of the square grid (bottom-most), then this version of the problem is solvable in polynomial time. Finally, we discuss several areas for future research and open problems.},
  archive      = {J_NACO},
  author       = {Caballero, David and Cantu, Angel A. and Gomez, Timothy and Luchsinger, Austin and Schweller, Robert and Wylie, Tim},
  doi          = {10.1007/s11047-024-10007-4},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {3-16},
  shortjournal = {Nat. Comput.},
  title        = {Uniform robot relocation is hard in only two directions even without obstacles},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preface. <em>NACO</em>, <em>24</em>(1), 1–2. (<a
href="https://doi.org/10.1007/s11047-025-10012-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NACO},
  author       = {Genova, Daniela and Kari, Jarkko},
  doi          = {10.1007/s11047-025-10012-1},
  journal      = {Natural Computing},
  month        = {3},
  number       = {1},
  pages        = {1-2},
  shortjournal = {Nat. Comput.},
  title        = {Preface},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="nca---44">NCA - 44</h2>
<ul>
<li><details>
<summary>
(2025). Improving paraphrase generation using supervised
neural-based statistical machine translation framework. <em>NCA</em>,
<em>37</em>(11), 7705–7719. (<a
href="https://doi.org/10.1007/s00521-023-08830-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In phrase generation (PG), a sentence in the natural language is changed into a new one with a different syntactic structure but having the same semantic meaning. The present sequence-to-sequence strategy aims to recall the words and structures from the training dataset rather than learning the words&#39; semantics. As a result, the resulting statements are frequently grammatically accurate but incorrect linguistically. The neural machine translation approach suffers to handle unusual words, domain mismatch, and unfamiliar words, but it takes context well. This work presents a novel model for creating paraphrases that use neural-based statistical machine translation (NSMT). Our approach creates potential paraphrases for any source input, calculates the level of semantic similarity between text segments of any length, and encodes paraphrases in a continuous space. To evaluate the suggested model, Quora Question Pair and Microsoft Common Objects in Context benchmark datasets are used. We demonstrate that the proposed technique achieves cutting-edge performance on both datasets using automatic and human assessments. Experimental findings across tasks and datasets demonstrate that the suggested NSMT-based PG outperforms those achieved with traditional phrase-based techniques. We also show that the proposed technique may be used automatically for the development of paraphrases for a variety of languages.},
  archive      = {J_NCA},
  author       = {Razaq, Abdur and Shah, Babar and Khan, Gohar and Alfandi, Omar and Ullah, Abrar and Halim, Zahid and Ur Rahman, Atta},
  doi          = {10.1007/s00521-023-08830-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7705-7719},
  shortjournal = {Neural Comput. Appl.},
  title        = {Improving paraphrase generation using supervised neural-based statistical machine translation framework},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of tampered real time videos using deep neural
networks. <em>NCA</em>, <em>37</em>(11), 7691–7703. (<a
href="https://doi.org/10.1007/s00521-024-09988-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been a significant increase in the creation and sharing of videos that promote the utilization of digitally interactive multimedia, including music, graphics, and videos, across various devices. This trend encompasses both social networking applications and everyday tasks, mirroring the growing reliance on digital communication devices. Forgery techniques and motivations in the digital realm have undergone significant advancements. Previously, video editing methods were employed to enhance digital content. However, the proliferation of affordable and user-friendly video editing software has introduced several drawbacks and risks associated with these editing techniques. These editing tools can be misused to create misleading, altered, or fabricated videos for malicious purposes, such as spreading misinformation, deception, or defamation. In order to produce altered or fraudulent videos, additional footage is mixed, edited, or synthesized. Sophisticated editing techniques can make it challenging to detect forged videos, making it easier for forgeries to be mistakenly perceived as genuine. Existing method uses methods that detect forgery in videos with simply static backgrounds only. Proposed systems uses a deep learning strategy that incorporates transfer learning utilizing VGG16 and Customized CNN layers to categorize real time videos as tampered or authentic. With the aid of deep neural networks, the suggested method may identify forgery in films with both static and moving backgrounds. The experimental findings show that the suggested strategy is more accurate and effective than existing methods also it provides trustworthy results with low computing cost and strong detection performance.},
  archive      = {J_NCA},
  author       = {Koshy, Litty and Shyry, S. Prayla},
  doi          = {10.1007/s00521-024-09988-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7691-7703},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detection of tampered real time videos using deep neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study of progressive data flow knowledge tracing based on
reconstructed attention mechanism. <em>NCA</em>, <em>37</em>(11),
7675–7689. (<a
href="https://doi.org/10.1007/s00521-024-10011-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge tracing (KT) is an essential task in intellectual education, which measures learners’ ability to learn new knowledge by collecting historical learning information from learners. With the introduction of Recurrent Neural Networks (RNN) and Transformer into the field of KT, although effective, they focus only on the temporal order in which the learner information is affected. To model accurately, we propose a KT model BPKT (Bayesian-Attention mechanism Progressive data flow for KT) that allows exercise embedding to be layered in different forms and incorporated into the model multiple times. The BPKT model integrates the relationship between exercises covering knowledge points in both the temporal and spatial aspects, and defines a Bayesian-Attention mechanism based on this, with an in-depth analysis of the realistic meaning of the micro-parameters Q, K, and V in the mechanism. Through experiments on four real benchmark datasets, the results show that the BPKT model is helpful for predicting learners’ future responses on large-scale datasets.},
  archive      = {J_NCA},
  author       = {Wu, Qianxi and Wang, Min and Zhou, Guohui and Ji, Weidong},
  doi          = {10.1007/s00521-024-10011-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7675-7689},
  shortjournal = {Neural Comput. Appl.},
  title        = {A study of progressive data flow knowledge tracing based on reconstructed attention mechanism},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep perceptual framework for affective video tagging
through multiband EEG signals modeling. <em>NCA</em>, <em>37</em>(11),
7657–7674. (<a
href="https://doi.org/10.1007/s00521-023-09086-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, multimedia content, such as photographs and movies, is ingrained in every aspect of human lives and has become a vital component of their entertainment. Multimedia content, such as videos or movie clips, is typically created with the intent to evoke certain feelings or emotions in viewers. Thus, by examining the viewer’s cognitive state while watching such content, its affectiveness can be evaluated. Considering the emotional aspect of videos, in this paper, a deep learning-based paradigm for affective tagging of video clips is proposed, in which participants’ irrational EEG responses are used to examine how people perceive videos. The information behind different brain regions, frequency waves, and connections among them play an important role in understanding a human’s cognitive state. Thus, here a contribution is made toward the effective modeling of EEG signals through two different representations, i.e., spatial feature matrix and combined power spectral density maps. The proposed feature representations highlight the spatial features of EEG signals and are therefore used to train a convolution neural network model for implicit tagging of two categories of videos in the Arousal domain, i.e., “Low Arousal” and “High Arousal.” The arousal emotional space represents the excitement level of the viewer; thus, this domain is selected to analyze the viewer’s engagement while watching video clips. The proposed model is developed using the EEG data taken from publicly available datasets “AMIGOS” and “DREAMER.” The model is tested using two different approaches, i.e., single-subject classification and multi-subject classification, and an average accuracy of 90%-95% and 90%-93% is achieved, respectively. The simulations presented in this paper show the pioneering applicability of the proposed framework for the development of brain–computer interface (BCI) devices for affective tagging of videos.},
  archive      = {J_NCA},
  author       = {Sharma, Shanu and Dubey, Ashwani Kumar and Ranjan, Priya and Rocha, Alvaro},
  doi          = {10.1007/s00521-023-09086-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7657-7674},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep perceptual framework for affective video tagging through multiband EEG signals modeling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Denoising histopathology images for the detection of breast
cancer. <em>NCA</em>, <em>37</em>(11), 7641–7655. (<a
href="https://doi.org/10.1007/s00521-023-08771-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the leading causes of mortality for women worldwide, both in developing and developed economies, is breast cancer. The gold standard for diagnosing cancer is still histological diagnosis, despite major advances in medical understanding. Admittedly, due to the sophistication of histopathology images and the significant increase in workload, this process takes a long time. Therefore, this field requires the development of automated and precise histopathology image analysis tools. Using deep learning, we proposed a system for denoising, detecting, and classifying breast cancer using deep learning architectures that are designed to solve certain related problems. CNN-based architectures are used to extract features from images, which are then put into a fully connected layer for the classification of malignant and benign cells, as well as their subclasses, in the suggested framework. The effectiveness of the suggested framework is evaluated through experiments leveraging accepted benchmark data sets. We achieve an accuracy of 94% and an F1 score of more than 90%.},
  archive      = {J_NCA},
  author       = {Zeb, Muhammad Haider and Al-Obeidat, Feras and Tubaishat, Abdallah and Qayum, Fawad and Fazeel, Ahsan and Amin, Muhammad},
  doi          = {10.1007/s00521-023-08771-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7641-7655},
  shortjournal = {Neural Comput. Appl.},
  title        = {Denoising histopathology images for the detection of breast cancer},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic gait analysis through computer vision: A pilot
study. <em>NCA</em>, <em>37</em>(11), 7619–7639. (<a
href="https://doi.org/10.1007/s00521-023-08549-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kinesiologists who study people&#39;s posture during walking depend on spreadsheets and visual posture reviews. Gold-standard evaluation relies on expert evaluation, not mediated by technology. However, today there are technological advances to automate specific processes adequately. Our proposal focuses on developing software based on computer vision and artificial intelligence (AI) to support recognition in the gait cycle and walking activities. The software is deployed in an architecture based on microservices to support the image analysis process with high concurrency. We opted for an open-source alternative, Openpose, because it is one of the most popular detection libraries for pose estimation and is capable of real-time multi-person pose analysis. We validate the choice through a proof of concept in which we prove that it can be possible to obtain valuable results for the kinesiology care process. This software assists specialists in analyzing and measuring lower extremity angles and distances during gait. We developed an information system based on open-source pose estimation algorithms for clinical decision-making. The technological approach was obtained by analyzing similar proposals and considering the characteristics of the clinic. We used a real-time multi-person pose estimation as an essential element enabling machines to visually comprehend and analyze humans and their interactions. In this instance, we identified accuracy metrics and optimized the evaluation process time. Using a non-probabilistic sample, we analyzed the videos of users performing the gait exercises. These results indicate that although the algorithms still need to achieve perfect accuracy, they save manual work for the final evaluation. On average, using the platforms reduces by about 50% the total time required to generate the final reports delivered by the kinesiology clinic. This proposal has always been justified as a support to the professional work and not as a replacement. We propose an information system based on open-source pose estimation algorithms for clinical decision-making. The technological approach was obtained by analyzing similar proposals and considering the characteristics of the clinic. We used a real-time multi-person pose estimation as an essential element enabling machines to visually comprehend and analyze humans and their interactions. While these recognition alternatives have been explored for some time, linking with particular needs and improving healthcare processes is critical.},
  archive      = {J_NCA},
  author       = {Díaz-Arancibia, Jaime and Córdova, Matías and Arango-López, Jeferson and Ahumada, Danay and Moreira, Fernando},
  doi          = {10.1007/s00521-023-08549-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7619-7639},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic gait analysis through computer vision: A pilot study},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A non-invasive approach for calcium deficiency detection in
pears using machine learning. <em>NCA</em>, <em>37</em>(11), 7609–7618.
(<a href="https://doi.org/10.1007/s00521-023-08444-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A pear is a sweet fruit that is rich in dietary fiber, antioxidants, and plant compounds. The nutritional disorder in pears is either due to deficiency of nutrients or toxicity of nutrients. The techniques to identify the nutrients deficiencies include tissue testing, soil analysis, plant analysis, and visual deficiency symptoms. The effects of alfalfa greening, black end, and cork spot are minimised by correcting the calcium nutrition in the pear tree. In this paper, a two-class decision jungle model is proposed for the recognition of calcium deficiency in pears based on a non-invasive approach. The calcium deficiency in pears makes a bumpy fruit surface and leaves yellow color on the affected area than the rest of the skin results in the greyish corky lesion. The nutrient deficiency that results in serious disorders in pears not only influences the plant but also impacts the fruit quality. The introduction of artificial intelligence in the agriculture industry has helped farmers to produce healthier fruits. The artificial intelligence provides a real-time data for the classifier that results in increasing agricultural efficiencies, better crop yields and reduce fruit production costs by facilitating the routine and most complex tasks. The two-class decision jungle model achieves an accuracy of 98% with a database of 1000 samples. The other approaches, such as Boosted decision tree, Bayes point machine, Logistic regression, Neural Network, and SVM, have an accuracy of 92.20%, 84.3%, 72.5%, 82.4%, and 72.5%, respectively for the equivalent datasets. The highest accuracy is achieved with the proposed two class decision jungle that has non-linear decision boundaries and the performance is resilient in the presence of features that consist of noise. The number of calcium-deficient and healthy pears is 500 each. The geometrical features are extracted for the development of an artificial intelligence-based model for the classification of two classes like calcium deficient and healthy pear. The extracted features are split into training, validation, and testing. For training, validation, and testing, 80%, 10% and 10% samples are used respectively. The precision level is observed to be 0.974 and test accuracy is achieved as 98.7% and the overall accuracy 98% which are better than the existing 88.2% accuracy for pears using Support Vector Machine.},
  archive      = {J_NCA},
  author       = {Yogesh and Dubey, Ashwani Kumar and Rocha, Alvaro},
  doi          = {10.1007/s00521-023-08444-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7609-7618},
  shortjournal = {Neural Comput. Appl.},
  title        = {A non-invasive approach for calcium deficiency detection in pears using machine learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of integrated information theory: A
perspective from artificial intelligence and the cognitive sciences.
<em>NCA</em>, <em>37</em>(11), 7575–7607. (<a
href="https://doi.org/10.1007/s00521-023-08328-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of consciousness has gained momentum in recent years by the scientific community. In this same sense, the relationship between cognitive sciences and artificial intelligence presents a fundamental theoretical framework in the study of integrated information theory (IIT) as a theory that makes its way into the knowledge of consciousness. However, there are few studies that integrate these topics and a systematic review of the literature is highly pertinent. This paper seeks to identify methods, methodologies or computational solutions using artificial intelligence and cognitive science fundamentals that can provide some kind of solution to the challenges posed by IIT.},
  archive      = {J_NCA},
  author       = {Guerrero, Luz Enith and Castillo, Luis Fernando and Arango-López, Jeferson and Moreira, Fernando},
  doi          = {10.1007/s00521-023-08328-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7575-7607},
  shortjournal = {Neural Comput. Appl.},
  title        = {A systematic review of integrated information theory: A perspective from artificial intelligence and the cognitive sciences},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SureUnet: Sparse autorepresentation encoder u-net for noise
artifact suppression in low-dose CT. <em>NCA</em>, <em>37</em>(11),
7561–7573. (<a
href="https://doi.org/10.1007/s00521-023-08847-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-dose computed tomography (LDCT) is desirable due to ionizing radiation, but the resulting images suffer from serious streak artifacts and spot noise. Recently, deep learning (DL)-based methods have emerged as promising alternatives for medical image processing. However, most DL-based methods are built intuitively and lack interpretability, and it is difficult to effectively separate the artifacts and noise in LDCT images. Obtaining diagnostically useful images, especially when using a low-dose scanner protocol, remains an open challenge. To improve the quality of LDCT images, we developed a novel processing network called the sparse autorepresentation U-Net (SureUnet). First, inspired by multilayer convolutional sparse coding (CSC), we constructed a sparse autorepresentation encoder to sufficiently capture and represent hierarchical image features. Then, we chose the widely used U-Net model for sparse autorepresentation block applications and designed SureUnet by adding a feature decoding block. Therefore, every module has well-defined interpretability in our network. Additionally, hybrid loss functions were specifically designed, including the mean absolute error, edge loss and perceptual loss. Through the cooperation of multiple loss functions, the noise artifact suppression effect of the network was improved. The visual results obtained on the MAYO and UIH datasets show that the proposed method’s noise artifact suppression effect was more significant. The quantitative results showed promising improvement levels compared to those of the other state-of-the-art methods. The SureUnet model significantly outperformed the compared methods on two datasets, with margins of 0.4 dB for the PSNR, 0.007 for the SSIM, and 1.6 for the FID on the MAYO dataset and margins of 0.5 dB for the PSNR, 0.004 for the SSIM and 2.9 for the FID on the UIH dataset. This work paves the way for sparse autorepresentation in DL for processing LDCT images. Experimental results have demonstrated the competitive performance of SureUnet in terms of noise suppression, structural fidelity and visual impression improvement.},
  archive      = {J_NCA},
  author       = {Liu, Jin and Zhang, Tingyu and Kang, Yanqin and Qiang, Jun and Hu, Dianlin and Zhang, Yikun},
  doi          = {10.1007/s00521-023-08847-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7561-7573},
  shortjournal = {Neural Comput. Appl.},
  title        = {SureUnet: Sparse autorepresentation encoder U-net for noise artifact suppression in low-dose CT},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MixDA: Mixup domain adaptation for glaucoma detection on
fundus images. <em>NCA</em>, <em>37</em>(11), 7541–7560. (<a
href="https://doi.org/10.1007/s00521-023-08572-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural network has achieved promising results for automatic glaucoma detection on fundus images. Nevertheless, the intrinsic discrepancy across glaucoma datasets is challenging for the data-driven neural network approaches. This discrepancy leads to the domain gap that affects model performance and declines model generalization capability. Existing domain adaptation-based transfer learning methods mostly fine-tune pretrained models on target domains to reduce the domain gap. However, this feature learning-based adaptation method is implicit, and it is not an optimal solution for transfer learning on the diverse glaucoma datasets. In this paper, we propose a mixup domain adaptation (mixDA) method that bridges domain adaptation with domain mixup to improve model performance across divergent glaucoma datasets. Specifically, the domain adaptation reduces the domain gap of glaucoma datasets in transfer learning with an explicit adaptation manner. Meanwhile, the domain mixup further minimizes the risk of outliers after domain adaptation and improves the model generalization capability. Extensive experiments show the superiority of our mixDA on several public glaucoma datasets. Moreover, our method outperforms state-of-the-art methods by a large margin on four glaucoma datasets: REFUGE, LAG, ORIGA, and RIM-ONE.},
  archive      = {J_NCA},
  author       = {Yan, Ming and Lin, Yun and Peng, Xi and Zeng, Zeng},
  doi          = {10.1007/s00521-023-08572-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7541-7560},
  shortjournal = {Neural Comput. Appl.},
  title        = {MixDA: Mixup domain adaptation for glaucoma detection on fundus images},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diabetic retinopathy classification based on dense
connectivity and asymmetric convolutional neural network. <em>NCA</em>,
<em>37</em>(11), 7527–7540. (<a
href="https://doi.org/10.1007/s00521-022-07952-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is the leading cause of blindness in diabetics. The low contrast and microscopic nature of the lesions lead to a high false positive rate for automated DR screening. To address this issue, we propose a neural network named AC-DenseNet for the five-stage DR classification. In order to exploit the shallow features and enhance the feature extraction performance, dense connectivity is added to the convolution layer of AC-DenseNet. For the convolution layer to be more robust for DR detection in rotated or flipped pictures, asymmetric convolution branches are also introduced. In addition, attention mechanisms and auxiliary classifiers are incorporated into the network for the improvement of the performance of DR classification. We validate AC-DenseNet on the enhanced Kaggle dataset. The results show that AC-DenseNet can achieve 88.8% accuracy, 97.1% specificity, and 88.7% sensitivity, demonstrating that our model outperforms several state-of-the-art algorithms.},
  archive      = {J_NCA},
  author       = {Cao, Juan and Chen, Jiaran and Zhang, Xinying and Peng, Yang},
  doi          = {10.1007/s00521-022-07952-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7527-7540},
  shortjournal = {Neural Comput. Appl.},
  title        = {Diabetic retinopathy classification based on dense connectivity and asymmetric convolutional neural network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DH-GAC: Deep hierarchical context fusion network with
modified geodesic active contour for multiple neurofibromatosis
segmentation. <em>NCA</em>, <em>37</em>(11), 7511–7526. (<a
href="https://doi.org/10.1007/s00521-022-07945-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delineating accurately and simultaneously all lesions is vital and challenging for computer-aided diagnosis for multiple neurofibromatosis (NF). However, existing CNN-based segmentation methods paid little attention to weak boundaries. Moreover, due to the intensity-inhomogeneous distribution of medical images, the ambiguous boundaries, and highly variable locations, sizes and shapes of the lesions, delineating multiple lesions simultaneously remains quite challenging. To address these challenges, we introduce a novel end-to-end segmentation framework of multiple NF, deep hierarchical geodesic active contour (DH-GAC). It leverages the elaborately designed deep hierarchical context fusion network (DH-CFN) to improve the generalization and robustness of DH-GAC, and the modified geodesic active contour (MGAC) to delineate precisely all lesions as much as possible. Specifically, it employs DH-CFN to predict specific parameter maps of each image for MGAC and feeds them into the energy function of MGAC to delineate NF lesions, which makes DH-GAC end-to-end trainable. Moreover, to improve the generalization of DH-GAC, we adopt two different settings to initialize the surface for DH-GAC. Experimental results demonstrate that DH-GAC not only improves the segmentation precision, but also overcomes the intrinsic drawback of classical geodesic active contour in boundary delineation.},
  archive      = {J_NCA},
  author       = {Wu, Xiangqiong and Tan, Guanghua and Pu, Bin and Duan, Mingxing and Cai, Wenli},
  doi          = {10.1007/s00521-022-07945-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7511-7526},
  shortjournal = {Neural Comput. Appl.},
  title        = {DH-GAC: Deep hierarchical context fusion network with modified geodesic active contour for multiple neurofibromatosis segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CSPP-IQA: A multi-scale spatial pyramid pooling-based
approach for blind image quality assessment. <em>NCA</em>,
<em>37</em>(11), 7499–7510. (<a
href="https://doi.org/10.1007/s00521-022-07874-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional image quality assessment (IQA) methods are usually based on convolutional neural networks (CNNs). For these IQA methods using CNNs, limited by the feature size of the fully connected layer, the input image needs be tailored to a pre-defined size, which usually results in destroying the original structure and content of the input image and thus reduces the accuracy of the quality assessment. In this paper, a blind image quality assessment method (named CSPP-IQA), which is based on multi-scale spatial pyramid pooling, is proposed. CSPP-IQA allows inputting the original image when assessing the image quality without any image adjustment. Moreover, by facilitating the convolutional block attention module and image understanding module, CSPP-IQA achieved better accuracy, generalization and efficiency than traditional IQA methods. The result of experiments running on real-scene IQA datasets in this study verified the effectiveness and efficiency of CSPP-IQA.},
  archive      = {J_NCA},
  author       = {Chen, Jingjing and Qin, Feng and Lu, Fangfang and Guo, Lingling and Li, Chao and Yan, Ke and Zhou, Xiaokang},
  doi          = {10.1007/s00521-022-07874-2},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7499-7510},
  shortjournal = {Neural Comput. Appl.},
  title        = {CSPP-IQA: A multi-scale spatial pyramid pooling-based approach for blind image quality assessment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CWC-transformer: A visual transformer approach for
compressed whole slide image classification. <em>NCA</em>,
<em>37</em>(11), 7485–7497. (<a
href="https://doi.org/10.1007/s00521-022-07857-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of Artificial Intelligence (AI) technology accelerates the application of computational pathology in clinical decision-making. Due to the restriction of computing resources and annotation information, it is challenging for AI-based computational pathology methods to effectively process and analyze the gigapixel whole slide image (WSI). Conventional methods utilize multiple instance learning (MIL) to convert WSI into patches for classification. However, without the patch-level annotation, it is difficult to extract discriminative features, even with pre-trained networks. Furthermore, forcibly applying the patch-level conversion will break the pathological characteristics of WSI from the spatial structure. In this study, we present a two-stage framework named Compressed WSI Classification (CWC-Transformer) to effectively solve the problems of feature extraction and spatial information loss in WSI classification. In the compression stage, we adopt contrastive learning to present a feature compression method, which not only extracts the discriminative features but also decreases the data deviation caused by staining and scanning inconsistency. In the learning stage, we extend the advantages of the convolutional neural network and transformer mechanism to enhance the co-relations between local and global information to provide the final results jointly. Experiments on three large-scale public datasets of different tasks show that our proposed framework outperforms other advanced methods in terms of robustness and interpretation.},
  archive      = {J_NCA},
  author       = {Wang, Yaowei and Guo, Jing and Yang, Yun and Kang, Yan and Xia, Yuelong and Li, Zhenhui and Duan, Yongchun and Wang, Kelong},
  doi          = {10.1007/s00521-022-07857-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7485-7497},
  shortjournal = {Neural Comput. Appl.},
  title        = {CWC-transformer: A visual transformer approach for compressed whole slide image classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Most relevant point query on road networks. <em>NCA</em>,
<em>37</em>(11), 7473–7483. (<a
href="https://doi.org/10.1007/s00521-022-07485-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are widespread in many real-life practical applications. One of a graph’s fundamental and popular researches is investigating the relations between two given vertices. The relationship between nodes in the graph can be measured by the shortest distance. Moreover, the number of paths is also a popular metric to assess the relationship of different nodes. In many location-based services, users make decisions on the basis of both the two metrics. To address this problem, we propose a new hybrid-metric based on the number of paths with a distance constraint for road networks, which are special graphs. Based on it, a most relevant node query on road networks is identified. To handle this problem, we first propose a Shortest-Distance Constrained DFS, which uses the shortest distance to prune unqualified nodes. To further improve query efficiency, we present Batch Query DFS algorithm, which only needs only one DFS search. Our experiments on four real-life road networks demonstrate the performance of the proposed algorithms.},
  archive      = {J_NCA},
  author       = {Zhang, Zining and Yang, Shenghong and Qin, Yunchuan and Yang, Zhibang and Huang, Yang and Zhou, Xu},
  doi          = {10.1007/s00521-022-07485-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7473-7483},
  shortjournal = {Neural Comput. Appl.},
  title        = {Most relevant point query on road networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-instance discriminative contrastive learning for brain
image representation. <em>NCA</em>, <em>37</em>(11), 7459–7472. (<a
href="https://doi.org/10.1007/s00521-022-07524-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the problem of learning discriminative representation for brain images, which is a critical task toward understanding brain developments. Related studies usually extract manual and statistical features from the functional magnetic resonance images (MRIs) to differentiate brain patterns. However, these features fail to consider the implicit and high-order variances, and the existing representation methods often suffer from the weak manual features and the small-size sample. This paper introduces a weakly-supervised representation learning model, dubbed multi-instance discriminative contrastive learning (MIDCL), to identify the different MRI patterns. MIDCL yields two versions for each instance of a subject by introducing noise patterns and then achieves latent representations for them via training an encoder network and a projection network. Due to the multi-instance problem, MIDCL simultaneously minimizes an unsupervised contrastive loss (UCL) between the two representations at the level of instances and a supervised contrastive loss (SCL) between the two concatenated feature vectors at the level of subjects. We finally conducted experiments on two publicly available brain image datasets. The experiment results manifest that MIDCL could benefit from both UCL and SCL, thereby improving brain image classification performance in comparison with the state-of-the-art models.},
  archive      = {J_NCA},
  author       = {Zhang, Yupei and Liu, Shuhui and Qu, Xiran and Shang, Xuequn},
  doi          = {10.1007/s00521-022-07524-7},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {11},
  pages        = {7459-7472},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-instance discriminative contrastive learning for brain image representation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Research on mining collaborative behaviour
patterns of dynamic supply chain network from the perspective of big
data. <em>NCA</em>, <em>37</em>(10), 7457–7458. (<a
href="https://doi.org/10.1007/s00521-025-11023-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Leng, Kaijun and Jing, Linbo and Lin, I.-Ching and Chang, Sheng-Hung and Lam, Anthony},
  doi          = {10.1007/s00521-025-11023-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7457-7458},
  shortjournal = {Neural Comput. Appl.},
  title        = {Retraction note: Research on mining collaborative behaviour patterns of dynamic supply chain network from the perspective of big data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RETRACTED ARTICLE: Deep learning-based algorithm for optimum
cluster head selection in sustainable wireless communication system.
<em>NCA</em>, <em>37</em>(10), 7455. (<a
href="https://doi.org/10.1007/s00521-023-08861-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Revanesh, M. and Mary, S. A. Sahaaya Arul and Gnaneswari, G. and Jones, G. Maria and Kanimozhi, K. V. and Kamalam, G. K.},
  doi          = {10.1007/s00521-023-08861-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7455},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Deep learning-based algorithm for optimum cluster head selection in sustainable wireless communication system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RETRACTED ARTICLE: Energy-efficient and sustainable
communication in optical networks for eliminating path reservation
criteria and providing guaranteed packet transmission between nodes.
<em>NCA</em>, <em>37</em>(10), 7453. (<a
href="https://doi.org/10.1007/s00521-023-08866-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Asha, P. and Kalaavathi, B. and Shantha Kumari, K. and Malarvizhi, K. and Kishore Kumar, A. and Sobitha Ahila, S.},
  doi          = {10.1007/s00521-023-08866-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7453},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Energy-efficient and sustainable communication in optical networks for eliminating path reservation criteria and providing guaranteed packet transmission between nodes},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RETRACTED ARTICLE: Analysis of complex cognitive task and
pattern recognition using distributed patterns of EEG signals with
cognitive functions. <em>NCA</em>, <em>37</em>(10), 7451. (<a
href="https://doi.org/10.1007/s00521-020-05439-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Zhao, Jianyu and Li, Ke and Xi, Xi and Wang, Shanshan and Saravanan, Vijayalakshmi and Samuel, R. Dinesh Jackson},
  doi          = {10.1007/s00521-020-05439-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7451},
  shortjournal = {Neural Comput. Appl.},
  title        = {RETRACTED ARTICLE: Analysis of complex cognitive task and pattern recognition using distributed patterns of EEG signals with cognitive functions},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Leveraging large language models for word sense
disambiguation. <em>NCA</em>, <em>37</em>(10), 7449–7450. (<a
href="https://doi.org/10.1007/s00521-025-11082-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Yae, Jung H. and Skelly, Nolan C. and Ranly, Neil C. and LaCasse, Phillip M.},
  doi          = {10.1007/s00521-025-11082-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7449-7450},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Leveraging large language models for word sense disambiguation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Securing IIoT operations with recurrent
federated network-based enhanced local search grasshopper. <em>NCA</em>,
<em>37</em>(10), 7447. (<a
href="https://doi.org/10.1007/s00521-024-10907-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Alassafi, Madini O.},
  doi          = {10.1007/s00521-024-10907-7},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7447},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Securing IIoT operations with recurrent federated network-based enhanced local search grasshopper},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: Software effort estimation using convolutional
neural network and fuzzy clustering. <em>NCA</em>, <em>37</em>(10),
7445. (<a href="https://doi.org/10.1007/s00521-024-10906-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Azzeh, Mohammad and Alkhateeb, Abedalrhman and Nassif, Ali Bou},
  doi          = {10.1007/s00521-024-10906-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7445},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: Software effort estimation using convolutional neural network and fuzzy clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: An artificial intelligence strategy for the
deployment of future microservice-based applications in 6G networks.
<em>NCA</em>, <em>37</em>(10), 7443. (<a
href="https://doi.org/10.1007/s00521-024-10754-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NCA},
  author       = {Ssemakula, John Bosco and Gorricho, Juan-Luis and Kibalya, Godfrey and Serrat-Fernandez, Joan},
  doi          = {10.1007/s00521-024-10754-6},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7443},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correction: An artificial intelligence strategy for the deployment of future microservice-based applications in 6G networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CONELPABO: Composite networks learning via parallel bayesian
optimization to predict remaining useful life in predictive maintenance.
<em>NCA</em>, <em>37</em>(10), 7423–7441. (<a
href="https://doi.org/10.1007/s00521-025-10995-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintaining equipment and machinery in industries is imperative for maximizing operational efficiency and prolonging their lifespan. The adoption of predictive maintenance enhances resource allocation, productivity, and product quality by proactively identifying and addressing potential equipment anomalies through rigorous data analysis before they escalate into critical issues. Consequently, these measures strengthen market competitiveness and generate favorable economic outcomes. In many applications, sensors operate at high frequencies or capture data over extended periods. This work introduces CONELPABO (Composite Networks Learning via Parallel Bayesian Optimization), a framework for analyzing long time series data, particularly for predicting the remaining useful life of a system or component. It uses a divide-and-conquer strategy to manage the exponential growth in the hyperparameter search space during Bayesian Optimization and to accelerate model training by 50%. Additionally, this strategy enables the training of deeper networks with limited resources. The usefulness of the framework is demonstrated through two case studies, in which it achieves state-of-the-art results, showing that CNN-CNN and RNN-RNN architectures are highly effective for long time-series data. These architectures outperform many existing approaches and challenge the common academic focus on CNN-RNN hybrids.},
  archive      = {J_NCA},
  author       = {Solís-Martín, David and Galán-Páez, Juan and Borrego-Díaz, Joaquín},
  doi          = {10.1007/s00521-025-10995-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7423-7441},
  shortjournal = {Neural Comput. Appl.},
  title        = {CONELPABO: Composite networks learning via parallel bayesian optimization to predict remaining useful life in predictive maintenance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic economic dispatch with uncertain wind power
generation using an enhanced artificial hummingbird algorithm.
<em>NCA</em>, <em>37</em>(10), 7397–7422. (<a
href="https://doi.org/10.1007/s00521-025-10982-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimum scheduling of the conventional thermal generators for three different dynamic test systems is percolated in this article. In pursuit of this objective, a developed version of a recent optimization algorithm, denoted as the leader artificial hummingbird algorithm, is introduced. The profile with the largest penetration of wind energy is obtained by calculating wind power from hourly wind speed using the Weibull distribution density function. After that, the test system and the wind profiles were connected to carry out dynamic economic dispatch (DED). The DED problem with wind uncertainty poses important challenges because of its complication, considered by multiple constraints including ramp rate limits and the valve-point effects (VPEs), nonconvexity, and nonlinearity, as well as the uncertainty of the wind energy. These complications make it critical to discover innovative optimization algorithms to find optimum solutions for the DED problem. First, in order to demonstrate the validity of the suggested LAHA approach in comparison with four contemporary techniques, simulations are run on 23 benchmark functions. Next, the 5-unit, 10-unit with/without transmission losses, 15-unit, modified 10-unit with transmission losses, and wind power test systems are used to evaluate the LAHA’s performance. The numerical results demonstrate how competitive the suggested approach is in reaching reduced total generation cost when compared to the other documented optimization algorithms.},
  archive      = {J_NCA},
  author       = {Hassan, Mohamed H. and Mohamed, Ehab Mahmoud and Kamel, Salah and Eslami, Mahdiyeh},
  doi          = {10.1007/s00521-025-10982-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7397-7422},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic economic dispatch with uncertain wind power generation using an enhanced artificial hummingbird algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AutoML for shape-writing biometrics. <em>NCA</em>,
<em>37</em>(10), 7379–7396. (<a
href="https://doi.org/10.1007/s00521-025-10983-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape-writing is a text entry method that allows users to type words on mobile devices by gliding their finger across the keyboard from one character to the next. This creates a trajectory of touch coordinates that contains rich information about the user. Previous work exploited this information to create Machine Learning (ML) models to predict demographic and behavioral targets, such as age, nationality, or handedness. However, previous work used pseudo-grid search, which is a bit tedious and rather inefficient. We show how to find better models with Automated Machine Learning (AutoML), by completely automating the architecture design process, outperforming all models reported in previous work. Our study suggests that researchers should incorporate AutoML to their training pipelines, as classification performance will likely be better than manually designing the model architecture. Taken together, our results show that it is possible to decode user’s latent information from shape-writing trajectories with higher performance than previously reported.},
  archive      = {J_NCA},
  author       = {Weber, Louis and Leiva, Luis A.},
  doi          = {10.1007/s00521-025-10983-3},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7379-7396},
  shortjournal = {Neural Comput. Appl.},
  title        = {AutoML for shape-writing biometrics},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing facial expression recognition in uncontrolled
environment: A lightweight CNN approach with pre-processing.
<em>NCA</em>, <em>37</em>(10), 7363–7378. (<a
href="https://doi.org/10.1007/s00521-025-10974-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expressions play a key role in human non-verbal type of communication, providing key insights into emotions and intentions. These expressions serve as universal signals, helping individuals convey their internal states across various personal and social contexts. With the growing interest in automatic facial emotion recognition, deep neural networks have emerged as a popular approach for detecting human emotions, even under challenging, real-world conditions. However, external factors can affect the system&#39;s performance, degrading the quality of facial features and making emotion detection more difficult. In the presented paper, we propose a highly optimized lightweight convolutional neural network (LCNN) for emotion recognition in controlled and uncontrolled environments. The proposed model is designed to learn hidden nonlinear patterns from facial images. The proposed convolutional neural network consisting a series of convolutional layers followed by max-pooling layers. The model&#39;s performance is evaluated with and without pre-processing steps to highlight the importance of pre-processing in improving detection accuracy. The LCNN achieves 65% accuracy on the FER-2013 dataset and 98% on the CK + dataset.},
  archive      = {J_NCA},
  author       = {Grover, Richa and Bansal, Sandhya},
  doi          = {10.1007/s00521-025-10974-4},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7363-7378},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing facial expression recognition in uncontrolled environment: A lightweight CNN approach with pre-processing},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing electroencephalogram signal quality in epileptic
patients using bidirectional stochastic long short-term memory network.
<em>NCA</em>, <em>37</em>(10), 7339–7361. (<a
href="https://doi.org/10.1007/s00521-025-10977-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artifacts frequently disrupt electroencephalogram (EEG) signal recordings, originating from diverse sources such as eye-blinks and muscle twitches. These artifacts present significant challenges when employing automated systems for diagnosing neurological disorders. In this research, we introduce an innovative architectural solution designed to effectively eliminate these artifacts from EEG signals acquired from individuals with epilepsy. Our proposed framework combines bidirectional long short-term memory networks with bidirectional stochastic configuration networks (BSCN). This integration empowers the model to discern intricate patterns within both past and future time steps of the EEG signal. Furthermore, the non-iterative training characteristic of the BSCN-based classifier enhances training efficiency. To assess the effectiveness of our approach, we conducted experiments on four epilepsy datasets and a sleep dataset. The performance of our novel technique was evaluated using a range of performance metrics, and the results unequivocally indicate its superiority over existing artifact removal methods.},
  archive      = {J_NCA},
  author       = {Pandey, Anviti and Singh, Sanjay Kumar and Udmale, Sandeep S. and Shukla, K. K.},
  doi          = {10.1007/s00521-025-10977-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7339-7361},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing electroencephalogram signal quality in epileptic patients using bidirectional stochastic long short-term memory network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel human actions recognition and classification using
semantic segmentation with deep learning techniques. <em>NCA</em>,
<em>37</em>(10), 7321–7337. (<a
href="https://doi.org/10.1007/s00521-024-10962-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel method for recognizing human actions through the semantic segmentation of images. The aim is to enhance action-motion dynamics by directing attention toward regions crucial for action recognition. The proposed approach utilizes a SegNet model with an incorporated attention mechanism and modified bidirectional gated recurrent unit (BiGRU) backbone. The process begins with the generation of binary masks for each frame in a video dataset, achieved through a combination of grayscale conversion, Gaussian blurring, and adaptive thresholding. The emphasis on crucial regions for action recognition and capturing temporal variations is heightened through the application of the frame-ranking method. In our experiments, we observed that the proposed method significantly enhances the dynamics of the action-motion representation. The SegNet architecture was designed for semantic segmentation tasks and features an encoder-decoder architecture. In this structure, the model performs hierarchical feature extraction from the input image via the encoder, whereas the decoder focuses on reconstructing the segmented output. Attention is paid to the encoded feature maps, augmenting the model&#39;s capability to capture dependencies over extensive spatial ranges. A bidirectional GRU layer is employed to capture the sequential dependencies in the concatenated feature maps. The integration of the SegNet model with the attention mechanism and a BiGRU backbone, featuring an encoder-decoder architecture for feature extraction, classification, and segmentation, demonstrated superior performance in capturing nuanced spatiotemporal features. The proposed method demonstrated an accuracy of 98.52% for UCF101 and 84.25% for HMDB51. The findings reveal that the model achieves state-of-the-art results in human action recognition tasks, outperforming the existing methods in terms of accuracy. The combination of semantic segmentation and BiGRU-based temporal modeling proved effective in discerning intricate patterns of human motion, showcasing its potential for real-world applications in video analysis and surveillance systems.},
  archive      = {J_NCA},
  author       = {Jayamohan, M. and Yuvaraj, S.},
  doi          = {10.1007/s00521-024-10962-0},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7321-7337},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel human actions recognition and classification using semantic segmentation with deep learning techniques},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quasi-synchronization analysis of heterogeneous neural
networks with multiple delays under impulsive control. <em>NCA</em>,
<em>37</em>(10), 7303–7319. (<a
href="https://doi.org/10.1007/s00521-024-10948-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the quasi-synchronization of impulsive controlled heterogeneous dynamic neutral networks with time-varying delay, distributed delays and proportional delay is discussed. Compared with the existing literature, the significant advantage of this paper is that all three types of delays are taken into account. Here we consider time-varying delay depending on probability distribution conditions, so the results of this paper also rely on the problem of probability distribution of time-varying delay. By establishing a suitable comparison system, creating a new kind of impulsive delay inequality and applying Bernoulli distributions and Lyapunov theory, some conditions to realize quasi-synchronization of heterogeneous neural networks are studied. Finally we illustrate the validity of our theorem with numerical examples.},
  archive      = {J_NCA},
  author       = {Wang, Qing and Guo, Yingxin and Zhang, Chuan and Fu, Jianting},
  doi          = {10.1007/s00521-024-10948-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7303-7319},
  shortjournal = {Neural Comput. Appl.},
  title        = {Quasi-synchronization analysis of heterogeneous neural networks with multiple delays under impulsive control},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced model for abstractive arabic text summarization
using natural language generation and named entity recognition.
<em>NCA</em>, <em>37</em>(10), 7279–7301. (<a
href="https://doi.org/10.1007/s00521-024-10949-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of Arabic digital content, effective summarization methods are essential. Current Arabic text summarization systems face challenges such as language complexity and vocabulary limitations. We introduce an innovative framework using Arabic Named Entity Recognition to enhance abstractive summarization, crucial for NLP applications like question answering and knowledge graph construction. Our model, based on natural language generation techniques, adapts to diverse datasets. It identifies key information, synthesizes it into coherent summaries, and ensures grammatical accuracy through deep learning. Evaluated on the EASC dataset, our model achieved a 74% ROUGE1 score and a 97.6% accuracy in semantic coherence, with high readability and relevance scores. This sets a new standard for Arabic text summarization, greatly improving NLP information processing.},
  archive      = {J_NCA},
  author       = {Essa, Nada and El-Gayar, M. M. and El-Daydamony, Eman M.},
  doi          = {10.1007/s00521-024-10949-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7279-7301},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced model for abstractive arabic text summarization using natural language generation and named entity recognition},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-light few-shot object detection via curve contrast
enhancement and flow-encoder-based variational autoencoder.
<em>NCA</em>, <em>37</em>(10), 7261–7278. (<a
href="https://doi.org/10.1007/s00521-024-10885-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problem of insufficient samples in low-light object detection in some environments, a low-light few-shot object detection method based on curve contrast enhancement and flow-encoder-based variational autoencoder (CCEFVAE) is proposed. Our approach involves designing a CCE module to enhance the detailed features and contrast of low-light images by deriving a relationship expression between the enhanced image and the low-light image through the recursive relationship of high-order curves. The lumination estimation module in the CCE module estimates the parameters of the expression to calculate the pixel values of the enhanced image. Moreover, we propose an FVAE module to improve the decoupling of support features by combining the flow model encoder with the variational autoencoder, facilitating subsequent feature aggregation and classification. To ensure the consistency of the loss function of the flow model with the few-shot object detection loss, we design a negative Jacobian determinant transformation function. This enables direct addition of the two losses, allowing for unified optimization. Experimental results demonstrate that our proposed algorithm outperforms mainstream few-shot object detection models by an average of 13.1–23% in average after training on the low-light dataset (ExDark), and shows an average improvement of 5.8% compared to the state-of-the-art (SOTA) few-shot object detection model VFA. When trained on the normal lighting dataset (PASCAL VOC), the proposed algorithm exhibits a 1.7% improvement in average compared to VFA.},
  archive      = {J_NCA},
  author       = {Jiang, Zetao and Jin, Xin and Kang, Junjie},
  doi          = {10.1007/s00521-024-10885-w},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7261-7278},
  shortjournal = {Neural Comput. Appl.},
  title        = {Low-light few-shot object detection via curve contrast enhancement and flow-encoder-based variational autoencoder},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supercell thunderstorm algorithm (STA): A nature-inspired
metaheuristic algorithm for engineering optimization. <em>NCA</em>,
<em>37</em>(10), 7207–7260. (<a
href="https://doi.org/10.1007/s00521-024-10848-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an optimization algorithm called supercell thunderstorm algorithm (STA) is proposed. STA draws inspiration from the strategies employed by storms, such as spiral motion, tornado formation, and the jet stream. It is a computational algorithm specifically designed to simulate and model the behavior of supercell thunderstorms. These storms are known for their rotating updrafts, strong wind shear, and potential for generating tornadoes. The optimization procedures of the STA algorithm are based on three distinct approaches: exploring a divergent search space using spiral motion, exploiting a convergent search space through tornado formation, and navigating through the search space with the aid of the jet stream. To evaluate the effectiveness of the proposed STA algorithm in achieving optimal solutions for various optimization problems, a series of test sequences were conducted. Initially, the algorithm was tested on a set of 23 well-established functions. Subsequently, the algorithm’s performance was assessed on more complex problems, including ten CEC2019 test functions, in the second experimental sequence. Finally, the algorithm was applied to five real-world engineering problems to validate its effectiveness. The experimental results of the STA algorithm were compared to those of contemporary metaheuristic methods. The analysis clearly demonstrates that the developed STA algorithm outperforms other methods in terms of performance.},
  archive      = {J_NCA},
  author       = {Hassan, Mohamed H. and Kamel, Salah},
  doi          = {10.1007/s00521-024-10848-1},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7207-7260},
  shortjournal = {Neural Comput. Appl.},
  title        = {Supercell thunderstorm algorithm (STA): A nature-inspired metaheuristic algorithm for engineering optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond administrative reports: A deep learning framework for
classifying and monitoring crime and accidents leveraging large-scale
online news. <em>NCA</em>, <em>37</em>(10), 7183–7205. (<a
href="https://doi.org/10.1007/s00521-024-10833-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The escalating prevalence of violent crimes and accidents underscores the urgent need for efficient and timely monitoring systems. Traditional methods reliant on administrative reports often suffer from significant delays. This paper proposes CRIMSON, a novel framework that leverages large-scale online news to provide real-time insights into crime and accident trends. CRIMSON utilizes a multi-label classification technique that leverages a fine-tuned, pre-trained, cross-lingual language model to accurately categorize news articles. Our experimental results, conducted on a substantial dataset of Thai news articles, demonstrate superior performance, achieving an average F1 score of 86%. Beyond classification, CRIMSON aggregates categorized news into real-time statistics, revealing strong correlations between news-reported incidents and official crime data. This study pioneers online news as a reliable and timely crime and accident monitoring source, offering valuable insights for law enforcement, policymakers, and researchers.},
  archive      = {J_NCA},
  author       = {Tuarob, Suppawong and Tatiyamaneekul, Phonarnun and Pongpaichet, Siripen and Tawichsri, Tanisa and Noraset, Thanapon},
  doi          = {10.1007/s00521-024-10833-8},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7183-7205},
  shortjournal = {Neural Comput. Appl.},
  title        = {Beyond administrative reports: A deep learning framework for classifying and monitoring crime and accidents leveraging large-scale online news},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GP-PSENet: A group-related dilated and a parallel
extensional dilation-wise residual encoder for scene text detection.
<em>NCA</em>, <em>37</em>(10), 7159–7181. (<a
href="https://doi.org/10.1007/s00521-024-10688-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, scene text detection is grabbing more and more attention as an offshoot of machine vision. However, due to the existing long types of text instances and complex background context, less exact localization and higher missed detection cases still remain in text detection domain. Accordingly, with the aim of tackling these two issues, we propose a text detector named GP-PSENet that comprises a combination of a group-related dilated encoder, a parallel extensional dilation-wise residual encoder and a mixed upsample. Firstly, feature maps of the lowest level processed by the backbone network are sent to a dilated encoder with group linkage. And the group residual module provides stratification to join group coefficients and dilated factors. This module can enhance the correctness of predictions about longer boundary boxes. Secondly, semantic information from the highest level is fed into a parallel extensional dilation-wise residual encoder. The extensional dilation-wise module is capable of obtaining diverse receptive fields by more parallel branches. And it can alleviate error detection from interfering material in the background. Thirdly, the feature maps processed in the second step are given to the mixed upsample module for transforming so as to the next fuse. Finally, the processed two-level feature maps are fused and sent to the progressive scale expansion algorithm for the final post-processing to gain the predicted coordinate points. Ablation experiments are conducted on CTW1500, ICDAR15, MSRA-TD500 and Total-Text datasets to confirm the availability of the proposed method. The values of precision on these datasets reach 86.24%, 87.84%, 73.98% and 90.48%. The proposed method is also competitive with other scene detection methods.},
  archive      = {J_NCA},
  author       = {Huang, Liwen and Yang, Wenyuan},
  doi          = {10.1007/s00521-024-10688-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7159-7181},
  shortjournal = {Neural Comput. Appl.},
  title        = {GP-PSENet: A group-related dilated and a parallel extensional dilation-wise residual encoder for scene text detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time optimal energy management of microgrid based on
multi-agent proximal policy optimization. <em>NCA</em>, <em>37</em>(10),
7145–7157. (<a
href="https://doi.org/10.1007/s00521-024-10654-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to achieve economic operation of the microgrid (MG), energy management problem (EMP) has attracted attention from scholars worldwide. In order to overcome the lack of flexibility when coping with uncertainties and topology changes, a multi-agent based proximal policy optimization algorithm (MAPPO) is proposed in this paper. Different from the offline training and online implementing mode, the proposed decentralized MAPPO algorithm has the characteristic of online training and online application, which can get higher optimization efficiency and lower communication burden. Taking into account users’ satisfaction, renewable energy utilization rate and operating costs, an optimization model is established. Aiming at the difficulty on satisfying the power balance constraint in EMPU using reinforcement learning (RL), a novel power imbalance penalty is designed. Compared with the traditional penalty function, the proposed penalty function can effectively avoid the phenomenon of power imbalance. Finally, 24-hour energy management results are provided to verify the effectiveness of the proposed algorithm. Moreover, the proposed MAPPO is compared with several popular multi-agent based RL algorithms. Simulation results show that the proposed algorithm has higher efficiency and can obtain better energy management strategies.},
  archive      = {J_NCA},
  author       = {Wang, Danlu and Sun, Qiuye and Su, Hanguang},
  doi          = {10.1007/s00521-024-10654-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7145-7157},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time optimal energy management of microgrid based on multi-agent proximal policy optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal consistent loss diffusion model for sentinel-3
single image super resolution. <em>NCA</em>, <em>37</em>(10), 7121–7143.
(<a href="https://doi.org/10.1007/s00521-024-10573-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of Earth observation, the trade-off between spatial, spectral, and temporal resolution often limits the versatility of remote sensing images in many important applications. In response, this paper introduces a novel deep learning diffusion model, specifically tailored to improve the spatial resolution of the optical products acquired by the Sentinel-3 (S3) satellite. Our framework employs a diffusion probabilistic model, benefiting from the higher spatial resolution of the Sentinel-2 satellite during training via a new multi-modal loss formulation. This ensures consistency with the original S3 images while enhancing the spatial details. Two distinct conditional low-resolution encoders were experimented with, providing insights into their respective contributions to the diffusion process. The efficacy of the proposed model is demonstrated through extensive ablation studies and comparisons with state-of-the-art methods, using both synthetic and real S3 products. The findings indicate that our model successfully improves spatial resolution while maintaining the integrity of the spectral information, contributing to the field of remote sensing single-image super-resolution.},
  archive      = {J_NCA},
  author       = {Ibañez, Damian and Fernandez-Beltran, Ruben and Pla, Filiberto and Yokoya, Naoto and Xia, Junshi},
  doi          = {10.1007/s00521-024-10573-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7121-7143},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-modal consistent loss diffusion model for sentinel-3 single image super resolution},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic generative r-CNN. <em>NCA</em>, <em>37</em>(10),
7107–7120. (<a
href="https://doi.org/10.1007/s00521-024-10739-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different techniques have been developed for object detection and recognition. These techniques can be divided into single-shot and two-shot methods. Single-shot methods focus on real-time applications, while two-shot methods are used in applications requiring higher accuracy. However, different versions of the two-shot techniques produce limited results in terms of accuracy and speed, or both. Therefore, this study proposes a novel model called dynamic generative R-CNN (DGR-CNN) that reduces the number of proposed regions using a dynamic programming model that applies the graph similarity method over graph-based image segmentation. Additionally, the proposed model employs DCGAN technique to improve detection performance. DGR-CNN reduces the overall detection and classification time and enhances the detection accuracy. The PASCAL VOC2007 and MS COCO datasets were utilized to evaluate the model. The results showed that DGR-CNN significantly reduces the number of candidate regions compared to the selective search algorithm employed in R-CNN and fast R-CNN. Although fast R-CNN utilizes 2000 regions and faster R-CNN utilizes 300 regions, DGR-CNN reduces the number of regions to approximately 130. The mean average precision of the proposed method was 75.1% on the PASCAL VOC2007, while fast and faster R-CNN scored 66.9% and 69.9%, respectively. Moreover, the DGR-CNN model significantly improved the classification accuracy when tested on the MS COCO dataset, achieving an MAP of 68.76%, compared with 32.64% and 42.3% for fast and faster R-CNN. This increase in accuracy was achieved without significantly compromising the speed compared with faster R-CNN.},
  archive      = {J_NCA},
  author       = {Saffarini, Rasha and Khamayseh, Faisal and Awwad, Yousef and Sabha, Muath and Eleyan, Derar},
  doi          = {10.1007/s00521-024-10739-5},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7107-7120},
  shortjournal = {Neural Comput. Appl.},
  title        = {Dynamic generative R-CNN},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing a continuous action learning automata (CALA)
optimizer for training artificial neural networks. <em>NCA</em>,
<em>37</em>(10), 7089–7105. (<a
href="https://doi.org/10.1007/s00521-024-10546-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep artificial neural networks (ANNs) get bigger, deeper, and used in more challenging applications, the need for non-gradient based training methods becomes more desirable. This paper explores a new non-gradient-based method to train ANNs and deep ANNs, the Continuous Action Learning Automata (CALA) optimizer. The CALA optimizer assigns a Learning Automata agent to every weight in a neural network and uses game theory to coordinate actions of the agents. We show that the CALA optimizer is computationally efficient, that it converges to a desired error rate faster than current gradient-based methods like stochastic gradient descent (SGD) and show how one could use a Finite Action Learning Automata (FALA) algorithm to find optimal values for the hyper-parameters required to optimize the CALA controller. The CALA method contrasts itself against other non-gradient methods in that it approaches the computational efficiency of top gradient descent methods like SGD. The CALA method converges fast, and there is any easy-to-follow algorithm to tune the hyper-parameters of the algorithm. These advantages address weaknesses that other non-gradient methods suffer from. Therefore, the CALA controller has the potential to see far greater implementation than other non-gradient-based optimization methods for training deep ANNs.},
  archive      = {J_NCA},
  author       = {Lindsay, James and Givigi, Sidney},
  doi          = {10.1007/s00521-024-10546-y},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7089-7105},
  shortjournal = {Neural Comput. Appl.},
  title        = {Optimizing a continuous action learning automata (CALA) optimizer for training artificial neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive dual-weighted feature network for insulator
detection in transmission lines. <em>NCA</em>, <em>37</em>(10),
7067–7087. (<a
href="https://doi.org/10.1007/s00521-024-10957-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of electrical power applications, high-voltage insulators necessitate routine inspection to assure the security and stability of the whole electric power system operation. Accurately positioning the insulator is extremely crucial for proceeding to the insulator defect detection. However, during UAV electrical line inspection, the presence of the electric power line magnetic field engenders a reduction in the pixel representation of the insulator within the image data, thereby diminishing the accuracy of insulator detection. In response to the prevailing issues, we present the creation of the adaptive dual-weighted feature network in this paper. Simultaneously, we create an insulator dataset to substantiate the effectiveness of enhanced model in detecting small insulators. Firstly, the integration of context fusion network is employed to capture comprehensive contextual features for each effective feature map. In addition, a cross-scale residual perception network is incorporated into the neck prior to three concatenation modules, facilitating the collection of diverse information across levels. Finally, a Dual-Weighted Feature Fusion module is designed to replace the conventional concatenation pattern within the neck, thus achieving a more precise representation of object features. Experiments are conducted on the insulator dataset, the RSOD dataset and the NWPU VHR-10 dataset to evaluate the designed model, resulting in mAP values that were 3.92%, 1.55% and 2.39% higher than the YOLOv7, respectively.},
  archive      = {J_NCA},
  author       = {Zhang, Jie and Wang, Xiabing and Li, Yinhua and Li, Dailin and Wang, Fengxian and Li, Linwei and Zhang, Huanlong and Shi, Xiaoping},
  doi          = {10.1007/s00521-024-10957-x},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7067-7087},
  shortjournal = {Neural Comput. Appl.},
  title        = {An adaptive dual-weighted feature network for insulator detection in transmission lines},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward better semantic segmentation by retaining spectral
information using matched wavelet pooling. <em>NCA</em>,
<em>37</em>(10), 7049–7066. (<a
href="https://doi.org/10.1007/s00521-025-11008-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pooling operations, such as average pooling, strided convolution, and max pooling, have become fundamental components of convolutional neural networks (CNNs) due to their ability to capture local features, expand receptive fields, and reduce computational costs. However, in the context of semantic segmentation, these pooling techniques can lead to the loss of crucial spatial details that are necessary for accurate pixel-level predictions. To tackle this issue, extensive research has focused on refining deep CNN models through architectural adaptations and novel training methods. Recent studies have demonstrated the importance of pooling layers, exemplified by innovations like the introduction of wavelet pooling. In our study, we highlight the value of incorporating our previously proposed matched wavelet pooling (MWP) into CNNs to enhance semantic segmentation pipelines. The core concept of MWP challenges the notion that including all sub-bands generated from wavelet decomposition consistently improves accuracy. Instead, we advocate for selecting specific sub-bands for the pooling process in each image during both training and testing. This approach introduces sub-band selection protocols customized for image-specific pooling, designed specifically for semantic segmentation CNN architectures, with a particular focus on the UNet and SegNet models. Across three widely used datasets, our proposed MWP- based pipeline, featuring the MWP-UNet architecture, consistently outperforms conventional pooling methods. It achieves a significant average improvement in intersection over union (IoU) of over 25% compared to recent literature. Additionally, our MWP-SegNet model outperformed the standard SegNet by 12.5% mIoU, further demonstrating the effectiveness of our matched wavelet pooling approach across different network architectures.},
  archive      = {J_NCA},
  author       = {El-Khamy, Said and El-Bana, Shimaa and Al-Kabbany, Ahmad and Elragal, Hassan},
  doi          = {10.1007/s00521-025-11008-9},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7049-7066},
  shortjournal = {Neural Comput. Appl.},
  title        = {Toward better semantic segmentation by retaining spectral information using matched wavelet pooling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey on arabic text augmentation:
Approaches, challenges, and applications. <em>NCA</em>, <em>37</em>(10),
7015–7048. (<a
href="https://doi.org/10.1007/s00521-025-11020-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arabic is a linguistically complex language with a rich structure and valuable syntax that pose unique challenges for natural language processing (NLP), primarily due to the scarcity of large, reliable annotated datasets essential for training models. The varieties of dialects and mixtures of more than one language within a single conversation further complicate the development and efficacy of deep learning models targeting Arabic. Data augmentation (DA) techniques have emerged as a promising solution to tackle data scarcity and improve model performance. However, implementing DA in Arabic NLP presents its challenges, particularly in maintaining semantic integrity and adapting to the language’s intricate morphological structure. This survey comprehensively examines various aspects of Arabic data augmentation techniques, covering strategies for model training, methods for evaluating augmentation performance, understanding the effects and applications of augmentation on data, studying NLP downstream tasks, addressing augmentation problems, proposing solutions, conducting in-depth literature reviews, and drawing conclusions. Through detailed analysis of 75 primary and 9 secondary papers, we categorize DA methods into diversity enhancement, resampling, and secondary approaches, each targeting specific challenges inherent in augmenting Arabic datasets. The goal is to offer insights into DA effectiveness, identify research gaps, and suggest future directions for advancing NLP in Arabic.},
  archive      = {J_NCA},
  author       = {ElSabagh, Ahmed Adel and Azab, Shahira Shaaban and Hefny, Hesham Ahmed},
  doi          = {10.1007/s00521-025-11020-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {7015-7048},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive survey on arabic text augmentation: Approaches, challenges, and applications},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding silent speech: A machine learning perspective on
data, methods, and frameworks. <em>NCA</em>, <em>37</em>(10), 6995–7013.
(<a href="https://doi.org/10.1007/s00521-024-10456-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At the nexus of signal processing and machine learning (ML), silent speech recognition (SSR) has evolved as a game-changing technology that allows for communication without audible voice. This study offers a thorough overview of SSR, tracing its evolution from early waveform analysis to the most recent ML methods. We start by examining current SSR techniques using ML and determining the essential conditions for efficient SSR systems. After that, we look at the datasets and data collection techniques currently employed in SSR research, highlighting the difficulties posed by the variety of articulatory movements and the scarcity of data. Examining state-of-the-art SSR frameworks, the paper covers important topics such signal processing, feature extraction, ML techniques for decoding and optimizing and assessing the performance of SSR models. We emphasize how deep learning (DL) and ML models have evolved to increase SSR resilience and accuracy. The field&#39;s proposed procedures are examined, with an emphasis on sophisticated feature extraction and classification methods. Modern SSR techniques are compared in terms of performance, highlighting the advantages and disadvantages of different models. There is also discussion of ethical issues, especially those pertaining to privacy and consent. The integration of multimodal information—visual cues, electromyography signals, and neuroimaging data—to improve SSR systems is covered in this work. We investigate the functions of transfer learning and domain adaptation in handling cross-subject variability. Lastly, the study offers suggestions and future prospects for SSR research, providing practitioners, engineers, and academics with a road map. As SSR continues to push the frontiers of human–machine interaction, our study aims to increase our collective understanding of the technological advances and societal effects of SSR in the ML age.},
  archive      = {J_NCA},
  author       = {Chowdhury, Adiba Tabassum and Newaz, Mehrin and Saha, Purnata and AbuHaweeleh, Mohannad Natheef and Mohsen, Sara and Bushnaq, Diala and Chabbouh, Malek and Aljindi, Raghad and Pedersen, Shona and Chowdhury, Muhammad E. H.},
  doi          = {10.1007/s00521-024-10456-z},
  journal      = {Neural Computing and Applications},
  month        = {4},
  number       = {10},
  pages        = {6995-7013},
  shortjournal = {Neural Comput. Appl.},
  title        = {Decoding silent speech: A machine learning perspective on data, methods, and frameworks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="npl---13">NPL - 13</h2>
<ul>
<li><details>
<summary>
(2025). Character-level encoding based neural machine translation
for hindi language. <em>NPL</em>, <em>57</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s11063-025-11718-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Machine Translation (NMT) is one step ahead of traditional statistical phrase-based translation systems because of its better translation ability. But it requires a large amount of parallel training data, which can be challenging for languages with limited resources like many Indian languages. In the past, researchers have tried to address the issue using data augmentation. In this paper, we present a data augmentation technique for the Hindi language based on five phrases: noun phrases, verb phrases, prepositional phrases, adjective phrases, and adverb phrases. We augment the training corpus using parser-generated phrasal segments and evaluate the efficiency of the proposed work on the Hindi language. Further, the paper presents training in the NMT model at the character level instead of the word level. This approach can help overcome challenges associated with word-level translations, such as handling rare and out-of-vocabulary words and phrases, dealing with morphological complexity, and addressing languages with ambiguous word boundaries. The proposed work was evaluated on a low-resource language pair, Hindi-English, using the Google Transformer model as the baseline state-of-the-art. The experiments used two distinct datasets: WMT14 Hin-Eng and Samanantar Hin-Eng parallel corpus with character-level encoding for the translation task. The proposed model is able to surpass the cutting-edge baseline and saw an increase in BLEU scores for the WMT14 translation challenge with +2.52 on base paper using three phrase sentences with character-level encoding and +2.68 BLEU Score on base paper using five phrase sentences with character-level encoding. Further, character-level encoding is evaluated on non-augmented Samanantar dataset; it performs better in the baseline approach for translation purposes. It clearly shows that the proposed model outperforms in Hindi language translation.},
  archive      = {J_NPL},
  author       = {Rathod, Divya and Yadav, Arun Kumar and Kumar, Mohit and Yadav, Divakar},
  doi          = {10.1007/s11063-025-11718-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Character-level encoding based neural machine translation for hindi language},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTIEA: Ontology-enhanced triple intrinsic-correlation for
cross-lingual entity alignment. <em>NPL</em>, <em>57</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s11063-025-11723-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual and cross-domain knowledge alignment without sufficient external resources is a fundamental and crucial task for fusing irregular message. Aiming to discover equivalent objects from different knowledge graphs (KGs), embedding-based entity alignment (EA) has been attracting great interest from industry and academic research recently. Most of related methods usually explore the correlation between entities and relations through neighbor nodes, structural information and external resources. However, the complex intrinsic interactions among triple elements and role information are rarely modeled, which leads to the inadequate illustration. In addition, external resources are unavailable in some scenarios especially cross-lingual and cross-domain applications, which reflects the weak scalability. To tackle the above insufficiency, a novel universal EA framework (OTIEA) based on ontology pair and role enhancement mechanism via triple-aware attention is proposed in this paper without introducing external resources. Specifically, an ontology-enhanced triple encoder is designed via mining intrinsic correlations and ontology pair information instead of independent elements. In addition, the EA-oriented representations can be obtained in triple-aware entity decoder by fusing role diversity. Finally, a bidirectional iterative alignment strategy is deployed to expand seed entity pairs. The experimental results on three real-world datasets show that our framework achieves a competitive performance compared with baselines.},
  archive      = {J_NPL},
  author       = {Zhang, Zhishuo and Tan, Chengxiang and Yang, Min and Zhao, Xueyan},
  doi          = {10.1007/s11063-025-11723-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {OTIEA: Ontology-enhanced triple intrinsic-correlation for cross-lingual entity alignment},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedDefense: A defense mechanism for dishonest client attacks
in federated learning. <em>NPL</em>, <em>57</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s11063-025-11724-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL), which allows multiple participants to co-train machine learning models, enhances privacy-preserving by avoiding exposing local data. In recent years, FL has been considered a promising paradigm. However, during the FL process, individual clients may fall out on the client’s side, or a particular client may engage in dishonest behavior such as uploading malicious data, thereby hindering the training of the global model. Most of the existing defense methods are considered only from the perspective of data filtering or model weighting, which have the disadvantages of poor robustness and high computational cost. Therefore, we propose a novel security FL (FedDefense) scheme based on client selection and adaptive rewards to defend against dishonest client attacks. First, to reduce the likelihood of poisoned clients participating in aggregation, we design a randomized subset method for client contribution evaluation via Kullback–Leibler (KL) divergence. Second, we reduce the server’s dependence on clients through a dynamic reward strategy to ensure healthy model training. Numerical analysis and performance evaluation show that the proposed technique prevents the threat of dishonest clients during FL processing. Compared with existing methods, our approach has significant advantages in terms of efficiency and performance.},
  archive      = {J_NPL},
  author       = {Yue, Gaofeng and Han, Xiaowei},
  doi          = {10.1007/s11063-025-11724-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {FedDefense: A defense mechanism for dishonest client attacks in federated learning},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal aspect-based sentiment analysis with external
knowledge and multi-granularity image-text features. <em>NPL</em>,
<em>57</em>(2), 1–34. (<a
href="https://doi.org/10.1007/s11063-025-11737-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal aspect-based sentiment analysis (MABSA) is an essential task in the field of sentiment analysis, which still confronts several critical challenges. The first challenge is how to effectively capture key information within both image and text features to enhance the recognition and understanding of complex sentiment expressions. The second challenge is how to achieve cross-modal alignment of multi-granularity text features and image features. The third challenge is how to narrow the semantic gap between image modality and text modality through effective cross-modal feature fusion. To address these issues, a framework that leverages external knowledge and multi-granularity image and text features (EKMG) is proposed. Firstly, an external knowledge enhanced semantic extraction module is introduced to fuse external knowledge with image features and text features, thereby capturing the key information from texts and images. Secondly, we design a multi-granularity image-text contrastive learning module. This module initially introduces a graph attention network and a novel cross-modal fusion mechanism to align image features and text features at multiple granularities. Additionally, the module employs an image-text contrastive learning strategy to narrow the semantic gap between different modalities. Experimental results on two public benchmark datasets demonstrate that EKMG achieves significant performance improvements compared to state-of-the-art baseline models.},
  archive      = {J_NPL},
  author       = {Liu, Zhanghui and Lin, Jiali and Chen, Yuzhong and Dong, Yu},
  doi          = {10.1007/s11063-025-11737-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-34},
  shortjournal = {Neural Process. Lett.},
  title        = {Multimodal aspect-based sentiment analysis with external knowledge and multi-granularity image-text features},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved condition for ISS of stochastic memristive fuzzy
cohen–grossberg BAM neural networks with time-varying delays.
<em>NPL</em>, <em>57</em>(2), 1–34. (<a
href="https://doi.org/10.1007/s11063-025-11739-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of this paper is to conduct a comprehensive investigation into the model of a memristive fuzzy Cohen–Grossberg bidirectional associative memory neural network (MFCGBAMNN) that integrates time-varying delays and stochastic disturbances. This study aims to introduce an innovative approach for addressing the input-to-state stability (ISS) property within this intricate framework. To enhance the understanding of ISS characteristics in these networks, we develop a Lyapunov–Krasovskii function that is instrumental in analyzing stability amidst time-varying delays and stochastic disturbances, serving as a cornerstone for deriving sufficient conditions for ISS. In distinguishing this work from existing studies, we establish a stability analytical framework grounded in the Lyapunov–Krasovskii function. By employing non-smooth analysis techniques and stochastic analysis theory, we derive novel sufficient conditions for ISS. This methodology is particularly relevant to the complexities introduced by stochastic disturbances in the dynamics of neural networks. Moreover, the incorporation of set-valued maps in our analysis provides a solid framework for addressing the uncertainties inherent in memristive systems, thereby enhancing the reliability of the stability conditions derived. To substantiate our theoretical findings, we present two numerical examples that effectively demonstrate the applicability and efficacy of the proposed conditions.},
  archive      = {J_NPL},
  author       = {Santhosh Kumar, S. and Chandrasekar, A.},
  doi          = {10.1007/s11063-025-11739-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-34},
  shortjournal = {Neural Process. Lett.},
  title        = {Improved condition for ISS of stochastic memristive fuzzy Cohen–Grossberg BAM neural networks with time-varying delays},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel non-iterative training method for CNN classifiers
using gram–schmidt process. <em>NPL</em>, <em>57</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s11063-025-11741-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks have become prominent machine learning models, particularly in the realm of computer vision, due to their ability to predict and extract robust features from raw image data. CNNs, similar to other neural network models, undergo training via backpropagation, an iterative technique. However, the backpropagation algorithm has notable challenges, including slow convergence, susceptibility to local minima, and hypersensitivity to learning rates. These challenges not only impact the model’s accuracy but also make the training process computationally intensive. To address these limitations, We introduce a novel approach that trains the CNN classifier using a non-iterative learning method. The proposed approach involves automatic extraction of pertinent features from the raw-data, followed by the application of Gram–Schmidt process to decompose the feature matrix and determine classifier’s weights. The proposed method has shown enhanced predictive accuracy over state-of-the-art models when evaluated on two benchmark datasets, MNIST and CIFAR-10. The extensive experimentation using most cited pre-trained experiments validate the effectiveness of our proposed method.},
  archive      = {J_NPL},
  author       = {Azam, Basim and Kuttichira, Deepthi and Sanjeewani, Pubudu and Verma, Brijesh and Rahman, Ashfaqur and Wang, Lipo},
  doi          = {10.1007/s11063-025-11741-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel non-iterative training method for CNN classifiers using Gram–Schmidt process},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving text classification on deep neural
network. <em>NPL</em>, <em>57</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s11063-025-11738-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of Internet information, the classification of massive Internet data plays a very important role in real life. Text classification has been widely used in spam text recognition, intention recognition, text matching, named entity recognition, and other fields. At present, many enterprises provide APIs for text classification for users. Users can upload their data to the cloud server deployed by service providers for analysis, and return the final classification results. However, there is a risk of user data and model leakage in this process. To solve this problem, we propose a privacy-preserving text classification scheme using CKKS fully homomorphic encryption scheme and self-attention mechanism model in the multi-party security computing scenario. Our scheme ensures that user can achieve efficient encrypted data analysis under the premise of their data security, and user must be authorized by the service provider to use the model. Finally, compared with the experimental results of the previous research on privacy text classification under fully homomorphic encryption, the implementation improves the accuracy by 7.97% at most and speed-ups 282.4 times for inference at most, and we ensure the security of the protocol participants.},
  archive      = {J_NPL},
  author       = {Li, Kunhong and Huang, Ruwei and Yang, Bo},
  doi          = {10.1007/s11063-025-11738-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Privacy-preserving text classification on deep neural network},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bipartite consensus in multi-agent systems: A node
decomposition approach for privacy preservation. <em>NPL</em>,
<em>57</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s11063-025-11717-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The consensus control protocol of the cooperative-competitive network requires nodes to transmit their own information to the rival group, which is detrimental to the security of the information. In this paper, we propose a novel node decomposition mechanism, which can prevent the state information from being revealed during the information exchange for multi-agent systems with antagonistic interactions. For each node, one of the two subnodes takes over the role of the primitive node with cooperative neighbors, and the other one is involved in antagonistic interactions. Under this method, the connectivity and structurally balanced of the system are not changed, so it can still achieve bipartite consensus. Besides, although the initial values of the two subnodes are chosen randomly, the average of these subnodes corresponds to the original state value, ensuring precise bipartite consensus. Moreover, we also prove that the privacy of a node can be guaranteed if and only if it has a neighbor in the same group. The effectiveness of the proposed approach is demonstrated by a numerical example.},
  archive      = {J_NPL},
  author       = {Wang, Yaqi and Zhang, Yuhong and Lu, Jianquan and Zhong, Jie and Li, Bowen},
  doi          = {10.1007/s11063-025-11717-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Neural Process. Lett.},
  title        = {Bipartite consensus in multi-agent systems: A node decomposition approach for privacy preservation},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WACSO: Wolf crow search optimizer for convolutional neural
network hyperparameter optimization. <em>NPL</em>, <em>57</em>(2), 1–22.
(<a href="https://doi.org/10.1007/s11063-025-11740-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) experience performance and training efficiency changes according to the selection of correct hyperparameters. The research presents WACSO which combines Crow Search Optimization with Grey Wolf Optimizer to improve Convolutional Neural Networks hyperparameter selection through a hybrid metaheuristic algorithm. The hybrid algorithm WACSO uses exploration parts from CSO together with GWO exploitation mechanics to obtain optimized performance. WACSO reaches higher classification accuracy than traditional optimization algorithms when performing tests on the MNIST and CIFAR-10 datasets along with Random Search and particle swarm optimization and genetic algorithms and standalone CSO and standalone GWO. The best classification results reached 98.9% accuracy levels on MNIST along with 91.5% accuracy levels on CIFAR-10. The final outcomes of this system depend on the combination of model structure along with dataset challenges and available computational power. The investigation demonstrates that mixing algorithms drawn from nature can lead to successful CNN hyperparameter optimization. The promising outcomes of WACSO depend on multiple variables including computation expenses and sensitive parameter adjustments and universal result adaptability between different datasets and network setups. Research into WACSO should expand to involve longer evaluations across multiple datasets and various models to confirm widespread usage.},
  archive      = {J_NPL},
  author       = {Papalkar, Rahul Rajendra and Jadhav, Jayendra and Pattewar, Tareek and Thorat, Vivek and Morey, Pallavi and Deshmukh, Mayur and Jagdale, Rajkumar},
  doi          = {10.1007/s11063-025-11740-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {WACSO: Wolf crow search optimizer for convolutional neural network hyperparameter optimization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review: One-shot object detection methods for conditional
detection of retail and warehouse products. <em>NPL</em>,
<em>57</em>(2), 1–32. (<a
href="https://doi.org/10.1007/s11063-025-11742-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facilitating the rapid dispatch and replenishment of products is a critical task in most large warehouses. Automated systems often rely on Deep Learning based object detection methods to monitor operations. A major challenge is the significant requirement for annotated data, and the system’s difficulty in adapting to new products. In contrast, human operators can quickly learn to recognize and adapt to new products with just a single example. This survey focuses on methods that enable conditional detection using a single support example per class. We first introduce common feature fusion techniques and discuss datasets suitable for warehouse and retail products. Next, we provide a comprehensive overview of the current State-Of-The-Art in One-Shot Object Detection. We categorize these approaches based on their detectors, which identify the object’s bounding boxes and classes. Then, we delve into detailed implementations of these methods, analyzing how they leverage this innovative vision approach to improve performance. Finally, we identify promising current trends in this emerging field.},
  archive      = {J_NPL},
  author       = {Desmarescaux, Matthieu and Kaddah, Wissam and Alfalou, Ayman and Deconninck, Jean-Charles},
  doi          = {10.1007/s11063-025-11742-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-32},
  shortjournal = {Neural Process. Lett.},
  title        = {A review: One-shot object detection methods for conditional detection of retail and warehouse products},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image retrieval using multi-layer orientation histograms.
<em>NPL</em>, <em>57</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s11063-025-11719-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various levels of feature maps extracted from the convolutional neural network models can capture multiple degrees of semantic cues in representation. However, learning the relationship between different semantic features across numerous layers can be challenging. Furthermore, existing representations cannot effectively capture the orientation cues. This paper proposes a representation method, the multi-layer orientation histogram, to address these problems. The main highlights are: (1) An iterative multi-layer integration method to combine the feature maps of various levels is suggested in this study. This method can provide discriminative characteristics based on spatial relationships. (2) An effective approach is suggested to apply Gabor filtering for detecting orientation cues. It can amplify the most dominant orientation cues and is convenient for efficiently using them in subsequent implementations. (3) The proposed representation directly captures orientation cues from each learned feature map. It can incorporate the learned deep features and orientation cues to create a more discriminative representation. Comparative experiments demonstrate that the proposed method exhibits a highly competitive performance on several benchmark datasets in terms of mean average precision. Moreover, this method can provide an effective architecture for learning discriminative global features.},
  archive      = {J_NPL},
  author       = {Li, Xiao-Peng and Liu, Guang-Hai and Lu, Fen},
  doi          = {10.1007/s11063-025-11719-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Image retrieval using multi-layer orientation histograms},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hydraulic-supports alignment by TD3 with segmented
experience pool. <em>NPL</em>, <em>57</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s11063-025-11744-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydraulic-supports alignment is to keep the coal mining face in line and is heavily influenced by the various geological states. The experiences produced by the moving process are unbalanced, which leads to the agent not learning important knowledge from the rare samples. This paper is the first to introduce the reinforcement learning to the hydraulic-supports alignment, and establish the Markov optimal decision model by TD3 algorithm. Aiming at the imbalance issue of the experience, this paper proposes a segmented experience pool and three sampling replay mechanisms according to the characteristics of the moving process with various geological states. Experimental results show that the improved TD3, utilizing a segmented experience pool with three different replay mechanisms, could effectively identify the optimal moving policy and achieve significant convergence in cases involving both normal movement and insufficient movement of hydraulic-supports. In contrast, the TD3 performs inadequately and struggles to find the optimal policy.},
  archive      = {J_NPL},
  author       = {Yang, Yi and Dai, Yapeng and Wang, Tian and Qian, Wei},
  doi          = {10.1007/s11063-025-11744-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Hydraulic-supports alignment by TD3 with segmented experience pool},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of data augmentation in domain generalization.
<em>NPL</em>, <em>57</em>(2), 1–38. (<a
href="https://doi.org/10.1007/s11063-025-11747-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most machine learning algorithms typically assume that the data distribution of the training and test sets are consistent, but this assumption often fails to hold in practical applications. Domain generalization aims to train a model using only available source data so that the model can generalize to unseen domains. Data augmentation is an important technique in domain generalization, but there are few comprehensive reviews investigating and summarizing its use in domain generalization. This study provides a comprehensive literature review of data augmentation methods in domain generalization for the first time. First, we formalize the definition of domain generalization and analyze the role of data augmentation in domain generalization. Second, we propose a new taxonomy that categorizes methods into three classes based on the augmentation objectives: domain-level, image-level, and feature-level augmentation. Third, we compare the experimental results of some data augmentation methods on three popular domain generalization datasets and discuss the characteristics and advantages of the current best methods. Fourth, we analyze the shortcomings of each category, propose the suggestions for improvements, and summarize the challenges and the future directions of data augmentation for achieving cross-domain generalization from both theoretical and practical perspectives.},
  archive      = {J_NPL},
  author       = {Zhong, Yingyi and Zhou, Wen’an and Wang, Zhixian},
  doi          = {10.1007/s11063-025-11747-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-38},
  shortjournal = {Neural Process. Lett.},
  title        = {A survey of data augmentation in domain generalization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="paaa---35">PAAA - 35</h2>
<ul>
<li><details>
<summary>
(2025). Novel construction methods for picture fuzzy divergence
measures with applications in pattern recognition, MADM, and clustering
analysis. <em>PAAA</em>, <em>28</em>(2), 1–28. (<a
href="https://doi.org/10.1007/s10044-024-01383-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Divergence measure of picture fuzzy sets is a valuable tool to study the problems related to decision-making, pattern classification, and clustering analysis. However, existing divergence/distance measures are sometimes ineffective in capturing the intricacies of uncertainty and imprecision inherent in picture fuzzy sets. In view of the theoretical and experimental weaknesses of existing picture fuzzy divergence/distance measures, this article introduces novel construction methods for deriving picture fuzzy divergence measures. The first one is inductive which utilizes existing intuitionistic fuzzy divergence and the second is based on forming picture fuzzy divergence measures from existing picture fuzzy divergence measures. Additionally, we have shown that restriction on the neutrality degree in picture fuzzy divergence is an intuitionistic fuzzy divergence. Moreover, we suggested a new picture fuzzy divergence measure utilizing the proposed approach and applied it to solve practical problems concerned with decision-making, pattern classification, and clustering analysis. The performance indices “Degree of Confidence” and “Cluster Validity Index” in the picture fuzzy framework further appreciated the advantages of the proposed measures. Comparative studies with existing picture fuzzy distance/divergence measures demonstrated the effectiveness and superiority of the proposed divergence measures.},
  archive      = {J_PAAA},
  author       = {Singh, Surender and Singh, Koushal},
  doi          = {10.1007/s10044-024-01383-9},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-28},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Novel construction methods for picture fuzzy divergence measures with applications in pattern recognition, MADM, and clustering analysis},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated multi-local and global dynamic perception
structure for sign language recognition. <em>PAAA</em>, <em>28</em>(2),
1–14. (<a href="https://doi.org/10.1007/s10044-024-01403-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current sign language recognition methods often focus on whole-body features, neglecting the detailed dynamic information of key body parts. We propose an integrated multi-local and global dynamic perception structure based on a hybrid feature fusion approach that fuses features from multiple local paths into the global path, aiming to benefit from the diverse local information available in videos. First, the multi-local dynamic perception module is designed to extract multiple sign language-related spatial features with fine-grained information on local body dynamics. This module is achieved by expanding multi-local features in the channel dimension, permitting the processing of different perspectives independently for multiple local feature inputs. Moreover, we design a multi-local to global fusion module that generates multi-local fusion representations encompassing both temporal and spatial dimensions. This module integrates the fusion of deep features from multiple local dynamics, to be integrated with shallow features of the global module, achieving a match between the deep features of the multi-local to global fusion module and the shallow features of the global dynamic perception module. Finally, extensive experiments based on several sign language recognition benchmarks demonstrate that our integrated multi-local and global dynamic perception structure effectively improves performance of sign language recognition models, and significantly outperforms a number of competitive baselines.},
  archive      = {J_PAAA},
  author       = {Liang, Siyu and Li, Yunan and Shi, Yuanyuan and Chen, Huizhou and Miao, Qiguang},
  doi          = {10.1007/s10044-024-01403-8},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Integrated multi-local and global dynamic perception structure for sign language recognition},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing semantic audio-visual representation learning with
supervised multi-scale attention. <em>PAAA</em>, <em>28</em>(2), 1–14.
(<a href="https://doi.org/10.1007/s10044-025-01414-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, breakthroughs in large models such as GPT and Transformers have demonstrated extraordinary versatility and power in various fields and tasks. However, despite significant progress in areas such as natural language processing, these models still face some unique challenges when processing multimodal data. Data from different modalities often contain significantly different characteristics, and the heterogeneity gap between different modalities makes it difficult to fuse these data to extract valuable information. To integrate and align semantic meanings between audio-visual modalities, this paper proposes a novel supervised multi-scale attention for enhancing semantic audio-visual representation learning from multimedia data, utilizing the audio-visual attention mechanism to combine multi-scale features. Specifically, we explore multi-scale feature extraction and audio-visual attention architecture, which computes cross-attention weights based on the correlation between joint feature representations and single-modal representations. In addition, the model is guided to learn powerful discriminative features by minimizing intra-modal and inter-modal discriminative losses and maximizing cross-modal correlations. With the widely used VEGAS and AVE benchmark datasets, our model demonstrates competitive experimental results. Extensive experiments verify that the proposed method significantly outperforms the state-of-the-art cross-modal retrieval methods.},
  archive      = {J_PAAA},
  author       = {Zhang, Jiwei and Yu, Yi and Tang, Suhua and Qi, GuoJun and Wu, Haiyuan and Hachiya, Hirotaka},
  doi          = {10.1007/s10044-025-01414-z},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Enhancing semantic audio-visual representation learning with supervised multi-scale attention},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multitask learning of adversarial-contrastive graph for
recommendation. <em>PAAA</em>, <em>28</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s10044-025-01417-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems play a critical role in our daily lives. Despite great progress, existing graph-based recommendation methods still suffer from challenges including skewed data distribution, vulnerability to noises, and sparse supervision signal. We attribute the inferior performance to the limited discriminative ability of the learned representations. To remedy this, in this paper, we develop a framework termed Multi-ACG by introducing self-supervised learning, adversarial learning, and multitask learning to learn representations with higher discrimination. Specifically, self-supervised learning and adversarial learning are first employed to synthesize hard samples for training. Meanwhile, multi-task learning is adopted to balance different loss terms for optimization. Experiments are conducted on benchmark datasets and the results have demonstrated the state-of-the-art performance of the proposed method against previous ones. The code is at https://github.com/xiaoma666123/Multi-ACG.},
  archive      = {J_PAAA},
  author       = {Ma, Xingyu and Wang, Chuanxu},
  doi          = {10.1007/s10044-025-01417-w},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multitask learning of adversarial-contrastive graph for recommendation},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pre-trained noise based unsupervised GAN for fruit disease
classification in imbalanced datasets. <em>PAAA</em>, <em>28</em>(2),
1–19. (<a href="https://doi.org/10.1007/s10044-025-01418-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early disease diagnosis in edible fruits and vegetables is crucial for sustainable economic agricultural production. Recently, deep neural networks have explicitly shown exceptional performance in early disease recognition. However, an insufficient and scarce dataset is a critical issue for training the neural network, which makes dataset acquisition a fundamental obstacle in enhancing the performance of deep network models. A considerable amount of dataset acquisition necessitates an additional, expensive effort owing to time constraints and expert requirements. To mitigate this challenge, a novel data augmentation method, FruitGAN, exploiting the generative adversarial architecture, has been developed. The variational autoencoder transforms the random Gaussian noise into a pre-trained noise vector, which is then input into the proposed FruitGAN method. The FruitGAN method is equipped with a self-attention, residual block, and super-resolution module to maintain tiny lesions, structural integrity, and perceptual quality in the generated fruit images. Moreover, a new real-field eggplant dataset containing the four pathogens and one healthy category, aggregating 1325 samples, has been collected from on-field farms. The proposed FruitGAN method is leveraged to generate real-like synthetic images of the eggplant to avoid class imbalance problems. The effectiveness of FruitGAN is tested on the eggplant dataset in terms of FID and SSIM scores, and the results are compared with seven other State-Of-The-Art GAN models. Furthermore, the classification performance of the FruitGAN-generated dataset has also been tested against nine pre-trained deep networks namely, AlexNet, VGG16, VGG19, ResNet50, ResNet101, DenseNet101, InceptionV3, Xception, and MobileNetV2 and four hybrid networks, namely, InceptionV3 + VGG16, SVM + VGG19, CNN + SVM, and MobileNet + Xception using transfer learning and evaluating the performance by test data. The experimental results affirmed that the developed FruitGAN outperformed all other considered GAN models by achieving 112.88 FID and 0.94 SSIM scores. Moreover, the classification accuracy of the FruitGAN augmented dataset was recorded as 95.74%, which is the highest among other considered GAN models. The code and datasets of the proposed method are available at https://github.com/ersachingupta11/FruitGAN},
  archive      = {J_PAAA},
  author       = {Gupta, Sachin and Tripathi, Ashish Kumar and Lewis, Nkenyereye},
  doi          = {10.1007/s10044-025-01418-9},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Pre-trained noise based unsupervised GAN for fruit disease classification in imbalanced datasets},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidirectional feature fusion via cross-attention transformer
for chrysanthemum classification. <em>PAAA</em>, <em>28</em>(2), 1–16.
(<a href="https://doi.org/10.1007/s10044-025-01419-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chrysanthemums hold significant ornamental, economic, and medicinal value, with their quality and economic worth heavily influenced by geographic origin. Accurate classification of chrysanthemums is crucial for ensuring product authenticity, boosting consumer trust, and promoting sustainable industry growth. Traditional classification methods, however, suffer from inefficiency and high costs. To address these challenges, we propose a novel chrysanthemum classification method utilizing a bidirectional feature fusion approach via cross-attention and two-stream network fusion. Our method preprocesses front and back images of chrysanthemums from diverse regions, employing the powerful Swin Transformer as the backbone to extract features. The cross-attention mechanism effectively integrates features from both image sides, and a secondary training strategy further enhances the model’s generalization capabilities. Experimental results demonstrate that our method achieves higher accuracy, precision, recall, and F1 score compared to state-of-the-art models, highlighting its potential for accurate chrysanthemum origin tracing. The code and datasets are openly available at https://github.com/dart-into/CCMCAM , ensuring transparency and reproducibility of our findings.},
  archive      = {J_PAAA},
  author       = {Chen, Yifan and Yang, Xichen and Yan, Hui and Liu, Jia and Jiang, Jian and Mao, Zhongyuan and Wang, Tianshu},
  doi          = {10.1007/s10044-025-01419-8},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Bidirectional feature fusion via cross-attention transformer for chrysanthemum classification},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remote sensing image change detection network with
multi-scale feature information mining and fusion. <em>PAAA</em>,
<em>28</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s10044-025-01420-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change detection (CD) aims to predict the pixels that have changed in an image by comparing images from different times. CNN is excellent at local feature extraction, while Transformer is excellent at extracting global features. However, simple CD networks that extract fused local and global feature information have limitations in their discriminative ability. This is due to the underutilization of local and global information for multi-scale features. For this reason, this paper proposes a remote sensing image change detection network for multi-scale feature information mining and fusion (MSFIMF-RSCDNet). Firstly, based on the hierarchical features displaying different levels of information, we design a selective convolutional attention module (SCBAM) to improve the distinguishability of multi-scale features. Subsequently, a cascaded cross-self-attention module (CCSAM) is proposed to refine the global information of the multi-scale features, and finally, a high-level feature-guided multi-scale feature fusion module (HFGFFM) is utilized to improve the discriminability of the model for objects of different sizes. We show through experiments on three public optical remote sensing image CD datasets, LEVIR-CD (Chen and Shi in Remote Sens 12(10):1662, 2020), WHU-CD (Ji et al. in Trans Geosci Remote Sens 57(1):574–586, 2018), and CDD (Lebedev et al. in Int Arch Photogramm Remote Sens Spat Inf Sci 42:565–571, 2018), that stronger change detection CD performance is achieved than other commonly used methods.},
  archive      = {J_PAAA},
  author       = {Xue, Songdong and Zhang, Minming and Qiao, Gangzhu and Zhang, Chaofan and Wang, Bin},
  doi          = {10.1007/s10044-025-01420-1},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Remote sensing image change detection network with multi-scale feature information mining and fusion},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TabMixer: Advancing tabular data analysis with an enhanced
MLP-mixer approach. <em>PAAA</em>, <em>28</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s10044-025-01423-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tabular data, prevalent in relational databases and spreadsheets, is fundamental across fields like healthcare, engineering, and finance. Despite significant advances in tabular data learning, critical challenges remain: handling missing values, addressing class imbalance, enabling transfer learning, and facilitating feature incremental learning beyond traditional supervised paradigms. We introduce TabMixer, an innovative model that enhances the multilayer perceptron (MLP) mixer architecture to address these challenges. TabMixer incorporates a self-attention mechanism, making it versatile across various learning scenarios including supervised learning, transfer learning, and feature incremental learning. Extensive experiments on eight public datasets demonstrate TabMixer’s superior performance over existing state-of-the-art methods. Notably, TabMixer achieved substantial improvements in ANOVA AUC across all scenarios: a 4% increase in supervised learning (0.840 to 0.881), 8% in transfer learning (0.803 to 0.872), and 4% in feature incremental learning (0.806 to 0.843). TabMixer demonstrates high computational efficiency and scalability through reduced floating-point operations and learnable parameters. Moreover, it exhibits strong resilience to missing values and class imbalances through both its architectural design and optional preprocessing enhancements. These results establish TabMixer as a promising model for tabular data analysis and a valuable tool for diverse applications.},
  archive      = {J_PAAA},
  author       = {Eslamian, Ali and Cheng, Qiang},
  doi          = {10.1007/s10044-025-01423-y},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Pattern Anal. Appl.},
  title        = {TabMixer: Advancing tabular data analysis with an enhanced MLP-mixer approach},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LMFR-net: Lightweight multi-scale feature refinement network
for retinal vessel segmentation. <em>PAAA</em>, <em>28</em>(2), 1–15.
(<a href="https://doi.org/10.1007/s10044-025-01424-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel segmentation is a crucial step in analyzing fundus images and plays a vital role in the early detection, diagnosis, and treatment of various diseases. To make the segmentation model more applicable to actual medical scenarios, A Lightweight Multi-scale Feature Refinement Network (LMFR-Net) based on dual-decoding structure is proposed for efficient retinal vessel segmentation. Using a dual-decoding structure to reduce information loss, an Improved Convolution Block (ICB) is proposed to enhance the ability to extract basic features. In addition, a Lightweight Multi-scale Attention Feature Fusion (LMAFF) module is designed to extract the multi-scale spatial structure features. A Feature Refinement Module (FRM) with dense connections is proposed to optimize detailed features and comprehensively improve network segmentation capability. Comparative experiments were conducted on the DRIVE, CHASEDB1, and STARE datasets to verify that LMFR-Net achieved the highest F1-score and Recall of 82.91% and 86.85%, respectively, with only 366kb of parameters. More refined segmentation results have also been achieved in the visualization comparison of segmented images, and the overall segmentation effect is well. This indicates that LMFR-Net achieves efficient retinal vessel segmentation with a significantly reduced computational complexity, making it well-suited for practical medical applications. The code is available at https://github.com/MCloud31/LMFR-Net .},
  archive      = {J_PAAA},
  author       = {Zhang, WenHao and Qu, ShaoJun and Feng, YueWen},
  doi          = {10.1007/s10044-025-01424-x},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {LMFR-net: Lightweight multi-scale feature refinement network for retinal vessel segmentation},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and accurate 3D lung tumor segmentation algorithm.
<em>PAAA</em>, <em>28</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s10044-025-01425-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a lung tumor segmentation algorithm based on the Allen–Cahn (AC) energy equation. The novelty lies in the fact that, when extracting the energy matrix using the AC energy equation, we employ a sliding window algorithm for feature extraction on the data without neglecting local features. After obtaining the energy matrix, we construct constraint conditions based on the minimum and maximum values in the matrix, forming an arithmetic progression. Due to the flexibility in setting the sliding window size and constraint conditions, we can achieve segmentation results according to different requirements. In the numerical experiments, we conduct segmentation experiments of varying difficulty in both two-dimensional (2D) and three-dimensional (3D) spaces to verify the effectiveness of the proposed method. When addressing the lung tumor segmentation problem, we compare the maximum diameter of 3D lung tumors segmented by our proposed segmentation algorithm with the maximum diameter of lung tumors in the original 2D CT images to validate the segmentation accuracy and significance of the proposed method. By conducting more detailed and precise measurements and segmentations of tumors in 3D space, this approach contributes to advancements in medical science and enhances patient treatment outcomes. We also conduct tumor segmentation experiments on the MSD and LIDC-IDRI datasets, setting up comparison metrics to further verify the method’s effectiveness.},
  archive      = {J_PAAA},
  author       = {Wang, Jian and Han, Ziwei and Chen, Xinlei and Kim, Junseok},
  doi          = {10.1007/s10044-025-01425-w},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A fast and accurate 3D lung tumor segmentation algorithm},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual emotion analysis using skill-based multi-teacher
knowledge distillation. <em>PAAA</em>, <em>28</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s10044-025-01426-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biggest challenge in visual emotion analysis (VEA) is bridging the affective gap between the features extracted from an image and the emotion it expresses. It is therefore essential to rely on multiple cues to have decent predictions. Recent approaches use deep learning models to extract rich features in an automated manner, through complex frameworks built with multi-branch convolutional neural networks and fusion or attention modules. This paper explores a different approach, by introducing a three-step training scheme and leveraging knowledge distillation (KD), which reconciles effectiveness and simplicity, and thus achieves promising performances despite using a very basic CNN. KD is involved in the first step, where a student model learns to extract the most relevant features on its own, by reproducing those of several teachers specialized in different tasks. The proposed skill-based multi-teacher knowledge distillation (SMKD) loss also ensures that for each instance, the student focuses more or less on the teachers depending on their capacity to obtain a good prediction, i.e. their relevance. The two remaining steps serve respectively to train the student’s classifier and to fine-tune the whole model, both for the VEA task. Experiments on two VEA databases demonstrate the gain in performance offered by our approach, where the students consistently outperform their teachers, and also state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Cladière, Tristan and Alata, Olivier and Ducottet, Christophe and Konik, Hubert and Legrand, Anne-Claire},
  doi          = {10.1007/s10044-025-01426-9},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Visual emotion analysis using skill-based multi-teacher knowledge distillation},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-stage convolutional neural radiance fields.
<em>PAAA</em>, <em>28</em>(2), 1–12. (<a
href="https://doi.org/10.1007/s10044-025-01427-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novel view synthesis captured from multiple images is a critical research topic in computer vision and computational photography due to its wide range of applications. Neural radiance fields significantly improve performance by optimizing continuous volumetric scene functions using a multi-layer perceptron. Although neural radiance fields and their modifications provide high-quality scenes, they have limitation in optimizing exact radiance fields due to their hierarchical architecture comprising coarse and fine networks. They also require numerous parameters and generally do not consider local and global relationships between samples on a ray. This paper proposes a unified single-stage paradigm that jointly learns the relative position of three-dimensional rays and their relative color and density for complex scenes using a convolutional neural network to reduce noise and irrelevant features and prevent overfitting. Experimental results including ablation tests verify the proposed approach’s superior robustness to current state-of-the-art models for synthesizing novel views. The code is available at https://github.com/xkdytk/scorf .},
  archive      = {J_PAAA},
  author       = {Lee, Yoonjae and Yoon, Gang-Joon and Song, Jinjoo and Yoon, Sang Min},
  doi          = {10.1007/s10044-025-01427-8},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-12},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Single-stage convolutional neural radiance fields},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tsi-cnn-net: Truly shift-invariant convolutional neural
network for indian sign language recognition system. <em>PAAA</em>,
<em>28</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s10044-025-01428-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The majority of Indian sign language (ISL) recognition systems applied convolutional neural network (CNN) based deep neural networks. However, the output of CNN image classifiers may vary significantly with a little shift in input images. This shortcoming can be partially addressed by data augmentation, anti-aliasing, or blurring that do not work with different input patterns the network trained on and non-linear activation functions like ReLU, respectively. To deal with this short-coming, an ISL recognition approach has been presented using truly shift-invariant CNN. A sub-sampling strategy i.e. adaptive polyphase sampling (APS) has been applied to allow CNN truly shift-invariant. The proposed system is completely consistent to classification task. Furthermore, it offers significantly outstanding classification accuracy not only on Indian sign language datasets but also on datasets of other sign languages.},
  archive      = {J_PAAA},
  author       = {Ghorai, Anudyuti and Nandi, Utpal and Singh, Moirangthem Marjit and Changdar, Chiranjit and Paul, Bachchu and Chowdhuri, Partha and Pal, Pabitra},
  doi          = {10.1007/s10044-025-01428-7},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Tsi-cnn-net: Truly shift-invariant convolutional neural network for indian sign language recognition system},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale adaptive detail enhancement dehazing network for
autonomous driving perception images. <em>PAAA</em>, <em>28</em>(2),
1–14. (<a href="https://doi.org/10.1007/s10044-025-01430-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hazy weather conditions, a significant accumulation of haze poses a severe challenge to the quality of image capture for autonomous driving systems, thereby heightening safety risks for autonomous vehicles. To solve this problem, we propose the multi-scale adaptive detail enhancement dehazing network, an innovative architecture comprising the initial feature extraction module, the multi-scale adaptive feature module, and the terminal detail enhancement module, specifically designed to eradicate haze with precision. To enhance the extraction of multi-scale features, the multi-scale adaptive feature module employs the squeeze-excitation residual dense block (SRD). It not only learns the intricate multi-scale features of the image but also adaptively recalibrates the feature response of each feature map, ultimately bolstering the network’s performance and resilience. The terminal detail enhancement module, crafted with the dilation refinement block (DRB), serves as a compensatory measure for any detail loss or pseudo-artifacts that might arise from the multi-scale adaptive feature module’s operations. By incorporating the terminal detail enhancement module, the overall dehazing effect is further optimized. Empirical evaluations reveal that the proposed multi-scale adaptive detail enhancement dehazing network achieves impressive results, with a PSNR value of 30.82, an SSIM value of 0.967, and an LPIPS value of 0.033. These figures indicate that the network is adept at removing haze from images while preserving intricate details, ensuring the efficacy and reliability of autonomous driving systems in hazy environments. Code is available at https://github.com/murong-carl/Adaptive-multi-scale-detail-enhancement-dehazing-network .},
  archive      = {J_PAAA},
  author       = {Wang, Juan and Wang, Sheng and Wu, Minghu and Yang, Hao and Cao, Ye and Hu, Shuyao and Shao, Jixiang and Zeng, Chunyan},
  doi          = {10.1007/s10044-025-01430-z},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multi-scale adaptive detail enhancement dehazing network for autonomous driving perception images},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interactive image segmentation combining global seeding and
sparse local reconstruction. <em>PAAA</em>, <em>28</em>(2), 1–23. (<a
href="https://doi.org/10.1007/s10044-025-01432-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seed segmentation methods are highly regarded for their effectiveness in processing complex images, user-friendliness, and compatibility with graph-based representations. However, these methods often depend on intricate computational tools, leading to issues such as poor image contour adherence and incomplete seed propagation. To address these limitations, this paper proposes an interactive framework that integrates global seed information with sparse local linear reconstruction regularization (GSSR). In this framework, a Gaussian mixture model is firstly employed to construct a flow of global seed information, establishing connections between pixel points and yielding more complete segmented objects. Additionally, the $$L_{p}(0 &lt; p \le 1)$$ norm is utilized to constrain the sparse local reconstruction term, facilitating the generation of sparse boundaries. An iterative process based on the Alternating Direction Method of Multipliers (ADMM) is developed to solve the $$L_1$$ regularization term, which is then generalized for the $$L_p$$ problem through reweighting. We conduct a comprehensive comparison on the BSD dataset, CVC-ClinicDB datasets and two publicly available MSRC datasets with different labeling schemes. Extensive experimental validation demonstrates that the proposed method outperforms existing results.The source code and datasets are openly available at: https://github.com/choppy-water/GSSR .},
  archive      = {J_PAAA},
  author       = {Long, Jianwu and Liu, Yuanqin and Zhang, Kaixin and Chen, Shuang and Luo, Qi},
  doi          = {10.1007/s10044-025-01432-x},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-23},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Interactive image segmentation combining global seeding and sparse local reconstruction},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSDBPN: Multi-column smoothed dilated convolution based back
projection network for stereo image super-resolution. <em>PAAA</em>,
<em>28</em>(2), 1–11. (<a
href="https://doi.org/10.1007/s10044-025-01433-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully exploiting the parallax information of stereo images for super-resolution (SR) can obtain remarkable performance. The most challenging issue for stereo image SR is how to capture complementary correlation information between the stereo image pair to accurately guide reconstruction. In this paper, we propose a multi-column smoothed dilated convolution based back projection network (MSDBPN) for stereo SR by explicitly learning and exploiting the parallax information. In particular, we incorporate adaptive weighted multi-column smoothed dilated convolutions to rapidly expand the receptive field while maintaining excellent inter-pixel correlation. Meanwhile, we reweight different column feature with adaptive learnable parameter to distinguish contributions. Furthermore, we employ a deep back projection mechanism to calculate projection error and implement self-correction to guide precise reconstruction. Extensive experiments on benchmark datasets demonstrate that our proposed method outperforms other state-of-the-art approaches on both quantitative and qualitative evaluations.},
  archive      = {J_PAAA},
  author       = {Zhou, Zihao and Wang, Yongfang and Lian, Junjie},
  doi          = {10.1007/s10044-025-01433-w},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-11},
  shortjournal = {Pattern Anal. Appl.},
  title        = {MSDBPN: Multi-column smoothed dilated convolution based back projection network for stereo image super-resolution},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic prototype-guided structural information maintaining
for unsupervised domain adaptation. <em>PAAA</em>, <em>28</em>(2), 1–14.
(<a href="https://doi.org/10.1007/s10044-025-01435-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) intends to transfer the knowledge learned from labeled source domain to unlabeled target domain. Most existing methods employ domain adversarial training to align the feature space distributions of two domains. However, these methods may destroy the discriminative structural information. In this paper, we propose a Dynamic Prototype-guided Structural Information Maintaining (DPSIM) approach to preserve the structural information of the target domain based on pairwise semantic similarity. Specifically, we propose a dynamic prototype learning module to learn the categorical intrinsic representation of the source domain and then to predict the similarity of pairwise samples of the target domain. Finally, a structural information maintaining module is proposed to restrict the target domain by discriminating structural information. Extensive experiments on both image classification and object detection tasks demonstrate the effectiveness of our method.},
  archive      = {J_PAAA},
  author       = {Li, Deng and Li, Peng and Liu, Jian and Han, Yahong},
  doi          = {10.1007/s10044-025-01435-8},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Dynamic prototype-guided structural information maintaining for unsupervised domain adaptation},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source screen identification using difference image mask
obtained from images recaptured through screenshots based on spatial
rich features. <em>PAAA</em>, <em>28</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s10044-025-01442-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As images are integral to many sectors in the digital age, it is essential to ensure their authenticity and integrity. However, the ease of digital image creation and sharing also exposes them to manipulation and misrepresentation, heightening concerns about privacy and misinformation. The process of recapturing, a prevalent anti-forensic technique, poses challenges to tampering detection methods, necessitating effective countermeasures to uphold image credibility. Monitor-screenshots, facilitated by the simplicity of capturing screenshots of Original images displayed on monitors, pose unique challenges in source identification. Addressing this, we propose a novel approach to unveil the screen fingerprint, capturing distinctive irregularities associated with blur exist in Monitor-screenshots for accurate source identification. Leveraging image registration, difference image masking, and sophisticated feature extraction techniques, our method enables precise identification of specific screens, enhancing the authentication of digital content. By scrutinizing screen-specific characteristics and artifacts left during recapture, proposed model can verify the claimed origin of Screenshots, tested on a Screenshot dataset using SVM classifier, offers a robust framework to authenticate digital content and trace its source with precision and reliability, mitigating risks associated with image manipulation and misrepresentation in the digital domain.},
  archive      = {J_PAAA},
  author       = {Anjum, Areesha and Islam, Saiful and Saleem, Mahreen and Siddiqui, Nadia},
  doi          = {10.1007/s10044-025-01442-9},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Source screen identification using difference image mask obtained from images recaptured through screenshots based on spatial rich features},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HCT: Image super-resolution restoration using hierarchical
convolution transformer networks. <em>PAAA</em>, <em>28</em>(2), 1–11.
(<a href="https://doi.org/10.1007/s10044-025-01413-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the computer vision domain, image super-resolution (SR) technology, which restores high-resolution details from low-resolution images, plays a vital role in practical applications such as medical imaging, public safety, and remote sensing. Traditional methods employ convolutional neural networks to address these issues, while Visual Transformers show potential performance in high-level vision tasks. However, compared to typical CNN architecture networks, Visual Transformers exhibit weaker reliance on high-frequency information in images, leading to blurred details and residual artifacts. To solve this issue, we use a hierarchical network structure, which allows for a more flexible feeling field for our approach. Firstly, our method complements lost spatial features using a Convolutional Swin Transformer Layer incorporating a Convolutional Feed Forward Network. This allows for the retrieval of missing spatial information and enhances the model’s representational capabilities. Next, deep feature extraction is performed by combining multiple layers into a Residual Convolutional Swin Transformer Block. Finally, we employ a hierarchical-type structure to combine the features of each branch. Experiments validate the effectiveness of the proposed method in generating images with greater detail aligned with human perception. Based on the experiments, our method is effective on SR tasks with magnification factors of 2, 3, and 4. Our method can reconstruct a clear and complete edge structure. We provide code at https://github.com/Q88392/HCT .},
  archive      = {J_PAAA},
  author       = {Guo, Ying and Tian, Chang and Wang, Han and Liu, Jie and Di, Chong and Ning, Keqing},
  doi          = {10.1007/s10044-025-01413-0},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-11},
  shortjournal = {Pattern Anal. Appl.},
  title        = {HCT: Image super-resolution restoration using hierarchical convolution transformer networks},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCDPose: Enhancing the lightweight 2D human pose estimation
model with pose-enhancing attention and context broadcasting.
<em>PAAA</em>, <em>28</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s10044-025-01431-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {2D human pose estimation is an important domain in computer vision. In recent years, the lightweight 2D human pose estimation (2DTLHPE) models based on vision transformer (ViT) have attracted extensive attention due to the fewer parameters and the lower computational requirements. However, these models are also facing the challenges of cluttered and occluded background. It results in the errors of locating keypoints. Therefore, this paper proposes the pose-enhanced contextual distillation for pose estimation model (PCDPose) to alleviate the influence of the challenges. Firstly, PCDPose introduces the pose-enhancing attention (PEA) module which highlights the foreground information in the feature map. It alleviates the influence caused by the cluttered background. Moreover, PCDPose introduces the context broadcasting (CB) module, which builds the long-range dependencies between the keypoints in occluded regions and the neighboring keypoints by broadcasting the context to each vision token (VT). It alleviates the influence caused by the occluded background. Experimental results show that PCDPose achieves a 73.5% average precision (AP) on the COCO2017 dataset, and it has a 1% performance improvement over the state-of-the-art (SOTA) model. On the CrowdPose dataset, PCDPose achieves a 71.3% AP, and it has a 5.9% performance improvement over the SOTA model.},
  archive      = {J_PAAA},
  author       = {Tian, Zhenyuan and Fu, Weina and Woźniak, Marcin and Liu, Shuai},
  doi          = {10.1007/s10044-025-01431-y},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Pattern Anal. Appl.},
  title        = {PCDPose: Enhancing the lightweight 2D human pose estimation model with pose-enhancing attention and context broadcasting},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPFCNet: Multi-scale parallel feature fusion convolutional
network for 3D knee segmentation from MR images. <em>PAAA</em>,
<em>28</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s10044-025-01437-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and automatic segmentation of knee magnetic resonance (MR) images plays a vital role in the diagnosis of osteoarthritis and knee bone diseases. However, the anatomical structure of the knee joint is complex, it is difficult to segment knee joints accurately and efficiently. This paper proposes a knee joint segmentation model from MR image, which is named a multi-scale parallel feature fusion convolutional network (MPFCNet). A Large Kernel Attention (LKA) module is coined in the MPFCNet, which effectively increases the receptive field and preserves detail textures, resulting in better feature extraction. To further utilize complementary information at various scales in both spatial and channel dimensions, a Multi-Scale Fusion (MSF) module is established. A Hybrid Feedforward Attention (HFA) module is proposed to establish long-range dependencies. Experiments and comparisons with state-of-the-art methods were conducted on the publicly available dataset OAI-ZIB. The results show that the MPFCNet achieved excellent segmentation results on the knee joint segmentation task, improving the average dice similarity coefficient.},
  archive      = {J_PAAA},
  author       = {Zhang, Hanzheng and Wu, Qing and Zhao, Xing and Wang, Yuanquan and Zhou, Shoujun and Zhang, Lei and Zhang, Tao},
  doi          = {10.1007/s10044-025-01437-6},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {MPFCNet: Multi-scale parallel feature fusion convolutional network for 3D knee segmentation from MR images},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fedpartwhole: Federated domain generalization via consistent
part-whole hierarchies. <em>PAAA</em>, <em>28</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s10044-025-01439-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Domain Generalization (FedDG) aims to address the challenge of generalizing to unseen domains at test time while adhering to data privacy constraints that prevent centralized data storage from various client domains. Existing approaches can be broadly classified into domain alignment, data manipulation, learning strategies, and optimization of model aggregation weights. This paper introduces a novel approach to FedDG that focuses on the backbone model architecture. The key insight is that objects, even under substantial domain shifts and appearance variations, retain a consistent hierarchical structure of parts and wholes. For example, a photograph and a sketch of a dog share the same structural organization, comprising a head, body, limbs, and so on. Our architecture explicitly integrates a feature representation for the image parse tree, enabling robust generalization across domains. To the best of our knowledge, this is the first work to approach FedDG from a model architecture perspective. We compared the performance of our proposed backbone against a comparable-sized CNN-based backbone (MobileNet) for 5 different algorithms on standard benchmark datasets (PACS and VLCS), and the results showed an average improved performance of up to 17.3%. Additionally, our approach marginally outperforms the Vision Transformer (ViT-Small) on average, despite utilizing approximately 5x fewer parameters. Unlike conventional convolutional neural networks, our method is inherently interpretable, fostering trust in its predictions-a critical asset in federated learning scenarios.},
  archive      = {J_PAAA},
  author       = {Radwan, Ahmed and Shehata, Mohamed},
  doi          = {10.1007/s10044-025-01439-4},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Fedpartwhole: Federated domain generalization via consistent part-whole hierarchies},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic metric memory network for long-term tracking with
spatial-temporal region proposal method. <em>PAAA</em>, <em>28</em>(2),
1–18. (<a href="https://doi.org/10.1007/s10044-025-01441-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully mining target information is critical to cope with the recovery of lost targets in long-term tracking scenarios. However, most existing trackers focus on either temporal or spatial information during tracking and do not utilize this information effectively simultaneously. Therefore, we propose a dynamic metric memory network for long-term tracking with spatial-temporal region proposals. First, we present a spatio-temporal region proposal method, in which temporal memory is utilized to construct dynamic templates that represent the variations in the historical appearance of the target. Meanwhile, spatial attention focuses on the geometric information of the target to enhance the perceptual capabilities of the model. This interactive use of spatio-temporal information makes the Regional Proposal Network (RPN) generate higher-quality object-oriented proposals. Second, a dynamic metric memory network encompassing writing and reading mechanisms is designed. The former includes a metric learning judgment strategy to maintain temporal consistency and dynamically memorize significant variations. The latter reads out the entire memory to verify the quality of the candidate region and infer the optimal candidate, in which the short-term memory is used to update the template. The designed network enhances the tracker’s adaptive capability to target changes. Finally, we employ an online refinement network to rectify the prediction results to further improve the tracking performance, which updates the memory pool and switches the local–global search strategy. our experimental results on benchmarks such as VOT-LT2018 and others demonstrate that our proposed tracker is on par with the current state-of-the-art tracking algorithms.},
  archive      = {J_PAAA},
  author       = {Zhang, Huanlong and Fu, Weiqiang and Yang, Xiangbo and Qi, Rui and Wang, Xin and Zhang, Chunjie},
  doi          = {10.1007/s10044-025-01441-w},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Dynamic metric memory network for long-term tracking with spatial-temporal region proposal method},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vehicle and license plate recognition with novel dataset for
toll collection. <em>PAAA</em>, <em>28</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s10044-025-01443-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an automatic toll tax collection framework designed for challenging conditions, consisting of three sequential steps: vehicle type recognition, license plate localization, and license plate reading. Traditional decorations on vehicle fronts often introduce significant intra-class variations, severe background clutter, and partial occlusions, complicating both license plate detection and reading. In addition, non-uniform license plate positions-particularly on trucks-and variations in font styles, sizes, and partially occluded characters further challenge the process. To address these issues, we leverage advanced deep learning architectures along with a novel dataset of 10k images covering six vehicle types. Each image is manually annotated with the vehicle type and the alphanumeric characters of its license plate. We evaluate our framework using state-of-the-art YOLO models, from the initial to the latest versions: Yolov2, Yolov3, Yolov4, YOLOv5, YOLOv8, and YOLOv11, and assess their lightweight (Nano) variants for real-time deployment on a Raspberry Pi. Our experimental results demonstrate that the large variants of YOLOv5, YOLOv8, and YOLOv11 consistently achieve a top mean average precision (mAP@0.5) of 99% across all tasks, while their Nano versions attain peak mAP values of 98%, 97%, and 98% for vehicle type recognition, license plate detection, and character recognition, respectively. The code, trained models, and test images are available at https://github.com/usama-x930/VT-LPR .},
  archive      = {J_PAAA},
  author       = {Usama, Muhammad and Anwar, Hafeez and Anwar, Saeed},
  doi          = {10.1007/s10044-025-01443-8},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Vehicle and license plate recognition with novel dataset for toll collection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSGGSA: A multi-strategy-guided gravitational search
algorithm for gene selection in cancer classification. <em>PAAA</em>,
<em>28</em>(2), 1–30. (<a
href="https://doi.org/10.1007/s10044-025-01446-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microarray gene expression data, widely employed in the field of cancer research, provides valuable insights for distinguishing between various types of cancers. However, the inherent challenges associated with microarray data, such as limited sample size and high dimensionality, complicate the process of cancer classification. To effectively address these challenges, swarm intelligence optimization techniques have been employed for gene selection from microarray gene expression datasets. Nevertheless, accurately classifying cancer types remains a formidable challenge. The present study presents a gene selection method for cancer classification, employing a multi-strategy-guided gravitational search algorithm (MSGGSA). In MSGGSA, the traditional gravitational search algorithm (GSA) is enhanced by incorporating strategies such as segmented population initialization, inertia stagnation, dynamic update of gravitational constant, and relearning strategy for elite individuals. The proposed enhancements effectively address the limitations associated with excessive randomness in the initial population, premature convergence susceptibility, and vulnerability to local optima encountered by traditional GSA. Moreover, this enhancement effectively achieves a balance between exploration and exploitation within algorithm. The superior performance of the proposed algorithm on high-dimensional data is demonstrated through rigorous testing on 12 publicly available microarray datasets, highlighting its superiority over other popular swarm intelligence algorithms and current state-of-the-art methods.},
  archive      = {J_PAAA},
  author       = {Li, Min and Jin, Chen and Cai, Yuheng and Deng, Shaobo and Wang, Lei},
  doi          = {10.1007/s10044-025-01446-5},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-30},
  shortjournal = {Pattern Anal. Appl.},
  title        = {MSGGSA: A multi-strategy-guided gravitational search algorithm for gene selection in cancer classification},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conversion-aware forecasting of alzheimer’s disease via
featurewise attention. <em>PAAA</em>, <em>28</em>(2), 1–15. (<a
href="https://doi.org/10.1007/s10044-025-01447-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a neurodegenerative disorder that leads to cerebral atrophy, impacting memory and cognitive abilities. A precursor to AD known as Mild Cognitive Impairment (MCI) shows subtle symptoms that do not overwhelm the patients’ daily activities. MCI patients might eventually progress to AD in later stages. Early detection of the conversion is a vital step in preventative treatment planning. However, conversion detection is challenging due to the rarity of conversion visits in public datasets and the unknown nature of the conversion. This study aims to improve conversion detection with an attention-based architecture designed to encode input biomarkers and time into a shared space where time and attribute embeddings are fused with attention. Temporal information is incorporated as a separate modality with time embeddings to capture the correlation between time and feature significance for the model’s predictions. Experiments with widely used public databases (TADPOLE and NACC) show encouraging performance in conversion detection. In TADPOLE, a conversion recall of 74.3%, significantly outperforming baseline models such as logistic regression (36.9%) and Long Short-Term Memory networks (62.3%), is reported while maintaining an area under the curve (AUC) score of 82.0%. In NACC, our model demonstrates a competitive conversion recall of 71.6% and an AUC of 82.6%. The experimental results highlight the contribution of the attention between time and attributes to MCI-AD conversion recall. The experimental analyses hold promise for assisting physicians in designing targeted preventative treatment strategies for at-risk individuals. The implementation of the proposed method is available at https://github.com/ALLab-Boun/FATE-Net .},
  archive      = {J_PAAA},
  author       = {Karasu, Elvan and Baytaş, İnci M.},
  doi          = {10.1007/s10044-025-01447-4},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Conversion-aware forecasting of alzheimer’s disease via featurewise attention},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dmvae: A dual-stream multi-modal variational autoencoder for
multi-task fake news detection. <em>PAAA</em>, <em>28</em>(2), 1–12. (<a
href="https://doi.org/10.1007/s10044-025-01412-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of fake news on social media platforms, facilitated by the development of the Internet, has become a pressing social issue, intensifying the urgency of detecting its diverse multi-modal forms. However, current methods are unable to verify the validity of the extracted multimodal features, ignore the problem of interaction between multimodal content, and fail to learn valid cross-modal features. In this paper, we took a look into new multi-modal learning methods for representation and fusion in fake news detection. A two-branch adversarial network is designed to extract different levels of event-irrelevant features, while inter-modal information interaction and intra-modal information enhancement are followed to improve the richness of the features. To improve the interpretability of the model, a multi-task learning methodology based on the variational autoencoder structure is proposed in detail, which redesigns a general loss function to balance competitive submodules, and verifies the effectiveness of the multi-modal features in turn. Finally, by comparing and analyzing the experimental results of different methods, it is demonstrated that the multimodal fake news detection model proposed in this paper can effectively improve the effectiveness of fake news detection.},
  archive      = {J_PAAA},
  author       = {Guo, Ying and Hu, Shuting and Li, Yao and Di, Chong and Liu, Jie},
  doi          = {10.1007/s10044-025-01412-1},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-12},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Dmvae: A dual-stream multi-modal variational autoencoder for multi-task fake news detection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uieanything: Zero-shot underwater image enhancement via
advanced depth estimation, white balance models, and improved sea-thru.
<em>PAAA</em>, <em>28</em>(2), 1–25. (<a
href="https://doi.org/10.1007/s10044-025-01422-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater image enhancement is fundamental for marine applications yet remains challenging due to complex light-water interactions that degrade image quality through wavelength-dependent absorption and scattering effects. Existing methods often require extensive paired training data and struggle to generalize across diverse underwater conditions. We propose UIEAnything, a novel zero-shot underwater image enhancement framework that integrates automatic white balance preprocessing, physics-guided depth estimation, and an improved restoration algorithm based on underwater light transport theory. Our approach introduces three key innovations: (1) a domain adaptation strategy that bridges the gap between underwater and natural images via physically motivated white balance correction, enabling effective utilization of pre-trained models; (2) an improved Sea-thru algorithm incorporating nonlinear backscatter modeling and adaptive attenuation estimation, accurately capturing the depth-dependent nature of underwater light propagation; and (3) a unified framework that eliminates the need for task-specific training while maintaining physical consistency. Extensive experiments on seven benchmark datasets demonstrate that UIEAnything consistently outperforms state-of-the-art methods, achieving average improvements of 15.3% in PSNR and 12.8% in SSIM. Furthermore, without additional training, our framework demonstrates remarkable generalization capability by successfully addressing other challenging vision tasks involving scattering media, such as image dehazing and sandstorm removal. These results establish UIEAnything as a significant advancement in physics-guided zero-shot learning for image enhancement in complex optical environments.},
  archive      = {J_PAAA},
  author       = {Shao, Jinxin and Zhang, Haosu and Miao, Jianming},
  doi          = {10.1007/s10044-025-01422-z},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-25},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Uieanything: Zero-shot underwater image enhancement via advanced depth estimation, white balance models, and improved sea-thru},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accumulating global channel-wise patterns via
deformed-bottleneck recalibration for image classification.
<em>PAAA</em>, <em>28</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s10044-025-01429-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding attention modules into deep convolutional neural networks (CNNs) is currently one of the common deliberations to enhance their learning ability of feature representation. In previous works, the global channel-wise patterns of a given tensor are computed and squeezed into CNN-based models through an attention mechanism. Squeezing different kinds of these features can lead to the less fusion of attentive information due to the independent operations of channel-wise recalibration. To deal with this issue, an efficient attention module of accumulated features ( $$\textrm{MAF}$$ ) is proposed by accumulating these diverse squeezes for a unitary recalibrating perceptron as follows. Firstly, we take advantage of average and deviation calculations to produce correspondingly statistical patterns of a given tensor for aggregating the global channel information. An adaptative perceptron of deformed-bottleneck recalibration ( $$\textrm{DBR}$$ ) is then presented to cohere the resultant features. Finally, the robust $$\textrm{DBR}$$ -based lightweights will be utilized to weight the concerning tensor. Additionally, to exploit more spatial-wise information, we address $$\textrm{MAF}$$ for an effective alternative of the channel-wise component in two critical attention units to form two corresponding modules that will be then inspected to indicate which integration is good for real applications. We adapt the MAF-based modules to MobileNets for further enhancement investigation. Experiments on benchmark datasets for image classification have proved the efficacy of our proposals. The code of the MAF module is available at https://github.com/nttbdrk25/MAFAttention .},
  archive      = {J_PAAA},
  author       = {Nguyen, Thanh Tuan and Nguyen, Thanh Phuong and Nguyen, Vincent},
  doi          = {10.1007/s10044-025-01429-6},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Accumulating global channel-wise patterns via deformed-bottleneck recalibration for image classification},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DPPCN: Density and position-based point convolution network
for point cloud segmentation. <em>PAAA</em>, <em>28</em>(2), 1–10. (<a
href="https://doi.org/10.1007/s10044-025-01436-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A point cloud can usually describe the outline and spatial location of an object. Due to the disorder and uneven density of the point cloud, it is a difficult task to fully obtain the local features and spatial context information of the point cloud. In this paper, we propose a point cloud segmentation network based on the encoding–decoding structure of point convolution, which extracts the local features of point clouds by density-position adaptive convolution, which integrates density information and positional relationships between points. To obtain the density information of center points, we design an auto-adjusted bandwidth and integrate it into adaptive kernel density estimation. In addition, to obtain the context of the point cloud to a greater extent, we design an encoding layer that carries the contextual information. In order to verify the effectiveness of our method, experiments were carried out on S3DIS and a self-built dataset. The experimental results verify the validity of our proposed method.},
  archive      = {J_PAAA},
  author       = {Li, Yaqian and Zhang, Ze and Li, Haibin and Zhang, Wenming},
  doi          = {10.1007/s10044-025-01436-7},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-10},
  shortjournal = {Pattern Anal. Appl.},
  title        = {DPPCN: Density and position-based point convolution network for point cloud segmentation},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive deep CNN: An effective alzheimer’s affected MRI
image registration using heuristic-aided deep learning model and
patch-based level fusion. <em>PAAA</em>, <em>28</em>(2), 1–24. (<a
href="https://doi.org/10.1007/s10044-025-01438-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aligning multiple images is referred to as image registration. Image registration methods aim to find the best adjustment to align the important elements in the images.Registering techniques can be modified to fit specific objectives by balancing rapidity with precision. Magnetic Resonance Imaging (MRI) methods are becoming increasingly significant in Alzheimer’s Disease (AD) in themedical sector. Several intriguing applications for machine learning approaches in clinical imaging exist, including the recognition of AD using MRI scans of the brain. Numerous preprocessing procedures, such as image registration, are often performed on these scans. However, the impact of registration of image approaches on machine learning classification effectiveness is little understood. To address these challenges, a new deep learning approach is suggested for registering images ofAD using MRI images. Originally, the images are garnered from the standard datasets. The patch-based label fusion method is suggested from the collected images, where the patches and their weights are estimated by the similarity measures among the patches using labeling and intensity-based distances. Subsequently, the patches are considered for hippocampal segmentation using anatlas-based segmentation model.The hippocampus is a critical brain structure involved in memory and learning, and it is one of the first regions to exhibit damage in AD. As Alzheimer’s grows, the hippocampus undergoes significant atrophy, leading to the characteristic memory loss and cognitive decline associated with the condition. Hippocampal segmentation, which involves isolating and analyzing the hippocampus from MRI scans, is essential for detecting these changes early. Accurately measuring the volume and structure of the hippocampus helps to identify signs of Alzheimer’s before other symptoms become apparent. Furthermore, precise hippocampal segmentation helps differentiate Alzheimer’s from other neurological conditions, ensuring more accurate diagnoses and tailored treatment strategies.Finally, the “Adaptive Deep Registration” is newly proposed to register the images by utilizing anAdaptive Deep Convolutional Neural Network (DCNN), in which the hyper-parameters are optimized using the Modified Gannet Optimization Algorithm (MGOA). The term “adaptive” in Adaptive DCNN reflects the model’s ability to dynamically optimize its parameters. In the context of image registration, this adaptiveness allows the MGOAto fine-tune DCNN’s parameters, such as hidden neuron count, epoch count, and step per epoch, in response to the complexity and variability of the input images. This ensures that the network can effectively learn from diverse data, improving its accuracy in aligning and registering images. The adaptive nature of the DCNN, further enhanced by the MGOA, allows the network to continuously tune its performance, adjusting hyperparameters on the fly to achieve the best possible outcomes in image registration tasks. This adaptability is crucial in handling the intricate patterns and subtle differences found in medical images, such as those of the hippocampus in Alzheimer’s disease, leading to more accurate and consistent results.At last, the efficacy of the model is examined using divergent measurements. Rather than existing methods, the proposed model acquires impressive results of performance enhancement.},
  archive      = {J_PAAA},
  author       = {Deshmukh, Vaidehi and Chapadgaonkar, Shilpa and Kowdiki, Manisha and Khaparde, Arti},
  doi          = {10.1007/s10044-025-01438-5},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-24},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Adaptive deep CNN: An effective alzheimer’s affected MRI image registration using heuristic-aided deep learning model and patch-based level fusion},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structured regularization with object size selection using
mathematical morphology. <em>PAAA</em>, <em>28</em>(2), 1–18. (<a
href="https://doi.org/10.1007/s10044-025-01444-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel way to incorporate morphology operators through structured regularization of machine learning models. Specifically, we introduce a feature map in the models that performs structured variable selection. The feature map is automatically processed by approximate morphology operators and is learned together with the model coefficients. Experiments were conducted with linear regression on both synthetic data, demonstrating that the proposed methods are effective in selecting groups of parameters with much less noise than baseline models, and on three-dimensional T1-weighted brain magnetic resonance images (MRI) for age prediction, demonstrating that the proposed methods enforce sparsity and select homogeneous regions of non-zero and relevant regression coefficients. The proposed methods improve interpretability in pattern analysis. The minimum size of features in the structured variable selection can be controlled by adjusting the structuring element in the approximate morphology operator, tailored to the specific study of interest. With these added benefits, the proposed methods still perform on par with commonly used variable selection and structured variable selection methods in terms of the coefficient of determination and the Pearson correlation coefficient.},
  archive      = {J_PAAA},
  author       = {Lin, Disi and Hägg, Linus and Wadbro, Eddie and Berggren, Martin and Löfstedt, Tommy},
  doi          = {10.1007/s10044-025-01444-7},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-18},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Structured regularization with object size selection using mathematical morphology},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel fusion approach with a robust ParallelNet model for
diabetic retinopathy diagnosis. <em>PAAA</em>, <em>28</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s10044-025-01448-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Retinopathy (DR) is a serious diabetes-related complication that can lead to significant retinal damage and irreversible vision loss if not detected and treated early. While numerous deep learning algorithms have recently been developed for DR diagnosis, however they often focus on specific symptoms like exudates, vessels, or hemorrhages, overlooking a comprehensive analysis of all relevant indicators. Though, previous studies have shown high performance on benchmark public datasets but have struggled with real-time data. This paper introduces a diagnostic system that systematically incorporates all detectable symptoms of diabetic retinopathy and has demonstrated reliable performance on 108 test images from Lahore General Hospital, showcasing its robustness in real-world scenarios. Additionally, a novel algorithm for extracting retinal exudates is proposed, outperforming existing methods. The study categorizes retinal fundus images into both 2-class and multi-class diabetic retinopathy. Evaluation of current models on a local hospital dataset shows significant accuracy improvements. We also present ParallelNet, a model for classifying Diabetic Retinopathy stages: No DR, NPDR, PDR. ParallelNet outperforms established models, achieving 96% accuracy on the APTOS dataset and 90.16% on the local dataset for binary classification. For multi-classification, it achieves 90% accuracy on the APTOS dataset and 87.05% on the local dataset. These results highlight the improved performance achieved by combining our extraction algorithms with the ParallelNet model, demonstrating robustness across both public and local real-time hospital datasets.},
  archive      = {J_PAAA},
  author       = {Mahmood, Haroon and Ather, Saad and Wali, Aamir and Ali, Arshad and Malik, Tayyaba Gul and Kafeel, Wardah},
  doi          = {10.1007/s10044-025-01448-3},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A novel fusion approach with a robust ParallelNet model for diabetic retinopathy diagnosis},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual stream deep attention networks for annual population
projection. <em>PAAA</em>, <em>28</em>(2), 1–13. (<a
href="https://doi.org/10.1007/s10044-025-01451-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate population projections are essential for local and state governments planning and decision-making processes, as they directly influence the development of local infrastructure and services. Recent advancements in time series forecasting, particularly through machine learning applied to diverse social and economic factors, have improved predictive accuracy, enabling more informed decision-making at local and state levels. Therefore, researchers have explored various statistical, machine learning, and deep learning methods. However, these approaches often rely on standalone models or simple feature integration, which results need to be improved. Furthermore, the existing methods lack hybrid methods with attention mechanisms to effectively capture rich intricate features. To tackle these challenges, we designed a hybrid method, a dual-stream deep attention network namely Deep Population Network (DPNET) for annual population forecasting. The first stream employs convolutional layers to capture spatial patterns while the second stream extracts the temporal information. The output of these two streams is then concatenated and fed to the self-attention module for feature refinement followed by a fully connected layer. The DPNET showcases promising performance in small-area population projection across multiple datasets collected from Korea, Australia, and New Zealand for 10-year and 5-year forecasting periods. Compared to existing approaches, DPNET significantly reduced the error rate, achieving the lowest Mean Absolute Percentage Error (MAPE) of 5.30% and Median Absolute Percentage Error (MedAPE) of 3.03% for the Korean dataset, 6.02% MAPE and 4.09% MedAPE for the Australian dataset, and 3.99% MedAPE for the New Zealand dataset.},
  archive      = {J_PAAA},
  author       = {Hussain, Adnan and Yar, Hikmat and Khan, Noman and Khan, Zulfiqar Ahmad and Kim, Min Je and Baik, Sung Wook},
  doi          = {10.1007/s10044-025-01451-8},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-13},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Dual stream deep attention networks for annual population projection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Texture-driven pose-guided human image synthesis.
<em>PAAA</em>, <em>28</em>(2), 1–16. (<a
href="https://doi.org/10.1007/s10044-025-01452-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of computer vision and artificial intelligence, significant breakthroughs have been made in the field of character image synthesis. Although existing methods can synthesize target pose images, there are still limitations in handling complex textures and pose alignment, such as texture distortion, pose misalignment, and missing information. To address this, this paper proposes a pose-guided human image synthesis method called Human Pose Transfer Generative Adversarial Network (HPT-GAN). The model significantly improves the quality and efficiency of synthetic images by introducing ResBlocks module, designing a Texture Transfer Module (TTM) and a ToRGB module. Specifically, ResBlocks enhance gradient stability while preserving context information, TTM efficiently aligns textures through a multi-head attention mechanism, and the ToRGB module optimizes the fusion of multi-resolution features. HPT-GAN has a small number of parameters while achieving faster processing speed than similar methods. Moreover, it has achieved good results on the DeepFashion and Market-1501 datasets.},
  archive      = {J_PAAA},
  author       = {Wei, Wei and Qin, Chao and Duan, Xiaodong},
  doi          = {10.1007/s10044-025-01452-7},
  journal      = {Pattern Analysis and Applications},
  month        = {6},
  number       = {2},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Texture-driven pose-guided human image synthesis},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ptrf---12">PTRF - 12</h2>
<ul>
<li><details>
<summary>
(2025). The dynamical ising-kac model in 3D converges to <span
class="math display"><em>Φ</em><sub>3</sub><sup>4</sup></span>.
<em>PTRF</em>, <em>191</em>(1), 671–778. (<a
href="https://doi.org/10.1007/s00440-024-01316-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Glauber dynamics of a ferromagnetic Ising-Kac model on a three-dimensional periodic lattice of size $$(2 N + 1)^3$$ , in which the flipping rate of each spin depends on an average field in a large neighborhood of radius $$\gamma ^{-1}&lt;\!\!&lt; N$$ . We study the random fluctuations of a suitably rescaled coarse-grained spin field as $$N \rightarrow \infty $$ and $$\gamma \rightarrow 0$$ ; we show that near the mean-field value of the critical temperature, the process converges in distribution to the solution of the dynamical $$\Phi ^4_3$$ model on a torus. Our result settles a conjecture from Giacomin et al. (1999). The dynamical $$\Phi ^4_3$$ model is given by a non-linear stochastic partial differential equation (SPDE) which is driven by an additive space-time white noise and which requires renormalisation of the non-linearity. A rigorous notion of solution for this SPDE and its renormalisation is provided by the framework of regularity structures (Hairer in Invent Math 198(2):269–504, 2014. https://doi.org/10.1007/s00222-014-0505-4 ). As in the two-dimensional case (Mourrat and Weber in Commun Pure Appl Math 70(4):717–812, 2017), the renormalisation corresponds to a small shift of the inverse temperature of the discrete system away from its mean-field value.},
  archive      = {J_PTRF},
  author       = {Grazieschi, P. and Matetski, K. and Weber, H.},
  doi          = {10.1007/s00440-024-01316-x},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {671-778},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {The dynamical ising-kac model in 3D converges to $$\Phi ^4_3$$},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantitative stochastic homogenization for random
conductance models with stable-like jumps. <em>PTRF</em>,
<em>191</em>(1), 627–669. (<a
href="https://doi.org/10.1007/s00440-024-01354-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider random conductance models with long range jumps on $$\mathbb {Z}^d$$ , where the one-step transition probability from x to y is proportional to $$w_{x,y}|x-y|^{-d-\alpha }$$ with $$\alpha \in (0,2)$$ . Assume that $$\{w_{x,y}\}_{(x,y)\in E}$$ are independent, identically distributed and uniformly bounded non-negative random variables with $$\mathbb {E}w_{x,y}=1$$ , where E is the set of all unordered pairs on $$\mathbb {Z}^d$$ . We obtain a quantitative version of stochastic homogenization for these random walks, with explicit polynomial rates up to logarithmic corrections.},
  archive      = {J_PTRF},
  author       = {Chen, Xin and Chen, Zhen-Qing and Kumagai, Takashi and Wang, Jian},
  doi          = {10.1007/s00440-024-01354-5},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {627-669},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {Quantitative stochastic homogenization for random conductance models with stable-like jumps},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluctuations in the logarithmic energy for zeros of random
polynomials on the sphere. <em>PTRF</em>, <em>191</em>(1), 569–626. (<a
href="https://doi.org/10.1007/s00440-024-01334-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smale’s Seventh Problem asks for an efficient algorithm to generate a configuration of n points on the sphere that nearly minimizes the logarithmic energy. As a candidate starting configuration for this problem, Armentano, Beltrán and Shub considered the set of points given by the stereographic projection of the roots of the random elliptic polynomial of degree n and computed the expected logarithmic energy. We study the fluctuations of the logarithmic energy associated to this random configuration and prove a central limit theorem. Our approach shows that all cumulants of the logarithmic energy are asymptotically linear in n, and hence the energy is well-concentrated on the scale of $$\sqrt{n}$$ .},
  archive      = {J_PTRF},
  author       = {Michelen, Marcus and Yakir, Oren},
  doi          = {10.1007/s00440-024-01334-9},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {569-626},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {Fluctuations in the logarithmic energy for zeros of random polynomials on the sphere},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularity of laws via dirichlet forms: Application to
quadratic forms in independent and identically distributed random
variables. <em>PTRF</em>, <em>191</em>(1), 523–567. (<a
href="https://doi.org/10.1007/s00440-024-01332-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the regularity of the law of a quadratic form Q(X, X), evaluated in a sequence $$X = (X_{i})$$ of independent and identically distributed random variables, when $$X_{1}$$ can be expressed as a sufficiently smooth function of a Gaussian field. This setting encompasses a large class of important and frequently used distributions, such as, among others, Gaussian, Beta, for instance uniform, Gamma distributions, or else any polynomial transform of them. Let us present an emblematic application. Take $$X = (X_{i})$$ a sequence of independent and identically distributed centered random variables, with unit variance, following such distribution. Consider also $$(Q_{n})$$ a sequence of quadratic forms, with associated symmetric Hilbert–Schmidt operators $$({\textsf{A}}^{(n)})$$ . Assume that $${{\,\textrm{Tr}\,}}[ ({\textsf{A}}^{(n)})^{2} ] = 1/2$$ , $${\textsf{A}}^{(n)}_{ii} =0$$ , and the spectral radius of $${\textsf{A}}^{(n)}$$ tends to 0. Then, $$(Q_{n}(X))$$ converges in a strong sense to the standard Gaussian distribution. Namely, all derivatives of the densities, which are well-defined for n sufficiently large, converge uniformly on $$\mathbb {R}$$ to the corresponding derivatives of the standard Gaussian density. While classical methods, from Malliavin calculus or $$\Gamma $$ -calculus, generally consist in bounding negative moments of the so-called carré du champ operator $$\Gamma (Q(X),Q(X))$$ , we provide a new paradigm through a second-order criterion involving the eigenvalues of a Hessian-type matrix related to Q(X). This Hessian is built by iterating twice a tailor-made gradient, the sharp operator $$\sharp $$ , obtained via a Gaussian representation of the carré du champ. We believe that this method, recently developed by the authors in the current paper and Herry et al. (Ann Probab 52(3):1162–1200, 2024), is of independent interest and could prove useful in other settings.},
  archive      = {J_PTRF},
  author       = {Herry, Ronan and Malicet, Dominique and Poly, Guillaume},
  doi          = {10.1007/s00440-024-01332-x},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {523-567},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {Regularity of laws via dirichlet forms: Application to quadratic forms in independent and identically distributed random variables},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence of three-dimensional loop-erased random walk in
the natural parametrization. <em>PTRF</em>, <em>191</em>(1), 421–521.
(<a href="https://doi.org/10.1007/s00440-024-01338-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we consider loop-erased random walk (LERW) and its scaling limit in three dimensions, and prove that 3D LERW parametrized by renormalized length converges to its scaling limit parametrized by some suitable measure with respect to the uniform convergence topology in the lattice size scaling limit. Our result greatly improves the work (Kozma in Acta Math 199:29-152, 2007) of Gady Kozma which establishes the weak convergence of the rescaled trace of 3D LERW towards a random compact set with respect to the Hausdorff distance.},
  archive      = {J_PTRF},
  author       = {Li, Xinyi and Shiraishi, Daisuke},
  doi          = {10.1007/s00440-024-01338-5},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {421-521},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {Convergence of three-dimensional loop-erased random walk in the natural parametrization},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From ABC to KPZ. <em>PTRF</em>, <em>191</em>(1), 361–420.
(<a href="https://doi.org/10.1007/s00440-024-01314-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the equilibrium fluctuations of an interacting particle system evolving on the discrete ring with $$N\in {\mathbb {N}}$$ points, denoted by $${\mathbb {T}}_N$$ , and with three species of particles that we name A, B and C, but such that at each site there is only one particle. We prove that proper choices of density fluctuation fields (that match those from nonlinear fluctuating hydrodynamics theory) associated to the (two) conserved quantities converge, in the limit $$N\rightarrow \infty $$ , to a system of stochastic partial differential equations, that can either be the Ornstein–Uhlenbeck equation or the Stochastic Burgers equation. To understand the cross interaction between the two conserved quantities, we derive a general version of the Riemann–Lebesgue lemma which is of independent interest.},
  archive      = {J_PTRF},
  author       = {Cannizzaro, G. and Gonçalves, P. and Misturini, R. and Occelli, A.},
  doi          = {10.1007/s00440-024-01314-z},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {361-420},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {From ABC to KPZ},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The fuzzy potts model in the plane: Scaling limits and arm
exponents. <em>PTRF</em>, <em>191</em>(1), 287–359. (<a
href="https://doi.org/10.1007/s00440-024-01319-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a critical Fortuin–Kasteleyn (FK) percolation with cluster weight $$q \in [1,4)$$ in the plane, and color its clusters in red (respectively blue) with probability $$r \in (0,1)$$ (respectively $$1-r$$ ), independently of each other. We study the resulting fuzzy Potts model, which corresponds to the critical Ising model in the special case $$q=2$$ and $$r=1/2$$ . We show that under the assumption that the critical FK percolation converges to a conformally invariant scaling limit (which is known to hold for the FK-Ising model,i.e. $$q=2$$ ), the obtained coloring converges to variants of Conformal Loop Ensembles constructed, described and studied by Miller, Sheffield and Werner. Based on discrete considerations, we also show that the arm exponents for this coloring in the discrete model are identical to the ones of the continuum model. Using the values of these arm exponents in the continuum, we determine the arm exponents for the fuzzy Potts model.},
  archive      = {J_PTRF},
  author       = {Köhler-Schindler, Laurin and Lehmkuehler, Matthis},
  doi          = {10.1007/s00440-024-01319-8},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {287-359},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {The fuzzy potts model in the plane: Scaling limits and arm exponents},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geodesic lévy flights and expected stopping time for random
searches. <em>PTRF</em>, <em>191</em>(1), 235–285. (<a
href="https://doi.org/10.1007/s00440-024-01327-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We give an analytic description for the infinitesimal generator constructed in Applebaum and Estrade (Ann Probab 28(1):166-184, 2000) for Lévy flights on a broad class of closed Riemannian manifolds including all negatively-curved manifolds, the flat torus and the sphere. Various properties of the associated semigroup and the asymptotics of the expected stopping time for Lévy flight based random searches for small targets, also known as the “narrow capture problem&quot;, are then obtained using our newfound understanding of the infinitesimal generator. Our study also relates to the Lévy flight foraging hypothesis in the field of biology as we compute the expected time for finding a small target by using the Lévy flight random search. Compared to the random search time for Brownian motion on surfaces done in Nursultanov et al. ( arXiv:2209.12425 ), our result suggests that Lévy flight may not always be the optimal strategy, consistent with the conclusion obtained in Palyulin et al. (Proc Natl Acad Sci 111(8):2931-2936, 2014) for the one dimensional case.},
  archive      = {J_PTRF},
  author       = {Chaubet, Yann and Bonthonneau, Yannick Guedes and Lefeuvre, Thibault and Tzou, Leo},
  doi          = {10.1007/s00440-024-01327-8},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {235-285},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {Geodesic lévy flights and expected stopping time for random searches},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Equivalence of approximate message passing and low-degree
polynomials in rank-one matrix estimation. <em>PTRF</em>,
<em>191</em>(1), 181–233. (<a
href="https://doi.org/10.1007/s00440-024-01322-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of estimating an unknown parameter vector $${\varvec{\theta }}\in {{\mathbb {R}}}^n$$ , given noisy observations $${{\varvec{Y}}}= {\varvec{\theta }}{\varvec{\theta }}^{\textsf{T}}/\sqrt{n}+{{\varvec{Z}}}$$ of the rank-one matrix $${\varvec{\theta }}{\varvec{\theta }}^{\textsf{T}}$$ , where $${{\varvec{Z}}}$$ has independent Gaussian entries. When information is available about the distribution of the entries of $${\varvec{\theta }}$$ , spectral methods are known to be strictly sub-optimal. Past work characterized the asymptotics of the accuracy achieved by the optimal estimator. However, no polynomial-time estimator is known that achieves this accuracy. It has been conjectured that this statistical-computation gap is fundamental, and moreover that the optimal accuracy achievable by polynomial-time estimators coincides with the accuracy achieved by certain approximate message passing (AMP) algorithms. We provide evidence towards this conjecture by proving that no estimator in the (broader) class of constant-degree polynomials can surpass AMP.},
  archive      = {J_PTRF},
  author       = {Montanari, Andrea and Wein, Alexander S.},
  doi          = {10.1007/s00440-024-01322-z},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {181-233},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {Equivalence of approximate message passing and low-degree polynomials in rank-one matrix estimation},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonparametric bayesian estimation in a multidimensional
diffusion model with high frequency data. <em>PTRF</em>,
<em>191</em>(1), 103–180. (<a
href="https://doi.org/10.1007/s00440-024-01317-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider nonparametric Bayesian inference in a multidimensional diffusion model with reflecting boundary conditions based on discrete high-frequency observations. We prove a general posterior contraction rate theorem in $$L^2$$ -loss, which is applied to Gaussian priors. The resulting posteriors, as well as their posterior means, are shown to converge to the ground truth at the minimax optimal rate over Hölder smoothness classes in any dimension. Of independent interest and as part of our proofs, we show that certain frequentist penalized least squares estimators are also minimax optimal.},
  archive      = {J_PTRF},
  author       = {Hoffmann, Marc and Ray, Kolyan},
  doi          = {10.1007/s00440-024-01317-w},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {103-180},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {Nonparametric bayesian estimation in a multidimensional diffusion model with high frequency data},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rearranged stochastic heat equation. <em>PTRF</em>,
<em>191</em>(1), 41–102. (<a
href="https://doi.org/10.1007/s00440-024-01335-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this work is to provide an explicit construction of a strong Feller semigroup on the space of probability measures over the real line that additionally maps bounded measurable functions into Lipschitz continuous functions, with a Lipschitz constant that blows up in an integrable manner in small time. Our construction relies on a rearranged version of the stochastic heat equation on the circle driven by a coloured noise. Formally, this stochastic equation writes as a reflected equation in infinite dimension. Under the action of the rearrangement, the solution is forced to live in a space of quantile functions that is isometric to the space of probability measures on the real line. We prove the equation to be solvable by means of an Euler scheme in which we alternate flat dynamics in the space of random variables on the circle with a rearrangement operation that projects back the random variables onto the subset of quantile functions. A first challenge is to prove that this scheme is tight. A second one is to provide a consistent theory for the limiting reflected equation and in particular to interpret in a relevant manner the reflection term. The last step in our work is to establish the aforementioned Lipschitz property of the semigroup by adapting earlier ideas from the Bismut–Elworthy–Li formula.},
  archive      = {J_PTRF},
  author       = {Delarue, François and Hammersley, William R. P.},
  doi          = {10.1007/s00440-024-01335-8},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {41-102},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {Rearranged stochastic heat equation},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local central limit theorem for gradient field models.
<em>PTRF</em>, <em>191</em>(1), 1–40. (<a
href="https://doi.org/10.1007/s00440-024-01330-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the gradient field model in $$\left[ -N,N\right] ^{2}\cap {\mathbb {Z}}^{2}$$ with a uniformly convex interaction potential. Naddaf–Spencer (Comm Math Phys 183(1):55–84, 1997) and Miller (Comm Math Phys 908(3):591–639, 2011) proved that the macroscopic averages of linear statistics of the field converge to a continuum Gaussian free field. In this paper we prove the distribution of $$\phi (0)/\sqrt{\log N}$$ converges uniformly in $${\mathbb {R}}$$ to a Gaussian density, with a Berry-Esseen type bound. This implies the distribution of $$\phi (0)$$ is sufficiently ‘Gaussian like’ between $$[-\sqrt{\log N}, \sqrt{\log N}]$$ .},
  archive      = {J_PTRF},
  author       = {Wu, Wei},
  doi          = {10.1007/s00440-024-01330-z},
  journal      = {Probability Theory and Related Fields},
  month        = {2},
  number       = {1},
  pages        = {1-40},
  shortjournal = {Probab. Theory Relat. Fields},
  title        = {Local central limit theorem for gradient field models},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="sac---20">SAC - 20</h2>
<ul>
<li><details>
<summary>
(2025). Simulation based composite likelihood. <em>SAC</em>,
<em>35</em>(3), 1–20. (<a
href="https://doi.org/10.1007/s11222-025-10584-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inference for high-dimensional hidden Markov models is challenging due to the exponential-in-dimension computational cost of calculating the likelihood. To address this issue, we introduce an innovative composite likelihood approach called “Simulation Based Composite Likelihood” (SimBa-CL). With SimBa-CL, we approximate the likelihood by the product of its marginals, which we estimate using Monte Carlo sampling. In a similar vein to approximate Bayesian computation (ABC), SimBa-CL requires multiple simulations from the model, but, in contrast to ABC, it provides a likelihood approximation that guides the optimization of the parameters. Leveraging automatic differentiation libraries, it is simple to calculate gradients and Hessians to not only speed up optimization but also to build approximate confidence sets. We present extensive empirical results which validate our theory and demonstrate its advantage over SMC, and apply SimBa-CL to real-world Aphtovirus data.},
  archive      = {J_SAC},
  author       = {Rimella, Lorenzo and Jewell, Chris and Fearnhead, Paul},
  doi          = {10.1007/s11222-025-10584-z},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-20},
  shortjournal = {Stat. Comput.},
  title        = {Simulation based composite likelihood},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact score and information matrix for panel hidden
semi-markov models. <em>SAC</em>, <em>35</em>(3), 1–12. (<a
href="https://doi.org/10.1007/s11222-025-10585-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We describe a general multivariate hidden semi-Markov model for time series and panel data. The model entails multiple response variables arising from exponential families conditionally on covariates and a discrete time-varying latent variable. The latter is modeled through transition probabilities and sojourn time distributions. We derive efficient forward recursions to exactly compute the score and information matrix. In a simulation study, we show the validity of our inferential approach for parameter and standard error estimation. The approach is also illustrated on an original real data example on sales of four arm types from member countries of the North Atlantic Treaty Organization to non-member countries in the period 2002–2022.},
  archive      = {J_SAC},
  author       = {Farcomeni, Alessio},
  doi          = {10.1007/s11222-025-10585-y},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-12},
  shortjournal = {Stat. Comput.},
  title        = {Exact score and information matrix for panel hidden semi-markov models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On approximations of subordinators in <span
class="math display"><em>L</em><sup><em>p</em></sup></span> and the
simulation of tempered stable distributions. <em>SAC</em>,
<em>35</em>(3), 1–16. (<a
href="https://doi.org/10.1007/s11222-025-10586-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subordinators are infinitely divisible distributions on the positive half-line. They are often used as mixing distributions in Poisson mixtures. We show that appropriately scaled Poisson mixtures can approximate the mixing subordinator and we derive a rate of convergence in $$L^p$$ for each $$p\in [1,\infty ]$$ . This includes the Kolmogorov and Wasserstein metrics as special cases. As an application, we develop an approach for approximate simulation of the underlying subordinator. In the interest of generality, we present our results in the context of more general mixtures, specifically those that can be represented as differences of randomly stopped Lévy processes. Particular focus is given to the case where the subordinator belongs to the class of tempered stable distributions.},
  archive      = {J_SAC},
  author       = {Grabchak, Michael and Saba, Sina},
  doi          = {10.1007/s11222-025-10586-x},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Stat. Comput.},
  title        = {On approximations of subordinators in $$L^p$$ and the simulation of tempered stable distributions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperparameter optimization for randomized algorithms: A
case study on random features. <em>SAC</em>, <em>35</em>(3), 1–28. (<a
href="https://doi.org/10.1007/s11222-025-10587-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomized algorithms exploit stochasticity to reduce computational complexity. One important example is random feature regression (RFR) that accelerates Gaussian process regression (GPR). RFR approximates an unknown function with a random neural network whose hidden weights and biases are sampled from a probability distribution. Only the final output layer is fit to data. In randomized algorithms like RFR, the hyperparameters that characterize the sampling distribution greatly impact performance, yet are not directly accessible from samples. This makes optimization of hyperparameters via standard (gradient-based) optimization tools inapplicable. Inspired by Bayesian ideas from GPR, this paper introduces a random objective function that is tailored for hyperparameter tuning of vector-valued random features. The objective is minimized with ensemble Kalman inversion (EKI). EKI is a gradient-free particle-based optimizer that is scalable to high-dimensions and robust to randomness in objective functions. A numerical study showcases the new black-box methodology to learn hyperparameter distributions in several problems that are sensitive to the hyperparameter selection: two global sensitivity analyses, integrating a chaotic dynamical system, and solving a Bayesian inverse problem from atmospheric dynamics. The success of the proposed EKI-based algorithm for RFR suggests its potential for automated optimization of hyperparameters arising in other randomized algorithms.},
  archive      = {J_SAC},
  author       = {Dunbar, Oliver R. A. and Nelsen, Nicholas H. and Mutic, Maya},
  doi          = {10.1007/s11222-025-10587-w},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-28},
  shortjournal = {Stat. Comput.},
  title        = {Hyperparameter optimization for randomized algorithms: A case study on random features},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust <span
class="math display"><em>ℓ</em><sub>2, 0</sub></span> -penalized rank
regression for high-dimensional group selection. <em>SAC</em>,
<em>35</em>(3), 1–16. (<a
href="https://doi.org/10.1007/s11222-025-10588-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse group selection is the process of selecting a small part of nonoverlapping groups to achieve the good interpretability and prediction on the response, and it has recently seen increasing applications in machine learning, image processing and bio-medical fields. However, developing robust and efficient algorithms for group selection remains a challenging research topic due to the computational complexity and potential outliers in high-dimensional settings. Motivated by the superior performance of rank-based methodology, we design a fast and efficient algorithm based on the $$\ell _{2,0}$$ penalty to achieve the goal of robust group selection for a given size of active groups s. This new algorithm can iteratively detect the active groups and exclude the irrelevant ones. When s is not less than $$s^*$$ (the true size of active groups), we theoretically prove that the proposed algorithm covers the true subset of active groups with high probability and the estimation error of the solution sequence generated by our algorithm decays to the optimal error bound in a few iterations. Moreover, coupled with the group Bayesian information criterion, an adaptive algorithm is further introduced to determine the optimal s. Theoretically, without any prior knowledge of $$s^*$$ , the proposed adaptive algorithm is able to exactly identify the true subset of active groups with probability approaching to one. Finally, extensive simulation examples show that our method outperforms existing competitors, resulting in significant improvements in terms of efficiency and accuracy of group selection and parametric estimation. The Bardet-Biedl syndrome gene expression data set is also analyzed to illustrate the application of our proposed method.},
  archive      = {J_SAC},
  author       = {Lv, Jing and Guo, Chaohui},
  doi          = {10.1007/s11222-025-10588-9},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Stat. Comput.},
  title        = {Robust $$\ell _{2,0}$$ -penalized rank regression for high-dimensional group selection},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequentist model averaging under a linear exponential loss.
<em>SAC</em>, <em>35</em>(3), 1–27. (<a
href="https://doi.org/10.1007/s11222-025-10589-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new model averaging approach to consider uncertainty in model specification using an asymmetric loss, linear exponential (LINEX) loss function. We are motivated by the existing model-averaging prediction analysis studies being based on symmetric loss functions, which cannot meet practical situations where different weights are needed for over-prediction and under-prediction. The existing approaches cannot be used for the asymmetric loss. The proposed model averaging estimator established via the LINEX model averaging (LMA) criterion is shown to be optimal in achieving the lowest possible LINEX loss. We demonstrate the superiority of the LMA method and its effectiveness in movie forecasting and bitcoin volatility forecasting applications. Compared to other methods, the LMA estimator effectively reduces asymmetric loss and performs reasonably well even in the case of symmetric loss.},
  archive      = {J_SAC},
  author       = {Li, Xinmin and Liang, Hua and Liu, Huihang and Tong, Tingting and Xie, Tian},
  doi          = {10.1007/s11222-025-10589-8},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-27},
  shortjournal = {Stat. Comput.},
  title        = {Frequentist model averaging under a linear exponential loss},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Group inference for high-dimensional mediation models.
<em>SAC</em>, <em>35</em>(3), 1–13. (<a
href="https://doi.org/10.1007/s11222-025-10591-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mediation analysis serves as a foundational statistical approach to comprehending the impact of exposure on an outcome. In this study, we investigate group inference for high-dimensional mediation models, examining mediators within a specified group either jointly or individually, allowing the number of mediators within the group to diverge. For both situations, we construct suitable test statistics and establish their asymptotic distributions. Extensive numerical studies demonstrate the superiority of our proposed methods over recent representative approaches. Our procedure can control the type I error well and exhibit the highest power. We also apply our methods to analyse how Deoxyribonucleic acid (DNA) methylation operates in the regulation of human stress reactivity impacted by childhood trauma. We have pinpointed seven key biological process groups, with the top five significant groups-axon development, neuron projection regeneration, positive regulation of the Mitogen-activated protein kinases (MAPK) cascade, regulation of neuron projection development, and axonogenesis-playing a collective role in nurturing nerve cell growth, development, and signal transmission.},
  archive      = {J_SAC},
  author       = {Yu, Ke and Guo, Xu and Luo, Shan},
  doi          = {10.1007/s11222-025-10591-0},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-13},
  shortjournal = {Stat. Comput.},
  title        = {Group inference for high-dimensional mediation models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational bayesian analysis for joint models of
longitudinal and failure time data with interval censoring.
<em>SAC</em>, <em>35</em>(3), 1–23. (<a
href="https://doi.org/10.1007/s11222-025-10592-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s Disease (AD) progression is marked by a gradual decline in cognitive function, with significant events often occurring within uncertain intervals. To comprehensively understand AD, it is essential to jointly model longitudinal cognitive assessments and interval-censored survival data. However, current methodologies have certain limitations when applied to joint models. Maximum Likelihood Estimation often neglects parameter and model uncertainty, while Bayesian methods permit uncertainty quantification but rely on traditional Markov Chain Monte Carlo algorithms, which suffer from slow convergence and high memory demands. To address these challenges, we propose variational Bayesian methods as a more computationally efficient and scalable alternative. Specifically, we focus on two approaches: the Non-Conjugate Variational Message Passing method and the Non-Conjugate Variational Laplace Approximation method. These techniques effectively approximate complex posterior distributions while minimizing the excessive computational demands typically associated with traditional Bayesian techniques. Additionally, we introduce a variational Bayesian framework for local influence analysis and outlier detection, utilizing sparse priors to enhance the model’s robustness against data anomalies. Through simulation studies and an application to the Alzheimer’s Disease Neuroimaging Initiative dataset, we demonstrate the effectiveness of our variational Bayesian joint modeling approach. Our results underscore the advantages of these methods in terms of computational efficiency and scalability, making them well-suited for analyzing complex longitudinal and interval-censored data in AD research.},
  archive      = {J_SAC},
  author       = {Li, Huiqiong and Luo, Lu and Liu, Wenting and Wang, Min and Tang, Niansheng},
  doi          = {10.1007/s11222-025-10592-z},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-23},
  shortjournal = {Stat. Comput.},
  title        = {Variational bayesian analysis for joint models of longitudinal and failure time data with interval censoring},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multifacet hierarchical sentiment-topic model with
application to multi-brand online review analysis. <em>SAC</em>,
<em>35</em>(3), 1–18. (<a
href="https://doi.org/10.1007/s11222-025-10593-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-brand analysis based on review comments and ratings is a commonly used strategy to compare different brands in marketing. It can help consumers make more informed decisions and help marketers understand their brand’s position in the market. In this work, we propose a multifacet hierarchical sentiment-topic model (MH-STM) to detect brand-associated sentiment polarities towards multiple comparative aspects from online customer reviews. The proposed method is built on a unified generative framework that explains review words with a hierarchical brand-associated topic model and the overall polarity score with a regression model on the empirical topic distribution. Moreover, a novel hierarchical Pólya urn (HPU) scheme is proposed to enhance the topic-word association among topic hierarchy, such that the general topics shared by all brands are separated effectively from the unique topics specific to individual brands. The performance of the proposed method is evaluated on both synthetic data and two real-world review corpora. Experimental studies demonstrate that the proposed method can be effective in detecting reasonable topic hierarchy and deriving accurate brand-associated rankings on multi-aspects.},
  archive      = {J_SAC},
  author       = {Liang, Qiao and Deng, Xinwei},
  doi          = {10.1007/s11222-025-10593-y},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Stat. Comput.},
  title        = {A multifacet hierarchical sentiment-topic model with application to multi-brand online review analysis},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Air-HOLP: Adaptive regularized feature screening for high
dimensional correlated data. <em>SAC</em>, <em>35</em>(3), 1–11. (<a
href="https://doi.org/10.1007/s11222-025-10599-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handling high-dimensional datasets presents substantial computational challenges, particularly when the number of features far exceeds the number of observations and when features are highly correlated. A modern approach to mitigate these issues is feature screening. In this work, the High-dimensional Ordinary Least-squares Projection (HOLP) feature screening method is advanced by employing adaptive ridge regularization. The impact of the ridge tuning parameter on the Ridge-HOLP method is examined and Adaptive iterative ridge-HOLP (Air-HOLP) is proposed, a data-adaptive advance to Ridge-HOLP where the ridge-regularization tuning parameter is selected iteratively and optimally for better feature screening performance. The proposed method addresses the challenges of tuning parameter selection in high dimensions by offering a computationally efficient and stable alternative to traditional methods like bootstrapping and cross-validation. Air-HOLP is evaluated using simulated data and a prostate cancer genetic dataset. The empirical results demonstrate that Air-HOLP has improved performance over a large range of simulation settings. We provide R codes implementing the Air-HOLP feature screening method and integrating it into existing feature screening methods that utilize the HOLP formula.},
  archive      = {J_SAC},
  author       = {Joudah, Ibrahim and Muller, Samuel and Zhu, Houying},
  doi          = {10.1007/s11222-025-10599-6},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-11},
  shortjournal = {Stat. Comput.},
  title        = {Air-HOLP: Adaptive regularized feature screening for high dimensional correlated data},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metropolis-adjusted interacting particle sampling.
<em>SAC</em>, <em>35</em>(3), 1–31. (<a
href="https://doi.org/10.1007/s11222-025-10595-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, various interacting particle samplers have been developed to sample from complex target distributions, such as those found in Bayesian inverse problems. These samplers are motivated by the mean-field limit perspective and implemented as ensembles of particles that move in the product state space according to coupled stochastic differential equations. The ensemble approximation and numerical time stepping used to simulate these systems can introduce bias and affect the invariance of the particle system with respect to the target distribution. To correct for this, we investigate the use of a Metropolization step, similar to the Metropolis-adjusted Langevin algorithm. We examine Metropolization of either the whole ensemble or smaller subsets of the ensemble, and prove basic convergence of the resulting ensemble Markov chain to the target distribution. Our numerical results demonstrate the benefits of this correction in numerical examples for popular interacting particle samplers such as ALDI, CBS, and stochastic SVGD.},
  archive      = {J_SAC},
  author       = {Sprungk, Björn and Weissmann, Simon and Zech, Jakob},
  doi          = {10.1007/s11222-025-10595-w},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-31},
  shortjournal = {Stat. Comput.},
  title        = {Metropolis-adjusted interacting particle sampling},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Monotonic warpings for additive and deep gaussian processes.
<em>SAC</em>, <em>35</em>(3), 1–22. (<a
href="https://doi.org/10.1007/s11222-025-10598-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian processes (GPs) are canonical as surrogates for computer experiments because they enjoy a degree of analytic tractability. But that breaks when the response surface is constrained, say to be monotonic. Here, we provide a “mono-GP” construction for a single input that is highly efficient even though the calculations are non-analytic. Key ingredients include transformation of a reference process and elliptical slice sampling. We then show how mono-GP may be deployed effectively in two ways. One is additive, extending monotonicity to more inputs; the other is as a prior on injective latent warping variables in a deep Gaussian process for (non-monotonic, multi-input) nonstationary surrogate modeling. We provide illustrative and benchmarking examples throughout, showing that our methods yield improved performance over the state-of-the-art on examples from those two classes of problems.},
  archive      = {J_SAC},
  author       = {Barnett, Steven D. and Beesley, Lauren J. and Booth, Annie S. and Gramacy, Robert B. and Osthus, Dave},
  doi          = {10.1007/s11222-025-10598-7},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-22},
  shortjournal = {Stat. Comput.},
  title        = {Monotonic warpings for additive and deep gaussian processes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty quantification and propagation in
surrogate-based bayesian inference. <em>SAC</em>, <em>35</em>(3), 1–28.
(<a href="https://doi.org/10.1007/s11222-025-10597-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate models are statistical or conceptual approximations for more complex simulation models. In this context, it is crucial to propagate the uncertainty induced by limited simulation budget and surrogate approximation error to predictions, inference, and subsequent decision-relevant quantities. However, quantifying and then propagating the uncertainty of surrogates is usually limited to special analytic cases or is otherwise computationally very expensive. In this paper, we propose a framework enabling a scalable, Bayesian approach to surrogate modeling with thorough uncertainty quantification, propagation, and validation. Specifically, we present three methods for Bayesian inference with surrogate models given measurement data. This is a task where the propagation of surrogate uncertainty is especially relevant, because failing to account for it may lead to biased and/or overconfident estimates of the parameters of interest. We showcase our approach in three detailed case studies for linear and nonlinear real-world modeling scenarios. Uncertainty propagation in surrogate models enables more reliable and safe approximation of expensive simulators and will therefore be useful in various fields of applications.},
  archive      = {J_SAC},
  author       = {Reiser, Philipp and Aguilar, Javier Enrique and Guthke, Anneli and Bürkner, Paul-Christian},
  doi          = {10.1007/s11222-025-10597-8},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-28},
  shortjournal = {Stat. Comput.},
  title        = {Uncertainty quantification and propagation in surrogate-based bayesian inference},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational bayes inference for simultaneous autoregressive
models with missing data. <em>SAC</em>, <em>35</em>(3), 1–16. (<a
href="https://doi.org/10.1007/s11222-025-10590-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The simultaneous autoregressive (SAR) models are often used to analyse spatially correlated data. Markov chain Monte Carlo is one of the most widely used Bayesian methods for estimating the SAR models, but it has significant limitations when it comes to handling missing data in the response variable due to its high computational cost. Variational Bayes (VB) approximation offers an alternative solution to this problem. Two VB-based algorithms employing Gaussian variational approximation with factor covariance structure are presented, joint VB (JVB) and hybrid VB (HVB), suitable for both missing at random and not at random inference. While the JVB method inaccurately estimates the posterior distributions of some SAR parameters and missing values, the standard HVB algorithm struggles to make accurate inferences when dealing with a large number of missing values. Our modified versions of HVB enable accurate inference within a reasonable computational time, thus improving its performance. The performance of the VB methods is evaluated using simulated and real datasets. While we demonstrate the method using SAR models, the approach has broad applicability to various models with missing data.},
  archive      = {J_SAC},
  author       = {Wijayawardhana, Anjana and Gunawan, David and Suesse, Thomas},
  doi          = {10.1007/s11222-025-10590-1},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Stat. Comput.},
  title        = {Variational bayes inference for simultaneous autoregressive models with missing data},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimation and model selection for finite mixtures of
tukey’s g- &amp;-h distributions. <em>SAC</em>, <em>35</em>(3), 1–18.
(<a href="https://doi.org/10.1007/s11222-025-10596-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A finite mixture of distributions is a popular statistical model, which is especially meaningful when the population of interest may include distinct subpopulations. This work is motivated by analysis of protein expression levels quantified using immunofluorescence immunohistochemistry assays of human tissues. The distributions of cellular protein expression levels in a tissue often exhibit multimodality, skewness and heavy tails, but there is a substantial variability between distributions in different tissues from different subjects, while some of these mixture distributions include components consistent with the assumption of a normal distribution. To accommodate such diversity, we propose a mixture of 4-parameter Tukey’s g- &amp;-h distributions for fitting finite mixtures with both Gaussian and non-Gaussian components. Tukey’s g- &amp;-h distribution is a flexible model that allows variable degree of skewness and kurtosis in mixture components, including normal distribution as a particular case. Since the likelihood of the Tukey’s g- &amp;-h mixtures does not have a closed analytical form, we propose a quantile least Mahalanobis distance (QLMD) estimator for parameters of such mixtures. QLMD is an indirect estimator minimizing the Mahalanobis distance between the sample and model-based quantiles, and its asymptotic properties follow from the general theory of indirect estimation. We have developed a stepwise algorithm to select a parsimonious Tukey’s g- &amp;-h mixture model and implemented all proposed methods in the R package QuantileGH available on CRAN. A simulation study was conducted to evaluate performance of the Tukey’s g- &amp;-h mixtures and compare to performance of mixtures of skew-normal or skew-t distributions. The Tukey’s g- &amp;-h mixtures were applied to model cellular expressions of Cyclin D1 protein in breast cancer tissues, and resulting parameter estimates evaluated as predictors of progression-free survival.},
  archive      = {J_SAC},
  author       = {Zhan, Tingting and Yi, Misung and Peck, Amy R. and Rui, Hallgeir and Chervoneva, Inna},
  doi          = {10.1007/s11222-025-10596-9},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-18},
  shortjournal = {Stat. Comput.},
  title        = {Estimation and model selection for finite mixtures of tukey’s g- &amp;-h distributions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new p-value based multiple testing procedure for
generalized linear models. <em>SAC</em>, <em>35</em>(3), 1–10. (<a
href="https://doi.org/10.1007/s11222-025-10600-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a novel p-value-based multiple testing approach tailored for generalized linear models. Despite the crucial role of generalized linear models in statistics, existing methodologies face obstacles arising from the heterogeneous variance of response variables and complex dependencies among estimated parameters. Our aim is to address the challenge of controlling the false discovery rate (FDR) amidst arbitrarily dependent test statistics. Through the development of efficient computational algorithms, we present a versatile statistical framework for multiple testing. The proposed framework accommodates a range of tools developed for constructing a new model matrix in regression-type analysis, including random row permutations and Model-X knockoffs. We devise efficient computing techniques to solve the encountered non-trivial quadratic matrix equations, enabling the construction of paired p-values suitable for the two-step multiple testing procedure proposed by Sarkar and Tang (Biometrika 109(4): 1149–1155, 2022). Theoretical analysis affirms the properties of our approach, demonstrating its capability to control the FDR at a given level. Empirical evaluations further substantiate its promising performance across diverse simulation settings.},
  archive      = {J_SAC},
  author       = {Rilling, Joseph and Tang, Cheng Yong},
  doi          = {10.1007/s11222-025-10600-2},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-10},
  shortjournal = {Stat. Comput.},
  title        = {A new p-value based multiple testing procedure for generalized linear models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian design for sampling anomalous spatio-temporal data.
<em>SAC</em>, <em>35</em>(3), 1–19. (<a
href="https://doi.org/10.1007/s11222-025-10594-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data collected from arrays of sensors are essential for informed decision-making in various systems. However, the presence of anomalies can compromise the accuracy and reliability of insights drawn from the collected data or information obtained via statistical analysis. This study aims to develop a robust Bayesian optimal experimental design framework with anomaly detection methods for high-quality data collection. We introduce a general framework that involves anomaly generation, detection and error scoring when searching for an optimal design. This method is demonstrated using two comprehensive simulated case studies: the first study uses a spatial dataset, and the second uses a spatio-temporal river network dataset. As a baseline approach, we employed a commonly used prediction-based utility function based on minimising errors. Results illustrate the trade-off between predictive accuracy and anomaly detection performance for our method under various design scenarios. An optimal design robust to anomalies ensures the collection and analysis of more trustworthy data, playing a crucial role in understanding the dynamics of complex systems such as the environment, therefore enabling informed decisions in monitoring, management, and response.},
  archive      = {J_SAC},
  author       = {Buchhorn, Katie and Mengersen, Kerrie and Santos-Fernandez, Edgar and McGree, James},
  doi          = {10.1007/s11222-025-10594-x},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Stat. Comput.},
  title        = {Bayesian design for sampling anomalous spatio-temporal data},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian analysis of doubly semiparametric mixture cure
models with interval-censored data. <em>SAC</em>, <em>35</em>(3), 1–19.
(<a href="https://doi.org/10.1007/s11222-025-10601-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-censored data are commonly encountered in medical studies, where the occurrence of a disease can only be observed within specific time intervals or during periodic examinations. In the presence of individuals being cured or never experiencing the disease, a mixture cure model is often assumed for regression analysis accounting for the mixture of cured and uncured individuals in the study population. In this model, the Cox proportional hazards model is typically specified as a latency component for the event time and logistic regression as an incidence component for the probability of uncured. Challenges appear in the analysis when some covariates are time-related. It is unrealistic to assume linear covariate effects on a known transformation of cure probability or the hazard ratio of uncured individuals, as is commonly done. We propose a doubly semiparametric mixture cure model for interval-censored data, providing more flexibility by allowing linear and nonlinear effects of covariates in both the incidence and latency parts. We develop a computationally feasible Bayesian estimation procedure, incorporating a two-stage data augmentation with Poisson latent variables to deal with interval-censored data and splines for modelling the nonlinear terms in the model. We evaluate the finite sample performance of the proposed method via extensive simulations and demonstrate its utility through analysis of data from a hypobaric decompression sickness study.},
  archive      = {J_SAC},
  author       = {Liu, Xiaoyu and Xiang, Liming},
  doi          = {10.1007/s11222-025-10601-1},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-19},
  shortjournal = {Stat. Comput.},
  title        = {Bayesian analysis of doubly semiparametric mixture cure models with interval-censored data},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse and debiased lasso estimation and statistical
inference for long time series via divide-and-conquer. <em>SAC</em>,
<em>35</em>(3), 1–16. (<a
href="https://doi.org/10.1007/s11222-025-10602-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle long time series with high-dimensional covariates and dependent non-Gaussian errors, we consider the divide-and-conquer strategy and develop a class of sparse and debiased Lasso estimators. To alleviate the serial correlation in long time series data, we sequentially split the long time series into several subseries and apply a generalized penalized least squares (GLS) method for linear regression models in each subseries allowing stationary covariates and AR(q) error processes. To make accurate statistical inference, we further propose a sparse and debiased estimator and investigate its asymptotic properties. By constructing a pseudo-response variable using a squared loss transformation, the proposed GLS method is extended to a unified M-estimation framework including Huber and quantile regression models to reduce computational burden. Extensive simulations validate theoretical properties and demonstrate that our proposed estimators have better performance than some existing methods. The proposed estimators are applied to Beijing Air Quality Data and NIFTY 50 Index Data to illustrate their validity and feasibility.},
  archive      = {J_SAC},
  author       = {Liu, Jin and Ma, Wei and Wang, Lei and Lian, Heng},
  doi          = {10.1007/s11222-025-10602-0},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-16},
  shortjournal = {Stat. Comput.},
  title        = {Sparse and debiased lasso estimation and statistical inference for long time series via divide-and-conquer},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Debiased transfer learning estimation and inference for
multinomial regression. <em>SAC</em>, <em>35</em>(3), 1–30. (<a
href="https://doi.org/10.1007/s11222-025-10607-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning has gained considerable attention for improving the performance of high-dimensional linear and generalized linear models by leveraging source data. However, few studies have explored transfer learning in multinomial regression (MR) for multi-class classification problems. In this paper, we propose a two-step MR transfer learning estimator when the transferable sources are known and establish its error bounds. When the target and source datasets are close, these bounds can be improved over the MR estimator using only target data under mild conditions. To address the bias introduced by the Lasso penalty, we develop a unified debiasing framework based on KKT conditions, establishing the asymptotic normality for the construction of confidence intervals and hypothesis tests. For practical implementation, a transferable source detection algorithm with theoretical guarantees is proposed. Numerical studies and an application to Genotype-Tissue Expression data demonstrate the effectiveness of our proposed methods.},
  archive      = {J_SAC},
  author       = {Yang, Jichen and Wang, Lei and Lian, Heng},
  doi          = {10.1007/s11222-025-10607-9},
  journal      = {Statistics and Computing},
  month        = {6},
  number       = {3},
  pages        = {1-30},
  shortjournal = {Stat. Comput.},
  title        = {Debiased transfer learning estimation and inference for multinomial regression},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="si---3">SI - 3</h2>
<ul>
<li><details>
<summary>
(2025). The viability of domain constrained coalition formation for
robotic collectives. <em>SI</em>, <em>19</em>(1), 55–96. (<a
href="https://doi.org/10.1007/s11721-024-00242-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications, such as military and disaster response, can benefit from robotic collectives’ ability to perform multiple cooperative tasks (e.g., surveillance, damage assessments) efficiently across a large spatial area. Coalition formation algorithms can potentially facilitate collective robots’ assignment to appropriate task teams; however, most coalition formation algorithms were designed for smaller multiple robot systems (i.e., 2–50 robots). Collectives’ scale and domain-relevant constraints (i.e., distribution, near real-time, minimal communication) make coalition formation more challenging. This manuscript identifies the challenges inherent to designing coalition formation algorithms for very large collectives (e.g., 1000 robots). A survey of multiple robot coalition formation algorithms finds that most are unable to transfer directly to collectives, due to the identified system differences; however, auctions and hedonic games may be the most transferable. A simulation-based evaluation of five total algorithms from two combinatorial auction families and one hedonic game family, applied to homogeneous and heterogeneous collectives, demonstrates that there are collective compositions for which no evaluated algorithm is viable; however, the experimental results and literature survey suggest paths forward.},
  archive      = {J_SI},
  author       = {Diehl, Grace and Adams, Julie A.},
  doi          = {10.1007/s11721-024-00242-x},
  journal      = {Swarm Intelligence},
  month        = {3},
  number       = {1},
  pages        = {55-96},
  shortjournal = {Swarm Intell.},
  title        = {The viability of domain constrained coalition formation for robotic collectives},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized traffic management of autonomous drones.
<em>SI</em>, <em>19</em>(1), 29–53. (<a
href="https://doi.org/10.1007/s11721-024-00241-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coordination of local and global aerial traffic has become a legal and technological bottleneck as the number of unmanned vehicles in the common airspace continues to grow. To meet this challenge, automation and decentralization of control is an unavoidable requirement. In this paper, we present a solution that enables self-organization of cooperating autonomous agents into an effective traffic flow state in which the common aerial coordination task—filled with conflicts—is resolved. Using realistic simulations, we show that our algorithm is safe, efficient, and scalable regarding the number of drones and their speed range, while it can also handle heterogeneous agents and even pairwise priorities between them. The algorithm works in any sparse or dense traffic scenario in two dimensions and can be made increasingly efficient by a layered flight space structure in three dimensions. To support the feasibility of our solution, we show stable traffic simulations with up to 5000 agents, and experimentally demonstrate coordinated aerial traffic of 100 autonomous drones within a 250 m wide circular area.},
  archive      = {J_SI},
  author       = {Balázs, Boldizsár and Vicsek, Tamás and Somorjai, Gergő and Nepusz, Tamás and Vásárhelyi, Gábor},
  doi          = {10.1007/s11721-024-00241-y},
  journal      = {Swarm Intelligence},
  month        = {3},
  number       = {1},
  pages        = {29-53},
  shortjournal = {Swarm Intell.},
  title        = {Decentralized traffic management of autonomous drones},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Imprecise evidence in social learning. <em>SI</em>,
<em>19</em>(1), 1–27. (<a
href="https://doi.org/10.1007/s11721-024-00238-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social learning is a collective approach to decentralised decision-making and is comprised of two processes; evidence updating and belief fusion. In this paper we propose a social learning model in which agents’ beliefs are represented by a set of possible states, and where the evidence collected can vary in its level of imprecision. We investigate this model using multi-agent and multi-robot simulations and demonstrate that it is robust to imprecise evidence. Our results also show that certain kinds of imprecise evidence can enhance the efficacy of the learning process in the presence of sensor errors.},
  archive      = {J_SI},
  author       = {Liu, Zixuan and Crosscombe, Michael and Lawry, Jonathan},
  doi          = {10.1007/s11721-024-00238-7},
  journal      = {Swarm Intelligence},
  month        = {3},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Swarm Intell.},
  title        = {Imprecise evidence in social learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="soco---62">SOCO - 62</h2>
<ul>
<li><details>
<summary>
(2025). Retraction note: IADF security: Insider attack detection
using fuzzy logic in wireless multimedia sensor networks. <em>SOCO</em>,
<em>29</em>(4), 2397. (<a
href="https://doi.org/10.1007/s00500-024-10397-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Janarthanan, Ashwinth and Kumar, Dhananjay and Antony, R. Remo and Parvathe, C. B. Divya},
  doi          = {10.1007/s00500-024-10397-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2397},
  shortjournal = {Soft Comput.},
  title        = {Retraction note: IADF security: insider attack detection using fuzzy logic in wireless multimedia sensor networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Enhancing performance of cell formation
problem using hybrid efficient swarm optimization. <em>SOCO</em>,
<em>29</em>(4), 2395. (<a
href="https://doi.org/10.1007/s00500-024-10393-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Nagaraj, G. and Arunachalam, Manimaran and Vinayagar, K. and Paramasamy, S.},
  doi          = {10.1007/s00500-024-10393-y},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2395},
  shortjournal = {Soft Comput.},
  title        = {Retraction note: Enhancing performance of cell formation problem using hybrid efficient swarm optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Classification of noiseless corneal image
using capsule networks. <em>SOCO</em>, <em>29</em>(4), 2393. (<a
href="https://doi.org/10.1007/s00500-024-10391-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Koresh, H. James Deva and Chacko, Shanty},
  doi          = {10.1007/s00500-024-10391-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2393},
  shortjournal = {Soft Comput.},
  title        = {Retraction note: Classification of noiseless corneal image using capsule networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RETRACTED ARTICLE: Near-infrared and visible light face
recognition: A comprehensive survey. <em>SOCO</em>, <em>29</em>(4),
2391. (<a href="https://doi.org/10.1007/s00500-023-08366-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Huang, Fangzheng and Tang, Xikai and Li, Chao and Ban, Dayan},
  doi          = {10.1007/s00500-023-08366-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2391},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: near-infrared and visible light face recognition: a comprehensive survey},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gender opposition recognition method fusing emojis and
multi-features in chinese speech. <em>SOCO</em>, <em>29</em>(4),
2379–2390. (<a
href="https://doi.org/10.1007/s00500-025-10492-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech with gender opposition on the internet have been causing antagonism, gamophobia, and pregnancy phobia among young groups. Recognizing gender opposition speech contributes to maintaining a healthy online environment and security in cyberspace. Traditional recognition model ignores the Chinese-owned features and emojis, which inevitably affects the recognition accuracy of gender opposition. To tackle this issue, a gender opposition recognition method fusing emojis and multi-features in Chinese speech(GOR-CS) is proposed. Firstly, the exBERT method is employed to expand the encoding of emojis into the BERT vocabulary, which can ensure BERT to extract the basis vectors containing characters and emojis information. Then, the feature vectors containing Wubi, Zhengma, and Pinyin information are extracted by Word2Vec to obtain the Chinese-owned features of gender opposition text. Further, the proposed basis vector and feature vectors are fused and then fed into the Bi-GRU network to extract deeper semantics from input sentences. Finally, to determine whether the speech are related to gender opposition, the sentiment polarities are calculated with the fully connected layer and SoftMax function. Experimental results show that the proposed method can effectively improve the accuracy of gender opposition recognition.},
  archive      = {J_SOCO},
  author       = {Zhang, Shunxiang and Ma, Zichen and Li, Hanchen and Liu, Yunduo and Chen, Lei and Li, Kuan-Ching},
  doi          = {10.1007/s00500-025-10492-4},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2379-2390},
  shortjournal = {Soft Comput.},
  title        = {Gender opposition recognition method fusing emojis and multi-features in chinese speech},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight CNN model for UAV-based image classification.
<em>SOCO</em>, <em>29</em>(4), 2363–2378. (<a
href="https://doi.org/10.1007/s00500-025-10512-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many unmanned aerial vehicle (UAV)-based applications, especially those that need to operate with resource-limited edge networked devices in real-time, it is crucial to have a lightweight computing model for data processing and analysis. In this study, we focus on UAV-based forest fire imagery detection using a lightweight convolution neural network (CNN). The task is challenging owing to complex image backgrounds and insufficient training samples. Specifically, we enhance the MobileNetV2 model with an attention mechanism for UAV-based image classification. The proposed model first employs a transfer learning strategy that leverages the pre-trained weights from ImageNet to expedite learning. Then, the model incorporates randomly initialised weights and dropout mechanisms to mitigate over-fitting during training. In addition, an ensemble framework with a majority voting scheme is adopted to improve the classification performance. A case study on forest fire scenes classification with benchmark and real-world images is demonstrated. The results on a publicly available UAV-based image data set reveal the competitiveness of our proposed model as compared with those from existing methods. In addition, based on a set of self-collected images with complex backgrounds, the proposed model illustrates its generalisation capability to undertake forest fire classification tasks with aerial images.},
  archive      = {J_SOCO},
  author       = {Deng, Xinjie and Shi, Michael and Khan, Burhan and Choo, Yit Hong and Ghaffar, Fazal and Lim, Chee Peng},
  doi          = {10.1007/s00500-025-10512-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2363-2378},
  shortjournal = {Soft Comput.},
  title        = {A lightweight CNN model for UAV-based image classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based model for automated STN localization
using local field potentials in parkinson’s disease. <em>SOCO</em>,
<em>29</em>(4), 2343–2362. (<a
href="https://doi.org/10.1007/s00500-025-10497-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of the subthalamic nucleus (STN) borders is time-consuming, relying heavily on the neurosurgeon expertise in manually interpreting the electrophysiological signals. Local field potentials (LFPs) have garnered imperative attention due to their strong correlation with the STN. However, existing detection models often face challenges with high computational complexity, hyperparameter optimization and lack of explainability, making them unreliable for clinicians. Therefore, this study introduces an explanatory framework using convolutional neural networks (CNN) for detecting the STN region from LFPs. Continuous wavelet transform is employed to convert LFPs signals into scalogram images, which are then processed by sixteen CNN models. We evaluated our framework by examining the impact of various limiting factors on the classification performance, including model size, learning rate (LR), optimizers and data scaling. Deep features are extracted from the top-performing CNN architectures to capture rich representations of the scalograms. These features are then fused and classified using k-nearest neighbour algorithm. Gradient-weighted class activation mapping is used to explain the decisions made by the proposed model. Our approach achieved an accuracy of 99.61%, outperforming individual CNN models for STN localization. The experimental results revealed that CNN models, embedded with additional hyperparameters and layers, generally outperformed smaller models. Besides, low LR significantly enhanced the performance compared to high LR. Moreover, features extracted from untuned networks produced lower performance than tuned networks. The proposed system could revolutionize deep brain stimulation surgery by increasing efficiency and reducing reliance on clinician expertise for STN detection.},
  archive      = {J_SOCO},
  author       = {Hosny, Mohamed and Naeem, Mohamed A. and Zhu, Minwei and Gao, Wenpeng and Elshenhab, Ahmed M. and Fu, Yili},
  doi          = {10.1007/s00500-025-10497-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2343-2362},
  shortjournal = {Soft Comput.},
  title        = {A deep learning-based model for automated STN localization using local field potentials in parkinson’s disease},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced single shot detector for small object detection in
drone-capture scenarios. <em>SOCO</em>, <em>29</em>(4), 2331–2341. (<a
href="https://doi.org/10.1007/s00500-025-10539-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have significantly improved object detection performance. However, detecting small objects in drone-captured imagery remains challenging due to their low resolution and noisy appearance. This paper presents the Enhanced Single Shot Detector (ESSD), designed for accurate small object detection. The ESSD incorporates a scale-confusion erasing module to reduce noise from larger objects, enhancing the detection of smaller ones. It also features a neighbor fusion module that integrates semantic information across layers. Our experiments on the VisDrone2019-DET benchmark dataset show that the ESSD achieves state-of-the-art performance in small object detection.},
  archive      = {J_SOCO},
  author       = {Shi, Yanxia and Liu, Yanrong and Liu, Yaru},
  doi          = {10.1007/s00500-025-10539-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2331-2341},
  shortjournal = {Soft Comput.},
  title        = {Enhanced single shot detector for small object detection in drone-capture scenarios},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure transmission of medical image using a wavelet
interval type-2 TSK fuzzy brain-imitated neural network. <em>SOCO</em>,
<em>29</em>(4), 2311–2329. (<a
href="https://doi.org/10.1007/s00500-025-10449-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this research is to develop a new design of a wavelet interval type-2 takagi–Sugeno-Kang fuzzy brain-imitated neural network (WIT2TFBINN), which is a combination of the mathematical models of a Takagi–Sugeno-Kang (TSK) fuzzy system based on wavelet interval type-2 function (WIT2) and a wavelet interval type-2 fuzzy brain imitated neural network (FBINN). The proposed WIT2TFBINN is used for synchronization control of a 4D Lorentz chaotic system and has the benefits of wavelet interval type-2 membership function, TSK fuzzy inference system, decision making, and emotional activity. To provide fast training, the proposed method&#39;s parameter update laws are derived using the gradient descent method. The proposed WIT2TFBINN synchronization technique is then applied to the transmission of medical images in a secure manner. As a cipher image, a medical image is encrypted into a chaotic trajectory. After transmission, the image can be decrypted using chaotic trajectory synchronization on the received signal. The simulation results show that the proposed neural network and the encryption/decryption method are powerful and effective. The results of the static test analysis (histogram, attack analysis, image with noise, image with cropping) show that the encryption/decryption method provides high security.},
  archive      = {J_SOCO},
  author       = {Pham, Duc-Hung and Huynh, Tuan-Tu and Lin, Chih-Min and Giap, Van Nam and Vu, Van-Phong},
  doi          = {10.1007/s00500-025-10449-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2311-2329},
  shortjournal = {Soft Comput.},
  title        = {Secure transmission of medical image using a wavelet interval type-2 TSK fuzzy brain-imitated neural network},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability analysis of discrete-time multi-state star
configuration power grid systems with performance sharing.
<em>SOCO</em>, <em>29</em>(4), 2297–2310. (<a
href="https://doi.org/10.1007/s00500-025-10478-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by practical engineering systems, this paper studies an assessment method for dynamic reliability of a discrete time multi-state star configuration power grid system with performance sharing. The proposed star configuration power grid system consists of n power generation subsystems fixed in star-terminal and one central collection and redistribution subsystem. The star-terminal subsystems with sufficient electric power can first transmit the surplus electric power to the central subsystem, and then the collected electric power in central subsystem is further redistributed to the star-terminal subsystems which are experiencing electric power deficiency through the corresponded transmission links. An algorithm based on the universal generating function (UGF) technique is presented to evaluate the dynamic reliability of the proposed power grid system with performance sharing. Finally, a numerical example and a case study are used to illustrate the accuracy of the proposed model and method. Studies indicate that the steady reliability of the proposed power grid system is improved by 9.41% and 37.28% for the numerical example when comparing the calculation results between performance sharing, unlimited performance sharing and no performance sharing. In the case study, the dynamic reliability of the proposed power grid system increased by 11.5% when comparing the calculation results between with performance sharing and no performance sharing when $$k\to \infty $$ .},
  archive      = {J_SOCO},
  author       = {Su, Peng and Zhang, Keyong and Shi, Honghua},
  doi          = {10.1007/s00500-025-10478-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2297-2310},
  shortjournal = {Soft Comput.},
  title        = {Reliability analysis of discrete-time multi-state star configuration power grid systems with performance sharing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deteriorating inventory model with advance-cash-credit
payment schemes and partial backlogging. <em>SOCO</em>, <em>29</em>(4),
2279–2295. (<a
href="https://doi.org/10.1007/s00500-025-10532-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In business transactions, suppliers often ask retailers for advance-cash-credit (ACC) payments, and retailers offer customers a cash-credit (CC) payment plan. An advance payment is generally requested to avoid order cancellation, while a credit payment serves as an efficient approach to stimulate sales. With supply chains being usually subject to inventory shortages in view of various uncertainties, this study explores an optimal inventory policy for perishable goods with partial backlogging considerations when suppliers adopt an ACC payment plan for retailers and retailers offer customers a CC payment plan. For this purpose, we establish a model based on two theorems and provide an easy-to-use method to derive the optimal ordering policy to maximize retailers’ total profits. This solution is illustrated using numerical examples. Finally, we conduct a sensitivity analysis to examine the influence of changes in the values of key parameters on the optimal solution.},
  archive      = {J_SOCO},
  author       = {Chang, Chun-Tao and Cheng, Mei-Chuan and Ouyang, Liang-Yuh},
  doi          = {10.1007/s00500-025-10532-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2279-2295},
  shortjournal = {Soft Comput.},
  title        = {Deteriorating inventory model with advance-cash-credit payment schemes and partial backlogging},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging feature fusion ensemble of VGG16 and ResNet-50
for automated potato leaf abnormality detection in precision
agriculture. <em>SOCO</em>, <em>29</em>(4), 2263–2277. (<a
href="https://doi.org/10.1007/s00500-025-10523-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of advancement in technology and modern agriculture, early disease detection of potato leaves will improve crop yield. Various researchers have focussed on disease due to different types of microbial infection in potato leaves using computer vision and machine learning approaches. In this paper, a data science approach for multiclass classification of potato normal and abnormal leaves due to fungal infection like early blight and late blight is performed using the ensembling of deep learning (DL) CNN models. Firstly, the performance of classification on potato disease is verified separately on VGG16 and ResNet-50 CNN models after pre-processing of the leaf dataset. The pre-processing includes noise removal and normalization. Further improvement in classification accuracy is achieved by the ensembling of VGG16 and ResNet-50 CNN models. The ensembling of CNN models is performed on the feature level by fusing features extracted using VGG16 and ResNet-50. From the experimental results, performed on publicly available datasets consisting of 2152 number of normal and abnormal images it is observed that the average classification accuracy of 98.22%, 96.16% and 95.68% is achieved using the proposed ensemble, VGG16 and ResNet-50 models respectively. The efficacy of the proposed approach (ensemble technique at feature level fusion) is verified in comparison with recently reported DL model-based approaches.},
  archive      = {J_SOCO},
  author       = {Trivedi, Amit Kumar and Mahajan, Tripti and Maheshwari, Tanmay and Mehta, Rajesh and Tiwari, Shailendra},
  doi          = {10.1007/s00500-025-10523-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2263-2277},
  shortjournal = {Soft Comput.},
  title        = {Leveraging feature fusion ensemble of VGG16 and ResNet-50 for automated potato leaf abnormality detection in precision agriculture},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adopting fuzzy multi-criteria decision-making ranking
approach ensuring connected topology in industrial wireless sensor
networks. <em>SOCO</em>, <em>29</em>(4), 2247–2261. (<a
href="https://doi.org/10.1007/s00500-025-10448-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks (WSNs), topology control aims to optimize the network structure to improve its performance and is a significant issue especially in mesh connected networks. As Industrial Wireless sensor networks (IWSNs) adopt a mesh-based strategy for communication, a connected topology and its maintenance is necessary. Therefore, identifying candidate nodes and reconfiguration under congestion and failure for reliable connection becomes important. A rank-based mechanism appears a viable solution to identify next best candidates to establish the connections among the nodes in the event of network disruption. As a solution, we propose adoption of MCDM (Multi-Criteria Decision-Making) based approach to compute the ranks among the sensor nodes when subject to varied constraints. Our paper compares and analyses the ranking of a node by using two methods, Analytical hierarchy Process (AHP) Weighted TOPSIS (Technique for Order Performance by Similarity to Ideal Solution) and FUZZY TOPSIS. A novel application of the rank-based strategy to determine the connection between the nodes for achieving a network with lower energy consumption and better connectivity for IWSNs is presented. On comparison with standard topology control algorithms, like connected dominating set (CDS) and articulation point strategy our results confirm that the topology formed through our ranking method achieves lower energy consumption in communication and better connectivity probability among the nodes. Further, we also observe performance of the network when subject to obstacles in the line-of-sight communication typical of IWSNs and our approach performs better in this case too.},
  archive      = {J_SOCO},
  author       = {Nandan, Anvita and Snigdh, Itu},
  doi          = {10.1007/s00500-025-10448-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2247-2261},
  shortjournal = {Soft Comput.},
  title        = {Adopting fuzzy multi-criteria decision-making ranking approach ensuring connected topology in industrial wireless sensor networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New vigenere method with pseudo-random affine functions for
color image encryption. <em>SOCO</em>, <em>29</em>(4), 2229–2245. (<a
href="https://doi.org/10.1007/s00500-025-10477-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this document, we propose an enhanced technique for encrypting color images, building upon a substantial refinement of the traditional Vigenere method, guaranteed by two strong pseudo-random replacement tables built from the utilization of dynamic linear functions and the most frequently utilized chaotic maps in cryptography domain. After original image vectorization and initialization value calculation, which serve to modify the initial pixel value, thereby triggering the ciphering procedure, our technique integrates a novel Vigenere circuit using dynamic pseudorandom functions to change pixel values. Finally, a positional shift of each pixel is applied to maximize the temporal complexity of our technology. Experiments carried out on a wide range of images spanning various formats and dimensions confirm the robustness of our method against established attack techniques.},
  archive      = {J_SOCO},
  author       = {El Bourakkadi, Hamid and Chemlal, Abdelhakim and Tabti, Hassan and Kattass, Mourad and Jarjar, Abdellatif and Benazzi, Abdelhamid},
  doi          = {10.1007/s00500-025-10477-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2229-2245},
  shortjournal = {Soft Comput.},
  title        = {New vigenere method with pseudo-random affine functions for color image encryption},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced TODIM-TOPSIS framework for design quality
evaluation for college smart sports venues under hesitant fuzzy sets.
<em>SOCO</em>, <em>29</em>(4), 2215–2227. (<a
href="https://doi.org/10.1007/s00500-025-10414-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the gradual development and application of modern intelligent technology in our country, it has become a key factor influencing the nation&#39;s overall competitive strength. The state has explicitly proposed the establishment of efficient and high-quality engineering projects in the current sports industry. By applying innovative technologies, smart sports venues will be created to support the future development of the nation and the sports sector, thereby comprehensively enhancing the country&#39;s overall competitive strength. Among these, university gyms, as important venues for modern school physical education, must keep pace with the nation&#39;s development. By establishing smart sports venues and utilizing Internet of Things (IoT) technology, cloud computing technology, and artificial intelligence technology, the comprehensive operation of sports venues can be promoted, leading to the stable development of the school sports industry. The design quality evaluation for college smart sports venues is a multiple-attribute decision-making (MADM) problem. Recently, the TODIM and TOPSIS methods have been demonstrated to address MAGDM issues. Hesitant fuzzy sets (HFSs) have been introduced as a means to characterize uncertain data during the design quality evaluation for college smart sports venues. In this study, the hesitant fuzzy TODIM-TOPSIS (HF-TODIM-TOPSIS) approach is proposed to solve MADM problems under HFSs. Finally, a numerical study for the design quality evaluation of college smart sports venues is presented to validate the proposed approach. The major contributions of this study are as follows: (1) The TODIM and TOPSIS methods are extended to HFSs; (2) Entropy is used to determine the weight values under HFSs; (3) The HF-TODIM-TOPSIS approach is established to handle MADM problems under HFSs; (4) Algorithm analysis and comparison for the design quality evaluation of college smart sports venues are conducted based on a numerical example to verify the feasibility and effectiveness of the HF-TODIM-TOPSIS approach.},
  archive      = {J_SOCO},
  author       = {Yang, Feng and Wu, Yuefang and Li, Yi},
  doi          = {10.1007/s00500-025-10414-4},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2215-2227},
  shortjournal = {Soft Comput.},
  title        = {Enhanced TODIM-TOPSIS framework for design quality evaluation for college smart sports venues under hesitant fuzzy sets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling and analysis of data corruption attacks and energy
consumption effects on edge servers using concurrent stochastic games.
<em>SOCO</em>, <em>29</em>(4), 2189–2214. (<a
href="https://doi.org/10.1007/s00500-025-10467-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate nature of modern edge architectures, relying on a vast array of computational logic and lightweight communication protocols, creates vulnerabilities that expose them to a broad spectrum of security threats. Moreover, security vulnerabilities can significantly impact the energy footprint of edge servers in these architectures. Our approach utilizes the concurrent stochastic game (CSG) formalism to model the behavior of IoT communication entities (players) while accounting for potential attacks at the communication edge and the resulting energy consumption caused by such attacks. We rely on the PRISM-games language for automated analysis where the game goals modeling functional and security requirements are expressed using reward probabilistic alternating temporal logic (rPATL). To validate our approach, we examine a data corruption attack applied to dam water flow control and study its side effect on energy consumption associated with SensiNact gateways. Our key innovation lies in using formal models at the architectural level to explore potential attacks. These models capture synchronous and asynchronous communication styles, along with their associated energy consumption. The methodology and the implemented formalism offer a significant advancement over traditional game equation models while still achieving the desired security and energy evaluation. Numerical results show that compared to synchronous communication, asynchronous styles suffer from significantly larger infected buffers and higher energy consumption due to attacks ranging from 66 to 91%.},
  archive      = {J_SOCO},
  author       = {Baouya, Abdelhakim and Hamid, Brahim and Gürgen, Levent and Bensalem, Saddek},
  doi          = {10.1007/s00500-025-10467-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2189-2214},
  shortjournal = {Soft Comput.},
  title        = {Modeling and analysis of data corruption attacks and energy consumption effects on edge servers using concurrent stochastic games},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel attention based deep learning model for software
defect prediction with bidirectional word embedding system.
<em>SOCO</em>, <em>29</em>(4), 2171–2188. (<a
href="https://doi.org/10.1007/s00500-025-10475-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction (SDP) is considered a dynamic research problem and is beneficial during the testing stage of the software development life cycle. Several artificial intelligence-based methods were available to predict these software defects. However, the detection accuracy is still low due to imbalanced datasets, poor feature learning, and tuning of the model&#39;s parameters. This paper proposes a novel attention-included Deep Learning (DL) model for SDP with effective feature learning and dimensionality reduction mechanisms. The system mainly comprises ‘6’ phases: dataset balancing, source code parsing, word embedding, feature extraction, dimensionality reduction, and classification. First, dataset balancing was performed using the density peak based k-means clustering (DPKMC) algorithm, which prevents the model from having biased outcomes. Then, the system parses the source code into abstract syntax trees (ASTs) that capture the structure and relationship between different elements of the code to enable type checking and the representative nodes on ASTs are selected to form token vectors. Then, we use bidirectional encoder representations from transformers (BERT), which converts the token vectors into numerical vectors and extracts semantic features from the data. We then input the embedded vectors to multi-head attention incorporated bidirectional gated recurrent unit (MHBGRU) for contextual feature learning. After that, the dimensionality reduction is performed using kernel principal component analysis (KPCA), which transforms the higher dimensional data into lower dimensions and removes irrelevant features. Finally, the system used a deep, fully connected network-based SoftMax layer for defect prediction, in which the cross-entropy loss is utilized to minimize the prediction loss. The experiments on the National Aeronautics and Space Administration (NASA) and AEEEM show that the system achieves better outcomes than the existing state-of-the-art models for SDP.},
  archive      = {J_SOCO},
  author       = {Devi, M. Chitra and Rajkumar, T. Dhiliphan},
  doi          = {10.1007/s00500-025-10475-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2171-2188},
  shortjournal = {Soft Comput.},
  title        = {A novel attention based deep learning model for software defect prediction with bidirectional word embedding system},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Review of quantum algorithms for medicine, finance and
logistics. <em>SOCO</em>, <em>29</em>(4), 2129–2170. (<a
href="https://doi.org/10.1007/s00500-025-10540-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing represents an emerging technology, that leverages the fundamental principles of quantum mechanics to solve highly complex problems that are beyond the capabilities of classical computers. Due to the unique characteristics of quantum computers, optimisation algorithms can be significantly improved, offering performance that surpasses classical methods, especially for computationally intractable problems. This study aims to provide a comprehensive overview of recent scientific research focused on the development of effective quantum algorithms in specific application contexts, with particular emphasis on the healthcare, finance, production planning and logistics sectors. Additionally, we present a comprehensive classification of methodologies and approaches employed in the design and implementation of quantum algorithms.},
  archive      = {J_SOCO},
  author       = {Ciacco, Alessia and Guerriero, Francesca and Macrina, Giusy},
  doi          = {10.1007/s00500-025-10540-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2129-2170},
  shortjournal = {Soft Comput.},
  title        = {Review of quantum algorithms for medicine, finance and logistics},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-ant colony algorithm based on the stackelberg game and
incremental learning. <em>SOCO</em>, <em>29</em>(4), 2107–2128. (<a
href="https://doi.org/10.1007/s00500-025-10469-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the difficulties of slow convergence and inadequate accuracy of traditional ant colony algorithms in solving the traveling salesman problem (TSP), we propose a multi-ant colony algorithm based on the Stackelberg game and incremental learning (SGIACO). We incorporate the Stackelberg game strategy across multiple colonies, where the leader guides the follower to optimize population co-evolution, ensuring a balance between convergence and diversity of the algorithm. Furthermore, we propose an incremental learning strategy that enhances efficient paths on the public routes and ignores inefficient ones, thus accelerating the convergence speed of the algorithm. Finally, when the algorithm stagnates, a pheromone balance mechanism is implemented to help the ants escape from local optima. We conducted experiments on 23 TSP instances to validate the algorithm&#39;s performance and compare it to ACS, MMAS, as well as other recent algorithms. In addition, non-parametric tests were conducted for comprehensive performance analysis. Moreover, we verified the feasibility of SGIACO through simulations in robot path planning scenarios. The experimental results show that SGIACO has good convergence and accuracy, which is competitive with other algorithms. Future research aims to scale SGIACO for larger real-world applications, enhancing its adaptability and scalability.},
  archive      = {J_SOCO},
  author       = {Wu, Qihuan and You, Xiaoming and Liu, Sheng},
  doi          = {10.1007/s00500-025-10469-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2107-2128},
  shortjournal = {Soft Comput.},
  title        = {Multi-ant colony algorithm based on the stackelberg game and incremental learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-population artificial tree algorithm based on adaptive
updating strategy for dominant populations. <em>SOCO</em>,
<em>29</em>(4), 2075–2106. (<a
href="https://doi.org/10.1007/s00500-025-10445-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An artificial tree (AT) algorithm has been proposed recently, and the performance of AT has been enhanced because of the introduction of improved AT algorithm with two-population (IATTP). However, the branch update operators of IATTP cannot effectively balance exploration and exploitation, which limits the optimization accuracy and efficiency of IATTP. To further improve the performance of IATTP, this work proposes a two-population artificial tree algorithm based on adaptive updating strategy for dominant populations (TATAD). In TATAD, six operators named self-evolution operator 2, crossover operator 2, improved self-evolution operator, gradient descent update operator, Gauss and Cauchy variational operator, and random traceless Sigma variational operator are applied to form an operator library. A dominant operator dynamic following mechanism is proposed to assign these six operators to the two populations in an optimal pairing scheme. Both populations and operators compete with each other, and the advantages of all operators are fully utilized. Moreover, the combination of diverse operators and dominant operator dynamic following mechanism can effectively balance the exploration and exploitation of TATAD. The performance of TATAD is compared with four AT algorithms and six efficient algorithms through typical test functions, and their results are bested by Wilcoxon rank sum test (WRST) and Friedman ranking test. It is found that TATAD is the most competitive algorithm among these algorithms for solving these optimization problems.},
  archive      = {J_SOCO},
  author       = {Xiao, Yaping and Niu, Linfeng and Li, Qiqi},
  doi          = {10.1007/s00500-025-10445-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2075-2106},
  shortjournal = {Soft Comput.},
  title        = {A two-population artificial tree algorithm based on adaptive updating strategy for dominant populations},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-objective multi-warehouse multi-period order picking
system under uncertainty: A benders decomposition approach.
<em>SOCO</em>, <em>29</em>(4), 2047–2074. (<a
href="https://doi.org/10.1007/s00500-025-10495-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In warehouse management order picking is one of the key operations that incur high costs as well as one of the most complex tasks. It comprises the construction of order batches, batch assignment, picker routes, and scheduling of pickers. Therefore, the development of an efficient order picking system and the optimization of these operations have significant effects on the overall efficiency of the warehouse. This paper focuses on studying and modeling the order batching, batch assignment, and picker routing problems in a multi-warehouse, multi-period, multi-picker order picking system. We propose a multi-objective mathematical model for minimizing the delivery times of batches and the total cost of order picking operations. Also, for the first time, a possibilistic approach is applied to overcome uncertain conditions in the order picking problem. Given the complexity of the problem, Benders decomposition is implemented to solve the proposed model. The applicability of the proposed method is evaluated through a range of small to large test problems and an actual case study. The results indicate that the proposed exact method is capable of finding high-quality solutions within a reasonable computational time and number of iterations, which serves as evidence of its suitability for large-scale, complex real-world industrial contexts.},
  archive      = {J_SOCO},
  author       = {Nikkhoo, Fatemeh and Husseinzadeh Kashan, Ali and Nikbakhsh, Ehsan and Ostadi, Bakhtiar},
  doi          = {10.1007/s00500-025-10495-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2047-2074},
  shortjournal = {Soft Comput.},
  title        = {A bi-objective multi-warehouse multi-period order picking system under uncertainty: A benders decomposition approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel instance density-based hybrid resampling for
imbalanced classification problems. <em>SOCO</em>, <em>29</em>(4),
2031–2045. (<a
href="https://doi.org/10.1007/s00500-025-10499-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem is one of the challenging issues in various machine learning applications. This problem occurs when the number of instances of a class is much smaller (or larger) than those of the other classes. To handle the imbalanced classification problems, many useful approaches have been developed, for example, synthetic minority oversampling technique (SMOTE). However, the SMOTE is often sensitive to the predetermined $$k$$ value, i.e., the number of nearest neighbors used to generate the synthetic instances. For example, if the $$k$$ value is moderately large, some of the synthetic instances generated by the SMOTE would be located near a decision boundary or even within the majority class area and thus these can be treated as unnecessary noisy instances. Thus, in this study, we propose an efficient hybrid resampling method based on instance density called IDHR (Instance Density-based Hybrid Resampling) to improve the classification performance by generating instances that are closer to the minority class than the majority class while avoiding generation of noisy instances. For this, we first apply the instance density-based oversampling (IDO) technique to generate new synthetic instances. And then, we eliminate some of the synthetic instances that are close to the decision boundary and determine the number of the synthetic instances among the retained synthetic ones which can be eliminated based on maximum of the distances from all the synthetic instances to the minority class instances and minimum of the distances from all the synthetic instances to the majority class instances as well as classification performances. To demonstrate the effectiveness of the proposed resampling method, comprehensive experiments are conducted on sixteen imbalanced datasets with considering three classifiers, i.e., C4.5 decision tree algorithm, support vector machine (SVM), and multi-layer perceptron neural network (MLP-NN). Through the experimental analysis, it is shown that the proposed resampling method outperforms the traditional oversampling methods with respect to AUC and F-measure for most of the imbalanced datasets regardless of classifiers.},
  archive      = {J_SOCO},
  author       = {Park, You-Jin and Ma, Chung-Kang},
  doi          = {10.1007/s00500-025-10499-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2031-2045},
  shortjournal = {Soft Comput.},
  title        = {A novel instance density-based hybrid resampling for imbalanced classification problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyber-attack detection based on a deep chaotic invasive weed
kernel optimized machine learning classifier in cloud computing.
<em>SOCO</em>, <em>29</em>(4), 2015–2030. (<a
href="https://doi.org/10.1007/s00500-025-10521-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Cloud Computing has attracted a lot of interest from both individual users and organization. However, cloud computing applications face certain security issues, such as data integrity, user privacy, and service availability. The only better solution to such issues is to identify and prevent cyber threats before they can cause seriously harm the cloud computing system. Several methods have been suggested so far to detect the attack in cloud computing (CC), but no one method attains satisfactory results. To overwhelm these drawbacks, a Cyber Security Attack Detection using Deep Kernel Machine Learning optimized with Chaotic Invasive Weed Optimization algorithm is proposed in this paper for Cloud Computing. Here, the data is amassed from CSE-CIC-IDS2018 and Bot-IoT datasets. Subsequently, a pre-processing step involving redundancy reduction and missing value replacement for uncertainty removal is achieved through the Developed Random Forest with Local Least Squares (DRFLLS) method. By utilizing Entropy-Kurtosis based feature selection approach, the pre-processing data is given to the feature selection to identify the optimal features. The selected features are supplied to the Deep Kernel Machine Learning classifier (DK-ML), which is optimized using the Chaotic Invasive Weed Optimization algorithm (Chaotic-IWOA) for classification. This classification process classifies the data as normal or anomalous categories with anomalies encompassing, like DoS, DDoS, Theft attacks, and normal attacks. The proposed technique is activated in MATLAB. The proposed technique achieves 24.88%, 17.98%, 45.65%, 35.95% better accuracy for CSE-CIC-IDS2018 dataset, and 23.93%, 13.94%, 32.94%, and 29.04% better accuracy for Bot-IoT dataset.},
  archive      = {J_SOCO},
  author       = {Indrasena Reddy, M. and Siva Kumar, A. P. and Subba Reddy, K.},
  doi          = {10.1007/s00500-025-10521-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2015-2030},
  shortjournal = {Soft Comput.},
  title        = {Cyber-attack detection based on a deep chaotic invasive weed kernel optimized machine learning classifier in cloud computing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring diversity and time-aware recommendations: An
LSTM-DNN model with novel bidirectional dynamic time warping algorithm.
<em>SOCO</em>, <em>29</em>(4), 2003–2013. (<a
href="https://doi.org/10.1007/s00500-025-10534-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the Web 3.0 era, the amount and types of data in the network have sharply increased, and the application scenarios of recommendation algorithms are continuously expanding. Location recommendation has gradually become one of the popular application scenarios in recommendation algorithms. Traditional recommendation algorithms not only ignore the temporal attribute of data when recommending information to users, but also blindly pursue the recommendation accuracy, which will cause certain “information cocoon room” problems. Therefore, this article treats user historical data as a time series and proposes an LSTM-DNN model based on the novel bidirectional Dynamic Time Warping (DTW) algorithm. Firstly, in response to the issue of different users consuming different amounts of information, this article proposes a novel bidirectional DTW algorithm to calculate the similarity between different users. Secondly, this article supplements the user dataset from three perspectives: “utilization” and “exploration” of information, and spatiotemporal attributes of data, which alleviates the problem of data sparsity and cold start in the dataset to a certain extent. Moreover, it effectively enhances the diversity of recommendation results. Finally, this paper constructs an Long Short-Term Memory-Deep Neural Networks (LSTM-DNN) to dynamically obtain user interests and preferences, and proposes a new metric Cumulative Self-System Diversity (CSSD) to measure the diversity of algorithm recommendation results. Experiments have shown that the model effectively enhances the diversity of recommendation results while ensuring recommendation accuracy.},
  archive      = {J_SOCO},
  author       = {Li, Te and Chen, Liqiong and Sun, Huaiying and Hou, Mengxia and Lei, Yunjie and Zhi, Kaiwen},
  doi          = {10.1007/s00500-025-10534-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2003-2013},
  shortjournal = {Soft Comput.},
  title        = {Exploring diversity and time-aware recommendations: An LSTM-DNN model with novel bidirectional dynamic time warping algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted rank aggregation based on ranker accuracies for
feature selection. <em>SOCO</em>, <em>29</em>(4), 1981–2001. (<a
href="https://doi.org/10.1007/s00500-025-10530-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rank aggregation is the combination of several ranked lists from a set of candidates to achieve a better ranking by combining information from different sources. In feature selection problem, due to the heterogeneity of methods, there are some base rankers (Filter-based methods) that are of diverse quality and usually the ground truth of ratings is not available. Existing rank aggregation methods that take the diverse quality of base rankers into account do not have any explicit approach for appropriate weighting, require prior assumptions, and suffers from high computational complexity. In this paper, to overcome these challenges, an efficient unsupervised method is introduced for estimating the base rankers’ qualities and aggregating the rankers based on the estimated weights. We first compute the ratio of disagreement between base rankers in ordering different element pairs and then estimate the accuracies in a way that to minimize the discrepancy between these computed ratios and their analytical counterparts. We use the weighted majority voting method for obtaining the aggregated results. To resolve the probable inconsistencies in the final aggregation, the result is formed as a graph, and a greedy algorithm is used to find an acyclic subgraph with the highest weigh. To demonstrate the performance of the proposed method, nine standard UCI datasets are used. The obtained results by the proposed method have higher values of classifier measures than the existing baseline Feature Selection methods and rank aggregation-based multi-filter methods in the most datasets. The experiments show that rank aggregation-based Feature Selection methods outperform individual methods. The proposed method also shows the weight of each Filter-based Feature Selection method, in which the MRMR method has a higher weight than other methods.},
  archive      = {J_SOCO},
  author       = {Abdolrazzagh-Nezhad, Majid and Kherad, Mahdi},
  doi          = {10.1007/s00500-025-10530-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {1981-2001},
  shortjournal = {Soft Comput.},
  title        = {Weighted rank aggregation based on ranker accuracies for feature selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex preference analysis: A score-based evaluation
strategy for ranking and comparison of the evolutionary algorithms.
<em>SOCO</em>, <em>29</em>(4), 1967–1980. (<a
href="https://doi.org/10.1007/s00500-025-10525-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an evaluation strategy is proposed for evaluation of optimization algorithms, called the Complex Preference Analysis, that assesses the efficiency of different evolutionary algorithms by considering multiple performance metrics concurrently across diverse dimensions and generating a single score for ranking. The proposed strategy allows for a thorough evaluation by assigning distinct priorities in the form of weights, to various performance parameters. The algorithm’s performances on each performance parameter are captured and the best and worst performances in each performance category are identified. The deviation of each algorithm from the best and worst performances in the respective performance category is formulated to generate a single score for each of the algorithms for comparison. The flexibility to adjust weights provides a valuable tool for customizing evaluations according to individual needs and preferences. The proposed evaluation strategy is studied by running evaluations on nine evolutionary algorithms based on their performance over five performance indicators on six datasets of the Travelling Salesman Problem. Conducting Complex Preference Analysis on the different evolutionary algorithms reveals distinctive patterns in their performance, with some algorithms such as Simulated Annealing, Tabu Search, Bat Algorithm, Genetic Algorithm, etc. consistently demonstrating superior results across multiple Travelling Salesman Problem instances, while other algorithms such as Ant Colony Optimization, Teaching Learning Based Optimization, etc. rank lower. The algorithms’ performances on individual performance parameters, when reflected on the final rank of the algorithms, generated based on the collective impact of all the parameters, elucidate the efficiency of the proposed evaluation strategy.},
  archive      = {J_SOCO},
  author       = {Sarkar, Debojyoti and Biswas, Anupam},
  doi          = {10.1007/s00500-025-10525-y},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {1967-1980},
  shortjournal = {Soft Comput.},
  title        = {Complex preference analysis: A score-based evaluation strategy for ranking and comparison of the evolutionary algorithms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A map-reduce algorithm to find strongly connected components
of directed graphs. <em>SOCO</em>, <em>29</em>(4), 1947–1966. (<a
href="https://doi.org/10.1007/s00500-025-10451-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks have become ubiquitous platforms, comprising intricately linked structures that reflect complex user interactions. Analyzing the interconnected component structure of these large directed graphs is pivotal for critical applications like viral marketing and contagion prediction. This paper presents a parallel algorithm to efficiently discover strongly connected components in massive social graphs by distributing computation across clustered servers. Our proposed distributed approach conducts localized connected component extraction during the Map phase. The merged aggregation in the Reduce phase then uncovers global maximum interconnected sets spanning the fragmented structures. We employ mathematical induction across Map-Reduce stages to demonstrate the algorithm’s correctness for obtaining exhaustive component enumeration across servers. Implementation and complexity analysis on synthetic benchmark graphs highlight significant efficiency gains, with the algorithm demonstrating near-linear speedup for increasing data-set and cluster sizes. The proposed technique advances the state-of-the-art for extracting strongly connected structures from colossal real-world social networks, enabling actionable insights around influence cascades and contagion pathways underlying these intricate linkage patterns.},
  archive      = {J_SOCO},
  author       = {Ji, Fujun and Jin, Jidong},
  doi          = {10.1007/s00500-025-10451-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {1947-1966},
  shortjournal = {Soft Comput.},
  title        = {A map-reduce algorithm to find strongly connected components of directed graphs},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving recurrent deterministic policy gradient strategy
in autonomous driving. <em>SOCO</em>, <em>29</em>(3), 1931–1946. (<a
href="https://doi.org/10.1007/s00500-025-10442-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even though autonomous driving has emerged as a prominent study topic, the conventional control systems for autonomous driving are often rule-based and need to be more adaptable to the flow and conditions of traffic that change over time. Recurrent deterministic policy gradient (RDPG) is a strategy for building autonomous driving control systems. Its performance has been shown to be better than some other methods. Consequently, in this study, we make use of the RDPG algorithm to implement our control strategies as well and further give more comprehensive considerations to the learning procedure to obtain better control performance in the testing procedure, e.g., various punishments to avoid vehicle collisions, different speed limitations to avoid slow-driving or fast-driving, distinct rewards to encourage the ego-vehicle to reach the destination, and so on. On the other hand, we also improve the training performance by focusing solely on the critical events during the training procedure. Namely, our training architecture is more efficient based on the same training time (training steps). The road scene and vehicular simulator, AirSim, has been selected as the experimental platform. The findings indicate that our design achieves more accurate and steady outcomes in control and faster convergence in learning compared to an existing RDPG control strategy for autonomous driving in the literature.},
  archive      = {J_SOCO},
  author       = {Ooi, Yee-Ming and Chang, Che-Cheng},
  doi          = {10.1007/s00500-025-10442-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1931-1946},
  shortjournal = {Soft Comput.},
  title        = {Improving recurrent deterministic policy gradient strategy in autonomous driving},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of discharge coefficient of submerged gates using
a stacking ensemble model. <em>SOCO</em>, <em>29</em>(3), 1911–1929. (<a
href="https://doi.org/10.1007/s00500-025-10518-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the precision of discharge coefficient (Cd) prediction is crucial for effective agricultural water management. However, existing methods for Cd calculation are often complex and dependent on specific assumptions. Therefore, there is a critical need for robust and automated models for Cd estimation. This study introduces a dual-stage ensemble model called EnsembleCNN, for Cd prediction using two distinct gate types under submerged flow conditions. The EnsembleCNN framework uniquely integrates machine learning (ML) models with a recurrent convolutional neural network (CNN) model to capture higher-order interactions and non-linearities. Five base ML models are employed to generate initial predictions. These predictions are subsequently processed by a CNN model embedded with long short-term memory (LSTM) layer, residual connection (RC) and an attention mechanism (ATM). This setup effectively manages the complexity of the combined predictions, seamlessly integrating the outputs from the base models. LSTM is exploited to aggregate the best features for prediction. ATM effectively prioritized high-performing base model outputs, while RC improved the gradient flow, collectively reducing the impact of irrelevant features. The proposed approach strategically weights the contributions of each base model, resulting in accurate Cd estimations. The proposed model achieved root mean square errors of 0.0552 and 0.0173 on vertical sluice gates and radial gates datasets, respectively. Additionally, EnsembleCNN outperformed the base and existing models in terms of prediction accuracy. The proposed system provides a robust tool for optimizing water resource management. Moreover, the adaptability to two field datasets further underscores the practical utility of our model in diverse irrigation scenarios.},
  archive      = {J_SOCO},
  author       = {Hosny, Mohamed and Abdelhaleem, Fahmy S. and Elshenhab, Ahmed M. and Ibrahim, Amir},
  doi          = {10.1007/s00500-025-10518-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1911-1929},
  shortjournal = {Soft Comput.},
  title        = {Prediction of discharge coefficient of submerged gates using a stacking ensemble model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label-specific multi-label text classification based on
dynamic graph convolutional networks. <em>SOCO</em>, <em>29</em>(3),
1897–1909. (<a
href="https://doi.org/10.1007/s00500-025-10446-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label text classification is a key task in natural language processing, aiming to assign each text to multiple predefined categories simultaneously. Existing neural network models usually learn the same text representation for different labels, which limits the effectiveness of the models in capturing deep semantics and distinguishing between similar labels; moreover, these models tend to ignore inter-label correlation, leading to loss of information. To overcome these limitations, we propose a novel label-specific dynamic graph convolutional network (LDGCN). This network combines convolutional operations and BiLSTM to model text sequences and obtains label-specific text representations through a label attention mechanism. In addition, LDGCN improves the dynamic graph convolutional network by utilizing statistical label co-occurrence and label reconstruction maps to effectively capture inter-label dependencies and adaptive interactions between label-specific semantic components. Extensive experiments on the RCV1, AAPD, and EUR-Lex datasets show that our model achieves 96.92%, 86.30%, and 81.42% on the P@1 metrics, respectively, and demonstrates a significant advantage in dealing with tail labels.},
  archive      = {J_SOCO},
  author       = {Yan, Yaoyao and Liu, Fang‘ai and Liu, Kenan and Xu, Weizhi and Zhuang, Xuqiang},
  doi          = {10.1007/s00500-025-10446-w},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1897-1909},
  shortjournal = {Soft Comput.},
  title        = {Label-specific multi-label text classification based on dynamic graph convolutional networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Threats to medical diagnosis systems: Analyzing targeted
adversarial attacks in deep learning-based COVID-19 diagnosis.
<em>SOCO</em>, <em>29</em>(3), 1879–1896. (<a
href="https://doi.org/10.1007/s00500-025-10516-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep and machine learning models have become pivotal in medical image analysis, especially for diagnosing COVID-19 using X-rays and CT scans. While these models, including transfer learning-based approaches, have achieved high accuracy, they remain highly vulnerable to adversarial attacks, which can manipulate input data and cause misclassification, posing critical risks in clinical applications. This study introduces a novel approach to addressing this issue by systematically evaluating the impact of adversarial attacks on COVID-19 diagnosis models built with two leading architectures, VGG-16 and DenseNet-121, using the Fast Gradient Sign Method (FGSM). The FGSM attack causes a dramatic drop in accuracy, reducing VGG-16’s accuracy from 95.12 to 9.97% and DenseNet-121’s from 96.51 to 10.13%. To counter these vulnerabilities, we propose a novel defense mechanism that combines adversarial training with Gaussian noise data augmentation, a dynamic approach that generates perturbations across various epsilon values during the training phase. This innovative method significantly enhances model robustness, restoring accuracy to over 92% on adversarial examples. These findings emphasize the need for strong defense mechanisms in deep learning models for COVID-19 diagnosis, ensuring reliability and security against adversarial threats in clinical environments.},
  archive      = {J_SOCO},
  author       = {Haque, Sheikh Burhan Ul and Zafar, Aasim and Haq, Sheikh Riyaz Ul and Haque, Sheikh Moeen Ul and Ahmad, Mohassin and Roshan, Khushnaseeb},
  doi          = {10.1007/s00500-025-10516-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1879-1896},
  shortjournal = {Soft Comput.},
  title        = {Threats to medical diagnosis systems: Analyzing targeted adversarial attacks in deep learning-based COVID-19 diagnosis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive multimodal approach for parkinson’s disease
classification using artificial intelligence: Insights and model
explainability. <em>SOCO</em>, <em>29</em>(3), 1845–1877. (<a
href="https://doi.org/10.1007/s00500-025-10463-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is a debilitating neurodegenerative disorder affecting millions worldwide. Early detection is vital for effective management, yet remains challenging. In this study, we investigated four distinct datasets for PD detection. Through comprehensive experimentation employing ensemble methods and feature selection, we achieved high classification accuracies across the datasets. For the Oxford Parkinson’s Disease Detection Dataset, an accuracy of 95.67%, precision of 97.59%, recall of 84.5%, specificity of 99.32%, and F1-score of 90.57% were achieved. For the Alzheimer Parkinson Diseases 3 Class Dataset, the “Stacking” approach surpasses individual models, reaching an accuracy of 99.85%, precision of 99.81%, recall of 99.81%, specificity of 99.86%, and F1 of 99.81%. For the NewHandPD dataset, Regarding the Spiral category, The “Base-P32-384” model surpasses others with an accuracy of 97.35%, precision of 96.50%, recall of 98.57%, and F1-score of 97.53%. The collective “Stacking” approach proves highly effective regarding the Circle category, achieving 100% across all performance metrics. Regarding the Meander category, the “Base-P16-224” model achieves an accuracy of 97.35%, precision of 99.26%, recall of 95.71%, specificity of 99.19%, and F1 of 97.45%. The Mobile Device Voice Recordings at King’s College London (MDVR-KCL) dataset contains two datasets. Regarding the “SpontaneousDialogue” dataset, accuracy, BAC, precision, recall, specificity, and F1-score were computed, resulting in values of 94.03%, 92.83%, 90.78%, 100.0%, and 85.67%, respectively. Regarding the “ReadText” dataset, accuracy, BAC, precision, recall, specificity, and F1-score were computed, resulting in values of 91.89%, 90.62%, 87.5%, 100.0%, and 81.25%, respectively. Our findings highlight the efficacy of leveraging diverse data sources and advanced machine learning techniques to enhance PD detection accuracy.},
  archive      = {J_SOCO},
  author       = {Balaha, Hossam Magdy and Hassan, Asmaa El-Sayed and Ahmed, Rawan Ayman and Balaha, Magdy Hassan},
  doi          = {10.1007/s00500-025-10463-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1845-1877},
  shortjournal = {Soft Comput.},
  title        = {Comprehensive multimodal approach for parkinson’s disease classification using artificial intelligence: Insights and model explainability},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing neural network predictions with finetuned numeric
embeddings for stock trend forecasting. <em>SOCO</em>, <em>29</em>(3),
1829–1844. (<a
href="https://doi.org/10.1007/s00500-025-10483-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The financial markets, particularly stock trading, offer a variety of profit-generating opportunities based on complex and volatile behaviour. Investors seek strategies to maximise returns, leading to an investigation of inherent market patterns. Converting OHLC (Open, High, Low, Close) data into transformers-based pre-trained language model compatible text is an innovative method for representing numeric data. Extending the language model’s utility to integrate stock market numeric time-series data incorporates its inherent numeracy in embeddings. Raw data are converted into a format compatible with the pre-trained language model through preprocessing and text templates. Using an ensemble of Bidirectional Encoder Representations from Transformers (BERT), FinBERT (BERT finetuned with the financial corpus), FLANG-BERT (BERT finetuned with the financial corpus) and FLANG-ELECTRA (ELECTRA finetuned with the financial corpus) as feature extractor, historical stock market data are utilised to generate an embedding matrix and fused with established neural network architectures, such as Backpropagation Neural Network (BPNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU), to predict stock market trends. The simulation results demonstrate that the proposed integrated approach is preferable to previous methodologies. The significance of the findings is confirmed by statistical validation using the Wilcoxon signed-rank test (p value &lt; 0.01). This study offers a promising approach for improving stock market trend prediction by integrating the ensemble of language model-based numeric embeddings with neural networks.},
  archive      = {J_SOCO},
  author       = {Trivedi, Avinash and Sangeetha, S.},
  doi          = {10.1007/s00500-025-10483-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1829-1844},
  shortjournal = {Soft Comput.},
  title        = {Enhancing neural network predictions with finetuned numeric embeddings for stock trend forecasting},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A game-theoretic exploration with surplus profit-sharing in
a three-channel supply chain, featuring e-commerce dynamics.
<em>SOCO</em>, <em>29</em>(3), 1811–1827. (<a
href="https://doi.org/10.1007/s00500-025-10453-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a three-channel supply chain, coordination can be challenging especially when a manufacturer has to work with a retailer and an online platform. In such a scenario, sales efforts can be critical to the success of the supply chain. However, there is a risk of free riding behavior by either the retailer or the manufacturer, which can lead to suboptimal sales performance. This article will explore the centralized and the decentralized models by the use of game theory (Nash and Stackelberg) and eventually tries to coordinate the three-channel supply chain with the help of Operational Research (OR) to optimize the decision-making and create a win–win situation. Numerical examples are provided to prove the efficiency of the presented models. Finally, the models are evaluated through sensitivity analysis, and managerial insights are provided to enhance the applicability of the models for coordinating a three-channel supply chain.},
  archive      = {J_SOCO},
  author       = {Vatanara, Maryam and Rabbani, Masoud and Heydari, Jafar},
  doi          = {10.1007/s00500-025-10453-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1811-1827},
  shortjournal = {Soft Comput.},
  title        = {A game-theoretic exploration with surplus profit-sharing in a three-channel supply chain, featuring e-commerce dynamics},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forest fire rescue framework to jointly optimize
firefighting force configuration and facility layout: A case study of
digital-twin simulation optimization. <em>SOCO</em>, <em>29</em>(3),
1789–1810. (<a
href="https://doi.org/10.1007/s00500-025-10434-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the pre-prevention stage, firefighting force configuration and facility layout play a critical role in reducing fire extinguishing time (FET) during the early-stage forest fire rescue. It is acknowledged that there is a scarcity of quantitative evaluation research establishing a connection between observed forest fire behaviors and pre-prevention research. Therefore, we propose a forest fire rescue framework to jointly optimize firefighting force configuration and facility layout. As an iterative optimization framework based on fire spread and suppression model (FSSM), firefighting force configuration and facility layout methods use differential-evolution-based algorithm and deep neural network to adjust the configuration funds of various firefighting forces and plan the spatial layout of multiple firefighting facilities. With iterations increasing, the proposed method can continue to find better solutions than before. Moreover, through the offensive and defensive procedures in FSSM, the best configuration and layout solution can mirror multi-rescue-resource interactions and mutual restraints. The performance of the proposed framework is validated through various maps and experiments in terms of FET, forest burned area, and uncontrolled fire rate, even under extreme wind-speed pressure conditions. This implies that the proposed framework demonstrates favorable adaptability. Furthermore, the proposed framework can be introduced into the related dynamic interactions and constraints optimization scenarios (e.g., smart factories, smart construction sites, and more), thereby opening the door of digital-twin simulation optimization.},
  archive      = {J_SOCO},
  author       = {Zhang, HongGuang and Ma, ShengWen and Li, Xiang and You, MingCan and Tao, YuXuan},
  doi          = {10.1007/s00500-025-10434-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1789-1810},
  shortjournal = {Soft Comput.},
  title        = {Forest fire rescue framework to jointly optimize firefighting force configuration and facility layout: A case study of digital-twin simulation optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient collocation algorithm for third order
non-linear emden–fowler equation. <em>SOCO</em>, <em>29</em>(3),
1767–1788. (<a
href="https://doi.org/10.1007/s00500-025-10431-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study presents a novel algorithm for solving third-order non-linear equations (Emden–Fowler type), which can be applied to various physical models. The algorithm uses a quintic trigonometric B-spline collocation method and a quasilinearization technique to avoid the non-linearity term in the equation. The study established a comprehensive error analysis for the proposed algorithm and proved that it has fourth order, i.e., $$(\mathscr {O}(h^4))$$ convergent. The algorithm’s ability to handle singular behavior at the point $$x=0$$ and its faster rate of convergence exhibit a promising approach to solving such problems. The study also validates the theoretical results through numerical experiments and shows that the proposed algorithm has a faster rate of convergence in comparison to the existing methods.},
  archive      = {J_SOCO},
  author       = {Alam, Mohammad Prawesh and Khan, Arshad},
  doi          = {10.1007/s00500-025-10431-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1767-1788},
  shortjournal = {Soft Comput.},
  title        = {An efficient collocation algorithm for third order non-linear Emden–Fowler equation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feature extraction method for rotating machinery fault
diagnosis based on a multiscale entropy fusion strategy and GA-RL-LDA
model. <em>SOCO</em>, <em>29</em>(3), 1747–1765. (<a
href="https://doi.org/10.1007/s00500-025-10484-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of information loss, feature redundancy and unsatisfactory diagnosis accuracy when using traditional multiscale entropy methods and feature reduction methods to diagnose rotating machinery faults, a feature extraction method based on a multiscale entropy fusion strategy and a GA-RL-LDA model is proposed in this paper. Firstly, the multiscale fluctuation dispersion entropy (MFDE), the refined composite multiscale dispersion entropy (RCMDE) and the refined composite multiscale fluctuation dispersion entropy (RCMFDE) of the collected vibration signal are calculated to form an original feature set. Then, based on the ReliefF algorithm and Laplacian score (LS), an RL index is constructed for feature sensitivity evaluation. After that, combing the RL with Linear discriminant analysis (LDA) and using genetic algorithm (GA) to optimize the uncertain parameters, a GA-RL-LDA model is proposed for feature reduction. Finally, the reduced feature subset is input into support vector machine (SVM) for fault classification. The experiment utilized data from Unit 3 of the SK Hydropower Station and bearing data from Case Western Reserve University, achieving diagnostic accuracies of 95.2381% and 97.3333%, respectively. In the 105 test samples from Unit 3 of the SK Hydropower Station, only 5 samples were misclassified, while in the 150 test samples from Case Western Reserve University, only 4 samples were misclassified. Compared with different information entropy and optimization strategies, the results show that the proposed method can more effectively extract fault sensitive features and accurately diagnose rotating machinery faults even with a small number of training samples.},
  archive      = {J_SOCO},
  author       = {Lu, Na and Li, Zhongliang and Liu, Dong and Cao, Chaofan and Jiang, Shuangyun and Chen, Xudong and Wang, Peng},
  doi          = {10.1007/s00500-025-10484-4},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1747-1765},
  shortjournal = {Soft Comput.},
  title        = {A feature extraction method for rotating machinery fault diagnosis based on a multiscale entropy fusion strategy and GA-RL-LDA model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning approach to analyse stress by using voice
and body posture. <em>SOCO</em>, <em>29</em>(3), 1719–1745. (<a
href="https://doi.org/10.1007/s00500-025-10441-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current scenario, where we can see young people struggling for their careers, they are even fighting a battle with their stress and tension. None of their work is done without stress to complete their task and compete with others. To overcome stress, one should have good emotional intelligence to cope with emotions and any upcoming stress. But at some point, due to lack of guidance, some people don’t know how to analyze the situations and how to handle them without taking the stress and end up with anxiety, depression, disappointment, suicide, heart attack, stroke etc. Due to the advancement of Human–Computer Interaction (HCI), medical science has leveled up to another peak. Machine Learning and Deep Learning played a major role in such interactions and predictions. Many applications have been developed in past years based on machine learning and deep learning. One of those applications is related to psychology and is still in research. These applications can be used for emotion and stress analysis among people, especially youngsters. Research in this field is being conducted using various verbal and non-verbal parameters. This paper addresses the research problem of improving emotion recognition accuracy and robustness to better analyze and manage stress. The primary objective is to develop an advanced Emotion Recognition System (ERS) that leverages deep learning algorithms to analyses both verbal and non-verbal cues—specifically, speech and body posture, including facial expressions. We have further integrated it with the Flask web framework to make an Emotion Recognition System that takes input in the form of video and audio to analyze Emotions and Stress. We have also compared our proposed ERS with existing ones and found that our ERS gives better results.},
  archive      = {J_SOCO},
  author       = {Gupta, Sumita and Gambhir, Sapna and Gambhir, Mohit and Majumdar, Rana and Shrivastava, Avinash K. and Pham, Hoang},
  doi          = {10.1007/s00500-025-10441-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1719-1745},
  shortjournal = {Soft Comput.},
  title        = {A deep learning approach to analyse stress by using voice and body posture},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced TOPSIS-CoCoSo framework for multi-attribute
decision-making with triangular fuzzy neutrosophic sets: “Effect
evaluation of intelligent technology empowering physical education
teaching” case. <em>SOCO</em>, <em>29</em>(3), 1703–1717. (<a
href="https://doi.org/10.1007/s00500-025-10411-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The history of human education development has proven that there is an interactive relationship between technological development and education and teaching. In the process of promoting education modernization and high-quality development, the widespread application of intelligent technology in the field of education is the trend, and intelligence is driving profound transformation and transformation in the field of education. The effect evaluation of intelligent technology empowering Physical Education teaching could be considered as multiple-attribute decision-making (MADM). Recently, the TOPSIS technique and Combined Compromise Solution (CoCoSo) technique was employed to deal with MADM. The triangular fuzzy neutrosophic sets (TFNSs) are employed as a better tool for expressing uncertain information during the effect evaluation of intelligent technology empowering Physical Education teaching. In this paper, the triangular fuzzy neutrosophic number TOPSIS-CoCoSo (TFNN-TOPSIS-CoCoSo) technique based on the TFNN relative closeness coefficient (TFNNRCC) technique is managed to cope with the MADM under TFNSs. The information entropy technique is employed to manage the weight values based on the TFNNRCC under TFNSs. Finally, a numerical example of effect evaluation of intelligent technology empowering Physical Education teaching is managed and some better comparisons are managed to verify the TFNN-TOPSIS-CoCoSo technique. The main contribution of this paper is outlined: (1)TFNN-TOPSIS-CoCoSo technique based on the TFNNRCC is constructed; (2) Entropy technique is employed to manage weight based on the TFNNRCC under TFNSs. (3) TFNN-TOPSIS-CoCoSo technique is founded to manage the MADM based on the TFNNRCC under TFNSs; (4) numerical example for effect evaluation of intelligent technology empowering Physical Education teaching and some comparative analysis is supplied to verify the proposed TFNN-TOPSIS-CoCoSo technique.},
  archive      = {J_SOCO},
  author       = {Xiao, Jie and Zhang, Yu},
  doi          = {10.1007/s00500-025-10411-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1703-1717},
  shortjournal = {Soft Comput.},
  title        = {Enhanced TOPSIS-CoCoSo framework for multi-attribute decision-making with triangular fuzzy neutrosophic sets: “effect evaluation of intelligent technology empowering physical education teaching” case},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lacunary statistical soft convergence in soft topology.
<em>SOCO</em>, <em>29</em>(3), 1691–1701. (<a
href="https://doi.org/10.1007/s00500-025-10479-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical convergence and some related types of convergence are a generalisation of topological convergence. Similarly, soft set theory, introduced by Molodtsov to deal with uncertainty in various scientific fields, is a generalisation of the classical concept of sets. Although both concepts have found extensive applications to various mathematical structures, the investigation of statistical convergence within soft topological spaces has not yet been undertaken. This study examines the lacunary statistical convergence of sequences of soft points in soft topological spaces, employing a density defined by an unbounded modulus function. Basic results and inclusion theorems concerning this convergence are presented.},
  archive      = {J_SOCO},
  author       = {Bayram, Erdal and Dervişoğlu, Melisa},
  doi          = {10.1007/s00500-025-10479-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1691-1701},
  shortjournal = {Soft Comput.},
  title        = {Lacunary statistical soft convergence in soft topology},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-InfNode: Ranking top-k influential nodes in complex
networks with random walk. <em>SOCO</em>, <em>29</em>(3), 1677–1690. (<a
href="https://doi.org/10.1007/s00500-025-10471-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complex network is a symbolic representation of distinct real-world systems where information propagates through nodes. Its goal is to identify communities that represent the network’s structure. However, locating the influential node with the maximal range among various nodes and the ability to disseminate influence to a wide portion of the network is one of the most essential concerns in such a network. Centrality is a traditional metric for understanding the effect of nodes in a network, with numerous variants such as closeness, betweenness, degree centrality, and so on. The centrality metrics either work locally or globally to identify influential nodes. In this study, a proposed algorithm named k-InfNode, based on the characteristics of community structure, captures the dynamics of nodes. k-InfNode uses a random walk and combines local and global properties to figure out which nodes are important in a complex network. It was inspired by the idea of overlapping nodes that show how nodes and communities interact with each other across the network. In the beginning, the fuzzy c-means algorithm finds the overlapping nodes in the network. Next, the algorithm assigns an initial score to each node based on node and community information, and iteratively scores each node using the Random Walk with Restart (RWR) algorithm. Experiments performed using real and artificial networks have shown that the k-InfNode is effective.},
  archive      = {J_SOCO},
  author       = {Hasan, Ahmadi and Kamal, Ahmad and Kumar, Pawan},
  doi          = {10.1007/s00500-025-10471-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1677-1690},
  shortjournal = {Soft Comput.},
  title        = {K-InfNode: Ranking top-k influential nodes in complex networks with random walk},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A micro-level approach for modeling rumor propagation in
online social networks. <em>SOCO</em>, <em>29</em>(3), 1667–1675. (<a
href="https://doi.org/10.1007/s00500-025-10456-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks have become the major platforms for information dissemination in recent years. However, rapid propagation of rumors in these networks as a special form of information can greatly influences social lives. Hence, work on rumor propagation models and analysis is under great attention by the research communities. Previously, researchers have proposed various models to explore the dynamics of rumor propagation and analyze steady-state. However, most of them did not consider people’s behavior differences in the spreading or opposing rumor. To overcome this limitation, we assume that individuals have different probability of spreading rumor, spreading anti-rumor and stifling. In this paper we introduce a new model for rumor propagation in social networks considering these differences at micro-level. The proposed model which considered both types of rumor and anti-rumor messages on people decision is an agent-based model in terms of probabilistic automata network. To evaluate the proposed model, we conduct a number of Monte-Carlo simulation experiments on Barabasi-Albert model of social networks that show the accuracy of the proposed model. We also conduct interesting sensitivity analysis to see the effects of different model parameters on the dynamics of the rumor propagation.},
  archive      = {J_SOCO},
  author       = {Sahafizadeh, Ebrahim and Talatian Azad, Saeed},
  doi          = {10.1007/s00500-025-10456-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1667-1675},
  shortjournal = {Soft Comput.},
  title        = {A micro-level approach for modeling rumor propagation in online social networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Paw decompositions of diamond and some edge cycle graphs.
<em>SOCO</em>, <em>29</em>(3), 1659–1665. (<a
href="https://doi.org/10.1007/s00500-025-10541-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $${C}_{n}, {K}_{n},{W}_{n},{K}_{r,s}$$ denote a cycle, complete graph, wheel graph, complete bipartite graph respectively. An edge cycle graph of a graph $$G$$ is the graph $$G({C}_{k})$$ formed from one copy of $$G$$ and $$|E(G)|$$ copies of $${P}_{k},$$ where t he ends of the $${i}^{th}$$ edge are identified with the ends of $${i}^{th}$$ copy of $${P}_{k}$$ . In this article, we determine the necessary and sufficient conditions for the existence of paw- decompositions of the diamond graph $${Br}_{n}$$ and some edge cycle graphs like $${K}_{n}\left({C}_{3}\right), { W}_{n}\left({C}_{3}\right),{ K}_{r,s}\left({C}_{3}\right), { C}_{n}\circ \stackrel{\leftharpoonup}{{K}_{m}}({C}_{3})$$ and $${P}_{n}\circ \stackrel{\leftharpoonup}{{K}_{m}}({C}_{3})$$ where $$\circ $$ denotes the corona of graphs.},
  archive      = {J_SOCO},
  author       = {Esakkimuthu, Murugan and Rameshbabu, Sivaprakash Gunniya},
  doi          = {10.1007/s00500-025-10541-y},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1659-1665},
  shortjournal = {Soft Comput.},
  title        = {Paw decompositions of diamond and some edge cycle graphs},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On goal programming approach for interval-valued
intuitionistic fuzzy multi-objective transportation problems with an
application to tourism industry. <em>SOCO</em>, <em>29</em>(3),
1627–1657. (<a
href="https://doi.org/10.1007/s00500-025-10420-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation problems are inevitably affected by numerous imprecise factors like weather, fuel expenses, topography, etc. Hence, the use of crisp parameters to model transportation problems appears to be both insufficient and inaccurate. Consequently, transportation problems using fuzzy/ intuitionistic fuzzy (IF) numbers seem more effective. Interval-valued intuitionistic fuzzy (IVIF) numbers are further generalization of IF numbers where membership and non-membership degrees are closed sub-intervals of [0, 1]. This concept of allocating interval values helps in dealing with the hesitancy of decision-maker while assigning fixed values to membership and non-membership degrees. In this article, balanced transportation problems having multiple objectives under the IVIF environment are examined. To overcome inconsistencies in the existing approaches, novel linear as well as non-linear interval-valued membership and non-membership functions have been proposed. Subsequently, an improved IVIF programming approach is developed using these newly defined functions along with theoretical validation. In addition, when goals are associated with objective functions, the proposed approach has been further improvised as IVIF prioritized goal programming. Eventually, a trip planning problem in the tourism industry is exhibited to illustrate the proposed IVIF technique and later, it is amalgamated with prioritized goals to demonstrate the proposed IVIF goal programming approach.},
  archive      = {J_SOCO},
  author       = {Chauhan, Abhishek and Mahajan, Sumati},
  doi          = {10.1007/s00500-025-10420-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1627-1657},
  shortjournal = {Soft Comput.},
  title        = {On goal programming approach for interval-valued intuitionistic fuzzy multi-objective transportation problems with an application to tourism industry},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-aware coverage path planning for a swarm of UAVs
using mobile ground stations for battery-swapping. <em>SOCO</em>,
<em>29</em>(3), 1605–1625. (<a
href="https://doi.org/10.1007/s00500-025-10537-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usage of swarms of drones is expected to continue growing in the next years, particularly in dangerous scenarios, such as monitoring and rescue missions in hostile and disaster areas. Small-sized Unmanned Aerial Vehicles (UAVs) are highly suitable for use in such scenarios due to their agility and maneuverability. On the other hand, their limited battery capacity poses significant challenges, especially during missions requiring full coverage of large areas in a short time and extreme weather conditions. This work proposed an energy efficiency approach, which makes use of mobile ground-based battery-swapping stations (BSSes), to speed up the UAV’s battery replacement and reduce energy waste in the round trip to the charging station. Specifically, a Context-Aware Coverage Path Planning (CACPP) problem has been formulated to determine the complete coverage path of a large area by a swarm of UAVs, minimizing the path overlapping and UAV battery swapping. The model takes into account the need to continue re-planning the mission, depending on the weather conditions (i.e., temperature and wind), the presence of obstacles, and the residual energy levels of the drones, as well as the relative positions of the drones and mobile BSSes. To solve the CACPP problem, an iterative approach leveraging two synchronized optimization models for planning UAV paths and BSS routes has been presented. As the CACPP problem is NP-hard, a heuristic procedure for solving it has also been evaluated. Experimental results show that it can be appropriate for large instances of the problem.},
  archive      = {J_SOCO},
  author       = {Porcelli, Lorenzo and Ficco, Massimo and D’Angelo, Gianni and Palmieri, Francesco},
  doi          = {10.1007/s00500-025-10537-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1605-1625},
  shortjournal = {Soft Comput.},
  title        = {Context-aware coverage path planning for a swarm of UAVs using mobile ground stations for battery-swapping},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using deep forest regression and multi-layer state
transition algorithm to soft measuring modeling with small sample data.
<em>SOCO</em>, <em>29</em>(3), 1587–1603. (<a
href="https://doi.org/10.1007/s00500-025-10527-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In actual industrial operation process, some key performance indicators (KPIs) are tricky to detect online due to the characteristics of the detection equipment and the nature of the parameters. Moreover, these KPIs usually present small sample attributes. In this article, a stable and efficient soft measuring model for the KPIs of industrial processes is proposed using deep forest regression (DFR) and multi-layer state transition algorithm (STA). First, DFR is used to build soft measuring models for KPIs with random initial hyperparameters. Second, an improved dynamic STA (DSTA) is developed to optimize the DFR’s hyperparameters. Furthermore, the probability parameters of the DSTA structure are optimally selected using a STA. Finally, gradient refinement is utilized to fine-tune the state factor, which achieves a more accurate optimization process during the internal iteration process. The proposed algorithm is evaluated on the benchmark function, dataset, and an actual industrial problem. Results prove that the use of our method in soft measuring modeling can be effective.},
  archive      = {J_SOCO},
  author       = {Xia, Heng and Tang, Jian and Yu, Wen},
  doi          = {10.1007/s00500-025-10527-w},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1587-1603},
  shortjournal = {Soft Comput.},
  title        = {Using deep forest regression and multi-layer state transition algorithm to soft measuring modeling with small sample data},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A community-based simulated annealing approach with a new
structure-based neighborhood search to identify influential nodes in
social networks. <em>SOCO</em>, <em>29</em>(3), 1567–1585. (<a
href="https://doi.org/10.1007/s00500-025-10490-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying influential nodes has attracted the attention of many researchers in recent years. Because of the weak tradeoff between accuracy and running time, and ignoring the community structure by the proposed algorithms in the past research studies, further studies in this area are required. In this paper, we consider communities and also use a novel structure-based neighborhood search to improve exploration strategy of the simulated annealing (SA) algorithm. Moreover, we use the k-shell method for generating a better initial solution instead of random generation. In the proposed algorithm called Ckshell-SA, first, the communities are detected, then the k-shell method is used in each community to find initial candidate nodes locally. Finally, SA algorithm is applied with a neighborhood search that considers the structural properties of the network, and three centralities to find the influential nodes globally. A derivative of the Ckshell-SA method called kshell-SA is also introduced in this paper to examine the impact of considering communities. Unlike the Ckshell-SA, the community structure is neglected, and the k-shell is performed on the whole network in kshell-SA algorithm. Extensive experiments are conducted on eight real-world networks under Independent Cascade Model (IC) and Weighted Independent Cascade Model (WC). The results show that the Ckshell-SA and kshell-SA algorithms outperform the state-of-the-art algorithms concerning influence spread. Furthermore, the results show that Ckshell-SA is more efficient in networks like Facebook with a high Power Law exponent and higher modularity. On the contrary, kshell-SA is more successful in networks like Slashdot or Epinions with lower modularity.},
  archive      = {J_SOCO},
  author       = {Abyaneh, Farzaneh Rajaee and Charkari, Nasrollah Moghadam and Roayaei, Mehdy},
  doi          = {10.1007/s00500-025-10490-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1567-1585},
  shortjournal = {Soft Comput.},
  title        = {A community-based simulated annealing approach with a new structure-based neighborhood search to identify influential nodes in social networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid genetic search based approach for the generalized
vehicle routing problem. <em>SOCO</em>, <em>29</em>(3), 1553–1566. (<a
href="https://doi.org/10.1007/s00500-025-10507-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel meta-heuristic for addressing a variant of the classical Capacitated Vehicle Routing Problem (CVRP) known as the Generalized Vehicle Routing Problem (GVRP). In the GVRP, nodes are organized into clusters, with the constraint that only one node from each cluster must be visited. The proposed meta-heuristic is a Hybrid Genetic Search (HGS) that leverages recent advancements in CVRP methodologies, adapting successful strategies and techniques from CVRP to the GVRP context. To evaluate the performance of the HGS meta-heuristic, we perform an extensive computational analysis on numerous benchmark instances ranging from small to large sizes. To thoroughly analyze the algorithm’s average behavior, convergence profiles over time are reported for the considered instances. Results show that the proposed algorithm achieves 174 new best solutions out of the 498 instances considered. In only six instances out of 498, the algorithm is unable to reach or improve upon the best-known solution in the literature. These results suggest that the proposed meta-heuristic has significant potential in addressing real-world generalized vehicle routing challenges. Code available at: https://github.com/vlatorre847/HGSGVRP .},
  archive      = {J_SOCO},
  author       = {Latorre, Vittorio},
  doi          = {10.1007/s00500-025-10507-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1553-1566},
  shortjournal = {Soft Comput.},
  title        = {A hybrid genetic search based approach for the generalized vehicle routing problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient reconfigurable architecture to extract image
features for face recognition using local binary pattern. <em>SOCO</em>,
<em>29</em>(3), 1541–1552. (<a
href="https://doi.org/10.1007/s00500-025-10415-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of the face is a widely used method to detect human features. In various scenarios the face recognition speed becomes significant which necessitates to improve the critical delay of the architecture. In this paper, we propose Efficient FPGA architecture to extract image features using Local Binary pattern (LBP) for Face Recognition. The face image is converted into standard size (256 × 256) as pre-processing and the Gaussian filter is used to remove the high frequency components. These image is then applied to optimized LBP block to obtain the LBP features for both database sample and test sample are further compared to make the decision for face recognition. The proposed LBP architecture is designed using simple counter and comparators which leads to minimum complexity in turn improving the critical delay and hardware utilizations of the entire system. The simulation is performed for Olivetti Research Laboratory (ORL) dataset using MATLAB by showing False Acceptance Rate (FAR), False Rejection Rate (FRR) and Total Success Rate (TSR) values. The thresholding is performed based on Weighted Mean Square Difference and is varied for Total Success Rate (TSR) calculations tested for different combinations of Person in Database (PID) and Person Out of database (POD). Finally, the proposed architecture is synthesized on Spartan 6-xc651 × 4c-3csg432 Digilent FPGA board. It is observed that the recognition time of our architecture in hardware (FPGA) is 1.05 µS which is better compared to existing methods.},
  archive      = {J_SOCO},
  author       = {Bhavikatti, Sumangala and Bhairannawar, Satish},
  doi          = {10.1007/s00500-025-10415-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1541-1552},
  shortjournal = {Soft Comput.},
  title        = {Efficient reconfigurable architecture to extract image features for face recognition using local binary pattern},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition matheuristics for last mile delivery using
public transportation systems. <em>SOCO</em>, <em>29</em>(3), 1511–1539.
(<a href="https://doi.org/10.1007/s00500-025-10513-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the potential of using public transportation systems for freight delivery, where we intend to utilize the spare capacities of public vehicles like buses, trams, metros, and trains, particularly during off-peak hours, to transport packages within the city instead of using dedicated delivery vehicles. The study contributes to the growing literature on innovative strategies for performing sustainable last mile deliveries. We study an operational level problem called the Three-Tier Delivery Problem on Public Transportation, where packages are first transported from the Consolidation and Distribution Center (CDC) to nearby public vehicle stations by delivery trucks, comprising the first tier of the problem. In the second tier, the public vehicles pick them up from the stops and transport them into the city area. The last leg, or the third tier of the delivery, is performed to deliver the packages to their respective customers using green vehicles or eco-friendly systems. We propose mixed-integer linear programming formulations to study the transport of packages from the CDC to the customers and employ decomposition-based matheuristics to solve them. We have three decomposition approaches based on the order of solving the tiers, resulting from the tier we start solving the problem from. We use a heuristic methodology to link the tiers by coordinating the flow of packages between them, and utilize CPLEX to solve the individual tiers. We provide numerical experiments to demonstrate the efficiency and effectiveness of the system. Our results show that this system has the potential to reduce the length of trips performed by traditional delivery trucks by 85.91%, thereby reducing the negative social and environmental impacts of existing last mile delivery systems.},
  archive      = {J_SOCO},
  author       = {Mandal, Minakshi Punam and Archetti, Claudia},
  doi          = {10.1007/s00500-025-10513-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1511-1539},
  shortjournal = {Soft Comput.},
  title        = {Decomposition matheuristics for last mile delivery using public transportation systems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure quantum homomorphic encryption ciphertext retrieval
scheme. <em>SOCO</em>, <em>29</em>(3), 1497–1509. (<a
href="https://doi.org/10.1007/s00500-025-10454-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent paper (Gong et al. Quantum Inf Process 19:3, 2020), a novel ciphertext retrieval scheme based on the Grover algorithm and quantum homomorphic encryption was presented. In this scheme, when the server performs the operation of marking the solution on the user’s encrypted state in the Grover iteration, it needs to remove many gate-errors generated in the homomorphic evaluation of the T gate. And the server could judge this specific solution from the quantum circuit of marking the solution. It makes this scheme unable to achieve the low-cost and secure ciphertext retrieval. Therefore, we improve the Gong et al.’s scheme and propose a secure quantum homomorphic encryption ciphertext retrieval scheme. In our scheme, the trusted third party is introduced to cooperate with the server to execute the Grover algorithm. In each Grover iteration, the trusted third party can quickly mark the solution on the plaintext state, encrypt the marked state, and transmit it to the server. Then the server performs the remaining operations of this Grover iteration on the encrypted state. The trusted third party finally decrypts the iterated state. This cooperative approach ensures that the number of auxiliary qubits required and extra quantum gates executed in our scheme are lower than the Gong et al.’s scheme. By analyzing the security of our scheme, we confirm that the server and the trusted third party will not be informed of this solution. Thus, our scheme realizes the secure ciphertext retrieval with low computational overhead. We utilize IBM’s Qiskit framework to simulate our scheme, and the experimental result shows that our scheme is correct. It is worth noting that the low-cost and secure ciphertext retrieval will play a crucial role in modern information security and privacy protection.},
  archive      = {J_SOCO},
  author       = {Cheng, Zhen-Wen and Chen, Xiu-Bo and Xu, Gang and Chang, Yan and Miao, Li-Hua and Yang, Yi-Xian and Wang, Ya-Lan},
  doi          = {10.1007/s00500-025-10454-w},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1497-1509},
  shortjournal = {Soft Comput.},
  title        = {A secure quantum homomorphic encryption ciphertext retrieval scheme},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing signature scheme: The enhanced edward
elgamal extreme performance accumulate signature approach for IoT and
blockchain applications. <em>SOCO</em>, <em>29</em>(3), 1473–1496. (<a
href="https://doi.org/10.1007/s00500-025-10426-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital signatures, essential for establishing trust in the digital realm, have evolved in their application and importance alongside emerging technologies such as the Internet of Things (IoT), Blockchain, and cryptocurrency. These advancements necessitate improvements in performance, security, and efficiency. This article examines and compares the Elliptic Curve Digital Signature Algorithm with the Hyper Elliptic Curve Digital Signature Algorithm and the Edwards Curve Digital Signature Algorithm. We highlight its superior capabilities for blockchain and IoT applications and advocate for its potential to deliver immediate enhancements in security and performance. Our study introduces a novel digital signature scheme specifically designed to enhance non-repudiation in blockchain ecosystems. Utilizing the Optimized Extreme Performance Edwards Curve Accumulated Signature scheme, our approach significantly reduces signing and verification times by 10% and 13%, respectively, compared to traditional signatures. Additionally, it offers a 10% boost in transaction throughput and block validation efficiency. Experiments conducted within various blockchain-integrated IoT setups demonstrate the scheme&#39;s effectiveness, consistently achieving improvements across diverse IoT sensor data. This highlights the innovative contribution of our scheme to the efficiency and security of blockchain technology.},
  archive      = {J_SOCO},
  author       = {Anusha, R. and Saravanan, R.},
  doi          = {10.1007/s00500-025-10426-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1473-1496},
  shortjournal = {Soft Comput.},
  title        = {Revolutionizing signature scheme: The enhanced edward elgamal extreme performance accumulate signature approach for IoT and blockchain applications},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank decomposition optimization and its application in
fabric defects. <em>SOCO</em>, <em>29</em>(3), 1453–1472. (<a
href="https://doi.org/10.1007/s00500-025-10399-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-rank decomposition model is frequently employed in defect detection. It separates the target matrix into a low-rank component and a sparse component using the nuclear norm and the $$l_1$$ -norm, which aids in extracting the background and defects. However, the nuclear norm, derived from singular value decomposition, often fails to effectively extract the background of fabrics. This paper introduces a novel matrix norm, defined by integrating several key elementary functions, enhancing the separation of the low-rank and sparse matrices. The Alternating Direction Method of Multipliers (ADMM) typically solves the low-rank decomposition model with a fixed step size penalty factor. This study dynamically adjusts the penalty factor based on defect detection characteristics, thus enhancing the algorithm’s computational efficiency. Additionally, the convergence of the proposed algorithm is validated. Experimental results demonstrate that this new model not only precisely distinguishes the sparse matrix but also achieves higher computational efficiency, surpassing other existing methods in both accuracy and efficiency.},
  archive      = {J_SOCO},
  author       = {Chen, Zhixiang and Shi, Wenya and Liang, Jiuzhen and Liu, Hao},
  doi          = {10.1007/s00500-025-10399-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1453-1472},
  shortjournal = {Soft Comput.},
  title        = {Low-rank decomposition optimization and its application in fabric defects},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient COVID-19 detection using data mining algorithms: A
comparison of basic and hybrid approaches. <em>SOCO</em>,
<em>29</em>(3), 1437–1451. (<a
href="https://doi.org/10.1007/s00500-025-10538-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient diagnosis of COVID-19 remains a significant challenge due to the limitations of current detection methods, such as blood tests and chest scans, which can be time-consuming and error-prone. This study aims to compare the performance of basic and hybrid data mining algorithms in diagnosing COVID-19, using blood test results and clinical information to identify the most effective approach. A dataset of 200 records from suspected and infected COVID-19 patients, with 23 characteristics and one diagnostic class, was analysed. Nine data mining algorithms were tested: four basic algorithms (Naive Bayes, Support Vector Machine, Decision Tree, K-Nearest Neighbor) and five hybrid algorithms (Random Forest, AdaBoost, Majority Voting, XGBoost, Bagging). The study also integrated Response Surface Methodology (RSM) and Adaptive-Network-based Fuzzy Inference System (ANFIS) to enhance model performance. The Bagging algorithm demonstrated superior performance with an accuracy of 88%, sensitivity of 74%, and F-criterion of 78%. The integration of RSM and ANFIS further showed that a smart model could be developed for efficient pandemic crisis management, achieving up to 100% accuracy when considering key factors like AST, Albumin, and CRP. The findings suggest that Bagging and hybrid data mining algorithms can significantly improve COVID-19 detection, reducing time and errors in identifying exposed individuals. The study highlights the potential of combining machine learning techniques with RSM-ANFIS models for effective pandemic management and decision-making in medical settings.},
  archive      = {J_SOCO},
  author       = {Saidi, Mohammad and Gheibi, Mohammad and Ghazikhani, Adel and Lotfata, Aynaz and Chahkandi, Benyamin and Familsamavati, Sajad and Behzadian, Kourosh},
  doi          = {10.1007/s00500-025-10538-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1437-1451},
  shortjournal = {Soft Comput.},
  title        = {Efficient COVID-19 detection using data mining algorithms: A comparison of basic and hybrid approaches},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging variant of CAE with sparse convolutional
embedding and two-stage application-driven data augmentation for image
clustering. <em>SOCO</em>, <em>29</em>(3), 1419–1435. (<a
href="https://doi.org/10.1007/s00500-025-10500-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep clustering approaches often struggle with redundant feature learning, which limits their effectiveness. The primary goal of this study is to address these issues by developing a more robust deep clustering method. To achieve this, we propose a variant of the convolutional autoencoder (CAE) called SCDAC, which incorporates sparse convolutional embedding and a two-stage application-driven data augmentation approach. The proposed model operates in two main stages: pretraining and finetuning. In the pretraining stage, we employ application-driven data augmentation to train the CAE variant, focusing on learning robust features and constructing a foundational feature space using sparse convolutional embedding. During the finetuning stage, the model performs joint feature learning and cluster assignment. The feature learning task utilizes an augmented framework to control the input of both original and augmented data, preserving the local structure of images in the feature space. For cluster assignment, the framework controls the input of original data and uses the sparse convolutional embedding layer to obtain low-dimensional representations for soft cluster assignment. Experimental evaluations on six publicly available datasets demonstrate the effectiveness of the proposed model, with significant improvements in accuracy, particularly increases of $$3\%$$ and $$10.3\%$$ on the COIL20 and ORL datasets, respectively. In conclusion, our findings underscore the significance of the SCDAC approach in enhancing deep image clustering performance, offering a viable solution to the limitations of existing methods.},
  archive      = {J_SOCO},
  author       = {Liu, Yanming and Liu, Jinglei},
  doi          = {10.1007/s00500-025-10500-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1419-1435},
  shortjournal = {Soft Comput.},
  title        = {Leveraging variant of CAE with sparse convolutional embedding and two-stage application-driven data augmentation for image clustering},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chatgpt and operations research: Evaluation on the shortest
path problem. <em>SOCO</em>, <em>29</em>(3), 1407–1418. (<a
href="https://doi.org/10.1007/s00500-025-10505-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ChatGPT tool, the large language model developed by OpenAI, is having a great impact among users, experts and scholars for its capabilities of answering questions and retrieving solutions automatically. Despite the short time since its release, it has already been employed in several application domains. However, to the best of our knowledge, it has not been studied in the field of operation research (OR). In this paper, we use ChatGPT to define solution strategies for addressing several variants of the shortest path problem. The results obtained by executing the solution approaches returned by the tool are compared, in terms of correctness and efficiency, to reference codes. They indicate that the proper utilization of this tool could represent a good aid for domain experts. In particular, the outputs provided by ChatGPT could represent not only a good base for more complex implementations, but also they represent a way to facilitate some tasks in order to reduce times to do certain activities, which in any case must involve human control, adaptation and supervision.},
  archive      = {J_SOCO},
  author       = {Luzzi, Martina and Guerriero, Francesca and Maratea, Marco and Greco, Gianluigi and Garofalo, Marco},
  doi          = {10.1007/s00500-025-10505-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1407-1418},
  shortjournal = {Soft Comput.},
  title        = {Chatgpt and operations research: Evaluation on the shortest path problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using past sample means in exponential ratio and regression
type estimators under a simple random sampling. <em>SOCO</em>,
<em>29</em>(3), 1389–1406. (<a
href="https://doi.org/10.1007/s00500-025-10408-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical sampling commonly employs auxiliary variables for the selection and estimation phases to improve efficiency of the estimators. However, existing estimators like ratio and product types display limitations under specific conditions. Regression-type estimators, known for their unbiasedness and efficiency, rely solely on current sample information. This highlights the need for more effective estimators capable of leveraging both past and current sample means to improve accuracy and applicability across diverse datasets. In this study, we introduce two novel memory-type estimators, drawing inspiration from Noor-ul-Amin&#39;s (2020) approach, which integrates past and current sample information using Hybrid Exponentially Weighted Moving Averages (HEWMA), particularly effective for time-based surveys. Through simulation studies and real data examples, we evaluate the performance of our estimators and identify crucial shortcomings in previous memory-type estimator studies. Furthermore, we highlight significant deficits in previous studies, particularly concerning the impact of sample sizes based on past means, correlation, number of past means, weight parameters and initial values of EWMA and HEWMA algorithms, and the distribution shape of the data on estimator efficiency. Our findings underscore the importance of parameter selection in HEWMA, a greater number of past means, and the significance of past sample sizes for optimizing the performance of the proposed memory-type estimators. By integrating HEWMA, our approach enhances the efficiency and applicability of these estimators, addressing essential gaps in the existing literature and laying the groundwork for more robust and efficient estimation techniques for future studies that use mean.},
  archive      = {J_SOCO},
  author       = {Koçyiğit, Eda Gizem},
  doi          = {10.1007/s00500-025-10408-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1389-1406},
  shortjournal = {Soft Comput.},
  title        = {Using past sample means in exponential ratio and regression type estimators under a simple random sampling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable selection of multiple types of data: A PLS
approach. <em>SOCO</em>, <em>29</em>(3), 1369–1387. (<a
href="https://doi.org/10.1007/s00500-025-10531-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of data collection techniques in recent years, multiple types of data have emerged, including scalar data, functional data (curve-like), and compositional data (pie-like). While existing studies propose predictive models for multiple-type of data, few address the issue of variable selection. The challenge lies in the fact that different data types originate from different vector spaces, making it difficult to conduct variable selection at the variable level instead of selection at their sub-component level. This study leverages the group selection ability of gPLS (group Partial Least Squares) and gsPLS (group sparse Partial Least Squares) by regarding the functional and compositional variables as natural groups and proposes two variable selection approaches, named MD-gPLS and MD-gsPLS, after building a vector space for multiple types of data. Numerical studies and real-world examples verify the effectiveness of the proposed approaches. This study broadens the statistical modeling tools of multiple types of data analysis in terms of variable selection and also contributes to the literature by introducing the vector space of multiple types of data.},
  archive      = {J_SOCO},
  author       = {Kong, Boao and Wang, Huiwen and Lu, Shan},
  doi          = {10.1007/s00500-025-10531-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1369-1387},
  shortjournal = {Soft Comput.},
  title        = {Variable selection of multiple types of data: A PLS approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictor–corrector approach for the numerical solution of
fuzzy fractional differential equations and linear multiterm fuzzy
fractional equations. <em>SOCO</em>, <em>29</em>(3), 1347–1368. (<a
href="https://doi.org/10.1007/s00500-025-10401-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the modeling of fuzzy fractional differential equations (FFDEs) has been a very significant issue in many new applications in applied sciences and engineering, while a natural tool for modeling such dynamical systems is to use fuzzy fractional differential equations. We establish the existence and uniqueness of solutions for fuzzy fractional differential equations under sufficient assumptions and contraction principles and study numerical solutions of FFDEs. Our study is based on Caputo’s generalized Hukuhara differentiability. By applying Schauder’s fixed point theorem and a hypothetical condition, we explore the existence of the solutions. In addition, we show the uniqueness of the system&#39;s solution by using the contraction mapping theorem. We analyze the predictor–corrector approach (PCA) for FFDEs and multiterm FFDEs. We utilize the PCA to find the approximate solutions to linear multiterm FFDEs under the Caputo fuzzy derivative. After that, we present numerical solutions to initial value problems for solving two families of fuzzy fractional problems: fuzzy fractional differential equations (FFDEs) and multiterm fuzzy fractional differential equations (MFFDEs) utilizing the PCA. The method used in this paper has several advantages; first, it is significant and yields stable results without diverging as well as its ability to solve other mathematical, physical, and engineering problems; second, it is higher accuracy, needs less effort to achieve the results and works to reduces the error between exact and approximate solutions, as depicted in the utilized figures and tables. Finally, the accuracy of our suggested approach is demonstrated by solving some specific examples and analyzing the figures and tables, along with several suggestions for future research directions.},
  archive      = {J_SOCO},
  author       = {Al-Sadi, Wadhah and Wei, Zhouchao and Moroz, Irene and Abu Arqub, Omar and Abdullah, Tariq Q. S.},
  doi          = {10.1007/s00500-025-10401-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1347-1368},
  shortjournal = {Soft Comput.},
  title        = {Predictor–corrector approach for the numerical solution of fuzzy fractional differential equations and linear multiterm fuzzy fractional equations},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new approach data processing: Density-based spatial
clustering of applications with noise (DBSCAN) clustering using
game-theory. <em>SOCO</em>, <em>29</em>(3), 1331–1346. (<a
href="https://doi.org/10.1007/s00500-025-10405-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the unpredictable growth of data in various fields, rapid clustering of big data is seriously needed in order to identify the hidden structure of data and discover the relationships between objects. Among clustering methods, density-based clustering methods have an acceptable processing speed for dealing with big data with high dimensions. However, some methods have fixed parameters that are certainly not optimized for all sections. In addition, the complexity of these clustering methods strongly depends on the number of objects. In this paper, a clustering method is presented in order to increase clustering performance and parameter sensitivity according to game-theory and using the concept of Nash equilibrium and dense games, the optimal parameter for clustering is selected and between noise and points clusters make a difference. This method includes (1) searching the grid with several spaces in which there is no cluster, (2) identifying the player through high density data points in order to determine the parameters and (3) combining the clusters to make the game and (4) merging the nearby clusters. The performance of the proposed method was evaluated in four big synthetic datasets, eight real datasets labeled and unlabeled. The obtained results indicate the superiority of the proposed method over SOM, K-means, DBSCAN, SCGPSC methods in terms of accuracy and purity in processing time.},
  archive      = {J_SOCO},
  author       = {Kazemi, Uranus and Soleimani, Seyfollah},
  doi          = {10.1007/s00500-025-10405-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1331-1346},
  shortjournal = {Soft Comput.},
  title        = {A new approach data processing: Density-based spatial clustering of applications with noise (DBSCAN) clustering using game-theory},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arithmetic optimization algorithm with cosine
transform-based two-dimensional composite chaotic mapping.
<em>SOCO</em>, <em>29</em>(3), 1289–1329. (<a
href="https://doi.org/10.1007/s00500-025-10412-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The arithmetic optimization algorithm (AOA) is a newly developed meta-heuristic algorithm that draws inspiration from the combination of arithmetic operations. Since many scholars have widely used traditional one-dimensional chaotic mapping at home and abroad in function optimization, the AOA based on cosine transform two-dimensional composite chaotic mapping is proposed. Firstly, seven two-dimensional chaotic mappings are proposed to be embedded into the MOA and MOP in AOA. Secondly, one-dimensional chaotic systems based on the cosine transform are put forward. Then the proposed chaotic system based on the cosine transform is combined with the two-dimensional chaotic mapping to form the cosine transformed two-dimensional composite chaotic mapping. Finally, six more cosine transformed two-dimensional composite chaotic mappings are embedded into the MOA and MOP of the AOA to balance the algorithm&#39;s global and local searching ability and improve the algorithm&#39;s performance. The superiority of the improved algorithm is verified by employing 12 benchmark test functions in CEC2022. Then it is compared with the Coati Optimization Algorithm (COA), Prairie Dog Optimization (PDO), Butterfly Optimization Algorithm (BOA), Reptile Search Algorithm (RSA), Bat Algorithm (BAT), and Rat Swarm Optimization (RSO) to verify its convergence. Finally, four engineering design problems (tension/compression spring problem, pressure vessel problem, cantilever beam design problem, and slotted bulkhead design problem) were optimized to validate the efficiency of the improved algorithm. The simulation experiments demonstrate that the improved AOA exhibits superior performance in addressing both function and engineering optimization problems. It showcases remarkable optimization capabilities and improves convergence accuracy.},
  archive      = {J_SOCO},
  author       = {Li, Yi-Xuan and Wang, Jie-Sheng and Zhang, Si-Wen and Zhang, Shi-Hui and Guan, Xin-Yi and Ma, Xin-Ru},
  doi          = {10.1007/s00500-025-10412-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1289-1329},
  shortjournal = {Soft Comput.},
  title        = {Arithmetic optimization algorithm with cosine transform-based two-dimensional composite chaotic mapping},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some new construction methods of similarity measure on
picture fuzzy sets. <em>SOCO</em>, <em>29</em>(3), 1273–1287. (<a
href="https://doi.org/10.1007/s00500-025-10536-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy sets address problems characterized by ambiguity, instability and inconsistent data. Similarity measures on picture fuzzy sets play an indispensable role in determining the relationships between two such sets. Consequently, the study of similarity measures for picture fuzzy sets has garnered significant attention from scholars, yielding fruitful results. Notably, the existing research on picture fuzzy set similarity has mainly focused on overcoming the limitations of certain existing similarity measures by proposing one or a few new ones, ignoring the construction methods for similarity measures. Therefore, this paper presents two novel construction methods for similarity measures on picture fuzzy sets. The first approach combines the differences among positive membership, neutral membership, negative membership, and refusal membership within picture fuzzy sets using a strictly monotonically decreasing function. Remarkably, this method not only integrates existing similarity measures but also generates novel ones, providing a unified framework for both. The second method employs a strictly decreasing binary function to aggregate the distance measures between two picture fuzzy sets. By varying the binary function and distance measures, we obtain a range of novel similarity measures. Additionally, we apply the newly developed similarity measures to pattern recognition and compare their performance against existing measures. Based on the identification results, it is evident that these novel similarity measures yield reasonable outcomes and exhibit a high degree of reliability.},
  archive      = {J_SOCO},
  author       = {Luo, Minxia and Gao, Jianlei and Li, Wenling},
  doi          = {10.1007/s00500-025-10536-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1273-1287},
  shortjournal = {Soft Comput.},
  title        = {Some new construction methods of similarity measure on picture fuzzy sets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
