<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SOCO_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="soco---62">SOCO - 62</h2>
<ul>
<li><details>
<summary>
(2025). Retraction note: IADF security: Insider attack detection
using fuzzy logic in wireless multimedia sensor networks. <em>SOCO</em>,
<em>29</em>(4), 2397. (<a
href="https://doi.org/10.1007/s00500-024-10397-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Janarthanan, Ashwinth and Kumar, Dhananjay and Antony, R. Remo and Parvathe, C. B. Divya},
  doi          = {10.1007/s00500-024-10397-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2397},
  shortjournal = {Soft Comput.},
  title        = {Retraction note: IADF security: insider attack detection using fuzzy logic in wireless multimedia sensor networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Enhancing performance of cell formation
problem using hybrid efficient swarm optimization. <em>SOCO</em>,
<em>29</em>(4), 2395. (<a
href="https://doi.org/10.1007/s00500-024-10393-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Nagaraj, G. and Arunachalam, Manimaran and Vinayagar, K. and Paramasamy, S.},
  doi          = {10.1007/s00500-024-10393-y},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2395},
  shortjournal = {Soft Comput.},
  title        = {Retraction note: Enhancing performance of cell formation problem using hybrid efficient swarm optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Retraction note: Classification of noiseless corneal image
using capsule networks. <em>SOCO</em>, <em>29</em>(4), 2393. (<a
href="https://doi.org/10.1007/s00500-024-10391-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Koresh, H. James Deva and Chacko, Shanty},
  doi          = {10.1007/s00500-024-10391-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2393},
  shortjournal = {Soft Comput.},
  title        = {Retraction note: Classification of noiseless corneal image using capsule networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RETRACTED ARTICLE: Near-infrared and visible light face
recognition: A comprehensive survey. <em>SOCO</em>, <em>29</em>(4),
2391. (<a href="https://doi.org/10.1007/s00500-023-08366-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SOCO},
  author       = {Huang, Fangzheng and Tang, Xikai and Li, Chao and Ban, Dayan},
  doi          = {10.1007/s00500-023-08366-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2391},
  shortjournal = {Soft Comput.},
  title        = {RETRACTED ARTICLE: near-infrared and visible light face recognition: a comprehensive survey},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gender opposition recognition method fusing emojis and
multi-features in chinese speech. <em>SOCO</em>, <em>29</em>(4),
2379–2390. (<a
href="https://doi.org/10.1007/s00500-025-10492-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech with gender opposition on the internet have been causing antagonism, gamophobia, and pregnancy phobia among young groups. Recognizing gender opposition speech contributes to maintaining a healthy online environment and security in cyberspace. Traditional recognition model ignores the Chinese-owned features and emojis, which inevitably affects the recognition accuracy of gender opposition. To tackle this issue, a gender opposition recognition method fusing emojis and multi-features in Chinese speech(GOR-CS) is proposed. Firstly, the exBERT method is employed to expand the encoding of emojis into the BERT vocabulary, which can ensure BERT to extract the basis vectors containing characters and emojis information. Then, the feature vectors containing Wubi, Zhengma, and Pinyin information are extracted by Word2Vec to obtain the Chinese-owned features of gender opposition text. Further, the proposed basis vector and feature vectors are fused and then fed into the Bi-GRU network to extract deeper semantics from input sentences. Finally, to determine whether the speech are related to gender opposition, the sentiment polarities are calculated with the fully connected layer and SoftMax function. Experimental results show that the proposed method can effectively improve the accuracy of gender opposition recognition.},
  archive      = {J_SOCO},
  author       = {Zhang, Shunxiang and Ma, Zichen and Li, Hanchen and Liu, Yunduo and Chen, Lei and Li, Kuan-Ching},
  doi          = {10.1007/s00500-025-10492-4},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2379-2390},
  shortjournal = {Soft Comput.},
  title        = {Gender opposition recognition method fusing emojis and multi-features in chinese speech},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight CNN model for UAV-based image classification.
<em>SOCO</em>, <em>29</em>(4), 2363–2378. (<a
href="https://doi.org/10.1007/s00500-025-10512-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many unmanned aerial vehicle (UAV)-based applications, especially those that need to operate with resource-limited edge networked devices in real-time, it is crucial to have a lightweight computing model for data processing and analysis. In this study, we focus on UAV-based forest fire imagery detection using a lightweight convolution neural network (CNN). The task is challenging owing to complex image backgrounds and insufficient training samples. Specifically, we enhance the MobileNetV2 model with an attention mechanism for UAV-based image classification. The proposed model first employs a transfer learning strategy that leverages the pre-trained weights from ImageNet to expedite learning. Then, the model incorporates randomly initialised weights and dropout mechanisms to mitigate over-fitting during training. In addition, an ensemble framework with a majority voting scheme is adopted to improve the classification performance. A case study on forest fire scenes classification with benchmark and real-world images is demonstrated. The results on a publicly available UAV-based image data set reveal the competitiveness of our proposed model as compared with those from existing methods. In addition, based on a set of self-collected images with complex backgrounds, the proposed model illustrates its generalisation capability to undertake forest fire classification tasks with aerial images.},
  archive      = {J_SOCO},
  author       = {Deng, Xinjie and Shi, Michael and Khan, Burhan and Choo, Yit Hong and Ghaffar, Fazal and Lim, Chee Peng},
  doi          = {10.1007/s00500-025-10512-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2363-2378},
  shortjournal = {Soft Comput.},
  title        = {A lightweight CNN model for UAV-based image classification},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based model for automated STN localization
using local field potentials in parkinson’s disease. <em>SOCO</em>,
<em>29</em>(4), 2343–2362. (<a
href="https://doi.org/10.1007/s00500-025-10497-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate identification of the subthalamic nucleus (STN) borders is time-consuming, relying heavily on the neurosurgeon expertise in manually interpreting the electrophysiological signals. Local field potentials (LFPs) have garnered imperative attention due to their strong correlation with the STN. However, existing detection models often face challenges with high computational complexity, hyperparameter optimization and lack of explainability, making them unreliable for clinicians. Therefore, this study introduces an explanatory framework using convolutional neural networks (CNN) for detecting the STN region from LFPs. Continuous wavelet transform is employed to convert LFPs signals into scalogram images, which are then processed by sixteen CNN models. We evaluated our framework by examining the impact of various limiting factors on the classification performance, including model size, learning rate (LR), optimizers and data scaling. Deep features are extracted from the top-performing CNN architectures to capture rich representations of the scalograms. These features are then fused and classified using k-nearest neighbour algorithm. Gradient-weighted class activation mapping is used to explain the decisions made by the proposed model. Our approach achieved an accuracy of 99.61%, outperforming individual CNN models for STN localization. The experimental results revealed that CNN models, embedded with additional hyperparameters and layers, generally outperformed smaller models. Besides, low LR significantly enhanced the performance compared to high LR. Moreover, features extracted from untuned networks produced lower performance than tuned networks. The proposed system could revolutionize deep brain stimulation surgery by increasing efficiency and reducing reliance on clinician expertise for STN detection.},
  archive      = {J_SOCO},
  author       = {Hosny, Mohamed and Naeem, Mohamed A. and Zhu, Minwei and Gao, Wenpeng and Elshenhab, Ahmed M. and Fu, Yili},
  doi          = {10.1007/s00500-025-10497-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2343-2362},
  shortjournal = {Soft Comput.},
  title        = {A deep learning-based model for automated STN localization using local field potentials in parkinson’s disease},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced single shot detector for small object detection in
drone-capture scenarios. <em>SOCO</em>, <em>29</em>(4), 2331–2341. (<a
href="https://doi.org/10.1007/s00500-025-10539-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep learning have significantly improved object detection performance. However, detecting small objects in drone-captured imagery remains challenging due to their low resolution and noisy appearance. This paper presents the Enhanced Single Shot Detector (ESSD), designed for accurate small object detection. The ESSD incorporates a scale-confusion erasing module to reduce noise from larger objects, enhancing the detection of smaller ones. It also features a neighbor fusion module that integrates semantic information across layers. Our experiments on the VisDrone2019-DET benchmark dataset show that the ESSD achieves state-of-the-art performance in small object detection.},
  archive      = {J_SOCO},
  author       = {Shi, Yanxia and Liu, Yanrong and Liu, Yaru},
  doi          = {10.1007/s00500-025-10539-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2331-2341},
  shortjournal = {Soft Comput.},
  title        = {Enhanced single shot detector for small object detection in drone-capture scenarios},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure transmission of medical image using a wavelet
interval type-2 TSK fuzzy brain-imitated neural network. <em>SOCO</em>,
<em>29</em>(4), 2311–2329. (<a
href="https://doi.org/10.1007/s00500-025-10449-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this research is to develop a new design of a wavelet interval type-2 takagi–Sugeno-Kang fuzzy brain-imitated neural network (WIT2TFBINN), which is a combination of the mathematical models of a Takagi–Sugeno-Kang (TSK) fuzzy system based on wavelet interval type-2 function (WIT2) and a wavelet interval type-2 fuzzy brain imitated neural network (FBINN). The proposed WIT2TFBINN is used for synchronization control of a 4D Lorentz chaotic system and has the benefits of wavelet interval type-2 membership function, TSK fuzzy inference system, decision making, and emotional activity. To provide fast training, the proposed method&#39;s parameter update laws are derived using the gradient descent method. The proposed WIT2TFBINN synchronization technique is then applied to the transmission of medical images in a secure manner. As a cipher image, a medical image is encrypted into a chaotic trajectory. After transmission, the image can be decrypted using chaotic trajectory synchronization on the received signal. The simulation results show that the proposed neural network and the encryption/decryption method are powerful and effective. The results of the static test analysis (histogram, attack analysis, image with noise, image with cropping) show that the encryption/decryption method provides high security.},
  archive      = {J_SOCO},
  author       = {Pham, Duc-Hung and Huynh, Tuan-Tu and Lin, Chih-Min and Giap, Van Nam and Vu, Van-Phong},
  doi          = {10.1007/s00500-025-10449-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2311-2329},
  shortjournal = {Soft Comput.},
  title        = {Secure transmission of medical image using a wavelet interval type-2 TSK fuzzy brain-imitated neural network},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reliability analysis of discrete-time multi-state star
configuration power grid systems with performance sharing.
<em>SOCO</em>, <em>29</em>(4), 2297–2310. (<a
href="https://doi.org/10.1007/s00500-025-10478-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by practical engineering systems, this paper studies an assessment method for dynamic reliability of a discrete time multi-state star configuration power grid system with performance sharing. The proposed star configuration power grid system consists of n power generation subsystems fixed in star-terminal and one central collection and redistribution subsystem. The star-terminal subsystems with sufficient electric power can first transmit the surplus electric power to the central subsystem, and then the collected electric power in central subsystem is further redistributed to the star-terminal subsystems which are experiencing electric power deficiency through the corresponded transmission links. An algorithm based on the universal generating function (UGF) technique is presented to evaluate the dynamic reliability of the proposed power grid system with performance sharing. Finally, a numerical example and a case study are used to illustrate the accuracy of the proposed model and method. Studies indicate that the steady reliability of the proposed power grid system is improved by 9.41% and 37.28% for the numerical example when comparing the calculation results between performance sharing, unlimited performance sharing and no performance sharing. In the case study, the dynamic reliability of the proposed power grid system increased by 11.5% when comparing the calculation results between with performance sharing and no performance sharing when $$k\to \infty $$ .},
  archive      = {J_SOCO},
  author       = {Su, Peng and Zhang, Keyong and Shi, Honghua},
  doi          = {10.1007/s00500-025-10478-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2297-2310},
  shortjournal = {Soft Comput.},
  title        = {Reliability analysis of discrete-time multi-state star configuration power grid systems with performance sharing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deteriorating inventory model with advance-cash-credit
payment schemes and partial backlogging. <em>SOCO</em>, <em>29</em>(4),
2279–2295. (<a
href="https://doi.org/10.1007/s00500-025-10532-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In business transactions, suppliers often ask retailers for advance-cash-credit (ACC) payments, and retailers offer customers a cash-credit (CC) payment plan. An advance payment is generally requested to avoid order cancellation, while a credit payment serves as an efficient approach to stimulate sales. With supply chains being usually subject to inventory shortages in view of various uncertainties, this study explores an optimal inventory policy for perishable goods with partial backlogging considerations when suppliers adopt an ACC payment plan for retailers and retailers offer customers a CC payment plan. For this purpose, we establish a model based on two theorems and provide an easy-to-use method to derive the optimal ordering policy to maximize retailers’ total profits. This solution is illustrated using numerical examples. Finally, we conduct a sensitivity analysis to examine the influence of changes in the values of key parameters on the optimal solution.},
  archive      = {J_SOCO},
  author       = {Chang, Chun-Tao and Cheng, Mei-Chuan and Ouyang, Liang-Yuh},
  doi          = {10.1007/s00500-025-10532-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2279-2295},
  shortjournal = {Soft Comput.},
  title        = {Deteriorating inventory model with advance-cash-credit payment schemes and partial backlogging},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging feature fusion ensemble of VGG16 and ResNet-50
for automated potato leaf abnormality detection in precision
agriculture. <em>SOCO</em>, <em>29</em>(4), 2263–2277. (<a
href="https://doi.org/10.1007/s00500-025-10523-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of advancement in technology and modern agriculture, early disease detection of potato leaves will improve crop yield. Various researchers have focussed on disease due to different types of microbial infection in potato leaves using computer vision and machine learning approaches. In this paper, a data science approach for multiclass classification of potato normal and abnormal leaves due to fungal infection like early blight and late blight is performed using the ensembling of deep learning (DL) CNN models. Firstly, the performance of classification on potato disease is verified separately on VGG16 and ResNet-50 CNN models after pre-processing of the leaf dataset. The pre-processing includes noise removal and normalization. Further improvement in classification accuracy is achieved by the ensembling of VGG16 and ResNet-50 CNN models. The ensembling of CNN models is performed on the feature level by fusing features extracted using VGG16 and ResNet-50. From the experimental results, performed on publicly available datasets consisting of 2152 number of normal and abnormal images it is observed that the average classification accuracy of 98.22%, 96.16% and 95.68% is achieved using the proposed ensemble, VGG16 and ResNet-50 models respectively. The efficacy of the proposed approach (ensemble technique at feature level fusion) is verified in comparison with recently reported DL model-based approaches.},
  archive      = {J_SOCO},
  author       = {Trivedi, Amit Kumar and Mahajan, Tripti and Maheshwari, Tanmay and Mehta, Rajesh and Tiwari, Shailendra},
  doi          = {10.1007/s00500-025-10523-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2263-2277},
  shortjournal = {Soft Comput.},
  title        = {Leveraging feature fusion ensemble of VGG16 and ResNet-50 for automated potato leaf abnormality detection in precision agriculture},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adopting fuzzy multi-criteria decision-making ranking
approach ensuring connected topology in industrial wireless sensor
networks. <em>SOCO</em>, <em>29</em>(4), 2247–2261. (<a
href="https://doi.org/10.1007/s00500-025-10448-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks (WSNs), topology control aims to optimize the network structure to improve its performance and is a significant issue especially in mesh connected networks. As Industrial Wireless sensor networks (IWSNs) adopt a mesh-based strategy for communication, a connected topology and its maintenance is necessary. Therefore, identifying candidate nodes and reconfiguration under congestion and failure for reliable connection becomes important. A rank-based mechanism appears a viable solution to identify next best candidates to establish the connections among the nodes in the event of network disruption. As a solution, we propose adoption of MCDM (Multi-Criteria Decision-Making) based approach to compute the ranks among the sensor nodes when subject to varied constraints. Our paper compares and analyses the ranking of a node by using two methods, Analytical hierarchy Process (AHP) Weighted TOPSIS (Technique for Order Performance by Similarity to Ideal Solution) and FUZZY TOPSIS. A novel application of the rank-based strategy to determine the connection between the nodes for achieving a network with lower energy consumption and better connectivity for IWSNs is presented. On comparison with standard topology control algorithms, like connected dominating set (CDS) and articulation point strategy our results confirm that the topology formed through our ranking method achieves lower energy consumption in communication and better connectivity probability among the nodes. Further, we also observe performance of the network when subject to obstacles in the line-of-sight communication typical of IWSNs and our approach performs better in this case too.},
  archive      = {J_SOCO},
  author       = {Nandan, Anvita and Snigdh, Itu},
  doi          = {10.1007/s00500-025-10448-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2247-2261},
  shortjournal = {Soft Comput.},
  title        = {Adopting fuzzy multi-criteria decision-making ranking approach ensuring connected topology in industrial wireless sensor networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New vigenere method with pseudo-random affine functions for
color image encryption. <em>SOCO</em>, <em>29</em>(4), 2229–2245. (<a
href="https://doi.org/10.1007/s00500-025-10477-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this document, we propose an enhanced technique for encrypting color images, building upon a substantial refinement of the traditional Vigenere method, guaranteed by two strong pseudo-random replacement tables built from the utilization of dynamic linear functions and the most frequently utilized chaotic maps in cryptography domain. After original image vectorization and initialization value calculation, which serve to modify the initial pixel value, thereby triggering the ciphering procedure, our technique integrates a novel Vigenere circuit using dynamic pseudorandom functions to change pixel values. Finally, a positional shift of each pixel is applied to maximize the temporal complexity of our technology. Experiments carried out on a wide range of images spanning various formats and dimensions confirm the robustness of our method against established attack techniques.},
  archive      = {J_SOCO},
  author       = {El Bourakkadi, Hamid and Chemlal, Abdelhakim and Tabti, Hassan and Kattass, Mourad and Jarjar, Abdellatif and Benazzi, Abdelhamid},
  doi          = {10.1007/s00500-025-10477-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2229-2245},
  shortjournal = {Soft Comput.},
  title        = {New vigenere method with pseudo-random affine functions for color image encryption},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced TODIM-TOPSIS framework for design quality
evaluation for college smart sports venues under hesitant fuzzy sets.
<em>SOCO</em>, <em>29</em>(4), 2215–2227. (<a
href="https://doi.org/10.1007/s00500-025-10414-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the gradual development and application of modern intelligent technology in our country, it has become a key factor influencing the nation&#39;s overall competitive strength. The state has explicitly proposed the establishment of efficient and high-quality engineering projects in the current sports industry. By applying innovative technologies, smart sports venues will be created to support the future development of the nation and the sports sector, thereby comprehensively enhancing the country&#39;s overall competitive strength. Among these, university gyms, as important venues for modern school physical education, must keep pace with the nation&#39;s development. By establishing smart sports venues and utilizing Internet of Things (IoT) technology, cloud computing technology, and artificial intelligence technology, the comprehensive operation of sports venues can be promoted, leading to the stable development of the school sports industry. The design quality evaluation for college smart sports venues is a multiple-attribute decision-making (MADM) problem. Recently, the TODIM and TOPSIS methods have been demonstrated to address MAGDM issues. Hesitant fuzzy sets (HFSs) have been introduced as a means to characterize uncertain data during the design quality evaluation for college smart sports venues. In this study, the hesitant fuzzy TODIM-TOPSIS (HF-TODIM-TOPSIS) approach is proposed to solve MADM problems under HFSs. Finally, a numerical study for the design quality evaluation of college smart sports venues is presented to validate the proposed approach. The major contributions of this study are as follows: (1) The TODIM and TOPSIS methods are extended to HFSs; (2) Entropy is used to determine the weight values under HFSs; (3) The HF-TODIM-TOPSIS approach is established to handle MADM problems under HFSs; (4) Algorithm analysis and comparison for the design quality evaluation of college smart sports venues are conducted based on a numerical example to verify the feasibility and effectiveness of the HF-TODIM-TOPSIS approach.},
  archive      = {J_SOCO},
  author       = {Yang, Feng and Wu, Yuefang and Li, Yi},
  doi          = {10.1007/s00500-025-10414-4},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2215-2227},
  shortjournal = {Soft Comput.},
  title        = {Enhanced TODIM-TOPSIS framework for design quality evaluation for college smart sports venues under hesitant fuzzy sets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling and analysis of data corruption attacks and energy
consumption effects on edge servers using concurrent stochastic games.
<em>SOCO</em>, <em>29</em>(4), 2189–2214. (<a
href="https://doi.org/10.1007/s00500-025-10467-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intricate nature of modern edge architectures, relying on a vast array of computational logic and lightweight communication protocols, creates vulnerabilities that expose them to a broad spectrum of security threats. Moreover, security vulnerabilities can significantly impact the energy footprint of edge servers in these architectures. Our approach utilizes the concurrent stochastic game (CSG) formalism to model the behavior of IoT communication entities (players) while accounting for potential attacks at the communication edge and the resulting energy consumption caused by such attacks. We rely on the PRISM-games language for automated analysis where the game goals modeling functional and security requirements are expressed using reward probabilistic alternating temporal logic (rPATL). To validate our approach, we examine a data corruption attack applied to dam water flow control and study its side effect on energy consumption associated with SensiNact gateways. Our key innovation lies in using formal models at the architectural level to explore potential attacks. These models capture synchronous and asynchronous communication styles, along with their associated energy consumption. The methodology and the implemented formalism offer a significant advancement over traditional game equation models while still achieving the desired security and energy evaluation. Numerical results show that compared to synchronous communication, asynchronous styles suffer from significantly larger infected buffers and higher energy consumption due to attacks ranging from 66 to 91%.},
  archive      = {J_SOCO},
  author       = {Baouya, Abdelhakim and Hamid, Brahim and Gürgen, Levent and Bensalem, Saddek},
  doi          = {10.1007/s00500-025-10467-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2189-2214},
  shortjournal = {Soft Comput.},
  title        = {Modeling and analysis of data corruption attacks and energy consumption effects on edge servers using concurrent stochastic games},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel attention based deep learning model for software
defect prediction with bidirectional word embedding system.
<em>SOCO</em>, <em>29</em>(4), 2171–2188. (<a
href="https://doi.org/10.1007/s00500-025-10475-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction (SDP) is considered a dynamic research problem and is beneficial during the testing stage of the software development life cycle. Several artificial intelligence-based methods were available to predict these software defects. However, the detection accuracy is still low due to imbalanced datasets, poor feature learning, and tuning of the model&#39;s parameters. This paper proposes a novel attention-included Deep Learning (DL) model for SDP with effective feature learning and dimensionality reduction mechanisms. The system mainly comprises ‘6’ phases: dataset balancing, source code parsing, word embedding, feature extraction, dimensionality reduction, and classification. First, dataset balancing was performed using the density peak based k-means clustering (DPKMC) algorithm, which prevents the model from having biased outcomes. Then, the system parses the source code into abstract syntax trees (ASTs) that capture the structure and relationship between different elements of the code to enable type checking and the representative nodes on ASTs are selected to form token vectors. Then, we use bidirectional encoder representations from transformers (BERT), which converts the token vectors into numerical vectors and extracts semantic features from the data. We then input the embedded vectors to multi-head attention incorporated bidirectional gated recurrent unit (MHBGRU) for contextual feature learning. After that, the dimensionality reduction is performed using kernel principal component analysis (KPCA), which transforms the higher dimensional data into lower dimensions and removes irrelevant features. Finally, the system used a deep, fully connected network-based SoftMax layer for defect prediction, in which the cross-entropy loss is utilized to minimize the prediction loss. The experiments on the National Aeronautics and Space Administration (NASA) and AEEEM show that the system achieves better outcomes than the existing state-of-the-art models for SDP.},
  archive      = {J_SOCO},
  author       = {Devi, M. Chitra and Rajkumar, T. Dhiliphan},
  doi          = {10.1007/s00500-025-10475-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2171-2188},
  shortjournal = {Soft Comput.},
  title        = {A novel attention based deep learning model for software defect prediction with bidirectional word embedding system},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Review of quantum algorithms for medicine, finance and
logistics. <em>SOCO</em>, <em>29</em>(4), 2129–2170. (<a
href="https://doi.org/10.1007/s00500-025-10540-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum computing represents an emerging technology, that leverages the fundamental principles of quantum mechanics to solve highly complex problems that are beyond the capabilities of classical computers. Due to the unique characteristics of quantum computers, optimisation algorithms can be significantly improved, offering performance that surpasses classical methods, especially for computationally intractable problems. This study aims to provide a comprehensive overview of recent scientific research focused on the development of effective quantum algorithms in specific application contexts, with particular emphasis on the healthcare, finance, production planning and logistics sectors. Additionally, we present a comprehensive classification of methodologies and approaches employed in the design and implementation of quantum algorithms.},
  archive      = {J_SOCO},
  author       = {Ciacco, Alessia and Guerriero, Francesca and Macrina, Giusy},
  doi          = {10.1007/s00500-025-10540-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2129-2170},
  shortjournal = {Soft Comput.},
  title        = {Review of quantum algorithms for medicine, finance and logistics},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-ant colony algorithm based on the stackelberg game and
incremental learning. <em>SOCO</em>, <em>29</em>(4), 2107–2128. (<a
href="https://doi.org/10.1007/s00500-025-10469-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the difficulties of slow convergence and inadequate accuracy of traditional ant colony algorithms in solving the traveling salesman problem (TSP), we propose a multi-ant colony algorithm based on the Stackelberg game and incremental learning (SGIACO). We incorporate the Stackelberg game strategy across multiple colonies, where the leader guides the follower to optimize population co-evolution, ensuring a balance between convergence and diversity of the algorithm. Furthermore, we propose an incremental learning strategy that enhances efficient paths on the public routes and ignores inefficient ones, thus accelerating the convergence speed of the algorithm. Finally, when the algorithm stagnates, a pheromone balance mechanism is implemented to help the ants escape from local optima. We conducted experiments on 23 TSP instances to validate the algorithm&#39;s performance and compare it to ACS, MMAS, as well as other recent algorithms. In addition, non-parametric tests were conducted for comprehensive performance analysis. Moreover, we verified the feasibility of SGIACO through simulations in robot path planning scenarios. The experimental results show that SGIACO has good convergence and accuracy, which is competitive with other algorithms. Future research aims to scale SGIACO for larger real-world applications, enhancing its adaptability and scalability.},
  archive      = {J_SOCO},
  author       = {Wu, Qihuan and You, Xiaoming and Liu, Sheng},
  doi          = {10.1007/s00500-025-10469-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2107-2128},
  shortjournal = {Soft Comput.},
  title        = {Multi-ant colony algorithm based on the stackelberg game and incremental learning},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A two-population artificial tree algorithm based on adaptive
updating strategy for dominant populations. <em>SOCO</em>,
<em>29</em>(4), 2075–2106. (<a
href="https://doi.org/10.1007/s00500-025-10445-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An artificial tree (AT) algorithm has been proposed recently, and the performance of AT has been enhanced because of the introduction of improved AT algorithm with two-population (IATTP). However, the branch update operators of IATTP cannot effectively balance exploration and exploitation, which limits the optimization accuracy and efficiency of IATTP. To further improve the performance of IATTP, this work proposes a two-population artificial tree algorithm based on adaptive updating strategy for dominant populations (TATAD). In TATAD, six operators named self-evolution operator 2, crossover operator 2, improved self-evolution operator, gradient descent update operator, Gauss and Cauchy variational operator, and random traceless Sigma variational operator are applied to form an operator library. A dominant operator dynamic following mechanism is proposed to assign these six operators to the two populations in an optimal pairing scheme. Both populations and operators compete with each other, and the advantages of all operators are fully utilized. Moreover, the combination of diverse operators and dominant operator dynamic following mechanism can effectively balance the exploration and exploitation of TATAD. The performance of TATAD is compared with four AT algorithms and six efficient algorithms through typical test functions, and their results are bested by Wilcoxon rank sum test (WRST) and Friedman ranking test. It is found that TATAD is the most competitive algorithm among these algorithms for solving these optimization problems.},
  archive      = {J_SOCO},
  author       = {Xiao, Yaping and Niu, Linfeng and Li, Qiqi},
  doi          = {10.1007/s00500-025-10445-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2075-2106},
  shortjournal = {Soft Comput.},
  title        = {A two-population artificial tree algorithm based on adaptive updating strategy for dominant populations},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-objective multi-warehouse multi-period order picking
system under uncertainty: A benders decomposition approach.
<em>SOCO</em>, <em>29</em>(4), 2047–2074. (<a
href="https://doi.org/10.1007/s00500-025-10495-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In warehouse management order picking is one of the key operations that incur high costs as well as one of the most complex tasks. It comprises the construction of order batches, batch assignment, picker routes, and scheduling of pickers. Therefore, the development of an efficient order picking system and the optimization of these operations have significant effects on the overall efficiency of the warehouse. This paper focuses on studying and modeling the order batching, batch assignment, and picker routing problems in a multi-warehouse, multi-period, multi-picker order picking system. We propose a multi-objective mathematical model for minimizing the delivery times of batches and the total cost of order picking operations. Also, for the first time, a possibilistic approach is applied to overcome uncertain conditions in the order picking problem. Given the complexity of the problem, Benders decomposition is implemented to solve the proposed model. The applicability of the proposed method is evaluated through a range of small to large test problems and an actual case study. The results indicate that the proposed exact method is capable of finding high-quality solutions within a reasonable computational time and number of iterations, which serves as evidence of its suitability for large-scale, complex real-world industrial contexts.},
  archive      = {J_SOCO},
  author       = {Nikkhoo, Fatemeh and Husseinzadeh Kashan, Ali and Nikbakhsh, Ehsan and Ostadi, Bakhtiar},
  doi          = {10.1007/s00500-025-10495-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2047-2074},
  shortjournal = {Soft Comput.},
  title        = {A bi-objective multi-warehouse multi-period order picking system under uncertainty: A benders decomposition approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel instance density-based hybrid resampling for
imbalanced classification problems. <em>SOCO</em>, <em>29</em>(4),
2031–2045. (<a
href="https://doi.org/10.1007/s00500-025-10499-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class imbalance problem is one of the challenging issues in various machine learning applications. This problem occurs when the number of instances of a class is much smaller (or larger) than those of the other classes. To handle the imbalanced classification problems, many useful approaches have been developed, for example, synthetic minority oversampling technique (SMOTE). However, the SMOTE is often sensitive to the predetermined $$k$$ value, i.e., the number of nearest neighbors used to generate the synthetic instances. For example, if the $$k$$ value is moderately large, some of the synthetic instances generated by the SMOTE would be located near a decision boundary or even within the majority class area and thus these can be treated as unnecessary noisy instances. Thus, in this study, we propose an efficient hybrid resampling method based on instance density called IDHR (Instance Density-based Hybrid Resampling) to improve the classification performance by generating instances that are closer to the minority class than the majority class while avoiding generation of noisy instances. For this, we first apply the instance density-based oversampling (IDO) technique to generate new synthetic instances. And then, we eliminate some of the synthetic instances that are close to the decision boundary and determine the number of the synthetic instances among the retained synthetic ones which can be eliminated based on maximum of the distances from all the synthetic instances to the minority class instances and minimum of the distances from all the synthetic instances to the majority class instances as well as classification performances. To demonstrate the effectiveness of the proposed resampling method, comprehensive experiments are conducted on sixteen imbalanced datasets with considering three classifiers, i.e., C4.5 decision tree algorithm, support vector machine (SVM), and multi-layer perceptron neural network (MLP-NN). Through the experimental analysis, it is shown that the proposed resampling method outperforms the traditional oversampling methods with respect to AUC and F-measure for most of the imbalanced datasets regardless of classifiers.},
  archive      = {J_SOCO},
  author       = {Park, You-Jin and Ma, Chung-Kang},
  doi          = {10.1007/s00500-025-10499-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2031-2045},
  shortjournal = {Soft Comput.},
  title        = {A novel instance density-based hybrid resampling for imbalanced classification problems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cyber-attack detection based on a deep chaotic invasive weed
kernel optimized machine learning classifier in cloud computing.
<em>SOCO</em>, <em>29</em>(4), 2015–2030. (<a
href="https://doi.org/10.1007/s00500-025-10521-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, Cloud Computing has attracted a lot of interest from both individual users and organization. However, cloud computing applications face certain security issues, such as data integrity, user privacy, and service availability. The only better solution to such issues is to identify and prevent cyber threats before they can cause seriously harm the cloud computing system. Several methods have been suggested so far to detect the attack in cloud computing (CC), but no one method attains satisfactory results. To overwhelm these drawbacks, a Cyber Security Attack Detection using Deep Kernel Machine Learning optimized with Chaotic Invasive Weed Optimization algorithm is proposed in this paper for Cloud Computing. Here, the data is amassed from CSE-CIC-IDS2018 and Bot-IoT datasets. Subsequently, a pre-processing step involving redundancy reduction and missing value replacement for uncertainty removal is achieved through the Developed Random Forest with Local Least Squares (DRFLLS) method. By utilizing Entropy-Kurtosis based feature selection approach, the pre-processing data is given to the feature selection to identify the optimal features. The selected features are supplied to the Deep Kernel Machine Learning classifier (DK-ML), which is optimized using the Chaotic Invasive Weed Optimization algorithm (Chaotic-IWOA) for classification. This classification process classifies the data as normal or anomalous categories with anomalies encompassing, like DoS, DDoS, Theft attacks, and normal attacks. The proposed technique is activated in MATLAB. The proposed technique achieves 24.88%, 17.98%, 45.65%, 35.95% better accuracy for CSE-CIC-IDS2018 dataset, and 23.93%, 13.94%, 32.94%, and 29.04% better accuracy for Bot-IoT dataset.},
  archive      = {J_SOCO},
  author       = {Indrasena Reddy, M. and Siva Kumar, A. P. and Subba Reddy, K.},
  doi          = {10.1007/s00500-025-10521-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2015-2030},
  shortjournal = {Soft Comput.},
  title        = {Cyber-attack detection based on a deep chaotic invasive weed kernel optimized machine learning classifier in cloud computing},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring diversity and time-aware recommendations: An
LSTM-DNN model with novel bidirectional dynamic time warping algorithm.
<em>SOCO</em>, <em>29</em>(4), 2003–2013. (<a
href="https://doi.org/10.1007/s00500-025-10534-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the Web 3.0 era, the amount and types of data in the network have sharply increased, and the application scenarios of recommendation algorithms are continuously expanding. Location recommendation has gradually become one of the popular application scenarios in recommendation algorithms. Traditional recommendation algorithms not only ignore the temporal attribute of data when recommending information to users, but also blindly pursue the recommendation accuracy, which will cause certain “information cocoon room” problems. Therefore, this article treats user historical data as a time series and proposes an LSTM-DNN model based on the novel bidirectional Dynamic Time Warping (DTW) algorithm. Firstly, in response to the issue of different users consuming different amounts of information, this article proposes a novel bidirectional DTW algorithm to calculate the similarity between different users. Secondly, this article supplements the user dataset from three perspectives: “utilization” and “exploration” of information, and spatiotemporal attributes of data, which alleviates the problem of data sparsity and cold start in the dataset to a certain extent. Moreover, it effectively enhances the diversity of recommendation results. Finally, this paper constructs an Long Short-Term Memory-Deep Neural Networks (LSTM-DNN) to dynamically obtain user interests and preferences, and proposes a new metric Cumulative Self-System Diversity (CSSD) to measure the diversity of algorithm recommendation results. Experiments have shown that the model effectively enhances the diversity of recommendation results while ensuring recommendation accuracy.},
  archive      = {J_SOCO},
  author       = {Li, Te and Chen, Liqiong and Sun, Huaiying and Hou, Mengxia and Lei, Yunjie and Zhi, Kaiwen},
  doi          = {10.1007/s00500-025-10534-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {2003-2013},
  shortjournal = {Soft Comput.},
  title        = {Exploring diversity and time-aware recommendations: An LSTM-DNN model with novel bidirectional dynamic time warping algorithm},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weighted rank aggregation based on ranker accuracies for
feature selection. <em>SOCO</em>, <em>29</em>(4), 1981–2001. (<a
href="https://doi.org/10.1007/s00500-025-10530-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rank aggregation is the combination of several ranked lists from a set of candidates to achieve a better ranking by combining information from different sources. In feature selection problem, due to the heterogeneity of methods, there are some base rankers (Filter-based methods) that are of diverse quality and usually the ground truth of ratings is not available. Existing rank aggregation methods that take the diverse quality of base rankers into account do not have any explicit approach for appropriate weighting, require prior assumptions, and suffers from high computational complexity. In this paper, to overcome these challenges, an efficient unsupervised method is introduced for estimating the base rankers’ qualities and aggregating the rankers based on the estimated weights. We first compute the ratio of disagreement between base rankers in ordering different element pairs and then estimate the accuracies in a way that to minimize the discrepancy between these computed ratios and their analytical counterparts. We use the weighted majority voting method for obtaining the aggregated results. To resolve the probable inconsistencies in the final aggregation, the result is formed as a graph, and a greedy algorithm is used to find an acyclic subgraph with the highest weigh. To demonstrate the performance of the proposed method, nine standard UCI datasets are used. The obtained results by the proposed method have higher values of classifier measures than the existing baseline Feature Selection methods and rank aggregation-based multi-filter methods in the most datasets. The experiments show that rank aggregation-based Feature Selection methods outperform individual methods. The proposed method also shows the weight of each Filter-based Feature Selection method, in which the MRMR method has a higher weight than other methods.},
  archive      = {J_SOCO},
  author       = {Abdolrazzagh-Nezhad, Majid and Kherad, Mahdi},
  doi          = {10.1007/s00500-025-10530-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {1981-2001},
  shortjournal = {Soft Comput.},
  title        = {Weighted rank aggregation based on ranker accuracies for feature selection},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex preference analysis: A score-based evaluation
strategy for ranking and comparison of the evolutionary algorithms.
<em>SOCO</em>, <em>29</em>(4), 1967–1980. (<a
href="https://doi.org/10.1007/s00500-025-10525-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an evaluation strategy is proposed for evaluation of optimization algorithms, called the Complex Preference Analysis, that assesses the efficiency of different evolutionary algorithms by considering multiple performance metrics concurrently across diverse dimensions and generating a single score for ranking. The proposed strategy allows for a thorough evaluation by assigning distinct priorities in the form of weights, to various performance parameters. The algorithm’s performances on each performance parameter are captured and the best and worst performances in each performance category are identified. The deviation of each algorithm from the best and worst performances in the respective performance category is formulated to generate a single score for each of the algorithms for comparison. The flexibility to adjust weights provides a valuable tool for customizing evaluations according to individual needs and preferences. The proposed evaluation strategy is studied by running evaluations on nine evolutionary algorithms based on their performance over five performance indicators on six datasets of the Travelling Salesman Problem. Conducting Complex Preference Analysis on the different evolutionary algorithms reveals distinctive patterns in their performance, with some algorithms such as Simulated Annealing, Tabu Search, Bat Algorithm, Genetic Algorithm, etc. consistently demonstrating superior results across multiple Travelling Salesman Problem instances, while other algorithms such as Ant Colony Optimization, Teaching Learning Based Optimization, etc. rank lower. The algorithms’ performances on individual performance parameters, when reflected on the final rank of the algorithms, generated based on the collective impact of all the parameters, elucidate the efficiency of the proposed evaluation strategy.},
  archive      = {J_SOCO},
  author       = {Sarkar, Debojyoti and Biswas, Anupam},
  doi          = {10.1007/s00500-025-10525-y},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {1967-1980},
  shortjournal = {Soft Comput.},
  title        = {Complex preference analysis: A score-based evaluation strategy for ranking and comparison of the evolutionary algorithms},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A map-reduce algorithm to find strongly connected components
of directed graphs. <em>SOCO</em>, <em>29</em>(4), 1947–1966. (<a
href="https://doi.org/10.1007/s00500-025-10451-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks have become ubiquitous platforms, comprising intricately linked structures that reflect complex user interactions. Analyzing the interconnected component structure of these large directed graphs is pivotal for critical applications like viral marketing and contagion prediction. This paper presents a parallel algorithm to efficiently discover strongly connected components in massive social graphs by distributing computation across clustered servers. Our proposed distributed approach conducts localized connected component extraction during the Map phase. The merged aggregation in the Reduce phase then uncovers global maximum interconnected sets spanning the fragmented structures. We employ mathematical induction across Map-Reduce stages to demonstrate the algorithm’s correctness for obtaining exhaustive component enumeration across servers. Implementation and complexity analysis on synthetic benchmark graphs highlight significant efficiency gains, with the algorithm demonstrating near-linear speedup for increasing data-set and cluster sizes. The proposed technique advances the state-of-the-art for extracting strongly connected structures from colossal real-world social networks, enabling actionable insights around influence cascades and contagion pathways underlying these intricate linkage patterns.},
  archive      = {J_SOCO},
  author       = {Ji, Fujun and Jin, Jidong},
  doi          = {10.1007/s00500-025-10451-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {4},
  pages        = {1947-1966},
  shortjournal = {Soft Comput.},
  title        = {A map-reduce algorithm to find strongly connected components of directed graphs},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving recurrent deterministic policy gradient strategy
in autonomous driving. <em>SOCO</em>, <em>29</em>(3), 1931–1946. (<a
href="https://doi.org/10.1007/s00500-025-10442-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even though autonomous driving has emerged as a prominent study topic, the conventional control systems for autonomous driving are often rule-based and need to be more adaptable to the flow and conditions of traffic that change over time. Recurrent deterministic policy gradient (RDPG) is a strategy for building autonomous driving control systems. Its performance has been shown to be better than some other methods. Consequently, in this study, we make use of the RDPG algorithm to implement our control strategies as well and further give more comprehensive considerations to the learning procedure to obtain better control performance in the testing procedure, e.g., various punishments to avoid vehicle collisions, different speed limitations to avoid slow-driving or fast-driving, distinct rewards to encourage the ego-vehicle to reach the destination, and so on. On the other hand, we also improve the training performance by focusing solely on the critical events during the training procedure. Namely, our training architecture is more efficient based on the same training time (training steps). The road scene and vehicular simulator, AirSim, has been selected as the experimental platform. The findings indicate that our design achieves more accurate and steady outcomes in control and faster convergence in learning compared to an existing RDPG control strategy for autonomous driving in the literature.},
  archive      = {J_SOCO},
  author       = {Ooi, Yee-Ming and Chang, Che-Cheng},
  doi          = {10.1007/s00500-025-10442-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1931-1946},
  shortjournal = {Soft Comput.},
  title        = {Improving recurrent deterministic policy gradient strategy in autonomous driving},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of discharge coefficient of submerged gates using
a stacking ensemble model. <em>SOCO</em>, <em>29</em>(3), 1911–1929. (<a
href="https://doi.org/10.1007/s00500-025-10518-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the precision of discharge coefficient (Cd) prediction is crucial for effective agricultural water management. However, existing methods for Cd calculation are often complex and dependent on specific assumptions. Therefore, there is a critical need for robust and automated models for Cd estimation. This study introduces a dual-stage ensemble model called EnsembleCNN, for Cd prediction using two distinct gate types under submerged flow conditions. The EnsembleCNN framework uniquely integrates machine learning (ML) models with a recurrent convolutional neural network (CNN) model to capture higher-order interactions and non-linearities. Five base ML models are employed to generate initial predictions. These predictions are subsequently processed by a CNN model embedded with long short-term memory (LSTM) layer, residual connection (RC) and an attention mechanism (ATM). This setup effectively manages the complexity of the combined predictions, seamlessly integrating the outputs from the base models. LSTM is exploited to aggregate the best features for prediction. ATM effectively prioritized high-performing base model outputs, while RC improved the gradient flow, collectively reducing the impact of irrelevant features. The proposed approach strategically weights the contributions of each base model, resulting in accurate Cd estimations. The proposed model achieved root mean square errors of 0.0552 and 0.0173 on vertical sluice gates and radial gates datasets, respectively. Additionally, EnsembleCNN outperformed the base and existing models in terms of prediction accuracy. The proposed system provides a robust tool for optimizing water resource management. Moreover, the adaptability to two field datasets further underscores the practical utility of our model in diverse irrigation scenarios.},
  archive      = {J_SOCO},
  author       = {Hosny, Mohamed and Abdelhaleem, Fahmy S. and Elshenhab, Ahmed M. and Ibrahim, Amir},
  doi          = {10.1007/s00500-025-10518-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1911-1929},
  shortjournal = {Soft Comput.},
  title        = {Prediction of discharge coefficient of submerged gates using a stacking ensemble model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label-specific multi-label text classification based on
dynamic graph convolutional networks. <em>SOCO</em>, <em>29</em>(3),
1897–1909. (<a
href="https://doi.org/10.1007/s00500-025-10446-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label text classification is a key task in natural language processing, aiming to assign each text to multiple predefined categories simultaneously. Existing neural network models usually learn the same text representation for different labels, which limits the effectiveness of the models in capturing deep semantics and distinguishing between similar labels; moreover, these models tend to ignore inter-label correlation, leading to loss of information. To overcome these limitations, we propose a novel label-specific dynamic graph convolutional network (LDGCN). This network combines convolutional operations and BiLSTM to model text sequences and obtains label-specific text representations through a label attention mechanism. In addition, LDGCN improves the dynamic graph convolutional network by utilizing statistical label co-occurrence and label reconstruction maps to effectively capture inter-label dependencies and adaptive interactions between label-specific semantic components. Extensive experiments on the RCV1, AAPD, and EUR-Lex datasets show that our model achieves 96.92%, 86.30%, and 81.42% on the P@1 metrics, respectively, and demonstrates a significant advantage in dealing with tail labels.},
  archive      = {J_SOCO},
  author       = {Yan, Yaoyao and Liu, Fang‘ai and Liu, Kenan and Xu, Weizhi and Zhuang, Xuqiang},
  doi          = {10.1007/s00500-025-10446-w},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1897-1909},
  shortjournal = {Soft Comput.},
  title        = {Label-specific multi-label text classification based on dynamic graph convolutional networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Threats to medical diagnosis systems: Analyzing targeted
adversarial attacks in deep learning-based COVID-19 diagnosis.
<em>SOCO</em>, <em>29</em>(3), 1879–1896. (<a
href="https://doi.org/10.1007/s00500-025-10516-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep and machine learning models have become pivotal in medical image analysis, especially for diagnosing COVID-19 using X-rays and CT scans. While these models, including transfer learning-based approaches, have achieved high accuracy, they remain highly vulnerable to adversarial attacks, which can manipulate input data and cause misclassification, posing critical risks in clinical applications. This study introduces a novel approach to addressing this issue by systematically evaluating the impact of adversarial attacks on COVID-19 diagnosis models built with two leading architectures, VGG-16 and DenseNet-121, using the Fast Gradient Sign Method (FGSM). The FGSM attack causes a dramatic drop in accuracy, reducing VGG-16’s accuracy from 95.12 to 9.97% and DenseNet-121’s from 96.51 to 10.13%. To counter these vulnerabilities, we propose a novel defense mechanism that combines adversarial training with Gaussian noise data augmentation, a dynamic approach that generates perturbations across various epsilon values during the training phase. This innovative method significantly enhances model robustness, restoring accuracy to over 92% on adversarial examples. These findings emphasize the need for strong defense mechanisms in deep learning models for COVID-19 diagnosis, ensuring reliability and security against adversarial threats in clinical environments.},
  archive      = {J_SOCO},
  author       = {Haque, Sheikh Burhan Ul and Zafar, Aasim and Haq, Sheikh Riyaz Ul and Haque, Sheikh Moeen Ul and Ahmad, Mohassin and Roshan, Khushnaseeb},
  doi          = {10.1007/s00500-025-10516-z},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1879-1896},
  shortjournal = {Soft Comput.},
  title        = {Threats to medical diagnosis systems: Analyzing targeted adversarial attacks in deep learning-based COVID-19 diagnosis},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive multimodal approach for parkinson’s disease
classification using artificial intelligence: Insights and model
explainability. <em>SOCO</em>, <em>29</em>(3), 1845–1877. (<a
href="https://doi.org/10.1007/s00500-025-10463-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson’s disease (PD) is a debilitating neurodegenerative disorder affecting millions worldwide. Early detection is vital for effective management, yet remains challenging. In this study, we investigated four distinct datasets for PD detection. Through comprehensive experimentation employing ensemble methods and feature selection, we achieved high classification accuracies across the datasets. For the Oxford Parkinson’s Disease Detection Dataset, an accuracy of 95.67%, precision of 97.59%, recall of 84.5%, specificity of 99.32%, and F1-score of 90.57% were achieved. For the Alzheimer Parkinson Diseases 3 Class Dataset, the “Stacking” approach surpasses individual models, reaching an accuracy of 99.85%, precision of 99.81%, recall of 99.81%, specificity of 99.86%, and F1 of 99.81%. For the NewHandPD dataset, Regarding the Spiral category, The “Base-P32-384” model surpasses others with an accuracy of 97.35%, precision of 96.50%, recall of 98.57%, and F1-score of 97.53%. The collective “Stacking” approach proves highly effective regarding the Circle category, achieving 100% across all performance metrics. Regarding the Meander category, the “Base-P16-224” model achieves an accuracy of 97.35%, precision of 99.26%, recall of 95.71%, specificity of 99.19%, and F1 of 97.45%. The Mobile Device Voice Recordings at King’s College London (MDVR-KCL) dataset contains two datasets. Regarding the “SpontaneousDialogue” dataset, accuracy, BAC, precision, recall, specificity, and F1-score were computed, resulting in values of 94.03%, 92.83%, 90.78%, 100.0%, and 85.67%, respectively. Regarding the “ReadText” dataset, accuracy, BAC, precision, recall, specificity, and F1-score were computed, resulting in values of 91.89%, 90.62%, 87.5%, 100.0%, and 81.25%, respectively. Our findings highlight the efficacy of leveraging diverse data sources and advanced machine learning techniques to enhance PD detection accuracy.},
  archive      = {J_SOCO},
  author       = {Balaha, Hossam Magdy and Hassan, Asmaa El-Sayed and Ahmed, Rawan Ayman and Balaha, Magdy Hassan},
  doi          = {10.1007/s00500-025-10463-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1845-1877},
  shortjournal = {Soft Comput.},
  title        = {Comprehensive multimodal approach for parkinson’s disease classification using artificial intelligence: Insights and model explainability},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing neural network predictions with finetuned numeric
embeddings for stock trend forecasting. <em>SOCO</em>, <em>29</em>(3),
1829–1844. (<a
href="https://doi.org/10.1007/s00500-025-10483-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The financial markets, particularly stock trading, offer a variety of profit-generating opportunities based on complex and volatile behaviour. Investors seek strategies to maximise returns, leading to an investigation of inherent market patterns. Converting OHLC (Open, High, Low, Close) data into transformers-based pre-trained language model compatible text is an innovative method for representing numeric data. Extending the language model’s utility to integrate stock market numeric time-series data incorporates its inherent numeracy in embeddings. Raw data are converted into a format compatible with the pre-trained language model through preprocessing and text templates. Using an ensemble of Bidirectional Encoder Representations from Transformers (BERT), FinBERT (BERT finetuned with the financial corpus), FLANG-BERT (BERT finetuned with the financial corpus) and FLANG-ELECTRA (ELECTRA finetuned with the financial corpus) as feature extractor, historical stock market data are utilised to generate an embedding matrix and fused with established neural network architectures, such as Backpropagation Neural Network (BPNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU), to predict stock market trends. The simulation results demonstrate that the proposed integrated approach is preferable to previous methodologies. The significance of the findings is confirmed by statistical validation using the Wilcoxon signed-rank test (p value &lt; 0.01). This study offers a promising approach for improving stock market trend prediction by integrating the ensemble of language model-based numeric embeddings with neural networks.},
  archive      = {J_SOCO},
  author       = {Trivedi, Avinash and Sangeetha, S.},
  doi          = {10.1007/s00500-025-10483-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1829-1844},
  shortjournal = {Soft Comput.},
  title        = {Enhancing neural network predictions with finetuned numeric embeddings for stock trend forecasting},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A game-theoretic exploration with surplus profit-sharing in
a three-channel supply chain, featuring e-commerce dynamics.
<em>SOCO</em>, <em>29</em>(3), 1811–1827. (<a
href="https://doi.org/10.1007/s00500-025-10453-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a three-channel supply chain, coordination can be challenging especially when a manufacturer has to work with a retailer and an online platform. In such a scenario, sales efforts can be critical to the success of the supply chain. However, there is a risk of free riding behavior by either the retailer or the manufacturer, which can lead to suboptimal sales performance. This article will explore the centralized and the decentralized models by the use of game theory (Nash and Stackelberg) and eventually tries to coordinate the three-channel supply chain with the help of Operational Research (OR) to optimize the decision-making and create a win–win situation. Numerical examples are provided to prove the efficiency of the presented models. Finally, the models are evaluated through sensitivity analysis, and managerial insights are provided to enhance the applicability of the models for coordinating a three-channel supply chain.},
  archive      = {J_SOCO},
  author       = {Vatanara, Maryam and Rabbani, Masoud and Heydari, Jafar},
  doi          = {10.1007/s00500-025-10453-x},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1811-1827},
  shortjournal = {Soft Comput.},
  title        = {A game-theoretic exploration with surplus profit-sharing in a three-channel supply chain, featuring e-commerce dynamics},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forest fire rescue framework to jointly optimize
firefighting force configuration and facility layout: A case study of
digital-twin simulation optimization. <em>SOCO</em>, <em>29</em>(3),
1789–1810. (<a
href="https://doi.org/10.1007/s00500-025-10434-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the pre-prevention stage, firefighting force configuration and facility layout play a critical role in reducing fire extinguishing time (FET) during the early-stage forest fire rescue. It is acknowledged that there is a scarcity of quantitative evaluation research establishing a connection between observed forest fire behaviors and pre-prevention research. Therefore, we propose a forest fire rescue framework to jointly optimize firefighting force configuration and facility layout. As an iterative optimization framework based on fire spread and suppression model (FSSM), firefighting force configuration and facility layout methods use differential-evolution-based algorithm and deep neural network to adjust the configuration funds of various firefighting forces and plan the spatial layout of multiple firefighting facilities. With iterations increasing, the proposed method can continue to find better solutions than before. Moreover, through the offensive and defensive procedures in FSSM, the best configuration and layout solution can mirror multi-rescue-resource interactions and mutual restraints. The performance of the proposed framework is validated through various maps and experiments in terms of FET, forest burned area, and uncontrolled fire rate, even under extreme wind-speed pressure conditions. This implies that the proposed framework demonstrates favorable adaptability. Furthermore, the proposed framework can be introduced into the related dynamic interactions and constraints optimization scenarios (e.g., smart factories, smart construction sites, and more), thereby opening the door of digital-twin simulation optimization.},
  archive      = {J_SOCO},
  author       = {Zhang, HongGuang and Ma, ShengWen and Li, Xiang and You, MingCan and Tao, YuXuan},
  doi          = {10.1007/s00500-025-10434-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1789-1810},
  shortjournal = {Soft Comput.},
  title        = {Forest fire rescue framework to jointly optimize firefighting force configuration and facility layout: A case study of digital-twin simulation optimization},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient collocation algorithm for third order
non-linear emden–fowler equation. <em>SOCO</em>, <em>29</em>(3),
1767–1788. (<a
href="https://doi.org/10.1007/s00500-025-10431-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study presents a novel algorithm for solving third-order non-linear equations (Emden–Fowler type), which can be applied to various physical models. The algorithm uses a quintic trigonometric B-spline collocation method and a quasilinearization technique to avoid the non-linearity term in the equation. The study established a comprehensive error analysis for the proposed algorithm and proved that it has fourth order, i.e., $$(\mathscr {O}(h^4))$$ convergent. The algorithm’s ability to handle singular behavior at the point $$x=0$$ and its faster rate of convergence exhibit a promising approach to solving such problems. The study also validates the theoretical results through numerical experiments and shows that the proposed algorithm has a faster rate of convergence in comparison to the existing methods.},
  archive      = {J_SOCO},
  author       = {Alam, Mohammad Prawesh and Khan, Arshad},
  doi          = {10.1007/s00500-025-10431-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1767-1788},
  shortjournal = {Soft Comput.},
  title        = {An efficient collocation algorithm for third order non-linear Emden–Fowler equation},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feature extraction method for rotating machinery fault
diagnosis based on a multiscale entropy fusion strategy and GA-RL-LDA
model. <em>SOCO</em>, <em>29</em>(3), 1747–1765. (<a
href="https://doi.org/10.1007/s00500-025-10484-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the problems of information loss, feature redundancy and unsatisfactory diagnosis accuracy when using traditional multiscale entropy methods and feature reduction methods to diagnose rotating machinery faults, a feature extraction method based on a multiscale entropy fusion strategy and a GA-RL-LDA model is proposed in this paper. Firstly, the multiscale fluctuation dispersion entropy (MFDE), the refined composite multiscale dispersion entropy (RCMDE) and the refined composite multiscale fluctuation dispersion entropy (RCMFDE) of the collected vibration signal are calculated to form an original feature set. Then, based on the ReliefF algorithm and Laplacian score (LS), an RL index is constructed for feature sensitivity evaluation. After that, combing the RL with Linear discriminant analysis (LDA) and using genetic algorithm (GA) to optimize the uncertain parameters, a GA-RL-LDA model is proposed for feature reduction. Finally, the reduced feature subset is input into support vector machine (SVM) for fault classification. The experiment utilized data from Unit 3 of the SK Hydropower Station and bearing data from Case Western Reserve University, achieving diagnostic accuracies of 95.2381% and 97.3333%, respectively. In the 105 test samples from Unit 3 of the SK Hydropower Station, only 5 samples were misclassified, while in the 150 test samples from Case Western Reserve University, only 4 samples were misclassified. Compared with different information entropy and optimization strategies, the results show that the proposed method can more effectively extract fault sensitive features and accurately diagnose rotating machinery faults even with a small number of training samples.},
  archive      = {J_SOCO},
  author       = {Lu, Na and Li, Zhongliang and Liu, Dong and Cao, Chaofan and Jiang, Shuangyun and Chen, Xudong and Wang, Peng},
  doi          = {10.1007/s00500-025-10484-4},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1747-1765},
  shortjournal = {Soft Comput.},
  title        = {A feature extraction method for rotating machinery fault diagnosis based on a multiscale entropy fusion strategy and GA-RL-LDA model},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning approach to analyse stress by using voice
and body posture. <em>SOCO</em>, <em>29</em>(3), 1719–1745. (<a
href="https://doi.org/10.1007/s00500-025-10441-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current scenario, where we can see young people struggling for their careers, they are even fighting a battle with their stress and tension. None of their work is done without stress to complete their task and compete with others. To overcome stress, one should have good emotional intelligence to cope with emotions and any upcoming stress. But at some point, due to lack of guidance, some people don’t know how to analyze the situations and how to handle them without taking the stress and end up with anxiety, depression, disappointment, suicide, heart attack, stroke etc. Due to the advancement of Human–Computer Interaction (HCI), medical science has leveled up to another peak. Machine Learning and Deep Learning played a major role in such interactions and predictions. Many applications have been developed in past years based on machine learning and deep learning. One of those applications is related to psychology and is still in research. These applications can be used for emotion and stress analysis among people, especially youngsters. Research in this field is being conducted using various verbal and non-verbal parameters. This paper addresses the research problem of improving emotion recognition accuracy and robustness to better analyze and manage stress. The primary objective is to develop an advanced Emotion Recognition System (ERS) that leverages deep learning algorithms to analyses both verbal and non-verbal cues—specifically, speech and body posture, including facial expressions. We have further integrated it with the Flask web framework to make an Emotion Recognition System that takes input in the form of video and audio to analyze Emotions and Stress. We have also compared our proposed ERS with existing ones and found that our ERS gives better results.},
  archive      = {J_SOCO},
  author       = {Gupta, Sumita and Gambhir, Sapna and Gambhir, Mohit and Majumdar, Rana and Shrivastava, Avinash K. and Pham, Hoang},
  doi          = {10.1007/s00500-025-10441-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1719-1745},
  shortjournal = {Soft Comput.},
  title        = {A deep learning approach to analyse stress by using voice and body posture},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced TOPSIS-CoCoSo framework for multi-attribute
decision-making with triangular fuzzy neutrosophic sets: “Effect
evaluation of intelligent technology empowering physical education
teaching” case. <em>SOCO</em>, <em>29</em>(3), 1703–1717. (<a
href="https://doi.org/10.1007/s00500-025-10411-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The history of human education development has proven that there is an interactive relationship between technological development and education and teaching. In the process of promoting education modernization and high-quality development, the widespread application of intelligent technology in the field of education is the trend, and intelligence is driving profound transformation and transformation in the field of education. The effect evaluation of intelligent technology empowering Physical Education teaching could be considered as multiple-attribute decision-making (MADM). Recently, the TOPSIS technique and Combined Compromise Solution (CoCoSo) technique was employed to deal with MADM. The triangular fuzzy neutrosophic sets (TFNSs) are employed as a better tool for expressing uncertain information during the effect evaluation of intelligent technology empowering Physical Education teaching. In this paper, the triangular fuzzy neutrosophic number TOPSIS-CoCoSo (TFNN-TOPSIS-CoCoSo) technique based on the TFNN relative closeness coefficient (TFNNRCC) technique is managed to cope with the MADM under TFNSs. The information entropy technique is employed to manage the weight values based on the TFNNRCC under TFNSs. Finally, a numerical example of effect evaluation of intelligent technology empowering Physical Education teaching is managed and some better comparisons are managed to verify the TFNN-TOPSIS-CoCoSo technique. The main contribution of this paper is outlined: (1)TFNN-TOPSIS-CoCoSo technique based on the TFNNRCC is constructed; (2) Entropy technique is employed to manage weight based on the TFNNRCC under TFNSs. (3) TFNN-TOPSIS-CoCoSo technique is founded to manage the MADM based on the TFNNRCC under TFNSs; (4) numerical example for effect evaluation of intelligent technology empowering Physical Education teaching and some comparative analysis is supplied to verify the proposed TFNN-TOPSIS-CoCoSo technique.},
  archive      = {J_SOCO},
  author       = {Xiao, Jie and Zhang, Yu},
  doi          = {10.1007/s00500-025-10411-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1703-1717},
  shortjournal = {Soft Comput.},
  title        = {Enhanced TOPSIS-CoCoSo framework for multi-attribute decision-making with triangular fuzzy neutrosophic sets: “effect evaluation of intelligent technology empowering physical education teaching” case},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lacunary statistical soft convergence in soft topology.
<em>SOCO</em>, <em>29</em>(3), 1691–1701. (<a
href="https://doi.org/10.1007/s00500-025-10479-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical convergence and some related types of convergence are a generalisation of topological convergence. Similarly, soft set theory, introduced by Molodtsov to deal with uncertainty in various scientific fields, is a generalisation of the classical concept of sets. Although both concepts have found extensive applications to various mathematical structures, the investigation of statistical convergence within soft topological spaces has not yet been undertaken. This study examines the lacunary statistical convergence of sequences of soft points in soft topological spaces, employing a density defined by an unbounded modulus function. Basic results and inclusion theorems concerning this convergence are presented.},
  archive      = {J_SOCO},
  author       = {Bayram, Erdal and Dervişoğlu, Melisa},
  doi          = {10.1007/s00500-025-10479-1},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1691-1701},
  shortjournal = {Soft Comput.},
  title        = {Lacunary statistical soft convergence in soft topology},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-InfNode: Ranking top-k influential nodes in complex
networks with random walk. <em>SOCO</em>, <em>29</em>(3), 1677–1690. (<a
href="https://doi.org/10.1007/s00500-025-10471-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complex network is a symbolic representation of distinct real-world systems where information propagates through nodes. Its goal is to identify communities that represent the network’s structure. However, locating the influential node with the maximal range among various nodes and the ability to disseminate influence to a wide portion of the network is one of the most essential concerns in such a network. Centrality is a traditional metric for understanding the effect of nodes in a network, with numerous variants such as closeness, betweenness, degree centrality, and so on. The centrality metrics either work locally or globally to identify influential nodes. In this study, a proposed algorithm named k-InfNode, based on the characteristics of community structure, captures the dynamics of nodes. k-InfNode uses a random walk and combines local and global properties to figure out which nodes are important in a complex network. It was inspired by the idea of overlapping nodes that show how nodes and communities interact with each other across the network. In the beginning, the fuzzy c-means algorithm finds the overlapping nodes in the network. Next, the algorithm assigns an initial score to each node based on node and community information, and iteratively scores each node using the Random Walk with Restart (RWR) algorithm. Experiments performed using real and artificial networks have shown that the k-InfNode is effective.},
  archive      = {J_SOCO},
  author       = {Hasan, Ahmadi and Kamal, Ahmad and Kumar, Pawan},
  doi          = {10.1007/s00500-025-10471-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1677-1690},
  shortjournal = {Soft Comput.},
  title        = {K-InfNode: Ranking top-k influential nodes in complex networks with random walk},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A micro-level approach for modeling rumor propagation in
online social networks. <em>SOCO</em>, <em>29</em>(3), 1667–1675. (<a
href="https://doi.org/10.1007/s00500-025-10456-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks have become the major platforms for information dissemination in recent years. However, rapid propagation of rumors in these networks as a special form of information can greatly influences social lives. Hence, work on rumor propagation models and analysis is under great attention by the research communities. Previously, researchers have proposed various models to explore the dynamics of rumor propagation and analyze steady-state. However, most of them did not consider people’s behavior differences in the spreading or opposing rumor. To overcome this limitation, we assume that individuals have different probability of spreading rumor, spreading anti-rumor and stifling. In this paper we introduce a new model for rumor propagation in social networks considering these differences at micro-level. The proposed model which considered both types of rumor and anti-rumor messages on people decision is an agent-based model in terms of probabilistic automata network. To evaluate the proposed model, we conduct a number of Monte-Carlo simulation experiments on Barabasi-Albert model of social networks that show the accuracy of the proposed model. We also conduct interesting sensitivity analysis to see the effects of different model parameters on the dynamics of the rumor propagation.},
  archive      = {J_SOCO},
  author       = {Sahafizadeh, Ebrahim and Talatian Azad, Saeed},
  doi          = {10.1007/s00500-025-10456-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1667-1675},
  shortjournal = {Soft Comput.},
  title        = {A micro-level approach for modeling rumor propagation in online social networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Paw decompositions of diamond and some edge cycle graphs.
<em>SOCO</em>, <em>29</em>(3), 1659–1665. (<a
href="https://doi.org/10.1007/s00500-025-10541-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let $${C}_{n}, {K}_{n},{W}_{n},{K}_{r,s}$$ denote a cycle, complete graph, wheel graph, complete bipartite graph respectively. An edge cycle graph of a graph $$G$$ is the graph $$G({C}_{k})$$ formed from one copy of $$G$$ and $$|E(G)|$$ copies of $${P}_{k},$$ where t he ends of the $${i}^{th}$$ edge are identified with the ends of $${i}^{th}$$ copy of $${P}_{k}$$ . In this article, we determine the necessary and sufficient conditions for the existence of paw- decompositions of the diamond graph $${Br}_{n}$$ and some edge cycle graphs like $${K}_{n}\left({C}_{3}\right), { W}_{n}\left({C}_{3}\right),{ K}_{r,s}\left({C}_{3}\right), { C}_{n}\circ \stackrel{\leftharpoonup}{{K}_{m}}({C}_{3})$$ and $${P}_{n}\circ \stackrel{\leftharpoonup}{{K}_{m}}({C}_{3})$$ where $$\circ $$ denotes the corona of graphs.},
  archive      = {J_SOCO},
  author       = {Esakkimuthu, Murugan and Rameshbabu, Sivaprakash Gunniya},
  doi          = {10.1007/s00500-025-10541-y},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1659-1665},
  shortjournal = {Soft Comput.},
  title        = {Paw decompositions of diamond and some edge cycle graphs},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On goal programming approach for interval-valued
intuitionistic fuzzy multi-objective transportation problems with an
application to tourism industry. <em>SOCO</em>, <em>29</em>(3),
1627–1657. (<a
href="https://doi.org/10.1007/s00500-025-10420-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transportation problems are inevitably affected by numerous imprecise factors like weather, fuel expenses, topography, etc. Hence, the use of crisp parameters to model transportation problems appears to be both insufficient and inaccurate. Consequently, transportation problems using fuzzy/ intuitionistic fuzzy (IF) numbers seem more effective. Interval-valued intuitionistic fuzzy (IVIF) numbers are further generalization of IF numbers where membership and non-membership degrees are closed sub-intervals of [0, 1]. This concept of allocating interval values helps in dealing with the hesitancy of decision-maker while assigning fixed values to membership and non-membership degrees. In this article, balanced transportation problems having multiple objectives under the IVIF environment are examined. To overcome inconsistencies in the existing approaches, novel linear as well as non-linear interval-valued membership and non-membership functions have been proposed. Subsequently, an improved IVIF programming approach is developed using these newly defined functions along with theoretical validation. In addition, when goals are associated with objective functions, the proposed approach has been further improvised as IVIF prioritized goal programming. Eventually, a trip planning problem in the tourism industry is exhibited to illustrate the proposed IVIF technique and later, it is amalgamated with prioritized goals to demonstrate the proposed IVIF goal programming approach.},
  archive      = {J_SOCO},
  author       = {Chauhan, Abhishek and Mahajan, Sumati},
  doi          = {10.1007/s00500-025-10420-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1627-1657},
  shortjournal = {Soft Comput.},
  title        = {On goal programming approach for interval-valued intuitionistic fuzzy multi-objective transportation problems with an application to tourism industry},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-aware coverage path planning for a swarm of UAVs
using mobile ground stations for battery-swapping. <em>SOCO</em>,
<em>29</em>(3), 1605–1625. (<a
href="https://doi.org/10.1007/s00500-025-10537-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usage of swarms of drones is expected to continue growing in the next years, particularly in dangerous scenarios, such as monitoring and rescue missions in hostile and disaster areas. Small-sized Unmanned Aerial Vehicles (UAVs) are highly suitable for use in such scenarios due to their agility and maneuverability. On the other hand, their limited battery capacity poses significant challenges, especially during missions requiring full coverage of large areas in a short time and extreme weather conditions. This work proposed an energy efficiency approach, which makes use of mobile ground-based battery-swapping stations (BSSes), to speed up the UAV’s battery replacement and reduce energy waste in the round trip to the charging station. Specifically, a Context-Aware Coverage Path Planning (CACPP) problem has been formulated to determine the complete coverage path of a large area by a swarm of UAVs, minimizing the path overlapping and UAV battery swapping. The model takes into account the need to continue re-planning the mission, depending on the weather conditions (i.e., temperature and wind), the presence of obstacles, and the residual energy levels of the drones, as well as the relative positions of the drones and mobile BSSes. To solve the CACPP problem, an iterative approach leveraging two synchronized optimization models for planning UAV paths and BSS routes has been presented. As the CACPP problem is NP-hard, a heuristic procedure for solving it has also been evaluated. Experimental results show that it can be appropriate for large instances of the problem.},
  archive      = {J_SOCO},
  author       = {Porcelli, Lorenzo and Ficco, Massimo and D’Angelo, Gianni and Palmieri, Francesco},
  doi          = {10.1007/s00500-025-10537-8},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1605-1625},
  shortjournal = {Soft Comput.},
  title        = {Context-aware coverage path planning for a swarm of UAVs using mobile ground stations for battery-swapping},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using deep forest regression and multi-layer state
transition algorithm to soft measuring modeling with small sample data.
<em>SOCO</em>, <em>29</em>(3), 1587–1603. (<a
href="https://doi.org/10.1007/s00500-025-10527-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In actual industrial operation process, some key performance indicators (KPIs) are tricky to detect online due to the characteristics of the detection equipment and the nature of the parameters. Moreover, these KPIs usually present small sample attributes. In this article, a stable and efficient soft measuring model for the KPIs of industrial processes is proposed using deep forest regression (DFR) and multi-layer state transition algorithm (STA). First, DFR is used to build soft measuring models for KPIs with random initial hyperparameters. Second, an improved dynamic STA (DSTA) is developed to optimize the DFR’s hyperparameters. Furthermore, the probability parameters of the DSTA structure are optimally selected using a STA. Finally, gradient refinement is utilized to fine-tune the state factor, which achieves a more accurate optimization process during the internal iteration process. The proposed algorithm is evaluated on the benchmark function, dataset, and an actual industrial problem. Results prove that the use of our method in soft measuring modeling can be effective.},
  archive      = {J_SOCO},
  author       = {Xia, Heng and Tang, Jian and Yu, Wen},
  doi          = {10.1007/s00500-025-10527-w},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1587-1603},
  shortjournal = {Soft Comput.},
  title        = {Using deep forest regression and multi-layer state transition algorithm to soft measuring modeling with small sample data},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A community-based simulated annealing approach with a new
structure-based neighborhood search to identify influential nodes in
social networks. <em>SOCO</em>, <em>29</em>(3), 1567–1585. (<a
href="https://doi.org/10.1007/s00500-025-10490-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying influential nodes has attracted the attention of many researchers in recent years. Because of the weak tradeoff between accuracy and running time, and ignoring the community structure by the proposed algorithms in the past research studies, further studies in this area are required. In this paper, we consider communities and also use a novel structure-based neighborhood search to improve exploration strategy of the simulated annealing (SA) algorithm. Moreover, we use the k-shell method for generating a better initial solution instead of random generation. In the proposed algorithm called Ckshell-SA, first, the communities are detected, then the k-shell method is used in each community to find initial candidate nodes locally. Finally, SA algorithm is applied with a neighborhood search that considers the structural properties of the network, and three centralities to find the influential nodes globally. A derivative of the Ckshell-SA method called kshell-SA is also introduced in this paper to examine the impact of considering communities. Unlike the Ckshell-SA, the community structure is neglected, and the k-shell is performed on the whole network in kshell-SA algorithm. Extensive experiments are conducted on eight real-world networks under Independent Cascade Model (IC) and Weighted Independent Cascade Model (WC). The results show that the Ckshell-SA and kshell-SA algorithms outperform the state-of-the-art algorithms concerning influence spread. Furthermore, the results show that Ckshell-SA is more efficient in networks like Facebook with a high Power Law exponent and higher modularity. On the contrary, kshell-SA is more successful in networks like Slashdot or Epinions with lower modularity.},
  archive      = {J_SOCO},
  author       = {Abyaneh, Farzaneh Rajaee and Charkari, Nasrollah Moghadam and Roayaei, Mehdy},
  doi          = {10.1007/s00500-025-10490-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1567-1585},
  shortjournal = {Soft Comput.},
  title        = {A community-based simulated annealing approach with a new structure-based neighborhood search to identify influential nodes in social networks},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid genetic search based approach for the generalized
vehicle routing problem. <em>SOCO</em>, <em>29</em>(3), 1553–1566. (<a
href="https://doi.org/10.1007/s00500-025-10507-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel meta-heuristic for addressing a variant of the classical Capacitated Vehicle Routing Problem (CVRP) known as the Generalized Vehicle Routing Problem (GVRP). In the GVRP, nodes are organized into clusters, with the constraint that only one node from each cluster must be visited. The proposed meta-heuristic is a Hybrid Genetic Search (HGS) that leverages recent advancements in CVRP methodologies, adapting successful strategies and techniques from CVRP to the GVRP context. To evaluate the performance of the HGS meta-heuristic, we perform an extensive computational analysis on numerous benchmark instances ranging from small to large sizes. To thoroughly analyze the algorithm’s average behavior, convergence profiles over time are reported for the considered instances. Results show that the proposed algorithm achieves 174 new best solutions out of the 498 instances considered. In only six instances out of 498, the algorithm is unable to reach or improve upon the best-known solution in the literature. These results suggest that the proposed meta-heuristic has significant potential in addressing real-world generalized vehicle routing challenges. Code available at: https://github.com/vlatorre847/HGSGVRP .},
  archive      = {J_SOCO},
  author       = {Latorre, Vittorio},
  doi          = {10.1007/s00500-025-10507-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1553-1566},
  shortjournal = {Soft Comput.},
  title        = {A hybrid genetic search based approach for the generalized vehicle routing problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient reconfigurable architecture to extract image
features for face recognition using local binary pattern. <em>SOCO</em>,
<em>29</em>(3), 1541–1552. (<a
href="https://doi.org/10.1007/s00500-025-10415-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of the face is a widely used method to detect human features. In various scenarios the face recognition speed becomes significant which necessitates to improve the critical delay of the architecture. In this paper, we propose Efficient FPGA architecture to extract image features using Local Binary pattern (LBP) for Face Recognition. The face image is converted into standard size (256 × 256) as pre-processing and the Gaussian filter is used to remove the high frequency components. These image is then applied to optimized LBP block to obtain the LBP features for both database sample and test sample are further compared to make the decision for face recognition. The proposed LBP architecture is designed using simple counter and comparators which leads to minimum complexity in turn improving the critical delay and hardware utilizations of the entire system. The simulation is performed for Olivetti Research Laboratory (ORL) dataset using MATLAB by showing False Acceptance Rate (FAR), False Rejection Rate (FRR) and Total Success Rate (TSR) values. The thresholding is performed based on Weighted Mean Square Difference and is varied for Total Success Rate (TSR) calculations tested for different combinations of Person in Database (PID) and Person Out of database (POD). Finally, the proposed architecture is synthesized on Spartan 6-xc651 × 4c-3csg432 Digilent FPGA board. It is observed that the recognition time of our architecture in hardware (FPGA) is 1.05 µS which is better compared to existing methods.},
  archive      = {J_SOCO},
  author       = {Bhavikatti, Sumangala and Bhairannawar, Satish},
  doi          = {10.1007/s00500-025-10415-3},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1541-1552},
  shortjournal = {Soft Comput.},
  title        = {Efficient reconfigurable architecture to extract image features for face recognition using local binary pattern},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition matheuristics for last mile delivery using
public transportation systems. <em>SOCO</em>, <em>29</em>(3), 1511–1539.
(<a href="https://doi.org/10.1007/s00500-025-10513-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores the potential of using public transportation systems for freight delivery, where we intend to utilize the spare capacities of public vehicles like buses, trams, metros, and trains, particularly during off-peak hours, to transport packages within the city instead of using dedicated delivery vehicles. The study contributes to the growing literature on innovative strategies for performing sustainable last mile deliveries. We study an operational level problem called the Three-Tier Delivery Problem on Public Transportation, where packages are first transported from the Consolidation and Distribution Center (CDC) to nearby public vehicle stations by delivery trucks, comprising the first tier of the problem. In the second tier, the public vehicles pick them up from the stops and transport them into the city area. The last leg, or the third tier of the delivery, is performed to deliver the packages to their respective customers using green vehicles or eco-friendly systems. We propose mixed-integer linear programming formulations to study the transport of packages from the CDC to the customers and employ decomposition-based matheuristics to solve them. We have three decomposition approaches based on the order of solving the tiers, resulting from the tier we start solving the problem from. We use a heuristic methodology to link the tiers by coordinating the flow of packages between them, and utilize CPLEX to solve the individual tiers. We provide numerical experiments to demonstrate the efficiency and effectiveness of the system. Our results show that this system has the potential to reduce the length of trips performed by traditional delivery trucks by 85.91%, thereby reducing the negative social and environmental impacts of existing last mile delivery systems.},
  archive      = {J_SOCO},
  author       = {Mandal, Minakshi Punam and Archetti, Claudia},
  doi          = {10.1007/s00500-025-10513-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1511-1539},
  shortjournal = {Soft Comput.},
  title        = {Decomposition matheuristics for last mile delivery using public transportation systems},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A secure quantum homomorphic encryption ciphertext retrieval
scheme. <em>SOCO</em>, <em>29</em>(3), 1497–1509. (<a
href="https://doi.org/10.1007/s00500-025-10454-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent paper (Gong et al. Quantum Inf Process 19:3, 2020), a novel ciphertext retrieval scheme based on the Grover algorithm and quantum homomorphic encryption was presented. In this scheme, when the server performs the operation of marking the solution on the user’s encrypted state in the Grover iteration, it needs to remove many gate-errors generated in the homomorphic evaluation of the T gate. And the server could judge this specific solution from the quantum circuit of marking the solution. It makes this scheme unable to achieve the low-cost and secure ciphertext retrieval. Therefore, we improve the Gong et al.’s scheme and propose a secure quantum homomorphic encryption ciphertext retrieval scheme. In our scheme, the trusted third party is introduced to cooperate with the server to execute the Grover algorithm. In each Grover iteration, the trusted third party can quickly mark the solution on the plaintext state, encrypt the marked state, and transmit it to the server. Then the server performs the remaining operations of this Grover iteration on the encrypted state. The trusted third party finally decrypts the iterated state. This cooperative approach ensures that the number of auxiliary qubits required and extra quantum gates executed in our scheme are lower than the Gong et al.’s scheme. By analyzing the security of our scheme, we confirm that the server and the trusted third party will not be informed of this solution. Thus, our scheme realizes the secure ciphertext retrieval with low computational overhead. We utilize IBM’s Qiskit framework to simulate our scheme, and the experimental result shows that our scheme is correct. It is worth noting that the low-cost and secure ciphertext retrieval will play a crucial role in modern information security and privacy protection.},
  archive      = {J_SOCO},
  author       = {Cheng, Zhen-Wen and Chen, Xiu-Bo and Xu, Gang and Chang, Yan and Miao, Li-Hua and Yang, Yi-Xian and Wang, Ya-Lan},
  doi          = {10.1007/s00500-025-10454-w},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1497-1509},
  shortjournal = {Soft Comput.},
  title        = {A secure quantum homomorphic encryption ciphertext retrieval scheme},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing signature scheme: The enhanced edward
elgamal extreme performance accumulate signature approach for IoT and
blockchain applications. <em>SOCO</em>, <em>29</em>(3), 1473–1496. (<a
href="https://doi.org/10.1007/s00500-025-10426-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital signatures, essential for establishing trust in the digital realm, have evolved in their application and importance alongside emerging technologies such as the Internet of Things (IoT), Blockchain, and cryptocurrency. These advancements necessitate improvements in performance, security, and efficiency. This article examines and compares the Elliptic Curve Digital Signature Algorithm with the Hyper Elliptic Curve Digital Signature Algorithm and the Edwards Curve Digital Signature Algorithm. We highlight its superior capabilities for blockchain and IoT applications and advocate for its potential to deliver immediate enhancements in security and performance. Our study introduces a novel digital signature scheme specifically designed to enhance non-repudiation in blockchain ecosystems. Utilizing the Optimized Extreme Performance Edwards Curve Accumulated Signature scheme, our approach significantly reduces signing and verification times by 10% and 13%, respectively, compared to traditional signatures. Additionally, it offers a 10% boost in transaction throughput and block validation efficiency. Experiments conducted within various blockchain-integrated IoT setups demonstrate the scheme&#39;s effectiveness, consistently achieving improvements across diverse IoT sensor data. This highlights the innovative contribution of our scheme to the efficiency and security of blockchain technology.},
  archive      = {J_SOCO},
  author       = {Anusha, R. and Saravanan, R.},
  doi          = {10.1007/s00500-025-10426-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1473-1496},
  shortjournal = {Soft Comput.},
  title        = {Revolutionizing signature scheme: The enhanced edward elgamal extreme performance accumulate signature approach for IoT and blockchain applications},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank decomposition optimization and its application in
fabric defects. <em>SOCO</em>, <em>29</em>(3), 1453–1472. (<a
href="https://doi.org/10.1007/s00500-025-10399-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low-rank decomposition model is frequently employed in defect detection. It separates the target matrix into a low-rank component and a sparse component using the nuclear norm and the $$l_1$$ -norm, which aids in extracting the background and defects. However, the nuclear norm, derived from singular value decomposition, often fails to effectively extract the background of fabrics. This paper introduces a novel matrix norm, defined by integrating several key elementary functions, enhancing the separation of the low-rank and sparse matrices. The Alternating Direction Method of Multipliers (ADMM) typically solves the low-rank decomposition model with a fixed step size penalty factor. This study dynamically adjusts the penalty factor based on defect detection characteristics, thus enhancing the algorithm’s computational efficiency. Additionally, the convergence of the proposed algorithm is validated. Experimental results demonstrate that this new model not only precisely distinguishes the sparse matrix but also achieves higher computational efficiency, surpassing other existing methods in both accuracy and efficiency.},
  archive      = {J_SOCO},
  author       = {Chen, Zhixiang and Shi, Wenya and Liang, Jiuzhen and Liu, Hao},
  doi          = {10.1007/s00500-025-10399-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1453-1472},
  shortjournal = {Soft Comput.},
  title        = {Low-rank decomposition optimization and its application in fabric defects},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient COVID-19 detection using data mining algorithms: A
comparison of basic and hybrid approaches. <em>SOCO</em>,
<em>29</em>(3), 1437–1451. (<a
href="https://doi.org/10.1007/s00500-025-10538-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and efficient diagnosis of COVID-19 remains a significant challenge due to the limitations of current detection methods, such as blood tests and chest scans, which can be time-consuming and error-prone. This study aims to compare the performance of basic and hybrid data mining algorithms in diagnosing COVID-19, using blood test results and clinical information to identify the most effective approach. A dataset of 200 records from suspected and infected COVID-19 patients, with 23 characteristics and one diagnostic class, was analysed. Nine data mining algorithms were tested: four basic algorithms (Naive Bayes, Support Vector Machine, Decision Tree, K-Nearest Neighbor) and five hybrid algorithms (Random Forest, AdaBoost, Majority Voting, XGBoost, Bagging). The study also integrated Response Surface Methodology (RSM) and Adaptive-Network-based Fuzzy Inference System (ANFIS) to enhance model performance. The Bagging algorithm demonstrated superior performance with an accuracy of 88%, sensitivity of 74%, and F-criterion of 78%. The integration of RSM and ANFIS further showed that a smart model could be developed for efficient pandemic crisis management, achieving up to 100% accuracy when considering key factors like AST, Albumin, and CRP. The findings suggest that Bagging and hybrid data mining algorithms can significantly improve COVID-19 detection, reducing time and errors in identifying exposed individuals. The study highlights the potential of combining machine learning techniques with RSM-ANFIS models for effective pandemic management and decision-making in medical settings.},
  archive      = {J_SOCO},
  author       = {Saidi, Mohammad and Gheibi, Mohammad and Ghazikhani, Adel and Lotfata, Aynaz and Chahkandi, Benyamin and Familsamavati, Sajad and Behzadian, Kourosh},
  doi          = {10.1007/s00500-025-10538-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1437-1451},
  shortjournal = {Soft Comput.},
  title        = {Efficient COVID-19 detection using data mining algorithms: A comparison of basic and hybrid approaches},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging variant of CAE with sparse convolutional
embedding and two-stage application-driven data augmentation for image
clustering. <em>SOCO</em>, <em>29</em>(3), 1419–1435. (<a
href="https://doi.org/10.1007/s00500-025-10500-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep clustering approaches often struggle with redundant feature learning, which limits their effectiveness. The primary goal of this study is to address these issues by developing a more robust deep clustering method. To achieve this, we propose a variant of the convolutional autoencoder (CAE) called SCDAC, which incorporates sparse convolutional embedding and a two-stage application-driven data augmentation approach. The proposed model operates in two main stages: pretraining and finetuning. In the pretraining stage, we employ application-driven data augmentation to train the CAE variant, focusing on learning robust features and constructing a foundational feature space using sparse convolutional embedding. During the finetuning stage, the model performs joint feature learning and cluster assignment. The feature learning task utilizes an augmented framework to control the input of both original and augmented data, preserving the local structure of images in the feature space. For cluster assignment, the framework controls the input of original data and uses the sparse convolutional embedding layer to obtain low-dimensional representations for soft cluster assignment. Experimental evaluations on six publicly available datasets demonstrate the effectiveness of the proposed model, with significant improvements in accuracy, particularly increases of $$3\%$$ and $$10.3\%$$ on the COIL20 and ORL datasets, respectively. In conclusion, our findings underscore the significance of the SCDAC approach in enhancing deep image clustering performance, offering a viable solution to the limitations of existing methods.},
  archive      = {J_SOCO},
  author       = {Liu, Yanming and Liu, Jinglei},
  doi          = {10.1007/s00500-025-10500-7},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1419-1435},
  shortjournal = {Soft Comput.},
  title        = {Leveraging variant of CAE with sparse convolutional embedding and two-stage application-driven data augmentation for image clustering},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chatgpt and operations research: Evaluation on the shortest
path problem. <em>SOCO</em>, <em>29</em>(3), 1407–1418. (<a
href="https://doi.org/10.1007/s00500-025-10505-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ChatGPT tool, the large language model developed by OpenAI, is having a great impact among users, experts and scholars for its capabilities of answering questions and retrieving solutions automatically. Despite the short time since its release, it has already been employed in several application domains. However, to the best of our knowledge, it has not been studied in the field of operation research (OR). In this paper, we use ChatGPT to define solution strategies for addressing several variants of the shortest path problem. The results obtained by executing the solution approaches returned by the tool are compared, in terms of correctness and efficiency, to reference codes. They indicate that the proper utilization of this tool could represent a good aid for domain experts. In particular, the outputs provided by ChatGPT could represent not only a good base for more complex implementations, but also they represent a way to facilitate some tasks in order to reduce times to do certain activities, which in any case must involve human control, adaptation and supervision.},
  archive      = {J_SOCO},
  author       = {Luzzi, Martina and Guerriero, Francesca and Maratea, Marco and Greco, Gianluigi and Garofalo, Marco},
  doi          = {10.1007/s00500-025-10505-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1407-1418},
  shortjournal = {Soft Comput.},
  title        = {Chatgpt and operations research: Evaluation on the shortest path problem},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using past sample means in exponential ratio and regression
type estimators under a simple random sampling. <em>SOCO</em>,
<em>29</em>(3), 1389–1406. (<a
href="https://doi.org/10.1007/s00500-025-10408-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Statistical sampling commonly employs auxiliary variables for the selection and estimation phases to improve efficiency of the estimators. However, existing estimators like ratio and product types display limitations under specific conditions. Regression-type estimators, known for their unbiasedness and efficiency, rely solely on current sample information. This highlights the need for more effective estimators capable of leveraging both past and current sample means to improve accuracy and applicability across diverse datasets. In this study, we introduce two novel memory-type estimators, drawing inspiration from Noor-ul-Amin&#39;s (2020) approach, which integrates past and current sample information using Hybrid Exponentially Weighted Moving Averages (HEWMA), particularly effective for time-based surveys. Through simulation studies and real data examples, we evaluate the performance of our estimators and identify crucial shortcomings in previous memory-type estimator studies. Furthermore, we highlight significant deficits in previous studies, particularly concerning the impact of sample sizes based on past means, correlation, number of past means, weight parameters and initial values of EWMA and HEWMA algorithms, and the distribution shape of the data on estimator efficiency. Our findings underscore the importance of parameter selection in HEWMA, a greater number of past means, and the significance of past sample sizes for optimizing the performance of the proposed memory-type estimators. By integrating HEWMA, our approach enhances the efficiency and applicability of these estimators, addressing essential gaps in the existing literature and laying the groundwork for more robust and efficient estimation techniques for future studies that use mean.},
  archive      = {J_SOCO},
  author       = {Koçyiğit, Eda Gizem},
  doi          = {10.1007/s00500-025-10408-2},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1389-1406},
  shortjournal = {Soft Comput.},
  title        = {Using past sample means in exponential ratio and regression type estimators under a simple random sampling},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable selection of multiple types of data: A PLS
approach. <em>SOCO</em>, <em>29</em>(3), 1369–1387. (<a
href="https://doi.org/10.1007/s00500-025-10531-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of data collection techniques in recent years, multiple types of data have emerged, including scalar data, functional data (curve-like), and compositional data (pie-like). While existing studies propose predictive models for multiple-type of data, few address the issue of variable selection. The challenge lies in the fact that different data types originate from different vector spaces, making it difficult to conduct variable selection at the variable level instead of selection at their sub-component level. This study leverages the group selection ability of gPLS (group Partial Least Squares) and gsPLS (group sparse Partial Least Squares) by regarding the functional and compositional variables as natural groups and proposes two variable selection approaches, named MD-gPLS and MD-gsPLS, after building a vector space for multiple types of data. Numerical studies and real-world examples verify the effectiveness of the proposed approaches. This study broadens the statistical modeling tools of multiple types of data analysis in terms of variable selection and also contributes to the literature by introducing the vector space of multiple types of data.},
  archive      = {J_SOCO},
  author       = {Kong, Boao and Wang, Huiwen and Lu, Shan},
  doi          = {10.1007/s00500-025-10531-0},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1369-1387},
  shortjournal = {Soft Comput.},
  title        = {Variable selection of multiple types of data: A PLS approach},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictor–corrector approach for the numerical solution of
fuzzy fractional differential equations and linear multiterm fuzzy
fractional equations. <em>SOCO</em>, <em>29</em>(3), 1347–1368. (<a
href="https://doi.org/10.1007/s00500-025-10401-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the modeling of fuzzy fractional differential equations (FFDEs) has been a very significant issue in many new applications in applied sciences and engineering, while a natural tool for modeling such dynamical systems is to use fuzzy fractional differential equations. We establish the existence and uniqueness of solutions for fuzzy fractional differential equations under sufficient assumptions and contraction principles and study numerical solutions of FFDEs. Our study is based on Caputo’s generalized Hukuhara differentiability. By applying Schauder’s fixed point theorem and a hypothetical condition, we explore the existence of the solutions. In addition, we show the uniqueness of the system&#39;s solution by using the contraction mapping theorem. We analyze the predictor–corrector approach (PCA) for FFDEs and multiterm FFDEs. We utilize the PCA to find the approximate solutions to linear multiterm FFDEs under the Caputo fuzzy derivative. After that, we present numerical solutions to initial value problems for solving two families of fuzzy fractional problems: fuzzy fractional differential equations (FFDEs) and multiterm fuzzy fractional differential equations (MFFDEs) utilizing the PCA. The method used in this paper has several advantages; first, it is significant and yields stable results without diverging as well as its ability to solve other mathematical, physical, and engineering problems; second, it is higher accuracy, needs less effort to achieve the results and works to reduces the error between exact and approximate solutions, as depicted in the utilized figures and tables. Finally, the accuracy of our suggested approach is demonstrated by solving some specific examples and analyzing the figures and tables, along with several suggestions for future research directions.},
  archive      = {J_SOCO},
  author       = {Al-Sadi, Wadhah and Wei, Zhouchao and Moroz, Irene and Abu Arqub, Omar and Abdullah, Tariq Q. S.},
  doi          = {10.1007/s00500-025-10401-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1347-1368},
  shortjournal = {Soft Comput.},
  title        = {Predictor–corrector approach for the numerical solution of fuzzy fractional differential equations and linear multiterm fuzzy fractional equations},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new approach data processing: Density-based spatial
clustering of applications with noise (DBSCAN) clustering using
game-theory. <em>SOCO</em>, <em>29</em>(3), 1331–1346. (<a
href="https://doi.org/10.1007/s00500-025-10405-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the unpredictable growth of data in various fields, rapid clustering of big data is seriously needed in order to identify the hidden structure of data and discover the relationships between objects. Among clustering methods, density-based clustering methods have an acceptable processing speed for dealing with big data with high dimensions. However, some methods have fixed parameters that are certainly not optimized for all sections. In addition, the complexity of these clustering methods strongly depends on the number of objects. In this paper, a clustering method is presented in order to increase clustering performance and parameter sensitivity according to game-theory and using the concept of Nash equilibrium and dense games, the optimal parameter for clustering is selected and between noise and points clusters make a difference. This method includes (1) searching the grid with several spaces in which there is no cluster, (2) identifying the player through high density data points in order to determine the parameters and (3) combining the clusters to make the game and (4) merging the nearby clusters. The performance of the proposed method was evaluated in four big synthetic datasets, eight real datasets labeled and unlabeled. The obtained results indicate the superiority of the proposed method over SOM, K-means, DBSCAN, SCGPSC methods in terms of accuracy and purity in processing time.},
  archive      = {J_SOCO},
  author       = {Kazemi, Uranus and Soleimani, Seyfollah},
  doi          = {10.1007/s00500-025-10405-5},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1331-1346},
  shortjournal = {Soft Comput.},
  title        = {A new approach data processing: Density-based spatial clustering of applications with noise (DBSCAN) clustering using game-theory},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arithmetic optimization algorithm with cosine
transform-based two-dimensional composite chaotic mapping.
<em>SOCO</em>, <em>29</em>(3), 1289–1329. (<a
href="https://doi.org/10.1007/s00500-025-10412-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The arithmetic optimization algorithm (AOA) is a newly developed meta-heuristic algorithm that draws inspiration from the combination of arithmetic operations. Since many scholars have widely used traditional one-dimensional chaotic mapping at home and abroad in function optimization, the AOA based on cosine transform two-dimensional composite chaotic mapping is proposed. Firstly, seven two-dimensional chaotic mappings are proposed to be embedded into the MOA and MOP in AOA. Secondly, one-dimensional chaotic systems based on the cosine transform are put forward. Then the proposed chaotic system based on the cosine transform is combined with the two-dimensional chaotic mapping to form the cosine transformed two-dimensional composite chaotic mapping. Finally, six more cosine transformed two-dimensional composite chaotic mappings are embedded into the MOA and MOP of the AOA to balance the algorithm&#39;s global and local searching ability and improve the algorithm&#39;s performance. The superiority of the improved algorithm is verified by employing 12 benchmark test functions in CEC2022. Then it is compared with the Coati Optimization Algorithm (COA), Prairie Dog Optimization (PDO), Butterfly Optimization Algorithm (BOA), Reptile Search Algorithm (RSA), Bat Algorithm (BAT), and Rat Swarm Optimization (RSO) to verify its convergence. Finally, four engineering design problems (tension/compression spring problem, pressure vessel problem, cantilever beam design problem, and slotted bulkhead design problem) were optimized to validate the efficiency of the improved algorithm. The simulation experiments demonstrate that the improved AOA exhibits superior performance in addressing both function and engineering optimization problems. It showcases remarkable optimization capabilities and improves convergence accuracy.},
  archive      = {J_SOCO},
  author       = {Li, Yi-Xuan and Wang, Jie-Sheng and Zhang, Si-Wen and Zhang, Shi-Hui and Guan, Xin-Yi and Ma, Xin-Ru},
  doi          = {10.1007/s00500-025-10412-6},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1289-1329},
  shortjournal = {Soft Comput.},
  title        = {Arithmetic optimization algorithm with cosine transform-based two-dimensional composite chaotic mapping},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Some new construction methods of similarity measure on
picture fuzzy sets. <em>SOCO</em>, <em>29</em>(3), 1273–1287. (<a
href="https://doi.org/10.1007/s00500-025-10536-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Picture fuzzy sets address problems characterized by ambiguity, instability and inconsistent data. Similarity measures on picture fuzzy sets play an indispensable role in determining the relationships between two such sets. Consequently, the study of similarity measures for picture fuzzy sets has garnered significant attention from scholars, yielding fruitful results. Notably, the existing research on picture fuzzy set similarity has mainly focused on overcoming the limitations of certain existing similarity measures by proposing one or a few new ones, ignoring the construction methods for similarity measures. Therefore, this paper presents two novel construction methods for similarity measures on picture fuzzy sets. The first approach combines the differences among positive membership, neutral membership, negative membership, and refusal membership within picture fuzzy sets using a strictly monotonically decreasing function. Remarkably, this method not only integrates existing similarity measures but also generates novel ones, providing a unified framework for both. The second method employs a strictly decreasing binary function to aggregate the distance measures between two picture fuzzy sets. By varying the binary function and distance measures, we obtain a range of novel similarity measures. Additionally, we apply the newly developed similarity measures to pattern recognition and compare their performance against existing measures. Based on the identification results, it is evident that these novel similarity measures yield reasonable outcomes and exhibit a high degree of reliability.},
  archive      = {J_SOCO},
  author       = {Luo, Minxia and Gao, Jianlei and Li, Wenling},
  doi          = {10.1007/s00500-025-10536-9},
  journal      = {Soft Computing},
  month        = {2},
  number       = {3},
  pages        = {1273-1287},
  shortjournal = {Soft Comput.},
  title        = {Some new construction methods of similarity measure on picture fuzzy sets},
  volume       = {29},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
