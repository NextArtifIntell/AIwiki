<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NPL_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="npl---13">NPL - 13</h2>
<ul>
<li><details>
<summary>
(2025). Character-level encoding based neural machine translation
for hindi language. <em>NPL</em>, <em>57</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s11063-025-11718-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Machine Translation (NMT) is one step ahead of traditional statistical phrase-based translation systems because of its better translation ability. But it requires a large amount of parallel training data, which can be challenging for languages with limited resources like many Indian languages. In the past, researchers have tried to address the issue using data augmentation. In this paper, we present a data augmentation technique for the Hindi language based on five phrases: noun phrases, verb phrases, prepositional phrases, adjective phrases, and adverb phrases. We augment the training corpus using parser-generated phrasal segments and evaluate the efficiency of the proposed work on the Hindi language. Further, the paper presents training in the NMT model at the character level instead of the word level. This approach can help overcome challenges associated with word-level translations, such as handling rare and out-of-vocabulary words and phrases, dealing with morphological complexity, and addressing languages with ambiguous word boundaries. The proposed work was evaluated on a low-resource language pair, Hindi-English, using the Google Transformer model as the baseline state-of-the-art. The experiments used two distinct datasets: WMT14 Hin-Eng and Samanantar Hin-Eng parallel corpus with character-level encoding for the translation task. The proposed model is able to surpass the cutting-edge baseline and saw an increase in BLEU scores for the WMT14 translation challenge with +2.52 on base paper using three phrase sentences with character-level encoding and +2.68 BLEU Score on base paper using five phrase sentences with character-level encoding. Further, character-level encoding is evaluated on non-augmented Samanantar dataset; it performs better in the baseline approach for translation purposes. It clearly shows that the proposed model outperforms in Hindi language translation.},
  archive      = {J_NPL},
  author       = {Rathod, Divya and Yadav, Arun Kumar and Kumar, Mohit and Yadav, Divakar},
  doi          = {10.1007/s11063-025-11718-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Character-level encoding based neural machine translation for hindi language},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTIEA: Ontology-enhanced triple intrinsic-correlation for
cross-lingual entity alignment. <em>NPL</em>, <em>57</em>(2), 1–19. (<a
href="https://doi.org/10.1007/s11063-025-11723-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-lingual and cross-domain knowledge alignment without sufficient external resources is a fundamental and crucial task for fusing irregular message. Aiming to discover equivalent objects from different knowledge graphs (KGs), embedding-based entity alignment (EA) has been attracting great interest from industry and academic research recently. Most of related methods usually explore the correlation between entities and relations through neighbor nodes, structural information and external resources. However, the complex intrinsic interactions among triple elements and role information are rarely modeled, which leads to the inadequate illustration. In addition, external resources are unavailable in some scenarios especially cross-lingual and cross-domain applications, which reflects the weak scalability. To tackle the above insufficiency, a novel universal EA framework (OTIEA) based on ontology pair and role enhancement mechanism via triple-aware attention is proposed in this paper without introducing external resources. Specifically, an ontology-enhanced triple encoder is designed via mining intrinsic correlations and ontology pair information instead of independent elements. In addition, the EA-oriented representations can be obtained in triple-aware entity decoder by fusing role diversity. Finally, a bidirectional iterative alignment strategy is deployed to expand seed entity pairs. The experimental results on three real-world datasets show that our framework achieves a competitive performance compared with baselines.},
  archive      = {J_NPL},
  author       = {Zhang, Zhishuo and Tan, Chengxiang and Yang, Min and Zhao, Xueyan},
  doi          = {10.1007/s11063-025-11723-3},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {OTIEA: Ontology-enhanced triple intrinsic-correlation for cross-lingual entity alignment},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedDefense: A defense mechanism for dishonest client attacks
in federated learning. <em>NPL</em>, <em>57</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s11063-025-11724-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL), which allows multiple participants to co-train machine learning models, enhances privacy-preserving by avoiding exposing local data. In recent years, FL has been considered a promising paradigm. However, during the FL process, individual clients may fall out on the client’s side, or a particular client may engage in dishonest behavior such as uploading malicious data, thereby hindering the training of the global model. Most of the existing defense methods are considered only from the perspective of data filtering or model weighting, which have the disadvantages of poor robustness and high computational cost. Therefore, we propose a novel security FL (FedDefense) scheme based on client selection and adaptive rewards to defend against dishonest client attacks. First, to reduce the likelihood of poisoned clients participating in aggregation, we design a randomized subset method for client contribution evaluation via Kullback–Leibler (KL) divergence. Second, we reduce the server’s dependence on clients through a dynamic reward strategy to ensure healthy model training. Numerical analysis and performance evaluation show that the proposed technique prevents the threat of dishonest clients during FL processing. Compared with existing methods, our approach has significant advantages in terms of efficiency and performance.},
  archive      = {J_NPL},
  author       = {Yue, Gaofeng and Han, Xiaowei},
  doi          = {10.1007/s11063-025-11724-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {FedDefense: A defense mechanism for dishonest client attacks in federated learning},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal aspect-based sentiment analysis with external
knowledge and multi-granularity image-text features. <em>NPL</em>,
<em>57</em>(2), 1–34. (<a
href="https://doi.org/10.1007/s11063-025-11737-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal aspect-based sentiment analysis (MABSA) is an essential task in the field of sentiment analysis, which still confronts several critical challenges. The first challenge is how to effectively capture key information within both image and text features to enhance the recognition and understanding of complex sentiment expressions. The second challenge is how to achieve cross-modal alignment of multi-granularity text features and image features. The third challenge is how to narrow the semantic gap between image modality and text modality through effective cross-modal feature fusion. To address these issues, a framework that leverages external knowledge and multi-granularity image and text features (EKMG) is proposed. Firstly, an external knowledge enhanced semantic extraction module is introduced to fuse external knowledge with image features and text features, thereby capturing the key information from texts and images. Secondly, we design a multi-granularity image-text contrastive learning module. This module initially introduces a graph attention network and a novel cross-modal fusion mechanism to align image features and text features at multiple granularities. Additionally, the module employs an image-text contrastive learning strategy to narrow the semantic gap between different modalities. Experimental results on two public benchmark datasets demonstrate that EKMG achieves significant performance improvements compared to state-of-the-art baseline models.},
  archive      = {J_NPL},
  author       = {Liu, Zhanghui and Lin, Jiali and Chen, Yuzhong and Dong, Yu},
  doi          = {10.1007/s11063-025-11737-x},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-34},
  shortjournal = {Neural Process. Lett.},
  title        = {Multimodal aspect-based sentiment analysis with external knowledge and multi-granularity image-text features},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved condition for ISS of stochastic memristive fuzzy
cohen–grossberg BAM neural networks with time-varying delays.
<em>NPL</em>, <em>57</em>(2), 1–34. (<a
href="https://doi.org/10.1007/s11063-025-11739-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of this paper is to conduct a comprehensive investigation into the model of a memristive fuzzy Cohen–Grossberg bidirectional associative memory neural network (MFCGBAMNN) that integrates time-varying delays and stochastic disturbances. This study aims to introduce an innovative approach for addressing the input-to-state stability (ISS) property within this intricate framework. To enhance the understanding of ISS characteristics in these networks, we develop a Lyapunov–Krasovskii function that is instrumental in analyzing stability amidst time-varying delays and stochastic disturbances, serving as a cornerstone for deriving sufficient conditions for ISS. In distinguishing this work from existing studies, we establish a stability analytical framework grounded in the Lyapunov–Krasovskii function. By employing non-smooth analysis techniques and stochastic analysis theory, we derive novel sufficient conditions for ISS. This methodology is particularly relevant to the complexities introduced by stochastic disturbances in the dynamics of neural networks. Moreover, the incorporation of set-valued maps in our analysis provides a solid framework for addressing the uncertainties inherent in memristive systems, thereby enhancing the reliability of the stability conditions derived. To substantiate our theoretical findings, we present two numerical examples that effectively demonstrate the applicability and efficacy of the proposed conditions.},
  archive      = {J_NPL},
  author       = {Santhosh Kumar, S. and Chandrasekar, A.},
  doi          = {10.1007/s11063-025-11739-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-34},
  shortjournal = {Neural Process. Lett.},
  title        = {Improved condition for ISS of stochastic memristive fuzzy Cohen–Grossberg BAM neural networks with time-varying delays},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel non-iterative training method for CNN classifiers
using gram–schmidt process. <em>NPL</em>, <em>57</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s11063-025-11741-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks have become prominent machine learning models, particularly in the realm of computer vision, due to their ability to predict and extract robust features from raw image data. CNNs, similar to other neural network models, undergo training via backpropagation, an iterative technique. However, the backpropagation algorithm has notable challenges, including slow convergence, susceptibility to local minima, and hypersensitivity to learning rates. These challenges not only impact the model’s accuracy but also make the training process computationally intensive. To address these limitations, We introduce a novel approach that trains the CNN classifier using a non-iterative learning method. The proposed approach involves automatic extraction of pertinent features from the raw-data, followed by the application of Gram–Schmidt process to decompose the feature matrix and determine classifier’s weights. The proposed method has shown enhanced predictive accuracy over state-of-the-art models when evaluated on two benchmark datasets, MNIST and CIFAR-10. The extensive experimentation using most cited pre-trained experiments validate the effectiveness of our proposed method.},
  archive      = {J_NPL},
  author       = {Azam, Basim and Kuttichira, Deepthi and Sanjeewani, Pubudu and Verma, Brijesh and Rahman, Ashfaqur and Wang, Lipo},
  doi          = {10.1007/s11063-025-11741-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {A novel non-iterative training method for CNN classifiers using Gram–Schmidt process},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving text classification on deep neural
network. <em>NPL</em>, <em>57</em>(2), 1–17. (<a
href="https://doi.org/10.1007/s11063-025-11738-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of Internet information, the classification of massive Internet data plays a very important role in real life. Text classification has been widely used in spam text recognition, intention recognition, text matching, named entity recognition, and other fields. At present, many enterprises provide APIs for text classification for users. Users can upload their data to the cloud server deployed by service providers for analysis, and return the final classification results. However, there is a risk of user data and model leakage in this process. To solve this problem, we propose a privacy-preserving text classification scheme using CKKS fully homomorphic encryption scheme and self-attention mechanism model in the multi-party security computing scenario. Our scheme ensures that user can achieve efficient encrypted data analysis under the premise of their data security, and user must be authorized by the service provider to use the model. Finally, compared with the experimental results of the previous research on privacy text classification under fully homomorphic encryption, the implementation improves the accuracy by 7.97% at most and speed-ups 282.4 times for inference at most, and we ensure the security of the protocol participants.},
  archive      = {J_NPL},
  author       = {Li, Kunhong and Huang, Ruwei and Yang, Bo},
  doi          = {10.1007/s11063-025-11738-w},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Privacy-preserving text classification on deep neural network},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bipartite consensus in multi-agent systems: A node
decomposition approach for privacy preservation. <em>NPL</em>,
<em>57</em>(2), 1–14. (<a
href="https://doi.org/10.1007/s11063-025-11717-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The consensus control protocol of the cooperative-competitive network requires nodes to transmit their own information to the rival group, which is detrimental to the security of the information. In this paper, we propose a novel node decomposition mechanism, which can prevent the state information from being revealed during the information exchange for multi-agent systems with antagonistic interactions. For each node, one of the two subnodes takes over the role of the primitive node with cooperative neighbors, and the other one is involved in antagonistic interactions. Under this method, the connectivity and structurally balanced of the system are not changed, so it can still achieve bipartite consensus. Besides, although the initial values of the two subnodes are chosen randomly, the average of these subnodes corresponds to the original state value, ensuring precise bipartite consensus. Moreover, we also prove that the privacy of a node can be guaranteed if and only if it has a neighbor in the same group. The effectiveness of the proposed approach is demonstrated by a numerical example.},
  archive      = {J_NPL},
  author       = {Wang, Yaqi and Zhang, Yuhong and Lu, Jianquan and Zhong, Jie and Li, Bowen},
  doi          = {10.1007/s11063-025-11717-1},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-14},
  shortjournal = {Neural Process. Lett.},
  title        = {Bipartite consensus in multi-agent systems: A node decomposition approach for privacy preservation},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WACSO: Wolf crow search optimizer for convolutional neural
network hyperparameter optimization. <em>NPL</em>, <em>57</em>(2), 1–22.
(<a href="https://doi.org/10.1007/s11063-025-11740-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) experience performance and training efficiency changes according to the selection of correct hyperparameters. The research presents WACSO which combines Crow Search Optimization with Grey Wolf Optimizer to improve Convolutional Neural Networks hyperparameter selection through a hybrid metaheuristic algorithm. The hybrid algorithm WACSO uses exploration parts from CSO together with GWO exploitation mechanics to obtain optimized performance. WACSO reaches higher classification accuracy than traditional optimization algorithms when performing tests on the MNIST and CIFAR-10 datasets along with Random Search and particle swarm optimization and genetic algorithms and standalone CSO and standalone GWO. The best classification results reached 98.9% accuracy levels on MNIST along with 91.5% accuracy levels on CIFAR-10. The final outcomes of this system depend on the combination of model structure along with dataset challenges and available computational power. The investigation demonstrates that mixing algorithms drawn from nature can lead to successful CNN hyperparameter optimization. The promising outcomes of WACSO depend on multiple variables including computation expenses and sensitive parameter adjustments and universal result adaptability between different datasets and network setups. Research into WACSO should expand to involve longer evaluations across multiple datasets and various models to confirm widespread usage.},
  archive      = {J_NPL},
  author       = {Papalkar, Rahul Rajendra and Jadhav, Jayendra and Pattewar, Tareek and Thorat, Vivek and Morey, Pallavi and Deshmukh, Mayur and Jagdale, Rajkumar},
  doi          = {10.1007/s11063-025-11740-2},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {WACSO: Wolf crow search optimizer for convolutional neural network hyperparameter optimization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review: One-shot object detection methods for conditional
detection of retail and warehouse products. <em>NPL</em>,
<em>57</em>(2), 1–32. (<a
href="https://doi.org/10.1007/s11063-025-11742-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facilitating the rapid dispatch and replenishment of products is a critical task in most large warehouses. Automated systems often rely on Deep Learning based object detection methods to monitor operations. A major challenge is the significant requirement for annotated data, and the system’s difficulty in adapting to new products. In contrast, human operators can quickly learn to recognize and adapt to new products with just a single example. This survey focuses on methods that enable conditional detection using a single support example per class. We first introduce common feature fusion techniques and discuss datasets suitable for warehouse and retail products. Next, we provide a comprehensive overview of the current State-Of-The-Art in One-Shot Object Detection. We categorize these approaches based on their detectors, which identify the object’s bounding boxes and classes. Then, we delve into detailed implementations of these methods, analyzing how they leverage this innovative vision approach to improve performance. Finally, we identify promising current trends in this emerging field.},
  archive      = {J_NPL},
  author       = {Desmarescaux, Matthieu and Kaddah, Wissam and Alfalou, Ayman and Deconninck, Jean-Charles},
  doi          = {10.1007/s11063-025-11742-0},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-32},
  shortjournal = {Neural Process. Lett.},
  title        = {A review: One-shot object detection methods for conditional detection of retail and warehouse products},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image retrieval using multi-layer orientation histograms.
<em>NPL</em>, <em>57</em>(2), 1–21. (<a
href="https://doi.org/10.1007/s11063-025-11719-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various levels of feature maps extracted from the convolutional neural network models can capture multiple degrees of semantic cues in representation. However, learning the relationship between different semantic features across numerous layers can be challenging. Furthermore, existing representations cannot effectively capture the orientation cues. This paper proposes a representation method, the multi-layer orientation histogram, to address these problems. The main highlights are: (1) An iterative multi-layer integration method to combine the feature maps of various levels is suggested in this study. This method can provide discriminative characteristics based on spatial relationships. (2) An effective approach is suggested to apply Gabor filtering for detecting orientation cues. It can amplify the most dominant orientation cues and is convenient for efficiently using them in subsequent implementations. (3) The proposed representation directly captures orientation cues from each learned feature map. It can incorporate the learned deep features and orientation cues to create a more discriminative representation. Comparative experiments demonstrate that the proposed method exhibits a highly competitive performance on several benchmark datasets in terms of mean average precision. Moreover, this method can provide an effective architecture for learning discriminative global features.},
  archive      = {J_NPL},
  author       = {Li, Xiao-Peng and Liu, Guang-Hai and Lu, Fen},
  doi          = {10.1007/s11063-025-11719-z},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Image retrieval using multi-layer orientation histograms},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hydraulic-supports alignment by TD3 with segmented
experience pool. <em>NPL</em>, <em>57</em>(2), 1–22. (<a
href="https://doi.org/10.1007/s11063-025-11744-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydraulic-supports alignment is to keep the coal mining face in line and is heavily influenced by the various geological states. The experiences produced by the moving process are unbalanced, which leads to the agent not learning important knowledge from the rare samples. This paper is the first to introduce the reinforcement learning to the hydraulic-supports alignment, and establish the Markov optimal decision model by TD3 algorithm. Aiming at the imbalance issue of the experience, this paper proposes a segmented experience pool and three sampling replay mechanisms according to the characteristics of the moving process with various geological states. Experimental results show that the improved TD3, utilizing a segmented experience pool with three different replay mechanisms, could effectively identify the optimal moving policy and achieve significant convergence in cases involving both normal movement and insufficient movement of hydraulic-supports. In contrast, the TD3 performs inadequately and struggles to find the optimal policy.},
  archive      = {J_NPL},
  author       = {Yang, Yi and Dai, Yapeng and Wang, Tian and Qian, Wei},
  doi          = {10.1007/s11063-025-11744-y},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-22},
  shortjournal = {Neural Process. Lett.},
  title        = {Hydraulic-supports alignment by TD3 with segmented experience pool},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of data augmentation in domain generalization.
<em>NPL</em>, <em>57</em>(2), 1–38. (<a
href="https://doi.org/10.1007/s11063-025-11747-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most machine learning algorithms typically assume that the data distribution of the training and test sets are consistent, but this assumption often fails to hold in practical applications. Domain generalization aims to train a model using only available source data so that the model can generalize to unseen domains. Data augmentation is an important technique in domain generalization, but there are few comprehensive reviews investigating and summarizing its use in domain generalization. This study provides a comprehensive literature review of data augmentation methods in domain generalization for the first time. First, we formalize the definition of domain generalization and analyze the role of data augmentation in domain generalization. Second, we propose a new taxonomy that categorizes methods into three classes based on the augmentation objectives: domain-level, image-level, and feature-level augmentation. Third, we compare the experimental results of some data augmentation methods on three popular domain generalization datasets and discuss the characteristics and advantages of the current best methods. Fourth, we analyze the shortcomings of each category, propose the suggestions for improvements, and summarize the challenges and the future directions of data augmentation for achieving cross-domain generalization from both theoretical and practical perspectives.},
  archive      = {J_NPL},
  author       = {Zhong, Yingyi and Zhou, Wen’an and Wang, Zhixian},
  doi          = {10.1007/s11063-025-11747-9},
  journal      = {Neural Processing Letters},
  month        = {4},
  number       = {2},
  pages        = {1-38},
  shortjournal = {Neural Process. Lett.},
  title        = {A survey of data augmentation in domain generalization},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
