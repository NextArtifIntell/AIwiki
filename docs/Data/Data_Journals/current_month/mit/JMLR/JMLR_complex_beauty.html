<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JMLR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jmlr---34">JMLR - 34</h2>
<ul>
<li><details>
<summary>
(2025). Gsplat: An open-source library for gaussian splatting.
<em>JMLR</em>, <em>26</em>(34), 1–17. (<a
href="https://jmlr.org/papers/v26/24-1476.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {gsplat is an open-source library designed for training and developing Gaussian Splatting methods. It features a front-end with Python bindings compatible with the PyTorch library and a back-end with highly optimized CUDA kernels. gsplat offers numerous features that enhance the optimization of Gaussian Splatting models, which include optimization improvements for speed, memory, and convergence times. Experimental results demonstrate that gsplat achieves up to 10% less training time and 4x less memory than the original implementation. Utilized in several research projects, gsplat is actively maintained on GitHub. Source code is available at https://github.com/nerfstudio-project/gsplat under Apache License 2.0. We welcome contributions from the open-source community.},
  archive      = {J_JMLR},
  author       = {Vickie Ye and Ruilong Li and Justin Kerr and Matias Turkulainen and Brent Yi and Zhuoyang Pan and Otto Seiskari and Jianbo Ye and Jeffrey Hu and Matthew Tancik and Angjoo Kanazawa},
  journal      = {Journal of Machine Learning Research},
  number       = {34},
  pages        = {1-17},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Gsplat: An open-source library for gaussian splatting},
  url          = {https://jmlr.org/papers/v26/24-1476.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Statistical inference of constrained stochastic optimization
via sketched sequential quadratic programming. <em>JMLR</em>,
<em>26</em>(33), 1–75. (<a
href="https://jmlr.org/papers/v26/24-0530.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider online statistical inference of constrained stochastic nonlinear optimization problems. We apply the Stochastic Sequential Quadratic Programming (StoSQP) method to solve these problems, which can be regarded as applying second-order Newton&#39;s method to the Karush-Kuhn-Tucker (KKT) conditions. In each iteration, the StoSQP method computes the Newton direction by solving a quadratic program, and then selects a proper adaptive stepsize $\bar{\alpha}_t$ to update the primal-dual iterate. To reduce dominant computational cost of the method, we inexactly solve the quadratic program in each iteration by employing an iterative sketching solver. Notably, the approximation error of the sketching solver need not vanish as iterations proceed, meaning that the per-iteration computational cost does not blow up. For the above StoSQP method, we show that under mild assumptions, the rescaled primal-dual sequence $1/\sqrt{\bar{\alpha}_t}\cdot (x_t -x^\star, \lambda_t - \lambda^\star)$ converges to a mean-zero Gaussian distribution with a nontrivial covariance matrix depending on the underlying sketching distribution. To perform inference in practice, we also analyze a plug-in covariance matrix estimator. We illustrate the asymptotic normality result of the method both on benchmark nonlinear problems in CUTEst test set and on linearly/nonlinearly constrained regression problems.},
  archive      = {J_JMLR},
  author       = {Sen Na and Michael Mahoney},
  journal      = {Journal of Machine Learning Research},
  number       = {33},
  pages        = {1-75},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Statistical inference of constrained stochastic optimization via sketched sequential quadratic programming},
  url          = {https://jmlr.org/papers/v26/24-0530.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sliced-wasserstein distances and flows on cartan-hadamard
manifolds. <em>JMLR</em>, <em>26</em>(32), 1–76. (<a
href="https://jmlr.org/papers/v26/24-0359.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While many Machine Learning methods have been developed or transposed on Riemannian manifolds to tackle data with known non-Euclidean geometry, Optimal Transport (OT) methods on such spaces have not received much attention. The main OT tool on these spaces is the Wasserstein distance, which suffers from a heavy computational burden. On Euclidean spaces, a popular alternative is the Sliced-Wasserstein distance, which leverages a closed-form solution of the Wasserstein distance in one dimension, but which is not readily available on manifolds. In this work, we derive general constructions of Sliced-Wasserstein distances on Cartan-Hadamard manifolds, Riemannian manifolds with non-positive curvature, which include among others Hyperbolic spaces or the space of Symmetric Positive Definite matrices. Then, we propose different applications such as classification of documents with a suitably learned ground cost on a manifold, and data set comparison on a product manifold. Additionally, we derive non-parametric schemes to minimize these new distances by approximating their Wasserstein gradient flows.},
  archive      = {J_JMLR},
  author       = {Clément Bonet and Lucas Drumetz and Nicolas Courty},
  journal      = {Journal of Machine Learning Research},
  number       = {32},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Sliced-wasserstein distances and flows on cartan-hadamard manifolds},
  url          = {https://jmlr.org/papers/v26/24-0359.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerating optimization over the space of probability
measures. <em>JMLR</em>, <em>26</em>(31), 1–40. (<a
href="https://jmlr.org/papers/v26/23-1288.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The acceleration of gradient-based optimization methods is a subject of significant practical and theoretical importance, particularly within machine learning applications. While much attention has been directed towards optimizing within Euclidean space, the need to optimize over spaces of probability measures in machine learning motivates the exploration of accelerated gradient methods in this context, too. To this end, we introduce a Hamiltonian-flow approach analogous to momentum-based approaches in Euclidean space. We demonstrate that, in the continuous-time setting, algorithms based on this approach can achieve convergence rates of arbitrarily high order. We complement our findings with numerical examples.},
  archive      = {J_JMLR},
  author       = {Shi Chen and Qin Li and Oliver Tse and Stephen J. Wright},
  journal      = {Journal of Machine Learning Research},
  number       = {31},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Accelerating optimization over the space of probability measures},
  url          = {https://jmlr.org/papers/v26/23-1288.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian multi-group gaussian process models for
heterogeneous group-structured data. <em>JMLR</em>, <em>26</em>(30),
1–34. (<a href="https://jmlr.org/papers/v26/23-0291.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian processes are pervasive in functional data analysis, machine learning, and spatial statistics for modeling complex dependencies. Scientific data are often heterogeneous in their inputs and contain multiple known discrete groups of samples; thus, it is desirable to leverage the similarity among groups while accounting for heterogeneity across groups. We propose multi-group Gaussian processes (MGGPs) defined over $\mathbb{R}^p\times \mathscr{C}$, where $\mathscr{C}$ is a finite set representing the group label, by developing general classes of valid (positive definite) covariance functions on such domains. MGGPs are able to accurately recover relationships between the groups and efficiently share strength across samples from all groups during inference, while capturing distinct group-specific behaviors in the conditional posterior distributions. We demonstrate inference in MGGPs through simulation experiments, and we apply our proposed MGGP regression framework to gene expression data to illustrate the behavior and enhanced inferential capabilities of multi-group Gaussian processes by jointly modeling continuous and categorical variables.},
  archive      = {J_JMLR},
  author       = {Didong Li and Andrew Jones and Sudipto Banerjee and Barbara E. Engelhardt},
  journal      = {Journal of Machine Learning Research},
  number       = {30},
  pages        = {1-34},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayesian multi-group gaussian process models for heterogeneous group-structured data},
  url          = {https://jmlr.org/papers/v26/23-0291.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Orthogonal bases for equivariant graph learning with
provable k-WL expressive power. <em>JMLR</em>, <em>26</em>(29), 1–35.
(<a href="https://jmlr.org/papers/v26/23-0178.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural network (GNN) models have been widely used for learning graph-structured data. Due to the permutation-invariant requirement of graph learning tasks, a basic element in graph neural networks is the invariant and equivariant linear layers. Previous work (Maron et al., 2019b) provided a maximal collection of invariant and equivariant linear layers and a simple deep neural network model, called k-IGN, for graph data defined on k-tuples of nodes. It is shown that the expressive power of k-IGN is at least as good as the k-Weisfeiler-Leman (WL) algorithm in graph isomorphism tests. However, the dimension of the invariant layer and equivariant layer is the k-th and 2k-th bell numbers, respectively. Such high complexity makes it computationally infeasible for k-IGNs with k &gt;= 3. In this paper, we show that a much smaller dimension for the linear layers is sufficient to achieve the same expressive power. We provide two sets of orthogonal bases for the linear layers, each with only 3(2^k-1)-k basis elements. Based on these linear layers, we develop neural network models GNN-a and GNN-b and show that for the graph data defined on k-tuples of data, GNN-a and GNN-b achieve the expressive power of the k-WL algorithm and the (k+1)-WL algorithm in graph isomorphism tests, respectively. In molecular prediction tasks on benchmark datasets, we demonstrate that low-order neural network models consisting of the proposed linear layers achieve better performance than other neural network models. In particular, order-2 GNN-b and order-3 GNN-a both have 3-WL expressive power, but use a much smaller basis and hence much less computation time than known neural network models.},
  archive      = {J_JMLR},
  author       = {Jia He and Maggie Cheng},
  journal      = {Journal of Machine Learning Research},
  number       = {29},
  pages        = {1-35},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Orthogonal bases for equivariant graph learning with provable k-WL expressive power},
  url          = {https://jmlr.org/papers/v26/23-0178.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal experiment design for causal effect identification.
<em>JMLR</em>, <em>26</em>(28), 1–56. (<a
href="https://jmlr.org/papers/v26/22-1516.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pearl’s do calculus is a complete axiomatic approach to learn the identifiable causal effects from observational data. When such an effect is not identifiable, it is necessary to perform a collection of often costly interventions in the system to learn the causal effect. In this work, we consider the problem of designing a collection of interventions with the minimum cost to identify the desired effect. First, we prove that this problem is NP-complete and subsequently propose an algorithm that can either find the optimal solution or a logarithmic-factor approximation of it. This is done by establishing a connection between our problem and the minimum hitting set problem. Additionally, we propose several polynomial time heuristic algorithms to tackle the computational complexity of the problem. Although these algorithms could potentially stumble on sub-optimal solutions, our simulations show that they achieve small regrets on random graphs.},
  archive      = {J_JMLR},
  author       = {Sina Akbari and Jalal Etesami and Negar Kiyavash},
  journal      = {Journal of Machine Learning Research},
  number       = {28},
  pages        = {1-56},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Optimal experiment design for causal effect identification},
  url          = {https://jmlr.org/papers/v26/22-1516.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mean aggregator is more robust than robust aggregators under
label poisoning attacks on distributed heterogeneous data.
<em>JMLR</em>, <em>26</em>(27), 1–51. (<a
href="https://jmlr.org/papers/v26/24-1307.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robustness to malicious attacks is of paramount importance for distributed learning. Existing works usually consider the classical Byzantine attacks model, which assumes that some workers can send arbitrarily malicious messages to the server and disturb the aggregation steps of the distributed learning process. To defend against such worst-case Byzantine attacks, various robust aggregators have been proposed. They are proven to be effective and much superior to the often-used mean aggregator. In this paper, however, we demonstrate that the robust aggregators are too conservative for a class of weak but practical malicious attacks, known as label poisoning attacks, where the sample labels of some workers are poisoned. Surprisingly, we are able to show that the mean aggregator is more robust than the state-of-the-art robust aggregators in theory, given that the distributed data are sufficiently heterogeneous. In fact, the learning error of the mean aggregator is proven to be order-optimal in this case. Experimental results corroborate our theoretical findings, showing the superiority of the mean aggregator under label poisoning attacks.},
  archive      = {J_JMLR},
  author       = {Jie Peng and Weiyu Li and Stefan Vlaski and Qing Ling},
  journal      = {Journal of Machine Learning Research},
  number       = {27},
  pages        = {1-51},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Mean aggregator is more robust than robust aggregators under label poisoning attacks on distributed heterogeneous data},
  url          = {https://jmlr.org/papers/v26/24-1307.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The blessing of heterogeneity in federated q-learning:
Linear speedup and beyond. <em>JMLR</em>, <em>26</em>(26), 1–85. (<a
href="https://jmlr.org/papers/v26/24-0579.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning, which exhibit a linear speedup with respect to the number of agents and near-optimal dependencies on other salient problem parameters. In the asynchronous setting, existing analyses of federated Q-learning, which adopt an equally weighted averaging of local Q-estimates, require that every agent covers the entire state-action space. In contrast, our improved sample complexity scales inverse proportionally to the minimum entry of the average stationary state-action occupancy distribution of all agents, thus only requiring the agents to collectively cover the entire state-action space, unveiling the blessing of heterogeneity. However, its sample complexity still suffers when the local trajectories are highly heterogeneous. In response, we propose a novel federated Q-learning algorithm with importance averaging, giving larger weights to more frequently visited state-action pairs, which achieves a robust linear speedup as if all trajectories are centrally processed, regardless of the heterogeneity of local behavior policies.},
  archive      = {J_JMLR},
  author       = {Jiin Woo and Gauri Joshi and Yuejie Chi},
  journal      = {Journal of Machine Learning Research},
  number       = {26},
  pages        = {1-85},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {The blessing of heterogeneity in federated Q-learning: Linear speedup and beyond},
  url          = {https://jmlr.org/papers/v26/24-0579.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Depyf: Open the opaque box of PyTorch compiler for machine
learning researchers. <em>JMLR</em>, <em>26</em>(25), 1–18. (<a
href="https://jmlr.org/papers/v26/24-0383.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PyTorch 2.x introduces a compiler designed to accelerate deep learning programs. However, for machine learning researchers, fully leveraging the PyTorch compiler can be challenging due to its operation at the Python bytecode level, making it appear as an opaque box. To address this, we introduce depyf, a tool designed to demystify the inner workings of the PyTorch compiler. depyf decompiles the bytecode generated by PyTorch back into equivalent source code and establishes connections between the code objects in the memory and their counterparts in source code format on the disk. This feature enables users to step through the source code line by line using debuggers, thus enhancing their understanding of the underlying processes. Notably, depyf is non-intrusive and user-friendly, primarily relying on two convenient context managers for its core functionality. The project is openly available at https://github.com/thuml/depyf and is recognized as a PyTorch ecosystem project at https://pytorch.org/blog/introducing-depyf.},
  archive      = {J_JMLR},
  author       = {Kaichao You and Runsheng Bai and Meng Cao and Jianmin Wang and Ion Stoica and Mingsheng Long},
  journal      = {Journal of Machine Learning Research},
  number       = {25},
  pages        = {1-18},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Depyf: Open the opaque box of PyTorch compiler for machine learning researchers},
  url          = {https://jmlr.org/papers/v26/24-0383.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The ODE method for stochastic approximation and
reinforcement learning with markovian noise. <em>JMLR</em>,
<em>26</em>(24), 1–76. (<a
href="https://jmlr.org/papers/v26/24-0100.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic approximation is a class of algorithms that update a vector iteratively, incrementally, and stochastically, including, e.g., stochastic gradient descent and temporal difference learning. One fundamental challenge in analyzing a stochastic approximation algorithm is to establish its stability, i.e., to show that the stochastic vector iterates are bounded almost surely. In this paper, we extend the celebrated Borkar-Meyn theorem for stability from the Martingale difference noise setting to the Markovian noise setting, which greatly improves its applicability in reinforcement learning, especially in those off-policy reinforcement learning algorithms with linear function approximation and eligibility traces. Central to our analysis is the diminishing asymptotic rate of change of a few functions, which is implied by both a form of the strong law of large numbers and a form of the law of the iterated logarithm.},
  archive      = {J_JMLR},
  author       = {Shuze Daniel Liu and Shuhang Chen and Shangtong Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {24},
  pages        = {1-76},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {The ODE method for stochastic approximation and reinforcement learning with markovian noise},
  url          = {https://jmlr.org/papers/v26/24-0100.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving graph neural networks on multi-node tasks with the
labeling trick. <em>JMLR</em>, <em>26</em>(23), 1–44. (<a
href="https://jmlr.org/papers/v26/23-0560.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study using graph neural networks (GNNs) for multi-node representation learning, where a representation for a set of more than one node (such as a link) is to be learned. Existing GNNs are mainly designed to learn single-node representations. When used for multi-node representation learning, a common practice is to directly aggregate the single-node representations obtained by a GNN. In this paper, we show a fundamental limitation of such an approach, namely the inability to capture the dependence among multiple nodes in the node set. A straightforward solution is to distinguish target nodes from others. Formalizing this idea, we propose \text{labeling trick}, which first labels nodes in the graph according to their relationships with the target node set before applying a GNN and then aggregates node representations obtained in the labeled graph for multi-node representations. Besides node sets in graphs, we also extend labeling tricks to posets, subsets and hypergraphs. Experiments verify that the labeling trick technique can boost GNNs on various tasks, including undirected link prediction, directed link prediction, hyperedge prediction, and subgraph prediction. Our work explains the superior performance of previous node-labeling-based methods and establishes a theoretical foundation for using GNNs for multi-node representation learning.},
  archive      = {J_JMLR},
  author       = {Xiyuan Wang and Pan Li and Muhan Zhang},
  journal      = {Journal of Machine Learning Research},
  number       = {23},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Improving graph neural networks on multi-node tasks with the labeling trick},
  url          = {https://jmlr.org/papers/v26/23-0560.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Directed cyclic graphs for simultaneous discovery of
time-lagged and instantaneous causality from longitudinal data using
instrumental variables. <em>JMLR</em>, <em>26</em>(22), 1–62. (<a
href="https://jmlr.org/papers/v26/23-0272.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of causal discovery from longitudinal observational data. We develop a novel framework that simultaneously discovers the time-lagged causality and the possibly cyclic instantaneous causality. Under common causal discovery assumptions, combined with additional instrumental information typically available in longitudinal data, we prove the proposed model is generally identifiable. To the best of our knowledge, this is the first causal identification theory for directed graphs with general cyclic patterns that achieves unique causal identifiability. Structural learning is carried out in a fully Bayesian fashion. Through extensive simulations and an application to the Women&#39;s Interagency HIV Study, we demonstrate the identifiability, utility, and superiority of the proposed model against state-of-the-art alternative methods.},
  archive      = {J_JMLR},
  author       = {Wei Jin and Yang Ni and Amanda B. Spence and Leah H. Rubin and Yanxun Xu},
  journal      = {Journal of Machine Learning Research},
  number       = {22},
  pages        = {1-62},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Directed cyclic graphs for simultaneous discovery of time-lagged and instantaneous causality from longitudinal data using instrumental variables},
  url          = {https://jmlr.org/papers/v26/23-0272.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian sparse gaussian mixture model for clustering in
high dimensions. <em>JMLR</em>, <em>26</em>(21), 1–50. (<a
href="https://jmlr.org/papers/v26/23-0142.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the sparse high-dimensional Gaussian mixture model when the number of clusters is allowed to grow with the sample size. A minimax lower bound for parameter estimation is established, and we show that a constrained maximum likelihood estimator achieves the minimax lower bound. However, this optimization-based estimator is computationally intractable because the objective function is highly nonconvex and the feasible set involves discrete structures. To address the computational challenge, we propose a computationally tractable Bayesian approach to estimate high-dimensional Gaussian mixtures whose cluster centers exhibit sparsity using a continuous spike-and-slab prior. We further prove that the posterior contraction rate of the proposed Bayesian method is minimax optimal. The mis- clustering rate is obtained as a by-product using tools from matrix perturbation theory. The proposed Bayesian sparse Gaussian mixture model does not require pre-specifying the number of clusters, which can be adaptively estimated. The validity and usefulness of the proposed method is demonstrated through simulation studies and the analysis of a real-world single-cell RNA sequencing data set.},
  archive      = {J_JMLR},
  author       = {Dapeng Yao and Fangzheng Xie and Yanxun Xu},
  journal      = {Journal of Machine Learning Research},
  number       = {21},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayesian sparse gaussian mixture model for clustering in high dimensions},
  url          = {https://jmlr.org/papers/v26/23-0142.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularizing hard examples improves adversarial robustness.
<em>JMLR</em>, <em>26</em>(20), 1–48. (<a
href="https://jmlr.org/papers/v26/22-1428.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have validated that pruning hard-to-learn examples from training improves the generalization performance of neural networks (NNs). In this study, we investigate this intriguing phenomenon---the negative effect of hard examples on generalization---in adversarial training. Particularly, we theoretically demonstrate that the increase in the difficulty of hard examples in adversarial training is significantly greater than the increase in the difficulty of easy examples. Furthermore, we verify that hard examples are only fitted through memorization of the label in adversarial training. We conduct both theoretical and empirical analyses of this memorization phenomenon, showing that pruning hard examples in adversarial training can enhance the model&#39;s robustness. However, the challenge remains in finding the optimal threshold for removing hard examples that degrade robustness performance. Based upon these observations, we propose a new approach, difficulty proportional label smoothing (DPLS), to adaptively mitigate the negative effect of hard examples, thereby improving the adversarial robustness of NNs. Notably, our experimental result indicates that our method can successfully leverage hard examples while circumventing the negative effect.},
  archive      = {J_JMLR},
  author       = {Hyungyu Lee and Saehyung Lee and Ho Bae and Sungroh Yoon},
  journal      = {Journal of Machine Learning Research},
  number       = {20},
  pages        = {1-48},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Regularizing hard examples improves adversarial robustness},
  url          = {https://jmlr.org/papers/v26/22-1428.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random ReLU neural networks as non-gaussian processes.
<em>JMLR</em>, <em>26</em>(19), 1–31. (<a
href="https://jmlr.org/papers/v26/24-0737.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a large class of shallow neural networks with randomly initialized parameters and rectified linear unit activation functions. We prove that these random neural networks are well-defined non-Gaussian processes. As a by-product, we demonstrate that these networks are solutions to stochastic differential equations driven by impulsive white noise (combinations of random Dirac measures). These processes are parameterized by the law of the weights and biases as well as the density of activation thresholds in each bounded region of the input domain. We prove that these processes are isotropic and wide-sense self-similar with Hurst exponent 3/2. We also derive a remarkably simple closed-form expression for their autocovariance function. Our results are fundamentally different from prior work in that we consider a non-asymptotic viewpoint: The number of neurons in each bounded region of the input domain (i.e., the width) is itself a random variable with a Poisson law with mean proportional to the density parameter. Finally, we show that, under suitable hypotheses, as the expected width tends to infinity, these processes can converge in law not only to Gaussian processes, but also to non-Gaussian processes depending on the law of the weights. Our asymptotic results provide a new take on several classical results (wide networks converge to Gaussian processes) as well as some new ones (wide networks can converge to non-Gaussian processes).},
  archive      = {J_JMLR},
  author       = {Rahul Parhi and Pakshal Bohra and Ayoub El Biari and Mehrsa Pourya and Michael Unser},
  journal      = {Journal of Machine Learning Research},
  number       = {19},
  pages        = {1-31},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Random ReLU neural networks as non-gaussian processes},
  url          = {https://jmlr.org/papers/v26/24-0737.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Riemannian bilevel optimization. <em>JMLR</em>,
<em>26</em>(18), 1–44. (<a
href="https://jmlr.org/papers/v26/24-0397.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider the bilevel optimization problem on Riemannian manifolds. We inspect the calculation of the hypergradient of such problems on general manifolds and thus enable the utilization of gradient-based algorithms to solve such problems. The calculation of the hypergradient requires utilizing the notion of Riemannian cross-derivative and we inspect the properties and the numerical calculations of Riemannian cross-derivatives. Algorithms in both deterministic and stochastic settings, named respectively RieBO and RieSBO, are proposed that include the existing Euclidean bilevel optimization algorithms as special cases. Numerical experiments on robust optimization on Riemannian manifolds are presented to show the applicability and efficiency of the proposed methods.},
  archive      = {J_JMLR},
  author       = {Jiaxiang Li and Shiqian Ma},
  journal      = {Journal of Machine Learning Research},
  number       = {18},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Riemannian bilevel optimization},
  url          = {https://jmlr.org/papers/v26/24-0397.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Supervised learning with evolving tasks and performance
guarantees. <em>JMLR</em>, <em>26</em>(17), 1–59. (<a
href="https://jmlr.org/papers/v26/24-0343.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple supervised learning scenarios are composed by a sequence of classification tasks. For instance, multi-task learning and continual learning aim to learn a sequence of tasks that is either fixed or grows over time. Existing techniques for learning tasks that are in a sequence are tailored to specific scenarios, lacking adaptability to others. In addition, most of existing techniques consider situations in which the order of the tasks in the sequence is not relevant. However, it is common that tasks in a sequence are evolving in the sense that consecutive tasks often have a higher similarity. This paper presents a learning methodology that is applicable to multiple supervised learning scenarios and adapts to evolving tasks. Differently from existing techniques, we provide computable tight performance guarantees and analytically characterize the increase in the effective sample size. Experiments on benchmark datasets show the performance improvement of the proposed methodology in multiple scenarios and the reliability of the presented performance guarantees.},
  archive      = {J_JMLR},
  author       = {Verónica Álvarez and Santiago Mazuelas and Jose A. Lozano},
  journal      = {Journal of Machine Learning Research},
  number       = {17},
  pages        = {1-59},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Supervised learning with evolving tasks and performance guarantees},
  url          = {https://jmlr.org/papers/v26/24-0343.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Error estimation and adaptive tuning for unregularized
robust m-estimator. <em>JMLR</em>, <em>26</em>(16), 1–40. (<a
href="https://jmlr.org/papers/v26/24-0060.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider unregularized robust M-estimators for linear models under Gaussian design and heavy-tailed noise, in the proportional asymptotics regime where the sample size n and the number of features p are both increasing such that $p/n \to \gamma\in (0,1)$. An estimator of the out-of-sample error of a robust M-estimator is analyzed and proved to be consistent for a large family of loss functions that includes the Huber loss. As an application of this result, we propose an adaptive tuning procedure of the scale parameter $\lambda&gt;0$ of a given loss function $\rho$: choosing $\hat \lambda$ in a given interval $I$ that minimizes the out-of-sample error estimate of the M-estimator constructed with loss $\rho_\lambda(\cdot) = \lambda^2 \rho(\cdot/\lambda)$ leads to the optimal out-of-sample error over $I$. The proof relies on a smoothing argument: the unregularized M-estimation objective function is perturbed, or smoothed, with a Ridge penalty that vanishes as $n\to+\infty$, and shows that the unregularized M-estimator of interest inherits properties of its smoothed version.},
  archive      = {J_JMLR},
  author       = {Pierre C. Bellec and Takuya Koriyama},
  journal      = {Journal of Machine Learning Research},
  number       = {16},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Error estimation and adaptive tuning for unregularized robust M-estimator},
  url          = {https://jmlr.org/papers/v26/24-0060.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From sparse to dense functional data in high dimensions:
Revisiting phase transitions from a non-asymptotic perspective.
<em>JMLR</em>, <em>26</em>(15), 1–40. (<a
href="https://jmlr.org/papers/v26/23-1578.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric estimation of the mean and covariance functions is ubiquitous in functional data analysis and local linear smoothing techniques are most frequently used. Zhang and Wang (2016) explored different types of asymptotic properties of the estimation, which reveal interesting phase transition phenomena based on the relative order of the average sampling frequency per subject $T$ to the number of subjects $n$, partitioning the data into three categories: “sparse”, “semi-dense”, and “ultra-dense”. In an increasingly available high-dimensional scenario, where the number of functional variables $p$ is large in relation to $n$, we revisit this open problem from a non-asymptotic perspective by deriving comprehensive concentration inequalities for the local linear smoothers. Besides being of interest by themselves, our non-asymptotic results lead to elementwise maximum rates of $L_2$ convergence and uniform convergence serving as a fundamentally important tool for further convergence analysis when $p$ grows exponentially with $n$ and possibly $T$. With the presence of extra $\log p$ terms to account for the high-dimensional effect, we then investigate the scaled phase transitions and the corresponding elementwise maximum rates from sparse to semi-dense to ultra-dense functional data in high dimensions. We also discuss a couple of applications of our theoretical results. Finally, numerical studies are carried out to confirm the established theoretical properties.},
  archive      = {J_JMLR},
  author       = {Shaojun Guo and Dong Li and Xinghao Qiao and Yizhu Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {15},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {From sparse to dense functional data in high dimensions: Revisiting phase transitions from a non-asymptotic perspective},
  url          = {https://jmlr.org/papers/v26/23-1578.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locally private causal inference for randomized experiments.
<em>JMLR</em>, <em>26</em>(14), 1–40. (<a
href="https://jmlr.org/papers/v26/23-1401.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local differential privacy is a differential privacy paradigm in which individuals first apply a privacy mechanism to their data (often by adding noise) before transmitting the result to a curator. The noise for privacy results in additional bias and variance in their analyses. Thus it is of great importance for analysts to incorporate the privacy noise into valid inference. In this article, we develop methodologies to infer causal effects from locally privatized data under randomized experiments. First, we present frequentist estimators under various privacy scenarios with their variance estimators and plug-in confidence intervals. We show a na\&quot;ive debiased estimator results in inferior mean-squared error (MSE) compared to minimax lower bounds. In contrast, we show that using a customized privacy mechanism, we can match the lower bound, giving minimax optimal inference. We also develop a Bayesian nonparametric methodology along with a blocked Gibbs sampling algorithm, which can be applied to any of our proposed privacy mechanisms, and which performs especially well in terms of MSE for tight privacy budgets. Finally, we present simulation studies to evaluate the performance of our proposed frequentist and Bayesian methodologies for various privacy budgets, resulting in useful suggestions for performing causal inference for privatized data.},
  archive      = {J_JMLR},
  author       = {Yuki Ohnishi and Jordan Awan},
  journal      = {Journal of Machine Learning Research},
  number       = {14},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Locally private causal inference for randomized experiments},
  url          = {https://jmlr.org/papers/v26/23-1401.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating network-mediated causal effects via principal
components network regression. <em>JMLR</em>, <em>26</em>(13), 1–99. (<a
href="https://jmlr.org/papers/v26/23-1317.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a method to decompose causal effects on a social network into an indirect effect mediated by the network, and a direct effect independent of the social network. To handle the complexity of network structures, we assume that latent social groups act as causal mediators. We develop principal components network regression models to differentiate the social effect from the non-social effect. Fitting the regression models is as simple as principal components analysis followed by ordinary least squares estimation. We prove asymptotic theory for regression coefficients from this procedure and show that it is widely applicable, allowing for a variety of distributions on the regression errors and network edges. We carefully characterize the counterfactual assumptions necessary to use the regression models for causal inference, and show that current approaches to causal network regression may result in over-control bias. The method is very general, so that it is applicable to many types of structured data beyond social networks, such as text, areal data, psychometrics, images and omics.},
  archive      = {J_JMLR},
  author       = {Alex Hayes and Mark M. Fredrickson and Keith Levin},
  journal      = {Journal of Machine Learning Research},
  number       = {13},
  pages        = {1-99},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Estimating network-mediated causal effects via principal components network regression},
  url          = {https://jmlr.org/papers/v26/23-1317.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective inference with distributed data. <em>JMLR</em>,
<em>26</em>(12), 1–44. (<a
href="https://jmlr.org/papers/v26/23-0309.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When data are distributed across multiple sites or machines rather than centralized in one location, researchers face the challenge of extracting meaningful information without directly sharing individual data points. While there are many distributed methods for point estimation using sparse regression, few options are available for estimating uncertainties or conducting hypothesis tests based on the estimated sparsity. In this paper, we introduce a procedure for performing selective inference with distributed data. We consider a scenario where each local machine solves a lasso problem and communicates the selected predictors to a central machine. The central machine then aggregates these selected predictors to form a generalized linear model (GLM). Our goal is to provide valid inference for the selected GLM while reusing data that have been used in the model selection process. Our proposed procedure only requires low-dimensional summary statistics from local machines, thus keeping communication costs low and preserving the privacy of individual data sets. Furthermore, this procedure can be applied in scenarios where model selection is repeatedly conducted on randomly subsampled data sets, addressing the p-value lottery problem linked with model selection. We demonstrate the effectiveness of our approach through simulations and an analysis of a medical data set on ICU admissions.},
  archive      = {J_JMLR},
  author       = {Sifan Liu and Snigdha Panigrahi},
  journal      = {Journal of Machine Learning Research},
  number       = {12},
  pages        = {1-44},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Selective inference with distributed data},
  url          = {https://jmlr.org/papers/v26/23-0309.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-timescale gradient descent ascent algorithms for
nonconvex minimax optimization. <em>JMLR</em>, <em>26</em>(11), 1–45.
(<a href="https://jmlr.org/papers/v26/22-0863.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a unified analysis of two-timescale gradient descent ascent (TTGDA) for solving structured nonconvex minimax optimization problems in the form of $\min_x \max_{y \in Y} f(x, y)$, where the objective function $f(x, y)$ is nonconvex in $x$ and concave in $y$, and the constraint set $Y \subseteq \mathbb{R}^n$ is convex and bounded. In the convex-concave setting, the single-timescale gradient descent ascent (GDA) algorithm is widely used in applications and has been shown to have strong convergence guarantees. In more general settings, however, it can fail to converge. Our contribution is to design TTGDA algorithms that are effective beyond the convex-concave setting, efficiently finding a stationary point of the function $\Phi(\cdot) := \max_{y \in Y} f(\cdot, y)$. We also establish theoretical bounds on the complexity of solving both smooth and nonsmooth nonconvex-concave minimax optimization problems. To the best of our knowledge, this is the first systematic analysis of TTGDA for nonconvex minimax optimization, shedding light on its superior performance in training generative adversarial networks (GANs) and in other real-world application problems.},
  archive      = {J_JMLR},
  author       = {Tianyi Lin and Chi Jin and Michael I. Jordan},
  journal      = {Journal of Machine Learning Research},
  number       = {11},
  pages        = {1-45},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Two-timescale gradient descent ascent algorithms for nonconvex minimax optimization},
  url          = {https://jmlr.org/papers/v26/22-0863.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An axiomatic definition of hierarchical clustering.
<em>JMLR</em>, <em>26</em>(10), 1–26. (<a
href="https://jmlr.org/papers/v26/24-1052.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we take an axiomatic approach to defining a population hierarchical clustering for piecewise constant densities, and in a similar manner to Lebesgue integration, extend this definition to more general densities. When the density satisfies some mild conditions, e.g., when it has connected support, is continuous, and vanishes only at infinity, or when the connected components of the density satisfy these conditions, our axiomatic definition results in Hartigan&#39;s definition of cluster tree.},
  archive      = {J_JMLR},
  author       = {Ery Arias-Castro and Elizabeth Coda},
  journal      = {Journal of Machine Learning Research},
  number       = {10},
  pages        = {1-26},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {An axiomatic definition of hierarchical clustering},
  url          = {https://jmlr.org/papers/v26/24-1052.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-time training on video streams. <em>JMLR</em>,
<em>26</em>(9), 1–29. (<a
href="https://jmlr.org/papers/v26/24-0439.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior work has established Test-Time Training (TTT) as a general framework to further improve a trained model at test time. Before making a prediction on each test instance, the model is first trained on the same instance using a self-supervised task such as reconstruction. We extend TTT to the streaming setting, where multiple test instances - video frames in our case - arrive in temporal order. Our extension is online TTT: The current model is initialized from the previous model, then trained on the current frame and a small window of frames immediately before. Online TTT significantly outperforms the fixed-model baseline for four tasks, on three real-world datasets. The improvements are more than 2.2x and 1.5x for instance and panoptic segmentation. Surprisingly, online TTT also outperforms its offline variant that accesses strictly more information, training on all frames from the entire test video regardless of temporal order. This finding challenges those in prior work using synthetic videos. We formalize a notion of locality as the advantage of online over offline TTT, and analyze its role with ablations and a theory based on bias-variance trade-off.},
  archive      = {J_JMLR},
  author       = {Renhao Wang and Yu Sun and Arnuv Tandon and Yossi Gandelsman and Xinlei Chen and Alexei A. Efros and Xiaolong Wang},
  journal      = {Journal of Machine Learning Research},
  number       = {9},
  pages        = {1-29},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Test-time training on video streams},
  url          = {https://jmlr.org/papers/v26/24-0439.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive client sampling in federated learning via online
learning with bandit feedback. <em>JMLR</em>, <em>26</em>(8), 1–67. (<a
href="https://jmlr.org/papers/v26/24-0385.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the high cost of communication, federated learning (FL) systems need to sample a subset of clients that are involved in each round of training. As a result, client sampling plays an important role in FL systems as it affects the convergence rate of optimization algorithms used to train machine learning models. Despite its importance, there is limited work on how to sample clients effectively. In this paper, we cast client sampling as an online learning task with bandit feedback, which we solve with an online stochastic mirror descent (OSMD) algorithm designed to minimize the sampling variance. We then theoretically show how our sampling method can improve the convergence speed of federated optimization algorithms over the widely used uniform sampling. Through both simulated and real data experiments, we empirically illustrate the advantages of the proposed client sampling algorithm over uniform sampling and existing online learning-based sampling strategies. The proposed adaptive sampling procedure is applicable beyond the FL problem studied here and can be used to improve the performance of stochastic optimization procedures such as stochastic gradient descent and stochastic coordinate descent.},
  archive      = {J_JMLR},
  author       = {Boxin Zhao and Lingxiao Wang and Ziqi Liu and Zhiqiang Zhang and Jun Zhou and Chaochao Chen and Mladen Kolar},
  journal      = {Journal of Machine Learning Research},
  number       = {8},
  pages        = {1-67},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Adaptive client sampling in federated learning via online learning with bandit feedback},
  url          = {https://jmlr.org/papers/v26/24-0385.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A random matrix approach to low-multilinear-rank tensor
approximation. <em>JMLR</em>, <em>26</em>(7), 1–64. (<a
href="https://jmlr.org/papers/v26/24-0193.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a comprehensive understanding of the estimation of a planted low-rank signal from a general spiked tensor model near the computational threshold. Relying on standard tools from the theory of large random matrices, we characterize the large-dimensional spectral behavior of the unfoldings of the data tensor and exhibit relevant signal-to-noise ratios governing the detectability of the principal directions of the signal. These results allow to accurately predict the reconstruction performance of truncated multilinear SVD (MLSVD) in the non-trivial regime. This is particularly important since it serves as an initialization of the higher-order orthogonal iteration (HOOI) scheme, whose convergence to the best low-multilinear-rank approximation depends entirely on its initialization. We give a sufficient condition for the convergence of HOOI and show that the number of iterations before convergence tends to $1$ in the large-dimensional limit.},
  archive      = {J_JMLR},
  author       = {Hugo Lebeau and Florent Chatelain and Romain Couillet},
  journal      = {Journal of Machine Learning Research},
  number       = {7},
  pages        = {1-64},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {A random matrix approach to low-multilinear-rank tensor approximation},
  url          = {https://jmlr.org/papers/v26/24-0193.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory gym: Towards endless tasks to benchmark memory
capabilities of agents. <em>JMLR</em>, <em>26</em>(6), 1–40. (<a
href="https://jmlr.org/papers/v26/24-0043.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memory Gym presents a suite of 2D partially observable environments, namely Mortar Mayhem, Mystery Path, and Searing Spotlights, designed to benchmark memory capabilities in decision-making agents. These environments, originally with finite tasks, are expanded into innovative, endless formats, mirroring the escalating challenges of cumulative memory games such as “I packed my bag”. This progression in task design shifts the focus from merely assessing sample efficiency to also probing the levels of memory effectiveness in dynamic, prolonged scenarios. To address the gap in available memory-based Deep Reinforcement Learning baselines, we introduce an implementation within the open-source CleanRL library that integrates Transformer-XL (TrXL) with Proximal Policy Optimization. This approach utilizes TrXL as a form of episodic memory, employing a sliding window technique. Our comparative study between the Gated Recurrent Unit (GRU) and TrXL reveals varied performances across our finite and endless tasks. TrXL, on the finite environments, demonstrates superior effectiveness over GRU, but only when utilizing an auxiliary loss to reconstruct observations. Notably, GRU makes a remarkable resurgence in all endless tasks, consistently outperforming TrXL by significant margins. Website and Source Code: https://marcometer.github.io/jmlr_2024.github.io/},
  archive      = {J_JMLR},
  author       = {Marco Pleines and Matthias Pallasch and Frank Zimmer and Mike Preuss},
  journal      = {Journal of Machine Learning Research},
  number       = {6},
  pages        = {1-40},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Memory gym: Towards endless tasks to benchmark memory capabilities of agents},
  url          = {https://jmlr.org/papers/v26/24-0043.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing graph representation learning with localized
topological features. <em>JMLR</em>, <em>26</em>(5), 1–36. (<a
href="https://jmlr.org/papers/v26/23-1424.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning on graphs is a fundamental problem that can be crucial in various tasks. Graph neural networks, the dominant approach for graph representation learning, are limited in their representation power. Therefore, it can be beneficial to explicitly extract and incorporate high-order topological and geometric information into these models. In this paper, we propose a principled approach to extract the rich connectivity information of graphs based on the theory of persistent homology. Our method utilizes the topological features to enhance the representation learning of graph neural networks and achieve state-of-the-art performance on various node classification and link prediction benchmarks. We also explore the option of end-to-end learning of the topological features, i.e., treating topological computation as a differentiable operator during learning. Our theoretical analysis and empirical study provide insights and potential guidelines for employing topological features in graph learning tasks.},
  archive      = {J_JMLR},
  author       = {Zuoyu Yan and Qi Zhao and Ze Ye and Tengfei Ma and Liangcai Gao and Zhi Tang and Yusu Wang and Chao Chen},
  journal      = {Journal of Machine Learning Research},
  number       = {5},
  pages        = {1-36},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Enhancing graph representation learning with localized topological features},
  url          = {https://jmlr.org/papers/v26/23-1424.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep out-of-distribution uncertainty quantification via
weight entropy maximization. <em>JMLR</em>, <em>26</em>(4), 1–68. (<a
href="https://jmlr.org/papers/v26/23-1359.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with uncertainty quantification and out-of-distribution detection in deep learning using Bayesian and ensemble methods. It proposes a practical solution to the lack of prediction diversity observed recently for standard approaches when used out-of-distribution (Ovadia et al., 2019; Liu et al., 2021). Considering that this issue is mainly related to a lack of weight diversity, we claim that standard methods sample in &quot;over-restricted&quot; regions of the weight space due to the use of &quot;over-regularization&quot; processes, such as weight decay and zero-mean centered Gaussian priors. We propose to solve the problem by adopting the maximum entropy principle for the weight distribution, with the underlying idea to maximize the weight diversity. Under this paradigm, the epistemic uncertainty is described by the weight distribution of maximal entropy that produces neural networks &quot;consistent&quot; with the training observations. Considering stochastic neural networks, a practical optimization is derived to build such a distribution, defined as a trade-off between the average empirical risk and the weight distribution entropy. We provide both theoretical and numerical results to assess the efficiency of the approach. In particular, the proposed algorithm appears in the top three best methods in all configurations of an extensive out-of-distribution detection benchmark including more than thirty competitors.},
  archive      = {J_JMLR},
  author       = {Antoine de Mathelin and François Deheeger and Mathilde Mougeot and Nicolas Vayatis},
  journal      = {Journal of Machine Learning Research},
  number       = {4},
  pages        = {1-68},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Deep out-of-distribution uncertainty quantification via weight entropy maximization},
  url          = {https://jmlr.org/papers/v26/23-1359.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DisC2o-HD: Distributed causal inference with covariates
shift for analyzing real-world high-dimensional data. <em>JMLR</em>,
<em>26</em>(3), 1–50. (<a
href="https://jmlr.org/papers/v26/23-1254.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional healthcare data, such as electronic health records (EHR) data and claims data, present two primary challenges due to the large number of variables and the need to consolidate data from multiple clinical sites. The third key challenge is the potential existence of heterogeneity in terms of covariate shift. In this paper, we propose a distributed learning algorithm accounting for covariate shift to estimate the average treatment effect (ATE) for high-dimensional data, named DisC2o-HD. Leveraging the surrogate likelihood method, our method calibrates the estimates of the propensity score and outcome models to approximately attain the desired covariate balancing property, while accounting for the covariate shift across multiple clinical sites. We show that our distributed covariate balancing propensity score estimator can approximate the pooled estimator, which is obtained by pooling the data from multiple sites together. The proposed estimator remains consistent if either the propensity score model or the outcome regression model is correctly specified. The semiparametric efficiency bound is achieved when both the propensity score and the outcome models are correctly specified. We conduct simulation studies to demonstrate the performance of the proposed algorithm; additionally, we conduct an empirical study to present the readiness of implementation and validity.},
  archive      = {J_JMLR},
  author       = {Jiayi Tong and Jie Hu and George Hripcsak and Yang Ning and Yong Chen},
  journal      = {Journal of Machine Learning Research},
  number       = {3},
  pages        = {1-50},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {DisC2o-HD: Distributed causal inference with covariates shift for analyzing real-world high-dimensional data},
  url          = {https://jmlr.org/papers/v26/23-1254.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayes meets bernstein at the meta level: An analysis of fast
rates in meta-learning with PAC-bayes. <em>JMLR</em>, <em>26</em>(2),
1–60. (<a href="https://jmlr.org/papers/v26/23-025.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bernstein&#39;s condition is a key assumption that guarantees fast rates in machine learning. For example, under this condition, the Gibbs posterior with prior $\pi$ has an excess risk in $O(d_{\pi}/n)$, as opposed to $O(\sqrt{d_{\pi}/n})$ in the general case, where $n$ denotes the number of observations and $d_{\pi}$ is a complexity parameter which depends on the prior $\pi$. In this paper, we examine the Gibbs posterior in the context of meta-learning, i.e., when learning the prior $\pi$ from $T$ previous tasks. Our main result is that Bernstein&#39;s condition always holds at the meta level, regardless of its validity at the observation level. This implies that the additional cost to learn the Gibbs prior $\pi$, which will reduce the term $d_\pi$ across tasks, is in $O(1/T)$, instead of the expected $O(1/\sqrt{T})$. We further illustrate how this result improves on the standard rates in three different settings: discrete priors, Gaussian priors and mixture of Gaussian priors.},
  archive      = {J_JMLR},
  author       = {Charles Riou and Pierre Alquier and Badr-Eddine Chérief-Abdellatif},
  journal      = {Journal of Machine Learning Research},
  number       = {2},
  pages        = {1-60},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Bayes meets bernstein at the meta level: An analysis of fast rates in meta-learning with PAC-bayes},
  url          = {https://jmlr.org/papers/v26/23-025.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiently escaping saddle points in bilevel optimization.
<em>JMLR</em>, <em>26</em>(1), 1–61. (<a
href="https://jmlr.org/papers/v26/22-0136.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bilevel optimization is one of the fundamental problems in machine learning and optimization. Recent theoretical developments in bilevel optimization focus on finding the first-order stationary points for nonconvex-strongly-convex cases. In this paper, we analyze algorithms that can escape saddle points in nonconvex-strongly-convex bilevel optimization. Specifically, we show that the perturbed approximate implicit differentiation (AID) with a warm start strategy finds an $\epsilon$-approximate local minimum of bilevel optimization in $\tilde{O}(\epsilon^{-2})$ iterations with high probability. Moreover, we propose an inexact NEgative-curvature-Originated-from-Noise Algorithm (iNEON), an algorithm that can escape saddle point and find local minimum of stochastic bilevel optimization. As a by-product, we provide the first nonasymptotic analysis of perturbed multi-step gradient descent ascent (GDmax) algorithm that converges to local minimax point for minimax problems.},
  archive      = {J_JMLR},
  author       = {Minhui Huang and Xuxing Chen and Kaiyi Ji and Shiqian Ma and Lifeng Lai},
  journal      = {Journal of Machine Learning Research},
  number       = {1},
  pages        = {1-61},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Efficiently escaping saddle points in bilevel optimization},
  url          = {https://jmlr.org/papers/v26/22-0136.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
