<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TMLR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tmlr---102">TMLR - 102</h2>
<ul>
<li><details>
<summary>
(2025). KAGNNs: Kolmogorov-arnold networks meet graph learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=03UB1MCAMr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Graph Neural Networks (GNNs) have become the de facto tool for learning node and graph representations. Most GNNs typically consist of a sequence of neighborhood aggregation (a.k.a., message-passing) layers, within which the representation of each node is updated based on those of its neighbors. The most expressive message-passing GNNs can be obtained through the use of the sum aggregator and of MLPs for feature transformation, thanks to their universal approximation capabilities. However, the limitations of MLPs recently motivated the introduction of another family of universal approximators, called Kolmogorov-Arnold Networks (KANs) which rely on a different representation theorem. In this work, we compare the performance of KANs against that of MLPs on graph learning tasks. We implement three new KAN-based GNN layers, inspired respectively by the GCN, GAT and GIN layers. We evaluate two different implementations of KANs using two distinct base families of functions, namely B-splines and radial basis functions. We perform extensive experiments on node classification, link prediction, graph classification and graph regression datasets. Our results indicate that KANs are on-par with or better than MLPs on all tasks studied in this paper. We also show that the size and training speed of RBF-based KANs is only marginally higher than for MLPs, making them viable alternatives. Code available at https://github.com/RomanBresson/KAGNN.},
  archive      = {J_TMLR},
  author       = {Roman Bresson and Giannis Nikolentzos and George Panagopoulos and Michail Chatzianastasis and Jun Pang and Michalis Vazirgiannis},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {KAGNNs: Kolmogorov-arnold networks meet graph learning},
  url          = {https://openreview.net/forum?id=03UB1MCAMr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). No need for ad-hoc substitutes: The expected cost is a
principled all-purpose classification metric. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5PPbvCExZs">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected cost (EC) is one of the main classification metrics introduced in statistical and machine learning books. It is based on the assumption that, for a given application of interest, each decision made by the system has a corresponding cost which depends on the true class of the sample. An evaluation metric can then be defined by taking the expectation of the cost over the data. Two special cases of the EC are widely used in the machine learning literature: the error rate (one minus the accuracy) and the balanced error rate (one minus the balanced accuracy or unweighted average recall). Other instances of the EC can be useful for applications in which some types of errors are more severe than others, or when the prior probabilities of the classes differ between the evaluation data and the use-case scenario. Surprisingly, the general form for the EC is rarely used in the machine learning literature. Instead, alternative ad-hoc metrics like the F-beta score and the Matthews correlation coefficient (MCC) are used for many applications. In this work, we argue that the EC is superior to these alternative metrics, being more general, interpretable, and adaptable to any application scenario. We provide both theoretically-motivated discussions as well as examples to illustrate the behavior of the different metrics.},
  archive      = {J_TMLR},
  author       = {Luciana Ferrer},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {No need for ad-hoc substitutes: The expected cost is a principled all-purpose classification metric},
  url          = {https://openreview.net/forum?id=5PPbvCExZs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing fairness in unsupervised graph anomaly detection
through disentanglement. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5zRs34Ls3C">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph anomaly detection (GAD) is becoming increasingly crucial in various applications, ranging from financial fraud detection to fake news detection. However, current GAD methods largely overlook the fairness problem, which might result in discriminatory decisions skewed toward certain demographic groups defined on sensitive attributes (e.g., gender). This greatly limits the applicability of these methods in real-world scenarios in light of societal and ethical restrictions. To address this critical gap, we make the first attempt to integrate fairness with utility in GAD decision-making. Specifically, we devise a novel DisEntangle-based FairnEss-aware aNomaly Detection framework on the attributed graph, named DEFEND. DEFEND first introduces disentanglement in GNNs to capture informative yet sensitive-irrelevant node representations, effectively reducing bias inherent in graphrepresentation learning. Besides, to alleviate discriminatory bias in evaluating anomalies, DEFEND adopts a reconstruction-based method, which concentrates solely on node attributes and avoids incorporating biased graph topology. Additionally, given the inherent association between sensitive-relevant and -irrelevant attributes, DEFEND further constrains the correlation between the reconstruction error and predicted sensitive attributes. Empirical evaluations on real-world datasets reveal that DEFEND performs effectively in GAD and significantly enhances fairness compared to state-of-the-art baselines. Our code is available at https://github.com/AhaChang/DEFEND.},
  archive      = {J_TMLR},
  author       = {Wenjing Chang and Kay Liu and Philip S. Yu and Jianjun Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing fairness in unsupervised graph anomaly detection through disentanglement},
  url          = {https://openreview.net/forum?id=5zRs34Ls3C},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DP-2Stage: Adapting language models as differentially
private tabular data generators. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=6nBIweDYzZ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating tabular data under differential privacy (DP) protection ensures theoretical privacy guarantees but poses challenges for training machine learning models, primarily due to the need to capture complex structures under noisy supervision signals. Recently, pre-trained Large Language Models (LLMs) -- even those at the scale of GPT-2 -- have demonstrated great potential in synthesizing tabular data. However, their applications under DP constraints remain largely unexplored. In this work, we address this gap by applying DP techniques to the generation of synthetic tabular data. Our findings shows that LLMs face difficulties in generating coherent text when fine-tuned with DP, as privacy budgets are inefficiently allocated to non-private elements like table structures. To overcome this, we propose DP-2Stage, a two-stage fine-tuning framework for differentially private tabular data generation. The first stage involves non-private fine-tuning on a pseudo dataset, followed by DP fine-tuning on a private dataset. Our empirical results show that this approach improves performance across various settings and metrics compared to directly fine-tuned LLMs in DP contexts. We release our code and setup at https://github.com/tejuafonja/DP-2Stage.},
  archive      = {J_TMLR},
  author       = {Tejumade Afonja and Hui-Po Wang and Raouf Kerkouche and Mario Fritz},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DP-2Stage: Adapting language models as differentially private tabular data generators},
  url          = {https://openreview.net/forum?id=6nBIweDYzZ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-explainable heterogeneous GNN for relational deep
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8Q4qxe9a9Z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, significant attention has been given to the idea of viewing relational databases as heterogeneous graphs, enabling the application of graph neural network (GNN) technology for predictive tasks. However, existing GNN methods struggle with the complexity of the heterogeneous graphs induced by databases with numerous tables and relations. Traditional approaches either consider all possible relational meta-paths, thus failing to scale with the number of relations, or rely on domain experts to identify relevant meta-paths. A recent solution does manage to learn informative meta-paths without expert supervision, but assumes that a node’s class depends solely on the existence of a meta-path occurrence. In this work, we present a self-explainable heterogeneous GNN for relational data, that supports models in which class membership depends on aggregate information obtained from multiple occurrences of a meta-path. Experimental results show that in the context of relational databases, our approach effectively identifies informative meta-paths that faithfully capture the model’s reasoning mechanisms. It significantly outperforms existing methods in both synthetic and real-world scenarios.},
  archive      = {J_TMLR},
  author       = {Francesco Ferrini and Antonio Longa and Andrea Passerini and Manfred Jaeger},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A self-explainable heterogeneous GNN for relational deep learning},
  url          = {https://openreview.net/forum?id=8Q4qxe9a9Z},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long short-term imputer: Handling consecutive missing values
in time series. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=9NVJ0ZgEfT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encountered frequently in time series data, missing values can significantly impede time-series analysis. With the progression of deep learning, advanced imputation models delve into the temporal dependencies inherent in time series data, showcasing remarkable performance. This positions them as intuitive selections for time series imputation tasks which assume ``Miss Completely at Random&#39;&#39;. Nonetheless, long-interval consecutive missing values may obstruct the model&#39;s ability to grasp long-term temporal dependencies, consequently hampering the efficacy of imputation performance. To tackle this challenge, we propose Long Short-term Imputer (LSTI) to impute consecutive missing values with different length of intervals. Long-term Imputer is designed using the idea of bi-directional autoregression. A forward prediction model and a backward prediction model are trained with a consistency regularization, which is designed to capture long-time dependency and can adapt to long-interval consecutive missing values. Short-term Imputer is designed to capture short-time dependency and can impute the short-interval consecutive missing values effectively. A meta-weighting network is then proposed to take advantage of the strengths of two imputers. As a result, LSTI can impute consecutive missing values with different intervals effectively. Experiments demonstrate that our approach, on average, reduces the error by 57.4% compared to state-of-the-art deep models across five datasets.},
  archive      = {J_TMLR},
  author       = {Jiacheng You and Xinyang Chen and Yu Sun and Weili Guan and Liqiang Nie},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Long short-term imputer: Handling consecutive missing values in time series},
  url          = {https://openreview.net/forum?id=9NVJ0ZgEfT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The 2024 foundation model transparency index. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=38cwP8xVxD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models are increasingly consequential yet extremely opaque. To characterize the status quo, the Foundation Model Transparency Index was launched in October 2023 to measure the transparency of leading foundation model developers. The October 2023 Index (v1.0) assessed 10 major foundation model developers (e.g. OpenAI, Google) on 100 transparency indicators (e.g. does the developer disclose the wages it pays for data labor?). At the time, developers publicly disclosed very limited information with the average score being 37 out of 100. To understand how the status quo has changed, we conduct a follow-up study (v1.1) after 6 months: we score 14 developers against the same 100 indicators. While in v1.0 we searched for publicly available information, in v1.1 developers submit reports on the 100 transparency indicators, potentially including information that was not previously public. We find that developers now score 58 out of 100 on average, a 21 point improvement over v1.0. Much of this increase is driven by developers disclosing information during the v1.1 process: on average, developers disclosed information related to 16.6 indicators that was not previously public. We observe regions of sustained (i.e. across v1.0 and v1.1) and systemic (i.e. across most or all developers) opacity such as on copyright status, data access, data labor, and downstream impact. We publish transparency reports for each developer that consolidate information disclosures: these reports are based on the information disclosed to us via developers. Our findings demonstrate that transparency can be improved in this nascent ecosystem, the Foundation Model Transparency Index likely contributes to these improvements, and policymakers should consider interventions in areas where transparency has not improved.},
  archive      = {J_TMLR},
  author       = {Rishi Bommasani and Kevin Klyman and Sayash Kapoor and Shayne Longpre and Betty Xiong and Nestor Maslej and Percy Liang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The 2024 foundation model transparency index},
  url          = {https://openreview.net/forum?id=38cwP8xVxD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HARE: Human-in-the-loop algorithmic recourse. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=56EBglCFvx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are seeing increasing use as decision making systems in domains such as education, finance and healthcare. It is desirable that these models are trustworthy to the end-user, by ensuring fairness, transparency and reliability of decisions. In this work, we consider a key aspect of responsible and transparent AI models -- actionable explanations, viz. the ability of such models to provide recourse to end users adversely affected by their decisions. While algorithmic recourse has seen a variety of efforts in recent years, there have been very few efforts on exploring personalized recourse for a given user. Two users with the same feature profile may prefer vastly different recourses. The limited work in this direction hitherto rely on one-time feature preferences provided by a user. Instead, we present a human-in-the-loop formulation of algorithmic recourse that can incorporate both relative and absolute human feedback for a given test instance. We show that our formulation can extend any existing recourse generating method, enabling the generation of recourses that are satisfactory to the user. We perform experiments on 3 benchmark datasets on top of 6 popular baseline recourse methods where we observe that our framework performs significantly better on simulated user preferences.},
  archive      = {J_TMLR},
  author       = {Sai Srinivas Kancheti and Rahul Vigneswaran and Bamdev Mishra and Vineeth N. Balasubramanian},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HARE: Human-in-the-loop algorithmic recourse},
  url          = {https://openreview.net/forum?id=56EBglCFvx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolution of discriminator and generator gradients in GAN
training: From fitting to collapse. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=58gPkcVbFL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are powerful generative models but often suffer from mode mixture and mode collapse. We propose a perspective that views GAN training as a two-phase progression from fitting to collapse, where mode mixture and mode collapse are treated as inter-connected. Inspired by the particle model interpretation of GANs, we leverage the discriminator gradient to analyze particle movement and the generator gradient, specifically &quot;steepness,&quot; to quantify the severity of mode mixture by measuring the generator&#39;s sensitivity to changes in the latent space. Using these theoretical insights into evolution of gradients, we design a specialized metric that integrates both gradients to detect the transition from fitting to collapse. This metric forms the basis of an early stopping algorithm, which stops training at a point that retains sample quality and diversity. Experiments on synthetic and real-world datasets, including MNIST, Fashion MNIST, and CIFAR-10, validate our theoretical findings and demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_TMLR},
  author       = {Weiguo Gao and Ming Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evolution of discriminator and generator gradients in GAN training: From fitting to collapse},
  url          = {https://openreview.net/forum?id=58gPkcVbFL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The BrowserGym ecosystem for web agent research.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5298fKGmv3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The BrowserGym ecosystem addresses the growing need for efficient evaluation and benchmarking of web agents, particularly those leveraging automation and Large Language Models (LLMs) for web interaction tasks. Many existing benchmarks suffer from fragmentation and inconsistent evaluation methodologies, making it challenging to achieve reliable comparisons and reproducible results. In an earlier work, Drouin et al. (2024) introduced BrowserGym which aims to solve this by providing a unified, gym-like environment with well-defined observation and actionspaces, facilitating standardized evaluation across diverse benchmarks. We propose an extended BrowserGym-based ecosystem for web agent research, which unifies existing benchmarks from the literature and includes AgentLab, a complementary framework that aids in agent creation, testing, and analysis. Our proposed ecosystem offers flexibility for integrating new benchmarks while ensuring consistent evaluation and comprehensive experiment management. This standardized approach seeks to reduce the time and complexity of developing web agents, supporting more reliable comparisons and facilitating in-depth analysis of agent behaviors, and could result in more adaptable, capable agents, ultimately accelerating innovation in LLM-driven automation. As a supporting evidence, we conduct the first large-scale, multi-benchmark web agent experiment and compare the performance of 6 state-of-the-art LLMs across 6 popular web agent benchmarks made available in BrowserGym. Among other findings, our results highlight a large discrepancy between OpenAI and Anthropic’s latests models, with Claude-3.5-Sonnet leading the way on almost all benchmarks, except on vision-related tasks where GPT-4o is superior. Despite these advancements, our results emphasize that building robust and efficient web agents remains a significant challenge, due to the inherent complexity of real-world web environments and the limitations of current models.},
  archive      = {J_TMLR},
  author       = {Thibault Le Sellier de Chezelles and Maxime Gasse and Alexandre Lacoste and Massimo Caccia and Alexandre Drouin and Léo Boisvert and Megh Thakkar and Tom Marty and Rim Assouel and Sahar Omidi Shayegan and Lawrence Keunho Jang and Xing Han Lù and Ori Yoran and Dehan Kong and Frank F. Xu and Siva Reddy and Graham Neubig and Quentin Cappart and Russ Salakhutdinov and Nicolas Chapados},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The BrowserGym ecosystem for web agent research},
  url          = {https://openreview.net/forum?id=5298fKGmv3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing estimators of squared calibration errors in
classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=BPDVZajOW5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a mean-squared error-based risk that enables the comparison and optimization of estimators of squared calibration errors in practical settings. Improving the calibration of classifiers is crucial for enhancing the trustworthiness and interpretability of machine learning models, especially in sensitive decision-making scenarios. Although various calibration (error) estimators exist in the current literature, there is a lack of guidance on selecting the appropriate estimator and tuning its hyperparameters. By leveraging the bilinear structure of squared calibration errors, we reformulate calibration estimation as a regression problem with independent and identically distributed (i.i.d.) input pairs. This reformulation allows us to quantify the performance of different estimators even for the most challenging calibration criterion, known as canonical calibration. Our approach advocates for a training-validation-testing pipeline when estimating a calibration error on an evaluation dataset. We demonstrate the effectiveness of our pipeline by optimizing existing calibration estimators and comparing them with novel kernel ridge regression-based estimators on standard image classification tasks.},
  archive      = {J_TMLR},
  author       = {Sebastian Gregor Gruber and Francis R. Bach},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Optimizing estimators of squared calibration errors in classification},
  url          = {https://openreview.net/forum?id=BPDVZajOW5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lean dataset for international math olympiad: Small steps
towards writing math proofs for hard problems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CrKMqRAhBo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using AI to write formal proofs for mathematical problems is a challenging task that has seen some advancements in recent years. Automated systems such as Lean can verify the correctness of proofs written in formal language, yet writing the proofs in formal language can be challenging for humans and machines. The miniF2F benchmark has 20 IMO problems in its test set, yet formal proofs are available only for 6 of these problems (3 of which are only written by mathematicians). The model with best accuracy can only prove 2 of these 20 IMO problems, from 1950s and 60s, while its training set is a secret. In this work, we write complete, original formal proofs for the remaining IMO problems in Lean along with 3 extra problems from IMO 2022 and 2023. This effort expands the availability of proof currently in the public domain by creating 5,880 lines of Lean proof. The goal of the paper is to pave the way for developing AI models that can automatically write the formal proofs for all the IMO problems in miniF2F and beyond by providing an evaluation benchmark. In this pursuit, we devise a method to decompose the proofs of these problems into their building blocks, constructing a dataset of 1,329 lemmas with more than 40k lines of Lean code. These lemmas are not trivial, yet they are approachable, providing the opportunity to evaluate and diagnose the failures and successes of AI models. We evaluate the ability of the SOTA LLMs on our dataset and analyze their success and failure modes from different perspectives. Our dataset and code is available at: https://github.com/roozbeh-yz/IMO-Steps.},
  archive      = {J_TMLR},
  author       = {Roozbeh Yousefzadeh and Xuenan Cao},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A lean dataset for international math olympiad: Small steps towards writing math proofs for hard problems},
  url          = {https://openreview.net/forum?id=CrKMqRAhBo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual privacy auditing with diffusion models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=D3DA7pgpvn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data reconstruction attacks on machine learning models pose a substantial threat to privacy, potentially leaking sensitive information. Although defending against such attacks using differential privacy (DP) provides theoretical guarantees, determining appropriate DP parameters remains challenging. Current formal guarantees on the success of data reconstruction suffer from overly stringent assumptions regarding adversary knowledge about the target data, particularly in the image domain, raising questions about their real-world applicability. In this work, we empirically investigate this discrepancy by introducing a reconstruction attack based on diffusion models (DMs) that only assumes adversary access to real-world image priors and specifically targets the DP defense. We find that (1) real-world data priors significantly influence reconstruction success, (2) current reconstruction bounds do not model the risk posed by data priors well, and (3) DMs can serve as heuristic auditing tools for visualizing privacy leakage.},
  archive      = {J_TMLR},
  author       = {Kristian Schwethelm and Johannes Kaiser and Moritz Knolle and Sarah Lockfisch and Daniel Rueckert and Alexander Ziller},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Visual privacy auditing with diffusion models},
  url          = {https://openreview.net/forum?id=D3DA7pgpvn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Out of spuriousity: Improving robustness to spurious
correlations without group annotations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EEeVYfXor5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are known to learn spurious correlations, i.e., features that have strong correlations with class labels but no causal relationship. Relying on these correlations leads to poor performance in data groups that do not contain these correlations, and poor generalization. Approaches to mitigate spurious correlations either rely on the availability of group annotations or require access to different model checkpoints to approximate these group annotations. We propose PruSC, a method for extracting a spurious-free subnetwork from a dense network. PruSC does not require prior knowledge of the spurious correlations and is able to mitigate the effect of multiple spurious attributes. Specifically, we observe that ERM training leads to clusters in representation space that are induced by spurious correlations. We then define a supervised contrastive loss to extract a subnetwork that distorts such clusters, forcing the model to learn only class-specific clusters, rather than attribute-class specific clusters. Our method outperforms all annotation-free methods, achieves worst-group accuracy competitive with methods that require annotations and can mitigate the effect of multiple spurious correlations. Our results show that in a fully trained dense network, there exists a subnetwork that uses only invariant features in classification tasks, thereby eliminating the influence of spurious features.},
  archive      = {J_TMLR},
  author       = {Phuong Quynh Le and Jörg Schlötterer and Christin Seifert},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Out of spuriousity: Improving robustness to spurious correlations without group annotations},
  url          = {https://openreview.net/forum?id=EEeVYfXor5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal discovery over high-dimensional structured hypothesis
spaces with causal graph partitioning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FecsgPCOHk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim in many sciences is to understand the mechanisms that underlie the observed distribution of variables, starting from a set of initial hypotheses. Causal discovery allows us to infer mechanisms as sets of cause and effect relationships in a generalized way---without necessarily tailoring to a specific domain. Causal discovery algorithms search over a structured hypothesis space, defined by the set of Directed Acyclic Graphs (DAG), to find the graph that best explains the data. For high-dimensional problems, however, this search becomes intractable and scalable algorithms for causal discovery are needed to bridge the gap. In this paper, we define a novel causal graph partition that allows for divide-and-conquer causal discovery with theoretical guarantees under the Maximal Ancestral Graph (MAG) class. We leverage the idea of a superstructure---a set of learned or existing candidate hypotheses---to partition the search space. We prove under certain assumptions that learning with a causal graph partition always yields the Markov Equivalence Class of the true causal graph. We show our algorithm achieves comparable accuracy and a faster time to solution for biologically-tuned synthetic networks and networks up to ${10^4}$ variables. This makes our method applicable to gene regulatory network inference and other domains with high-dimensional structured hypothesis spaces.},
  archive      = {J_TMLR},
  author       = {Ashka Shah and Adela Frances DePavia and Nathaniel C Hudson and Ian Foster and Rick Stevens},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Causal discovery over high-dimensional structured hypothesis spaces with causal graph partitioning},
  url          = {https://openreview.net/forum?id=FecsgPCOHk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-exploring language models: Active preference
elicitation for online alignment. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FoQK84nwY3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preference optimization, particularly through Reinforcement Learning from Human Feedback (RLHF), has achieved significant success in aligning Large Language Models (LLMs) to adhere to human intentions. Unlike offline alignment with a fixed dataset, online feedback collection from humans or AI on model generations typically leads to more capable reward models and better-aligned LLMs through an iterative process. However, achieving a globally accurate reward model requires systematic exploration to generate diverse responses that span the vast space of natural language. Random sampling from standard reward-maximizing LLMs alone is insufficient to fulfill this requirement. To address this issue, we propose a bilevel objective optimistically biased towards potentially high-reward responses to actively explore out-of-distribution regions. By solving the inner-level problem with the reparameterized reward function, the resulting algorithm, named Self-Exploring Language Models (SELM), eliminates the need for a separate RM and iteratively updates the LLM with a straightforward objective. Compared to Direct Preference Optimization (DPO), the SELM objective reduces indiscriminate favor of unseen extrapolations and enhances exploration efficiency. Our experimental results demonstrate that when fine-tuned on Zephyr-7B-SFT and Llama-3-8B-Instruct models, SELM significantly boosts the performance on instruction-following benchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard academic benchmarks in different settings.},
  archive      = {J_TMLR},
  author       = {Shenao Zhang and Donghan Yu and Hiteshi Sharma and Han Zhong and Zhihan Liu and Ziyi Yang and Shuohang Wang and Hany Hassan Awadalla and Zhaoran Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Self-exploring language models: Active preference elicitation for online alignment},
  url          = {https://openreview.net/forum?id=FoQK84nwY3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variational neural stochastic differential equations with
change points. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GEilvtsFNV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we explore modeling change points in time-series data using neural stochastic differential equations (neural SDEs). We propose a novel model formulation and training procedure based on the variational autoencoder (VAE) framework for modeling time-series as a neural SDE. Unlike existing algorithms training neural SDEs as VAEs, our proposed algorithm only necessitates a Gaussian prior of the initial state of the latent stochastic process, rather than a Wiener process prior on the entire latent stochastic process. We develop two methodologies for modeling and estimating change points in time-series data with distribution shifts. Our iterative algorithm alternates between updating neural SDE parameters and updating the change points based on either a maximum likelihood-based approach or a change point detection algorithm using the sequential likelihood ratio test. We also discuss theoretical implications of the proposed change point detection scheme. Finally, we present an empirical evaluation that demonstrates the expressive power of our proposed model, showing that it can effectively model both classical parametric SDEs and some real datasets with distribution shifts.},
  archive      = {J_TMLR},
  author       = {Yousef El-Laham and Zhongchang Sun and Haibei Zhu and Tucker Balch and Svitlana Vyetrenko},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variational neural stochastic differential equations with change points},
  url          = {https://openreview.net/forum?id=GEilvtsFNV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cycle conditioning for robust representation learning from
categorical data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GkYOcbNLaW">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel diffusion-based method for learning representations from categorical data. Conditional diffusion models have demonstrated their potential to extract meaningful representations from input samples. However, they often struggle to yield versatile, general-purpose information, limiting their adaptability to unforeseen tasks. To address this, we propose a cycle conditioning approach for diffusion models, designed to capture expressive information from conditioning samples. However, cycle conditioning alone can be insufficient. Diffusion models may ignore conditioning samples that vary across training iterations, an issue that occurs within cycle conditioning. To counter this limitation, we introduce additional &quot;spelling&quot; information to guide the conditioning process, ensuring that the conditioning sample remains influential during denoising. While this supervision enhances the generalizability of extracted representations, it is constrained by the sparse nature of spelling information in categorical data, leading to sparse latent conditions. This sparsity reduces the robustness of the extracted representations for downstream tasks or as effective guidance in the diffusion process. To overcome this challenge, we propose a linear navigation strategy within the latent space of conditioning samples, allowing dense representations to be extracted even with sparse supervision. Our experiments demonstrate that our method achieves at least a 1.42\% improvement in AUROC and a 4.12\% improvement in AUCPR over the best results from existing state-of-the-art methods.},
  archive      = {J_TMLR},
  author       = {Mohsen Tabejamaat and Farzaneh Etminani and Mattias Ohlsson},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cycle conditioning for robust representation learning from categorical data},
  url          = {https://openreview.net/forum?id=GkYOcbNLaW},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalized tangent kernel: A unified geometric foundation
for natural gradient and standard gradient. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HOnL5hjaIt">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural gradients have been widely studied from both theoretical and empirical perspectives, and it is commonly believed that natural gradients have advantages over standard (Euclidean) gradients in capturing the intrinsic geometric structure of the underlying function space and being invariant under reparameterization. However, for function optimization, a fundamental theoretical issue regarding the existence of natural gradients on the function space remains underexplored. We address this issue by providing a geometric perspective and mathematical framework for studying both natural gradient and standard gradient that is more complete than existing studies. The key tool that unifies natural gradient and standard gradient is a generalized form of the Neural Tangent Kernel (NTK), which we name the Generalized Tangent Kernel (GTK). Using a novel orthonormality property of GTK, we show that for a fixed parameterization, GTK determines a Riemannian metric on the entire function space which makes the standard gradient as “natural&quot; as the natural gradient in capturing the intrinsic structure of the parameterized function space. Many aspects of this approach relate to RKHS theory. For the practical side of this theory paper, we showcase that our framework motivates new solutions to the non-immersion/degenerate case of natural gradient and leads to new families of natural/standard gradient descent methods.},
  archive      = {J_TMLR},
  author       = {Qinxun Bai and Steven Rosenberg and Wei Xu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generalized tangent kernel: A unified geometric foundation for natural gradient and standard gradient},
  url          = {https://openreview.net/forum?id=HOnL5hjaIt},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards efficient mixture of experts: A holistic study of
compression techniques. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HTpMOl6xSI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scaling large language models has driven remarkable advancements across various domains, yet the continual increase in model size presents significant challenges for real-world deployment. The Mixture of Experts (MoE) architecture offers a promising solution by dynamically selecting and activating only a subset of experts during inference, thus substantially reducing computational costs while preserving high performance. Despite these benefits, MoE introduces new inefficiencies, such as excessive parameters and communication overhead. In this work, we present a holistic study of compression techniques for Mixture of Experts to enhance both efficiency and scalability. While recent efforts have focused on Expert Trimming, which reduces the number of experts, these approaches still suffer from considerable communication and computational costs. To address this, we propose more aggressive strategies, such as Layer Drop, which removes entire MoE layers, and Block Drop, which eliminates transformer blocks. Surprisingly, these aggressive pruning techniques not only preserve model performance but also substantially improve computation and memory efficiency. Furthermore, beyond Expert Trimming, we also introduce Expert Slimming, which compresses individual experts to further boost performance and can be seamlessly integrated with Expert Trimming. Extensive experimental results demonstrate the effectiveness of our proposed methods—Layer Drop and Block Drop—along with the comprehensive recipe that integrates Expert Slimming and Expert Trimming, achieving a 6.05× speedup with 77.1% reduced memory usage while maintaining over 92% of performance on Mixtral-8×7B. Our code is released at https://github.com/CASE-Lab-UMD/Unified-MoE-Compression.},
  archive      = {J_TMLR},
  author       = {Shwai He and Daize Dong and Liang Ding and Ang Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards efficient mixture of experts: A holistic study of compression techniques},
  url          = {https://openreview.net/forum?id=HTpMOl6xSI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlabelled compressive sensing under sparse permutation and
prior information. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HaAg9RN7Hi">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of unlabelled compressed sensing, where the correspondence between the measurement values and the rows of the sensing matrix is lost, the number of measurements is less than the dimension of the regression vector, and the regression vector is sparse in the identity basis. Additionally, motivated by practical situations, we assume that we accurately know a small number of correspondences between the rows of the measurement matrix and the measurement vector. We propose a tractable estimator, based on a modified form of the \textsc{Lasso}, to estimate the regression vector, and we derive theoretical error bounds for the estimate. This is unlike previous approaches to unlabelled compressed sensing, which either do not produce theoretical bounds or which produce bounds for intractable estimators. We show that our algorithm outperforms a hard thresholding pursuit (\textsc{Htp}) approach and an $\ell_1$-norm estimator used to solve a similar problem across diverse regimes. We also propose a modified \textsc{Htp} based estimator which has superior properties to the baseline \textsc{Htp} estimator. Lastly, we show an application of unlabelled compressed sensing in image registration, demonstrating the utility of a few known point correspondences.},
  archive      = {J_TMLR},
  author       = {Garweet Sresth and Satish Mulleti and Ajit Rajwade},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unlabelled compressive sensing under sparse permutation and prior information},
  url          = {https://openreview.net/forum?id=HaAg9RN7Hi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep active learning in the open world. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HkmymFPODz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models deployed in open-world scenarios often encounter unfamiliar conditions and perform poorly in unanticipated situations. As AI systems advance and find application in safety-critical domains, effectively handling out-of-distribution (OOD) data is crucial to building open-world learning systems. In this work, we introduce ALOE, a novel active learning algorithm for open-world environments designed to enhance model adaptation by incorporating new OOD classes via a two-stage approach. First, diversity sampling selects a representative set of examples, followed by energy-based OOD detection to prioritize likely unknown classes for annotation. This strategy accelerates class discovery and learning, even under constrained annotation budgets. Evaluations on three long-tailed image classification benchmarks demonstrate that ALOE outperforms traditional active learning baselines, effectively expanding known categories while balancing annotation cost. Our findings reveal a crucial tradeoff between enhancing known-class performance and discovering new classes, setting the stage for future advancements in open-world machine learning.},
  archive      = {J_TMLR},
  author       = {Tian Xie and Jifan Zhang and Haoyue Bai and Robert D Nowak},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Deep active learning in the open world},
  url          = {https://openreview.net/forum?id=HkmymFPODz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing the convergence of game dynamics via
potentialness. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Is9APiPg4V">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the convergence landscape of multi-agent learning is a fundamental problem of great practical relevance in many applications of artificial intelligence and machine learning. While it is known that learning dynamics converge to Nash equilibrium in potential games, the behavior of dynamics in many important classes of games that do not admit a potential is poorly understood. To measure how ``close&#39;&#39; a game is to being potential, we consider a distance function, that we call ``potentialness&#39;&#39;, and which relies on a strategic decomposition of games introduced by Candogan et al. (2011). We introduce a numerical framework enabling the computation of this metric, which we use to calculate the degree of ``potentialness&#39;&#39; in generic matrix games, as well as (non-generic) games that are important in economic applications, namely auctions and contests. Understanding learning in the latter games has become increasingly important due to the wide-spread automation of bidding and pricing with no-regret learning algorithms. We empirically show that potentialness decreases and concentrates with an increasing number of agents or actions; in addition, potentialness turns out to be a good predictor for the existence of pure Nash equilibria and the convergence of no-regret learning algorithms in matrix games. In particular, we observe that potentialness is very low for complete-information models of the all-pay auction where no pure Nash equilibrium exists, and much higher for Tullock contests, first-, and second-price auctions, explaining the success of learning in the latter. In the incomplete-information version of the all-pay auction, a pure Bayes-Nash equilibrium exists and it can be learned with gradient-based algorithms. Potentialness nicely characterizes these differences to the complete-information version.},
  archive      = {J_TMLR},
  author       = {Martin Bichler and Davide Legacci and Panayotis Mertikopoulos and Matthias Oberlechner and Bary Pradelski},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Characterizing the convergence of game dynamics via potentialness},
  url          = {https://openreview.net/forum?id=Is9APiPg4V},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online control-informed learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=LDzvZEVl5H">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an Online Control-Informed Learning (OCIL) framework, which employs the well-established optimal control and state estimation techniques in the field of control to solve a broad class of learning tasks in an online fashion. This novel integration effectively handles practical issues in machine learning such as noisy measurement data, online learning, and data efficiency. By considering any robot as a tunable optimal control system, we propose an online parameter estimator based on extended Kalman filter (EKF) to incrementally tune the system in an online fashion, enabling it to complete designated learning or control tasks. The proposed method also improves the robustness in learning by effectively managing noise in the data. Theoretical analysis is provided to demonstrate the convergence of OCIL. Three learning modes of OCIL, i.e. Online Imitation Learning, Online System Identification, and Policy Tuning On-the-fly, are investigated via experiments, which validate their effectiveness.},
  archive      = {J_TMLR},
  author       = {Zihao Liang and Tianyu Zhou and Zehui Lu and Shaoshuai Mou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Online control-informed learning},
  url          = {https://openreview.net/forum?id=LDzvZEVl5H},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensemble and mixture-of-experts DeepONets for operator
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MGdydNfWzQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel deep operator network (DeepONet) architecture for operator learning, the ensemble DeepONet, that allows for enriching the trunk network of a single DeepONet with multiple distinct trunk networks. This trunk enrichment allows for greater expressivity and generalization capabilities over a range of operator learning problems. We also present a spatial mixture-of-experts (MoE) DeepONet trunk network architecture that utilizes a partition-of-unity (PoU) approximation to promote spatial locality and model sparsity in the operator learning problem. We first prove that both the ensemble and PoU-MoE DeepONets are universal approximators. We then demonstrate that ensemble DeepONets containing a trunk ensemble of a standard trunk, the PoU-MoE trunk, and/or a proper orthogonal decomposition (POD) trunk can achieve 2-4x lower relative $\ell_2$ errors than standard DeepONets and POD-DeepONets on both standard and challenging new operator learning problems involving partial differential equations (PDEs) in two and three dimensions. Our new PoU-MoE formulation provides a natural way to incorporate spatial locality and model sparsity into any neural network architecture, while our new ensemble DeepONet provides a powerful and general framework for incorporating basis enrichment in scientific machine learning architectures for operator learning.},
  archive      = {J_TMLR},
  author       = {Ramansh Sharma and Varun Shankar},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Ensemble and mixture-of-experts DeepONets for operator learning},
  url          = {https://openreview.net/forum?id=MGdydNfWzQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning linear polytree structural equation model.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=N28FdYO2sH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are interested in the problem of learning the directed acyclic graph (DAG) when data are generated from a linear structural equation model (SEM) and the causal structure can be characterized by a polytree. Under the Gaussian polytree models, we study sufficient conditions on the sample sizes for the well-known Chow-Liu algorithm to exactly recover both the skeleton and the equivalence class of the polytree, which is uniquely represented by a CPDAG. On the other hand, necessary conditions on the required sample sizes for both skeleton and CPDAG recovery are also derived in terms of information-theoretic lower bounds, which match the respective sufficient conditions and thereby give a sharp characterization of the difficulty of these tasks. We also consider the problem of inverse correlation matrix estimation under the linear polytree models, and establish the estimation error bound in terms of the dimension and the total number of v-structures. We also consider an extension of group linear polytree models, in which each node represents a group of variables. Our theoretical findings are illustrated by comprehensive numerical simulations, and experiments on benchmark data also demonstrate the robustness of polytree learning when the true graphical structures can only be approximated by polytrees.},
  archive      = {J_TMLR},
  author       = {Xingmei Lou and Yu Hu and Xiaodong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Learning linear polytree structural equation model},
  url          = {https://openreview.net/forum?id=N28FdYO2sH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active diffusion subsampling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OGifiton47">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsampling is commonly used to mitigate costs associated with data acquisition, such as time or energy requirements, motivating the development of algorithms for estimating the fully-sampled signal of interest $x$ from partially observed measurements $y$. In maximum- entropy sampling, one selects measurement locations that are expected to have the highest entropy, so as to minimize uncertainty about $x$. This approach relies on an accurate model of the posterior distribution over future measurements, given the measurements observed so far. Recently, diffusion models have been shown to produce high-quality posterior samples of high-dimensional signals using guided diffusion. In this work, we propose Active Diffusion Subsampling (ADS), a method for designing intelligent subsampling masks using guided dif- fusion in which the model tracks a distribution of beliefs over the true state of $x$ throughout the reverse diffusion process, progressively decreasing its uncertainty by actively choosing to acquire measurements with maximum expected entropy, ultimately producing the pos- terior distribution $p(x | y)$. ADS can be applied using pre-trained diffusion models for any subsampling rate, and does not require task-specific retraining – just the specification of a measurement model. Furthermore, the maximum entropy sampling policy employed by ADS is interpretable, enhancing transparency relative to existing methods using black-box policies. Experimentally, we show that through designing informative subsampling masks, ADS significantly improves reconstruction quality compared to fixed sampling strategies on the MNIST and CelebA datasets, as measured by standard image quality metrics, includ- ing PSNR, SSIM, and LPIPS. Furthermore, on the task of Magnetic Resonance Imaging acceleration, we find that ADS performs competitively with existing supervised methods in reconstruction quality while using a more interpretable acquisition scheme design procedure. Code is available at https://active-diffusion-subsampling.github.io/.},
  archive      = {J_TMLR},
  author       = {Oisín Nolan and Tristan Stevens and Wessel L. van Nierop and Ruud Van Sloun},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Active diffusion subsampling},
  url          = {https://openreview.net/forum?id=OGifiton47},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence guarantees for RMSProp and adam in
generalized-smooth non-convex optimization with affine noise variance.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QIzRdjIWnS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides the first tight convergence analyses for RMSProp and Adam for non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. RMSProp is firstly analyzed, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to the dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and the first-order momentum. We develop a new upper bound on the first-order term in the descent lemma, which is also a function of the gradient norm. We show that Adam with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. Our complexity results for both RMSProp and Adam match with the complexity lower bound established in Arjevani et al. (2023).},
  archive      = {J_TMLR},
  author       = {Qi Zhang and Yi Zhou and Shaofeng Zou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Convergence guarantees for RMSProp and adam in generalized-smooth non-convex optimization with affine noise variance},
  url          = {https://openreview.net/forum?id=QIzRdjIWnS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State space models can express <span
class="math inline"><em>n</em></span>-gram languages. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QlBaDKb370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in recurrent neural networks (RNNs) have reinvigorated interest in their application to natural language processing tasks, particularly with the development of more efficient and parallelizable variants known as state space models (SSMs), which have shown competitive performance against transformer models while maintaining a lower memory footprint. While RNNs and SSMs (e.g., Mamba) have been empirically more successful than rule-based systems based on $n$-gram models, a rigorous theoretical explanation for this success has not yet been developed, as it is unclear how these models encode the combinatorial rules that govern the next-word prediction task. In this paper, we construct state space language models that can solve the next-word prediction task for languages generated from $n$-gram rules, thereby showing that the former are more expressive. Our proof shows how SSMs can encode $n$-gram rules using new theoretical results on their memorization capacity, and demonstrates how their context window can be controlled by restricting the spectrum of the state transition matrix. We conduct experiments with a small dataset generated from $n$-gram rules to show how our framework can be applied to SSMs and RNNs obtained through gradient-based optimization.},
  archive      = {J_TMLR},
  author       = {Vinoth Nandakumar and Qiang Qu and Peng Mi and Tongliang Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {State space models can express $n$-gram languages},
  url          = {https://openreview.net/forum?id=QlBaDKb370},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path-specific counterfactual fairness via dividend
correction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=RXoSmiyObR">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual fairness is a fundamental principle in machine learning that allows the analysis of the effects of sensitive attributes in each individual decision by integrating the knowledge of causal graphs. An issue in dealing with counterfactual fairness is that unfair causal effects are often context-specific, influenced by religious, cultural, and national differences, making it difficult to create a universally applicable model. This leads to the challenge of dealing with frequent adaptation to changes in fairness assessments when localizing a model. Thus, applicability across a variety of models and efficiency becomes necessary to meet this challenge. We propose the first efficient post-process approach to achieve path-specific counterfactual fairness by adjusting a model&#39;s outputs based on a given causal graph. This approach is model-agnostic, prioritizing on flexibility and generalizability to deliver robust results across various domains and model architectures. By means of the mathematical tools in cooperative game, the Möbius inversion formula and dividends, we demonstrate that our post-process approach can be executed efficiently. We empirically show that proposed algorithm outperforms existing in-process approaches for path-specific counterfactual fairness and a post-process approach for counterfactual fairness.},
  archive      = {J_TMLR},
  author       = {Daisuke Hatano and Satoshi Hara and Hiromi Arai},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Path-specific counterfactual fairness via dividend correction},
  url          = {https://openreview.net/forum?id=RXoSmiyObR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variation matters: From mitigating to embracing zero-shot
NAS ranking function variation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SbGt90dxdp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Architecture Search (NAS) is a powerful automatic alternative to manual design of a neural network. In the zero-shot version, a fast ranking function is used to compare architectures without training them. The outputs of the ranking functions often vary significantly due to different sources of randomness, including the evaluated architecture&#39;s weights&#39; initialization or the batch of data used for calculations. A common approach to addressing the variation is to average a ranking function output over several evaluations. We propose taking into account the variation in a different manner, by viewing the ranking function output as a random variable representing a proxy performance metric. During the search process, we strive to construct a stochastic ordering of the performance metrics to determine the best architecture. Our experiments show that the proposed stochastic ordering can effectively boost performance of a search on standard benchmark search spaces.},
  archive      = {J_TMLR},
  author       = {Pavel Rumiantsev and Mark Coates},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Variation matters: From mitigating to embracing zero-shot NAS ranking function variation},
  url          = {https://openreview.net/forum?id=SbGt90dxdp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HoSNNs: Adversarially-robust homeostatic spiking neural
networks with adaptive firing thresholds. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UV58hNygne">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While spiking neural networks (SNNs) offer a promising neurally-inspired model of computation, they are vulnerable to adversarial attacks. We present the first study that draws inspiration from neural homeostasis to design a threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model and utilize TA-LIF neurons to construct the adversarially robust homeostatic SNNs (HoSNNs) for improved robustness. The TA-LIF model incorporates a self-stabilizing dynamic thresholding mechanism, offering a local feedback control solution to the minimization of each neuron&#39;s membrane potential error caused by adversarial disturbance. Theoretical analysis demonstrates favorable dynamic properties of TA-LIF neurons in terms of the bounded-input bounded-output stability and suppressed time growth of membrane potential error, underscoring their superior robustness compared with the standard LIF neurons. When trained with weak FGSM attacks (\(\epsilon = 2/255\)), our HoSNNs significantly outperform conventionally trained LIF-based SNNs across multiple datasets. Furthermore, under significantly stronger PGD7 attacks (\(\epsilon = 8/255\)), HoSNN achieves notable improvements in accuracy, increasing from 30.90% to 74.91% on FashionMNIST, 0.44% to 36.82% on SVHN, 0.54% to 43.33% on CIFAR10, and 0.04% to 16.66% on CIFAR100.},
  archive      = {J_TMLR},
  author       = {Hejia Geng and Peng Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {HoSNNs: Adversarially-robust homeostatic spiking neural networks with adaptive firing thresholds},
  url          = {https://openreview.net/forum?id=UV58hNygne},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early directional convergence in deep homogeneous neural
networks for small initializations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VNM6V1gi3k">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the gradient flow dynamics that arise when training deep homogeneous neural networks assumed to have locally Lipschitz gradients and an order of homogeneity strictly greater than two. It is shown here that for sufficiently small initializations, during the early stages of training, the weights of the neural network remain small in (Euclidean) norm and approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of the recently introduced neural correlation function. Additionally, this paper also studies the KKT points of the neural correlation function for feed-forward networks with (Leaky) ReLU and polynomial (Leaky) ReLU activations, deriving necessary and sufficient conditions for rank-one KKT points.},
  archive      = {J_TMLR},
  author       = {Akshay Kumar and Jarvis Haupt},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Early directional convergence in deep homogeneous neural networks for small initializations},
  url          = {https://openreview.net/forum?id=VNM6V1gi3k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unlearning personal data from a single image. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=VxC4PZ71Ym">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine unlearning aims to erase data from a model as if the latter never saw them during training. While existing approaches unlearn information from complete or partial access to the training data, this access can be limited over time due to privacy regulations. Currently, no setting or benchmark exists to probe the effectiveness of unlearning methods in such scenarios. To fill this gap, we propose a novel task we call One-Shot Unlearning of Personal Identities (1-SHUI) that evaluates unlearning models when the training data is not available. We focus on unlearning identity data, which is specifically relevant due to current regulations requiring personal data deletion after training. To cope with data absence, we expect users to provide a portraiting picture to aid unlearning. We design requests on CelebA, CelebA-HQ, and MUFAC with different unlearning set sizes to evaluate applicable methods in 1-SHUI. Moreover, we propose MetaUnlearn, an effective method that meta-learns to forget identities from a single image. Our findings indicate that existing approaches struggle when data availability is limited, especially when there is a dissimilarity between the provided samples and the training data.},
  archive      = {J_TMLR},
  author       = {Thomas De Min and Massimiliano Mancini and Stéphane Lathuilière and Subhankar Roy and Elisa Ricci},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unlearning personal data from a single image},
  url          = {https://openreview.net/forum?id=VxC4PZ71Ym},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixed sparsity training: Achieving 4<span
class="math inline">×</span> FLOP reduction for transformer pretraining.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XosdLS7KVE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have made significant strides in complex tasks, yet their widespread adoption is impeded by substantial computational demands. With hundreds of billion parameters, transformer-based LLMs necessitate months of pretraining across a high-end GPU cluster. However, this paper reveals a compelling finding: transformers exhibit considerable redundancy in pretraining computations, which motivates our proposed solution, Mixed Sparsity Training (MST), an efficient pretraining method that can reduce about $75$% of Floating Point Operations (FLOPs) while maintaining performance. MST integrates dynamic sparse training (DST) with Sparsity Variation (SV) and Hybrid Sparse Attention (HSA) during pretraining, involving three distinct phases: warm-up, ultra-sparsification, and restoration. The warm-up phase transforms the dense model into a sparse one, and the restoration phase reinstates connections. Throughout these phases, the model is trained with a dynamically evolving sparse topology and an HSA mechanism to maintain performance and minimize training FLOPs concurrently. Our experiment on GPT-2 showcases a FLOP reduction of $4\times$ without compromising performance.},
  archive      = {J_TMLR},
  author       = {Pihe Hu and Shaolong Li and Xun Wang and Longbo Huang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixed sparsity training: Achieving 4$\times$ FLOP reduction for transformer pretraining},
  url          = {https://openreview.net/forum?id=XosdLS7KVE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention overlap is responsible for the entity missing
problem in text-to-image diffusion models! <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Xv3ZrFayIO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image diffusion models such as Stable Diffusion and DALL-E have exhibited impressive capabilities in producing high-quality, diverse, and realistic images based on textual prompts. Nevertheless, a common issue arises where these models encounter difficulties in faithfully generating every entity specified in the prompt, leading to a recognized challenge known as entity missing in visual compositional generation. While previous studies indicated that actively adjusting cross-attention maps during inference could potentially resolve the issue, there has been a lack of systematic investigation into the specific objective function required for this task. In this work, we thoroughly investigate three potential causes of entity missing from the perspective of cross-attention maps: insufficient attention intensity, excessive attention spread, and significant overlap between attention maps of different entities. Through comprehensive empirical analysis, we found that optimizing metrics that quantify the overlap between attention maps of entities is highly effective at mitigating entity missing. We hypothesize that during the denoising process, entity-related tokens engage in a form of competition for attention toward specific regions through the cross-attention mechanism. This competition may result in the attention of a spatial location being divided among multiple tokens, leading to difficulties in accurately generating the entities associated with those tokens. Building on this insight, we propose four overlap-based loss functions that can be used to implicitly manipulate the latent embeddings of the diffusion model during inference: Intersection over union (IoU), center-of-mass (CoM) distance, Kullback–Leibler (KL) divergence, and clustering compactness (CC). Extensive experiments on a diverse set of prompts demonstrate that our proposed training-free methods substantially outperform previous approaches on a range of compositional alignment metrics, including visual question-answering, captioning score, CLIP similarity, and human evaluation. Notably, our method outperforms the best baseline by $9\%$ in human evaluation.},
  archive      = {J_TMLR},
  author       = {Arash Mari Oriyad and Mohammadali Banayeeanzade and Reza Abbasi and Mohammad Hossein Rohban and Mahdieh Soleymani Baghshah},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Attention overlap is responsible for the entity missing problem in text-to-image diffusion models!},
  url          = {https://openreview.net/forum?id=Xv3ZrFayIO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Buffer-based gradient projection for continual federated
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Xz5IcOizQ6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Federated Learning (CFL) is essential for enabling real-world applications where multiple decentralized clients adaptively learn from continuous data streams. A significant challenge in CFL is mitigating catastrophic forgetting, where models lose previously acquired knowledge when learning new information. Existing approaches often face difficulties due to the constraints of device storage capacities and the heterogeneous nature of data distributions among clients. While some CFL algorithms have addressed these challenges, they frequently rely on unrealistic assumptions about the availability of task boundaries (i.e., knowing when new tasks begin). To address these limitations, we introduce Fed-A-GEM, a federated adaptation of the A-GEM method, which employs a buffer-based gradient projection approach. Fed-A-GEM alleviates catastrophic forgetting by leveraging local buffer samples and aggregated buffer gradients, thus preserving knowledge across multiple clients. Our method is combined with existing CFL techniques, enhancing their performance in the CFL context. Our experiments on standard benchmarks show consistent performance improvements across diverse scenarios. For example, in a task-incremental learning scenario using the CIFAR-100 dataset, our method can increase the accuracy by up to 27%. Our code is available at https://github.com/shenghongdai/Fed-A-GEM.},
  archive      = {J_TMLR},
  author       = {Shenghong Dai and Jy-yong Sohn and Yicong Chen and S M Iftekharul Alam and Ravikumar Balakrishnan and Suman Banerjee and Nageen Himayat and Kangwook Lee},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Buffer-based gradient projection for continual federated learning},
  url          = {https://openreview.net/forum?id=Xz5IcOizQ6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeoMask3D: Geometrically informed mask selection for
self-supervised point cloud learning in 3D. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Yk7GUlJwGa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel approach to self-supervised learning for point clouds, employing a geometrically informed mask selection strategy called GeoMask3D (GM3D) to boost the efficiency of Masked Auto Encoders (MAE). Unlike the conventional method of random masking, our technique utilizes a teacher-student model to focus on intricate areas within the data, guiding the model’s focus toward regions with higher geometric complexity. This strategy is grounded in the hypothesis that concentrating on harder patches yields a more robust feature representation, as evidenced by the improved performance on downstream tasks. Our method also presents a feature-level knowledge distillation technique designed to guide the prediction of geometric complexity, which utilizes a comprehensive context from feature-level information. Extensive experiments confirm our method’s superiority over State-Of-The-Art (SOTA) baselines, demonstrating marked improvements in classification, segmentation, and few-shot tasks.},
  archive      = {J_TMLR},
  author       = {Ali Bahri and Moslem Yazdanpanah and Mehrdad Noori and Milad Cheraghalikhani and Gustavo Adolfo Vargas Hakim and David OSOWIECHI and Farzad Beizaee and Ismail Ben Ayed and Christian Desrosiers},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {GeoMask3D: Geometrically informed mask selection for self-supervised point cloud learning in 3D},
  url          = {https://openreview.net/forum?id=Yk7GUlJwGa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An elementary concentration bound for gibbs measures arising
in statistical learning theory. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZInwrlkQ3f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an elementary concentration bound for Gibbs measures whose log-likelihood is a function of the empirical risk. This bound controls the distance between samples from the (random) Gibbs measure and the minimizers of the population risk function. This bound is a generalization of a recent inequality developed by Ramsay et al., 2024. As a corollary, we obtain sample complexity bounds and bounds on the inverse temperature so that the samples are within a prescribed error of the population value. The latter bound on the inverse temperature is essentially sharp. We demonstrate our work on three canonical classes of examples: classification of two component mixture models, robust regression, and spiked matrix and tensor models.},
  archive      = {J_TMLR},
  author       = {Kelly Ramsay and Aukosh Jagannath and Shojaeddin Chenouri},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An elementary concentration bound for gibbs measures arising in statistical learning theory},
  url          = {https://openreview.net/forum?id=ZInwrlkQ3f},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reset-free reinforcement learning with world models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZdMIXltJzK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) is an appealing paradigm for training intelligent agents, enabling policy acquisition from the agent&#39;s own autonomously acquired experience. However, the training process of RL is far from automatic, requiring extensive human effort to reset the agent and environments. To tackle the challenging reset-free setting, we first demonstrate the superiority of model-based (MB) RL methods in such setting, showing that a straightforward adaptation of MBRL can outperform all the prior state-of-the-art methods while requiring less supervision. We then identify limitations inherent to this direct extension and propose a solution called model-based reset-free (MoReFree) agent, which further enhances the performance. MoReFree adapts two key mechanisms, exploration and policy learning, to handle reset-free tasks by prioritizing task-relevant states. It exhibits superior data-efficiency across various reset-free tasks without access to environmental reward or demonstrations while significantly outperforming privileged baselines that require supervision. Our findings suggest model-based methods hold significant promise for reducing human effort in RL. Website: https://yangzhao-666.github.io/morefree},
  archive      = {J_TMLR},
  author       = {Zhao Yang and Thomas M. Moerland and Mike Preuss and Aske Plaat and Edward S. Hu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reset-free reinforcement learning with world models},
  url          = {https://openreview.net/forum?id=ZdMIXltJzK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to leverage predictive uncertainty estimates for
reducing catastrophic forgetting in online continual learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dczXe0S1oL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world applications require machine-learning models to be able to deal with non-stationary data distributions and thus learn autonomously over an extended period of time, often in an online setting. One of the main challenges in this scenario is the so-called catastrophic forgetting (CF) for which the learning model tends to focus on the most recent tasks while experiencing predictive degradation on older ones. In the online setting, the most effective solutions employ a fixed-size memory buffer to store old samples used for replay when training on new tasks. Many approaches have been presented to tackle this problem and conflicting strategies are proposed to populate the memory. Are the easiest-to-forget or the easiest-to-remember samples more effective in combating CF? Furthermore, it is not clear how predictive uncertainty information for memory management can be leveraged in the most effective manner. Starting from the intuition that predictive uncertainty provides an idea of the samples&#39; location in the decision space, this work presents an in-depth analysis of different uncertainty estimates and strategies for populating the memory. The investigation provides a better understanding of the characteristics data points should have for alleviating CF. Then, we propose an alternative method for estimating predictive uncertainty via the generalised variance induced by the negative log-likelihood. Finally, we demonstrate that the use of predictive uncertainty measures helps in reducing CF in different settings.},
  archive      = {J_TMLR},
  author       = {Giuseppe Serra and Ben Werner and Florian Buettner},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How to leverage predictive uncertainty estimates for reducing catastrophic forgetting in online continual learning},
  url          = {https://openreview.net/forum?id=dczXe0S1oL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking knowledge transfer in learning using privileged
information. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dg1tqNIWg3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supervised machine learning, privileged information (PI) is information that is unavailable at inference, but is accessible during training time. Research on learning using privileged information (LUPI) aims to transfer the knowledge captured in PI onto a model that can perform inference without PI. It seems that this extra bit of information ought to make the resulting model better. However, finding conclusive theoretical or empirical evidence that supports the ability to transfer knowledge using PI has been challenging. In this paper, we critically examine the assumptions underlying existing theoretical analyses and argue that there is little theoretical justification for when LUPI should work. We analyze two main LUPI methods - generalized distillation and marginalization with weight sharing - and reveal that apparent improvements in empirical risk may not directly result from PI. Instead, these improvements often stem from dataset anomalies or modifications in model design misguidedly attributed to PI. Our experiments for a wide variety of application domains further demonstrate that state-of-the-art LUPI approaches fail to effectively transfer knowledge from PI. Thus, we advocate for practitioners to exercise caution when working with PI to avoid unintended inductive biases.},
  archive      = {J_TMLR},
  author       = {Danil Provodin and Bram van den Akker and Christina Katsimerou and Maurits Clemens Kaptein and Mykola Pechenizkiy},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rethinking knowledge transfer in learning using privileged information},
  url          = {https://openreview.net/forum?id=dg1tqNIWg3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The time-energy model: Selective time-series forecasting
using energy-based models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=iHYCdTAOqF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series forecasting is an important task in many domains, including finance, weather prediction, and energy consumption forecasting, and deep learning methods have emerged as the best-performing time-series forecasting methods over the last few years. However, most proposed time-series forecasting models are deterministic and are prone to errors when deployed in production, potentially causing significant losses and penalties when making predictions with low confidence. In this paper, we propose the Time-Energy Model (TEM), a framework that introduces so-called selective time-series forecasting using energy-based models. Selective forecasting estimates model confidence and allows the end-user to selectively reject forecasts while maintaining a desired target coverage. TEM is model-agnostic and can be used to improve forecasting accuracy of any encoder-decoder deterministic time-series forecasting model. TEM is trained using a combination of supervised and self-supervised learning, leveraging excellent single-point prediction accuracy while maintaining the ability to reject forecasts based on model confidence. Experimental results indicate that TEM generalizes well across 5 state-of-the-art deterministic time-series forecasting models and 5 benchmark time-series forecasting datasets. Using selective forecasting, TEM reduces prediction error by up to $49.1\%$ over 5 state-of-the-art deterministic models. Furthermore, TEM has up to $87.0\%$ lower error than selected baseline EBM models, and achieves significantly better performance than state-of-the-art selective deep learning models. Code for the proposed TEM framework is available at https://github.com/JonasBrusokas/Time-Energy-Model},
  archive      = {J_TMLR},
  author       = {Jonas Brusokas and Seshu Tirupathi and Dalin Zhang and Torben Bach Pedersen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The time-energy model: Selective time-series forecasting using energy-based models},
  url          = {https://openreview.net/forum?id=iHYCdTAOqF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards graph foundation models: A study on the
generalization of positional and structural encodings. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=mSoDRZXsqj">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in integrating positional and structural encodings (PSEs) into graph neural networks (GNNs) have significantly enhanced their performance across various graph learning tasks. However, the general applicability of these encodings and their potential to serve as foundational representations for graphs remain uncertain. This paper investigates the fine-tuning efficiency, scalability with sample size, and generalization capability of learnable PSEs across diverse graph datasets. Specifically, we evaluate their potential as universal pre-trained models that can be easily adapted to new tasks with minimal fine-tuning and limited data. Furthermore, we assess the expressivity of the learned representations, particularly, when used to augment downstream GNNs. We demonstrate through extensive benchmarking and empirical analysis that PSEs generally enhance downstream models. However, some datasets may require specific PSE-augmentations to achieve optimal performance. Nevertheless, our findings highlight their significant potential to become integral components of future graph foundation models. We provide new insights into the strengths and limitations of PSEs, contributing to the broader discourse on foundation models in graph learning.},
  archive      = {J_TMLR},
  author       = {Billy Joe Franks and Moshe Eliasof and Semih Cantürk and Guy Wolf and Carola-Bibiane Schönlieb and Sophie Fellenz and Marius Kloft},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards graph foundation models: A study on the generalization of positional and structural encodings},
  url          = {https://openreview.net/forum?id=mSoDRZXsqj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain generalization for time series: Enhancing drilling
regression models for stick-slip index prediction. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nNN1pPJRVL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a comprehensive comparison of domain generalization techniques applied to time series data within a drilling context, focusing on the prediction of a continuous Stick-Slip Index (SSI), a critical metric for assessing torsional downhole vibrations at the drill bit. The study aims to develop a robust regression model that can generalize across domains by training on $60$~ second labeled sequences of $1$~Hz surface drilling data to predict the SSI. The model is tested in wells that are different from those used during training. To fine-tune the model architecture, a grid search approach is employed to optimize key hyperparameters. A comparative analysis of the Adversarial Domain Generalization (ADG), Invariant Risk Minimization (IRM) and baseline models is presented, along with an evaluation of the effectiveness of transfer learning (TL) in improving model performance. The ADG and IRM models achieve performance improvements of $10\%$ and $8\%$, respectively, over the baseline model. Most importantly, severe events are detected $60\%$ of the time, against $20\%$ for the baseline model. Overall, the results indicate that both ADG and IRM models surpass the baseline, with the ADG model exhibiting a slight advantage over the IRM model. Additionally, applying TL to a pre-trained model further improves performance. Our findings demonstrate the potential of domain generalization approaches in drilling applications, with ADG emerging as the most effective approach.},
  archive      = {J_TMLR},
  author       = {Hana YAHIA and Bruno Figliuzzi and Florent Di Meglio and Gerbaud and Stephane Menand and Mohamed MAHJOUB},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Domain generalization for time series: Enhancing drilling regression models for stick-slip index prediction},
  url          = {https://openreview.net/forum?id=nNN1pPJRVL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calibrated probabilistic forecasts for arbitrary sequences.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nuIUTHGlM5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data streams can change unpredictably due to distribution shifts, feedback loops and adversarial actors, which challenges the validity of forecasts. We present a forecasting framework ensuring valid uncertainty estimates regardless of how data evolves. Leveraging the concept of Blackwell approachability from game theory, we introduce a forecasting framework that guarantees calibrated uncertainties for outcomes in any compact space (e.g., classification or bounded regression). We extend this framework to recalibrate existing forecasters, guaranteeing calibration without sacrificing predictive performance. We implement both general-purpose gradient-based algorithms and algorithms optimized for popular special cases of our framework. Empirically, our algorithms improve calibration and downstream decision-making for energy systems.},
  archive      = {J_TMLR},
  author       = {Charles Marx and Volodymyr Kuleshov and Stefano Ermon},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Calibrated probabilistic forecasts for arbitrary sequences},
  url          = {https://openreview.net/forum?id=nuIUTHGlM5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unifying framework for generalised bayesian online
learning in non-stationary environments. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=osesw2V10u">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a unifying framework for methods that perform probabilistic online learning in non-stationary environments. We call the framework BONE, which stands for generalised (B)ayesian (O)nline learning in (N)on-stationary (E)nvironments. BONE provides a common structure to tackle a variety of problems, including online continual learning, prequential forecasting, and contextual bandits. The framework requires specifying three modelling choices: (i) a model for measurements (e.g., a neural network), (ii) an auxiliary process to model non-stationarity (e.g., the time since the last changepoint), and (iii) a conditional prior over model parameters (e.g., a multivariate Gaussian). The framework also requires two algorithmic choices, which we use to carry out approximate inference under this framework: (i) an algorithm to estimate beliefs (posterior distribution) about the model parameters given the auxiliary variable, and (ii) an algorithm to estimate beliefs about the auxiliary variable. We show how the modularity of our framework allows for many existing methods to be reinterpreted as instances of BONE, and it allows us to propose new methods. We compare experimentally existing methods with our proposed new method on several datasets, providing insights into the situations that make each method more suitable for a specific task. We provide a Jax open source library to facilitate the adoption of this framework.},
  archive      = {J_TMLR},
  author       = {Gerardo Duran-Martin and Leandro Sánchez-Betancourt and Alex Shestopaloff and Kevin Patrick Murphy},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A unifying framework for generalised bayesian online learning in non-stationary environments},
  url          = {https://openreview.net/forum?id=osesw2V10u},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FlashAttention on a napkin: A diagrammatic approach to deep
learning IO-awareness. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=pF2ukh7HxA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing deep learning algorithms currently requires slow, manual derivation, potentially leaving much performance untapped. Methods like FlashAttention have achieved a x6 performance improvement over native PyTorch by avoiding unnecessary data transfers, but required three iterations over three years to be developed. Automated compiled methods have consistently lagged behind. This paper extends Neural Circuit Diagrams for deep learning models to consider resource usage and the distribution of tasks across a GPU hierarchy. We show how diagrams can use simple relabellings to derive high-level streaming and tiling optimization strategies along with performance models. We show how this high-level performance model allows the effects of quantization and multi-level GPU hierarchies to be readily considered. We develop a methodology for representing intermediate-level pseudocode with diagrams, allowing hardware-aware algorithms to be derived step-by-step. Finally, we show how our methodology can be used to better understand existing techniques like FlashAttention. This work uses a theoretical framework to link assumptions about GPU behaviour to claims about performance. We aim to lay the groundwork for a scientific approach to GPU optimization where experiments can address clear hypotheses rather than post-hoc rationalizations.},
  archive      = {J_TMLR},
  author       = {Vincent Abbott and Gioele Zardini},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FlashAttention on a napkin: A diagrammatic approach to deep learning IO-awareness},
  url          = {https://openreview.net/forum?id=pF2ukh7HxA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shedding light on problems with hyperbolic graph learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=rKAkp1f3R7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent papers in the graph machine learning literature have introduced a number of approaches for hyperbolic representation learning. The asserted benefits are improved performance on a variety of graph tasks, node classification and link prediction included. Claims have also been made about the geometric suitability of particular hierarchical graph datasets to representation in hyperbolic space. Despite these claims, our work makes a surprising discovery: when simple Euclidean models with comparable numbers of parameters are properly trained in the same environment, in most cases, they perform as well, if not better, than all introduced hyperbolic graph representation learning models, even on graph datasets previously claimed to be the most hyperbolic as measured by Gromov $\delta$-hyperbolicity (i.e., perfect trees). This observation gives rise to a simple question: how can this be? We answer this question by taking a careful look at the field of hyperbolic graph representation learning as it stands today, and find that a number of results do not diligently present baselines, make faulty modelling assumptions when constructing algorithms, and use misleading metrics to quantify geometry of graph datasets. We take a closer look at each of these three problems, elucidate the issues, perform an analysis of methods, and introduce a parametric family of benchmark datasets to ascertain the applicability of (hyperbolic) graph neural networks.},
  archive      = {J_TMLR},
  author       = {Isay Katsman and Anna Gilbert},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Shedding light on problems with hyperbolic graph learning},
  url          = {https://openreview.net/forum?id=rKAkp1f3R7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Align and distill: Unifying and improving domain adaptive
object detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ssXSrZ94sR">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, increasing the diversity of available DAOD benchmarks, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes $\rightarrow$ Foggy Cityscapes, +5.7 AP50 on Sim10k $\rightarrow$ Cityscapes (where ours is the only method to outperform a fair baseline), and +0.6 AP50 on CFC-DAOD. ALDI and ALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and DETR-based DAOD as well without additional hyperparameter tuning. Our framework, dataset, and method offer a critical reset for DAOD and provide a strong foundation for future research.},
  archive      = {J_TMLR},
  author       = {Justin Kay and Timm Haucke and Suzanne Stathatos and Siqi Deng and Erik Young and Pietro Perona and Sara Beery and Grant Van Horn},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Align and distill: Unifying and improving domain adaptive object detection},
  url          = {https://openreview.net/forum?id=ssXSrZ94sR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Random walk diffusion for efficient large-scale graph
generation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tSFpsfndE7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph generation addresses the problem of generating new graphs that have a data distribution similar to real-world graphs. While previous diffusion-based graph generation methods have shown promising results, they often struggle to scale to large graphs. In this work, we propose ARROW-Diff (AutoRegressive RandOm Walk Diffusion), a novel random walk-based diffusion approach for efficient large-scale graph generation. Our method encompasses two components in an iterative process of random walk sampling and graph pruning. We demonstrate that ARROW-Diff can scale to large graphs efficiently, surpassing other baseline methods in terms of both generation time and multiple graph statistics, reflecting the high quality of the generated graphs.},
  archive      = {J_TMLR},
  author       = {Tobias Bernecker and Ghalia Rehawi and Francesco Paolo Casale and Janine Knauer-Arloth and Annalisa Marsico},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Random walk diffusion for efficient large-scale graph generation},
  url          = {https://openreview.net/forum?id=tSFpsfndE7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CroissantLLM: A truly bilingual french-english language
model. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uA19Xo1o31">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3T English and French tokens, to bring to the research and industrial community a high-performance, fully open-sourced bilingual model that runs swiftly on consumer-grade local hardware. To that end, we pioneer the approach of training an intrinsically bilingual model with a 1:1 English-to-French pretraining data ratio, a custom tokenizer, and bilingual finetuning datasets. We release the training dataset, notably containing a French split with manually curated, high-quality, and varied data sources. To assess performance outside of English, we craft a novel benchmark, FrenchBench, consisting of an array of classification and generation tasks, covering various orthogonal aspects of model performance in the French Language. Additionally, rooted in transparency and to foster further Large Language Model research, we release codebases, and dozens of checkpoints across various model sizes, training data distributions, and training steps, as well as fine-tuned Chat models, and strong translation models. We evaluate our model through the FMTI framework, and validate 81 % of the transparency criteria, far beyond the scores of even most open initiatives. This work enriches the NLP landscape, breaking away from previous English-centric work in order to strengthen our understanding of multilinguality in language models.},
  archive      = {J_TMLR},
  author       = {Manuel Faysse and Patrick Fernandes and Nuno M Guerreiro and António Loison and Duarte Miguel Alves and Caio Corrro and Nicolas Boizard and João Alves and Ricardo Rei and Pedro Henrique Martins and Antoni Bigata Casademunt and François Yvon and Andre Martins and Gautier Viaud and CELINE HUDELOT and Pierre Colombo},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CroissantLLM: A truly bilingual french-english language model},
  url          = {https://openreview.net/forum?id=uA19Xo1o31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reheated gradient-based discrete sampling for combinatorial
optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uPCvfyr2KP">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, gradient-based discrete sampling has emerged as a highly efficient, general-purpose solver for various combinatorial optimization (CO) problems, achieving performance comparable to or surpassing the popular data-driven approaches. However, we identify a critical issue in these methods, which we term ``wandering in contours&#39;&#39;. This behavior refers to sampling new different solutions that share very similar objective values for a long time, leading to computational inefficiency and suboptimal exploration of potential solutions. In this paper, we introduce a novel reheating mechanism inspired by the concept of critical temperature and specific heat in physics, aimed at overcoming this limitation. Empirically, our method demonstrates superiority over existing sampling-based and data-driven algorithms across a diverse array of CO problems.},
  archive      = {J_TMLR},
  author       = {Muheng Li and Ruqi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Reheated gradient-based discrete sampling for combinatorial optimization},
  url          = {https://openreview.net/forum?id=uPCvfyr2KP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the robustness of kolmogorov-arnold networks: An
adversarial perspective. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uafxqhImPM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kolmogorov-Arnold Networks (KANs) have recently emerged as a novel paradigm for function approximation by leveraging univariate spline-based decompositions inspired by the Kolmogorov–Arnold theorem. Despite their theoretical appeal---particularly the potential for inducing smoother decision boundaries and lower effective Lipschitz constants---their adversarial robustness remains largely unexplored. In this work, we conduct the first comprehensive evaluation of KAN robustness in adversarial settings, focusing on both fully connected (FCKANs) and convolutional (CKANs) instantiations for image classification tasks. Across a wide range of benchmark datasets (MNIST, FashionMNIST, KMNIST, CIFAR-10, SVHN, and a subset of ImageNet), we compare KANs against conventional architectures using an extensive suite of attacks, including white-box methods (FGSM, PGD, C\&amp;W, MIM), black-box approaches (Square Attack, SimBA, NES), and ensemble attacks (AutoAttack). Our experiments reveal that while small- and medium-scale KANs are not consistently more robust than their standard counterparts, large-scale KANs exhibit markedly enhanced resilience against adversarial perturbations. An ablation study further demonstrates that critical hyperparameters---such as number of knots and spline order---significantly influence robustness. Moreover, adversarial training experiments confirm the inherent safety advantages of KAN-based architectures. Overall, our findings provide novel insights into the adversarial behavior of KANs and lay a rigorous foundation for future research on robust, interpretable network designs.},
  archive      = {J_TMLR},
  author       = {Tal Alter and Raz Lapid and Moshe Sipper},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the robustness of kolmogorov-arnold networks: An adversarial perspective},
  url          = {https://openreview.net/forum?id=uafxqhImPM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Respecting the limit: Bayesian optimization with a bound on
the optimal value. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=y5Hf0otJLk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world optimization problems, we have prior information about what objective function values are achievable. In this paper, we study the scenario that we have either exact knowledge of the minimum value or a, possibly inexact, lower bound on its value. We propose bound-aware Bayesian optimization (BABO), a Bayesian optimization method that uses a new surrogate model and acquisition function to utilize such prior information. We present SlogGP, a new surrogate model that incorporates bound information and adapts the Expected Improvement (EI) acquisition function accordingly. Empirical results on a variety of benchmarks demonstrate the benefit of taking prior information about the optimal value into account, and that the proposed approach significantly outperforms existing techniques. Furthermore, we notice that even in the absence of prior information on the bound, the proposed SlogGP surrogate model still performs better than the standard GP model in most cases, which we explain by its larger expressiveness.},
  archive      = {J_TMLR},
  author       = {Hanyang Wang and Juergen Branke and Matthias Poloczek},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Respecting the limit: Bayesian optimization with a bound on the optimal value},
  url          = {https://openreview.net/forum?id=y5Hf0otJLk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lower ricci curvature for efficient community detection.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EoiuRII7MQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces the Lower Ricci Curvature (LRC), a novel, scalable, and scale-free discrete curvature designed to enhance community detection in networks. Addressing the computational challenges posed by existing curvature-based methods, LRC offers a streamlined approach with linear computational complexity, which makes it well suited for large-scale network analysis. We further develop an LRC-based preprocessing method that effectively augments popular community detection algorithms. Through applications on multiple real-world datasets, including the NCAA football league network, the DBLP collaboration network, the Amazon product co-purchasing network, and the YouTube social network, we demonstrate the efficacy of our method in significantly improving the performance of various community detection algorithms.},
  archive      = {J_TMLR},
  author       = {Yun Jin Park and Didong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lower ricci curvature for efficient community detection},
  url          = {https://openreview.net/forum?id=EoiuRII7MQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing maritime trajectory forecasting via h3 index and
causal language modelling (CLM). <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tIfS6jyO9f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of ship trajectories is a growing field of study in artificial intelligence. Traditional methods rely on the use of LSTM, GRU networks, and even Transformer architectures for the prediction of spatio-temporal series. This study proposes a viable alternative for predicting these trajectories using only GNSS positions. It considers this spatio-temporal problem as a natural language processing problem. The latitude/longitude coordinates of AIS messages are transformed into cell identifiers using the H3 index. Thanks to the pseudo-octal representation, it becomes easier for language models to learn the spatial hierarchy of the H3 index. The method is qualitatively compared to a classical Kalman filter and quantitatively to Seq2Seq and TrAISformer models. The Fréchet distance is introduced as the main evaluation metric for these comparisons. We show that it is possible to predict ship trajectories quite precisely up to 8 hours ahead with 30 minutes of context, using solely GNSS positions, without relying on any additional information such as speed, course, or external conditions — unlike many traditional methods. We demonstrate that this alternative works well enough to predict trajectories worldwide.},
  archive      = {J_TMLR},
  author       = {Nicolas Drapier and Aladine Chetouani and Aurélien Chateigner},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing maritime trajectory forecasting via h3 index and causal language modelling (CLM)},
  url          = {https://openreview.net/forum?id=tIfS6jyO9f},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning optimizers for communication-efficient
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uRbf9ANAns">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication-efficient variants of SGD, specifically local SGD, have received a great deal of interest in recent years. These approaches compute multiple gradient steps locally on each worker, before averaging model parameters, helping relieve the critical communication bottleneck in distributed deep learning training. Although many variants of these approaches have been proposed, they can sometimes lag behind state-of-the-art adaptive optimizers for deep learning. In this work, we investigate if the recent progress in the emerging area of learned optimizers can potentially close this gap in homogeneous data and homogeneous device settings while remaining communication-efficient. Specifically, we meta-learn how to perform global updates given an update from local SGD iterations. Our results demonstrate that learned optimizers can substantially outperform local SGD and its sophisticated variants while maintaining their communication efficiency. Our learned optimizers can even generalize to unseen and much larger datasets and architectures, including ImageNet and ViTs, and to unseen modalities such as language modeling. We therefore show the potential of learned optimizers for improving communication-efficient distributed learning.},
  archive      = {J_TMLR},
  author       = {Charles-Étienne Joseph and Benjamin Thérien and Abhinav Moudgil and Boris Knyazev and Eugene Belilovsky},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning optimizers for communication-efficient learning},
  url          = {https://openreview.net/forum?id=uRbf9ANAns},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse decomposition of graph neural networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xdWP1d8BxI">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNN) exhibit superior performance in graph representation learning, but their inference cost can be high, due to an aggregation operation that can require a memory fetch for a very large number of nodes. This inference cost is the major obstacle to deploying GNN models with \emph{online prediction} to reflect the potentially dynamic node features. To address this, we propose an approach to reduce the number of nodes that are included during aggregation. We achieve this through a sparse decomposition, learning to approximate node representations using a weighted sum of linearly transformed features of a carefully selected subset of nodes within the extended neighbourhood. The approach achieves linear complexity with respect to the average node degree and the number of layers in the graph neural network. We introduce an algorithm to compute the optimal parameters for the sparse decomposition, ensuring an accurate approximation of the original GNN model, and present effective strategies to reduce the training time and improve the learning process. We demonstrate via extensive experiments that our method outperforms other baselines designed for inference speedup, achieving significant accuracy gains with comparable inference times for both node classification and spatio-temporal forecasting tasks.},
  archive      = {J_TMLR},
  author       = {Yaochen Hu and Mai Zeng and Ge Zhang and Pavel Rumiantsev and Liheng Ma and Yingxue Zhang and Mark Coates},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparse decomposition of graph neural networks},
  url          = {https://openreview.net/forum?id=xdWP1d8BxI},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Which backbone to use: A resource-efficient domain specific
comparison for computer vision. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XVSQnnf7QT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For computer vision applications on small, niche, and proprietary datasets, fine-tuning a neural network (NN) backbone that is pre-trained on a large dataset, such as the ImageNet, is a common practice. However, it is unknown whether the backbones that perform well on large datasets, such as vision transformers, are also the right choice for fine-tuning on smaller custom datasets. The present comprehensive analysis aims to aid machine learning practitioners in selecting the most suitable backbone for their specific problem. We systematically evaluated multiple lightweight, pre-trained backbones under consistent training settings across a variety of domains spanning natural, medical, deep space, and remote sensing images. We found that even though attention-based architectures are gaining popularity, they tend to perform poorly compared to CNNs when fine-tuned on small amounts of domain-specific data. We also observed that certain CNN architectures consistently perform better than others when controlled for network size. Our findings provide actionable insights into the performance trade-offs and effectiveness of different backbones for a broad spectrum of computer vision domains.},
  archive      = {J_TMLR},
  author       = {Pranav Jeevan P and Amit Sethi},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Which backbone to use: A resource-efficient domain specific comparison for computer vision},
  url          = {https://openreview.net/forum?id=XVSQnnf7QT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distilling datasets into less than one image. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=qsipSdfWeV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataset distillation aims to compress a dataset into a much smaller one so that a model trained on the distilled dataset achieves high accuracy. Current methods frame this as maximizing the distilled classification accuracy for a budget of K distilled images-per-class, where K is a positive integer. In this paper, we push the boundaries of dataset distillation, compressing the dataset into less than an image-per-class. It is important to realize that the meaningful quantity is not the number of distilled images-per-class but the number of distilled pixels-per-dataset. We therefore, propose Poster Dataset Distillation (PoDD), a new approach that distills the entire original dataset into a single poster. The poster approach motivates new technical solutions for creating training images and learnable labels. Our method can achieve comparable or better performance with less than an image-per-class compared to existing methods that use one image-per-class. Specifically, our method establishes a new state-of-the-art performance on CIFAR-10, CIFAR-100, and CUB200 on the well established 1 IPC benchmark, while using as little as 0.3 images-per-class.},
  archive      = {J_TMLR},
  author       = {Asaf Shul and Eliahu Horwitz and Yedid Hoshen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Distilling datasets into less than one image},
  url          = {https://openreview.net/forum?id=qsipSdfWeV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On using secure aggregation in differentially private
federated learning with multiple local steps. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uxyWlXPuIg">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed learning setting where the main aim is to train machine learning models without having to share raw data but only what is required for learning. To guarantee training data privacy and high-utility models, differential privacy and secure aggregation techniques are often combined with federated learning. However, with fine-grained protection granularities, e.g., with the common sample-level protection, the currently existing techniques generally require the parties to communicate for each local optimization step, if they want to fully benefit from the secure aggregation in terms of the resulting formal privacy guarantees. In this paper, we show how a simple new analysis allows the parties to perform multiple local optimization steps while still benefiting from using secure aggregation. We show that our analysis enables higher utility models with guaranteed privacy protection under limited number of communication rounds.},
  archive      = {J_TMLR},
  author       = {Mikko A. Heikkilä},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On using secure aggregation in differentially private federated learning with multiple local steps},
  url          = {https://openreview.net/forum?id=uxyWlXPuIg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Illustrated landmark graphs for long-horizon policy
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0AOUWC4ss8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying learning-based approaches to long-horizon sequential decision-making tasks requires a human teacher to carefully craft reward functions or curate demonstrations to elicit desired behaviors. To simplify this, we first introduce an alternative form of task-specification, Illustrated Landmark Graph (ILG), that represents the task as a directed graph where each vertex corresponds to a region of the state space (a landmark), and each edge represents an easier to achieve sub-task. A landmark in the ILG is conveyed to the agent through a few illustrative examples grounded in the agent’s observation space. Second, we propose ILG-Learn, a human in the loop algorithm that interleaves planning over the ILG and sub-task policy learning. ILG-Learn adaptively plans through the ILG by relying on the human teacher’s feedback to estimate the success rates of learned policies. We conduct experiments on long-horizon block stacking and point maze navigation tasks, and find that our approach achieves considerably higher success rates (~ 50% improvement) compared to hierarchical reinforcement learning and imitation learning baselines. Additionally, we highlight how the flexibility of the ILG specification allows the agent to learn a sequence of sub-tasks that is better suited to its limited capabilities.},
  archive      = {J_TMLR},
  author       = {Christopher Watson and Arjun Krishna and Rajeev Alur and Dinesh Jayaraman},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Illustrated landmark graphs for long-horizon policy learning},
  url          = {https://openreview.net/forum?id=0AOUWC4ss8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Show or tell? Effectively prompting vision-language models
for semantic segmentation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0yPWtbR3MC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Vision-Language Models (VLMs) are increasingly being regarded as foundation models that can be instructed to solve diverse tasks by prompting, without task-specific training. We examine the seemingly obvious question: \emph{how to effectively prompt VLMs for semantic segmentation}. To that end, we systematically evaluate the segmentation performance of several recent models guided by either text or visual prompts on the out-of-distribution MESS dataset collection. We introduce a scalable prompting scheme, \emph{few-shot prompted semantic segmentation}, inspired by open-vocabulary segmentation and few-shot learning. It turns out that VLMs lag far behind specialist models trained for a specific segmentation task, by about 30\% on average on the Intersection-over-Union metric. Moreover, we find that text prompts and visual prompts are complementary: each one of the two modes fails on many examples that the other one can solve. Our analysis suggests that being able to anticipate the most effective prompt modality can lead to a 11\% improvement in performance. Motivated by our findings, we propose PromptMatcher, a remarkably simple training-free baseline that combines both text and visual prompts, achieving state-of-the-art results outperforming the best text-prompted VLM by 2.5\%, and the top visual-prompted VLM by 3.5\% on few-shot prompted semantic segmentation.},
  archive      = {J_TMLR},
  author       = {Niccolò Avogaro and Thomas Frick and Mattia Rigotti and Andrea Bartezzaghi and Filip Janicki and A. Cristiano I. Malossi and Konrad Schindler and Roy Assaf},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Show or tell? effectively prompting vision-language models for semantic segmentation},
  url          = {https://openreview.net/forum?id=0yPWtbR3MC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A vector bernstein inequality for self-normalized
martingales. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4ZJjr9YbBw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove a Bernstein inequality for vector-valued self-normalized martingales. We first give an alternative perspective of the corresponding sub-Gaussian bound due to Abbasi-Yadkori et al. via a PAC-Bayesian argument with Gaussian priors. By instantiating this argument to priors drawn uniformly over well-chosen ellipsoids, we obtain a Bernstein bound.},
  archive      = {J_TMLR},
  author       = {Ingvar Ziemann},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A vector bernstein inequality for self-normalized martingales},
  url          = {https://openreview.net/forum?id=4ZJjr9YbBw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Theoretical insights into overparameterized models in
multi-task and replay-based continual learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=4zGPT0ZwnU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) is a machine learning paradigm that aims to improve the generalization performance of a model on multiple related tasks by training it simultaneously on those tasks. Unlike MTL, where the model has instant access to the training data of all tasks, continual learning (CL) involves adapting to new sequentially arriving tasks over time without forgetting the previously acquired knowledge. Despite the wide practical adoption of CL and MTL and extensive literature on both areas, there remains a gap in the theoretical understanding of these methods when used with overparameterized models such as deep neural networks. This paper studies the overparameterized linear models as a proxy for more complex models. We develop theoretical results describing the effect of various system parameters on the model&#39;s performance in an MTL setup. Specifically, we study the impact of model size, dataset size, and task similarity on the generalization error and knowledge transfer. Additionally, we present theoretical results to characterize the performance of replay-based CL models. Our results reveal the impact of buffer size and model capacity on the forgetting rate in a CL setup and help shed light on some of the state-of-the-art CL methods. Finally, through extensive empirical evaluations, we demonstrate that our theoretical findings are also applicable to deep neural networks, offering valuable guidance for designing MTL and CL models in practice.},
  archive      = {J_TMLR},
  author       = {Mohammadamin Banayeeanzade and Mahdi Soltanolkotabi and Mohammad Rostami},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Theoretical insights into overparameterized models in multi-task and replay-based continual learning},
  url          = {https://openreview.net/forum?id=4zGPT0ZwnU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decision-focused surrogate modeling for mixed-integer linear
optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=A6tOXkkE4Z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mixed-integer optimization is at the core of many online decision-making systems that demand frequent updates of decisions in real time. However, due to their combinatorial nature, mixed-integer linear programs (MILPs) can be difficult to solve, rendering them often unsuitable for time-critical online applications. To address this challenge, we develop a data-driven approach for constructing surrogate optimization models in the form of linear programs (LPs) that can be solved much more efficiently than the corresponding MILPs. We train these surrogate LPs in a decision-focused manner such that for different model inputs, they achieve the same or close to the same optimal solutions as the original MILPs. One key advantage of the proposed method is that it allows the incorporation of all of the original MILP’s linear constraints, which significantly increases the likelihood of obtaining feasible predicted solutions. Results from two computational case studies indicate that this decision-focused surrogate modeling approach is highly data-efficient and provides very accurate predictions of the optimal solutions. In these examples, the resulting surrogate LPs outperform state-of-the-art neural-network-based optimization proxies.},
  archive      = {J_TMLR},
  author       = {Shivi Dixit and Rishabh Gupta and Qi Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Decision-focused surrogate modeling for mixed-integer linear optimization},
  url          = {https://openreview.net/forum?id=A6tOXkkE4Z},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering strong lottery tickets in graph transformers: A
path to memory efficient and robust graph learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=B1q9po4LPl">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Transformers (GTs) have recently demonstrated strong capabilities for capturing complex relationships in graph-structured data using global self-attention mechanisms. On the other hand, their high memory requirements during inference remain a challenge for practical deployment. In this study, we investigate the existence of strong lottery tickets (SLTs) — subnetworks within randomly initialized neural networks that can attain competitive accuracy without weight training — in GTs. Previous studies have explored SLTs in message-passing neural networks (MPNNs), showing that SLTs not only exist in MPNNs but also help mitigate over-smoothing problems and improve robustness. However, the potential of SLTs in GTs remains unexplored. With GTs having 4.5$\times$ more parameters than MPNNs, SLTs hold even greater application value in this context. We find that fixed random weights with a traditional SLT search method cannot adapt to imbalances of features in GTs, leading to highly biased attention that destabilizes model performance. To overcome this issue and efficiently search for SLTs, we introduce a novel approach called Adaptive Scaling. We empirically confirm the existence of SLTs within GTs and demonstrate their versatility through extensive experiments across different GT architectures, including NodeFormer, GRIT, and GraphGPS. Our findings demonstrate that SLTs achieve comparable accuracy while reducing memory usage by 2--32$\times$, effectively generalize to out-of-distribution data, and enhance robustness against adversarial perturbations. This work highlights that SLTs offer a resource-efficient approach to improving the scalability, efficiency, and robustness of GTs, with broad implications for applications involving graph data.},
  archive      = {J_TMLR},
  author       = {Hiroaki Ito and Jiale Yan and Hikari Otsuka and Kazushi Kawamura and Masato Motomura and Thiem Van Chu and Daichi Fujiki},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncovering strong lottery tickets in graph transformers: A path to memory efficient and robust graph learning},
  url          = {https://openreview.net/forum?id=B1q9po4LPl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Removing structured noise using diffusion models.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=BvKYsaOVEn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving ill-posed inverse problems requires careful formulation of prior beliefs over the signals of interest and an accurate description of their manifestation into noisy measurements. Handcrafted signal priors based on e.g. sparsity are increasingly replaced by data-driven deep generative models, and several groups have recently shown that state-of-the-art score-based diffusion models yield particularly strong performance and flexibility. In this paper, we show that the powerful paradigm of posterior sampling with diffusion models can be extended to include rich, structured, noise models. To that end, we propose a joint conditional reverse diffusion process with learned scores for the noise and signal-generating distribution. We demonstrate strong performance gains across various inverse problems with structured noise, outperforming competitive baselines using normalizing flows, adversarial networks and various posterior sampling methods for diffusion models. This opens up new opportunities and relevant practical applications of diffusion modeling for inverse problems in the context of non-Gaussian measurement models.},
  archive      = {J_TMLR},
  author       = {Tristan Stevens and Hans van Gorp and Faik C Meral and Junseob Shin and Jason Yu and Jean-luc Robert and Ruud Van Sloun},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Removing structured noise using diffusion models},
  url          = {https://openreview.net/forum?id=BvKYsaOVEn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-agent cooperation learning through teammate
lookahead. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CeNNIQ8GJf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative Multi-Agent Reinforcement Learning (MARL) is a rapidly growing research field that has achieved outstanding results across a variety of challenging cooperation tasks. However, existing MARL algorithms typically overlook the concurrent updates of teammate agents. An agent always learns from the data that it cooperates with one set of (current) teammates, but then practices with another set of (updated) teammates. This phenomenon, termed as ``teammate delay&#39;&#39;, leads to a discrepancy between the agent&#39;s learning objective and the actual evaluation scenario, which can degrade learning stability and efficiency. In this paper, we tackle this challenge by introducing a lookahead strategy that enables agents to learn to cooperate with predicted future teammates, allowing the explicit awareness of concurrent teammate updates. This lookahead strategy is designed to seamlessly integrate with existing policy-gradient-based MARL methods, enhancing their performance without significant modifications to their underlying structures. The extensive experiments demonstrate the effectiveness of this approach, showing that the lookahead strategy can enhance the cooperation learning efficiency and achieve superior performance over the state-of-the-art MARL algorithms.},
  archive      = {J_TMLR},
  author       = {Feng Chen and Xinwei Chen and Rong-Jun Qin and Cong Guan and Lei Yuan and Zongzhang Zhang and Yang Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient multi-agent cooperation learning through teammate lookahead},
  url          = {https://openreview.net/forum?id=CeNNIQ8GJf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-context LLMs struggle with long in-context learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Cw2xlg0e46">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) have made significant strides in handling long sequences. Some models like Gemini could even be capable of dealing with millions of tokens. However, their performance evaluation has largely been confined to metrics like perplexity and synthetic tasks, which may not fully capture their true abilities in more challenging, real-world scenarios. We introduce a benchmark (LongICLBench) for long in-context learning in extreme-label classification using six datasets with 28 to 174 classes and input lengths from 2K to 50K tokens. Our benchmark requires LLMs to comprehend the entire input to recognize the massive label spaces to make correct predictions. We evaluate on 15 long-context LLMs and find that they perform well on less challenging classification tasks with smaller label space and shorter demonstrations. However, they struggle with more challenging task like Discovery with 174 labels, suggesting a gap in their ability to process long, context-rich sequences. Further analysis reveals a bias towards labels presented later in the sequence and a need for improved reasoning over multiple pieces of information. Our study reveals that long context understanding and reasoning is still a challenging task for the existing LLMs. We believe LongICLBench could serve as a more realistic evaluation for the future long-context LLMs.},
  archive      = {J_TMLR},
  author       = {Tianle Li and Ge Zhang and Quy Duc Do and Xiang Yue and Wenhu Chen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Long-context LLMs struggle with long in-context learning},
  url          = {https://openreview.net/forum?id=Cw2xlg0e46},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-modular classification: Learning to generalize with
memory replacement. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DcIW0idrg8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel memory-modular learner for image classification that separates knowledge memorization from reasoning. Our model enables effective generalization to new classes by simply replacing the memory contents, without the need for model retraining. Unlike traditional models that encode both world knowledge and task-specific skills into their weights during training, our model stores knowledge in the external memory of web-crawled image and text data. At inference time, the model dynamically selects relevant content from the memory based on the input image, allowing it to adapt to arbitrary classes by simply replacing the memory contents. The key differentiator that our learner meta-learns to perform classification tasks with noisy web data from unseen classes, resulting in robust performance across various classification scenarios. Experimental results demonstrate the promising performance and versatility of our approach in handling diverse classification tasks, including zero-shot/few-shot classification of unseen classes, fine-grained classification, and class-incremental classification.},
  archive      = {J_TMLR},
  author       = {Dahyun Kang and Ahmet Iscen and Eunchan Jo and Sua Choi and Minsu Cho and Cordelia Schmid},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Memory-modular classification: Learning to generalize with memory replacement},
  url          = {https://openreview.net/forum?id=DcIW0idrg8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster tree for nearest neighbor search. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ELtNtkGXoK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree-based algorithms are an important and widely used class of algorithms for Nearest Neighbor Search (NNS) with random partition (RP) tree being arguably the most well studied. However, in spite of possessing theoretical guarantees and strong practical performance, a major drawback of the RP tree is its lack of adaptability to the input dataset. Inspired by recent theoretical and practical works for NNS, we attempt to remedy this by introducing *ClusterTree*, a new tree based algorithm. Our approach utilizes randomness as in RP trees while adapting to the underlying cluster structure of the dataset to create well-balanced and meaningful partitions. Experimental evaluations on real world datasets demonstrate improvements over RP trees and other tree based methods for NNS while maintaining efficient construction time. In addition, we show theoretically and empirically that *ClusterTree* finds partitions which are superior to those found by RP trees in preserving the cluster structure of the input dataset.},
  archive      = {J_TMLR},
  author       = {Dan Kushnir and Sandeep Silwal},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cluster tree for nearest neighbor search},
  url          = {https://openreview.net/forum?id=ELtNtkGXoK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparsified state-space models are efficient highway
networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=G1p0YwrX8X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-space models (SSMs) offer a promising architecture for sequence modeling, providing an alternative to Transformers by replacing expensive self-attention with linear recurrences. In this paper, we propose a simple yet effective trick to enhance SSMs within given computational budgets by sparsifying them. Our intuition is that tokens in SSMs are highly redundant due to gradual recurrent updates, and dense recurrence operations block the delivery of past information. In particular, we observe that upper layers of SSMs tend to be more redundant as they encode global information, while lower layers encode local information. Motivated by this, we introduce Simba, a hierarchical sparsification method for SSMs based on token pruning. Simba sparsifies upper layers more than lower layers, encouraging the upper layers to behave like highways. To achieve this, we propose a novel token pruning criterion for SSMs, measuring the global impact of tokens on the final output by accumulating local recurrences. We demonstrate that Simba outperforms the baseline model, Mamba, with the same FLOPS in various natural language tasks. Moreover, we illustrate the effect of highways, showing that Simba not only enhances efficiency but also improves the information flow across long sequences. Code is available at https://github.com/woominsong/Simba.},
  archive      = {J_TMLR},
  author       = {Woomin Song and Jihoon Tack and Sangwoo Mo and Seunghyuk Oh and Jinwoo Shin},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Sparsified state-space models are efficient highway networks},
  url          = {https://openreview.net/forum?id=G1p0YwrX8X},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient training of multi-task neural solver for
combinatorial optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HJbcwRbMQQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently training a multi-task neural solver for various combinatorial optimization problems (COPs) has been less studied so far. Naive application of conventional multi-task learning approaches often falls short in delivering a high-quality, unified neural solver. This deficiency primarily stems from the significant computational demands and a lack of adequate consideration for the complexities inherent in COPs. In this paper, we propose a general and efficient training paradigm to deliver a unified combinarotial multi-task neural solver. To this end, we resort to the theoretical loss decomposition for multiple tasks under an encoder-decoder framework, which enables more efficient training via proper bandit task-sampling algorithms through an intra-task influence matrix. By employing theoretically grounded approximations, our method significantly enhances overall performance, regardless of whether it is within constrained training budgets, across equivalent training epochs, or in terms of generalization capabilities, when compared to conventional training schedules. On the real-world datasets of TSPLib and CVRPLib, our method also achieved the best results compared to single task learning and multi-task learning approaches. Additionally, the influence matrix provides empirical evidence supporting common practices in the field of learning to optimize, further substantiating the effectiveness of our approach. Our code is open-sourced and available at \url{https://github.com/LOGO-CUHKSZ/MTL-COP}.},
  archive      = {J_TMLR},
  author       = {Chenguang Wang and Zhang-Hua Fu and Pinyan Lu and Tianshu Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Efficient training of multi-task neural solver for combinatorial optimization},
  url          = {https://openreview.net/forum?id=HJbcwRbMQQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent representations in networks trained with the
forward-forward algorithm. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JhYbGiFn3Y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Backpropagation algorithm has often been criticised for its lack of biological realism. In an attempt to find a more biologically plausible alternative, the recently introduced Forward-Forward algorithm replaces the forward and backward passes of Backpropagation with two forward passes. In this work, we show that the internal representations obtained by the Forward-Forward algorithm can organise into category-specific ensembles exhibiting high sparsity -- composed of a low number of active units. This situation is reminiscent of what has been observed in cortical sensory areas, where neuronal ensembles are suggested to serve as the functional building blocks for perception and action. Interestingly, while this sparse pattern does not typically arise in models trained with standard Backpropagation, it can emerge in networks trained with Backpropagation on the same objective proposed for the Forward-Forward algorithm.},
  archive      = {J_TMLR},
  author       = {Niccolo Tosato and Lorenzo Basile and Emanuele Ballarin and Giuseppe De Alteriis and Alberto Cazzaniga and Alessio ansuini},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Emergent representations in networks trained with the forward-forward algorithm},
  url          = {https://openreview.net/forum?id=JhYbGiFn3Y},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FRAP: Faithful and realistic text-to-image generation with
adaptive prompt weighting. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=MKCwO34oIq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-image (T2I) diffusion models have demonstrated impressive capabilities in generating high-quality images given a text prompt. However, ensuring the prompt-image alignment remains a considerable challenge, i.e., generating images that faithfully align with the prompt&#39;s semantics. Recent works attempt to improve the faithfulness by optimizing the latent code, which potentially could cause the latent code to go out-of-distribution and thus produce unrealistic images. In this paper, we propose FRAP, a simple, yet effective approach based on adaptively adjusting the per-token prompt weights to improve prompt-image alignment and authenticity of the generated images. We design an online algorithm to adaptively update each token&#39;s weight coefficient, which is achieved by minimizing a unified objective function that encourages object presence and the binding of object-modifier pairs. Through extensive evaluations, we show FRAP generates images with significantly higher prompt-image alignment to prompts from complex datasets, while having a lower average latency compared to recent latent code optimization methods, e.g., 4 seconds faster than D&amp;B on the COCO-Subject dataset. Furthermore, through visual comparisons and evaluation of the CLIP-IQA-Real metric, we show that FRAP not only improves prompt-image alignment but also generates more authentic images with realistic appearances. We also explore combining FRAP with prompt rewriting LLM to recover their degraded prompt-image alignment, where we observe improvements in both prompt-image alignment and image quality. We release the code at the following link: https://github.com/LiyaoJiang1998/FRAP/.},
  archive      = {J_TMLR},
  author       = {Liyao Jiang and Negar Hassanpour and Mohammad Salameh and Mohan Sai Singamsetti and Fengyu Sun and Wei Lu and Di Niu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FRAP: Faithful and realistic text-to-image generation with adaptive prompt weighting},
  url          = {https://openreview.net/forum?id=MKCwO34oIq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture-of-transformers: A sparse and scalable architecture
for multi-modal foundation models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Nu6N69i8SB">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of large language models (LLMs) has expanded to multi-modal systems capable of processing text, images, and speech within a unified framework. Training these models demands significantly larger datasets and computational resources compared to text-only LLMs. To address the scaling challenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modal transformer architecture that significantly reduces pretraining computational costs. MoT decouples non-embedding parameters of the model by modality -- including feed-forward networks, attention matrices, and layer normalization -- enabling modality-specific processing with global self-attention over the full input sequence. We evaluate MoT across multiple settings and model scales. In the Chameleon 7B setting (autoregressive text-and-image generation), MoT matches the dense baseline&#39;s performance using only 55.8% of the FLOPs. When extended to include speech, MoT reaches speech performance comparable to the dense baseline with only 37.2% of the FLOPs. In the Transfusion setting, where text and image are trained with different objectives, a 7B MoT model matches the image modality performance of the dense baseline with one third of the FLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key image generation metrics. System profiling further highlights MoT&#39;s practical benefits, achieving dense baseline image quality in 47.2% of the wall-clock time and text quality in 75.6% of the wall-clock time (measured on AWS p4de.24xlarge instances with NVIDIA A100 GPUs).},
  archive      = {J_TMLR},
  author       = {Weixin Liang and LILI YU and Liang Luo and Srini Iyer and Ning Dong and Chunting Zhou and Gargi Ghosh and Mike Lewis and Wen-tau Yih and Luke Zettlemoyer and Xi Victoria Lin},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixture-of-transformers: A sparse and scalable architecture for multi-modal foundation models},
  url          = {https://openreview.net/forum?id=Nu6N69i8SB},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Daphne: Multi-pass compilation of probabilistic programs
into graphical models and neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OGCuDFab4b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Daphne is a probabilistic programming system that provides an expressive syntax to denote a large, but restricted, class of probabilistic models. Programs written in the Daphne language can be compiled into a general graph data structure of a corresponding probabilistic graphical model with simple link functions that can easily be implemented in a wide range of programming environments. Alternatively Daphne can also further compile such a graphical model into understandable and vectorized PyTorch code that can be used to train neural networks for inference. The Daphne compiler is structured in a layered multi-pass compiler framework that allows independent and easy extension of the syntax by adding additional passes. It leverages extensive partial evaluation to reduce all syntax extensions to the graphical model at compile time.},
  archive      = {J_TMLR},
  author       = {Christian Dietrich Weilbach and Frank Wood},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Daphne: Multi-pass compilation of probabilistic programs into graphical models and neural networks},
  url          = {https://openreview.net/forum?id=OGCuDFab4b},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive incentive design for markov decision processes with
unknown rewards. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Rwf31BYTAU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incentive design, also known as model design or environment design for Markov decision processes(MDPs), refers to a class of problems in which a leader can incentivize his follower by modifying the follower&#39;s reward function, in anticipation that the follower&#39;s optimal policy in the resulting MDP can be desirable for the leader&#39;s objective. In this work, we propose gradient-ascent algorithms to compute the leader&#39;s optimal incentive design, despite the lack of knowledge about the follower&#39;s reward function. First, we formulate the incentive design problem as a bi-level optimization problem and demonstrate that, by the softmax temporal consistency between the follower&#39;s policy and value function, the bi-level optimization problem can be reduced to single-level optimization, for which a gradient-based algorithm can be developed to optimize the leader&#39;s objective. We establish several key properties of incentive design in MDPs and prove the convergence of the proposed gradient-based method. Next, we show that the gradient terms can be estimated from observations of the follower&#39;s best response policy, enabling the use of a stochastic gradient-ascent algorithm to compute a locally optimal incentive design without knowing or learning the follower&#39;s reward function. Finally, we analyze the conditions under which an incentive design remains optimal for two different rewards which are policy invariant. The effectiveness of the proposed algorithm is demonstrated using a small probabilistic transition system and a stochastic gridworld.},
  archive      = {J_TMLR},
  author       = {Haoxiang Ma and Shuo Han and Ahmed Hemida and Charles A kamhoua and Jie Fu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive incentive design for markov decision processes with unknown rewards},
  url          = {https://openreview.net/forum?id=Rwf31BYTAU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation-based bayesian inference from privacy protected
data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=SB7JzhDG45">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many modern statistical analysis and machine learning applications require training models on sensitive user data. Under a formal definition of privacy protection, differentially private algorithms inject calibrated noise into the confidential data or during the data analysis process to produce privacy-protected datasets or queries. However, restricting access to only privatized data during statistical analysis makes it computationally challenging to make valid statistical inferences. In this work, we propose simulation-based inference methods from privacy-protected datasets. In addition to sequential Monte Carlo approximate Bayesian computation, we adopt neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and with ordinary linear regression models. Illustrating the privacy-utility trade-off, our experiments and analysis demonstrate the necessity and feasibility of designing valid statistical inference procedures to correct for biases introduced by the privacy-protection mechanisms.},
  archive      = {J_TMLR},
  author       = {Yifei Xiong and Nianqiao Ju and Sanguo Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Simulation-based bayesian inference from privacy protected data},
  url          = {https://openreview.net/forum?id=SB7JzhDG45},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuron-based explanations of neural networks sacrifice
completeness and interpretability. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UWNa9Pv6qA">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High quality explanations of neural networks (NNs) should exhibit two key properties. Completeness ensures that they accurately reflect a network’s function and interpretability makes them understandable to humans. Many existing methods provide explanations of individual neurons within a network. In this work we provide evidence that for AlexNet pretrained on ImageNet, neuron-based explanation methods sacrifice both completeness and interpretability compared to activation principal components. Neurons are a poor basis for AlexNet embeddings because they don’t account for the distributed nature of these representations. By examining two quantitative measures of completeness and conducting a user study to measure interpretability, we show the most important principal components provide more complete and interpretable explanations than the most important neurons. Much of the activation variance may be explained by examining relatively few high-variance PCs, as opposed to studying every neuron. These principal components also strongly affect network function, and are significantly more interpretable than neurons. Our findings suggest that explanation methods for networks like AlexNet should avoid using neurons as a basis for embeddings and instead choose a basis, such as principal components, which accounts for the high dimensional and distributed nature of a network&#39;s internal representations. Interactive demo and code available at https://ndey96.github.io/neuron-explanations-sacrifice.},
  archive      = {J_TMLR},
  author       = {Nolan Simran Dey and Eric Taylor and Alexander Wong and Bryan P. Tripp and Graham W. Taylor},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neuron-based explanations of neural networks sacrifice completeness and interpretability},
  url          = {https://openreview.net/forum?id=UWNa9Pv6qA},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On using certified training towards empirical robustness.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UaaT2fI9DC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training is arguably the most popular way to provide empirical robustness against specific adversarial examples. While variants based on multi-step attacks incur significant computational overhead, single-step variants are vulnerable to a failure mode known as catastrophic overfitting, which hinders their practical utility for large perturbations. A parallel line of work, certified training, has focused on producing networks amenable to formal guarantees of robustness against any possible attack. However, the wide gap between the best-performing empirical and certified defenses has severely limited the applicability of the latter. Inspired by recent developments in certified training, which rely on a combination of adversarial attacks with network over-approximations, and by the connections between local linearity and catastrophic overfitting, we present experimental evidence on the practical utility and limitations of using certified training towards empirical robustness. We show that, when tuned for the purpose, a recent certified training algorithm can prevent catastrophic overfitting on single-step attacks, and that it can bridge the gap to multi-step baselines under appropriate experimental settings. Finally, we present a conceptually simple regularizer for network over-approximations that can achieve similar effects while markedly reducing runtime.},
  archive      = {J_TMLR},
  author       = {Alessandro De Palma and Serge Durand and Zakaria Chihani and François Terrier and Caterina Urban},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On using certified training towards empirical robustness},
  url          = {https://openreview.net/forum?id=UaaT2fI9DC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust symbolic regression for dynamical system
identification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZfPbCFZQbx">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world complex systems often miss high-fidelity physical descriptions and are typically subject to partial observability. Learning the dynamics of such systems is a challenging and ubiquitous problem, encountered in diverse critical applications which require interpretability and qualitative guarantees.Our paper addresses this problem in the case of sparsely observed probability distribution flows, governed by ODEs. Specifically, we devise a {\it white box} approach -dubbed Symbolic Distribution Flow Learner (\texttt{SDFL})- leveraging symbolic search with a Wasserstein-based loss function, resulting in a robust model-recovery scheme which naturally lends itself to cope with partial observability. Additionally, we furnish the proposed framework with theoretical guarantees on the number of required {\it snapshots} to achieve a certain level of fidelity in the model-discovery. We illustrate the performance of the proposed scheme on the prototypical problem of Kuramoto networks and a standard benchmark of single-cell RNA sequence trajectory data. The numerical experiments demonstrate the competitive performance of \texttt{SDFL} in comparison to the state-of-the-art.},
  archive      = {J_TMLR},
  author       = {Ramzi Dakhmouche and Ivan Lunati and Hossein Gorji},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust symbolic regression for dynamical system identification},
  url          = {https://openreview.net/forum?id=ZfPbCFZQbx},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedDr+: Stabilizing dot-regression with global feature
distillation for federated learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=a6WthNFhL2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has emerged as a pivotal framework for the development of effective global models (global FL) or personalized models (personalized FL) across clients with heterogeneous, non-iid data distribution. A key challenge in FL is client drift, where data heterogeneity impedes the aggregation of scattered knowledge. Recent studies have tackled the client drift issue by identifying significant divergence in the last linear (classifier) layer. To mitigate this divergence, strategies such as freezing the classifier weights and aligning the feature extractor accordingly have proven effective. Although the local alignment between classifier and feature extractor has been studied as a crucial factor in FL, we observe that it may lead the model to overemphasize the observed classes and underestimate the unobserved classes within each client. Therefore, our goals are twofold: (1) improving local alignment and (2) maintaining the representation of unseen class samples, ensuring that the solution seamlessly incorporates knowledge from individual clients, thus enhancing performance in both global and personalized FL. To achieve this, we introduce a novel algorithm named FedDr+, which empowers local model alignment using dot-regression loss. FedDr+ freezes the classifier as a simplex ETF to align the features and improves aggregated global models by employing a feature distillation mechanism to retain information about unseen/missing classes. Our empirical results demonstrate that FedDr+ not only outperforms methods with a frozen classifier but also surpasses other state-of-the-art approaches, ensuring robust performance across diverse data distributions.},
  archive      = {J_TMLR},
  author       = {Seongyoon Kim and Minchan Jeong and Sungnyun Kim and Sungwoo Cho and Sumyeong Ahn and Se-Young Yun},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FedDr+: Stabilizing dot-regression with global feature distillation for federated learning},
  url          = {https://openreview.net/forum?id=a6WthNFhL2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified view of double-weighting for marginal distribution
shift. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=aPyJilTiIb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised classification traditionally assumes that training and testing samples are drawn from the same underlying distribution. However, practical scenarios are often affected by distribution shifts, such as covariate and label shifts. Most existing techniques for correcting distribution shifts are based on a reweighted approach that weights training samples, assigning lower relevance to the samples that are unlikely at testing. However, these methods may achieve poor performance when the weights obtained take large values at certain training samples. In addition, in multi-source cases, existing methods do not exploit complementary information among sources, and equally combine sources for all instances. In this paper, we establish a unified learning framework for distribution shift adaptation. We present a double-weighting approach to deal with distribution shifts, considering weight functions associated with both training and testing samples. For the multi-source case, the presented methods assign source-dependent weights for training and testing samples, where weights are obtained jointly using information from all sources. We also present generalization bounds for the proposed methods that show a significant increase in the effective sample size compared with existing approaches. Empirically, the proposed methods achieve enhanced classification performance in both synthetic and empirical experiments.},
  archive      = {J_TMLR},
  author       = {José I. Segovia-Martín and Santiago Mazuelas and Anqi Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A unified view of double-weighting for marginal distribution shift},
  url          = {https://openreview.net/forum?id=aPyJilTiIb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning population-based methods for reinforcement
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=d9htascfP8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL) algorithms are highly sensitive to their hyperparameter settings. Recently, numerous methods have been proposed to dynamically optimize these hyperparameters. One prominent approach is Population-Based Bandits (PB2), which uses time-varying Gaussian processes (GP) to dynamically optimize hyperparameters with a population of parallel agents. Despite its strong overall performance, PB2 experiences slow starts due to the GP initially lacking sufficient information. To mitigate this issue, we propose four different methods that utilize meta-data from various environments. These approaches are novel in that they adapt meta-learning methods to accommodate the time-varying setting. Among these approaches, MultiTaskPB2, which uses meta-learning for the surrogate model, stands out as the most promising approach. It outperforms PB2 and other baselines in both anytime and final performance across two RL environment families.},
  archive      = {J_TMLR},
  author       = {Johannes Hog and Raghu Rajan and André Biedenkapp and Noor Awad and Frank Hutter and Vu Nguyen},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning population-based methods for reinforcement learning},
  url          = {https://openreview.net/forum?id=d9htascfP8},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic neural operators for functional uncertainty
quantification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gangoPXSRw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural operators aim to approximate the solution operator of a system of differential equations purely from data. They have shown immense success in modeling complex dynamical systems across various domains. However, the occurrence of uncertainties inherent in both model and data has so far rarely been taken into account\textemdash{}a critical limitation in complex, chaotic systems such as weather forecasting. In this paper, we introduce the probabilistic neural operator (PNO), a framework for learning probability distributions over the output function space of neural operators. PNO extends neural operators with generative modeling based on strictly proper scoring rules, integrating uncertainty information directly into the training process. We provide a theoretical justification for the approach and demonstrate improved performance in quantifying uncertainty across different domains and with respect to different baselines. Furthermore, PNO requires minimal adjustment to existing architectures, shows improved performance for most probabilistic prediction tasks, and leads to well-calibrated predictive distributions and adequate uncertainty representations even for long dynamical trajectories. Implementing our approach into large-scale models for physical applications can lead to improvements in corresponding uncertainty quantification and extreme event identification, ultimately leading to a deeper understanding of the prediction of such surrogate models.},
  archive      = {J_TMLR},
  author       = {Christopher Bülte and Philipp Scholl and Gitta Kutyniok},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Probabilistic neural operators for functional uncertainty quantification},
  url          = {https://openreview.net/forum?id=gangoPXSRw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAFE-NID: Self-attention with normalizing-flow encodings for
network intrusion detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=hDywd5AbIM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models are increasingly adopted to monitor network traffic and detect intrusions. In this work, we introduce SAFE-NID, a novel machine learning approach for real-time packet-level traffic monitoring and intrusion detection that includes a safeguard to detect zero day attacks as out-of-distribution inputs. Unlike traditional models, which falter against zero-day attacks and concept drift, SAFE-NID leverages a lightweight encoder-only transformer architecture combined with a novel normalizing flows-based safeguard. This safeguard not only quantifies uncertainty but also identifies out-of-distribution (OOD) inputs, enabling robust performance in dynamic threat landscapes. Our generative model learns class-conditional representations of the internal features of the deep neural network. We demonstrate the effectiveness of our approach by converting publicly available network flow-level intrusion datasets into packet-level ones. We release the labeled packet-level versions of these datasets with over 50 million packets each and describe the challenges in creating these datasets. We withhold from the training data certain attack categories to simulate zero-day attacks. Existing deep learning models, which achieve an accuracy of over 99% when detecting known attacks, only correctly classify 1% of the novel attacks. Our proposed transformer architecture with normalizing flows model safeguard achieves an area under the receiver operating characteristic curve of over 0.97 in detecting these novel inputs, outperforming existing combinations of neural architectures and model safeguards. The additional latency in processing each packet by the safeguard is a small fraction of the overall inference task. This dramatic improvement in detecting zero-day attacks and distribution shifts emphasizes SAFE-NID’s novelty and utility as a reliable and efficient safety monitoring tool for real-world network intrusion detection.},
  archive      = {J_TMLR},
  author       = {Brian Matejek and Ashish Gehani and Nathaniel D. Bastian and Daniel J Clouse and Bradford J Kline and Susmit Jha},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SAFE-NID: Self-attention with normalizing-flow encodings for network intrusion detection},
  url          = {https://openreview.net/forum?id=hDywd5AbIM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Posterior sampling for reinforcement learning on graphs.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=kd6CfmdPfX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many Markov Decision Processes (MDPs) exhibit structure in their state and action spaces that is not exploited. We consider the case where the structure can be modelled using a directed acyclic graph (DAG) composed of nodes and edges. In this case, each node has a state, and the state transition dynamics are influenced by the states and actions at its parent nodes. We propose an MDP framework, \emph{Directed Acyclic Markov Decision Process} (DAMDP) that formalises this problem, and we develop algorithms to perform planning and learning. Crucially, DAMDPs retain many of the benefits of MDPs, as we can show that Dynamic Programming can find the optimal policy in known DAMDPs. We also demonstrate how to perform Reinforcement Learning in DAMDPs when the transition probabilities and the reward function are unknown. To this end, we derive a posterior sampling-based algorithm that is able to leverage the graph structure to boost learning efficiency. Moreover, we obtain a theoretical bound on the Bayesian regret for this algorithm, which directly shows the efficiency gain from considering the graph structure. We then conclude by empirically demonstrating that by harnessing the DAMDP, our algorithm outperforms traditional posterior sampling for Reinforcement Learning in both a maximum flow problem and a real-world wind farm optimisation task.},
  archive      = {J_TMLR},
  author       = {Arnaud Robert and Aldo A. Faisal and Ciara Pike-Burke},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Posterior sampling for reinforcement learning on graphs},
  url          = {https://openreview.net/forum?id=kd6CfmdPfX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compositionality in time series: A proof of concept using
symbolic dynamics and compositional data augmentation. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=msI02LXVJX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates whether time series of natural phenomena can be understood as being generated by sequences of latent states which are ordered in systematic and regular ways. We focus on clinical time series and ask whether clinical measurements can be interpreted as being generated by meaningful physiological states whose succession follows systematic principles. Uncovering the underlying compositional structure will allow us to create synthetic data to alleviate the notorious problem of sparse and low-resource data settings in clinical time series forecasting, and deepen our understanding of clinical data. We start by conceptualizing compositionality for time series as a property of the data generation process, and then study data-driven procedures that can reconstruct the elementary states and composition rules of this process. We evaluate the success of this methods using two empirical tests originating from a domain adaptation perspective. Both tests infer the similarity of the original time series distribution and the synthetic time series distribution from the similarity of expected risk of time series forecasting models trained and tested on original and synthesized data in specific ways. Our experimental results show that the test set performance achieved by training on compositionally synthesized data is comparable to training on original clinical time series data, and that evaluation of models on compositionally synthesized test data shows similar results to evaluating on original test data. In both experiments, performance based on compositionally synthesized data by far surpasses that based on synthetic data that were created by randomization-based data augmentation. An additional downstream evaluation of the prediction task of sequential organ failure assessment (SOFA) scores shows significant performance gains when model training is entirely based on compositionally synthesized data compared to training on original data, with improvements increasing with the size of the synthesized training set.},
  archive      = {J_TMLR},
  author       = {Michael Hagmann and Michael Staniek and Stefan Riezler},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Compositionality in time series: A proof of concept using symbolic dynamics and compositional data augmentation},
  url          = {https://openreview.net/forum?id=msI02LXVJX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplayer information asymmetric contextual bandits.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nMCJ8bFq4B">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-player contextual bandits are a well-studied problem in reinforcement learning that has seen applications in various fields such as advertising, healthcare, and finance. In light of the recent work on information asymmetric bandits, we propose a novel multiplayer information asymmetric contextual bandit framework where there are multiple players each with their own set of actions. At every round, they observe the same context vectors and simultaneously take an action from their own set of actions, giving rise to a joint action. However, upon taking this action the players are subjected to information asymmetry in (1) actions and/or (2) rewards. We designed an algorithm mLinUCB by modifying the classical single-player algorithm LinUCB in \cite{chu2011contextual} to achieve the optimal regret $O(\sqrt{T})$ when only one kind of asymmetry is present. We then propose a novel algorithm ETC that is built on explore-then-commit principles to achieve the same optimal regret when both types of asymmetry are present.},
  archive      = {J_TMLR},
  author       = {William Chang and Yuanhao Lu},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Multiplayer information asymmetric contextual bandits},
  url          = {https://openreview.net/forum?id=nMCJ8bFq4B},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding and robustifying sub-domain alignment for
domain adaptation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=oAzu0gzUUb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In unsupervised domain adaptation (UDA), aligning source and target domains improves the predictive performance of learned models on the target domain. A common methodological improvement in alignment methods is to divide the domains and align sub-domains instead. These sub-domain-based algorithms have demonstrated great empirical success but lack theoretical support. In this work, we establish a rigorous theoretical understanding of the advantages of these methods that have the potential to enhance their overall impact on the field. Our theory uncovers that sub-domain-based methods optimize an error bound that is at least as strong as non-sub-domain-based error bounds and is empirically verified to be much stronger. Furthermore, our analysis indicates that when the marginal weights of sub-domains shift between source and target tasks, the performance of these methods may be compromised. We therefore implement an algorithm to robustify sub-domain alignment for domain adaptation under sub-domain shift, offering a valuable adaptation strategy for future sub-domain-based methods. Empirical experiments across various benchmarks validate our theoretical insights, prove the necessity for the proposed adaptation strategy, and demonstrate the algorithm&#39;s competitiveness in handling label shift.},
  archive      = {J_TMLR},
  author       = {Yiling Liu and Juncheng Dong and Ziyang Jiang and Ahmed Aloui and Keyu Li and Michael Hunter Klein and Vahid Tarokh and David Carlson},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding and robustifying sub-domain alignment for domain adaptation},
  url          = {https://openreview.net/forum?id=oAzu0gzUUb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relationship between batch size and number of steps needed
for nonconvex optimization of stochastic gradient descent using
armijo-line-search learning rate. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=pqZ6nOm3WF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While stochastic gradient descent (SGD) can use various learning rates, such as constant or diminishing rates, previous numerical results showed that SGD performs better than other deep-learning optimizers when it uses learning rates given by line search methods. In this paper, we perform a convergence analysis on SGD with a learning rate given by an Armijo line search for nonconvex optimization indicating that the upper bound of the expectation of the squared norm of the full gradient becomes small when the number of steps and the batch size are large. Next, we show that, for SGD with the Armijo-line-search learning rate, the number of steps needed for nonconvex optimization is a monotone decreasing convex function of the batch size; that is, the number of steps needed for nonconvex optimization decreases as the batch size increases. Furthermore, we show that the stochastic first-order oracle (SFO) complexity, which is the stochastic gradient computation cost, is a convex function of the batch size; that is, there exists a critical batch size that minimizes the SFO complexity. Finally, we provide numerical results that support our theoretical results.},
  archive      = {J_TMLR},
  author       = {Yuki Tsukada and Hideaki Iiduka},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Relationship between batch size and number of steps needed for nonconvex optimization of stochastic gradient descent using armijo-line-search learning rate},
  url          = {https://openreview.net/forum?id=pqZ6nOm3WF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information theoretic approach to machine unlearning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=t1utIThKHD">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To comply with AI and data regulations, the need to forget private or copyrighted information from trained machine learning models is increasingly important. The key challenge in unlearning is forgetting the necessary data in a timely manner, while preserving model performance. In this work, we address the zero-shot unlearning scenario, whereby an unlearning algorithm must be able to remove data given only a trained model and the data to be forgotten. We explore unlearning from an information theoretic perspective, connecting the influence of a sample to the information gain a model receives by observing it. From this, we derive a simple but principled zero-shot unlearning method based on the geometry of the model. Our approach takes the form of minimising the gradient of a learned function with respect to a small neighbourhood around a target forget point. This induces a smoothing effect, causing forgetting by moving the boundary of the classifier. We explore the intuition behind why this approach can jointly unlearn forget samples while preserving general model performance through a series of low-dimensional experiments. We perform extensive empirical evaluation of our method over a range of contemporary benchmarks, verifying that our method is competitive with state-of-the-art performance under the strict constraints of zero-shot unlearning.},
  archive      = {J_TMLR},
  author       = {Jack Foster and Kyle Fogarty and Stefan Schoepf and Zack Dugue and Cengiz Oztireli and Alexandra Brintrup},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An information theoretic approach to machine unlearning},
  url          = {https://openreview.net/forum?id=t1utIThKHD},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Influence learning in complex systems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tUnyInYbjK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High sample complexity hampers the successful application of reinforcement learning methods, especially in real-world problems where simulating complex dynamics is computationally demanding. Influence-based abstraction (IBA) was proposed to mitigate this issue by breaking down the global model of large-scale distributed systems, such as traffic control problems, into small local sub-models. Each local model includes only a few state variables and a representation of the influence exerted by the external portion of the system. This approach allows converting a complex simulator into local lightweight simulators, enabling more effective applications of planning and reinforcement learning methods. However, the effectiveness of IBA critically depends on the ability to accurately approximate the influence of each local model. While there are a few examples showing promising results in benchmark problems, the question of whether this approach is feasible in more practical scenarios remains open. In this work, we take steps towards addressing this question by conducting an extensive empirical study of learning models for influence approximations in various realistic domains, and evaluating how these models generalize over long horizons. We find that learning the influence is often a manageable learning task, even for complex and large systems. Additionally, we demonstrate the efficacy of the approximation models for long-horizon problems. By using short trajectories, we can learn accurate influence approximations for much longer horizons.},
  archive      = {J_TMLR},
  author       = {Elena Congeduti and roberto rocchetta and Frans A Oliehoek},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Influence learning in complex systems},
  url          = {https://openreview.net/forum?id=tUnyInYbjK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Building blocks for robust and effective semi-supervised
real-world object detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=vRYt8QLKqK">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised object detection (SSOD) based on pseudo-labeling significantly reduces dependence on large labeled datasets by effectively leveraging both labeled and unlabeled data. However, real-world applications of SSOD often face critical challenges, including class imbalance, label noise, and labeling errors. We present an in-depth analysis of SSOD under real-world conditions, uncovering causes of suboptimal pseudo-labeling and key trade-offs between label quality and quantity. Based on our findings, we propose four building blocks that can be seamlessly integrated into an SSOD framework. Rare Class Collage (RCC): a data augmentation method that enhances the representation of rare classes by creating collages of rare objects. Rare Class Focus (RCF): a stratified batch sampling strategy that ensures a more balanced representation of all classes during training. Ground Truth Label Correction (GLC): a label refinement method that identifies and corrects false, missing, and noisy ground truth labels by leveraging the consistency of teacher model predictions. Pseudo-Label Selection (PLS): a selection method for removing low-quality pseudo-labeled images, guided by a novel metric estimating the missing detection rate while accounting for class rarity. We validate our methods through comprehensive experiments on autonomous driving datasets, resulting in up to 6% increase in SSOD performance. Overall, our investigation and novel, data-centric, and broadly applicable building blocks enable robust and effective SSOD in complex, real-world scenarios. Code is available at https://mos-ks.github.io/publications.},
  archive      = {J_TMLR},
  author       = {Moussa Kassem Sbeyti and Nadja Klein and Azarm Nowzad and Fikret Sivrikaya and Sahin Albayrak},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Building blocks for robust and effective semi-supervised real-world object detection},
  url          = {https://openreview.net/forum?id=vRYt8QLKqK},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Salsa fresca: Angular embeddings and pre-training for ML
attacks on learning with errors. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=w4nd5695sq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with Errors (LWE) is a hard math problem underlying recently standardized post-quantum cryptography (PQC) systems for key exchange and digital signatures. Prior work proposed new machine learning (ML)-based attacks on LWE problems with small, sparse secrets, but these attacks require millions of LWE samples to train on and take days to recover secrets. We propose three key methods---better preprocessing, angular embeddings and model pre-training---to improve these attacks, speeding up preprocessing by $25\times$ and improving model sample efficiency by $10\times$. We demonstrate for the first time that pre-training improves and reduces the cost of ML attacks on LWE. Our architecture improvements enable scaling to larger-dimension LWE problems: this work is the first instance of ML attacks recovering sparse binary secrets in dimension $n=1024$, the smallest dimension used in practice for homomorphic encryption applications of LWE where sparse binary secrets are proposed, albeit for larger modulus $q$. Our ML-based approach is the only attack which has successfully recovered secrets for these parameters.},
  archive      = {J_TMLR},
  author       = {Samuel Stevens and Emily Wenger and Cathy Yuanchen Li and Niklas Nolte and Eshika Saxena and Francois Charton and Kristin E. Lauter},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Salsa fresca: Angular embeddings and pre-training for ML attacks on learning with errors},
  url          = {https://openreview.net/forum?id=w4nd5695sq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A limitation on black-box dynamics approaches to
reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wPHVijYksq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove a fundamental limitation on the computational efficiency of a large class of Reinforcement Learning (RL) methods. This limitation applies to model-free RL methods as well as some model-based methods, such as AlphaZero. We provide a formalism that describes this class and present a family of RL problems provably intractable for these methods. Conversely, the problems in the family can be efficiently solved by toy methods. We identify several types of algorithms proposed in the literature that can avoid our limitation, including algorithms that construct an inverse dynamics model, and planning algorithms that leverage an explicit model of the dynamics.},
  archive      = {J_TMLR},
  author       = {Brieuc Pinon and Raphael Jungers and Jean-Charles Delvenne},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A limitation on black-box dynamics approaches to reinforcement learning},
  url          = {https://openreview.net/forum?id=wPHVijYksq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What’s left after distillation? How knowledge transfer
impacts fairness and bias. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xBbj46Y2fN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Distillation is a commonly used Deep Neural Network (DNN) compression method, which often maintains overall generalization performance. However, we show that even for balanced image classification datasets, such as CIFAR-100, Tiny ImageNet and ImageNet, as many as 41% of the classes are statistically significantly affected by distillation when comparing class-wise accuracy (i.e. class bias) between a teacher/distilled student or distilled student/non-distilled student model. Changes in class bias are not necessarily an undesirable outcome when considered outside of the context of a model’s usage. Using two common fairness metrics, Demographic Parity Difference (DPD) and Equalized Odds Difference (EOD) on models trained with the CelebA, Trifeature, and HateXplain datasets, our results suggest that increasing the distillation temperature improves the distilled student model’s fairness, and the distilled student fairness can even surpass the fairness of the teacher model at high temperatures. Additionally, we examine individual fairness, ensuring similar instances receive similar predictions. Our results confirm that higher temperatures also improve the distilled student model’s individual fairness. This study highlights the uneven effects of distillation on certain classes and its potentially significant role in fairness, emphasizing that caution is warranted when using distilled models for sensitive application domains.},
  archive      = {J_TMLR},
  author       = {Aida Mohammadshahi and Yani Ioannou},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {What’s left after distillation? how knowledge transfer impacts fairness and bias},
  url          = {https://openreview.net/forum?id=xBbj46Y2fN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting sub-population specific viral evolution.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Mae23iEqPS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting the change in the distribution of viral variants is crucial for therapeutic design and disease surveillance. This task poses significant modeling challenges due to the sharp differences in virus distributions across sub-populations (e.g., countries) and their dynamic interactions. Existing machine learning approaches that model the variant distribution as a whole are incapable of making location-specific predictions and ignore transmissions that shape the viral landscape. In this paper, we propose a sub-population specific protein evolution model, which predicts the time-resolved distributions of viral proteins in different locations. The algorithm explicitly models the transmission rates between sub-populations and learns their interdependence from data. The change in protein distributions across all sub-populations is defined through a linear ordinary differential equation (ODE) parametrized by transmission rates. Solving this ODE yields the likelihood of a given protein occurring in particular sub-populations. Multi-year evaluation on both SARS-CoV-2 and influenza A/H3N2 demonstrates that our model outperforms baselines in accurately predicting distributions of viral proteins across continents and countries. We also find that the transmission rates learned from data are consistent with the transmission pathways discovered by retrospective phylogenetic analysis.},
  archive      = {J_TMLR},
  author       = {Wenxian Shi and Menghua Wu and Regina Barzilay},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Predicting sub-population specific viral evolution},
  url          = {https://openreview.net/forum?id=Mae23iEqPS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposing the dark matter of sparse autoencoders.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sXq3Wb3vef">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse autoencoders (SAEs) are a promising technique for decomposing language model activations into interpretable linear features. However, current SAEs fall short of completely explaining model performance, resulting in ``dark matter&#39;&#39;: unexplained variance in activations. This work investigates dark matter as an object of study in its own right. Surprisingly, we find that much of SAE dark matter---about half of the error vector itself and $&gt;90\% $ of its norm---can be linearly predicted from the initial activation vector. Additionally, we find that the scaling behavior of SAE error norms at a per token level is remarkably predictable: larger SAEs mostly struggle to reconstruct the same contexts as smaller SAEs. We build on the linear representation hypothesis to propose models of activations that might lead to these observations, including postulating a new type of ``introduced error&#39;&#39;; these insights imply that the part of the SAE error vector that cannot be linearly predicted (``nonlinear&#39;&#39; error) might be fundamentally different from the linearly predictable component. To validate this hypothesis, we empirically analyze nonlinear SAE error and show that 1) it contains fewer not yet learned features, 2) SAEs trained on it are quantitatively worse, 3) it helps predict SAE per-token scaling behavior, and 4) it is responsible for a proportional amount of the downstream increase in cross entropy loss when SAE activations are inserted into the model. Finally, we examine two methods to reduce nonlinear SAE error: inference time gradient pursuit, which leads to a very slight decrease in nonlinear error, and linear transformations from earlier layer SAE outputs, which leads to a larger reduction.},
  archive      = {J_TMLR},
  author       = {Joshua Engels and Logan Riggs Smith and Max Tegmark},
  journal      = {Transactions on Machine Learning Research},
  month        = {3},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Decomposing the dark matter of sparse autoencoders},
  url          = {https://openreview.net/forum?id=sXq3Wb3vef},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
