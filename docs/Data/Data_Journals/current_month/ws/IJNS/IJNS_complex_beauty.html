<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJNS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijns---21">IJNS - 21</h2>
<ul>
<li><details>
<summary>
(2025). End-user confidence in artificial intelligence-based
predictions applied to biomedical data. <em>IJNS</em>, <em>35</em>(4),
2550017. (<a href="https://doi.org/10.1142/S0129065725500170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of Artificial Intelligence (AI) are revolutionizing biomedical research and healthcare by offering data-driven predictions that assist in diagnoses. Supervised learning systems are trained on large datasets to predict outcomes for new test cases. However, they typically do not provide an indication of the reliability of these predictions, even though error estimates are integral to model development. Here, we introduce a novel method to identify regions in the feature space that diverge from training data, where an AI model may perform poorly. We utilize a compact precompiled structure that allows for fast and direct access to confidence scores in real time at the point of use without requiring access to the training data or model algorithms. As a result, users can determine when to trust the AI model’s outputs, while developers can identify where the model’s applicability is limited. We validate our approach using simulated data and several biomedical case studies, demonstrating that our approach provides fast confidence estimates ( &lt; 0 . 2 milliseconds per case), with high concordance to previously developed methods ( f - score &gt; 0 . 9 6 5 ). These estimates can be easily added to real-world AI applications. We argue that providing confidence estimates should be a standard practice for all AI applications in public use.},
  archive      = {J_IJNS},
  author       = {Zvi Kam and Lorenzo Peracchio and Giovanna Nicora},
  doi          = {10.1142/S0129065725500170},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550017},
  shortjournal = {Int. J. Neural Syst.},
  title        = {End-user confidence in artificial intelligence-based predictions applied to biomedical data},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimal neural network conditions for encoding future
interactions. <em>IJNS</em>, <em>35</em>(4), 2550016. (<a
href="https://doi.org/10.1142/S0129065725500169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Space and time are fundamental attributes of the external world. Deciphering the brain mechanisms involved in processing the surrounding environment is one of the main challenges in neuroscience. This is particularly defiant when situations change rapidly over time because of the intertwining of spatial and temporal information. However, understanding the cognitive processes that allow coping with dynamic environments is critical, as the nervous system evolved in them due to the pressure for survival. Recent experiments have revealed a new cognitive mechanism called time compaction. According to it, a dynamic situation is represented internally by a static map of the future interactions between the perceived elements (including the subject itself). The salience of predicted interactions (e.g. collisions) over other spatiotemporal and dynamic attributes during the processing of time-changing situations has been shown in humans, rats, and bats. Motivated by this ubiquity, we study an artificial neural network to explore its minimal conditions necessary to represent a dynamic stimulus through the future interactions present in it. We show that, under general and simple conditions, the neural activity linked to the predicted interactions emerges to encode the perceived dynamic stimulus. Our results show that this encoding improves learning, memorization and decision making when dealing with stimuli with impending interactions compared to no-interaction stimuli. These findings are in agreement with theoretical and experimental results that have supported time compaction as a novel and ubiquitous cognitive process.},
  archive      = {J_IJNS},
  author       = {Sergio Diez-Hermano and Gonzalo Aparicio-Rodriguez and Paloma Manubens and Abel Sanchez-Jimenez and Carlos Calvo-Tapia and David Levcik and José Antonio Villacorta-Atienza},
  doi          = {10.1142/S0129065725500169},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550016},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Minimal neural network conditions for encoding future interactions},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-assisted local attention in lower layers of visual
transformers. <em>IJNS</em>, <em>35</em>(4), 2550015. (<a
href="https://doi.org/10.1142/S0129065725500157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since vision transformers excel at establishing global relationships between features, they play an important role in current vision tasks. However, the global attention mechanism restricts the capture of local features, making convolutional assistance necessary. This paper indicates that transformer-based models can attend to local information without using convolutional blocks, similar to convolutional kernels, by employing a special initialization method. Therefore, this paper proposes a novel hybrid multi-scale model called Frequency-Assisted Local Attention Transformer (FALAT). FALAT introduces a Frequency-Assisted Window-based Positional Self-Attention (FWPSA) module that limits the attention distance of query tokens, enabling the capture of local contents in the early stage. The information from value tokens in the frequency domain enhances information diversity during self-attention computation. Additionally, the traditional convolutional method is replaced with a depth-wise separable convolution to downsample in the spatial reduction attention module for long-distance contents in the later stages. Experimental results demonstrate that FALAT-S achieves 83.0% accuracy on IN-1k with an input size of 2 2 4 × 2 2 4 using 29.9 M parameters and 5.6 G FLOPs. This model outperforms the Next-ViT-S by 0.9 AP b /0.8 AP m with Mask-R-CNN 1 × on COCO and surpasses the recent FastViT-SA36 by 3.1% mIoU with FPN on ADE20k.},
  archive      = {J_IJNS},
  author       = {Xin Zhou and Zeyu Jiang and Shihua Zhou and Zhaohui Ren and Yongchao Zhang and Tianzhuang Yu and Yulin Liu},
  doi          = {10.1142/S0129065725500157},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550015},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Frequency-assisted local attention in lower layers of visual transformers},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online and cross-user finger movement pattern recognition by
decoding neural drive information from surface electromyogram.
<em>IJNS</em>, <em>35</em>(4), 2550014. (<a
href="https://doi.org/10.1142/S0129065725500145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-user variability is a well-known challenge that leads to severe performance degradation and impacts the robustness of practical myoelectric control systems. To address this issue, a novel method for myoelectric recognition of finger movement patterns is proposed by incorporating a neural decoding approach with unsupervised domain adaption (UDA) learning. In our method, the neural decoding approach is implemented by extracting microscopic features characterizing individual motor unit (MU) activities obtained from a two-stage online surface electromyogram (SEMG) decomposition. A specific deep learning model is designed and initially trained using labeled data from a set of existing users. The model can update adaptively when recognizing the movement patterns of a new user. The final movement pattern was determined by a fuzzy weighted decision strategy. SEMG signals were collected from the finger extensor muscles of 15 subjects to detect seven dexterous finger-movement patterns. The proposed method achieved a movement pattern recognition accuracy of ( 9 3 . 9 4 ± 1 . 5 4 )% over seven movements under cross-user testing scenarios, much higher than that of the conventional methods using global SEMG features. Our study presents a novel robust myoelectric pattern recognition approach at a fine-grained MU level, with wide applications in neural interface and prosthesis control.},
  archive      = {J_IJNS},
  author       = {Haowen Zhao and Yunfei Liu and Xinhui Li and Xiang Chen and Xu Zhang},
  doi          = {10.1142/S0129065725500145},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550014},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Online and cross-user finger movement pattern recognition by decoding neural drive information from surface electromyogram},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Architecture knowledge distillation for evolutionary
generative adversarial network. <em>IJNS</em>, <em>35</em>(4), 2550013.
(<a href="https://doi.org/10.1142/S0129065725500133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) are effective for image generation, but their unstable training limits broader applications. Additionally, neural architecture search (NAS) for GANs with one-shot models often leads to insufficient subnet training, where subnets inherit weights from a supernet without proper optimization, further degrading performance. To address both issues, we propose Architecture Knowledge Distillation for Evolutionary GAN (AKD-EGAN). AKD-EGAN operates in two stages. First, architecture knowledge distillation (AKD) is used during supernet training to efficiently optimize subnetworks and accelerate learning. Second, a multi-objective evolutionary algorithm (MOEA) searches for optimal subnet architectures, ensuring efficiency by considering multiple performance metrics. This approach, combined with a strategy for architecture inheritance, enhances GAN stability and image quality. Experiments show that AKD-EGAN surpasses state-of-the-art methods, achieving a Fréchet Inception Distance (FID) of 7.91 and an Inception Score (IS) of 8.97 on CIFAR-10, along with competitive results on STL-10 (FID: 20.32, IS: 10.06). Code and models will be available at https://github.com/njit-ly/AKD-EGAN .},
  archive      = {J_IJNS},
  author       = {Yu Xue and Yan Lin and Ferrante Neri},
  doi          = {10.1142/S0129065725500133},
  journal      = {International Journal of Neural Systems},
  number       = {4},
  pages        = {2550013},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Architecture knowledge distillation for evolutionary generative adversarial network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autism spectrum disorder detection using prominent
connectivity features from electroencephalography. <em>IJNS</em>,
<em>35</em>(3), 2550011. (<a
href="https://doi.org/10.1142/S012906572550011X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) is a disorder of brain growth with great variability whose clinical presentation initially shows up during early stages or youth, and ASD follows a repetitive pattern of behavior in most cases. Accurate diagnosis of ASD has been difficult in clinical practice as there is currently no valid indicator of ASD. Since ASD is regarded as a neurodevelopmental disorder, brain signals specially electroencephalography (EEG) are an effective method for detecting ASD. Therefore, this research aims at developing a method of extracting features from EEG signal for discriminating between ASD and control subjects. This study applies six prominent connectivity features, namely Cross Correlation (XCOR), Phase Locking Value (PLV), Pearson’s Correlation Coefficient (PCC), Mutual Information (MI), Normalized Mutual Information (NMI) and Transfer Entropy (TE), for feature extraction. The Connectivity Feature Maps (CFMs) are constructed and used for classification through Convolutional Neural Network (CNN). As CFMs contain spatial information, they are able to distinguish ASD and control subjects better than other features. Rigorous experimentation has been performed on the EEG datasets collected from Italy and Saudi Arabia according to different criteria. MI feature shows the best result for categorizing ASD and control participants with increased sample size and segmentation.},
  archive      = {J_IJNS},
  author       = {Zahrul Jannat Peya and Mahfuza Akter Maria and Sk Imran Hossain and M. A. H. Akhand and Nazmul Siddique},
  doi          = {10.1142/S012906572550011X},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550011},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Autism spectrum disorder detection using prominent connectivity features from electroencephalography},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label zero-shot learning via contrastive label-based
attention. <em>IJNS</em>, <em>35</em>(3), 2550010. (<a
href="https://doi.org/10.1142/S0129065725500108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label zero-shot learning (ML-ZSL) strives to recognize all objects in an image, regardless of whether they are present in the training data. Recent methods incorporate an attention mechanism to locate labels in the image and generate class-specific semantic information. However, the attention mechanism built on visual features treats label embeddings equally in the prediction score, leading to severe semantic ambiguity. This study focuses on efficiently utilizing semantic information in the attention mechanism. We propose a contrastive label-based attention method (CLA) to associate each label with the most relevant image regions. Specifically, our label-based attention, guided by the latent label embedding, captures discriminative image details. To distinguish region-wise correlations, we implement a region-level contrastive loss. In addition, we utilize a global feature alignment module to identify labels with general information. Extensive experiments on two benchmarks, NUS-WIDE and Open Images, demonstrate that our CLA outperforms the state-of-the-art methods. Especially under the ZSL setting, our method achieves 2.0% improvements in mean Average Precision (mAP) for NUS-WIDE and 4.0% for Open Images compared with recent methods.},
  archive      = {J_IJNS},
  author       = {Shixuan Meng and Rongxin Jiang and Xiang Tian and Fan Zhou and Yaowu Chen and Junjie Liu and Chen Shen},
  doi          = {10.1142/S0129065725500108},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550010},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multi-label zero-shot learning via contrastive label-based attention},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unraveling the differential efficiency of dorsal and ventral
pathways in visual semantic decoding. <em>IJNS</em>, <em>35</em>(3),
2550009. (<a href="https://doi.org/10.1142/S0129065725500091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual semantic decoding aims to extract perceived semantic information from the visual responses of the human brain and convert it into interpretable semantic labels. Although significant progress has been made in semantic decoding across individual visual cortices, studies on the semantic decoding of the ventral and dorsal cortical visual pathways remain limited. This study proposed a graph neural network (GNN)-based semantic decoding model on a natural scene dataset (NSD) to investigate the decoding differences between the dorsal and ventral pathways in process various parts of speech, including verbs, nouns, and adjectives. Our results indicate that the decoding accuracies for verbs and nouns with motion attributes were significantly higher for the dorsal pathway as compared to those for the ventral pathway. Comparative analyses reveal that the dorsal pathway significantly outperformed the ventral pathway in terms of decoding performance for verbs and nouns with motion attributes, with evidence showing that this superiority largely stemmed from higher-level visual cortices rather than lower-level ones. Furthermore, these two pathways appear to converge in their heightened sensitivity toward semantic content related to actions. These findings reveal unique visual neural mechanisms through which the dorsal and ventral cortical pathways segregate and converge when processing stimuli with different semantic categories.},
  archive      = {J_IJNS},
  author       = {Wei Huang and Ying Tang and Sizhuo Wang and Jingpeng Li and Kaiwen Cheng and Hongmei Yan},
  doi          = {10.1142/S0129065725500091},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550009},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Unraveling the differential efficiency of dorsal and ventral pathways in visual semantic decoding},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel state space model with dynamic graphic neural
network for EEG event detection. <em>IJNS</em>, <em>35</em>(3), 2550008.
(<a href="https://doi.org/10.1142/S012906572550008X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is a widely used physiological signal to obtain information of brain activity, and its automatic detection holds significant research importance, which saves doctors’ time, improves detection efficiency and accuracy. However, current automatic detection studies face several challenges: large EEG data volumes require substantial time and space for data reading and model training; EEG’s long-term dependencies test the temporal feature extraction capabilities of models; and the dynamic changes in brain activity and the non-Euclidean spatial structure between electrodes complicate the acquisition of spatial information. The proposed method uses range-EEG (rEEG) to extract time-frequency features from EEG to reduce data volume and resource consumption. Additionally, the next-generation state-space model Mamba is utilized as a temporal feature extractor to effectively capture the temporal information in EEG data. To address the limitations of state space models (SSMs) in spatial feature extraction, Mamba is combined with Dynamic Graph Neural Networks, creating an efficient model called DG-Mamba for EEG event detection. Testing on seizure detection and sleep stage classification tasks showed that the proposed method improved training speed by 10 times and reduced memory usage to less than one-seventh of the original data while maintaining superior performance. On the TUSZ dataset, DG-Mamba achieved an AUROC of 0.931 for seizure detection and in the sleep stage classification task, the proposed model surpassed all baselines.},
  archive      = {J_IJNS},
  author       = {Xinying Li and Shengjie Yan and Yonglin Wu and Chenyun Dai and Yao Guo},
  doi          = {10.1142/S012906572550008X},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550008},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A novel state space model with dynamic graphic neural network for EEG event detection},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the versatility of spiking neural networks:
Applications across diverse scenarios. <em>IJNS</em>, <em>35</em>(3),
2550007. (<a href="https://doi.org/10.1142/S0129065725500078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few decades, Artificial Neural Networks have become more and more important, evolving into a powerful tool to implement learning algorithms. Spiking neural networks represent the third generation of Artificial Neural Networks; they have earned growing significance due to their remarkable achievements in pattern recognition, finding extensive utility across diverse domains such as e.g. diagnostic medicine. Usually, Spiking Neural Networks are slightly less accurate than other Artificial Neural Networks, but they require a reduced amount of energy to perform calculations; this amount of energy further reduces in a very significant manner if they are implemented on hardware specifically designed for them, like neuromorphic hardware. In this work, we focus on exploring the versatility of Spiking Neural Networks and their potential applications across a range of scenarios by exploiting their adaptability and dynamic processing capabilities, which make them suitable for various tasks. A first rough network is designed based on the dataset’s general attributes; the network is then refined through an extensive grid search algorithm to identify the optimal values for hyperparameters. This dual-step process ensures that the Spiking Neural Network can be tailored to diverse and potentially very different situations in a direct and intuitive manner. We test this by considering three different scenarios: epileptic seizure detection, both considering binary and multi-classification tasks, as well as wine classification. The proposed methodology turned out to be highly effective in binary class scenarios: the Spiking Neural Networks models achieved significantly lower energy consumption compared to Artificial Neural Networks while approaching nearly 100% accuracy. In the case of multi-class classification, the model achieved an accuracy of approximately 90%, thus indicating that it can still be further improved.},
  archive      = {J_IJNS},
  author       = {Matteo Cavaleri and Claudio Zandron},
  doi          = {10.1142/S0129065725500078},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550007},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Exploring the versatility of spiking neural networks: Applications across diverse scenarios},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A context-dependent CNN-based framework for multiple
sclerosis segmentation in MRI. <em>IJNS</em>, <em>35</em>(3), 2550006.
(<a href="https://doi.org/10.1142/S0129065725500066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite several automated strategies for identification/segmentation of Multiple Sclerosis (MS) lesions in Magnetic Resonance Imaging (MRI) being developed, they consistently fall short when compared to the performance of human experts. This emphasizes the unique skills and expertise of human professionals in dealing with the uncertainty resulting from the vagueness and variability of MS, the lack of specificity of MRI concerning MS, and the inherent instabilities of MRI. Physicians manage this uncertainty in part by relying on their radiological, clinical, and anatomical experience. We have developed an automated framework for identifying and segmenting MS lesions in MRI scans by introducing a novel approach to replicating human diagnosis, a significant advancement in the field. This framework has the potential to revolutionize the way MS lesions are identified and segmented, being based on three main concepts: (1) Modeling the uncertainty; (2) Use of separately trained Convolutional Neural Networks (CNNs) optimized for detecting lesions, also considering their context in the brain, and to ensure spatial continuity; (3) Implementing an ensemble classifier to combine information from these CNNs. The proposed framework has been trained, validated, and tested on a single MRI modality, the FLuid-Attenuated Inversion Recovery (FLAIR) of the MSSEG benchmark public data set containing annotated data from seven expert radiologists and one ground truth. The comparison with the ground truth and each of the seven human raters demonstrates that it operates similarly to human raters. At the same time, the proposed model demonstrates more stability, effectiveness and robustness to biases than any other state-of-the-art model though using just the FLAIR modality.},
  archive      = {J_IJNS},
  author       = {Giuseppe Placidi and Luigi Cinque and Gian Luca Foresti and Francesca Galassi and Filippo Mignosi and Michele Nappi and Matteo Polsinelli},
  doi          = {10.1142/S0129065725500066},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550006},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A context-dependent CNN-based framework for multiple sclerosis segmentation in MRI},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A cloud detection network based on adaptive laplacian
coordination enhanced cross-feature u-net. <em>IJNS</em>,
<em>35</em>(2), 2550005. (<a
href="https://doi.org/10.1142/S0129065725500054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud cover experiences rapid fluctuations, significantly impacting the irradiance reaching the ground and causing frequent variations in photovoltaic power output. Accurate detection of thin and fragmented clouds is crucial for reliable photovoltaic power generation forecasting. In this paper, we introduce a novel cloud detection method, termed Adaptive Laplacian Coordination Enhanced Cross-Feature U-Net (ALCU-Net). This method augments the traditional U-Net architecture with three innovative components: an Adaptive Feature Coordination (AFC) module, an Adaptive Laplacian Cross-Feature U-Net with a Multi-Grained Laplacian-Enhanced (MLE) feature module, and a Criss-Cross Feature Fused Detection (CCFE) module. The AFC module enhances spatial coherence and bridges semantic gaps across multi-channel images. The Adaptive Laplacian Cross-Feature U-Net integrates features from adjacent hierarchical levels, using the MLE module to refine cloud characteristics and edge details over time. The CCFE module, embedded in the U-Net decoder, leverages criss-cross features to improve detection accuracy. Experimental evaluations show that ALCU-Net consistently outperforms existing cloud detection methods, demonstrating superior accuracy in identifying both thick and thin clouds and in mapping fragmented cloud patches across various environments, including oceans, polar regions, and complex ocean-land mixtures.},
  archive      = {J_IJNS},
  author       = {Kaizheng Wang and Ruohan Zhou and Jian Wang and Ferrante Neri and Yitong Fu and Shunzhen Zhou},
  doi          = {10.1142/S0129065725500054},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550005},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A cloud detection network based on adaptive laplacian coordination enhanced cross-feature U-net},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection using complete cycle consistent generative
adversarial network. <em>IJNS</em>, <em>35</em>(2), 2550004. (<a
href="https://doi.org/10.1142/S0129065725500042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents a robust adversarial method for anomaly detection in real-world scenarios, leveraging the power of generative adversarial neural networks (GANs) through cycle consistency in reconstruction error. Traditional approaches often falter due to high variance in class-wise accuracy, rendering them ineffective across different anomaly types. Our proposed model addresses these challenges by introducing an innovative flow of information in the training procedure and integrating it as a new discriminator into the framework, thereby optimizing the training dynamics. Furthermore, it employs a supplementary distribution in the input space to steer reconstructions toward the normal data distribution. This adjustment distinctly isolates anomalous instances and enhances detection precision. Also, two unique anomaly scoring mechanisms were developed to augment detection capabilities. Comprehensive evaluations on six varied datasets have confirmed that our model outperforms one-class anomaly detection benchmarks. The implementation is openly accessible to the academic community, available on Github. a},
  archive      = {J_IJNS},
  author       = {Zahra Dehghanian and Saeed Saravani and Maryam Amirmazlaghani and Mohamad Rahmati},
  doi          = {10.1142/S0129065725500042},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550004},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Anomaly detection using complete cycle consistent generative adversarial network},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A modified transformer network for seizure detection using
EEG signals. <em>IJNS</em>, <em>35</em>(2), 2550003. (<a
href="https://doi.org/10.1142/S0129065725500030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seizures have a serious impact on the physical function and daily life of epileptic patients. The automated detection of seizures can assist clinicians in taking preventive measures for patients during the diagnosis process. The combination of deep learning (DL) model with convolutional neural network (CNN) and transformer network can effectively extract both local and global features, resulting in improved seizure detection performance. In this study, an enhanced transformer network named Inresformer is proposed for seizure detection, which is combined with Inception and Residual network extracting different scale features of electroencephalography (EEG) signals to enrich the feature representation. In addition, the improved transformer network replaces the existing Feedforward layers with two half-step Feedforward layers to enhance the nonlinear representation of the model. The proposed architecture utilizes discrete wavelet transform (DWT) to decompose the original EEG signals, and the three sub-bands are selected for signal reconstruction. Then, the Co-MixUp method is adopted to solve the problem of data imbalance, and the processed signals are sent to the Inresformer network for seizure information capture and recognition. Finally, discriminant fusion is performed on the results of three-scale EEG sub-signals to achieve final seizure recognition. The proposed network achieves the best accuracy of 100% on Bonn dataset and the average accuracy of 98.03%, sensitivity of 95.65%, and specificity of 98.57% on the long-term CHB-MIT dataset. Compared to the existing DL networks, the proposed method holds significant potential for clinical research and diagnosis applications with competitive performance.},
  archive      = {J_IJNS},
  author       = {Wenrong Hu and Juan Wang and Feng Li and Daohui Ge and Yuxia Wang and Qingwei Jia and Shasha Yuan},
  doi          = {10.1142/S0129065725500030},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550003},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A modified transformer network for seizure detection using EEG signals},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SATEER: Subject-aware transformer for EEG-based emotion
recognition. <em>IJNS</em>, <em>35</em>(2), 2550002. (<a
href="https://doi.org/10.1142/S0129065725500029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a Subject-Aware Transformer-based neural network designed for the Electroencephalogram (EEG) Emotion Recognition task (SATEER), which entails the analysis of EEG signals to classify and interpret human emotional states. SATEER processes the EEG waveforms by transforming them into Mel spectrograms, which can be seen as particular cases of images with the number of channels equal to the number of electrodes used during the recording process; this type of data can thus be processed using a Computer Vision pipeline. Distinct from preceding approaches, this model addresses the variability in individual responses to identical stimuli by incorporating a User Embedder module. This module enables the association of individual profiles with their EEGs, thereby enhancing classification accuracy. The efficacy of the model was rigorously evaluated using four publicly available datasets, demonstrating superior performance over existing methods in all conducted benchmarks. For instance, on the AMIGOS dataset (A dataset for Multimodal research of affect, personality traits, and mood on Individuals and GrOupS), SATEER’s accuracy exceeds 99.8% accuracy across all labels and showcases an improvement of 0.47% over the state of the art. Furthermore, an exhaustive ablation study underscores the pivotal role of the User Embedder module and each other component of the presented model in achieving these advancements.},
  archive      = {J_IJNS},
  author       = {Romeo Lanzino and Danilo Avola and Federico Fontana and Luigi Cinque and Francesco Scarcello and Gian Luca Foresti},
  doi          = {10.1142/S0129065725500029},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2550002},
  shortjournal = {Int. J. Neural Syst.},
  title        = {SATEER: Subject-aware transformer for EEG-based emotion recognition},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse spike feature learning to recognize traceable
interictal epileptiform spikes. <em>IJNS</em>, <em>35</em>(2), 2450071.
(<a href="https://doi.org/10.1142/S0129065724500710">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interictal epileptiform spikes (spikes) and epileptogenic focus are strongly correlated. However, partial spikes are insensitive to epileptogenic focus, which restricts epilepsy neurosurgery. Therefore, identifying spike subtypes that are strongly associated with epileptogenic focus (traceable spikes) could facilitate their use as reliable signal sources for accurately tracing epileptogenic focus. However, the sparse firing phenomenon in the transmission of intracranial neuronal discharges leads to differences within spikes that cannot be observed visually. Therefore, neuro-electro-physiologists are unable to identify traceable spikes that could accurately locate epileptogenic focus. Herein, we propose a novel sparse spike feature learning method to recognize traceable spikes and extract discrimination information related to epileptogenic focus. First, a multilevel eigensystem feature representation was determined based on a multilevel feature representation module to express the intrinsic properties of a spike. Second, the sparse feature learning module expressed the sparse spike multi-domain context feature representation to extract sparse spike feature representations. Among them, a sparse spike encoding strategy was implemented to effectively simulate the sparse firing phenomenon for the accurate encoding of the activity of intracranial neurosources. The sensitivity of the proposed method was 97.1%, demonstrating its effectiveness and significant efficiency relative to other state-of-the-art methods.},
  archive      = {J_IJNS},
  author       = {Chenchen Cheng and Yunbo Shi and Yan Liu and Bo You and Yuanfeng Zhou and Ardalan Aarabi and Yakang Dai},
  doi          = {10.1142/S0129065724500710},
  journal      = {International Journal of Neural Systems},
  number       = {2},
  pages        = {2450071},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Sparse spike feature learning to recognize traceable interictal epileptiform spikes},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning recognition of paroxysmal kinesigenic
dyskinesia based on EEG functional connectivity. <em>IJNS</em>,
<em>35</em>(1), 2550001. (<a
href="https://doi.org/10.1142/S0129065725500017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paroxysmal kinesigenic dyskinesia (PKD) is a rare neurological disorder marked by transient involuntary movements triggered by sudden actions. Current diagnostic approaches, including genetic screening, face challenges in identifying secondary cases due to symptom overlap with other disorders. This study introduces a novel PKD recognition method utilizing a resting-state electroencephalogram (EEG) functional connectivity matrix and a deep learning architecture (AT-1CBL). Resting-state EEG data from 44 PKD patients and 44 healthy controls (HCs) were collected using a 128-channel EEG system. Functional connectivity matrices were computed and transformed into graph data to examine brain network property differences between PKD patients and controls through graph theory. Source localization was conducted to explore neural circuit differences in patients. The AT-1CBL model, integrating 1D-CNN and Bi-LSTM with attentional mechanisms, achieved a classification accuracy of 93.77% on phase lag index (PLI) features in the Theta band. Graph theoretic analysis revealed significant phase synchronization impairments in the Theta band of the functional brain network in PKD patients, particularly in the distribution of weak connections compared to HCs. Source localization analyses indicated greater differences in functional connectivity in sensorimotor regions and the frontal-limbic system in PKD patients, suggesting abnormalities in motor integration related to clinical symptoms. This study highlights the potential of deep learning models based on EEG functional connectivity for accurate and cost-effective PKD diagnosis, supporting the development of portable EEG devices for clinical monitoring and diagnosis. However, the limited dataset size may affect generalizability, and further exploration of multimodal data integration and advanced deep learning architectures is necessary to enhance the robustness of PKD diagnostic models.},
  archive      = {J_IJNS},
  author       = {Liang Zhao and Renling Zou and Linpeng Jin},
  doi          = {10.1142/S0129065725500017},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2550001},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Deep learning recognition of paroxysmal kinesigenic dyskinesia based on EEG functional connectivity},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding continuous tracking eye movements from cortical
spiking activity. <em>IJNS</em>, <em>35</em>(1), 2450070. (<a
href="https://doi.org/10.1142/S0129065724500709">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye movements are the primary way primates interact with the world. Understanding how the brain controls the eyes is therefore crucial for improving human health and designing visual rehabilitation devices. However, brain activity is challenging to decipher. Here, we leveraged machine learning algorithms to reconstruct tracking eye movements from high-resolution neuronal recordings. We found that continuous eye position could be decoded with high accuracy using spiking data from only a few dozen cortical neurons. We tested eight decoders and found that neural network models yielded the highest decoding accuracy. Simpler models performed well above chance with a substantial reduction in training time. We measured the impact of data quantity (e.g. number of neurons) and data format (e.g. bin width) on training time, inference time, and generalizability. Training models with more input data improved performance, as expected, but the format of the behavioral output was critical for emphasizing or omitting specific oculomotor events. Our results provide the first demonstration, to our knowledge, of continuously decoded eye movements across a large field of view. Our comprehensive investigation of predictive power and computational efficiency for common decoder architectures provides a much-needed foundation for future work on real-time gaze-tracking devices.},
  archive      = {J_IJNS},
  author       = {Kendra K. Noneman and J. Patrick Mayo},
  doi          = {10.1142/S0129065724500709},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450070},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Decoding continuous tracking eye movements from cortical spiking activity},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing motor imagery classification with residual graph
convolutional networks and multi-feature fusion. <em>IJNS</em>,
<em>35</em>(1), 2450069. (<a
href="https://doi.org/10.1142/S0129065724500692">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke, an abrupt cerebrovascular ailment resulting in brain tissue damage, has prompted the adoption of motor imagery (MI)-based brain–computer interface (BCI) systems in stroke rehabilitation. However, analyzing electroencephalogram (EEG) signals from stroke patients poses challenges. To address the issues of low accuracy and efficiency in EEG classification, particularly involving MI, the study proposes a residual graph convolutional network (M-ResGCN) framework based on the modified S -transform (MST), and introduces the self-attention mechanism into residual graph convolutional network (ResGCN). This study uses MST to extract EEG time-frequency domain features, derives spatial EEG features by calculating the absolute Pearson correlation coefficient (aPcc) between channels, and devises a method to construct the adjacency matrix of the brain network using aPcc to measure the strength of the connection between channels. Experimental results involving 16 stroke patients and 16 healthy subjects demonstrate significant improvements in classification quality and robustness across tests and subjects. The highest classification accuracy reached 94.91% and a Kappa coefficient of 0.8918. The average accuracy and F 1 scores from 10 times 10-fold cross-validation are 94.38% and 94.36%, respectively. By validating the feasibility and applicability of brain networks constructed using the aPcc in EEG signal analysis and feature encoding, it was established that the aPcc effectively reflects overall brain activity. The proposed method presents a novel approach to exploring channel relationships in MI-EEG and improving classification performance. It holds promise for real-time applications in MI-based BCI systems.},
  archive      = {J_IJNS},
  author       = {Fangzhou Xu and Weiyou Shi and Chengyan Lv and Yuan Sun and Shuai Guo and Chao Feng and Yang Zhang and Tzyy-Ping Jung and Jiancai Leng},
  doi          = {10.1142/S0129065724500692},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450069},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Enhancing motor imagery classification with residual graph convolutional networks and multi-feature fusion},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural memory state space models for medical image
segmentation. <em>IJNS</em>, <em>35</em>(1), 2450068. (<a
href="https://doi.org/10.1142/S0129065724500680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid advancement of deep learning, computer-aided diagnosis and treatment have become crucial in medicine. UNet is a widely used architecture for medical image segmentation, and various methods for improving UNet have been extensively explored. One popular approach is incorporating transformers, though their quadratic computational complexity poses challenges. Recently, State-Space Models (SSMs), exemplified by Mamba, have gained significant attention as a promising alternative due to their linear computational complexity. Another approach, neural memory Ordinary Differential Equations (nmODEs), exhibits similar principles and achieves good results. In this paper, we explore the respective strengths and weaknesses of nmODEs and SSMs and propose a novel architecture, the nmSSM decoder, which combines the advantages of both approaches. This architecture possesses powerful nonlinear representation capabilities while retaining the ability to preserve input and process global information. We construct nmSSM-UNet using the nmSSM decoder and conduct comprehensive experiments on the PH2, ISIC2018, and BU-COCO datasets to validate its effectiveness in medical image segmentation. The results demonstrate the promising application value of nmSSM-UNet. Additionally, we conducted ablation experiments to verify the effectiveness of our proposed improvements on SSMs and nmODEs.},
  archive      = {J_IJNS},
  author       = {Zhihua Wang and Jingjun Gu and Wang Zhou and Quansong He and Tianli Zhao and Jialong Guo and Li Lu and Tao He and Jiajun Bu},
  doi          = {10.1142/S0129065724500680},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450068},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Neural memory state space models for medical image segmentation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatially selective retinal ganglion cell activation using
low invasive extraocular temporal interference stimulation.
<em>IJNS</em>, <em>35</em>(1), 2450066. (<a
href="https://doi.org/10.1142/S0129065724500667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional retinal implants involve complex surgical procedures and require invasive implantation. Temporal Interference Stimulation (TIS) has achieved noninvasive and focused stimulation of deep brain regions by delivering high-frequency currents with small frequency differences on multiple electrodes. In this study, we conducted in silico investigations to evaluate extraocular TIS’s potential as a novel visual restoration approach. Different from the previously published retinal TIS model, the new model of extraocular TIS incorporated a biophysically detailed retinal ganglion cell (RGC) population, enabling a more accurate simulation of retinal outputs under electrical stimulation. Using this improved model, we made the following major discoveries: (1) the maximum value of TIS envelope electric potential ( EP max ) showed a strong correlation with TIS-induced RGC activation; (2) the preferred stimulating/return electrode (SE/RE) locations to achieve focalized TIS were predicted; (3) the performance of extraocular TIS was better than same-frequency sinusoidal stimulation (SSS) in terms of lower RGC threshold and more focused RGC activation; (4) the optimal stimulation parameters to achieve lower threshold and focused activation were identified; and (5) spatial selectivity of TIS could be improved by integrating current steering strategy and reducing electrode size. This study provides insights into the feasibility and effectiveness of a low-invasive stimulation approach in enhancing vision restoration.},
  archive      = {J_IJNS},
  author       = {Xiaoyu Song and Tianruo Guo and Saidong Ma and Feng Zhou and Jiaxin Tian and Zhengyang Liu and Jiao Liu and Heng Li and Yao Chen and Xinyu Chai and Liming Li},
  doi          = {10.1142/S0129065724500667},
  journal      = {International Journal of Neural Systems},
  number       = {1},
  pages        = {2450066},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Spatially selective retinal ganglion cell activation using low invasive extraocular temporal interference stimulation},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
