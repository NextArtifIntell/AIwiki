<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJSEKE_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijseke---12">IJSEKE - 12</h2>
<ul>
<li><details>
<summary>
(2025). HCIA: Hierarchical change impact analysis based on hierarchy
program slices. <em>IJSEKE</em>, <em>35</em>(2), 263–292. (<a
href="https://doi.org/10.1142/S0218194025500056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change impact analysis (CIA) is an essential method in software maintenance and evolution. Its accuracy and usability play a crucial role in its application. However, most CIAs are coarse-grained and limited to class and method levels. Despite the fine-grained CIAs’ success in giving the statement-level impact set, they are still limited without the sub-statement level dependency analysis, leading to low precision. Additionally, their unstructured impact sets make it challenging for users to comprehend the impact content. This paper proposes Hierarchical Change Impact Analysis (HCIA), a Hierarchical CIA technique based on the sub-statement level dependence graph. HCIA can perform a forward hierarchy program slicing on the change set from five levels: sub-statement, statement, method, class, and package. Based on the program slices, HCIA calculates the impact factor of the impact sets at the five levels to generate the final impact set. In the experiment, we evaluate the relationship between the impact factor and the actual affected codes and assess the most appropriate size of HCIA impact sets. Furthermore, we evaluate HCIA on 10 open-source projects by comparing our approach with popular CIAs at the five levels. The experimental result shows that HCIA is more accurate than the popular CIAs.},
  archive      = {J_IJSEKE},
  author       = {Jianming Chang and Lulu Wang and Zaixing Zhang},
  doi          = {10.1142/S0218194025500056},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {263-292},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {HCIA: Hierarchical change impact analysis based on hierarchy program slices},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A model-based evaluation metric for question answering
systems. <em>IJSEKE</em>, <em>35</em>(2), 243–262. (<a
href="https://doi.org/10.1142/S0218194025500032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the limitations of traditional evaluation metrics for Question Answering (QA) systems that primarily focus on syntax and n-gram similarity. We propose a novel model-based evaluation metric, MQA-metric, and create a human-judgment-based dataset, squad-qametric and marco-qametric, to validate our approach. The research aims to solve several key problems: the objectivity in dataset labeling, the effectiveness of metrics when there is no syntax similarity, the impact of answer length on metric performance, and the influence of real answer quality on metric results. To tackle these challenges, we designed an interface for dataset labeling and conducted extensive experiments with human reviewers. Our analysis shows that the MQA-metric outperforms traditional metrics like BLEU, ROUGE and METEOR. Unlike existing metrics, MQA-metric leverages semantic comprehension through large language models (LLMs), enabling it to capture contextual nuances and synonymous expressions more effectively. This approach sets a standard for evaluating QA systems by prioritizing semantic accuracy over surface-level similarities. The proposed metric correlates better with human judgment, making it a more reliable tool for evaluating QA systems. Our contributions include the development of a robust evaluation workflow, creation of high-quality datasets, and an extensive comparison with existing evaluation methods. The results indicate that our model-based approach provides a significant improvement in assessing the quality of QA systems, which is crucial for their practical application and trustworthiness.},
  archive      = {J_IJSEKE},
  author       = {Dilan Bakır and Mehmet S. Aktas and Beytullah Yıldız},
  doi          = {10.1142/S0218194025500032},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {243-262},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A model-based evaluation metric for question answering systems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method to evaluate the credibility of domain knowledge
network using validated expert knowledge. <em>IJSEKE</em>,
<em>35</em>(2), 217–241. (<a
href="https://doi.org/10.1142/S0218194025500020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are living in an era of knowledge explosion, where all kinds of knowledge are emerging and becoming more and more complicated with the development of new techniques and new ideas. When we study knowledge and apply them to understand and solve problems, the credibility of knowledge is becoming our main concerns. Usually, high credible domain knowledge can guide us correctly understand all concepts and the relationships between them in this domain. Due to its good layer structure and scalability, domain knowledge network is widely used to represent knowledge in knowledge engineering, artificial intelligence and others in recent years. How to ensure the credibility of domain knowledge network? This is an important and interesting topic. In this paper, we propose a method to evaluate the knowledge credibility for domain knowledge network, which means that we can start from the layer structure of domain knowledge network, and evaluate the credibility of knowledge layer by layer using validated expert knowledge such as domain dictionary, domain ontology and domain expert experience. We conduct experiments with six domain knowledge network constructed based on network data and six domain knowledge network constructed manually based on published books or domain dictionaries, which describe the same domain knowledge in pairs. Experimental results show that the knowledge credibility of domain knowledge network constructed from validated expert knowledge is significantly higher than the knowledge credibility of domain knowledge network constructed directly from network data, which satisfy our expectation and also prove the effectiveness of our credibility evaluation method.},
  archive      = {J_IJSEKE},
  author       = {Yin Li and Ying Zhou and Li Liao and Bixin Li},
  doi          = {10.1142/S0218194025500020},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {217-241},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {A method to evaluate the credibility of domain knowledge network using validated expert knowledge},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RESEARCH NOTES: Design of a distributed and highly scalable
fog architecture for heterogeneous IoT infrastructures. <em>IJSEKE</em>,
<em>35</em>(2), 195–215. (<a
href="https://doi.org/10.1142/S0218194025430016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fog computing can provide an effective solution to the challenges presented by today’s ever-emerging Internet of Things (IoT) infrastructures. As the number of interconnected devices progressively increases, these infrastructures require better solutions to ensure high scalability and processing capacity, along with an efficient use of available resources. This is why this paper presents a distributed Fog architecture, specifically designed to address the challenges and difficulties presented by heterogeneous IoT environments. This Fog architecture is used as an intermediate layer between the IoT devices and the final layer, it has been designed after the previous analysis of the requirements to be met for the solution, then the modularization of the architecture has been carried out so that it can be easily distributed, and finally, an implementation has been generated on a real environment as a validation case of the proposal.},
  archive      = {J_IJSEKE},
  author       = {Lucía Arnau Muñoz and José Vicente Berná Martínez and Carlos Calatayud Asensi and David Saavedra Pastor},
  doi          = {10.1142/S0218194025430016},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {195-215},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {RESEARCH NOTES: Design of a distributed and highly scalable fog architecture for heterogeneous IoT infrastructures},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward a pattern-based comprehensive framework using process
mining for RBAC conformance checks. <em>IJSEKE</em>, <em>35</em>(2),
157–194. (<a href="https://doi.org/10.1142/S0218194025500019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event logs often record the execution of business process instances. Detecting traces in the event logs that do not comply with access control policies, such as role-based access control (RBAC) policies, is essential to ensuring system security. Moreover, process mining has been extensively utilized for security analysis in recent years. However, pattern-based approaches for designing and analyzing RBAC policies in the context of business processes through process mining are notably absent. In this paper, we present a systematic framework for checking the conformance of RBAC implemented in the event logs of business processes with the RBAC policies specified in domain knowledge. To facilitate the representation of the RBAC policies derived from the domain knowledge, we employ an RBAC domain-specific language (DSL) combined with our RBAC-driven object constraint language (OCL) invariant patterns built from the various types of RBAC constraints. The implemented RBAC in an event log is represented as snapshots within our framework. Then, we validate the snapshots with the RBAC policies to be able to detect RBAC conformance issues. The proposed framework is experimented with and evaluated on two business process logs, one simulated log and one real-world event log named “BPI Challenge 2017”.},
  archive      = {J_IJSEKE},
  author       = {Duc-Hieu Nguyen and Yuichi Sei and Yasuyuki Tahara and Akihiko Ohsuga},
  doi          = {10.1142/S0218194025500019},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {157-194},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Toward a pattern-based comprehensive framework using process mining for RBAC conformance checks},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software quality assessment model: A new approach for
software testing tools. <em>IJSEKE</em>, <em>35</em>(2), 139–155. (<a
href="https://doi.org/10.1142/S0218194024500517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of software testing is a crucial phase in determining the quality of software, and this phase requires significant costs and a considerable amount of time for testers. This paper discusses the development of a framework for software quality assessment, involving flexible choices of software testing methods and variables in the form of an application. The method used is experimental, developing a new framework based on previous research, where previous research was limited to specific methods and testing variables. The result of this research is the creation of a new framework for software quality assessment. It is hoped that this framework can serve as a reference for software companies in evaluating software quality. In terms of complexity, this framework has the advantage of allowing a tester to choose methods with more flexible or unlimited testing variables. Regarding the estimated time and costs, with PF = 4 , 5 and 1 0 , the practical application complexity of the developed framework is estimated to have the best costs, time and human resources at IDR 254,240,000, with an estimated time of 3,178 work hours and 6,356 work hours with a team of 3 people.},
  archive      = {J_IJSEKE},
  author       = {Zulkifli Zulkifli and Mardiana Mardiana and Dikpride Despa},
  doi          = {10.1142/S0218194024500517},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {2},
  pages        = {139-155},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Software quality assessment model: A new approach for software testing tools},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mining fine-grained code change patterns using multiple
feature analysis. <em>IJSEKE</em>, <em>35</em>(1), 111–138. (<a
href="https://doi.org/10.1142/S0218194024500505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintaining high code quality is a crucial concern in software development. Existing studies demonstrated that developers frequently face recurrent bugs and adopt similar fix measures, known as code change patterns. As an essential static analysis technique, code pattern mining supports various tasks, including code refactoring, automated program repair, and defect prediction, thus significantly improving software development processes. A prevalent approach to identifying code patterns involves translating code changes to edit actions into a Bag-of-Words (BoW) model. However, when applied to open-source projects, this method exhibits several limitations. For instance, it overlooks function call information and disregards feature word order. This study introduces MIFA, a novel technique for mining code change patterns using multiple feature analysis. MIFA extends existing BoW methods by incorporating analysis of function calls and overall changes in the Abstract Syntax Tree (AST) structure. We selected 20 popular Python projects and evaluated MIFA in both intra-project and cross-project scenarios. The experimental results indicate that: (1) MIFA achieved higher silhouette coefficients and F1 scores compared to other state-of-the-art methods, demonstrating a superior accuracy; (2) MIFA can assist developers in detecting unique change patterns more earlier, with an efficiency improvement of over 40% compared to random sampling. Additionally, we discussed critical parameters for measuring the similarity of code changes, guiding users to apply our method effectively.},
  archive      = {J_IJSEKE},
  author       = {Di Liu and Yang Feng},
  doi          = {10.1142/S0218194024500505},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {111-138},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Mining fine-grained code change patterns using multiple feature analysis},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Code recommendation for schema evolution of mimic storage
systems. <em>IJSEKE</em>, <em>35</em>(1), 89–110. (<a
href="https://doi.org/10.1142/S0218194024500499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schema evolution of mimic storage systems is a time-consuming and error-prone task due to the redundant development of heterogeneous executors. The ORM-based proxy requires an entire class to represent the structure of a data table. There lacks domain-specific code recommendation techniques to boost storage development. To address this issue, we design a novel type of code context, i.e. schema context, that combines features of code text, syntax and structure. Regarding the requirements of class-level granularity, we focus on behavior and attribute in code syntax, and use element position and structural metrics to mine the hidden relationships. Based on schema context and an existing inference mode, we propose SchemaRec to recommend ORM-related class for the database executors once one of them has been changed. We conduct experiments with 110 open-source projects, and the results show that SchemaRec obtains more accurate results than Lucene, DeepCS, QobCS and SEA in terms of Top-1, Top-10 and MRR accuracy due to the better ability of context representation. We also find that code syntax is the most important information because it involves behavior and attribute information of ORM-related classes.},
  archive      = {J_IJSEKE},
  author       = {Xianglong Kong and Zhuo Lv and Cen Chen and Hao Chang and Nuannuan Li and Fan Zhang},
  doi          = {10.1142/S0218194024500499},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {89-110},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Code recommendation for schema evolution of mimic storage systems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The trustworthiness metric model of interface based on
defects. <em>IJSEKE</em>, <em>35</em>(1), 59–88. (<a
href="https://doi.org/10.1142/S0218194024500487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interface is a crucial element in component-based software, enabling the linkage of distinct components to facilitate interaction. Defects within the interface can significantly impact the overall trustworthiness of the system. Therefore, it is essential to assess the interface trustworthiness based on a defect-centric approach. This paper introduces a novel model for evaluating interface trustworthiness, anchored in defect analysis. First, the defect types are formalized based on interface specifications. Then, the comprehensive weight allocation method is established to characterize the importance degree of each interface defect type by combining the G1 and CRITIC methods. Subsequently, the attributes of the interface are evaluated by defect value analysis, and the trustworthiness measurement model of the interface is proposed based on these attributes. Furthermore, to evaluate the trustworthiness of the whole system, the trustworthiness measure models under different combination structure of components are established. Finally, the model’s’ applicability is demonstrated through an illustrative example. This trustworthiness evaluation from the interface view can guide interface designers to obtain high-quality interfaces and improve the trustworthiness of the entire software.},
  archive      = {J_IJSEKE},
  author       = {Yanfang Ma and Xiaotong Gao},
  doi          = {10.1142/S0218194024500487},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {59-88},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {The trustworthiness metric model of interface based on defects},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing translation validation of compiler transformations
with large language models. <em>IJSEKE</em>, <em>35</em>(1), 45–57. (<a
href="https://doi.org/10.1142/S0218194024500475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework that integrates Large Language Models (LLMs) into translation validation, targeting LLVM compiler transformations where formal verification tools fall short. Our framework utilizes the existing tools, like Alive2, to perform initial validation. For transformations deemed unsolvable by traditional methods, our approach leverages fine-tuned LLMs to predict soundness or unsoundness, with subsequent fuzzing applied to identify counterexamples for unsound transformations. Our approach has proven effective in complex scenarios, such as deep-learning accelerator designs, enhancing the reliability of compiler transformations.},
  archive      = {J_IJSEKE},
  author       = {Yanzhao Wang and Fei Xie},
  doi          = {10.1142/S0218194024500475},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {45-57},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Enhancing translation validation of compiler transformations with large language models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical study of fault localization on novice programs
and addressing the tie problem. <em>IJSEKE</em>, <em>35</em>(1), 19–44.
(<a href="https://doi.org/10.1142/S0218194024500426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming education is becoming increasingly popular in universities. However, due to a lack of debugging experience, novices often encounter numerous difficulties in the programming process. Automatic fault localization techniques have emerged as a promising solution to address this issue. Among these techniques, Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) have been widely used in industrial programs. However, there is a significant difference between industrial and novice programs and the performance of these methods on novice programs has not been extensively studied. To fill this gap, we conducted an empirical study to evaluate the fault localization performance and execution overhead of SBFL and MBFL in a typical novice programming environment. Our study specifically examined how different program characteristics, including code coverage and mutation score, affect the accuracy of these localization methods. Additionally, during the study, we identified the tie problem in both methods and further investigated its impact on fault localization techniques in novice programs. To remove the impact of the tie problem, we proposed using PageRank scores as weights for the suspiciousness, sorting, and locating faults based on the weighted suspiciousness. The PageRank algorithm is based on statement coverage information and constructs a directed graph. From the directed graph, a transition matrix generates the weight scores (PageRank scores) for each statement. Our research demonstrates that both SBFL and MBFL are effective for fault localization in novice programs, with MBFL showing significantly better performance in our tests. In TOP- N ( N = 1 , 3 , 5 ) , MBFL accurately locates 67, 96 and 114 faults, respectively, indicating superior performance. Additionally, calculating weighted suspiciousness significantly alleviates the tie problem.},
  archive      = {J_IJSEKE},
  author       = {Yuxing Liu and Jiaxin Zhong and Qihua Hei and Xuchuan Zhou and Jingzhong Xiao},
  doi          = {10.1142/S0218194024500426},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {19-44},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {An empirical study of fault localization on novice programs and addressing the tie problem},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using peer assessment leveraging large language models in
software engineering education. <em>IJSEKE</em>, <em>35</em>(1), 1–18.
(<a href="https://doi.org/10.1142/S0218194024500359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the integration of generative AI and large language models into the realm of software engineering education and training, with a specific focus on the transformation of traditional peer assessment methodologies. The motivation stems from the growing demand for innovative educational techniques that can effectively engage and empower learners in mastering Software Engineering principles. The proposed approach involves presenting students with modeling exercises solved by ChatGPT, prompting them to critically evaluate and provide constructive feedback on the generated solutions. By engaging students in a dialogue with the AI model, we aim to foster a dynamic learning environment where learners can articulate their considerations and insights, thereby enhancing their comprehension of software engineering principles, critical thinking and self evaluation skills. Preliminary results from pilot implementations indicate promising outcomes, suggesting that this approach not only enhances the quality of peer feedback but also contributes to a more interactive and engaging educational experience.},
  archive      = {J_IJSEKE},
  author       = {Marco Fiore and Marina Mongiello},
  doi          = {10.1142/S0218194024500359},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Using peer assessment leveraging large language models in software engineering education},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
