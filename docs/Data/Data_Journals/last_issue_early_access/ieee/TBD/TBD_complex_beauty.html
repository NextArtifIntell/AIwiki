<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TBD_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tbd---6">TBD - 6</h2>
<ul>
<li><details>
<summary>
(2025). Blockchain-empowered federated learning: Benefits,
challenges, and solutions. <em>IEEE Transactions on Big Data</em>, 1–20.
(<a href="https://doi.org/10.1109/TBDATA.2025.3541560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Federated learning (FL) is a distributed machine learning approach that protects user data privacy by training models locally on clients and aggregating them on a parameter server. While effective at preserving privacy, FL systems face limitations such as single points of failure, lack of incentives, and inadequate security. To address these challenges, blockchain technology is integrated into FL systems to provide stronger security, fairness, and scalability. However, blockchain-empowered FL (BC-FL) systems introduce additional demands on network, computing, and storage resources. This survey provides a comprehensive review of recent research on BC-FL systems, analyzing the benefits and challenges associated with blockchain integration. We explore why blockchain is applicable to FL, how it can be implemented, and the challenges and existing solutions for its integration. Additionally, we offer insights on future research directions for the BC-FL system.},
  archive  = {J},
  author   = {Zeju Cai and Jianguo Chen and Yuting Fan and Zibin Zheng and Keqin Li},
  doi      = {10.1109/TBDATA.2025.3541560},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  pages    = {1-20},
  title    = {Blockchain-empowered federated learning: Benefits, challenges, and solutions},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the trade-offs: Unified large language models vs
local fine-tuned models for highly-specific radiology NLI task. <em>IEEE
Transactions on Big Data</em>, 1–14. (<a
href="https://doi.org/10.1109/TBDATA.2025.3536928">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recently, ChatGPT and GPT-4 have emerged and gained immense global attention due to their unparalleled performance in language processing. Despite demonstrating impressive capability in various open-domain tasks, their adequacy in highly specific fields like radiology remains untested. Radiology presents unique linguistic phenomena distinct from open-domain data due to its specificity and complexity. Assessing the performance of large language models (LLMs) in such specific domains is crucial not only for a thorough evaluation of their overall performance but also for providing valuable insights into future model design directions: whether model design should be generic or domain-specific. To this end, in this study, we evaluate the performance of ChatGPT/GPT-4 on a radiology natural language inference (NLI) task and compare it to other models fine-tuned specifically on task-related data samples. We also conduct a comprehensive investigation on ChatGPT/GPT-4&#39;s reasoning ability by introducing varying levels of inference difficulty. Our results show that 1) ChatGPT and GPT-4 outperform other LLMs in the radiology NLI task; 2) other specifically fine-tuned Bert-based models require significant amounts of data samples to achieve comparable performance to ChatGPT/GPT-4. These findings not only demonstrate the feasibility and promise of constructing a generic model capable of addressing various tasks across different domains, but also highlight several key factors crucial for developing a unified model, particularly in a medical context, paving the way for future artificial general intelligence (AGI) systems. We release our code and data to the research community$^\ddagger$.},
  archive  = {J},
  author   = {Zihao Wu and Lu Zhang and Chao Cao and Xiaowei Yu and Zhengliang Liu and Lin Zhao and Yiwei Li and Haixing Dai and Chong Ma and Gang Li and Wei Liu and Quanzheng Li and Dinggang Shen and Xiang Li and Dajiang Zhu and Tianming Liu},
  doi      = {10.1109/TBDATA.2025.3536928},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  pages    = {1-14},
  title    = {Exploring the trade-offs: Unified large language models vs local fine-tuned models for highly-specific radiology NLI task},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A theoretical analysis of efficiency constrained
utility-privacy bi-objective optimization in federated learning.
<em>IEEE Transactions on Big Data</em>, 1–13. (<a
href="https://doi.org/10.1109/TBDATA.2025.3534622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Federated learning (FL) enables multiple clients to collaboratively learn a shared model without sharing their individual data. Concerns about utility, privacy, and training efficiency in FL have garnered significant research attention. Differential privacy has emerged as a prevalent technique in FL, safeguarding the privacy of individual user data while impacting utility and training efficiency. Within Differential Privacy Federated Learning (DPFL), previous studies have primarily focused on the utility-privacy trade-off, neglecting training efficiency, which is crucial for timely completion. Moreover, differential privacy achieves privacy by introducing controlled randomness (noise) on selected clients in each communication round. Previous work has mainly examined the impact of noise level (σ) and communication rounds (T) on the privacy-utility dynamic, overlooking other influential factors like the sample ratio (q, the proportion of selected clients). This paper systematically formulates an efficiency-constrained utility-privacy bi-objective optimization problem in DPFL, focusing on σ, T, and q. We provide a comprehensive theoretical analysis, yielding analytical solutions for the Pareto front. Extensive empirical experiments verify the validity and efficacy of our analysis, offering valuable guidance for low-cost parameter design in DPFL.},
  archive  = {J},
  author   = {Hanlin Gu and Xinyuan Zhao and Gongxi Zhu and Yuxing Han and Yan Kang and Lixin Fan and Qiang Yang},
  doi      = {10.1109/TBDATA.2025.3534622},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  pages    = {1-13},
  title    = {A theoretical analysis of efficiency constrained utility-privacy bi-objective optimization in federated learning},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Higher-order community detection by motif-based modularity
optimization. <em>IEEE Transactions on Big Data</em>, 1–16. (<a
href="https://doi.org/10.1109/TBDATA.2025.3544129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recently higher-order community detection based on network motifs has received increasing attention, because motif-based communities reflect not only mesoscale structures but also functional characteristics of real-life networks. In this study, we propose a Modularity Optimization method for Motif-based Community Detection (MOMCD). In order to approximate the global optimum in modularity optimization, an improved nature-inspired metaheuristic algorithm is proposed as optimization strategy. In addition, by comprehensively utilizing motif-based (higher-order) and edge-based (lower-order) structural information, a neighbor community modification operation and a local search operation are also designed to improve the quality of individuals and promote the convergence of MOMCD. Experimental results show that MOMCD is promising and competitive in identifying motif-based communities from synthetic and real-life networks, which outperforms state-of-the-art approaches in terms of quality and accuracy, and deepens our understanding of network structural and functional characteristics.},
  archive  = {J},
  author   = {Jing Xiao and Yu-Cheng Zou and Xiao-Ke Xu},
  doi      = {10.1109/TBDATA.2025.3544129},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  pages    = {1-16},
  title    = {Higher-order community detection by motif-based modularity optimization},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LightST: A simplifying spatio-temporal graph neural network
for traffic flow forecasting. <em>IEEE Transactions on Big Data</em>,
1–12. (<a href="https://doi.org/10.1109/TBDATA.2025.3544131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Traffic flow forecasting task plays an essential role in intelligent transportation systems. Accurately capturing the intricate spatio-temporal dependencies in traffic network signals is the core of precise prediction. Recently, a paradigm that models spatio-temporal dependencies through graph neural networks and time series models has become one of the most promising methods to solve this problem. However, existing methods still have limitations due to ineffectively modeling dynamic spatial dependencies and high time and space complexity. To address these issues, we propose a simplifying and powerful general spatio-temporal traffic flow forecasting model called LightST. Specifically, LightST first embeds temporal covariates and spatial position information to enhance the spatio-temporal modeling capabilities. Then, stacked temporal linear layers are introduced to capture temporal dependencies efficiently. Finally,we propose a concise adaptive spatio-temporal embedding graph convolution method to extract implicit spatial dependencies over time via dynamic graph convolution with adaptive spatio-temporal embedding graph generation. Extensive experiment results on four public traffic flow datasets demonstrate the superiority of our LightST concerning computational efficiency and prediction performance.},
  archive  = {J},
  author   = {Jie Hu and Taichuan Zheng and Lilan Peng and Fei Teng and Shengdong Du and Tianrui Li},
  doi      = {10.1109/TBDATA.2025.3544131},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  pages    = {1-12},
  title    = {LightST: A simplifying spatio-temporal graph neural network for traffic flow forecasting},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How to decide like human? A commonsense-aware hierarchical
framework for knowledge graph reasoning. <em>IEEE Transactions on Big
Data</em>, 1–13. (<a
href="https://doi.org/10.1109/TBDATA.2025.3544126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Reasoning over knowledge graphs has attracted considerable attention from researchers and is being widely applied to contribute question answering systems, recommender systems, and other information retrieval systems. However, existing reasoning methods tend to suffer from poor interpretability which is not consistent with human commonsense. The trustworthiness and reliability of the knowledge discover outcomes thus decreased as a result. Inspired by the process of human decision-making, we propose a commonsense-aware hierarchical framework called HDLH, which incorporates commonsense knowledge into hierarchical knowledge graph reasoning process with deep reinforcement learning. HDLH implements hierarchical reasoning process through exploration and exploitation sequentially by applying multi-agent reinforcement learning. Multiple agents in HDLH simulate the multi-level decision-making ability of humans, and reason hierarchically and reasonably to maintain its efficiency and interpretability. Moreover, commonsense knowledge is incorporated by means of the reward-shaping function, ultimately guiding the agent to reason more consistently with human perceptions and reduce the huge search space. We evaluated HDLH with various tasks on five real-world datasets. The experimental results reveal that HDLH achieves better performance compared with state-of-the-art baseline models.},
  archive  = {J},
  author   = {Yi Xia and Gang Zhou and Junyong Luo and Mingjing Lan and Ningbo Huang},
  doi      = {10.1109/TBDATA.2025.3544126},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  pages    = {1-13},
  title    = {How to decide like human? a commonsense-aware hierarchical framework for knowledge graph reasoning},
  year     = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
