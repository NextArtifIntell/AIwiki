<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TCDS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tcds---15">TCDS - 15</h2>
<ul>
<li><details>
<summary>
(2025). Automated mental fatigue detection from electroencephalogram
using joint time-frequency representation based on multivariate
iterative filtering. <em>TCDS</em>, 1–10. (<a
href="https://doi.org/10.1109/TCDS.2025.3538947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driver drowsiness detection is a crucial technology for enhancing road safety and preventing accidents caused by fatigue. This paper proposes a method for analyzing electroencephalogram (EEG) signals during driving tasks to assess the driver’s mental state. Due to the nonstationary nature of EEG, the conventional Fourier spectrum is not well suited for spectral estimation of EEG. To address this, the study employs a multivariate iterative filtering (MIF) technique to decompose multichannel EEG signals into narrowband amplitude-frequency modulated components. The instantaneous amplitude and frequency are estimated using the discrete energy separation algorithm (DESA), and a joint time-frequency representation (JTFR) based on DESA is applied to estimate the spectral content of multichannel EEG. Mental states associated with drowsiness are identified using the joint marginal spectrum and an artificial neural network classifier. The proposed MIF-based framework was validated on two EEG datasets, achieving classification accuracies of 95.03±1.08% and 98.33±1.51%, respectively. These results demonstrate the potential of the method in preventing accidents caused by drowsy or distracted driving.},
  archive      = {J_TCDS},
  author       = {Kritiprasanna Das and Ram Bilas Pachori},
  doi          = {10.1109/TCDS.2025.3538947},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Automated mental fatigue detection from electroencephalogram using joint time-frequency representation based on multivariate iterative filtering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved few-shot learning based on triplet metric for motor
imagery EEG classification. <em>TCDS</em>, 1–14. (<a
href="https://doi.org/10.1109/TCDS.2025.3539398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motor imagery-based brain-computer interface (MI-BCI) technology establishes a connection between human intention and external devices in active rehabilitation. However, obtaining a mass of labeled EEG data is often difficult due to the strict requirement of experimental environment and the necessity for highly cooperative subjects, which makes the application of few-shot learning of EEG classification particularly important. Therefore, we propose a method that combines few-shot learning with triplet metric learning, aiming to maintain strong generalization capabilities of the model with limited samples. Firstly, we pretrain a base model using large auxiliary dataset, and then fine-tune it with a small number of labeled samples from the test subjects to obtain a specific model. During the training process, metric learning between anchor samples and positive/negative samples are employed to gradually converge similar samples, creating clearer class boundaries. Then the feature information of the samples is enhanced through an attention mechanism to obtain their essential features. The proposed framework was evaluated using two publicly available datasets and obtained classification accuracies of 68.29% and 84.40%, respectively, representing enhancements of 1.04% and 1.28% over existing state-of-the-art methods. In conclusion, experimental results indicate that our proposed approach can improve the effectiveness of MI-BCI rehabilitation training.},
  archive      = {J_TCDS},
  author       = {Qingshan She and Chengjun Li and Tongcai Tan and Feng Fang and Yingchun Zhang},
  doi          = {10.1109/TCDS.2025.3539398},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Improved few-shot learning based on triplet metric for motor imagery EEG classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Where to learn: Embodied perception learning planned by
vision-language models. <em>TCDS</em>, 1–11. (<a
href="https://doi.org/10.1109/TCDS.2025.3539665">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embodied learning plays a crucial role in transferring self-learning agents to adapt to the environment. Existing embodied learning methods primarily rely on Reinforcement Learning (RL) exploration policy to collect inaccurate perceptual result samples for improving perceptual capabilities. However, RL-based exploration policies encounter several challenges such as the need for substantial data for training and the struggle to keep the diversity of the collected samples. In this paper, we propose an embodied learning method that employs Vision-Language Models (VLMs) as task planners, code planners, and path planners. Specifically, our method employs layout knowledge of the VLMs to decompose the embodied learning task into multiple sub-tasks, and then convert each sub-task into executable code which will be executed to guide the agent to explore and collect the diverse samples in different types of rooms. Additionally, VLMs incorporate an external database to identify regions that enhance perceptual capabilities, and the agent will explore these poor perception regions to collect samples that can improve the perception performance. Experimental results demonstrate the effectiveness of our approach without the need for additional training.},
  archive      = {J_TCDS},
  author       = {Juan Wang and Di Guo and Huaping Liu},
  doi          = {10.1109/TCDS.2025.3539665},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Where to learn: Embodied perception learning planned by vision-language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized reinforcement learning for multiple robotic
fish in cooperative pursuit task. <em>TCDS</em>, 1–13. (<a
href="https://doi.org/10.1109/TCDS.2025.3540071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of multi-robot systems, particularly in the pursuit-evasion (PE) with multiple robots, has gained significant attention in both academic and non-academic settings. However, the collaborative operation of multi-robotic fish systems encounters substantial challenges due to the complex underwater environment and unique movement mode. In this paper, we propose a multi-agent reinforcement learning (MARL) approach to develop a viable strategy for underwater cooperative pursuit. Initially, considering the hydrodynamic model and motion characteristics of robotic fish, we construct a specific simulation environment with multiple fish-like agents, which provides a highly realistic state transition model. Next, we develop a MARL-based strategy learning framework that incorporates appropriate reward functions and agent actions for policy learning. Finally, a series of comprehensive simulations and practical experiments are conducted to validate the effectiveness of the proposed method and confirm its successful application in underwater pursuit scenarios. These findings offer valuable insights for further research in underwater multiple robot systems.},
  archive      = {J_TCDS},
  author       = {Yukai Feng and Zhengxing Wu and Jian Wang and Sijie Li and Yupei Huang and Junzhi Yu and Min Tan},
  doi          = {10.1109/TCDS.2025.3540071},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Decentralized reinforcement learning for multiple robotic fish in cooperative pursuit task},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Visual reinforcement learning based on multi-view
optimization aggregation. <em>TCDS</em>, 1–11. (<a
href="https://doi.org/10.1109/TCDS.2025.3540115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although recent research has made some progress in deep reinforcement learning based on raw pixels, the low sample efficiency remains a key challenge in this field. Existing solutions often focus solely on extracting more effective state representations in the representation learning stage and overlook how to better utilize these state representations in the policy learning stage. To address this, a simple and sample-efficient visual reinforcement learning method based on multi-view optimization aggregation (MVOA-VRL) is proposed for pixel-based off-policy reinforcement learning frameworks. This method enables the agent to concurrently focus on learning and utilizing state representations. Specifically, MVOA-VRL acquires multiple views of samples through random crop and adaptive intensity adjustment. It then introduces optimization aggregation methods separately in the representation learning and reinforcement learning modules to aggregate the similarities, actions, and state values of multiple samples from different views. MVOA-VRL aims to promote the agent’s learning of effective representations and stable policies. Experimental results on continuous control tasks in the DMControl environment show that, compared with state-of-the-art methods, MVOA-VRL achieves higher scores and significantly improves sample efficiency.},
  archive      = {J_TCDS},
  author       = {Xuesong Wang and Ruyi Lu and Hengrui Zhang and Yuhu Cheng},
  doi          = {10.1109/TCDS.2025.3540115},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Visual reinforcement learning based on multi-view optimization aggregation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spike-VAD: Efficient and robust spiking neural network for
voice activity detection. <em>TCDS</em>, 1–13. (<a
href="https://doi.org/10.1109/TCDS.2025.3540020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern speech applications, achieving both low power consumption and noise robustness is critically essential. A well-designed Voice Activity Detection (VAD) front-end minimizes processing demands. Spiking Neural Networks (SNNs), a cutting-edge paradigm in brain-inspired computing, excel in energy efficiency due to their spike-based processing mechanisms. This makes them a promising solution for developing more efficient VAD models. In recent years, researchers have achieved notable advancements in applying SNNs to VAD, particularly in energy efficiency and performance. However, current SNN-based VAD models still struggle to achieve sufficient robustness and fail to fully exploit the low-power potential of SNNs. To address this challenge, we propose an energy-efficient and highly robust spike-based VAD model, called Spike-VAD. Spike-VAD leverages an energy-saving resonate-and-fire frequency (RF-FRE) spike encoding scheme, eliminating the need for computation-intensive Fourier Transform (FT) operations. Inspired by the human auditory frequency preference, a spike-based attention module is designed to refine the encoded spike features and enhance robustness. Furthermore, an Adaptive Memory Modulation Strategy (AMMS) is introduced to dynamically modulate historical information from the audio, facilitating more effective decision-making. Experiments on the QUT-NOISE-TIMIT dataset indicate that compared with previous SNN-based VAD models, our model achieves state-of-the-art (SOTA) performance in both robustness and energy consumption.},
  archive      = {J_TCDS},
  author       = {Kexin Shi and Mengshu Hou and Xiaoling Luo and Dehao Zhang and Hanwen Liu and Jingya Wang},
  doi          = {10.1109/TCDS.2025.3540020},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Spike-VAD: Efficient and robust spiking neural network for voice activity detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Barrier offset varying-parameter dynamic learning network
for solving dual-arms human-like behavior generation. <em>TCDS</em>,
1–12. (<a href="https://doi.org/10.1109/TCDS.2025.3541070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Enabling robots to imitate human actions and perform tasks with high precision while avoiding potential obstacles in the environment can effectively enhance the interaction between social robots and humans. In this paper, to achieve higher precision trajectory tracking and obstacle avoidance for dual-arm humanoid robots, the barrier offset varying-parameter dynamic learning neural (BOVDL) network method is proposed and applied to dual-arm humanoid behavior generation scheme. To do so, a dual-arms humanoid robot model is set up, and transformed into a constrained time-varying quadratic programming (TVQP) problem. Secondly, by using lagrangian multiplier method and Karush-Kuhn-Tuchker condition, the inequality constrained TVQP is converted as a time-varying equation with a barrier parameter. Thirdly, a varying-parameter dynamic learning network is presented to solve the time-varying equation with a barrier parameter. Computer simulation experiments are conducted to verify the feasibility, accuracy, and safety of the proposed BOVDL network method. Experimental results show that all 14 joints of the humanoid robot’s arms are within the motion range of each real human arm’s physical constraints. The maximum position error and velocity error between the desired trajectory and the actual trajectory of the end effector are less than 10–6m magnitude and 10–7m magnitude, respectively, representing a reduction of 5 orders of magnitude compared to the traditional varying-parameter convergent-differential neural network. Furthermore, the proposed method also enables the dual-arm humanoid robot to avoid collisions with obstacles while performing tasks, demonstrating the superiority of the proposed BOVDL network scheme.},
  archive      = {J_TCDS},
  author       = {Zhijun Zhang and Mingyang Zhang and Jinjia Guo and Haotian He},
  doi          = {10.1109/TCDS.2025.3541070},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Barrier offset varying-parameter dynamic learning network for solving dual-arms human-like behavior generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memristor-based circuit of sequential associative memory
with memory interactions and stimulus similarity effect. <em>TCDS</em>,
1–14. (<a href="https://doi.org/10.1109/TCDS.2025.3540591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most proposed memristor-based circuits of associative memory consider various mechanisms in only one associative memory. Few works on circuit design of sequential associative memory have been reported. In this paper, a memristor-based circuit of sequential associative memory with memory interactions and stimulus similarity effect is designed. Two associative memories, the prior associative memory (PAM) and the later associative memory (LAM), are formed successively. The PAM modifies the rate of the formation of the LAM, and the LAM, in turn, affects the strength of the PAM, which are two interactions in sequential associative memory, called transfer and retroaction. In addition, the magnitudes of transfer and retroaction are determined by the similarity of the conditioned stimuli. The above functions are realized by the ring input processing module, memory module, transfer module and retroaction module. It has been identified in circuit analysis that the proposed circuit is power efficient and has good robustness. Furthermore, the proposed circuit has promising applications for fire rescue robots.},
  archive      = {J_TCDS},
  author       = {Dongdong Xiong and Xiaoping Wang and Yiming Jiang and Chao Yang and Man Jiang and Jingang Lai and Zhigang Zeng},
  doi          = {10.1109/TCDS.2025.3540591},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Memristor-based circuit of sequential associative memory with memory interactions and stimulus similarity effect},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved dual neural network method based on levy flight
for multi-robot cooperative area coverage search in 3D unknown
environments. <em>TCDS</em>, 1–12. (<a
href="https://doi.org/10.1109/TCDS.2025.3541416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research on multi-robot collaborative search in unknown 3D environments, based on bio-inspired neural networks, holds significant value and importance.However, challenges arise in 3D environments, including excessive turning and vertical movement, as well as the potential for collisions between robots. In response, we propose an improved Glasius Bio-Inspired Neural Network(GBNN) that mitigates decision conflicts among robots and considers the impact of turning and vertical movement on robot decision-making. Furthermore, to address the issue of robots getting trapped in local deadlocks during the search process, we present a dual neural network algorithm based on Levy flights. In the method Dual Glasius Bio-Inspired Neural Network based on Levy Flight(LF-DUAL-GBNN) proposed in this paper, robots obtain random target points through Levy flights and are then guided by a dual neural network to navigate to the vicinity of the target points, thus breaking free from local deadlock states. Finally, we conducted simulation experiments to validate the algorithm’s effectiveness.},
  archive      = {J_TCDS},
  author       = {Fangfang Zhang and Yongqi Wang and Wenhao Wang and Jianbin Xin and Jinzhu Peng and Yaonan Wang},
  doi          = {10.1109/TCDS.2025.3541416},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {An improved dual neural network method based on levy flight for multi-robot cooperative area coverage search in 3D unknown environments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variability in sensory event related potential as an early
marker of cognitive impairment. <em>TCDS</em>, 1–13. (<a
href="https://doi.org/10.1109/TCDS.2025.3541729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mild cognitive impairment (MCI) is a precursor to dementia and poses significant health and economic challenges. Early detection of MCI can slow disease progression and ease the burden on patients and caregivers. This study aimed to explore sensory-perception deficits and fluctuations in MCI using auditory event-related potentials (ERPs) from a prefrontal two-channel EEG device. The study involved 573 MCI patients and 1,295 cognitively normal (CN) individuals, with cognitive decline assessed through the Seoul Neuropsychological Screening Battery (SNSB) and the Mini-Mental State Examination (MMSE). This study analyzed ERPs and trial-to-trial variability using the response variance curve (RVC) in neural responses to eight auditory sounds. While no significant differences were observed in ERP amplitudes and area under the curves (AUCs) for sensory (N1) and perception (P2) processing between MCI and CN groups, MCI patients showed notable differences in trial-to-trial variability, particularly in those aged 70 to 79 years. This variability remained significant even after adjusting for factors like age, sex, years of education, and MMSE scores. The study suggests that MCI is associated with instability in pre-attentive auditory detection and higher-order perceptual processing. The findings highlight that people in their 70s may be in a transitional phase associating these sensory-perceptual variabilities with cognitive impairment. Given the large sample size and limitations of current neuropsychological tests, the study underscores the potential of sensory ERP measures as a supplementary tool for MCI screening.},
  archive      = {J_TCDS},
  author       = {Joel Eyamu and Wuon-shik Kim and Kahye Kim and Lee Kun Ho and Jaeuk U. Kim},
  doi          = {10.1109/TCDS.2025.3541729},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Variability in sensory event related potential as an early marker of cognitive impairment},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RoboGPT: An LLM-based long-term decision-making embodied
agent for instruction following tasks. <em>TCDS</em>, 1–11. (<a
href="https://doi.org/10.1109/TCDS.2025.3543364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic agents are tasked with mastering common sense and making long-term sequential decisions to execute daily tasks based on natural language instructions. Recent advancements in Large Language Models (LLMs) have catalyzed efforts for complex robotic planning. However, despite their superior generalization and comprehension capabilities, LLM task plans sometimes suffer from issues of accuracy and feasibility. To address these challenges, we propose RoboGPT11For more details, please refer to our project page https://github.com/Cwb0106/RoboGPT., an embodied agent specifically designed to make long-term decisions for instruction following tasks. RoboGPT integrates three key modules: 1) RoboPlanner, an LLM-based planning module equipped with 67K embodied planning data, breaks down tasks into logical subgoals. We compile a new robotic dataset using a template feedback-based self-instruction method to fine-tune the Llama model. RoboPlanner with strong generalization can plan hundreds of instruction following tasks; 2) RoboSkill, customized for each subgoal to improve navigation and manipulation capabilities; 3) Re-Plan, a module that dynamically adjusts the subgoals based on real-time environmental feedback. By utilizing the precise semantic map generated by RoboSkill, the target objects can be replaced by calculating the similarity between subgoals and the objects present in the environment. Experimental results demonstrate that RoboGPT exceeds the performance of other state-of-the-art (SOTA) methods, particularly LLM-based methods, in terms of task planning rationality for hundreds of unseen daily tasks and even tasks from other domains.},
  archive      = {J_TCDS},
  author       = {Yaran Chen and Wenbo Cui and Yuanwen Chen and Mining Tan and Xinyao Zhang and Jinrui Liu and Haoran Li and Dongbin Zhao and He Wang},
  doi          = {10.1109/TCDS.2025.3543364},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {RoboGPT: An LLM-based long-term decision-making embodied agent for instruction following tasks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Foundational policy acquisition via multitask learning for
motor skill generation. <em>TCDS</em>, 1–11. (<a
href="https://doi.org/10.1109/TCDS.2025.3543350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a multitask reinforcement learning algorithm for foundational policy acquisition to generate novel motor skills. Learning the rich representation of the multitask policy is a challenge in dynamic movement generation tasks because the policy needs to cope with changes in goals or environments with different reward functions or physical parameters. Inspired by human sensorimotor adaptation mechanisms, we developed the learning pipeline to construct the encoder-decoder networks and network selection to facilitate foundational policy acquisition under multiple situations. First, we compared the proposed method with previous multitask reinforcement learning methods in the standard multi-locomotion tasks. The results showed that the proposed approach outperformed the baseline methods. Then, we applied the proposed method to the ball heading task using a monopod robot model to evaluate skill generation performance. The results showed that the proposed method was able to adapt to novel target positions or inexperienced ball restitution coefficients but to acquire a foundational policy network, originally learned for heading motion, which can generate an entirely new overhead kicking skill.},
  archive      = {J_TCDS},
  author       = {Satoshi Yamamori and Jun Morimoto},
  doi          = {10.1109/TCDS.2025.3543350},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Foundational policy acquisition via multitask learning for motor skill generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-task reinforcement learning via
task-specific action correction. <em>TCDS</em>, 1–15. (<a
href="https://doi.org/10.1109/TCDS.2025.3543694">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task reinforcement learning (MTRL) holds potential for building general-purpose agents, enabling them to generalize across a variety of tasks. However, MTRL may still be susceptible to conflicts between tasks. A primary reason for this problem is that a universal policy struggles to balance short-term and dense learning signals across various tasks, e.g. , distinct reward functions in reinforcement learning. In social cognitive theory, internalized future goals, as a form of cognitive representations, can effectively mitigate potential short-term conflicts in multitask settings. Considering the benefits of future goals, we propose a novel and general framework called Task-Specific Action Correction (TSAC) from the goal perspective as an orthogonal research to previous MTRL methods. Specifically, to avoid myopia, TSAC introduces goal-oriented sparse rewards and decomposes policy learning into two separate policies: a shared policy (SP) and an action correction policy (ACP). The SP outputs a short-term perspective action based on guiding dense rewards. To alleviate conflicts resulting from excessive focus on specific tasks’ details in SP, the ACP incorporates goal-oriented sparse rewards, enabling an agent to adopt a long-term perspective to output a correction action and achieve generalization across tasks. Finally, the actions output by SP and ACP are combined based on the action correction function to form a final action that interact with the environment. Extensive experiments conducted on Meta-World and multi-task StarCraft II multi-agent scenarios demonstrate that TSAC outperforms existing state-of-the-art methods, achieving significant improvements in sample efficiency, generalization and effective action execution across tasks.},
  archive      = {J_TCDS},
  author       = {Jinyuan Feng and Min Chen and Zhiqiang Pu and Tenghai Qiu and Jianqiang Yi and Jie Zhang},
  doi          = {10.1109/TCDS.2025.3543694},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Efficient multi-task reinforcement learning via task-specific action correction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A marr-inspired framework for raising “good” robots.
<em>TCDS</em>, 1–11. (<a
href="https://doi.org/10.1109/TCDS.2025.3540217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our current computer and AI systems are built on Neuroscience principles from almost a century ago. Recent advances in our understanding of biological computation have not crossed into computer science to catalyse advancements. We outline a multidimensional blueprint for a form of bio-inspired agent leveraging modern Neuroscience principles (including the co-localisation of memory and compute, plasticity, embodiment, active inference, and neurodevelopmental principles). We discuss how combining these core features could theoretically lead to cognitive agents that are aligned to our prosocial values, transparent, explainable, and energy efficient (i.e., “good” robots). In particular, we leverage Marr’s tri-level framework and advocate for an “Implementation Level” consisting of embodied neuromorphic hardware, an “Algorithmic Level” consisting of Active Inference, and a “Computational Level” consisting of prosocial goals (supported by evidence of prosociality catalysing the development of our own complex cognitive abilities). A developmental process scaffolds different prosocial computations over time. Supporting our perspective, we include simulation data demonstrating the transfer of priors between two different prosocial behaviours (Computational Level) via Active Inference (Algorithmic Level), supported by an embodied process (Implementation Level). Agent behaviour is transparent and explainable throughout. We advocate for this blueprint as a guide in creating capable, ethical, and sustainable machine intelligence.},
  archive      = {J_TCDS},
  author       = {Sarah Hamburg and Alejandro Jimenez-Rodriguez and Aung Htet and Alessandro Di Nuovo},
  doi          = {10.1109/TCDS.2025.3540217},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {A marr-inspired framework for raising “Good” robots},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-subject and cross-session EEG emotion recognition
based on multi-source structural deep clustering. <em>TCDS</em>, 1–15.
(<a href="https://doi.org/10.1109/TCDS.2025.3545666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individual fluctuations and temporal variabilities of Electroencephalogram (EEG) pose challenges in precisely identifying emotions. Although a model performs well with data specific to a certain subject or session, the fluctuations in EEG data can significantly impair the performance on a different subject or session. As a result, current approaches synchronize the original and new subject or session feature distributions. Directly matching EEG data across individuals or sessions may undermine the inherent distinguishability due to the heterogeneity in data distribution. Instead of direct alignment, this work utilizes multi-source structural deep clustering to identify the inherent structural knowledge of the target itself and regularize it through the distribution of source labels. Furthermore, the method was implemented on the intermediate output utilizing high-confidence features to improve pattern identification in the latent feature space. This led to more distinct differentiations across subdomains with varying labels. Comparative analyses were performed with state-of-the-art (SOTA) models on SEED and SEED-IV datasets. The model proposed outperformed other baseline models under the strict leave-one-subject-out strategy, reaching an average accuracy of 88.20%/90.06% in a cross-subject/cross-session experiment on SEED and 71.49%/69.96% in SEED-IV. This research provides a novel approach to align EEG features without the need for direct distance calculation.},
  archive      = {J_TCDS},
  author       = {Yiyuan Chen and Xiaodong Xu and Xiaowei Qin},
  doi          = {10.1109/TCDS.2025.3545666},
  journal      = {IEEE Transactions on Cognitive and Developmental Systems},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Cogn. Develop. Syst.},
  title        = {Cross-subject and cross-session EEG emotion recognition based on multi-source structural deep clustering},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
