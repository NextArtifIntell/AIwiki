<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tai---33">TAI - 33</h2>
<ul>
<li><details>
<summary>
(2025). HDL: Hybrid and dynamic learning for fake face recognition.
<em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3537963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face swapping aims to replace a source face with a target face, generating a fake face that is indistinguishable from the real one to the human eye. Existing face recognition methods usually discriminate the fake face as the target face identity, which happens to be misguided. To address this embarrassment, we pioneer a new task called “fake face recognition”, which seeks to discover the identity of the source face based on the fake face. Besides, we design a hybrid and dynamic learning strategy for fake face recognition. Specifically, we hybridize the existing real face recognition dataset with the fake face dataset. Based on the popular margin-based face recognition approach, we achieve dynamic learning by adjusting the margin for the fake face samples. The deep network is guided to first focus on real samples and then explore the identity implicit commonalities between real and fake samples. To verify the performance of the fake face recognition model, we further organize the existing fake face datasets into face pairs. Extensive experiments on the fake face datasets show that our proposed hybrid and dynamic learning strategy achieves superior average accuracy (98.46%) compared to benchmark studies.},
  archive      = {J_TAI},
  author       = {Baojin Huang and Jiaqi Ma and Guangcheng Wang and Hui Wang},
  doi          = {10.1109/TAI.2025.3537963},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {HDL: Hybrid and dynamic learning for fake face recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial networks for dynamic malware
behavior: A comprehensive review, categorization, and analysis.
<em>TAI</em>, 1–23. (<a
href="https://doi.org/10.1109/TAI.2025.3537966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper highlights the critical role of Machine Learning (ML) in combating the dynamic nature of cybersecurity threats. Unlike previous studies focusing mainly on static analysis, this work surveys the literature on dynamic analysis-based malware generation and detection. The study addresses the complexities of applying GANs to tabular data with heavy-tailed and multimodal distributions. It also examines the challenges of generating sequential malware behavior data and categorizes GAN-based models and their primary use cases. Furthermore, the paper evaluates adversarial losses and their limitations in generating dynamic malware behavior. Finally, it identifies existing metrics to assess GAN generalization in malware research and suggests future research directions based on identified limitations.},
  archive      = {J_TAI},
  author       = {Ghebrebrhan Gebrehans and Naveed Ilyas and Khouloud Eledlebi and Willian T. Lunardi and Martin Andreoni and Chan Yeob Yeun and Ernesto Damiani},
  doi          = {10.1109/TAI.2025.3537966},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-23},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Generative adversarial networks for dynamic malware behavior: A comprehensive review, categorization, and analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel recursive ensemble feature selection framework for
high-dimensional data. <em>TAI</em>, 1–12. (<a
href="https://doi.org/10.1109/TAI.2025.3538549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble feature selection combines feature subsets with diversity, potentially providing a better approximation of the optimal feature subset. While extensive research has focused on enhancing diversity among ensemble members, its critical role during the aggregation process remains underexplored. To address this gap, we propose a novel Recursive Ensemble Feature Selection (REFS) framework that explicitly incorporates diversity into the aggregation phase to improve both robustness and accuracy. The framework comprises three key components: (1) a randomization-based feature mapping strategy to generate diverse base feature selectors optimized for performance; (2) a quantitative diversity metric to evaluate the complementarity of these selectors; and (3) a fuzzy aggregation method that leverages order statistics, rank scores, and weight information to effectively integrate multiple ranked feature lists. Experimental evaluations on fifteen real-world datasets demonstrate that REFS consistently outperforms competitive methods in terms of classification accuracy and resilience to parameter variations. By explicitly integrating diversity into the aggregation process, REFS provides a more comprehensive and effective approach to feature selection, paving the way for improved predictive performance across diverse applications.},
  archive      = {J_TAI},
  author       = {Xiaojian Ding and Zihan Xu and Yi Li and Fumin Ma and Shilin Chen},
  doi          = {10.1109/TAI.2025.3538549},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A novel recursive ensemble feature selection framework for high-dimensional data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CWPFormer: Towards high-performance visual place recognition
for robot with cross-weight attention learning. <em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3538818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important component of robot localization and navigation, visual place recognition (VPR) has made significant improvements in the past few decades. Most existing state-of-the-art VPR methods face the following challenges: 1) Aiming only for performance with ideal conditions while overlooking real-world conditions; 2) The existing VPR paradigm, struggling to reconcile the transfer gap between upstream pre-training and downstream fine-tuning; 3) Deeper networks produce high-dimensional parameters in the model training that results in lower efficient of models. To address those problems, we propose a high-performance visual place recognition framework for robot navigation tasks. Concretely, our framework is composed of three major modules: 1) based on vision transformer (ViT), we design a siamese Cross-weight Pyramid Transformer (CWPFormer) backbone for image feature extraction. First, we integrate feature reconstruction and content cognition by inserting a feature pyramid phase into pre-training. Second, we establish weight correlation and sharing between feature downsampling and upsampling that offers multi-stage supervision to fine-tuning. 2) We found that the attention map has high similarity between heads, and the high-dimensional data processing based on the ViT leads to computational redundancy. To cope with this problem, we present a cascaded hash attention (CHA) module to feed the hash attention head with different complete feature splits, which not only saves the computational cost but also improves the attention diversity. 3) Besides, we adopt a Bayesian learning scheme with a dynamically constructed similarity matrix to learn one-dimensional compact hash codes to improve recognition accuracy. Exhaustive experiments demonstrate the superiority of our proposed VPR approach on datasets and real-world environments. Our code is available: https://github.com/CV4RA/CWPFormer.},
  archive      = {J_TAI},
  author       = {Zhenyu Li and Pengjie Xu and Tianyi Shang},
  doi          = {10.1109/TAI.2025.3538818},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {CWPFormer: Towards high-performance visual place recognition for robot with cross-weight attention learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-empowered cyber-secure federated learning for
trustworthy edge computing. <em>TAI</em>, 1–9. (<a
href="https://doi.org/10.1109/TAI.2025.3539258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) is a privacy-preserving distributed machine learning scheme, where each participant’s data remains on the participant’s devices and only the local model generated utilizing the local computational power is transmitted throughout the database. However, the distributed computational nature of FL creates the necessity to develop a mechanism that can remotely trigger any network agents, track their activities, and prevent threats to the overall process posed by malicious participants. Particularly, the FL paradigm may become vulnerable due to an active attack from the network participants, called a poisonous attack. In such an attack, the malicious participant acts as a benign agent capable of affecting the global model quality by uploading an obfuscated poisoned local model update to the server. This paper presents a cross-device FL model that ensures trustworthiness, fairness, and authenticity in the underlying FL training process. We leverage trustworthiness by constructing a reputation-based trust model based on agents’ contributions toward model convergence. We ensure fairness by identifying and removing malicious agents from the training process through an outlier detection technique. Additionally, we establish authenticity by generating a token for each participating device through a distributed sensing mechanism and storing that unique token in a blockchain smart contract. Further, we insert the trust scores of all agents into a blockchain and validate their reputations using various consensus mechanisms that consider the computational task.},
  archive      = {J_TAI},
  author       = {Ervin Moore and Ahmed Imteaj and Md Zarif Hossain and Shabnam Rezapour and M. Hadi Amini},
  doi          = {10.1109/TAI.2025.3539258},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-9},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Blockchain-empowered cyber-secure federated learning for trustworthy edge computing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Beyond histogram comparison: Distribution-aware simple-path
graph kernels. <em>TAI</em>, 1–14. (<a
href="https://doi.org/10.1109/TAI.2025.3539642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {R-convolution graph kernels are conventional methods for graph classification. They decompose graphs into substructures and aggregate all the substructure similarity as graph similarity. However, the substructure similarity is based on graph isomorphism, which not only leads to binary similarity values but also cannot be aware of the probability distribution of substructures in each graph. Moreover, the simple sum aggregation is not aware of the probability distribution differences of substructures across graphs. These drawbacks cause inaccurate graph similarity. To resolve these problems, we propose a new method called the Distribution-Aware Simple-Path (DASP) graph kernel. The neural language models are employed to capture the probability distribution of substructures (specifically, simple paths) in each graph. A new metric called Probabilistic Minkowski Distance is developed to capture the probability distribution differences of simple paths across graphs. To further improve the performance, the label alphabet is expanded to enlarge the corpus of simple paths for the neural language models and DASP. Experiments demonstrate that DASP achieves the best classification accuracy on all the selected graph benchmark datasets.},
  archive      = {J_TAI},
  author       = {Wei Ye and Shuhao Tang and Hao Tian and Qijun Chen},
  doi          = {10.1109/TAI.2025.3539642},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Beyond histogram comparison: Distribution-aware simple-path graph kernels},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-dimensional hyperparameter optimization via adjoint
differentiation. <em>TAI</em>, 1–15. (<a
href="https://doi.org/10.1109/TAI.2025.3540799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging machine learning task, high-dimensional hyperparameter optimization (HO) aims at enhancing traditional deep learning models by simultaneously optimizing the neural networks’ weights and hyperparameters in a joint bilevel configuration. However, such nested objectives can impose nontrivial difficulties for the pursuit of the gradient of the validation risk with respect to the hyperparameters (a.k.a. hypergradient). To tackle this challenge, we revisit its bilevel objective from the novel perspective of continuous dynamics and then solve the whole HO problem with the adjoint state theory. The proposed HO framework, termed Adjoint Diff, is naturally scalable to a very deep neural network with high-dimensional hyperparameters because it only requires constant memory cost in training. Adjoint Diff is in fact, a general framework that some existing gradient-based HO algorithms are well interpreted by it with simple algebra. In addition, we further offer the Adjoint Diff+ framework by incorporating the prevalent momentum learning concept into the basic Adjoint Diff for enhanced convergence. Experimental results show that our Adjoint Diff frameworks outperform several state-of-the-art approaches on three high-dimensional HO instances including designing loss function for imbalanced data, selecting samples from noisy labels and learning auxiliary tasks for fine-grained classification.},
  archive      = {J_TAI},
  author       = {Hongkun Dou and Hongjue Li and Jinyang Du and Leyuan Fang and Qing Gao and Yue Deng and Wen Yao},
  doi          = {10.1109/TAI.2025.3540799},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {High-dimensional hyperparameter optimization via adjoint differentiation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path-aware few-shot knowledge graph completion.
<em>TAI</em>, 1–14. (<a
href="https://doi.org/10.1109/TAI.2025.3540796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Knowledge Graph Completion (FKGC) has emerged as a significant area of interest for addressing the long-tail problem in knowledge graphs. Traditional approaches often focus on the sparse few-shot neighborhood to derive semantic representation, overlooking other critical information forms such as relation paths. In this paper, we introduce an innovative method, called PARE, which fully leverages relation paths to enhance the few-shot representation by simultaneously incorporating both neighborhood and relation path information. Inspired by the principles of information transmission, PARE directly models relation paths between entities and parameterizes the information interference within different relation paths. Through parameter learning, PARE effectively captures information propagation along relation paths while mitigating the influence of relation dependency. To preserve neighborhood information, we employ a two-step neighborhood aggregator to resolve few-shot neighbors’ ambiguity and develop a reconstruction module. By integrating the representations of relation paths and contextual neighborhoods, we achieve a comprehensive fewshot representation for two given entities. We utilize a matching processor for knowledge triplet evaluation. Extensive experiments demonstrate that our PARE model outperforms state-of-the-art baselines on widely-used benchmark datasets.},
  archive      = {J_TAI},
  author       = {Shuo Yu and Yingbo Wang and Zhitao Wan and Yanming Shen and Qiang Zhang and Feng Xia},
  doi          = {10.1109/TAI.2025.3540796},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Path-aware few-shot knowledge graph completion},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient solution validation of constraint satisfaction
problems on neuromorphic hardware: The case of sudoku puzzles.
<em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3536428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) offer an effective approach to solving constraint satisfaction problems (CSPs) by leveraging their temporal, event-driven dynamics. Moreover, neuromorphic hardware platforms provide the potential for achieving significant energy efficiency in implementing such models. Building upon these foundations, we present an enhanced, fully spiking pipeline for solving CSPs on the SpiNNaker neuromorphic hardware platform. Focusing on the use case of Sudoku puzzles, we demonstrate that the adoption of a constraint stabilization strategy, coupled with a neuron idling mechanism and a built-in validation process, enables this application to be realized through a series of additional layers of neurons capable of performing control logic operations, verifying solutions, and memorizing the network’s state. Simulations conducted in the GPU-enhanced Neuronal Networks (GeNN) environment validate the contributions of each pipeline component before deployment on SpiNNaker. This approach offers three key advantages: i) Improved success rates for solving CSPs, particularly for challenging instances from the hard class, surpassing state-of-the-art SNN-based solvers. ii) Reduced data transmission overhead by transmitting only the final activity state from SpiNNaker instead of all generated spikes. iii) Substantially decreased spike extraction time. Compared to previous work focused on the same use case, our approach achieves a significant reduction in the number of extracted spikes (54.63% to 99.98%) and extraction time (88.56% to 96.41%).},
  archive      = {J_TAI},
  author       = {Riccardo Pignari and Vittorio Fra and Enrico Macii and Gianvito Urgese},
  doi          = {10.1109/TAI.2025.3536428},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Efficient solution validation of constraint satisfaction problems on neuromorphic hardware: The case of sudoku puzzles},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised multivariate time series anomaly detection by
feature decoupling in federated learning scenarios. <em>TAI</em>, 1–15.
(<a href="https://doi.org/10.1109/TAI.2025.3533437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalies are usually regarded as data errors or novel patterns previously unseen, which are quite different from most observed data. Accurate detection of anomalies is crucial in various application scenarios. This paper focuses on unsupervised anomaly detection from Multivariate Time Series (MTS), as real-world data collected from sources such as wearable devices, medical equipment and industrial machines typically manifest as MTS and are often unlabeled. Anomaly detection in MTS represents a data-driven challenge that traditionally requires substantial centralized data for training models. However, in practice, data are frequently distributed among multiple institutions, with privacy concerns restricting unrestricted access. To address these issues, we introduce Feature Decoupling Federated Learning (FDFL), an approach designed to collaboratively train a representation learning network over multiple clients for unsupervised anomaly detection in MTS. Unlike previous methods that simply integrate MTS anomaly detection algorithms with federated learning strategies, FDFL specifically addresses heterogeneity among clients by decoupling the representation network into shared and private branches through a contrastive learning mechanism. This method aggregates shared parameters during each federated round while maintaining client-specific private parameters locally. Additionally, we develop a self-attention block that integrates the representations derived from both shared and private parameters to reconstruct MTS and identify anomalies based on reconstruction errors. Extensive experiments conducted on three publicly available datasets demonstrate that FDFL outperforms existing algorithms in most cases, highlighting the effectiveness and superiority of our proposed method in MTS anomaly detection.},
  archive      = {J_TAI},
  author       = {Yifan He and Xi Ding and Yateng Tang and Jihong Guan and Shuigeng Zhou},
  doi          = {10.1109/TAI.2025.3533437},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Unsupervised multivariate time series anomaly detection by feature decoupling in federated learning scenarios},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting gaussian noise variance for dynamic differential
poisoning in federated learning. <em>TAI</em>, 1–17. (<a
href="https://doi.org/10.1109/TAI.2025.3540030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging field of Federated Learning (FL) is reshaping privacy-preserved data analysis and decision support mechanisms within several critical infrastructure (CIs) sectors such as autonomous transportation, energy, and healthcare. To shield sensitive operational and client data from privacy attackers, Differential Privacy (DP) has been proposed to integrate on top of the FL process. Yet, we identify that integrating Gaussian noise for achieving DP guarantee can inadvertently create a new vector for differential model poisoning attacks in FL. Moreover, exploiting the variance in Gaussian noise enables attackers to camouflage their activities within the legitimate noise of the system, a significant yet largely overlooked security flaw in the differentially private federated learning (DPFL) framework. Addressing this research gap, we introduce a novel adaptive model poisoning through episodic loss memorization (α-MPELM) technique. This method enables attackers to dynamically inject adversarial noise into the differentially private local model parameters. The technique has a dual purpose: hindering the optimal convergence of the global FL model and simultaneously avoiding detection by the anomaly detectors. Our evaluation of the α-MPELM attack reveals its capability to deceive Norm, Accuracy, and Mix anomaly detection algorithms, surpassing the conventional random malicious device (RMD) attacks with attack accuracy improvements of 6.8%, 12.6%, and 13.8%, respectively. Additionally, we introduce a reinforcement learning-based DP level selection strategy, rDP, as an effective countermeasure against α-MPELM attack. Our empirical findings confirm that this defense mechanism steadily progresses to an optimal policy.},
  archive      = {J_TAI},
  author       = {Md Tamjid Hossain and Shahriar Badsha and Hung La and Shafkat Islam and Ibrahim Khalil},
  doi          = {10.1109/TAI.2025.3540030},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Exploiting gaussian noise variance for dynamic differential poisoning in federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multi-particle swarm neural architecture search for
high-incidence cancer prediction. <em>TAI</em>, 1–12. (<a
href="https://doi.org/10.1109/TAI.2025.3543822">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cancer is a disease caused by uncontrolled growth and spread of cells, and early diagnosis is essential to improve the cure rate and reduce mortality. Although machine learning and deep learning have shown great potential in early cancer prediction, the accuracy of detection and prediction still needs to be improved due to the different scales of lesion areas. Therefore, we propose an adaptive multi-particle swarm neural architecture search method to automatically explore an efficient deep neural network architecture for high-incidence cancer prediction. Firstly, the multi-particle swarm strategy is used to initialize the high-quality architecture in the scale adaptive search space to enhance multi-scale perception. Then, the improved weighted average method is combined with classification accuracy, parameters and floating-point operations to adaptively update the particle swarm architecture to avoid falling into local optimum. In addition, a method based on weight sharing is used to improve the efficiency of architecture search. The experimental results show that comparing with the manual design network and the existing neural architecture search method, the proposed algorithm achieves average increments of 26.33%, 33.99%, 8.98%, 37.41%, 35.1% and 51.76% in classification accuracy, F1-Score, Cohen’s kappa, AUC, exponential balance accuracy and search efficiency, respectively.},
  archive      = {J_TAI},
  author       = {Liming Xu and Jie Zheng and Chunlin He and Jing Wang and Bochuan Zheng and Jiancheng Lv},
  doi          = {10.1109/TAI.2025.3543822},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Adaptive multi-particle swarm neural architecture search for high-incidence cancer prediction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facilitating continuous facial aging through latent age
attribute modulation. <em>TAI</em>, 1–15. (<a
href="https://doi.org/10.1109/TAI.2025.3543811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, facial aging has attracted significant research interest due to its broad applications and potential benefits. While Generative Adversarial Networks (GANs) have achieved notable progress in synthesizing realistic facial images, many GAN-based facial aging methods struggle to accurately capture the continuous progression of age-related changes over time. In this paper, we propose an innovative framework featuring the Latent Age Attribute Module (LAAM), which maps age attributes to a structured latent space that facilitates efficient sampling for precisely age attribute modeling. We further introduce the Age-AdaIN Fusion Module (AFM), which seamlessly integrates age features from LAAM with facial content features, enabling the generation of images that exhibit smooth, continuous age transitions. This framework excels in capturing fine-grained aging details, particularly for elderly individuals. Quantitative and qualitative evaluations on benchmark datasets demonstrate the effectiveness of our approach in generating realistic age-progressed facial images, with a notable improvement in elderly aging accuracy and detail.},
  archive      = {J_TAI},
  author       = {Xiyuan Hu and Jinglei Qu and Chen Chen},
  doi          = {10.1109/TAI.2025.3543811},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Facilitating continuous facial aging through latent age attribute modulation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multimodal-driven fusion data augmentation framework for
emotion recognition. <em>TAI</em>, 1–16. (<a
href="https://doi.org/10.1109/TAI.2025.3537965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pursuit of imbuing computers with emotional intelligence has driven extensive research into physiological signal analysis for emotion recognition. Deep learning techniques offer promising avenues for analyzing physiological signals in this domain. Despite numerous studies on emotion recognition using various physiological signals, challenges persist in classifying multimodal physiological signals due to data scarcity. Current research lacks focus on addressing data insufficiency for multimodal physiological signals. This paper proposes an innovative method to address this issue and improve the effect of emotion recognition using multimodal physiological signal data. Our model comprises a physiological signal encoder, a multimodal data generator, and a multimodal emotion recognizer. Specifically, we introduce a customized ConvNeXt-Attention fusion model (CNXAF) to fuse diverse physiological signals, generating fused multimodal data. The multimodal data generator employs a conditional Self-Attention Generative Adversarial Network (c-SAGAN) to synthesize additional data across different categories, augmenting original datasets. Finally, the multimodal emotion recognizer utilizes the ConvNeXt-t classifier for emotion recognition on the extended dataset. Through extensive experimentation, our model achieves accuracies of 96.06% on the DEAP dataset and 95.70% on the WESAD dataset, demonstrating the effectiveness of our approach in accurately recognizing emotions. Experimental results underscore the superior performance of our method compared to existing approaches in multimodal emotion recognition research. Our code is publicly available at https://github.com/suprola1017/Multimodal-Data-Enhance-Framework-for-Emotion-Recognation.},
  archive      = {J_TAI},
  author       = {Ao Li and Minchao Wu and Rui Ouyang and Yongming Wang and Fan Li and Zhao Lv},
  doi          = {10.1109/TAI.2025.3537965},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {A multimodal-driven fusion data augmentation framework for emotion recognition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ContentDM: A layout diffusion model for content-aware layout
generation. <em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3544172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Content-aware layout generation aims to produce fitting element arrangements based on the background contents, which is used for graphic design applications such as automatic poster layout design. In this paper, we propose ContentDM, a layout diffusion model specifically designed for the content-aware layout generation task, overcoming the limitations suffered from existing methods: irrational arrangement among layout elements and lack of refining ability for coarse generated results. ContentDM defines the layout diffusion process through random perturbations applied to both the position and type of layout elements. During the denoising training phase, the content-aware layout generator is trained to reconstruct samples from these perturbed layouts. This process enables the model to learn the correct arrangement patterns within the layout elements, thereby enhancing the rationality of generated layouts. Moreover, we develop an iterative layout inference strategy to enable the layout generator to refine the generated layouts progressively, thereby enhancing the overall quality of the generation results. Extensive experiments demonstrate that ContentDM significantly outperforms existing methods, achieving state-of-the-art performance in content-aware layout generation, both in terms of visual quality and quantitative metrics.},
  archive      = {J_TAI},
  author       = {Honglin Guo and Weizhi Nie and Ruidong Chen and Lanjun Wang and Guoqing Jin and Anan Liu},
  doi          = {10.1109/TAI.2025.3544172},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ContentDM: A layout diffusion model for content-aware layout generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-generated vs. Human text: Introducing a new dataset for
benchmarking and analysis. <em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3544183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence (AI) is increasingly embedded in our everyday lives. With the introduction of ChatGPT in November 2022 by OpenAI, people can now ask a bot to generate comprehensive writeups in seconds. This new transformative technology also introduces ethical, safety, and other general concerns. It is important to harness the power of AI to understand whether a body of text is generated by AI or whether it is organically human. In this paper, we create and curate a medium-sized dataset of 10,000 records containing both human and machine-generated text and utilize it to train a reliable model to accurately distinguish between the two. First, we use DistilGPT-2 with various inputs to generate machine text. Then, we acquire an equal sample size of human-generated text. All the text is cleaned, explored, and visualized using the Uniform Manifold Approximation and Projection (UMAP) dimensionality reduction technique. Finally, the text is transformed into vectors using several techniques, including BoW, TF-IDF, BERT, and neural network-based embeddings. Machine learning experiments are then performed with traditional models such as Logistic Regression, Random Forest, and XGBoost, as well as deep learning models like LSTM, CNN, and CNN-LSTM. Across all vectorization strategies and machine learning algorithms, we measure accuracy, precision, recall, and F1 scores. We also time each exercise. Each model completes its training within an hour, and we observe scores above 90%. We then use the SHapley Additive exPlanations (SHAP) package on machine learning models to explore if and how we can explain the model to further validate results. Lastly, we deploy our TF-IDF Random Forest model to a user-friendly web application using the Streamlit framework, allowing users without coding expertise to interact with the model.},
  archive      = {J_TAI},
  author       = {Ali Al Bataineh and Rachel Sickler and Kerry Kurcz and Kristen Pedersen},
  doi          = {10.1109/TAI.2025.3544183},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {AI-generated vs. human text: Introducing a new dataset for benchmarking and analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture density function estimation in shape clustering.
<em>TAI</em>, 1–15. (<a
href="https://doi.org/10.1109/TAI.2025.3543815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent developments in measurement tools have made it easier to obtain shape data, a collection of point coordinates in vector space that are meaningful when some of them are gathered together. As a result, clustering of shape data becomes increasingly important. However, few studies still perform applicable clustering in various cases because some studies rely on their specific shape representations. Thus, we apply a simple and widely recognized representation and generative model to shape. A configuration matrix of the point coordinates is used for the representation, and it is the simplest and most well-accepted representation in conventional shape analysis. As a generative model, we consider the mixture density function, a well-known model in statistics for expressing a population density function, which is a linear combination of subpopulation density functions. The aim of this paper is to present a mixture density-based model that will be useful for clustering shape data. The clustering of shapes involves estimating the parameters of the model, and this estimation is derived using an EM algorithm based on the model. As examples of promising shape-data applications, the computational analyses of ape skulls, American football formations, and baseball pitches were performed. In addition, we evaluated the performance of the EM algorithm by comparing it with other typical clustering methods. The theoretical results not only contribute to statistical estimation for shape data but also extend the clustering of non-vector shape data. The experimental results show that the derived EM algorithm performs well in shape clustering.},
  archive      = {J_TAI},
  author       = {Kazunori Iwata},
  doi          = {10.1109/TAI.2025.3543815},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Mixture density function estimation in shape clustering},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Similar or related: Spectral-based item relationship mining
with graph convolutional network for complementary recommendation.
<em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3543820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complementary recommendation, which aims to recommend frequently co-purchased items to users, has gained significant attention. Unlike traditional similarity-based recommendations, complementary recommendation focus on items that are related but not necessarily similar (e.g., computers and keyboards), that aligns with users’ purchasing habits. However, most of current complementary recommendation systems fail to effectively differentiate or measure these two types of relationships. In this paper, we propose Similar or Related: Spectral-Based Item Relationship Mining with Graph Convolutional Network for Complementary Recommendation (SR-Rec). Firstly, we design two spectral-based filters to fully mine the similarity and relevance information of items, thereby achieving effective discrimination between the two types of relationships. Then, we compute similarity and relevance scores between items separately, and employ a pairwise self-attention mechanism to measure the impact of these relationships on the final recommendations. Experimental results on three public open-source datasets demonstrate that SR-Rec outperforms state-of-the-art performance in complementary recommendation. The code is available at https://github.com/Andrewsama/SR-Rec-master.},
  archive      = {J_TAI},
  author       = {Gang-Feng Ma and Xu-Hua Yang and Haixia Long and Yujiao Huang},
  doi          = {10.1109/TAI.2025.3543820},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Similar or related: Spectral-based item relationship mining with graph convolutional network for complementary recommendation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent actor-critic generative AI for query resolution
and analysis. <em>TAI</em>, 1–15. (<a
href="https://doi.org/10.1109/TAI.2025.3544173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce MASQRAD (Multi-Agent Strategic Query Resolution and Diagnostic tool), a transformative framework for query resolution based on the actor-critic model, which utilizes multiple generative AI agents. MASQRAD is excellent at translating imprecise or ambiguous user inquiries into precise and actionable requests. This framework generates pertinent visualizations and responses to these focused queries, as well as thorough analyses and insightful interpretations for users. MASQRAD addresses the common shortcomings of existing solutions in domains that demand fast and precise data interpretation, such as their incapacity to successfully apply AI for generating actionable insights and their challenges with the inherent ambiguity of user queries. MASQRAD functions as a sophisticated multi-agent system but “masquerades” to users as a single AI entity, which lowers errors and enhances data interaction. This approach makes use of three primary AI agents: Actor Generative AI, Critic Generative AI, and Expert Analysis Generative AI. Each is crucial for creating, enhancing, and evaluating data interactions. The Actor AI generates Python scripts to generate data visualizations from large datasets within operational constraints, and the Critic AI rigorously refines these scripts through multi-agent debate. Finally, the Expert Analysis AI contextualizes the outcomes to aid in decision-making. With an accuracy rate of 87% when handling tasks related to natural language visualization, MASQRAD establishes new benchmarks for automated data interpretation and showcases a noteworthy advancement that has the potential to revolutionize AI-driven applications.},
  archive      = {J_TAI},
  author       = {Mohammad Wali Ur Rahman and Ric Nevarez and Lamia Tasnim Mim and Salim Hariri},
  doi          = {10.1109/TAI.2025.3544173},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Multi-agent actor-critic generative AI for query resolution and analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KnowZRel: Common sense knowledge-based zero-shot
relationship retrieval for generalised scene graph generation.
<em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3544177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A scene graph is a key image representation in visual reasoning. The generalisability of Scene Graph Generation (SGG) methods is crucial for reliable reasoning and real-world applicability. However, imbalanced training datasets limit this, underrepresenting meaningful visual relationships. Current SGG methods using external knowledge sources face limitations due to these imbalances or restricted relationship coverage, impacting their reasoning and generalisation capabilities. We propose a novel neurosymbolic approach that integrates data-driven object detection with heterogeneous knowledge graph-based object refinement and zero-shot relationship retrieval, highlighting the loosely coupled synergy between neural and symbolic components. This combination addresses the limitations of imbalanced training datasets in scene graph generation and enables effective prediction of unseen visual relationships. Objects are detected using a region-based deep neural network and refined based on their positional and structural similarity, followed by retrieval of pairwise visual relationships using a heterogeneous knowledge graph. The redundant and irrelevant visual relationships are discarded based on the similarity of relationship labels and node embeddings. Finally, the visual relationships are interlinked to generate the scene graph. The employed heterogeneous knowledge graph combines diverse knowledge sources, offering rich common sense knowledge about objects and their interactions in the world. Our method, evaluated using the benchmark Visual Genome dataset and zero-shot recall (zR@K) metric, shows a 59.96% improvement over existing state-of-the-art methods, highlighting its effectiveness in generalised SGG. The object refinement step effectively improved the object detection performance by 57.1%. Additional evaluation using the GQA dataset confirms the cross-dataset generalisability of our method. We also compared various knowledge sources and embedding models to determine an optimal combination for zero-shot SGG. The source code is available at https://github.com/jaleedkhan/zsrr-sgg.},
  archive      = {J_TAI},
  author       = {M. Jaleed Khan and John G. Breslin and Edward Curry},
  doi          = {10.1109/TAI.2025.3544177},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {KnowZRel: Common sense knowledge-based zero-shot relationship retrieval for generalised scene graph generation},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LaBINet - an approach for seamlessly integrating new
advertisement into an existing scene. <em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3544595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Billboards in multimedia images are critical for capturing wide audiences through advertising. Currently, no open-source platform exists for automated billboard integration, which impacts industries such as filmmaking, advertising, and sports broadcasting. Effective detection and seamless integration of new advertisements into existing frames are essential for this process. This paper introduces LaBINet, a technique that leverages advanced deep learning methodologies to localize existing advertisements and utilizes image registration techniques for seamless integration of new ads. The process begins with generating a probabilistic map using AdSegNet to obtain transformed coordinates. Next, seamless integration is performed using the Poisson equation combined with Laplace matrices. To address the challenge of evaluating image quality in the absence of a reference image, we propose an evaluation method that correlates and statistically verifies subjective and objective scores. Experimental results demonstrate that our method outperforms existing techniques in integrating billboards under various lighting conditions, achieving strong subjective preference scores (76% to 95%) and low distortion scores (median values ranging from 21.817 to 22.529), indicating superior image quality.},
  archive      = {J_TAI},
  author       = {Sukriti Dhang and Mimi Zhang and Soumyabrata Dev},
  doi          = {10.1109/TAI.2025.3544595},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {LaBINet - an approach for seamlessly integrating new advertisement into an existing scene},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SecureLLAMA: Secure FPGAs using LLAMA large language models.
<em>TAI</em>, 1–14. (<a
href="https://doi.org/10.1109/TAI.2025.3544590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Field-Programmable Gate Arrays (FPGAs) are increasingly utilized in critical applications across sectors such as infrastructure, defense, and autonomous systems. However, the inherent flexibility of FPGAs introduces significant security vulnerabilities, particularly in the hardware description languages (HDLs) used to program them. This paper introduces SecureLLAMA, an enhanced version of the LLAMA2 model, specifically designed to detect and mitigate FPGA vulnerabilities. Leveraging a novel dataset “FPGAvul” which includes both real-world examples and synthetically generated vulnerabilities. Our dataset FPGAvul addresses vulnerabilities such as initialization errors, clock domain crossing issues, insecure state machines, resource sharing conflicts, and buffer overflows. SecureLLAMA demonstrates superior accuracy in identifying and addressing security flaws in FPGA configurations. Comprehensive evaluation shows that SecureLLAMA significantly improves the detection of vulnerabilities, providing a robust solution for securing FPGAs in embedded systems. The findings of this research have the potential to advance FPGA security practices, ensuring their safe integration in critical environments where reliability is essential.},
  archive      = {J_TAI},
  author       = {Mansour Alqarni and Akramul Azim},
  doi          = {10.1109/TAI.2025.3544590},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {SecureLLAMA: Secure FPGAs using LLAMA large language models},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pruning networks only using few-shot pre-training based on
gradient similarity frequency. <em>TAI</em>, 1–13. (<a
href="https://doi.org/10.1109/TAI.2025.3544582">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network pruning is a popular and promising approach aiming at reducing heavy networks to lightweight ones by removing redundancies. Most existing methods adopt a three-stage pipeline, including pre-training, pruning, and fine-tuning. However, it is time-consuming to train a large and redundant network in the pre-training process. In this work, we propose a new minimal pre-training pruning method, GSFP (Gradient Similarity Frequency-based Pruning), which prunes a given network only using few-shot pre-training before training. Instead of pre-training a fully-trained over-parameterized model, our method only uses one epoch to obtain the ranked list of convolution filters to be pruned according to their gradient similarity frequency, and determines the redundant convolution filters that should be removed. Then the obtained sparse network is trained in the standard way without the need to fine-tune the inherited weights from the full model. Finally, a series of experiments are conducted to verify the effectiveness on CIFAR10/100 and ImageNet. The results show that our method can achieve remarkable results on some popular networks, such as VGG, ResNet, and DenseNet. Importantly, the proposed pruning approach never requires pre-training the over-parameterized model, thus offering a promising prospect of application and spreading for limited computational resources.},
  archive      = {J_TAI},
  author       = {Haigen Hu and Huihuang Zhang and Qianwei Zhou and Tieming Chen},
  doi          = {10.1109/TAI.2025.3544582},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Pruning networks only using few-shot pre-training based on gradient similarity frequency},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing generalization of offline RL in data-limited
settings with heuristic rules. <em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3544971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ability to learn from static datasets, Offline Reinforcement Learning (RL) emerges as a compelling avenue for real-world applications. However, state-of-the-art offline RL algorithms perform suboptimally when confronted with limited data confined to specific regions within the state space. Performance degradation is attributed to the inability of offline RL algorithms to learn appropriate actions for rare or unseen observations. This paper proposes a heuristic rule-based regularization technique and adaptively refines the initial knowledge from heuristics to considerably boost performance in limited data with partially omitted states. The key insight is that the regularization term mitigates erroneous actions for sparse samples and unobserved states covered by domain knowledge. Empirical evaluations on standard offline RL datasets demonstrate a substantial average performance increase compared to ensemble of domain knowledge and existing offline RL algorithms operating on limited data.},
  archive      = {J_TAI},
  author       = {Briti Gangoppadhyay and Wang Zhao and Jia-Fong Yeh and Shingo Takamatsu},
  doi          = {10.1109/TAI.2025.3544971},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enhancing generalization of offline RL in data-limited settings with heuristic rules},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enabling efficient and interpretable cybersecurity reasoning
through hyperdimensional computing. <em>TAI</em>, 1–14. (<a
href="https://doi.org/10.1109/TAI.2025.3545394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs play a crucial role in addressing the complexities of cybersecurity, as the increasing frequency and sophistication of cyber threats pose significant challenges to traditional defense technologies. In this paper, we propose a novel reasoning model, called INCYSER, that is tailored for cybersecurity. By leveraging Hyperdimensional Computing (HDC) as a symbolic and transparent computational model, INCYSER offers efficient and interpretable reasoning capabilities, ensuring reliable and trustworthy outcomes. Our model combines embedding-based unsupervised learning and HDC-based graph representation learning to construct a general representation for cybersecurity knowledge graphs, enabling diverse tasks including reasoning and general graph operations. Experimental evaluations demonstrate the effectiveness and efficiency of INCYSER, surpassing state-of-the-art models in link prediction and triple classification tasks. Additionally, a comprehensive ablation study examines the impact of various hyperparameters, showcasing the versatility of INCYSER. This work contributes to advancing the field of cybersecurity by introducing an interpretable and representation-based reasoning model for cybersecurity knowledge graphs.},
  archive      = {J_TAI},
  author       = {Ali Zakeri and Hanning Chen and Narayan Srinivasa and Hugo Latapie and Mohsen Imani},
  doi          = {10.1109/TAI.2025.3545394},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enabling efficient and interpretable cybersecurity reasoning through hyperdimensional computing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ITF-VAE: Variational auto-encoder using interpretable
continuous time series features. <em>TAI</em>, 1–13. (<a
href="https://doi.org/10.1109/TAI.2025.3545396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms are driven by data. However, the quantity and quality of data in industries are limited due to multiple process constraints. Generating artificial data and performing a transfer learning task is a common solution to overcome these limitations. Recently, deep generative models have become one of the leading solutions for modeling a given source domain. The main hindrance to using those machine learning approaches is the lack of interpretability. Therefore, we present a novel variational autoencoder approach to generate time series data on a probabilistic latent feature representation and enhance interpretability within the generative model and the output trajectory. We sample selective and parameter values for certain continuous function candidates to assemble the synthetic time series. The sparse design of the generative model enables direct interpretability and matches an estimated posterior distribution of the detected components in the source domain. Through residual stacking, conditionality, and a mixture of prior distributions, we derive a stacked version of the evidence lower bound to learn our network. Tests on synthetic and real industrial datasets underline the performance and interpretability of our generative model. Depending on the model and function candidates, the user can define a trade-off between flexibility and interpretability. Overall, this work presents an innovative interpretable representation of the latent space and further developed evidence lower bound criterion driven by the designed architecture.},
  archive      = {J_TAI},
  author       = {H. Klopries and A. Schwung},
  doi          = {10.1109/TAI.2025.3545396},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {ITF-VAE: Variational auto-encoder using interpretable continuous time series features},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance analysis and design of a weighted personalized
quantum federated learning. <em>TAI</em>, 1–12. (<a
href="https://doi.org/10.1109/TAI.2025.3545393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in federated and quantum computing have improved data privacy and efficiency in distributed systems. Quantum Federated Learning (QFL), like its classical counterpart, Classic Federated Learning (CFL), struggles with challenges in heterogeneous environments. To address these, we propose wp-QFL, a weighted personalized approach with quantum federated averaging (qFedAvg), tackling non-IID data and local model drift. While CFL personalization has been well explored, its application to QFL remains underdeveloped due to inherent differences. The proposed wp-QFL fills this gap by adapting to data heterogeneity with weighted personalization and drift correction. The code implementation is available at https://github.com/s222416822/wpQFL.},
  archive      = {J_TAI},
  author       = {Dev Gurung and Shiva Raj Pokhrel},
  doi          = {10.1109/TAI.2025.3545393},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Performance analysis and design of a weighted personalized quantum federated learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedECE: Federated estimation of causal effect based on
causal graphical modelling. <em>TAI</em>, 1–15. (<a
href="https://doi.org/10.1109/TAI.2025.3545794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal effect estimation as a basic task in causal inference has been widely studied in past decades. In recent years, preserving data privacy has gained significant attention due to increasing incidents of data abuse and data leakage, however, most existing methods do not consider the problem of protecting data privacy when calculating causal effects. Thus in this paper, we propose a FedECE (Federated Estimation of Causal Effect) framework for causal effect estimation in a federated setting using causal graphical modelling, which comprises two modules: a federated causal structure learning (FedCSL) module and a federated causal effect (FedCE) module. We first instantiate the FedECE framework with a basic FedECE algorithm, called FedECE-B. FedECE-B presents a layer-wise cooperative optimization strategy to learn a global skeleton by the consideration of preserving data privacy. In addition, a distributed optimal consensus strategy for V-structure identification is proposed to orient edges in the learned global skeleton. To tackle the CPDAG problem in the learned causal structure, FedECE-B presents a progressively integrated multiset strategy for federated causal effect computation. To further improve the computational efficiency and accuracy of FedECE-B, we also propose the FedECE-L and FedECE-O algorithms. The extensive experiments validate the effectiveness of the proposed methods.},
  archive      = {J_TAI},
  author       = {Yongsheng Zhao and Kui Yu and Guodu Xiang and Xianjie Guo and Fuyuan Cao},
  doi          = {10.1109/TAI.2025.3545794},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {FedECE: Federated estimation of causal effect based on causal graphical modelling},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive operator selection for meta-heuristics: A survey.
<em>TAI</em>, 1–21. (<a
href="https://doi.org/10.1109/TAI.2025.3545792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Appropriate selection of search operators plays a critical role in meta-heuristic algorithm design. Adaptive selection of suitable operators to the characteristics of different optimization stages is an important task that owns promising potential to improve the performance of a meta-heuristic algorithm. A variety of adaptive operator selection methods have been proposed in last decades, from the machine learning and optimization communities. However, the existing studies have not been systematically reviewed so far. To fill the gap, this paper provides a comprehensive survey of adaptive operator selection for meta-heuristics. According to the information required for selection, adaptive operator selection methods are classified into two categories: (i) stateless methods and (ii) state-based methods. Each category is further summarized into several key components. The strategies of each component belonging to the two categories are reviewed respectively. The motivation, strengths and weaknesses of the proposed strategies are also discussed. Furthermore, studied meta-heuristics and optimization problems in the literature are summarized. The effects from the difference of meta-heuristics and problems to the specific design of methods are discussed, together with the guidance of selecting the suitable method in different application scenarios. At the end, emerging challenges that could guide further research are discussed.},
  archive      = {J_TAI},
  author       = {Jiyuan Pei and Yi Mei and Jialin Liu and Mengjie Zhang and Xin Yao},
  doi          = {10.1109/TAI.2025.3545792},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-21},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Adaptive operator selection for meta-heuristics: A survey},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensuring fairness in spectral clustering via disparate
impact-based graph construction. <em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3545800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering algorithms rely on graphs where edges are defined based on the similarity between the vertices (data points). The effectiveness and fairness of spectral clustering depend significantly on how the graph is constructed. While automated graph construction methods, which learn graphs from real-valued vector datasets, have demonstrated strong performance in the quality of clustering, fairness concerns still remain. In this work, we introduce a graph construction method that incorporates a new fairness definition—Edge Disparate Impact—into the edge relationships, aiming to produce a fair graph. This approach modifies the optimization process of automated graph construction to account for fairness, resulting in a more equitable graph. Extensive experiments were conducted to compare our method with the latest graph construction techniques and fair spectral clustering algorithms. The results prove that, by using a fair graph for spectral clustering, fairness is improved in the resulting clusters. We also demonstrate that our method outperforms baseline approaches in both fairness and the quality of clustering.},
  archive      = {J_TAI},
  author       = {Adithya K Moorthy and V. Vijaya Saradhi and Bhanu Prasad},
  doi          = {10.1109/TAI.2025.3545800},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Ensuring fairness in spectral clustering via disparate impact-based graph construction},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning models for realistic multicomponent signal
modulation classification. <em>TAI</em>, 1–10. (<a
href="https://doi.org/10.1109/TAI.2025.3546190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we study the application of three recent computer vision architectures to the classification of the modulation type of single- and dual-component signals, making emphasis on their usage in a realistic context by simultaneously considering a wide variety of modulations while varying the number of components. In order to do so, we first generate synthetic signal reception data of 15 modulation types, used for training and testing small variants of these models, chosen such that throughput is maximized and latency minimized, since we consider the context of a time-sensitive application. Given enough training compute, and in the single-component case, all convolutional models obtain an accuracy of 95% or more when signal-to-noise ratio (SNR) is at least 0 dB, and one variant obtains 90% accuracy at -3 dB. In the dual-component case, convolutional models manage upwards of 95% when SNR is at least 12 dB, and more than 90% when SNR is at least 6 dB. Finally, we also measure their throughput and latency as a function of batch size (important parameters for applications such as radar and communication systems), with a convolutional model variant yielding the highest throughput at 14432 samples per second. Based on the obtained results, our work paves the way towards the classification of modern complex modulation schemes and provides selection rules for the most appropriate algorithm depending on the performance feature to be optimized (such as throughput and size).},
  archive      = {J_TAI},
  author       = {Agustín M. Galante-Cerviño and Alberto Martínez-Fernández and Adrián Colomer and Valery Naranjo and Carlos García-Meca},
  doi          = {10.1109/TAI.2025.3546190},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-10},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Deep learning models for realistic multicomponent signal modulation classification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancement of robot dynamics learning by integrating
analytical models into deep neural networks: A data fusion perspective.
<em>TAI</em>, 1–11. (<a
href="https://doi.org/10.1109/TAI.2025.3544591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise modeling of dynamical systems can be crucial for engineering applications. Traditional analytical models often struggle when capturing real-world complexities due to challenges in system nonlinearity representation and model parameter determination. Data-driven models, such as deep neural networks (DNNs), offer better accuracy and generalization but require large quantities of high-quality data. The present paper introduces a novel method called the Synthesized-Data Neural Network (SDNN), which integrates analytical models, which represent physics, with DNNs to enhance the dynamic model. The main steps of the present method are as follows: The first three degrees of freedom (DOF) of a Kinova Gen3 Lite manipulator are formulated using the Euler-Lagrange equations of motion. The experimental data are recorded from the manipulator. Simulated data from the analytical model are combined with experimental data to train the neural network. The model’s performance is evaluated using the Mean Squared Error (MSE) in real-time experiments with the Kinova Gen3 Lite manipulator. Training datasets represent 14 trajectories, with the MSE calculated for four testing trajectories. The obtained results have led to the following conclusions: The SDNN model has shown improved performance in predicting joint torques when compared to the purely analytical model or the purely data-driven model. The SDNN, when trained with Synthesized data from 14 trajectories (SDNN-14) achieved the lowest MSE of 2.14, outperforming the analytical model (MSE of 2.81) and the neural network trained solely on experimental data (MSE of 3.05).},
  archive      = {J_TAI},
  author       = {Erfaan Rezvanfar and Jing Wang and Clarence W. de Silva},
  doi          = {10.1109/TAI.2025.3544591},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-11},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {Enhancement of robot dynamics learning by integrating analytical models into deep neural networks: A data fusion perspective},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GeoDCL: Weak geometrical distortion based contrastive
learning for fine-grained fashion image retrieval. <em>TAI</em>, 1–13.
(<a href="https://doi.org/10.1109/TAI.2025.3545791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses fine-grained fashion image retrieval (FIR), which aims at the detailed and precise retrieval of fashion items from extensive databases. Conventional fine-grained FIR methods design complex attention modules to enhance attribute-aware feature discrimination. However, they often ignore the multi-view characteristics of real-world fashion data, leading to diminished model accuracy. Furthermore, our empirical analysis revealed that the straightforward application of standard contrastive learning methods to fine-grained FIR often yields suboptimal results. To alleviate this issue, we propose a novel weak geometrical distortion-based contrastive learning (GeoDCL) strategy. Specifically, GeoDCL incorporates both a novel positive pair design and a novel contrastive loss. GeoDCL can be seamlessly integrated into state-of-the-art (SOTA) fine-grained FIR methods during the training stage to enhance performance during inference. When GeoDCL is applied, the model structures of SOTA methods require no modifications. Additionally, GeoDCL is not utilized during inference, ensuring no increase in inference time. Experiments on the FashionAI, DeepFashion, and Zappos50K datasets verified GeoDCL’s effectiveness in consistently improving SOTA models. In particular, GeoDCL drastically improved ASENet_V2 from 60.76% to 66.48% in mAP on the FashionAI dataset.},
  archive      = {J_TAI},
  author       = {Ling Xiao and Toshihiko Yamasaki},
  doi          = {10.1109/TAI.2025.3545791},
  journal      = {IEEE Transactions on Artificial Intelligence},
  month        = {2},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Artif. Intell.},
  title        = {GeoDCL: Weak geometrical distortion based contrastive learning for fine-grained fashion image retrieval},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
