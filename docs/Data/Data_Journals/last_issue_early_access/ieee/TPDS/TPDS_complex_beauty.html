<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TPDS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tpds---9">TPDS - 9</h2>
<ul>
<li><details>
<summary>
(2025). Flips: A flexible partitioning strategy near memory
processing architecture for recommendation system. <em>TPDS</em>, 1–14.
(<a href="https://doi.org/10.1109/TPDS.2025.3539534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation systems are massively deployed in production data centers. The memory-intensive embedding layers of recommendation systems are the crucial performance bottleneck, with operations manifesting as sparse memory lookups and simple reduction computations. Recent studies propose near-memory processing (NMP) architectures to speed up embedding operations by utilizing high internal memory bandwidth. However, these solutions typically employ a fixed vector partitioning strategy that fail to adapt to changes in data center deployment scenarios and lack practicality. We propose Flips, a flexible partitioning strategy NMP architecture that accelerates embedding layers. Flips supports more than ten partitioning strategies through hardware-software co-design. Novel hardware architectures and address mapping schemes are designed for the memory-side and host-side. We provide two approaches to determine the optimal partitioning strategy for each embedding table, enabling the architecture to accommodate changes in deployment scenarios. Importantly, Flips is decoupled from the NMP level and can utilize rank-level, bank-group-level and bank-level parallelism. In peer-level NMP evaluations, Flips outperforms state-of-the-art NMP solutions, RecNMP, TRiM, and ReCross by up to 4.0×, 4.1×, and 3.5×, respectively.},
  archive      = {J_TPDS},
  author       = {Yudi Qiu and Lingfei Lu and Shiyan Yi and Minge Jing and Xiaoyang Zeng and Yang Kong and Yibo Fan},
  doi          = {10.1109/TPDS.2025.3539534},
  journal      = {IEEE Transactions on Parallel and Distributed Systems},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Parallel Distrib. Syst.},
  title        = {Flips: A flexible partitioning strategy near memory processing architecture for recommendation system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task-aware service placement for distributed learning in
wireless edge networks. <em>TPDS</em>, 1–15. (<a
href="https://doi.org/10.1109/TPDS.2025.3539620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has been a driving force in the evolution of tremendous computing services and applications in the past decade. Traditional learning systems rely on centralized training and inference, which poses serious privacy and security concerns. To solve this problem, distributed learning over wireless edge networks (DLWENs) emerges as a trending solution and has attracted increasing research interests. In DLWENs, corresponding services need to be placed onto the edge servers to process the distributed tasks. Apparently, different placement of training services can significantly affect the performance of all distributed learning tasks. In this paper, we propose TASP, a task-aware service placement scheme for distributed learning in wireless edge networks. By carefully considering the structures (directed acyclic graphs) of the distributed learning tasks, the fine-grained task requests and inter-task dependencies are incorporated into the placement strategies to realize the parallel computation of learning services. We also exploit queuing theory to characterize the dynamics caused by task uncertainties. Extensive experiments based on the Alibaba ML dataset show that, compared to the state-of-the-art schemes, the proposed work reduces the overall delay of distributed learning tasks by 38.6% on average.},
  archive      = {J_TPDS},
  author       = {Rong Cong and Zhiwei Zhao and Mengfan Wang and Geyong Min and Jiangshu Liu and Jiwei Mo},
  doi          = {10.1109/TPDS.2025.3539620},
  journal      = {IEEE Transactions on Parallel and Distributed Systems},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Parallel Distrib. Syst.},
  title        = {Task-aware service placement for distributed learning in wireless edge networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy efficient and multi-resource optimization for virtual
machine placement by improving MOEA/d. <em>TPDS</em>, 1–15. (<a
href="https://doi.org/10.1109/TPDS.2025.3538525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive growth of cloud services, large-scale data centers are being built around the world to meet numerous and multifarious cloud computing services. The expansion of data centers over the past few years has been encountered substantial energy consumption. Virtual machine placement (VMP) has been heavily investigated as a way to provide flexible and scalable cloud services in an energy efficient way in data centers. However, due to a more complex and diversified tendency of applications, VMP suffer from waste of resources and bottlenecks for accommodating diversified VM&#39;s resource demands due to unbalanced utilization of multi-resource. To investigate joint optimization of power consumption and multi-dimensional resources utilization, in this paper, we present a bi-objective optimization model for virtual machine placement. Unfortunately, solving such a large-scale bi-objective model involves a challenge in the trade off between performance and time complexity.To this end, an improved decomposition-based multi-objective evolutionary (MOEA/D) algorithm based on $\varepsilon$-domination, termed $\varepsilon$-IMOEA/D-M2M is designed to provide solutions for the proposed optimization problem. Compared with both heuristics and evolutionary based algorithms, the performance evaluation shows that our proposal reduces power consumption and balances multidimensional resources while significantly reducing running time.},
  archive      = {J_TPDS},
  author       = {Wenting Wei and Huaxi Gu and Zhe Xiao and Yi Chen},
  doi          = {10.1109/TPDS.2025.3538525},
  journal      = {IEEE Transactions on Parallel and Distributed Systems},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Parallel Distrib. Syst.},
  title        = {Energy efficient and multi-resource optimization for virtual machine placement by improving MOEA/D},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A tail latency SLO guaranteed task scheduling scheme for
user-facing services. <em>TPDS</em>, 1–16. (<a
href="https://doi.org/10.1109/TPDS.2025.3542638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A primary design objective for user-facing services for cloud and edge computing is to maximize query throughput, while meeting query tail latency Service Level Objectives (SLOs) for individual queries. Unfortunately, the existing solutions fall short of achieving this design objective, which we argue, is largely attributed to the fact that they fail to take the query fanout explicitly into account. In this paper, we propose TailGuard based on a Tail-latency-SLO-and-Fanout-aware Earliest-Deadline-First Queuing policy (TF-EDFQ) for task queuing at individual task servers the query tasks are fanned out to. With the task pre-dequeuing time deadline for each task being derived based on both query tail latency SLO and query fanout, TailGuard takes an important first step towards achieving the design objective. A query admission control scheme is also developed to provide tail latency SLO guarantee in the presence of resource shortages. TailGuard is evaluated against First-In-First-Out (FIFO) task queuing, task PRIority Queuing (PRIQ) and Tail-latency-SLO-aware EDFQ (T-EDFQ) policies by both simulation and testing in the Amazon EC2 cloud. It is driven by three types of applications in the Tailbench benchmark suite, featuring web search, in-memory key-value store, and transactional database applications. The results demonstrate that TailGuard can significantly improve resource utilization (e.g., up to 80% compared to FIFO), while also meeting the targeted tail latency SLOs, as compared with the other three policies. TailGuard is also implemented and tested in a highly heterogeneous Sensing-$a$s-a-Service (SaS) testbed for a data sensing service, demonstrating performance gains of up to 33%. These results are consistent with both the simulation and Amazon EC2 results.},
  archive      = {J_TPDS},
  author       = {Zhijun Wang and Huiyang Li and Lin Sun and Todd Rosenkrantz and Hao Che and Hong Jiang},
  doi          = {10.1109/TPDS.2025.3542638},
  journal      = {IEEE Transactions on Parallel and Distributed Systems},
  month        = {2},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Parallel Distrib. Syst.},
  title        = {A tail latency SLO guaranteed task scheduling scheme for user-facing services},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spread+: Scalable model aggregation in federated learning
with non-IID data. <em>TPDS</em>, 1–16. (<a
href="https://doi.org/10.1109/TPDS.2025.3539738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) addresses privacy concerns by training models without sharing raw data, overcoming the limitations of traditional machine learning paradigms. However, the rise of smart applications has accentuated the heterogeneity in data and devices, which presents significant challenges for FL. In particular, data skewness among participants can compromise model accuracy, while diverse device capabilities lead to aggregation bottlenecks, causing severe model congestion. In this paper, we introduce Spread+, a hierarchical system that enhances FL by organizing clients into clusters and delegating model aggregation to edge devices, thus mitigating these challenges. Spread+ leverages hedonic coalition formation game to optimize customer organization and adaptive algorithms to regulate aggregation intervals within and across clusters. Moreover, it refines the aggregation algorithm to boost model accuracy. Our experiments demonstrate that Spread+ significantly alleviates the central aggregation bottleneck and surpasses mainstream benchmarks, achieving performance improvements of 49.58% over FAVG and 22.78% over Ring-allreduce.},
  archive      = {J_TPDS},
  author       = {Huanghuang Liang and Xin Yang and Xiaoming Han and Boan Liu and Chuang Hu and Dan Wang and Xiaobo Zhou and Dazhao Cheng},
  doi          = {10.1109/TPDS.2025.3539738},
  journal      = {IEEE Transactions on Parallel and Distributed Systems},
  month        = {2},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Parallel Distrib. Syst.},
  title        = {Spread+: Scalable model aggregation in federated learning with non-IID data},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Libfork: Portable continuation-stealing with stackless
coroutines. <em>TPDS</em>, 1–12. (<a
href="https://doi.org/10.1109/TPDS.2025.3543442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully-strict fork-join parallelism is a powerful model for shared-memory programming due to its optimal time-scaling and strong bounds on memory scaling. The latter is rarely achieved due to the difficulty of implementing continuationstealing in traditional High Performance Computing (HPC) languages – where it is often impossible without modifying the compiler or resorting to non-portable techniques. We demonstrate how stackless-coroutines (a new feature in C++20) can enable fullyportable continuation stealing and present libfork a wait-free fine-grained parallelism library, combining coroutines with userspace, geometric segmented-stacks. We show our approach is able to achieve optimal time/memory scaling, both theoretically and empirically, across a variety of benchmarks. Compared to openMP (libomp), libfork is on average 7.2× faster and consumes 10× less memory. Similarly, compared to Intel&#39;s TBB, libfork is on average 2.7× faster and consumes 6.2× less memory. Additionally, we introduce non-uniform memory access (NUMA) optimizations for schedulers that demonstrate performance matching busy-waiting schedulers},
  archive      = {J_TPDS},
  author       = {C.J. Williams and J.A. Elliott},
  doi          = {10.1109/TPDS.2025.3543442},
  journal      = {IEEE Transactions on Parallel and Distributed Systems},
  month        = {2},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Parallel Distrib. Syst.},
  title        = {Libfork: Portable continuation-stealing with stackless coroutines},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedTune-SGM: A stackelberg-driven personalized federated
learning strategy for edge networks. <em>TPDS</em>, 1–12. (<a
href="https://doi.org/10.1109/TPDS.2025.3543368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has emerged as a prominent solution for distributed learning environments, enabling collaborative model training without centralized data collection. However, FL faces significant challenges such as data heterogeneity and resource-constraint edge devices for model training and analysis, leading to accuracy degradation and bias in model performance. To address these critical issues, we propose a novel FL strategy named FedTune-SGM, designed to optimize model training in decentralized settings. In this strategy, a cloud-based model is initially trained and fine-tuned on the edge devices with additional layers tailored to the specific data characteristics. This fine-tuning process effectively mitigates the impact of data heterogeneity, enhancing the robustness and generalization capability of the model. FedTune-SGM employs a strategic weighting mechanism that ensures a balanced and equitable contribution from participating edge devices to prevent dominant influences from resource-rich devices and promote a fairer and more accurate aggregated model. Additionally, the proposed strategy integrates a Stackelberg Game model to foster an interactive and dynamic cloud-edge setup that motivates edge devices to invest more effort in model training and ensures the effectiveness of resource-constraint edge devices. Extensive experiments conducted on three diverse datasets highlight the superior performance of the proposed FedTune-SGM strategy compared to state-of-the-art FL techniques in terms of accuracy and robustness while meeting the critical challenges of data heterogeneity and resource limitations in FL environments. Through these innovations, FedTune-SGM paves the way for more reliable and efficient distributed learning systems, unlocking the full potential of FL in practical applications.},
  archive      = {J_TPDS},
  author       = {Neha Singh and Mainak Adhikari},
  doi          = {10.1109/TPDS.2025.3543368},
  journal      = {IEEE Transactions on Parallel and Distributed Systems},
  month        = {2},
  pages        = {1-12},
  shortjournal = {IEEE Trans. Parallel Distrib. Syst.},
  title        = {FedTune-SGM: A stackelberg-driven personalized federated learning strategy for edge networks},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Courier: A unified communication agent to support concurrent
flow scheduling in cluster computing. <em>TPDS</em>, 1–17. (<a
href="https://doi.org/10.1109/TPDS.2025.3543882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the pillars in cluster computing frameworks, coflow scheduling algorithms can effectively shorten the network transmission time of cluster computing jobs, thus reducing the job completion times and improving the execution performance. However, most of existing coflow scheduling algorithms failed to consider the influences of concurrent flows, which can degrade their performance under a massive number of concurrent flows. To fill the gap, we propose a unified communication agent named Courier to minimize the number of concurrent flows in cluster computing applications, which is compatible with the mainstream coflow scheduling approaches. To maintain the scheduling order given by the scheduling algorithms, Courier merges multiple flows between each pair of hosts into a unified flow, and determines its order based on that of origin flows. In addition, in order to adapt to various types of topologies, Courier introduces a control mechanism to adjust the number of flows while maintaining the scheduling order. Extensive large-scale trace-driven simulations have shown that Courier is compatible with existing scheduling algorithms, and outperforms the state-of-the-art approaches by about 30% under a variety of workloads and topologies.},
  archive      = {J_TPDS},
  author       = {Zhaochen Zhang and Xu Zhang and Zhaoxiang Bao and Liang Wei and Chaohong Tan and Wanchun Dou and Guihai Chen and Chen Tian},
  doi          = {10.1109/TPDS.2025.3543882},
  journal      = {IEEE Transactions on Parallel and Distributed Systems},
  month        = {2},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Parallel Distrib. Syst.},
  title        = {Courier: A unified communication agent to support concurrent flow scheduling in cluster computing},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IoT-dedup: Device relationship-based IoT data deduplication
scheme. <em>TPDS</em>, 1–14. (<a
href="https://doi.org/10.1109/TPDS.2025.3544315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cyclical and continuous working characteristics of Internet of Things (IoT) devices make a large amount of the same or similar data, which can significantly consume storage space. To solve this problem, various secure data deduplication schemes have been proposed. However, existing deduplication schemes only perform deduplication based on data similarity, ignoring the internal connection among devices, making the existing schemes not directly applicable to parallel and distributed scenarios like IoT. Furthermore, since secure data deduplication leads to multiple users sharing same encryption key, which may lead to security issues. To this end, we propose a device relationship-based IoT data deduplication scheme that fully considers the IoT data characteristics and devices internal connections. Specifically, we propose a device relationship prediction approach, which can obtain device collaborative relationships by clustering the topology of their communication graph, and classifies the data types based on device relationships to achieve data deduplication with different security levels. Then, we design a similarity-preserving encryption algorithm, so that the security level of encryption key is determined by the data type, ensuring the security of the deduplicated data. In addition, two different data deduplication methods, identical deduplication and similar deduplication, have been designed to meet the privacy requirement of different data types, improving the efficiency of deduplication while ensuring data privacy as much as possible. We evaluate the performance of our scheme using five real datasets, and the results show that our scheme has favorable results in terms of both deduplication performance and computational cost.},
  archive      = {J_TPDS},
  author       = {Yuan Gao and Liquan Chen and Jianchang Lai and Tianyi Wang and Xiaoming Wu and Shui Yu},
  doi          = {10.1109/TPDS.2025.3544315},
  journal      = {IEEE Transactions on Parallel and Distributed Systems},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Parallel Distrib. Syst.},
  title        = {IoT-dedup: Device relationship-based IoT data deduplication scheme},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
