<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TROB_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="trob---29">TROB - 29</h2>
<ul>
<li><details>
<summary>
(2025). Ambilateral activity recognition and continuous adaptation
with a powered knee-ankle prosthesis. <em>TROB</em>, 1–17. (<a
href="https://doi.org/10.1109/TRO.2025.3539206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For powered prosthetic legs to be viable in everyday situations, they require an activity classification system that is not only accurate but also straightforward to understand and use. However, incorporating the numerous activity modes in real-world ambulation often requires high-dimensional feature spaces and restrictions on the leg leading each transition. This paper addresses these challenges by delegating sit/stand transitions and variable-incline walking to the mid-level controller, effectively reducing the classification space to four states with easily distinguishable features. We implement simple heuristic rules for both prosthetic-led and intact-led (i.e., ambilateral) transitions, using lower-limb kinematic features, ground contact and inclination, and environmental distance from an ultrasonic sensor. Two transfemoral amputee subjects using a powered knee-ankle prosthesis demonstrated an ambilateral transition accuracy of 99.2% under both self-paced and rapid-paced/fatiguing conditions, with a 100% recovery rate due to backup logic or user-cued resets. The incline estimator enabled the prosthesis to continuously adapt between level and inclined surfaces without explicit classification. These results and an outdoor multi-terrain demonstration indicate that simple and straightforward transition logic can enable powered prosthetic legs to be used reliably across a broad array of daily activities.},
  archive      = {J_TROB},
  author       = {Shihao Cheng and Curt A. Laubscher and T. Kevin Best and Robert D. Gregg},
  doi          = {10.1109/TRO.2025.3539206},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Ambilateral activity recognition and continuous adaptation with a powered knee-ankle prosthesis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight powered hip exoskeleton with parallel
actuation for frontal and sagittal plane assistance. <em>TROB</em>,
1–17. (<a href="https://doi.org/10.1109/TRO.2025.3539172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wearable robots and powered exoskeletons may improve ambulation for millions of individuals with poor mobility. Powered exoskeletons primarily assist in the sagittal plane to improve walking efficiency and speed. However, individuals with poor mobility often have limited mediolateral balance, which requires torque generation in the frontal plane. Existing hip exoskeletons that assist in both the sagittal and frontal planes are too heavy and bulky for use in the real world. Here we present the kinematic model, mechatronic design, and benchtop and human testing of a powered hip exoskeleton with a unique parallel kinematic actuator. The exoskeleton is lightweight (5.3 kg), has a slim profile, and can generate 30 Nm and 20 Nm of torque during gait in the sagittal and frontal planes. The exoskeleton torque density is 5.7 Nm/kg—53% higher than previously possible with series kinematic design. Testing with five healthy subjects indicate that frontal plane torques applied during stance or swing can alter step width, while sagittal plane torque can assist with hip flexion and extension. A device with these characteristics may improve both gait economy and balance in the real world.},
  archive      = {J_TROB},
  author       = {Dante Archangeli and Brendon Ortolano and Rosemarie Murray and Lukas Gabert and Tommaso Lenzi},
  doi          = {10.1109/TRO.2025.3539172},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A lightweight powered hip exoskeleton with parallel actuation for frontal and sagittal plane assistance},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continuously shaping prioritized jacobian approach for
hierarchical optimal control with task priority transition.
<em>TROB</em>, 1–18. (<a
href="https://doi.org/10.1109/TRO.2025.3539204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical control is widely employed for redundant robots to manage multiple simultaneous tasks with distinct priority levels. A novel hierarchical optimal control strategy was recently introduced to achieve performance-optimal tracking under static and strict priority constraints. However, in complex and dynamic environments, robots must possess the capability to switch hierarchical behaviors online to adapt to varying operational scenarios. Existing continuous priority-switching methods often sacrifice hierarchical control performance and fail to asymptotically track the hierarchical optimal trajectory. In this paper, a continuously shaping prioritized Jacobian algorithm is proposed and integrated into a newly developed continuous hierarchical optimal control framework with priority transitions. This approach not only ensures optimal control performance but also facilitates continuous priority switching. The continuity and accuracy of the proposed algorithm, as well as the bounded stability of the closed-loop system state variables, are thoroughly analyzed in this work. The effectiveness of the proposed method is validated through simulations and experiments on the Franka Emika Panda robot.},
  archive      = {J_TROB},
  author       = {Yeqing Yuan and Weichao Sun},
  doi          = {10.1109/TRO.2025.3539204},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Continuously shaping prioritized jacobian approach for hierarchical optimal control with task priority transition},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation-aided policy tuning for black-box robot learning.
<em>TROB</em>, 1–17. (<a
href="https://doi.org/10.1109/TRO.2025.3539192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How can robots learn and adapt to new tasks and situations with little data? Systematic exploration and simulation are crucial tools for efficient robot learning. We present a novel black-box policy search algorithm focused on data-efficient policy improvements. The algorithm learns directly on the robot and treats simulation as an additional information source to speed up the learning process. At the core of the algorithm, a probabilistic model learns the dependence between the policy parameters and the robot learning objective not only by performing experiments on the robot, but also by leveraging data from a simulator. This substantially reduces interaction time with the robot. Using the model, we can guarantee improvements with high probability for each policy update, thereby facilitating fast, goal-oriented learning. We evaluate our algorithm on simulated fine-tuning tasks and demonstrate the data-efficiency of the proposed dual-information source optimization algorithm. In a real robot learning experiment, we show fast and successful task learning on a robot manipulator with the aid of an imperfect simulator.},
  archive      = {J_TROB},
  author       = {Shiming He and Alexander von Rohr and Dominik Baumann and Ji Xiang and Sebastian Trimpe},
  doi          = {10.1109/TRO.2025.3539192},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Simulation-aided policy tuning for black-box robot learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AirSLAM: An efficient and illumination-robust point-line
visual SLAM system. <em>TROB</em>, 1–20. (<a
href="https://doi.org/10.1109/TRO.2025.3539171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an efficient visual SLAM system designed to tackle both short-term and long-term illumination challenges. Our system adopts a hybrid approach that combines deep learning techniques for feature detection and matching with traditional backend optimization methods. Specifically, we propose a unified convolutional neural network (CNN) that simultaneously extracts keypoints and structural lines. These features are then associated, matched, triangulated, and optimized in a coupled manner. Additionally, we introduce a lightweight relocalization pipeline that reuses the built map, where keypoints, lines, and a structure graph are used to match the query frame with the map. To enhance the applicability of the proposed system to real-world robots, we deploy and accelerate the feature detection and matching networks using C++ and NVIDIA TensorRT. Extensive experiments conducted on various datasets demonstrate that our system outperforms other state-of-the-art visual SLAM systems in illumination-challenging environments. Efficiency evaluations show that our system can run at a rate of 73Hz on a PC and 40Hz on an embedded platform. Our implementation is open-sourced: https://github.com/sair-lab/AirSLAM.},
  archive      = {J_TROB},
  author       = {Kuan Xu and Yuefan Hao and Shenghai Yuan and Chen Wang and Lihua Xie},
  doi          = {10.1109/TRO.2025.3539171},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {AirSLAM: An efficient and illumination-robust point-line visual SLAM system},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model-based robust position control of an underactuated
dielectric elastomer soft robot. <em>TROB</em>, 1–18. (<a
href="https://doi.org/10.1109/TRO.2025.3539184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving accurate closed-loop position control of soft robots remains an ongoing research problem, due to the challenges posed by underactuation, elastic nonlinearities, and material creep. Although soft driving technologies relying on tendons and smart material transducers (e.g., dielectric elastomers, shape memory alloys) offer more ease of controllability compared to pneumatics, the corresponding controller design problem becomes even more challenging because of additional nonlinear effects. Those include a configuration-dependent actuation matrix, that stems from the kinematics of the actuation, and control input saturation, which is especially critical for smart material actuators. In this paper, we investigate for the first time the closed-loop position control of a soft robotic system driven by dielectric elastomer actuators. The objective is to regulate the robot state to a constant setpoint, accounting for the effects of open-loop instability, underactuation, control input saturation, and constant external disturbances. To achieve this goal, we propose a model-based feedback scheme which combines a stabilizing energy-shaping controller with a robustifying PI- like law. After presenting the general theory, a linear matrix inequalities algorithm is proposed to practically address the controller design in spite of strong model nonlinearities. Experimental validation conducted on a prototype of the soft robotic system confirms the effectiveness of the proposed control approach.},
  archive      = {J_TROB},
  author       = {Giovanni Soleti and Paolo Roberto Massenio and Julian Kunze and Gianluca Rizzello},
  doi          = {10.1109/TRO.2025.3539184},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Model-based robust position control of an underactuated dielectric elastomer soft robot},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Containment control of multi-robot systems with non-uniform
time-varying delays. <em>TROB</em>, 1–15. (<a
href="https://doi.org/10.1109/TRO.2025.3539195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The containment of multi-robot systems (MRSs) has a wide range of applications. However, time delays in communication among robots introduce difficulties to the system to accomplish containment. Additionally, the specific dynamics of robot models poses new nonlinear and nonholonomic challenges. To solve these problems, a containment control law is proposed first for double- integrator MRSs subject to non-uniform time-varying delays. In contrast to impractical uniform delays, non-uniform time-varying delays are considered more deeply from the perspective of the Laplace matrix in this paper. The stability is proved by the Lyapunov-Krasovskii function and linear matrix inequalities. The proposed control law is further refined into a dual-loop structure for multi-nonholonomic-mobile-robot systems (NHMRSs), addressing the problem of nonholonomic constraints. Specifically, the first loop decouples the control inputs in a finite time, and then the nonholonomic robot models are regarded as linear models, which facilitates the proof of system stability. The effectiveness of the above two control laws is validated through simulations and experiments. Under these containment control laws, followers in the system reach the convex hull formed by leaders and meet the convergence objective despite the constraint of non-uniform time-varying delays.},
  archive      = {J_TROB},
  author       = {Meng Ren and Wenhang Liu and Kun Song and Ling Shi and Zhenhua Xiong},
  doi          = {10.1109/TRO.2025.3539195},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-15},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Containment control of multi-robot systems with non-uniform time-varying delays},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RING#: PR-by-PE global localization with roto-translation
equivariant gram learning. <em>TROB</em>, 1–20. (<a
href="https://doi.org/10.1109/TRO.2025.3543267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global localization using onboard perception sensors, such as cameras and LiDARs, is crucial in autonomous driving and robotics applications when GPS signals are unreliable. Most approaches achieve global localization by sequential place recognition (PR) and pose estimation (PE). Some methods train separate models for each task, while others employ a single model with dual heads, trained jointly with separate task-specific losses. However, the accuracy of localization heavily depends on the success of place recognition, which often fails in scenarios with significant changes in viewpoint or environmental appearance. Consequently, this renders the final pose estimation of localization ineffective. To address this, we introduce a new paradigm, PR-by-PE localization, which bypasses the need for separate place recognition by directly deriving it from pose estimation. We propose RING#, an end-to-end PR-by-PE localization network that operates in the bird&#39;s-eye-view (BEV) space, compatible with both vision and LiDAR sensors. RING# incorporates a novel design that learns two equivariant representations from BEV features, enabling globally convergent and computationally efficient pose estimation. Comprehensive experiments on the NCLT and Oxford datasets show that RING# outperforms state-of-the-art methods in both vision and LiDAR modalities, validating the effectiveness of the proposed approach. The code is available at https://github.com/lus6-Jenny/RINGSharp.},
  archive      = {J_TROB},
  author       = {Sha Lu and Xuecheng Xu and Dongkun Zhang and Yuxuan Wu and Haojian Lu and Xieyuanli Chen and Rong Xiong and Yue Wang},
  doi          = {10.1109/TRO.2025.3543267},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {RING#: PR-by-PE global localization with roto-translation equivariant gram learning},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Position and orientation tracking control of a cable-driven
tensegrity continuum robot. <em>TROB</em>, 1–20. (<a
href="https://doi.org/10.1109/TRO.2025.3543292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trajectory tracking control of flexible continuum robots is challenging due to their inherent compliance and highly nonlinearity. Many related works exclude the control of the end&#39;s orientation, i.e., only the end&#39;s position is considered. In this paper, a differential-algebraic equations (DAEs) model-based instantaneous optimal control (IOC) framework for the end&#39;s position and orientation cooperative tracking of a cable-driven tensegrity continuum robot (TCR) is developed. Based on the tensegrity concept, a TCR is designed first as the control object, which can achieve multimode deformations such as bending, scoliosis, contraction, and the S- or J-shape. Then, the actuation of cables is introduced as the system kinematic constraints from the view of multibody dynamics, so that a control-oriented model of the TCR can be built by DAEs. Subsequently, the original continuous trajectory tracking problem is approximated for a series of IOC problems at each discrete time slot. Finally, considering the constraints of control input saturation, a linear complementarity problem (LCP) was derived for solving these IOC problems. The method provides an easy-to-implement and unified framework for addressing the trajectory tracking control issues of cable-driven continuum robots, which can improve the control performance of the position-only tracking controllers and exploit the TCR&#39;s advantages to handle more application scenarios. The advanced performance and potential applications of the proposed controller have been evaluated via several numerical simulations and experiments on the TCR prototype.},
  archive      = {J_TROB},
  author       = {Fei Li and Hao Yang and Guoying Gu and Yongqing Wang and Haijun Peng},
  doi          = {10.1109/TRO.2025.3543292},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Position and orientation tracking control of a cable-driven tensegrity continuum robot},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast ergodic search with kernel functions. <em>TROB</em>,
1–20. (<a href="https://doi.org/10.1109/TRO.2025.3543298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ergodic search enables optimal exploration of an information distribution with guaranteed asymptotic coverage of the search space. However, current methods typically have exponential computational complexity and are limited to Euclidean space. We introduce a computationally efficient ergodic search method. Our contributions are two-fold: First, we develop a kernel-based ergodic metric, generalizing it from Euclidean space to Lie groups. We prove this metric is consistent with the exact ergodic metric and ensures linear complexity. Second, we derive an iterative optimal control algorithm for trajectory optimization with the kernel metric. Numerical benchmarks show our method is two orders of magnitude faster than the state-of-the-art method. Finally, we demonstrate the proposed algorithm with a peg-in-hole insertion task. We formulate the problem as a coverage task in the space of SE(3) and use a 30-second-long human demonstration as the prior distribution for ergodic coverage. Ergodicity guarantees the asymptotic solution of the peg-in-hole problem so long as the solution resides within the prior information distribution, which is seen in the 100% success rate.},
  archive      = {J_TROB},
  author       = {Max Muchen Sun and Ayush Gaggar and Pete Trautman and Todd Murphey},
  doi          = {10.1109/TRO.2025.3543298},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Fast ergodic search with kernel functions},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From flies to robots: Inverted landing in small quadcopters
with dynamic perching. <em>TROB</em>, 1–18. (<a
href="https://doi.org/10.1109/TRO.2025.3543263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inverted landing is a routine behavior among a number of animal fliers. However, mastering this feat poses a considerable challenge for robotic fliers, especially to perform dynamic perching with rapid body rotations (or flips) and landing against gravity. Inverted landing in flies have suggested that optical flow senses are closely linked to the precise triggering and control of body flips that lead to a variety of successful landing behaviors. Building upon this knowledge, we aimed to replicate the flies&#39; landing behaviors in small quadcopters by developing a control policy general to arbitrary ceiling-approach conditions. First, we employed reinforcement learning in simulation to optimize discrete sensory-motor pairs across a broad spectrum of ceiling-approach velocities and directions. Next, we converted the sensory-motor pairs to a two-stage control policy in a continuous optical flow space augmented by ceiling distance measurement. The control policy consists of a first-stage Flip-Trigger Policy, which employs a one-class support vector machine, and a second-stage Flip-Action Policy, implemented as a feed-forward neural network. To transfer the inverted-landing policy to physical systems, we utilized domain randomization and system identification techniques for a zero-shot sim-to-real transfer with emulated optical flow using external motion tracking. As a result, we successfully achieved a range of robust inverted-landing behaviors in small quadcopters, emulating those observed in flies.},
  archive      = {J_TROB},
  author       = {Bryan Habas and Bo Cheng},
  doi          = {10.1109/TRO.2025.3543263},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Robot.},
  title        = {From flies to robots: Inverted landing in small quadcopters with dynamic perching},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). InvSlotGNN: Unsupervised discovery of viewpoint invariant
multi-object representations and visual dynamics. <em>TROB</em>, 1–13.
(<a href="https://doi.org/10.1109/TRO.2025.3543274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning multi-object dynamics purely from visual data is challenging due to the need for robust object representations that can be learned through robot interactions. In previous work [1] we introduced two novel architectures: SlotTransport for discovering object-centric representations from singleview RGB images, referred to as slots, and SlotGNN for predicting scene dynamics from singleview RGB images and robot interactions using the discovered slots. This paper introduces InvSlotGNN, a novel framework for learning multiview slot discovery and dynamics that are invariant to the camera viewpoint. First, we demonstrate that SlotTransport can be trained on multiview data such that a single model discovers temporally aligned, object-centric representations from a wide range of different camera angles. These slots bind to objects from various viewpoints, even under occlusion or absence. Next, we introduce InvSlotGNN, an extension of SlotGNN, that learns multi-object dynamics invariant to the camera angle and predicts the future state from observations taken by uncalibrated cameras. InvSlotGNN learns a graph representation of the scene using the slots from SlotTransport and performs relational and spatial reasoning to predict the future state of the scene for arbitrary viewpoints, conditioned on robot actions. We demonstrate the effectiveness of SlotTransport in learning multiview object-centric features that accurately encode visual and positional information. Furthermore, we highlight the accuracy of InvSlotGNN in downstream robotic tasks, including long-horizon prediction and multi-object rearrangement. Finally, with minimal real data, our framework robustly predicts slots and their dynamics in real-world multiview scenarios. Our project page: https://bit.ly/InvSlotGNN.},
  archive      = {J_TROB},
  author       = {Alireza Rezazadeh and Houjian Yu and Karthik Desingh and Changhyun Choi},
  doi          = {10.1109/TRO.2025.3543274},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-13},
  shortjournal = {IEEE Trans. Robot.},
  title        = {InvSlotGNN: Unsupervised discovery of viewpoint invariant multi-object representations and visual dynamics},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). System design of a soft underwater exosuit to reduce
metabolic cost across multiple aquatic movements during diving.
<em>TROB</em>, 1–17. (<a
href="https://doi.org/10.1109/TRO.2025.3543264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assisting underwater movements improves divers&#39; efficiency and reduces the risk of decompression sickness from physical activity. Although exoskeletons have been developed for numerous land-based scenarios, their application in underwater diving remains unexplored. This paper proposes a soft underwater lower-limb exosuit designed to assist three aquatic movements: flutter kick, breaststroke kick, and underwater walk. We presented the mechanical design of the exosuit that is capable of assisting bidirectional leg movements in full kicking/gait cycle, while ensuring natural leg mobility without impeding normal leg function. A cascade force integral controller is also designed to resolve issues related to uncontrollable states and stiffness variations within the system. To verify the assistive performance of the system, experiments were conducted with nine participants to assess how the proposed exosuit aids in reducing metabolic cost across various motion patterns and frequencies. The findings indicate that the underwater exosuit effectively reduces the air consumption rate by $29.77\pm 7.68$% during flutter kick, $25.70\pm 5.99$% during breaststroke kick, and $18.35\pm 4.53$% during underwater walk.},
  archive      = {J_TROB},
  author       = {Xiangyang Wang and Chunjie Chen and Jianquan Sun and Sida Du and Yue Ma and Xinyu Wu},
  doi          = {10.1109/TRO.2025.3543264},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {System design of a soft underwater exosuit to reduce metabolic cost across multiple aquatic movements during diving},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed multi-robot multi-target tracking using
heterogeneous limited-range sensors. <em>TROB</em>, 1–18. (<a
href="https://doi.org/10.1109/TRO.2025.3543303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utilizing heterogeneous mobile sensors to actively gather information improves adaptability and reliability in extended environments. This paper presents a cooperative multi-robot multi-target search and tracking framework aimed at enhancing the efficiency of the heterogeneous sensor network and, consequently, improving overall target tracking accuracy. The concept of normalized unused sensing capacity is introduced to quantify the information a sensor is currently gathering relative to its theoretical maximum. This measurement can be computed using entirely local information and is applicable to various sensor models, distinguishing it from previous literature on the subject. It is then utilized to develop a heuristics distributed coverage control strategy for a heterogeneous sensor network, adaptively balancing the workload based on each sensor&#39;s current unused capacity. The algorithm is validated through a series of ROS and MATLAB simulations, demonstrating superior results compared to standard approaches that do not account for heterogeneity or current usage rates.},
  archive      = {J_TROB},
  author       = {Jun Chen and Mohammed Abugurain and Philip Dames and Shinkyu Park},
  doi          = {10.1109/TRO.2025.3543303},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Distributed multi-robot multi-target tracking using heterogeneous limited-range sensors},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning rhythmic trajectories with geometric constraints
for laser-based skincare procedures. <em>TROB</em>, 1–17. (<a
href="https://doi.org/10.1109/TRO.2025.3543301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing deployment of robots has significantly enhanced the automation levels across a wide and diverse range of industries. This paper investigates the automation challenges of laser-based dermatology procedures in the beauty industry; This group of related manipulation tasks involves delivering energy from a cosmetic laser onto the skin with repetitive patterns. To automate this procedure, we propose to use a robotic manipulator and endow it with the dexterity of a skilled dermatology practitioner through a learning-fromdemonstration framework. To ensure that the cosmetic laser can properly deliver the energy onto the skin surface of an individual, we develop a novel structured prediction-based imitation learning algorithm with the merit of handling geometric constraints. Notably, our proposed algorithm effectively tackles the imitation challenges associated with quasi-periodic motions, a common feature of many laser-based cosmetic tasks. The conducted realworld experiments illustrate the performance of our robotic beautician in mimicking realistic dermatological procedures; Our new method is shown to not only replicate the rhythmic movements from the provided demonstrations but also to adapt the acquired skills to previously unseen scenarios and subjects.},
  archive      = {J_TROB},
  author       = {Anqing Duan and Wanli Liuchen and Jinsong Wu and Raffaello Camoriano and Lorenzo Rosasco and David Navarro-Alarcon},
  doi          = {10.1109/TRO.2025.3543301},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Learning rhythmic trajectories with geometric constraints for laser-based skincare procedures},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bio-inspired fast-moving and steerable insect-scale soft
aquatic surface robot. <em>TROB</em>, 1–16. (<a
href="https://doi.org/10.1109/TRO.2025.3543273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High speed and good trajectory controllability are two critical attributes of small artificial aquatic surface robots. Inspired by the moving mechanism of water striders, we herein propose insect-scale soft aquatic surface robots utilizing piezoelectric actuation coupled with asymmetric footpads. The aquatic surface robots move quickly without penetrating the water-air interface and utilize incoordinate propulsive force from asymmetric footpads to realize precise trajectory control. An ultrafast linear speed of 21.82 BL/s (24 cm/s) and a high angular speed of 303 °/s are achieved, which are advanced among small aquatic surface robots. We showcase agility and maneuverability by navigating through a water maze with a total route length of 88 cm in an actual driving time of 16.5 seconds. Moreover, proof-of-concept for search and rescue operations is demonstrated by using a robot to tow an on-water monitoring system to record a real-time video showing the “SOS” symbol. An untethered robot is also demonstrated to improve the practical potential. The design principles, operation mechanisms, and steering characteristics presented in this work provide fundamental guidelines for the development of future small aquatic surface robots.},
  archive      = {J_TROB},
  author       = {Dazhe Zhao and Renkun Wang and Sen Ding and Jiaze Shan and Xiao Guan and Zhaoyang Li and Jiaming Liang and Wenxi Gu and Bingpu Zhou and Iek Man Lei and Liwei Lin and Junwen Zhong},
  doi          = {10.1109/TRO.2025.3543273},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Bio-inspired fast-moving and steerable insect-scale soft aquatic surface robot},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A differential-mechanism-based leg configuration balances
the load and dynamic contribution for all actuators of the quadruped
robot. <em>TROB</em>, 1–18. (<a
href="https://doi.org/10.1109/TRO.2025.3543262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kinematic performance of a quadruped robot is determined by the mechanical structure. This paper presents a novel leg structure for legged robots that integrates a differential mechanism into the conventional design. This approach enables all actuators to be positioned within the robot&#39;s torso at fixed locations, significantly reducing the leg&#39;s inertia. Furthermore, the new structure introduces a parallel transmission system that balances motion and torque distribution among the joint actuators, effectively reducing torque peaks and enhancing the drive capability during dynamic motions. A family of configurations of differential leg structures is constructed, and their mappings to the classic Serial Leg structure is dissected in kinematic and mathematic. Simulations of various single-leg models are conducted to validate the performance of the new configuration under typical gait conditions. Subsequently, a leg prototype is designed, manufactured, and tested in experiments involving tasks such as trajectory tracking, weighted squats, and squat jumps. The development of a prototype quadruped robot featuring this novel leg structure is also presented.},
  archive      = {J_TROB},
  author       = {Zeyu Wang and Wenchuan Jia and Yi Sun and Tianxu Bao and Zihan Ding and Qi Chen},
  doi          = {10.1109/TRO.2025.3543262},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Robot.},
  title        = {A differential-mechanism-based leg configuration balances the load and dynamic contribution for all actuators of the quadruped robot},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analytical approach for dealing with explicit physical
constraints in excitation optimization problems of dynamic
identification. <em>TROB</em>, 1–20. (<a
href="https://doi.org/10.1109/TRO.2025.3543296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating optimal excitation trajectories is crucial for ensuring that the observation matrix is well-conditioned in robot dynamic identification. This task is a typical optimization problem involving explicit physical constraints defined by initial conditions (zero initial joint velocity and acceleration) and physical limits (joint position, velocity, and acceleration within specified bounds). Physical constraints complicate problem-solving, necessitating the use of heuristic or gradient-based iteration methods. Despite extensive study of this problem over many years, the success rate of finding feasible solutions that do not violate physical constraints within a limited number of iteration steps is lower than desired, and two major challenges remain: 1) a low success rate and 2) high time consumption, which adversely affect practical applications. This article presents an analytical approach to address these physical constraints in optimization. Feasible solutions are ensured through a deterministic calculation of the Fourier series-based parameterization rather than relying on iterative searches. Specifically, initial conditions are met by assigning offsets directly, while scaling and central-translation operations ensure adherence to physical limits. Our approach achieves a 100% success rate in generating physically executable excitation trajectories. Extensive experiments indicate that our approach has improved optimization efficiency by an order of magnitude compared to available methods, while delivering excellent excitation performance. For practitioners, our method renders excitation optimization a viable approach for time-critical payload identification tasks.},
  archive      = {J_TROB},
  author       = {Shifeng Huang and Fan Li and Xing Zhou and Molong Duan},
  doi          = {10.1109/TRO.2025.3543296},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {An analytical approach for dealing with explicit physical constraints in excitation optimization problems of dynamic identification},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AAGE: Air-assisted ground robotic autonomous exploration in
large-scale unknown environments. <em>TROB</em>, 1–20. (<a
href="https://doi.org/10.1109/TRO.2025.3543275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents an air-assisted ground robotic autonomous exploration framework (AAGE), which leverages the high mobility and wide aerial perspective of Unmanned Aerial Vehicles (UAVs) to assist Unmanned Ground Vehicles (UGVs) in detailed exploration, enhancing exploration efficiency and improving the quality of point cloud collection in regions of interest (RoIs) in large-scale, unknown environments. In this framework, the UAV, equipped with an onboard RGB camera, rapidly surveys large unknown areas and generates a Bird&#39;s Eye View (BEV) to identify critical zones for UGV exploration. With prior information about the unexplored area&#39;s outline from the real-time shared BEV, the UGV can carry out more efficient and informed exploration from a global perspective. To maximize the utility of this prior information and optimize point cloud collection, a hierarchical exploration strategy and an attention mechanism are incorporated to guide the UGV&#39;s focus toward areas requiring detailed mapping, rather than broad, featureless regions. Real-world experiments validate the effectiveness of the framework, demonstrating significant improvements in exploration efficiency and point cloud collection compared to state-of-the-art methods. The results further show that even with a coarse BEV, the UGV&#39;s exploration efficiency is greatly enhanced.},
  archive      = {J_TROB},
  author       = {Lanxiang Zheng and Mingxin Wei and Ruidong Mei and Kai Xu and Junlong Huang and Hui Cheng},
  doi          = {10.1109/TRO.2025.3543275},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {AAGE: Air-assisted ground robotic autonomous exploration in large-scale unknown environments},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). COLA: COarse-LAbel multi-source LiDAR semantic segmentation
for autonomous driving. <em>TROB</em>, 1–14. (<a
href="https://doi.org/10.1109/TRO.2025.3543302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDAR semantic segmentation for autonomous driving has been a growing field of interest in recent years. Datasets and methods have appeared and expanded very quickly, but methods have not been updated to exploit this new data availability and rely on the same classical datasets. Different ways of performing LIDAR semantic segmentation training and inference can be divided into several subfields, which include the following: domain generalization, source-to-source segmentation, and pre-training. In this work, we aim to improve results in all of these subfields with the novel approach of multi-source training. Multi-source training relies on the availability of various datasets at training time. To overcome the common obstacles in multi-source training, we introduce the coarse labels and call the newly created multi-source dataset COLA. We propose three applications of this new dataset that display systematic improvement over single-source strategies: COLA-DG for domain generalization (+10%), COLA-S2S for source-to-source segmentation (+5.3%), and COLA-PT for pre-training (+12%). We demonstrate that multi-source approaches bring systematic improvement over single-source approaches.},
  archive      = {J_TROB},
  author       = {Jules Sanchez and Jean-Emmanuel Deschaud and François Goulette},
  doi          = {10.1109/TRO.2025.3543302},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Robot.},
  title        = {COLA: COarse-LAbel multi-source LiDAR semantic segmentation for autonomous driving},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tactile-reactive roller grasper. <em>TROB</em>, 1–18. (<a
href="https://doi.org/10.1109/TRO.2025.3543324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manipulation of objects within a robot&#39;s hand is one of the most important challenges in achieving robot dexterity. To address this challenge, Roller Graspers use steerable rolling fingertips. The fingertips impart motions and exert forces to achieve six degree of freedom mobility and closed-loop grasp force control. The design reported here uses image processing from cameras placed inside steerable compliant rollers to track contact conditions and locations. Integration of this data into a controller enables a variety of robust in-hand manipulation capabilities. We demonstrate that the same information can be used to reconstruct object shape. In addition, we show that by converting in-hand manipulation from a discontinuous process, with fingers frequently attaching and detaching from the object surface, to a continuous process, we can implement a convergent control loop that minimizes errors that otherwise accumulate during large object motions. The difference is apparent when comparing the results of an object rotation using a discontinuous finger-gaiting approach, as would be required without rolling fingertips, to the results obtained with continuous rolling. The results suggest that hybrid rolling fingertip and finger-gaiting approaches to manipulation may be a promising future research direction.},
  archive      = {J_TROB},
  author       = {Shenli Yuan and Shaoxiong Wang and Radhen Patel and Megha Tippur and Connor L. Yako and Mark R. Cutkosky and Edward Adelson and Kenneth Salisbury},
  doi          = {10.1109/TRO.2025.3543324},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-18},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Tactile-reactive roller grasper},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultrasound image-based average q-learning control of
magnetic microrobots. <em>TROB</em>, 1–14. (<a
href="https://doi.org/10.1109/TRO.2025.3543261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic microrobots have garnered significant attention and hold great potential for biomedical research applications. However, achieving precise manipulation in vivo poses significant challenges, particularly in medical image-based real-time feedback control, because it is difficult for a visual camera to track the motion of magnetic microrobots inside the body in biomedical applications. To realize the precise control of magnetic microrobots, it is also necessary to design and implement a simple and powerful control method. This approach allows for avoiding resource-intensive and complex control strategies. In this paper, we present a learning-based real-time control method utilizing ultrasound images. Inspired by the ADboost concept, we use a reinforcement learning approach to integrate two simple control methods: a Proportional-Integral-Derivative controller and a guiding vector field controller. We develop a novel Q-learning method called average Q-learning that incorporates average operation and n-step bootstraps. Its primary objective is to dynamically adjust the outputs of the different simple controllers. While each controller individually offers a straightforward solution, their integration contributes to a powerful control approach. To demonstrate its scalability, a non-smooth path is utilized to investigate the integration performance of three simple controllers. In addition, we enhance a classic segmentation module, U-net, by incorporating an atrous spatial pyramid pooling module. To validate the effectiveness of the proposed control method, we conduct simulations and experiments using various planar paths. The quantitative analysis of the results demonstrates the efficacy of our approach in achieving precise manipulation, leveraging real-time control based on medical images for magnetic microrobots. Overall, this study provides a preliminary investigation into the field of medical image-based precise manipulation of magnetic microrobots in vivo applications.},
  archive      = {J_TROB},
  author       = {Jia Liu and Guoyao Ma and Shixiong Fu and Chenyang Huang and Xinyu Wu and Tiantian Xu},
  doi          = {10.1109/TRO.2025.3543261},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-14},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Ultrasound image-based average Q-learning control of magnetic microrobots},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CliReg: Clique-based robust point cloud registration.
<em>TROB</em>, 1–20. (<a
href="https://doi.org/10.1109/TRO.2025.3542954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a branch-and-bound algorithm for robust rigid registration of two point clouds in the presence of a large number of outlier correspondences. For this purpose, we consider a maximum consensus formulation of the registration problem and reformulate it as a (large) maximal clique search in a correspondence graph, where a clique represents a complete rigid transformation. Specifically, we use a maximum clique algorithm to enumerate large maximal cliques and a fitness procedure that evaluates each clique by solving a least-squares optimization problem. The main advantages of our approach are $i)$ it is possible to exploit the cutting-edge optimization techniques employed by current exact maximum clique algorithms, such as partial maximum satisfiability-based bounds, branching by partitioning or the use of bitstrings, etc.; $ii)$ the correspondence graphs are expected to be sparse in real problems (confirmed empirically in our tests), and, consequently, the maximum clique problem is expected to be easy; $iii)$ it is possible to have a good control of suboptimality with a k-nearest neighbor analysis that determines the size of the correspondence graph as a function of $k$. The new algorithm is called CliReg and has been implemented in C++. To evaluate CliReg, we have carried out extensive tests both on synthetic and real public datasets. The results show that CliReg clearly dominates the state of the art (e.g., RANSAC, FGR, and TEASER++) in terms of robustness, with a running time comparable to TEASER++ and RANSAC. In addition, we have implemented a fast variant called CliRegMutual that performs similarly to the fastest heuristic FGR.},
  archive      = {J_TROB},
  author       = {Javier Laserna and Pablo San Segundo and David Álvarez},
  doi          = {10.1109/TRO.2025.3542954},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CliReg: Clique-based robust point cloud registration},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remote robotic palpation with depth-vision-driven
autonomous-dimensionality-reduction shared control. <em>TROB</em>, 1–16.
(<a href="https://doi.org/10.1109/TRO.2025.3544104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teleoperated medical robots have the potential to revolutionize healthcare. However, when developing systems for tasks like remote palpation, state-of-the-art literature still uses test phantoms of oversimplified geometries, due to the complexity of the required mechanical robot-patient interaction. In reality, human bodies have complex 3D shapes and require fine-tuning of all 6 manipulator&#39;s degrees of freedom, controlled by the user. In this paper, we argue that the implementation of depth-vision-driven autonomous dimensionality-reduction (DVD ADR) shared control can greatly improve the users&#39; performance. The proposed control method keeps the user in control of the end-effector&#39;s position, while automatically adjusting its orientation in order to maintain the tactile sensor normal to the phantom&#39;s surface. A depth camera and a computer vision algorithm are used to infer the phantom&#39;s shape and achieve DVD ADR shared control. Experimental results showcase how this leads to statistically significant performance improvement. Not only were the participants able to achieve more precise palpations, with up to $29.5\%$ and $22.4\%$ more accuracy in position and orientation, respectively, but the DVD ADR shared control allowed them to achieve a $8.8\%$ better detection accuracy while needing $13.8\%$ less time. The above-mentioned results are all tested for statistical significance and achieved a p-value lower than 0.05.},
  archive      = {J_TROB},
  author       = {Jingwen Zhao and Leone Costi and Luca Scimeca and Fumiya Iida},
  doi          = {10.1109/TRO.2025.3544104},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Remote robotic palpation with depth-vision-driven autonomous-dimensionality-reduction shared control},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relative localizability and localization for multi-robot
systems. <em>TROB</em>, 1–19. (<a
href="https://doi.org/10.1109/TRO.2025.3544103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inter-robot relative positions are crucial for executing various multi-robot missions, such as formation maneuvering and collaborative inspection. However, the current sensing technology only provides part of relative position information, such as inter-robot distances, bearings and angles. This prompts the study of determining inter-robot relative positions, i.e., relative localization, from these partial measurements. Based on the existing results of static networks&#39; localizability and mobile networks&#39; relative localization, we propose a novel concept, relative localizability to describe whether a multi-robot system is relatively localizable. Given each robot&#39;s self-displacement measurements and inter-robot partial measurements in $d$ ($d\leq 4$) sampling instants, we show that a multi-robot system&#39;s relative localization can be achieved in a purely algebraic and distributed manner, in which the multi-robot system is said to be $d$-step relatively localizable. To make the results more general, we consider that a) the multi-robot system consists of landmarks, leaders and followers, b) and the inter-robot measurements can be distances, bearings or angles. When robots&#39; coordinate frames have different orientations, we show that the given local measurements can be used to determine robots&#39; relative positions and their coordinate frames&#39; relative orientations simultaneously. Simulations and experiments of relative localization for ground robots are conducted to validate the obtained results.},
  archive      = {J_TROB},
  author       = {Liangming Chen and Chenyang Liang and Shenghai Yuan and Muqing Cao and Lihua Xie},
  doi          = {10.1109/TRO.2025.3544103},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-19},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Relative localizability and localization for multi-robot systems},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robotic haptic exploration of object shape with autonomous
symmetry detection. <em>TROB</em>, 1–16. (<a
href="https://doi.org/10.1109/TRO.2025.3544113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haptic robotic exploration aims to control the movements of a robot with the objective of touching an object and retrieving physical information about it. In this work, we present an innovative exploration strategy to simultaneously detect symmetries in a 3D object and use this information to enhance shape estimation. This is achieved by leveraging a novel formulation of Gaussian Process models that allows the modeling of symmetric surfaces. Our procedure does not assume any prior knowledge about the object, neither about its shape nor about the presence and type of symmetry, necessitating only an approximate estimate of the size and boundaries (bounding box). We report experimental results both in simulation and in the real world, showing that using symmetric models leads to a reduction in shape estimation error, exploration time, and in the number of physical contacts performed by a robot when exploring objects that have symmetries.},
  archive      = {J_TROB},
  author       = {Aramis Augusto Bonzini and Lucia Seminara and Simone Macciò and Alessandro Carfì and Lorenzo Jamone},
  doi          = {10.1109/TRO.2025.3544113},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-16},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Robotic haptic exploration of object shape with autonomous symmetry detection},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic path planning for wheel-legged rover in dense
environment based on extended MDP and configuration topology analysis.
<em>TROB</em>, 1–20. (<a
href="https://doi.org/10.1109/TRO.2025.3546789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheel-legged planetary rovers possess superb locomotion capabilities. This paper combines an offline, predefined motion planning library with online path planning, integrating energy consumption and probabilistic aspects of the robotic system. The primary focus is on addressing the planning challenges in dense environments, where the distance between any adjacent obstacles is smaller than the width of the prototype. Therefore, it is necessary to consider the interaction between the prototype and the environment. Firstly, the GF (Generalized Function) set theory and configuration topology theory are utilized to mathematically describe the motions of multi-limbed systems. Based on the representation, an offline planning library is established. Secondly, the MDP (Markov Decision Processes)- based path planning method is extended by incorporating the platform&#39;s geometry and locomotion capabilities. The concept of “LTR (Limb Travel Relevant) nodes” is introduced. To address the numerous iteration problem, the Informed VI (Informed Value Iteration) algorithm is proposed. Thirdly, a multi-layered map is evaluated to further enhance computational efficiency. Finally, the proposed algorithm is implemented on the TAWL (Terrain Adaptive Wheel-Legged) rover. Experimental results demonstrate that the proposed algorithm is capable of finding the optimal path with high computational efficiency, and it exhibits excellent adaptability on non-uniform maps},
  archive      = {J_TROB},
  author       = {Bike Zhu and Jun He and Zhicheng Yuan and Feng Gao},
  doi          = {10.1109/TRO.2025.3546789},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Probabilistic path planning for wheel-legged rover in dense environment based on extended MDP and configuration topology analysis},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CMRNext: Camera to LiDAR matching in the wild for
localization and extrinsic calibration. <em>TROB</em>, 1–20. (<a
href="https://doi.org/10.1109/TRO.2025.3546784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LiDARs are widely used for mapping and localization in dynamic environments. However, their high cost limits their widespread adoption. On the other hand, monocular localization in LiDAR maps using inexpensive cameras is a cost-effective alternative for large-scale deployment. Nevertheless, most existing approaches struggle to generalize to new sensor setups and environments, requiring retraining or fine-tuning. In this paper, we present CMRNext, a novel approach for camera-LIDAR matching that is independent of sensor-specific parameters, generalizable, and can be used in the wild for monocular localization in LiDAR maps and camera-LiDAR extrinsic calibration. CMRNext exploits recent advances in deep neural networks for matching cross-modal data and standard geometric techniques for robust pose estimation. We reformulate the point-pixel matching problem as an optical flow estimation problem and solve the Perspective-n-Point problem based on the resulting correspondences to find the relative pose between the camera and the LiDAR point cloud. We extensively evaluate CMRNext on six different robotic platforms, including three publicly available datasets and three in-house robots. Our experimental evaluations demonstrate that CMRNext outperforms existing approaches on both tasks and effectively generalizes to previously unseen environments and sensor setups in a zero-shot manner. We make the code and pre-trained models publicly available at http://cmrnext.cs.uni-freiburg.de.},
  archive      = {J_TROB},
  author       = {Daniele Cattaneo and Abhinav Valada},
  doi          = {10.1109/TRO.2025.3546784},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-20},
  shortjournal = {IEEE Trans. Robot.},
  title        = {CMRNext: Camera to LiDAR matching in the wild for localization and extrinsic calibration},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultimate passivity: Balancing performance and stability in
physical human-robot interaction. <em>TROB</em>, 1–17. (<a
href="https://doi.org/10.1109/TRO.2025.3546856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haptic interaction is critical in physical Human-Robot Interaction (pHRI), given its wide applications in manufacturing, medical and healthcare, and various industry tasks. A stable haptic interface is always needed while the human operator interacts with the robot. Passivity-based approaches have been widely utilised in the control design as a sufficient condition for stability. However, it is a conservative approach which therefore sacrifices performance to maintain stability. This paper proposes a novel concept to characterise an ultimately passive system, which can achieve the boundedness of the energy in the steady-state. A so-called Ultimately Passive Controller (UPC) is then proposed. This algorithm switches the system between a nominal mode for keeping desired performance and a conservative mode when needed to remain stable. An experimental evaluation on two robotic systems, one admittance-based and one impedance-based, demonstrates the potential interest of the proposed framework compared to existing approaches. The results demonstrate the possibility of UPC in finding a more aggressive trade-off between haptic performance and system stability, while still providing a stability guarantee.},
  archive      = {J_TROB},
  author       = {Xinliang Guo and Zheyu Liu and Vincent Crocher and Ying Tan and Denny Oetomo and Arno H. A. Stienen},
  doi          = {10.1109/TRO.2025.3546856},
  journal      = {IEEE Transactions on Robotics},
  month        = {2},
  pages        = {1-17},
  shortjournal = {IEEE Trans. Robot.},
  title        = {Ultimate passivity: Balancing performance and stability in physical human-robot interaction},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
