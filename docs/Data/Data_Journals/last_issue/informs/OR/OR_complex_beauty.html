<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>OR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="or---29">OR - 29</h2>
<ul>
<li><details>
<summary>
(2025). On the optimality of greedy policies in dynamic matching.
<em>OR</em>, <em>73</em>(1), 560–582. (<a
href="https://doi.org/10.1287/opre.2021.0596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study centralized dynamic matching markets with finitely many agent types and heterogeneous match values. A network topology describes the pairs of agent types that can form a match and the value generated from each match. A matching policy is hindsight optimal if the policy can (nearly) maximize the total value simultaneously at all times. We find that suitably designed greedy policies are hindsight optimal in two-way matching networks. This implies that there is essentially no positive externality from having agents waiting to form future matches. We first show that the greedy longest-queue policy with a minor variation is hindsight optimal. Importantly, the policy is greedy relative to a residual network, which includes only nonredundant matches with respect to the static optimal matching rates. Moreover, when the residual network is acyclic (e.g., as in two-sided networks), we prescribe a greedy static priority policy that is also hindsight optimal. The priority order of this policy is robust to arrival rate perturbations that do not alter the residual network. Hindsight optimality is closely related to the lengths of type-specific queues. Queue lengths cannot be smaller (in expectation) than of the order of ϵ − 1 , where ϵ is the general position gap that quantifies the stability in the network. The greedy longest-queue policy achieves this lower bound. Funding: This work was supported by National Science Foundation (CMMI-2010940) and U.S. Department of Defense (STTR A18B-T007).},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0596},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {560-582},
  shortjournal = {Oper. Res.},
  title        = {On the optimality of greedy policies in dynamic matching},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shape-constrained regression using sum of squares
polynomials. <em>OR</em>, <em>73</em>(1), 543–559. (<a
href="https://doi.org/10.1287/opre.2021.0383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a hierarchy of semidefinite programs (SDPs) for the problem of fitting a shape-constrained (multivariate) polynomial to noisy evaluations of an unknown shape-constrained function. These shape constraints include convexity or monotonicity over a box. We show that polynomial functions that are optimal to any fixed level of our hierarchy form a consistent estimator of the underlying shape-constrained function. As a by-product of the proof, we establish that sum of squares-convex polynomials are dense in the set of polynomials that are convex over an arbitrary box. A similar sum-of-squares-type density result is established for monotone polynomials. In addition, we classify the complexity of convex and monotone polynomial regression as a function of the degree of the polynomial regressor. Whereas our results show NP-hardness of these problems for degree three or larger, we can check numerically that our SDP-based regressors often achieve a similar training error at low levels of the hierarchy. Finally, on the computational side, we present an empirical comparison of our SDP-based convex regressors with the convex least squares estimator introduced in Hildreth [ Hildreth C (1954) Point estimates of ordinates of concave functions. J. Amer. Statist. Assoc. 49(267):598–619] and Holloway [ Holloway CA (1979) On the estimation of convex functions. Oper. Res. 27(2):401–407] and show that our regressor is valuable in settings in which the number of data points is large and the dimension is relatively small. We demonstrate the performance of our regressor for the problem of computing optimal transport maps in a color transfer task and that of estimating the optimal value function of a conic program. A real-time application of the latter problem to inventory management contract negotiation is presented. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2021.0383 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0383},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {543-559},
  shortjournal = {Oper. Res.},
  title        = {Shape-constrained regression using sum of squares polynomials},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal routing under demand surges: The value of future
arrival rates. <em>OR</em>, <em>73</em>(1), 510–542. (<a
href="https://doi.org/10.1287/opre.2022.0282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the growing availability of advanced demand forecast tools, we study how to use future demand information in designing routing strategies in queueing systems under demand surges. We consider a parallel server system operating in a nonstationary environment with general time-varying arrival rates. Servers are cross-trained to help nonprimary customer classes during demand surges. However, such flexibility comes with various operational costs, such as a loss of efficiency and inconvenience in coordination. We characterize how to incorporate the future arrival information into the routing policy to balance the tradeoff between various costs and quantify the benefit of doing so. Based on transient fluid control analysis, we develop a two-stage index-based look-ahead policy that explicitly takes the overflow costs and future arrival rates into account. The policy has an interpretable structure, is easy to implement and is adaptive when the future arrival information is inaccurate. In the special case of the N-model, we prove that this policy is asymptotically optimal even in the presence of certain prediction errors in the demand forecast. We substantiate our theoretical analysis with extensive numerical experiments, showing that our policy achieves superior performance compared with other benchmark policies (i) in complicated parallel server systems and (ii) when the demand forecast is imperfect with various forms of prediction errors. Funding: This work was supported by the National Science Foundation Civil, Mechanical, and Manufacturing Innovation [Grant 1944209]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2022.0282 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0282},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {510-542},
  shortjournal = {Oper. Res.},
  title        = {Optimal routing under demand surges: The value of future arrival rates},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal routing to parallel servers in heavy traffic.
<em>OR</em>, <em>73</em>(1), 483–509. (<a
href="https://doi.org/10.1287/opre.2022.0055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a system with heterogeneous parallel servers, each with an infinite waiting room. Upon arrival, a job is routed to the queue of one of the servers, possibly depending on the dynamic state information such as the real-time queue lengths, the arrival, and service history of jobs. The objective is to find the routing policy that best uses the available state information to minimize the expected stationary queue length. In this paper, we establish the diffusion limit for the round-robin policy (respectively, arrival-chasing policy, service-chasing policy), and show that with properly chosen parameters, it achieves the optimal performance asymptotically within the class of admissible policies that require no state information (respectively, require arrival history, service history). Like the jointhe-shortest-queue and the balanced routing policies that use real-time queue length information, the optimal service-chasing policy is also asymptotically optimal over all admissible policies. Further analysis of the diffusion limits yields a number of insights into the performance of these routing policies and reveals the value of various state information. We numerically demonstrate the effectiveness of the estimators derived from the diffusion limits for the policies being studied and obtain interesting observations. We also address the problem of interchange of limits under the aforementioned policies, which justifies the stationary performance of the diffusion limit as a valid approximation to that of the original system under respective policies. Methodologically, this study contributes to the application of the BIGSTEP method for constructing control policy to optimize stationary performance and the recipe for justifying the interchange of limits in the heavy traffic analysis of stochastic processing networks. Funding: This work was supported by the Research Grants Council, University Grants Committee [GRF Grant 15501421 and NSFC/RGC Grant N_PolyU590/22]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2022.0055 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0055},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {483-509},
  shortjournal = {Oper. Res.},
  title        = {Optimal routing to parallel servers in heavy traffic},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The when and how of delegated search. <em>OR</em>,
<em>73</em>(1), 461–482. (<a
href="https://doi.org/10.1287/opre.2019.0498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Firms often outsource search processes, such as the acquisition of real estate, new technologies, or talent. To ensure the efficacy of such delegated search, firms need to carefully design incentive contracts to attenuate the ill effects of agency issues. We model this problem using a dynamic principal-agent framework, embedding the standard sequential search model. The optimal contract pays the agent a fixed per-period fee plus a bonus for finding a suitable alternative. The bonus size is defined a priori and decreases over time, whereas the range of values deemed suitable expands over time. If the principal is unable to contract on the value of the delivered alternatives, the optimal contract consists of two parts. Early in the search process, the agent is granted a small bonus for every alternative brought to the principal, irrespective of whether the principal accepts it; late in the search process, the agent is awarded a comparatively larger bonus, which is decreasing in time, but only if the principal accepts the alternative. We also consider situations where the principal chooses between searching in house and outsourcing. This decision is shown to hinge on the principal’s trade-off between speed and quality. The age-old aphorism “if you want it done right, do it yourself” holds, as in-house search is optimal for a principal who prioritizes quality. Yet, in the context of our model, we also establish an addendum: “If you want it done fast, hire someone else to do it.” Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2019.0498 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2019.0498},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {461-482},
  shortjournal = {Oper. Res.},
  title        = {The when and how of delegated search},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strategic pricing in volatile markets. <em>OR</em>,
<em>73</em>(1), 444–460. (<a
href="https://doi.org/10.1287/opre.2021.0550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study dynamic entry deterrence through limit pricing in markets subject to persistent demand shocks. An incumbent is privately informed about its costs, high or low, and can deter a Bayesian potential entrant by setting its prices strategically. The entrant can irreversibly enter the market at any time for a fixed cost, earning a payoff that depends on the market conditions and the incumbent’s unobserved type. Market demand evolves as a geometric Brownian motion. When market demand is low, entry becomes a distant threat, so there is little benefit to further deterrence, and, in equilibrium, a weak incumbent becomes tempted to reveal itself by raising its prices. We characterize a unique equilibrium in which the entrant enters when market demand is sufficiently high (relative to the incumbent’s current reputation), and the weak incumbent mixes over revealing itself when market demand is sufficiently low. In this equilibrium, pricing and entry decisions exhibit path dependence, depending not only on the market’s current size, but also its historical minimum. Supplemental Material: The electronic companion is available at https://doi.org/10.1287/opre.2021.0550 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0550},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {444-460},
  shortjournal = {Oper. Res.},
  title        = {Strategic pricing in volatile markets},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contextual inverse optimization: Offline and online
learning. <em>OR</em>, <em>73</em>(1), 424–443. (<a
href="https://doi.org/10.1287/opre.2021.0369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problems of offline and online contextual optimization with feedback information, where instead of observing the loss, we observe, after the fact, the optimal action an oracle with full knowledge of the objective function would have taken. We aim to minimize regret, which is defined as the difference between our losses and the ones incurred by an all-knowing oracle. In the offline setting, the decision maker has information available from past periods and needs to make one decision, whereas in the online setting, the decision maker optimizes decisions dynamically over time based a new set of feasible actions and contextual functions in each period. For the offline setting, we characterize the optimal minimax policy, establishing the performance that can be achieved as a function of the underlying geometry of the information induced by the data. In the online setting, we leverage this geometric characterization to optimize the cumulative regret. We develop an algorithm that yields the first regret bound for this problem that is logarithmic in the time horizon. Finally, we show via simulation that our proposed algorithms outperform previous methods from the literature. Supplemental Material: The online appendices are available at https://doi.org/10.1287/opre.2021.0369 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0369},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {424-443},
  shortjournal = {Oper. Res.},
  title        = {Contextual inverse optimization: Offline and online learning},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Competitive algorithms for the online minimum peak job
scheduling. <em>OR</em>, <em>73</em>(1), 408–423. (<a
href="https://doi.org/10.1287/opre.2021.0080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a fundamental online scheduling problem called the minimum peak job scheduling (MPJS) problem. In this problem, there is a sequence of arriving jobs, each with a specified required scheduled time for one unit of a scarce and reusable resource. The goal is to schedule each job upon arrival within a scheduling interval to minimize the resulting peak utilization (i.e., the maximum number of units used simultaneously throughout the entire scheduling interval). The MPJS problem captures many practical settings of real-time appointment scheduling. Its offline version where all jobs are known in advance is equivalent to the well-known bin-packing problem, where jobs correspond to items and the unit resource is a bin. However, the online variant of MPJS allows additional flexibility in that initially, one only commits to the scheduling time, but the allocation to the resources can be done later. In the bin-packing problem, this corresponds to the ability to move items across bins. Some relaxed versions of online bin-packing problems have already been studied, but none fundamentally capture the MPJS model studied in this paper. The paper describes the first competitive online algorithm to the MPJS problem called the harmonic rematching (HR) algorithm. The analysis shows that the HR algorithm has an asymptotic competitive ratio below 1.5. The fact that the current best lower bound on randomized online algorithms for the bin-packing problem is 1.536 highlights the fundamental difference between these two related models. Funding: The work of C. Escribe was partially supported by the Centre for Humane Innovations in Clinical Care [Grant 4000093665]. The work of M. Hu was partially funded by an MGH-MIT Fellowship. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2021.0080 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0080},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {408-423},
  shortjournal = {Oper. Res.},
  title        = {Competitive algorithms for the online minimum peak job scheduling},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian process-based random search for continuous
optimization via simulation. <em>OR</em>, <em>73</em>(1), 385–407. (<a
href="https://doi.org/10.1287/opre.2021.0303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random search is an important category of algorithms to solve continuous optimization via simulation problems. To design an efficient random search algorithm, the handling of the triple “E” (i.e., exploration, exploitation and estimation) is critical. The first two E’s refer to the design of sampling distribution to balance explorative and exploitative searches, whereas the third E refers to the estimation of objective function values based on noisy simulation observations. In this paper, we propose a class of Gaussian process-based random search (GPRS) algorithms, which provide a new framework to handle the triple “E.” In each iteration, algorithms under the framework build a Gaussian process surrogate model to estimate the objective function based on single observation of each sampled solution and randomly sample solutions from a lower-bounded sampling distribution. Under the assumption of heteroscedastic and known simulation noise, we prove the global convergence of GPRS algorithms. Moreover, for Gaussian processes having continuously differentiable sample paths, we show that the rate of convergence of GPRS algorithms can be no slower than O p ( n − 1 / ( d + 2 ) ) . Then, we introduce a specific GPRS algorithm to show how to design an integrated GPRS algorithm with adaptive sampling distributions and how to implement the algorithm efficiently. Numerical experiments show that the algorithm has good performances, even for problems where the variances of simulation noises are unknown. Funding: This work was supported by the National Natural Science Foundation of China [Grants 72031007, 72091211, 71931007]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2021.0303 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0303},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {385-407},
  shortjournal = {Oper. Res.},
  title        = {Gaussian process-based random search for continuous optimization via simulation},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expanding service capabilities through an on-demand
workforce. <em>OR</em>, <em>73</em>(1), 363–384. (<a
href="https://doi.org/10.1287/opre.2021.0651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An on-demand workforce can greatly benefit a traditional call center by allowing it to adjust its service capacity on demand quickly. Despite its conceptual elegance, the operationalization of this process is challenging due to the various sources of randomness involved. The purpose of this paper is to help call centers enhance service levels while keeping operating expenses low by taking advantage of an on-call pool of temporary agents in day-to-day operations. For that purpose, we develop a two-stage decision model in which the first stage seeks the optimal mix of permanent and on-call staff, and the second stage seeks a joint on-demand staffing and call scheduling policy to minimize the associated cost given the base staffing level and the size of the on-call pool. Because the exact analysis of the two-stage decision model seems analytically intractable, we resort to an approximation in a suitable asymptotic regime. In that regime, we characterize the system dynamics of the service operation and derive an optimal joint on-demand staffing and call scheduling policy for the second-stage problem, which in turn is used to find an approximate solution to the first-stage problem. In particular, the derived policy for the second-stage problem involves tapping into the on-call pool to procure a team of on-demand agents when the number of calls to be processed exceeds a certain threshold and dismissing them when it falls below another threshold; additionally, the call scheduling rule shows an unusual pattern due to the interplay between staffing and scheduling decisions. Extensive numerical studies under realistic parameter settings show that the solution approach we propose can achieve significant cost savings. Funding: W. Liu has been supported by the President’s Graduate Fellowship at the National University of Singapore. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2021.0651 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0651},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {363-384},
  shortjournal = {Oper. Res.},
  title        = {Expanding service capabilities through an on-demand workforce},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scores for multivariate distributions and level sets.
<em>OR</em>, <em>73</em>(1), 344–362. (<a
href="https://doi.org/10.1287/opre.2020.0365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasts of multivariate probability distributions are required for a variety of applications. Scoring rules enable the evaluation of forecast accuracy and comparison between forecasting methods. We propose a theoretical framework for scoring rules for multivariate distributions that encompasses the existing quadratic score and multivariate continuous ranked probability score. We demonstrate how this framework can be used to generate new scoring rules. In some multivariate contexts, it is a forecast of a level set that is needed, such as a density level set for anomaly detection or the level set of the cumulative distribution as a measure of risk. This motivates consideration of scoring functions for such level sets. For univariate distributions, it is well established that the continuous ranked probability score can be expressed as the integral over a quantile score. We show that, in a similar way, scoring rules for multivariate distributions can be decomposed to obtain scoring functions for level sets. Using this, we present scoring functions for different types of level sets, including density level sets and level sets for cumulative distributions. To compute the scores, we propose a simple numerical algorithm. We perform a simulation study to support our proposals, and we use real data to illustrate usefulness for forecast combining and conditional value at risk estimation. Funding: The work of S. Li was supported by the National Natural Science Foundation of China [Grant 12201399] and the Shanghai Frontier Research Institute for Modern Analysis.},
  archive      = {J_OR},
  doi          = {10.1287/opre.2020.0365},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {344-362},
  shortjournal = {Oper. Res.},
  title        = {Scores for multivariate distributions and level sets},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving efficiency in black-box simulation of distribution
tails with self-structuring importance samplers. <em>OR</em>,
<em>73</em>(1), 325–343. (<a
href="https://doi.org/10.1287/opre.2021.0331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel importance sampling (IS) scheme for estimating distribution tails of performance measures modeled with a rich set of tools, such as linear programs, integer linear programs, piecewise linear/quadratic objectives, feature maps specified with deep neural networks, etc. The conventional approach of explicitly identifying efficient changes of measure suffers from feasibility and scalability concerns beyond highly stylized models because of their need to be tailored intricately to the objective and the underlying probability distribution. This bottleneck is overcome in the proposed scheme with an elementary transformation that is capable of implicitly inducing an effective IS distribution in a variety of models by replicating the concentration properties observed in less rare samples. This novel approach is guided by developing a large deviations principle that brings out the phenomenon of self-similarity of optimal IS distributions. The proposed sampler is the first to attain asymptotically optimal variance reduction across a spectrum of multivariate distributions despite being oblivious to the specifics of the underlying model. Its applicability is illustrated with contextual shortest-path and portfolio credit risk models informed by neural networks. Funding: This work was supported by the Singapore Ministry of Education Academic Research Fund [Grant MOE2019-T2-2-163]. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2021.0331 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0331},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {325-343},
  shortjournal = {Oper. Res.},
  title        = {Achieving efficiency in black-box simulation of distribution tails with self-structuring importance samplers},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projective hedging algorithms for multistage stochastic
programming, supporting distributed and asynchronous implementation.
<em>OR</em>, <em>73</em>(1), 311–324. (<a
href="https://doi.org/10.1287/opre.2022.0228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a decomposition algorithm for multistage stochastic programming that resembles the progressive hedging method of Rockafellar and Wets but is provably capable of several forms of asynchronous operation. We derive the method from a class of projective operator splitting methods fairly recently proposed by Combettes and Eckstein, significantly expanding the known applications of those methods. Our derivation assures convergence for convex problems whose feasible set is compact, subject to some standard regularity conditions and a mild “fairness” condition on subproblem selection. The method’s convergence guarantees are deterministic and do not require randomization, in contrast to other proposed asynchronous variations of progressive hedging. Computational experiments described in an online appendix show the method to outperform progressive hedging on large-scale problems in a highly parallel computing environment. Funding: This work was supported by the National Science Foundation Directorate of Computer and Information Science and Engineering [Grant CCF-1617617] and U.S. Department of Energy [Office of Electricity’s Advanced Grid Modeling program]. Supplemental Material: The online appendices are available at https://doi.org/10.1287/opre.2022.0228 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0228},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {311-324},
  shortjournal = {Oper. Res.},
  title        = {Projective hedging algorithms for multistage stochastic programming, supporting distributed and asynchronous implementation},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavior-aware queueing: The finite-buffer setting with many
strategic servers. <em>OR</em>, <em>73</em>(1), 290–310. (<a
href="https://doi.org/10.1287/opre.2023.2487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Service system design is often informed by queueing theory. Traditional queueing theory assumes that servers work at constant speeds. That is reasonable in computer science and manufacturing contexts. However, servers in service systems are people, and in contrast to machines, the incentives created by design decisions influence their work speeds. We study how server work speed is affected by managerial decisions concerning (i) how many servers to staff and how much to pay them and (ii) whether and when to turn away customers in the context of many-server queues with finite or infinite buffers ( M / M / N / k with k ∈ Z + ∪ { ∞ } ) in which the work speeds emerge as the solution to a noncooperative game. We show that a symmetric equilibrium always exists in a loss system ( N = k ) and provide conditions for equilibrium existence in a single-server system ( N = 1). For the general M / M / N / k system, we provide a sufficient condition for the existence of a solution to the first-order condition and bounds on such a solution; however, showing that it is an equilibrium is challenging because of the existence of multiple local maxima in the utility function. Nevertheless, in an asymptotic regime in which demand becomes large, the utility function becomes concave, allowing us to characterize underloaded, critically loaded, and overloaded equilibria. Funding: This work was supported in part by funding from the Social Sciences and Humanities Research Council of Canada [Grant 430-2020-00334] and the Charles M. Harper Faculty Fellowship at the University of Chicago Booth School of Business. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2023.2487 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.2487},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {290-310},
  shortjournal = {Oper. Res.},
  title        = {Behavior-aware queueing: The finite-buffer setting with many strategic servers},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical note—online matching with bayesian rewards.
<em>OR</em>, <em>73</em>(1), 278–289. (<a
href="https://doi.org/10.1287/opre.2021.0499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study in this paper an online matching problem where a central platform needs to match a number of limited resources to different groups of users that arrive sequentially over time. The reward of each matching option depends on both the type of resource and the time period the user arrives. The matching rewards are assumed to be unknown but drawn from probability distributions that are known a priori. The platform then needs to learn the true rewards online based on real-time observations of the matching results. The goal of the central platform is to maximize the total reward from all of the matchings without violating the resource capacity constraints. We formulate this matching problem with Bayesian rewards as a Markovian multiarmed bandit problem with budget constraints, where each arm corresponds to a pair of a resources and a time period. We devise our algorithm by first finding policies for each single arm separately via a relaxed linear program and then “assembling” these policies together through judicious selection criteria and well-designed pulling orders. We prove that the expected reward of our algorithm is at least 1 2 ( 2 − 1 ) of the expected reward of an optimal algorithm. Funding: The authors thank the Massachusetts Institute of Technology (MIT)-IBM partnership in Artificial Intelligence and the MIT Data Science Laboratory for support. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2021.0499 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0499},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {278-289},
  shortjournal = {Oper. Res.},
  title        = {Technical Note—Online matching with bayesian rewards},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical note—a stationary infinite-horizon supply contract
under asymmetric inventory information. <em>OR</em>, <em>73</em>(1),
270–277. (<a href="https://doi.org/10.1287/opre.2020.0495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a decentralized supply chain in which a supplier sells goods to a retailer facing general random demand over an infinite horizon. The retailer satisfies the demand to the extent of the inventory on hand. The retailer has private information about the retailer’s stock in each period, and the supplier offers the retailer a supply contract menu to account for the information asymmetry. We obtain a necessary condition for optimizing a long-term stationary truth-telling contract under general demand and belief distributions. We apply it to a batch-order contract, which replenishes a prespecified inventory quantity for a fixed payment in each period only when the retailer’s beginning inventory becomes zero. Methodologically, we formulate the supplier’s contract design as a calculus of variations problem and apply the concept of Gâteaux derivative to obtain these results. This methodology can potentially be applied to other dynamic contracting problems. Funding: A. Bensoussan acknowledges support from the National Science Foundation [Grant NSF-DMS 220 47 95]. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2020.0495 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2020.0495},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {270-277},
  shortjournal = {Oper. Res.},
  title        = {Technical Note—A stationary infinite-horizon supply contract under asymmetric inventory information},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical note—conic mixed-binary sets: Convex hull
characterizations and applications. <em>OR</em>, <em>73</em>(1),
251–269. (<a href="https://doi.org/10.1287/opre.2020.0827">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a general conic mixed-binary set where each homogeneous conic constraint j involves an affine function of independent continuous variables and an epigraph variable associated with a nonnegative function, f j , of common binary variables. Sets of this form naturally arise as substructures in a number of applications, including mean-risk optimization, chance-constrained problems, portfolio optimization, lot sizing and scheduling, fractional programming, variants of the best subset selection problem, a class of sparse semidefinite programs, and distributionally robust chance-constrained programs. We give a convex hull description of this set that relies on simultaneous characterization of the epigraphs of f j ’s, which is easy to do when all functions f j ’s are submodular. Our result unifies and generalizes an existing result in two important directions. First, it considers multiple general convex cone constraints instead of a single second-order cone type constraint. Second, it takes arbitrary nonnegative functions instead of a specific submodular function obtained from the square root of an affine function. We close by demonstrating the applicability of our results in the context of a number of problem classes. Funding: The research is supported, in part, by ONR [Grants N00014-19-1-2321 and N00014-22-1-2602], AFOSR [Grant FA9550-22-1-0365], the Institute for Basic Science [IBS-R029-C1, Y2], the FOUR Brain Korea 21 Program [NRF-5199990113928], the National Research Foundation of Korea [NRF-2022M3J6A1063021], the KAIST Starting Fund [KAIST-G04220016], NSF [Grant CMMI 1454548], and Early Postdoc Mobility Fellowship SNSF [Grant P2ELP2_195149].},
  archive      = {J_OR},
  doi          = {10.1287/opre.2020.0827},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {251-269},
  shortjournal = {Oper. Res.},
  title        = {Technical Note—Conic mixed-binary sets: Convex hull characterizations and applications},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Technical note—a new rate-optimal sampling allocation for
linear belief models. <em>OR</em>, <em>73</em>(1), 239–250. (<a
href="https://doi.org/10.1287/opre.2022.2337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive a new optimal sampling budget allocation for belief models based on linear regression with continuous covariates, where the expected response is interpreted as the value of the covariate vector, and an “error” occurs if a lower-valued vector is falsely identified as being better than a higher-valued one. Our allocation optimizes the rate at which the probability of error converges to zero using a large deviations theoretic characterization. This is the first large deviations-based optimal allocation for continuous decision spaces, and it turns out to be considerably simpler and easier to implement than allocations that use discretization. We give a practicable sequential implementation and illustrate its empirical potential. Funding: This work was supported by the National Science Foundation [Grant CMMI-2112828].},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.2337},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {239-250},
  shortjournal = {Oper. Res.},
  title        = {Technical Note—A new rate-optimal sampling allocation for linear belief models},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal no-regret learning in repeated first-price auctions.
<em>OR</em>, <em>73</em>(1), 209–238. (<a
href="https://doi.org/10.1287/opre.2020.0282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study online learning in repeated first-price auctions where a bidder, only observing the winning bid at the end of each auction, learns to adaptively bid to maximize the cumulative payoff. To achieve this goal, the bidder faces censored feedback: If the bidder wins the bid, then the bidder is not able to observe the highest bid of the other bidders, which we assume is i.i.d. drawn from an unknown distribution. In this paper, we develop the first learning algorithm that achieves a near-optimal O ˜ ( T ) regret bound, by exploiting two structural properties of first-price auctions, that is, the specific feedback structure and payoff function. We first formulate the feedback structure in first-price auctions as partially ordered contextual bandits, a combination of the graph feedback across actions (bids), the cross-learning across contexts (private values), and a partial order over the contexts. We establish both strengths and weaknesses of this framework by showing a curious separation that a regret nearly independent of the action/context sizes is possible under stochastic contexts but is impossible under adversarial contexts. In particular, this framework leads to an O ( T log 2.5 T ) regret for first-price auctions when the bidder’s private values are independent and identically distributed. Despite the limitation of this framework, we further exploit the special payoff function of first-price auctions to develop a sample-efficient algorithm even in the presence of adversarially generated private values. We establish an O ( T log 3 T ) regret bound for this algorithm, hence providing a complete characterization of optimal learning guarantees for first-price auctions. Funding: This project was supported in part by the National Science Foundation [Awards CCF-2106467 and CCF-2106508]. Y. Han and T. Weissman were partially supported by the Yahoo Faculty Research and Engagement Program.},
  archive      = {J_OR},
  doi          = {10.1287/opre.2020.0282},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {209-238},
  shortjournal = {Oper. Res.},
  title        = {Optimal no-regret learning in repeated first-price auctions},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to persuade on the fly: Robustness against
ignorance. <em>OR</em>, <em>73</em>(1), 194–208. (<a
href="https://doi.org/10.1287/opre.2021.0529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by information sharing in online platforms, we study repeated persuasion between a sender and a stream of receivers, where, at each time, the sender observes a payoff-relevant state drawn independently and identically from an unknown distribution and shares state information with the receivers, who each choose an action. The sender seeks to persuade the receivers into taking actions aligned with the sender’s preference by selectively sharing state information. However, in contrast to the standard models, neither the sender nor the receivers know the distribution, and the sender has to persuade while learning the distribution on the fly. We study the sender’s learning problem of making persuasive action recommendations to achieve low regret against the optimal persuasion mechanism with the knowledge of the distribution. To do this, we first propose and motivate a persuasiveness criterion for the unknown distribution setting that centers robustness as a requirement in the face of uncertainty. Our main result is an algorithm that, with high probability, is robustly persuasive and achieves O ( T log T ) regret, where T is the horizon length. Intuitively, at each time, our algorithm maintains a set of candidate distribution and chooses a signaling mechanism that is simultaneously persuasive for all of them. Core to our proof is a tight analysis about the cost of robust persuasion, which may be of independent interest. We further prove that this regret order is optimal (up to logarithmic terms) by showing that no algorithm can achieve regret better than Ω ( T ) . Funding: Y. Zu and K. Iyer gratefully acknowledge partial support from the National Science Foundation (NSF) Division of Civil, Mechanical, and Manufacturing Innovation [Grant CMMI-2002156]. H. Xu is supported by the NSF Division of Computing and Communication Foundations [Award CCF-2303372], the Army Research Office [Award W911NF-23-1-0030], and a Google Faculty Research Award. Supplemental Material: The e-companion is available at https://doi.org/10.1287/opre.2021.0529 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2021.0529},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {194-208},
  shortjournal = {Oper. Res.},
  title        = {Learning to persuade on the fly: Robustness against ignorance},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pricing optimal outcomes in coupled and non-convex markets:
Theory and applications to electricity markets. <em>OR</em>,
<em>73</em>(1), 178–193. (<a
href="https://doi.org/10.1287/opre.2023.0401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world markets, participants have non-convex preferences, and the allocation problem needs to consider complex constraints. Electricity markets are a prime example, but similar problems appear in many markets, which has led to a growing literature on market design. Competitive equilibrium does not generally exist in such markets. Today, power markets use heuristic pricing rules based on the dual of a relaxed allocation problem. With increasing levels of renewables, these rules have come under scrutiny as they lead to high out-of-market side payments to some participants and inadequate congestion signals. We show that existing pricing heuristics optimize specific design goals that can be conflicting. The tradeoffs can be substantial, and we establish that the design of pricing rules is fundamentally a multiobjective optimization problem addressing different incentives. In addition to traditional multiobjective optimization techniques that involve weighting individual objectives, we introduce a novel parameter-free pricing rule that minimizes incentives for market participants to deviate locally. Our theoretical and experimental findings show how the new pricing rule capitalizes on the upsides of existing pricing rules under scrutiny today. It leads to prices that incur low make-whole payments while providing adequate congestion signals and low lost opportunity costs. Our suggested pricing rule does not require weighing objectives, it is computationally scalable, and balances tradeoffs in a principled manner, addressing a critical policy issue in electricity markets. Funding: The financial support from the German Research Foundation (Deutsche Forschungsgemeinschaft, DFG) [Grant BI 1057/9-1] is gratefully acknowledged. Supplemental Material: The computer code and data that supports the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2023.0401 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0401},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {178-193},
  shortjournal = {Oper. Res.},
  title        = {Pricing optimal outcomes in coupled and non-convex markets: Theory and applications to electricity markets},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Price interpretability of prediction markets: A convergence
analysis. <em>OR</em>, <em>73</em>(1), 157–177. (<a
href="https://doi.org/10.1287/opre.2022.0417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction markets are long known for prediction accuracy. This study systematically explores the fundamental properties of prediction markets, addressing questions about their information aggregation process and the factors contributing to their remarkable efficacy. We propose a novel multivariate utility–based mechanism that unifies several existing automated market-making schemes. Using this mechanism, we establish the convergence results for markets comprised of risk-averse traders who have heterogeneous beliefs and repeatedly interact with the market maker. We demonstrate that the resulting limiting wealth distribution aligns with the Pareto efficient frontier defined by the utilities of all market participants. With the help of this result, we establish analytical and numerical results for the limiting price in different market models. Specifically, we show that the limiting price converges to the geometric mean of agent beliefs in exponential utility-based markets. In risk measure-based markets, we construct a family of risk measures that satisfy the convergence criteria and prove that the price converges to a unique level represented by the weighted power mean of agent beliefs. In broader markets with constant relative risk aversion utilities, we reveal that the limiting price can be characterized by systems of equations that encapsulate agent beliefs, risk parameters, and wealth. Despite the impact of traders’ trading sequences on the limiting price, we establish a price invariance result for markets with a large trader population. Using this result, we propose an efficient approximation scheme for the limiting price. Numerical experiments demonstrate that the accuracy of this approximation scheme outperforms existing approximation methods across various scenarios. Our findings serve to aid market designers in better tailoring and adjusting the market-making mechanism for more effective opinion elicitation. Funding: This work was supported by the National Natural Science Foundation of China [Grants 71671045, 71971132, 72150002, 72201067, and 72394361], the InnoHK initiative of the Government of the HKSAR, Laboratory for AI-Powered Financial Technologies, the Guangdong Provincial Key Laboratory of Mathematical Foundations for Artificial Intelligence [Grant 2023B1212010001], the Shanghai Research Center for Data Science and Decision Technology, and the Key Laboratory of Interdisciplinary Research of Computation and Economics, Ministry of Education, Shanghai University of Finance and Economics. Supplemental Material: The computer code and data that supports the findings of this study is available within this article’s supplemental material at https://doi.org/10.1287/opre.2022.0417 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0417},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {157-177},
  shortjournal = {Oper. Res.},
  title        = {Price interpretability of prediction markets: A convergence analysis},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The role of lookahead and approximate policy evaluation in
reinforcement learning with linear value function approximation.
<em>OR</em>, <em>73</em>(1), 139–156. (<a
href="https://doi.org/10.1287/opre.2022.0357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Function approximation is widely used in reinforcement learning to handle the computational difficulties associated with very large state spaces. However, function approximation introduces errors that may lead to instabilities when using approximate dynamic programming techniques to obtain the optimal policy. Therefore, techniques such as lookahead for policy improvement and m -step rollout for policy evaluation are used in practice to improve the performance of approximate dynamic programming with function approximation. We quantitatively characterize the impact of lookahead and m -step rollout on the performance of approximate dynamic programming (DP) with function approximation. (i) Without a sufficient combination of lookahead and m -step rollout, approximate DP may not converge. (ii) Both lookahead and m -step rollout improve the convergence rate of approximate DP. (iii) Lookahead helps mitigate the effect of function approximation and the discount factor on the asymptotic performance of the algorithm. Our results are presented for two approximate DP methods: one that uses least-squares regression to perform function approximation and another that performs several steps of gradient descent of the least-squares objective in each iteration. Funding: The research presented here was supported in part by a grant from Sandia National Labs and the NSF [Grants CCF 1934986, CCF 2207547, CNS 2106801], ONR [Grant N00014-19-1-2566], and ARO [Grant W911NF-19-1-0379].},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0357},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {139-156},
  shortjournal = {Oper. Res.},
  title        = {The role of lookahead and approximate policy evaluation in reinforcement learning with linear value function approximation},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online learning for constrained assortment optimization
under markov chain choice model. <em>OR</em>, <em>73</em>(1), 109–138.
(<a href="https://doi.org/10.1287/opre.2022.0693">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a dynamic assortment selection problem where arriving customers make purchase decisions among offered products from a universe of products under a Markov chain choice (MCC) model. The retailer only observes the assortment and the customer’s single choice per period. Given limited display capacity, resource constraints, and no a priori knowledge of problem parameters, the retailer’s objective is to sequentially learn the choice model and optimize cumulative revenues over a finite selling horizon. We develop a fast linear system based explore-then-commit (FastLinETC for short) learning algorithm that balances the tradeoff between exploration and exploitation. The algorithm can simultaneously estimate the arrival and transition probabilities in the MCC model by solving a linear system of equations and determining the near-optimal assortment based on these estimates. Furthermore, our consistent estimators offer superior computational times compared with existing heuristic estimation methods, which often suffer from inconsistency or a significant computational burden. Funding: The research of Q. Luo is partially supported by the National Science Foundation [Grant CMMI-2308750]. The research of Z. Huang is partially supported by the Shanghai Sailing Program [Grant 22YF1451100 and the Fundamental Research Funds for the Central Universities]. The research of C. Shi is partially supported by Amazon [Research Award].},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0693},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {109-138},
  shortjournal = {Oper. Res.},
  title        = {Online learning for constrained assortment optimization under markov chain choice model},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Drone-delivery network for opioid overdose: Nonlinear
integer queueing-optimization models and methods. <em>OR</em>,
<em>73</em>(1), 86–108. (<a
href="https://doi.org/10.1287/opre.2022.0489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new stochastic emergency network design model that uses a fleet of drones to quickly deliver naloxone in response to opioid overdoses. The network is represented as a collection of M / G / K queueing systems in which the capacity K of each system is a decision variable, and the service time is modeled as a decision-dependent random variable. The model is a queuing-based optimization problem which locates fixed (drone bases) and mobile (drones) servers and determines the drone dispatching decisions and takes the form of a nonlinear integer problem intractable in its original form. We develop an efficient reformulation and algorithmic framework. Our approach reformulates the multiple nonlinearities (fractional, polynomial, exponential, factorial terms) to give a mixed-integer linear programming (MILP) formulation. We demonstrate its generalizability and show that the problem of minimizing the average response time of a collection of M / G / K queueing systems with unknown capacity K is always MILP-representable. We design an outer approximation branch-and-cut algorithmic framework that is computationally efficient and scales well. The analysis based on real-life data reveals that drones can in Virginia Beach: (1) decrease the response time by 82%, (2) increase the survival chance by more than 273%, (3) save up to 33 additional lives per year, and (4) provide annually up to 279 additional quality-adjusted life years. Funding: M. A. Lejeune acknowledges the support of the National Science Foundation [Grant ECCS-2114100] and the Office of Naval Research [Grant N00014-22-1-2649]. Supplemental Material: The online appendices are available at https://doi.org/10.1287/opre.2022.0489 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2022.0489},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {86-108},
  shortjournal = {Oper. Res.},
  title        = {Drone-delivery network for opioid overdose: Nonlinear integer queueing-optimization models and methods},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving the security of united states elections with
robust optimization. <em>OR</em>, <em>73</em>(1), 61–85. (<a
href="https://doi.org/10.1287/opre.2023.0422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For more than a century, election officials across the United States have inspected voting machines before elections using a procedure called logic and accuracy testing (LAT). This procedure consists of election officials casting a test deck of ballots into each voting machine and confirming the machine produces the expected vote total for each candidate. We bring a scientific perspective to LAT by introducing the first formal approach to designing test decks with rigorous security guarantees. Specifically, our approach employs robust optimization to find test decks that are guaranteed to detect any voting machine misconfiguration that would cause votes to be swapped across candidates. Of all the test decks with this security guarantee, our robust optimization problem yields the test deck with the minimum number of ballots, thereby minimizing implementation costs for election officials. To facilitate deployment at scale, we develop a practically efficient exact algorithm for solving our robust optimization problems based on the cutting plane method. In partnership with the Michigan Bureau of Elections, we retrospectively applied our approach to all 6,928 ballot styles from Michigan’s November 2022 general election; this retrospective study reveals that the test decks with rigorous security guarantees obtained by our approach require, on average, only 1.2% more ballots than current practice. Our approach has since been piloted in real-world elections by the Michigan Bureau of Elections as a low-cost way to improve election security and increase public trust in democratic institutions. Funding: This research was supported by the U.S. National Science Foundation [Grant CNS-1518888]. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. Supplemental Material: All supplemental materials, including the computer code and data that support the findings of this study are available at https://doi.org/10.1287/opre.2023.0422 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0422},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {61-85},
  shortjournal = {Oper. Res.},
  title        = {Improving the security of united states elections with robust optimization},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preventing price-mediated contagion due to fire sales
externalities: Strategic foundations of macroprudential regulation.
<em>OR</em>, <em>73</em>(1), 40–60. (<a
href="https://doi.org/10.1287/opre.2023.0237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We offer a stress test framework in which interaction between regulated banks occurs through the impact they may have on asset prices when they deleverage. Because banks are constrained to maintain their risk-based capital ratio higher than a threshold, the deleveraging problem yields a generalized game in which the solvency constraint of each bank depends on the decisions of the others. We analyze the game under microprudential but also under macroprudential regulation. Microprudential regulation corresponds to the standard situation in which each bank considers its own solvency constraint, whereas macroprudential regulation is defined as the situation in which each bank faces a systemic constraint in that it must consider the solvency constraints of all the banks. When bankruptcies can be avoided, we show that a Nash equilibrium generically exists under macroprudential regulation, contagion of failures due to fire sales externalities is prevented, whereas it may not exist under microprudential regulation. We eventually analyze the deleveraging problem when bankruptcies cannot be avoided and present additional results. Supplemental Material: The online appendix is available at https://doi.org/10.1287/opre.2023.0237 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0237},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {40-60},
  shortjournal = {Oper. Res.},
  title        = {Preventing price-mediated contagion due to fire sales externalities: Strategic foundations of macroprudential regulation},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application-driven learning: A closed-loop prediction and
optimization approach applied to dynamic reserves and demand
forecasting. <em>OR</em>, <em>73</em>(1), 22–39. (<a
href="https://doi.org/10.1287/opre.2023.0565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision making is generally modeled as sequential forecast-decision steps with no feedback, following an open-loop approach. For instance, in the electricity sector, system operators use the forecast-decision approach followed by ad hoc rules to determine reserve requirements and biased net load forecasts to guard the system against renewable generation and demand uncertainty. Such procedures lack technical formalism to minimize operating and reliability costs. We present a new closed-loop framework, named application-driven learning, in which the best forecasting model is defined according to a given application cost function. We consider applications in which the decision-making process is driven by two-stage optimization schemes fed by multivariate point forecasts. We present our estimation method as a bilevel optimization problem and prove convergence to the best estimator regarding the expected application cost. We propose two solution methods: an exact method based on the KKT conditions of the second-level problems and a scalable heuristic suitable for decomposition. Thus, we offer an alternative scientifically grounded approach to current ad hoc procedures implemented in industry practices. We test the proposed methodology with real data and large-scale systems with thousands of buses. Results show that the proposed methodology is scalable and consistently performs better than the standard open-loop approach. Funding: J. Dias Garcia was partially supported by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) [Finance Code 001]. A. Street was partially supported by Fundação de Amparo à Pesquisa do Estado do Rio de Janeiro (FAPERJ) and Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq). T. Homem-de-Mello acknowledges the support of Grant FONDECYT 1221770 from ANID, Chile. Supplemental Material: All supplemental materials, including the computer code and data that support the findings of this study, are available at https://doi.org/10.1287/opre.2023.0565 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2023.0565},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {22-39},
  shortjournal = {Oper. Res.},
  title        = {Application-driven learning: A closed-loop prediction and optimization approach applied to dynamic reserves and demand forecasting},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Error propagation in asymptotic analysis of the data-driven
(s, s) inventory policy. <em>OR</em>, <em>73</em>(1), 1–21. (<a
href="https://doi.org/10.1287/opre.2020.0568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study periodic review stochastic inventory control in the data-driven setting where the retailer makes ordering decisions based only on historical demand observations without any knowledge of the probability distribution of the demand. Because an ( s , S )-policy is optimal when the demand distribution is known, we investigate the statistical properties of the data-driven ( s , S )-policy obtained by recursively computing the empirical cost-to-go functions. This policy is inherently challenging to analyze because the recursion induces propagation of the estimation error backward in time. In this work, we establish the asymptotic properties of this data-driven policy by fully accounting for the error propagation. In this setting, the empirical cost-to-go functions for the estimated parameters are not i.i.d. sums because of the error propagation. Our main methodological innovation comes from an asymptotic representation for multi-sample U -processes in terms of i.i.d. sums. This representation enables us to apply empirical process theory to derive the influence functions of the estimated parameters and to establish joint asymptotic normality. Based on these results, we also propose an entirely data-driven estimator of the optimal expected cost, and we derive its asymptotic distribution. We demonstrate some useful applications of our asymptotic results, including sample size determination and interval estimation. Funding: This work was supported by Singapore MOE AcRF Tier 2 [A-8001052-00-00] and the National Natural Science Foundation of China [72071138]. Supplemental Material: The computer code and data that support the findings of this study are available within this article’s supplemental material at https://doi.org/10.1287/opre.2020.0568 .},
  archive      = {J_OR},
  doi          = {10.1287/opre.2020.0568},
  journal      = {Operations Research},
  month        = {1-2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Oper. Res.},
  title        = {Error propagation in asymptotic analysis of the data-driven (s, s) inventory policy},
  volume       = {73},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
