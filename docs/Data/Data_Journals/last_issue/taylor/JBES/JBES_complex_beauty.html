<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JBES_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jbes---20">JBES - 20</h2>
<ul>
<li><details>
<summary>
(2025). Statistical inference for heterogeneous treatment effects
discovered by generic machine learning in randomized experiments.
<em>JBES</em>, <em>43</em>(1), 256–268. (<a
href="https://doi.org/10.1080/07350015.2024.2358909">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers are increasingly turning to machine learning (ML) algorithms to investigate causal heterogeneity in randomized experiments. Despite their promise, ML algorithms may fail to accurately ascertain heterogeneous treatment effects under practical settings with many covariates and small sample size. In addition, the quantification of estimation uncertainty remains a challenge. We develop a general approach to statistical inference for heterogeneous treatment effects discovered by a generic ML algorithm. We apply the Neyman’s repeated sampling framework to a common setting, in which researchers use an ML algorithm to estimate the conditional average treatment effect and then divide the sample into several groups based on the magnitude of the estimated effects. We show how to estimate the average treatment effect within each of these groups, and construct a valid confidence interval. In addition, we develop nonparametric tests of treatment effect homogeneity across groups, and rank-consistency of within-group average treatment effects. The validity of our methodology does not rely on the properties of ML algorithms because it is solely based on the randomization of treatment assignment and random sampling of units. Finally, we generalize our methodology to the cross-fitting procedure by accounting for the additional uncertainty induced by the random splitting of data.},
  archive      = {J_JBES},
  author       = {Kosuke Imai and Michael Lingzhi Li},
  doi          = {10.1080/07350015.2024.2358909},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {256-268},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Statistical inference for heterogeneous treatment effects discovered by generic machine learning in randomized experiments},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimation of the local conditional tail average treatment
effect. <em>JBES</em>, <em>43</em>(1), 241–255. (<a
href="https://doi.org/10.1080/07350015.2024.2356731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conditional tail average treatment effect (CTATE) is defined as a difference between the conditional tail expectations of potential outcomes, which can capture heterogeneity and deliver aggregated local information on treatment effects over different quantile levels and is closely related to the notion of second-order stochastic dominance and the Lorenz curve. These properties render it a valuable tool for policy evaluation. In this article, we study estimation of the CTATE locally for a group of compliers (local CTATE or LCTATE) under the two-sided noncompliance framework. We consider a semiparametric treatment effect framework under endogeneity for the LCTATE estimation using a newly introduced class of consistent loss functions jointly for the CTE and quantile. We establish the asymptotic theory of our proposed LCTATE estimator and provide an efficient algorithm for its implementation. We then apply the method to evaluate the effects of participating in programs under the Job Training Partnership Act in the United States.},
  archive      = {J_JBES},
  author       = {Le-Yu Chen and Yu-Min Yen},
  doi          = {10.1080/07350015.2024.2356731},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {241-255},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimation of the local conditional tail average treatment effect},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous confidence intervals for partially identified
parameters. <em>JBES</em>, <em>43</em>(1), 232–240. (<a
href="https://doi.org/10.1080/07350015.2024.2356083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article extends the Imbens and Manski and Stoye confidence interval for a partially identified scalar parameter to a vector-valued parameter. The proposed method produces uniformly valid simultaneous confidence intervals for each dimension, or, equivalently, a rectangular confidence region that covers points in the identified set with a specified probability. The method applies when asymptotically normal estimates of upper and lower bounds for each dimension are available. The intervals are computationally simple and fast relative to methods based on test inversion or bootstrapped calibration, and do not suffer from the conservativity of projection-based approaches.},
  archive      = {J_JBES},
  author       = {Brigham R. Frandsen and Zachari A. Pond},
  doi          = {10.1080/07350015.2024.2356083},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {232-240},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Simultaneous confidence intervals for partially identified parameters},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting inflation using economic narratives.
<em>JBES</em>, <em>43</em>(1), 216–231. (<a
href="https://doi.org/10.1080/07350015.2024.2347619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We use economic narratives to forecast inflation with a large news corpus and machine learning algorithms. The economic narratives from the full text content of over 880,000 Wall Street Journal articles are decomposed into multiple time series representing interpretable news topics, which are then used to predict inflation. The results indicate that narrative-based forecasts are more accurate than the benchmarks, especially during recession periods. Narrative-based forecasts perform better in long-run forecasting and provide incremental predictive information even after controlling macroeconomic big data. In particular, information about inflation expectations and prices of specific goods embedded in narratives contributes to their predictive power. Overall, we provide a novel representation of economic narratives and document the important role of economic narratives in inflation forecasting.},
  archive      = {J_JBES},
  author       = {Yongmiao Hong and Fuwei Jiang and Lingchao Meng and Bowen Xue},
  doi          = {10.1080/07350015.2024.2347619},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {216-231},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Forecasting inflation using economic narratives},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification and estimation of discrete choice models with
unobserved choice sets. <em>JBES</em>, <em>43</em>(1), 204–215. (<a
href="https://doi.org/10.1080/07350015.2024.2342731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a framework for nonparametric identification and estimation of discrete choice models with unobserved choice sets. We recover the joint distribution of choice sets and preferences from a cross-section of repeated choices. We assume that either the latent choice sets are sparse or that the number of repeated choices is sufficiently large. Sparsity requires the number of possible choice sets to be relatively small. It is satisfied, for instance, when the choice sets are nested or when they form a partition. Our estimation procedure is computationally fast and uses mixed-integer programming to recover the sparse support of choice sets. Analyzing the ready-to-eat cereal industry using a household scanner dataset, we find that ignoring the unobservability of choice sets can lead to incorrect estimates of preferences.},
  archive      = {J_JBES},
  author       = {Victor H. Aguiar and Nail Kashaev},
  doi          = {10.1080/07350015.2024.2342731},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {204-215},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Identification and estimation of discrete choice models with unobserved choice sets},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Trending time-varying coefficient spatial panel data models.
<em>JBES</em>, <em>43</em>(1), 191–203. (<a
href="https://doi.org/10.1080/07350015.2024.2340516">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the estimation and inference of spatial panel data models in which the regression coefficient vector is a trending function. We use time differences to eliminate the individual effects and employ various GMM estimations for regression coefficients with both linear and quadratic moments. Time trend estimator based on these GMM estimations is also proposed. Monte Carlo experiments show that the finite sample performance of the estimators is satisfactory. As an empirical illustration, we investigate the trending pattern of the spillover effect of air pollution among Chinese cities from 2015 to 2021.},
  archive      = {J_JBES},
  author       = {Hsuan-Yu Chang and Xiaojun Song and Jihai Yu},
  doi          = {10.1080/07350015.2024.2340516},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {191-203},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Trending time-varying coefficient spatial panel data models},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting weak distribution shifts via displacement
interpolation. <em>JBES</em>, <em>43</em>(1), 178–190. (<a
href="https://doi.org/10.1080/07350015.2024.2335957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting weak, systematic distribution shifts and quantitatively modeling individual, heterogeneous responses to policies or incentives have found increasing empirical applications in social and economic sciences. Given two probability distributions P (null) and Q (alternative), we study the problem of detecting weak distribution shift deviating from the null P toward the alternative Q , where the level of deviation vanishes as a function of n , the sample size. We propose a model for weak distribution shifts via displacement interpolation between P and Q , drawing from the optimal transport theory. We study a hypothesis testing procedure based on the Wasserstein distance, derive sharp conditions under which detection is possible, and provide the exact characterization of the asymptotic Type I and Type II errors at the detection boundary using empirical processes. We demonstrate how the proposed testing procedure works in modeling and detecting weak distribution shifts in real datasets using two empirical examples: distribution shifts in consumer spending after COVID-19, and heterogeneity in the published p -values of statistical tests in journals across different disciplines.},
  archive      = {J_JBES},
  author       = {YoonHaeng Hur and Tengyuan Liang},
  doi          = {10.1080/07350015.2024.2335957},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {178-190},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Detecting weak distribution shifts via displacement interpolation},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Abadie’s kappa and weighting estimators of the local average
treatment effect. <em>JBES</em>, <em>43</em>(1), 164–177. (<a
href="https://doi.org/10.1080/07350015.2024.2332763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research has demonstrated the importance of flexibly controlling for covariates in instrumental variables estimation. In this article we study the finite sample and asymptotic properties of various weighting estimators of the local average treatment effect (LATE), motivated by Abadie’s kappa theorem and offering the requisite flexibility relative to standard practice. We argue that two of the estimators under consideration, which are weight normalized, are generally preferable. Several other estimators, which are unnormalized, do not satisfy the properties of scale invariance with respect to the natural logarithm and translation invariance, thereby exhibiting sensitivity to the units of measurement when estimating the LATE in logs and the centering of the outcome variable more generally. We also demonstrate that, when noncompliance is one sided, certain weighting estimators have the advantage of being based on a denominator that is strictly greater than zero by construction. This is the case for only one of the two normalized estimators, and we recommend this estimator for wider use. We illustrate our findings with a simulation study and three empirical applications, which clearly document the sensitivity of unnormalized estimators to how the outcome variable is coded. We implement the proposed estimators in the Stata package kappalate .},
  archive      = {J_JBES},
  author       = {Tymon Słoczyński and S. Derya Uysal and Jeffrey M. Wooldridge},
  doi          = {10.1080/07350015.2024.2332763},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {164-177},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Abadie’s kappa and weighting estimators of the local average treatment effect},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear spatial dynamic panel data models with endogenous
dominant units: An application to share data. <em>JBES</em>,
<em>43</em>(1), 150–163. (<a
href="https://doi.org/10.1080/07350015.2024.2329645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article develops a nonlinear spatial dynamic panel data model with one particularly interesting application to a structural interaction model for share data. To account for effects from dominant (popular) units, the spatial weights matrix in our model can allow for unbounded column sums. To account for heterogeneity, our model includes two-way fixed effects and heteroscedastic errors. We further consider the potential endogeneity of the spatial weight matrix constructed from socioeconomic distance. We investigate the quasi-maximum likelihood estimator (QMLE), generalized methods of moments estimator (GMME), and root estimator (RTE), and establish their consistency and asymptotic normality based on the near epoch dependence (NED) framework. The RTE can derive a relatively computationally simple and closed-form solution without evaluating the QMLE’s Jacobian matrix as well as the iterations by GMME. We consider both n , T → ∞ , and the strength of the dominant units is equal to 1 when T → ∞ . For the purpose of empirical analysis, we derive the marginal effects and their limiting distributions based on the proposed estimators. In an empirical application, we apply our model to China’s prefecture city-level data, revealing significant spillover effects of the tertiary industry share. These findings suggest that the development of the tertiary sector in large cities can foster its growth in small cities.},
  archive      = {J_JBES},
  author       = {Jiajun Zhang and Chuanmin Zhao and Xi Qu},
  doi          = {10.1080/07350015.2024.2329645},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {150-163},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Nonlinear spatial dynamic panel data models with endogenous dominant units: An application to share data},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating posterior sensitivities with application to
structural analysis of bayesian vector autoregressions. <em>JBES</em>,
<em>43</em>(1), 134–149. (<a
href="https://doi.org/10.1080/07350015.2024.2329639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent feature of Bayesian empirical analysis is the dependence of posterior inference on prior parameters, which researchers typically specify. However, quantifying the magnitude of this dependence remains difficult. This article extends Infinitesimal Perturbation Analysis, widely used in classical simulation, to compute asymptotically unbiased and consistent sensitivities of posterior statistics with respect to prior parameters from Markov chain Monte Carlo inference via Gibbs sampling. The method demonstrates the possibility of efficiently computing the complete set of prior sensitivities for a wide range of posterior statistics, alongside the estimation algorithm using Automatic Differentiation. The method’s application is exemplified in Bayesian Vector Autoregression analysis of fiscal policy in U.S. macroeconomic time series data. The analysis assesses the sensitivities of posterior estimates, including the Impulse response functions and Forecast error variance decompositions, to prior parameters under common Minnesota shrinkage priors. The findings illuminate the significant and intricate influence of prior specification on the posterior distribution. This effect is particularly notable in crucial posterior statistics, such as the substantial absolute eigenvalue of the companion matrix, ultimately shaping the structural analysis.},
  archive      = {J_JBES},
  author       = {Liana Jacobi and Dan Zhu and Mark Joshi},
  doi          = {10.1080/07350015.2024.2329639},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {134-149},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Estimating posterior sensitivities with application to structural analysis of bayesian vector autoregressions},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Panel data cointegration testing with structural
instabilities. <em>JBES</em>, <em>43</em>(1), 122–133. (<a
href="https://doi.org/10.1080/07350015.2024.2327844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spurious regression analysis in panel data when the time series are cross-section dependent is analyzed in the article. The set-up includes (possibly unknown) multiple structural breaks that can affect both the deterministic and the common factor components. We show that consistent estimation of the long-run average parameter is possible once cross-section dependence is controlled using cross-section averages in the spirit of Pesaran’s common correlated effects approach. This result is used to design individual and panel cointegration test statistics that accommodate the presence of structural breaks that can induce parameter instabilities in the deterministic component, the cointegration vector and the common factor loadings.},
  archive      = {J_JBES},
  author       = {Anindya Banerjee and Josep Lluís Carrion-i-Silvestre},
  doi          = {10.1080/07350015.2024.2327844},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {122-133},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Panel data cointegration testing with structural instabilities},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully data-driven normalized and exponentiated kernel
density estimator with hyvärinen score. <em>JBES</em>, <em>43</em>(1),
110–121. (<a
href="https://doi.org/10.1080/07350015.2024.2326149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Jewson and Rossell proposed a new approach for kernel density estimation using an exponentiated form of kernel density estimators. The density estimator contained two hyperparameters that flexibly controls the smoothness of the resulting density. We tune them in a data-driven manner by minimizing an objective function based on the Hyvärinen score to avoid the optimization involving the intractable normalizing constant caused by the exponentiation. We show the asymptotic properties of the proposed estimator and emphasize the importance of including the two hyperparameters for flexible density estimation. Our simulation studies and application to income data show that the proposed density estimator is promising when the underlying density is multi-modal or when observations contain outliers.},
  archive      = {J_JBES},
  author       = {Shunsuke Imai and Takuya Koriyama and Shouto Yonekura and Shonosuke Sugasawa and Yoshihiko Nishiyama},
  doi          = {10.1080/07350015.2024.2326149},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {110-121},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Fully data-driven normalized and exponentiated kernel density estimator with hyvärinen score},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reduced rank spatio-temporal models. <em>JBES</em>,
<em>43</em>(1), 98–109. (<a
href="https://doi.org/10.1080/07350015.2024.2326142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To simultaneously model the cross-sectional dependency and dynamic time dependency among n units, most research in spatial econometrics parameterizes the coefficient matrices among the n units as functions of known weights matrices. This modeling framework is over-simplified and faces the risk of misspecification when constructing the weights matrices. In this article, we propose a novel reduced-rank spatio-temporal model by assuming the coefficient matrices follow a reduced-rank structure. This specification avoids construction of the weights matrices and provides a good interpretation, especially for financial data. To estimate the unknown parameters, a quasi-maximum likelihood estimator (QMLE) is proposed and obtained via the Gradient descent algorithm with Armijo line search. We establish the asymptotic properties of QMLE when the number of units and the number of time periods both diverge to infinity. To determine the rank, we propose a ridge-type ratio estimator and demonstrate its rank selection consistency. The proposed methodology is illustrated via extensive simulation studies. Finally, a Chinese stock dataset is analyzed to investigate the cross-sectional and temporal spillover effects among stock returns.},
  archive      = {J_JBES},
  author       = {Dan Pu and Kuangnan Fang and Wei Lan and Jihai Yu and Qingzhao Zhang},
  doi          = {10.1080/07350015.2024.2326142},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {98-109},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Reduced rank spatio-temporal models},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantile policy effects: An application to u.s.
Macroprudential policy. <em>JBES</em>, <em>43</em>(1), 81–97. (<a
href="https://doi.org/10.1080/07350015.2024.2326140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To assess the dynamic distributional impacts of macroeconomic policy, we propose quantile policy effects to quantify disparities between the quantiles of potential outcomes under different policies. We first identify quantile policy effects under the unconfoundedness assumption and propose an inverse probability weighting estimator. We then examine the asymptotic behavior of the proposed estimator in a time series framework and suggest a blockwise bootstrap method for inference. Applying this method, we investigate the effectiveness of U.S. macroprudential actions on bank credit growth from 1948 to 2019. Empirically, we find that the effects of macroprudential policy on credit growth are asymmetric and depend on the quantiles of credit growth. The tightening of macroprudential actions fails to rein in high credit growth, whereas easing policies do not effectively stimulate bank credit growth during low-growth periods. These findings suggest that U.S. macroprudential policies might not sufficiently address the challenges of soaring bank credit or ensure overarching financial stability.},
  archive      = {J_JBES},
  author       = {Hsin-Yi Lin and Yu-Hsiang Hsiao and Yu-Chin Hsu},
  doi          = {10.1080/07350015.2024.2326140},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {81-97},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Quantile policy effects: An application to U.S. macroprudential policy},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grouped heterogeneity in linear panel data models with
heterogeneous error variances. <em>JBES</em>, <em>43</em>(1), 68–80. (<a
href="https://doi.org/10.1080/07350015.2024.2325440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a procedure to identify latent group structures in linear panel data models that exploits a grouping in the error variances of cross-sectional units. To accommodate such grouping, we introduce an objective function that avoids a singularity that arises in a pseudolikelihood approach. We provide theoretical and numerical evidence showing when allowing for variance groups improves classification. The developed procedure provides new evidence on the relation between firm-level research and development (R&amp;D) investments and the business cycle. We find a well-defined group structure in the variances that ex-post can be related to firm size. Our estimates indicate stronger procyclical investment patterns at medium-size firms compared to large firms.},
  archive      = {J_JBES},
  author       = {Jhordano Aguilar Loyo and Tom Boot},
  doi          = {10.1080/07350015.2024.2325440},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {68-80},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Grouped heterogeneity in linear panel data models with heterogeneous error variances},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing many zero restrictions in a high dimensional linear
regression setting. <em>JBES</em>, <em>43</em>(1), 55–67. (<a
href="https://doi.org/10.1080/07350015.2024.2325436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a test of many zero parameter restrictions in a high dimensional linear iid regression model with k ≫ n regressors. The test statistic is formed by estimating key parameters one at a time based on many low dimension regression models with nuisance terms. The parsimoniously parameterized models identify whether the original parameter of interest is or is not zero. Estimating fixed low dimension sub-parameters ensures greater estimator accuracy, it does not require a sparsity assumption nor therefore a regularized estimator, it is computationally fast compared to, for example, de-biased Lasso, and using only the largest in a sequence of weighted estimators reduces test statistic complexity and therefore estimation error. We provide a parametric wild bootstrap for p -value computation, and prove the test is consistent and has nontrivial n / { ln ( n ) M n } -local-to-null power where M n is the l ∞ covariate fourth moment.},
  archive      = {J_JBES},
  author       = {Jonathan B. Hill},
  doi          = {10.1080/07350015.2024.2325436},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {55-67},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Testing many zero restrictions in a high dimensional linear regression setting},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A statistically identified structural vector autoregression
with endogenously switching volatility regime. <em>JBES</em>,
<em>43</em>(1), 44–54. (<a
href="https://doi.org/10.1080/07350015.2024.2322090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a structural vector autoregressive model with endogenously switching conditional covariance matrix. The structural shocks are identified by simultaneously diagonalizing the reduced form error covariance matrices. It is not, however, always clear whether the condition for the full statistical identification is satisfied, and its validity is difficult to justify formally. Therefore, we provide general sets of conditions, that allow to combine sign and zero restrictions on the impact matrix, for identifying a subset of the shocks when the condition for statistical identification of the model fails. In an empirical application to the effects of the U.S. monetary policy shock, we find that a contractionary monetary policy shock significantly decreases output in a persistent hump-shaped pattern. Prices decrease permanently, but there is short-run inertia in their response. The accompanying R package gmvarkit provides a comprehensive set of tools for numerical analysis of the model.},
  archive      = {J_JBES},
  author       = {Savi Virolainen},
  doi          = {10.1080/07350015.2024.2322090},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {44-54},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {A statistically identified structural vector autoregression with endogenously switching volatility regime},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian process vector autoregressions and macroeconomic
uncertainty. <em>JBES</em>, <em>43</em>(1), 27–43. (<a
href="https://doi.org/10.1080/07350015.2024.2322089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop a nonparametric multivariate time series model that remains agnostic on the precise relationship between a (possibly) large set of macroeconomic time series and their lagged values. The main building block of our model is a Gaussian process prior on the functional relationship that determines the conditional mean of the model, hence, the name of Gaussian process vector autoregression (GP-VAR). A flexible stochastic volatility specification is used to provide additional flexibility and control for heteroscedasticity. Markov chain Monte Carlo (MCMC) estimation is carried out through an efficient and scalable algorithm which can handle large models. The GP-VAR is used to analyze the effects of macroeconomic uncertainty, with a particular emphasis on time variation and asymmetries in the transmission mechanisms.},
  archive      = {J_JBES},
  author       = {Niko Hauzenberger and Florian Huber and Massimiliano Marcellino and Nico Petz},
  doi          = {10.1080/07350015.2024.2322089},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {27-43},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Gaussian process vector autoregressions and macroeconomic uncertainty},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gamma-driven markov processes and extensions with
application to realized volatility. <em>JBES</em>, <em>43</em>(1),
14–26. (<a href="https://doi.org/10.1080/07350015.2024.2321375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel class of Markov processes for dealing with continuous positive time series data, which is constructed based on a latent gamma effect and named gamma-driven (GD) models. The GD processes possess desirable properties and features: (i) it can produce any desirable invariant distribution with support on R + , (ii) it is time-reversible, and (iii) it has the transition density function given in an explicit form. Estimation of parameters is performed through the maximum likelihood method combined with a Gauss Laguerre quadrature to approximate the likelihood function. The evaluation of the estimators and also confidence intervals of parameters are explored via Monte Carlo simulation studies. Two generalizations of the GD processes are also proposed to handle nonstationary and long-memory time series. We apply the proposed methodologies to analyze the daily realized volatility of the FTSE 100 equity index.},
  archive      = {J_JBES},
  author       = {Fernanda G. B. Mendes and Wagner Barreto-Souza and Sokol Ndreca},
  doi          = {10.1080/07350015.2024.2321375},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {14-26},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Gamma-driven markov processes and extensions with application to realized volatility},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Max share identification of multiple shocks: An application
to uncertainty and financial conditions. <em>JBES</em>, <em>43</em>(1),
1–13. (<a href="https://doi.org/10.1080/07350015.2024.2316829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We generalize the Max Share approach to allow for simultaneous identification of a multiplicity of shocks in a Structural Vector Autoregression. Our machinery therefore overcomes the well-known drawbacks that individually identified shocks (i) tend to be correlated to each other or (ii) can be separated under orthogonalizations with weak economic ground. We show that identification corresponds to solving a nontrivial optimization problem. We provide conditions for non-emptiness of solutions and point-identification, and Bayesian algorithms for estimation and inference. We use the approach to study the effects of uncertainty and financial shocks, allowing for the possibility that the former responds contemporaneously to other shocks, distinguishing macroeconomic from financial uncertainty and credit supply shocks. Using U.S. data we find that financial uncertainty mimics a demand shock, while the interpretation of macro uncertainty is more mixed. Furthermore, variation in uncertainty partially represents the endogenous response of uncertainty to other shocks.},
  archive      = {J_JBES},
  author       = {Andrea Carriero and Alessio Volpicella},
  doi          = {10.1080/07350015.2024.2316829},
  journal      = {Journal of Business &amp; Economic Statistics},
  month        = {1},
  number       = {1},
  pages        = {1-13},
  shortjournal = {J. Busin. Econ. Stat.},
  title        = {Max share identification of multiple shocks: An application to uncertainty and financial conditions},
  volume       = {43},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
