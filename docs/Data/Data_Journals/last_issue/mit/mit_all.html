<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>mit_all</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h1 id="mit">MIT</h1>
<h2 id="alj---8">ALJ - 8</h2>
<ul>
<li><details>
<summary>
(2025). Survival and evolutionary adaptation of populations under
disruptive habitat change: A study with darwinian cellular automata.
<em>ALJ</em>, <em>31</em>(1), 106–123. (<a
href="https://doi.org/10.1162/artl_a_00457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of living beings with continuous and consistent progress toward adaptation and ways to model evolution along principles as close as possible to Darwin’s are important areas of focus in Artificial Life. Though genetic algorithms and evolutionary strategies are good methods for modeling selection, crossover, and mutation, biological systems are undeniably spatially distributed processes in which living organisms interact with locally available individuals rather than with the entire population at once. This work presents a model for the survival of organisms during a change in the environment to a less favorable one, putting them at risk of extinction, such as many organisms experience today under climate change or local habitat loss or fragmentation. Local spatial structure of resources and environmental quality also impacts the capacity of an evolving population to adapt. The problem is considered on a probabilistic cellular automaton with update rules based on the principles of genetic algorithms. To carry out simulations according to the described model, the Darwinian cellular automata are introduced, and the software has been designed with the code available open source. An experimental evaluation of the behavioral characteristics of the model was carried out, completed by a critical evaluation of the results obtained, parametrically describing conditions and thresholds under which extinction or survival of the population may occur.},
  archive      = {J_ALJ},
  author       = {Derets, Hanna and Nehaniv, Chrystopher L.},
  doi          = {10.1162/artl_a_00457},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {106-123},
  shortjournal = {Artif. Life},
  title        = {Survival and evolutionary adaptation of populations under disruptive habitat change: A study with darwinian cellular automata},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergence of self-replicating hierarchical structures in a
binary cellular automaton. <em>ALJ</em>, <em>31</em>(1), 96–105. (<a
href="https://doi.org/10.1162/artl_a_00449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have discovered a novel transition rule for binary cellular automata (CAs) that yields self-replicating structures across two spatial and temporal scales from sparse random initial conditions. Lower-level, shape-shifting clusters frequently follow a transient attractor trajectory, generating new clusters, some of which periodically self-duplicate. When the initial distribution of live cells is sufficiently sparse, these clusters coalesce into larger formations that also self-replicate. These formations may further form the boundaries of an expanding complex on an even larger scale. This rule, dubbed “Outlier,” is rotationally symmetric and applies to 2-D Moore neighborhoods. It was evolved through genetic programming during an extensive search for rules that foster open-ended evolution in CAs. While self-replicating structures, both crafted and emergent, have been created in CAs with state sets intentionally designed for this purpose, the Outlier may be the first known rule to facilitate nontrivial emergent self-replication across two spatial scales in binary CAs.},
  archive      = {J_ALJ},
  author       = {Yang, Bo},
  doi          = {10.1162/artl_a_00449},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {96-105},
  shortjournal = {Artif. Life},
  title        = {Emergence of self-replicating hierarchical structures in a binary cellular automaton},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-reproduction and evolution in cellular automata: 25
years after evoloops. <em>ALJ</em>, <em>31</em>(1), 81–95. (<a
href="https://doi.org/10.1162/artl_a_00451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The year 2024 marks the 25th anniversary of the publication of evoloops, an evolutionary variant of Chris Langton’s self-reproducing loops, which proved constructively that Darwinian evolution of self-reproducing organisms by variation and natural selection is possible within deterministic cellular automata. Over the last few decades, this line of Artificial Life research has since undergone several important developments. Although it experienced a relative dormancy of activity for a while, the recent rise of interest in open-ended evolution and the success of continuous cellular automata models have brought researchers’ attention back to how to make spatiotemporal patterns self-reproduce and evolve within spatially distributed computational media. This article provides a review of the relevant literature on this topic over the past 25 years and highlights the major accomplishments made so far, the challenges being faced, and promising future research directions.},
  archive      = {J_ALJ},
  author       = {Sayama, Hiroki and Nehaniv, Chrystopher L.},
  doi          = {10.1162/artl_a_00451},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {81-95},
  shortjournal = {Artif. Life},
  title        = {Self-reproduction and evolution in cellular automata: 25 years after evoloops},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cell–cell interactions: How coupled boolean networks tend to
criticality. <em>ALJ</em>, <em>31</em>(1), 68–80. (<a
href="https://doi.org/10.1162/artl_a_00444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biological cells are usually operating in conditions characterized by intercellular signaling and interaction, which are supposed to strongly influence individual cell dynamics. In this work, we study the dynamics of interacting random Boolean networks, focusing on attractor properties and response to perturbations. We observe that the properties of isolated critical Boolean networks are substantially maintained also in interaction settings, while interactions bias the dynamics of chaotic and ordered networks toward that of critical cells. The increase in attractors observed in multicellular scenarios, compared to single cells, allows us to hypothesize that biological processes, such as ontogeny and cell differentiation, leverage interactions to modulate individual and collective cell responses.},
  archive      = {J_ALJ},
  author       = {Braccini, Michele and Baldini, Paolo and Roli, Andrea},
  doi          = {10.1162/artl_a_00444},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {68-80},
  shortjournal = {Artif. Life},
  title        = {Cell–Cell interactions: How coupled boolean networks tend to criticality},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial: Special issue “the distributed ghost”—cellular
automata, distributed dynamical systems, and their applications to
intelligence. <em>ALJ</em>, <em>31</em>(1), 65–67. (<a
href="https://doi.org/10.1162/artl_e_00450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed dynamical systems like cellular automata (CAs) and random boolean networks (RBNs) (and everything in between) have long been used as models to understand computation and self-replication in biology, morphogenesis, gene regulation, life-as-it-could-be, and the Universe.Such complex system models have been extensively studied mathematically and experimentally in all their different variations, such as synchronous and asynchronous updates and dynamic automata networks that can grow and change their structure, including components and interconnection topology, as well as their robustness.Wuensche (1994) investigated the basins of attraction of CAs and RBNs and even suggested that they are the “ghost in the machine.”Recent advances in such models, including continuous CAs, such as Lenia (Chan, 2019), and neural-based CAs (Mordvintsev et al., 2020), have been proposed as substrates to study the emergence of a more general intelligence (Gregor &amp;amp; Besse, 2021; Hamon et al., 2022), thanks to their propensity to support properties like self-organization, emergence, and open-endedness.But what can we learn from CAs and distributed dynamical system models about intelligence? And how can CAs and distributed dynamical system models be used to study the emergence of intelligence?To address such questions, we organized a workshop at the 2023 Artificial Life conference in Sapporo, Japan, that aimed to bridge the gap between the ALife community working with CAs and distributed dynamical systems and the broader artificial intelligence (AI) community interested in exploring concepts from complex systems, self-organization, and Artificial Life for AI research and machine learning.The workshop was named “The Distributed Ghost,” inspired by the Artificial Life conference theme “Ghost in the Machine.” The workshop program (Nichele et al., 2023) consisted of two invited keynotes, by Bert Chan and Andrea Roli, and a set of 10 abstract-based presentations. After the workshop, four high-quality contributions were extended as full papers and have been collected in this special issue.In “Cell-Cell Interactions: How Coupled Boolean Networks Tend to Criticality,” Braccini and coauthors investigate interacting RBNs as a theoretical model of multicellular biological systems with cell–cell interactions. They find not only that the interacting versions of RBNs show the same general trends of dynamical properties as their individual counterparts but also that the networks in ordered or chaotic regimes tend toward a critical regime when turned into interacting networks (while individually critical networks remain critical). This result suggests the importance of the interconnected nature of a distributed multicellular system for its system-level criticality (and thus biological functioning) as a whole.In “Emergence of Self-Replicating Hierarchical Structures in a Binary Cellular Automaton,” using genetic programming to explore the vast space of binary CAs (with Moore neighborhood and rotationally symmetric rule sets in two dimensions) for open-ended temporal evolution, Yang reports on the discovery of a novel CA rule, the “Outlier.” Most strikingly, this CA and therefore also its distinct chiral twin (obtained by mirroring the rule table) are unique among known models of self-replication in that structures exhibit replication across two different nested spatiotemporal scales. Moreover, the self-replicating structures appear from sparse random initial conditions and follow characteristic attractor trajectories involving such multiscale self-replication.In “Survival and Evolutionary Adaptation of Populations Under Disruptive Habitat Change: A Study With Darwinian Cellular Automata,” Derets and Nehaniv focus on the evolution of living beings, emphasizing continuous adaptation akin to Darwinian principles within the domain of Artificial Life. The introduced model addresses the survival of organisms amid environmental changes, particularly during transitions to less favorable conditions (modeled using percolation theory). A probabilistic CA is employed based on update rules derived from genetic algorithm principles. Finally, an experimental investigation of the model’s behavioral features is presented, analyzing parameters and thresholds governing population survival or extinction outcomes.In “Self-Reproduction and Evolution in Cellular Automata: 25 Years After Evoloops,” Sayama and Nehaniv offer a comprehensive review of advancements in CAs subjected to Darwinian evolution. The contribution marks the 25th anniversary of the seminal work on evoloops (Sayama, 1999). The review highlights significant developments, ongoing challenges, and prospective research avenues in Artificial Life, focusing on self-reproducing and evolving patterns in distributed computational environments.We are continuing the tradition of the “distributed series” in 2024 by organizing a special session named “The Distributed Viking” at the Artificial Life conference in Copenhagen, Denmark. More information can be found at the special session web page (https://www.nichele.eu/ALIFE-DistributedViking/).},
  archive      = {J_ALJ},
  author       = {Nichele, Stefano and Sayama, Hiroki and Medvet, Eric and Nehaniv, Chrystopher and Pavone, Mario},
  doi          = {10.1162/artl_e_00450},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {65-67},
  shortjournal = {Artif. Life},
  title        = {Editorial: Special issue “The distributed Ghost”—Cellular automata, distributed dynamical systems, and their applications to intelligence},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guideless artificial life model for reproduction,
development, and interactions. <em>ALJ</em>, <em>31</em>(1), 31–64. (<a
href="https://doi.org/10.1162/artl_a_00466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reproduction, development, and individual interactions are vital yet complex natural processes. Tierra (an ALife model proposed by Thomas Ray) and cellular automata, which can manage these aspects in a complex manner, are significantly limited in their ability to express morphology and behavior. In contrast, the virtual creatures proposed by Karl Sims have a considerably higher degree of freedom in terms of morphology and behavior. However, they also exhibit a limited capacity for processes like reproduction, development, and individual interactions. In addition, they employ genetic algorithms, which can result in a loss of biological diversity, as their implementation necessitates predefining a fitness function. Contrarily, the evolution of natural life is determined by mutation and natural selection, rather than by a human-defined fitness function. This study carefully extracts the characteristics of these models to propose a new Artificial Life model that can simulate reproduction, development, and individual interactions while exhibiting a high expressive power for morphology and behavior. The model is based on the concept of incorporating Tierra and cellular automata mechanisms into a cell that moves freely in 3-D space. In this model, no predefined fitness function or form that qualifies as a living creature exists. In other words, this approach can be rephrased as searching for persistent patterns, which is similar to the approach of Conway’s Game of Life. The primary objective of this study was to conduct a proof-of-concept demonstration to showcase the capabilities of this model. Guideless simulation by the proposed model using mutation and natural selection resulted in the formation of two types of creatures—dumbbell shaped and reticulated. These creatures exhibit intriguing features, exploiting the degrees of freedom inherent to the proposed model. Particularly noteworthy is their unique method of reproduction, which bears a striking resemblance to that of real organisms. These results reinforce the potential of this approach in modeling intricate processes observed in actual organisms and its ability to generate virtual creatures with intriguing ecologies.},
  archive      = {J_ALJ},
  author       = {Utimula, Keishu},
  doi          = {10.1162/artl_a_00466},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {31-64},
  shortjournal = {Artif. Life},
  title        = {Guideless artificial life model for reproduction, development, and interactions},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling the mutation and competition of certain
nutrient-producing protocells by means of specific turing machines.
<em>ALJ</em>, <em>31</em>(1), 2–30. (<a
href="https://doi.org/10.1162/artl_a_00463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is very important to model the behavior of protocells as basic lifelike artificial organisms more and more accurately from the level of genomes to the level of populations. A better understanding of basic protocell communities may help us in describing more complex ecological systems accurately. In this article, we propose a new comprehensive, bilevel mathematical model of a community of three protocell species (one generalist and two specialists ). The aim is to achieve a model that is as basic/fundamental as possible while already displaying mutation, selection, and complex population dynamics phenomena (like competitive exclusion and keystone species). At the microlevel of genetic codes, the protocells and their mutations are modeled with Turing machines (TMs). The specialists arise from the generalist by means of mutation. Then the species are put into a common habitat, where, at the macrolevel of populations, they have to compete for the available nutrients, a part of which they themselves can produce. Because of different kinds of mutations, the running times of the species as TMs (algorithms) are different. This feature is passed on to the macrolevel as different reproduction times. At the macrolevel, a discrete-time dynamic model describes the competition. The model displays complex lifelike behavior known from population ecology, including the so-called competitive exclusion principle and the effect of keystone species. In future works, the bilevel model will have a good chance of serving as a simple and useful tool for studying more lifelike phenomena (like evolution) in their pure/abstract form.},
  archive      = {J_ALJ},
  author       = {Kicsiny, Richárd and Hufnagel, Levente and Lóczi, Lajos and Székely, László and Varga, Zoltán},
  doi          = {10.1162/artl_a_00463},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {2-30},
  shortjournal = {Artif. Life},
  title        = {Modeling the mutation and competition of certain nutrient-producing protocells by means of specific turing machines},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A word from the editors. <em>ALJ</em>, <em>31</em>(1), 1.
(<a href="https://doi.org/10.1162/artl_e_00469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This issue comprises two parts.A series of articles form a special issue on “The Distributed Ghost,” an outcome of a workshop held at the 2023 Artificial Life conference in Sapporo, Japan. This has been compiled by editors Stefano Nichele, Hiroki Sayama, Eric Medvet, Chrystopher Nehaniv, and Mario Pavone. Two preceding standard research articles neatly align with the special issue in that they also consider the dynamics of interacting biological systems using traditional computational approaches (cellular automata, Tierra-like assembly languages, feed-forward neural networks, and Turing machines) for modeling activities, from a behavioral rather than an intelligential perspective. Tackling central themes of ALife, they study the emergence of persistent morphologies and the behaviors of mutant specialists and generalists competing for resources in a well-mixed environment. These articles demonstrate two approaches to investigating attributes of interacting populations of simple computational, protocellular creatures.},
  archive      = {J_ALJ},
  author       = {Dorin, Alan and Stepney, Susan},
  doi          = {10.1162/artl_e_00469},
  journal      = {Artificial Life},
  month        = {2},
  number       = {1},
  pages        = {1},
  shortjournal = {Artif. Life},
  title        = {A word from the editors},
  volume       = {31},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="coli---9">COLI - 9</h2>
<ul>
<li><details>
<summary>
(2025). Automatic language identification in texts. <em>COLI</em>,
<em>51</em>(1), 339–341. (<a
href="https://doi.org/10.1162/coli_r_00521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language identification (LI) for text data, in the ideal scenario, determines the human languages used at every location in a corpus. In practice this often means choosing the likeliest language at the document level: This is already quite useful, for example, when presenting a webpage to the user and deciding (a) whether to translate it and (b) which model to use for that purpose. However, nuances like code-switching (language alternation), dialect variation, and ambiguously short content are increasingly common with the ubiquity of digital communication like text messaging and micro-blogs. Geographic areas like Africa and the Indian subcontinent bring enormous linguistic diversity and flexibility that break the document-level LI paradigm. While standard references (Jurafsky and Martin 2023) introduce LI, touch on these subtleties, and often present related methods and models in other contexts, Automatic Language Identification in Texts is specifically dedicated to LI in its full practical variety.In the course of producing a broad and thorough survey, perhaps the most striking takeaway from Jauhiainen et al. is the chaotic state of research on this critical task. This might be due to the view that, for digitally well-attested languages occurring in domains with monolingual documents of at least modest length, LI is solved: These circumstances are common, and the emphasis on massive data sets can make the rarer cases seem less important. When challenges arise in specific, applied downstream research, they are often addressed in an ad hoc fashion, such as through active learning techniques for gathering human annotations or linear programming to incorporate prior knowledge (Lippincott and Van Durme 2016), without consolidation into broader outcomes for the research community. Throughout Automatic Language Identification in Texts, the authors have the consistent goal of improving this situation. The book is structured into six chapters:Chapter 1 introduces the history of LI, stretching from early feature-engineering approaches to still-standard models based on character n-grams closely related to fundamental models of communication (Shannon 1948), and the burgeoning collection of shared tasks aimed at specific domains, such as ancient scripts or regional dialects. Unlike much of machine learning for natural language processing tasks, traditional models have remained highly competitive for LI compared with deep neural networks: perhaps data sparsity prevents effective training, or traditional features are already well-suited for LI. Downstream use-cases and challenges are summarized, with copious citations to prior and ongoing work.Chapter 2 begins with the authors’ efforts to standardize the discourse around LI by specifying a common notation that subsumes the variety utilized in the literature. While the notation is a modest shift from those that treat data as a sequence of fully distinct documents, treating documents as boundaries within a single large sequence of characters consolidates the spectrum of methods that will be covered. In terms of linguistic features, the focus is on character n-grams, and the authors address several standard concerns: weighting, smoothing, and incorporating linguistic knowledge. The latter is particularly interesting and perhaps under-explored, since there is often less practical motivation to move beyond the immediate use-case and consider, for example, the phylogenetic structure of world languages. The bulk of the chapter is devoted to describing a wide range of classification methods that use these features, some standard (e.g., logistic regression, naive Bayes), others the specific ensembles or statistical tests adopted by existing research.Chapter 3 addresses evaluation, the other end of the experimental pipeline that requires standardization. While a handful of metrics have been used historically, most research has converged on macro balanced F-score, which equally weights precision and recall as well as performance on each language. In the absence of a clearly articulated reason to do otherwise, this is the most even-handed approach. The bulk of the chapter is devoted to a survey of standard data sets and shared tasks, both historical and ongoing. This is a useful reference for researchers in search of venues aimed at their specific goals, or looking for broader patterns in outcomes.Chapter 4 considers the primary axes that may elevate LI from “solved” to “challenging”: language similarity, low-resource languages, orthographic systems and variation, short text, and code-switching. Some of these involve questions of representation: What do we treat as a “language”? What is the “correct” label of a short text that’s valid in multiple languages, such as “quando?”, which is a common question in Portuguese and Italian? How should one label a text containing multiple languages, such as “I’ll ask mi hombre next time I see him”? Chapter 5 then considers the pursuit of a maximally general model capable of characterizing massive collections of heterogeneous content, unknown languages, and domain shift.Chapter 6 discusses several prominent or otherwise compelling uses of LI, from the pragmatic needs of machine translation to subtle tasks like determining the native language based on characteristic patterns in a second language. For instance, corpora of writing from known L2 speakers of English are widespread due to the popularity of English as a second language throughout education, allowing the study of orthographic mistakes grounded in phonetic properties of a native language. Stylistics and authorship attribution share useful features with LI, as they strive to avoid learning topical properties that are often correlated with language.The authors conclude by reiterating the diversity of phenomena that existing LI techniques rarely treat as first-order challenges (until they become immediately relevant), and the difficulty of drawing broader conclusions from the current literature. The book effectively catalogues these challenges and heterogeneity while also providing a stable reference for the community working to organize and extend research in this area. This is useful for several audiences and purposes: Students seeking to understand the history and landscape of LIResearchers hoping to unify or extend existing methodsPractitioners or stakeholders who need to select and justify an approach to a specific taskThe only notable “limitation” of the book is in fact endemic to the topic: The poorly mapped variety of LI research is naturally going to show through any thorough survey. The authors are up-front about this state of affairs and succeed at improving on it.},
  archive      = {J_COLI},
  author       = {Lippincott, Tom},
  doi          = {10.1162/coli_r_00521},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {339-341},
  shortjournal = {Comput. Lingu.},
  title        = {Automatic language identification in texts},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey on LLM-generated text detection: Necessity,
methods, and future directions. <em>COLI</em>, <em>51</em>(1), 275–338.
(<a href="https://doi.org/10.1162/coli_a_00549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The remarkable ability of large language models (LLMs) to comprehend, interpret, and generate complex language has rapidly integrated LLM-generated text into various aspects of daily life, where users increasingly accept it. However, the growing reliance on LLMs underscores the urgent need for effective detection mechanisms to identify LLM-generated text. Such mechanisms are critical to mitigating misuse and safeguarding domains like artistic expression and social networks from potential negative consequences. LLM-generated text detection, conceptualized as a binary classification task, seeks to determine whether an LLM produced a given text. Recent advances in this field stem from innovations in watermarking techniques, statistics-based detectors, and neural-based detectors. Human-assisted methods also play a crucial role. In this survey, we consolidate recent research breakthroughs in this field, emphasizing the urgent need to strengthen detector research. Additionally, we review existing datasets, highlighting their limitations and developmental requirements. Furthermore, we examine various LLM-generated text detection paradigms, shedding light on challenges like out-of-distribution problems, potential attacks, real-world data issues, and ineffective evaluation frameworks. Finally, we outline intriguing directions for future research in LLM-generated text detection to advance responsible artificial intelligence. This survey aims to provide a clear and comprehensive introduction for newcomers while offering seasoned researchers valuable updates in the field. 1},
  archive      = {J_COLI},
  author       = {Wu, Junchao and Yang, Shu and Zhan, Runzhe and Yuan, Yulin and Chao, Lidia Sam and Wong, Derek Fai},
  doi          = {10.1162/coli_a_00549},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {275-338},
  shortjournal = {Comput. Lingu.},
  title        = {A survey on LLM-generated text detection: Necessity, methods, and future directions},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural semantic parsing with extremely rich symbolic meaning
representations. <em>COLI</em>, <em>51</em>(1), 235–274. (<a
href="https://doi.org/10.1162/coli_a_00542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current open-domain neural semantics parsers show impressive performance. However, closer inspection of the symbolic meaning representations they produce reveals significant weaknesses: Sometimes they tend to merely copy character sequences from the source text to form symbolic concepts, defaulting to the most frequent word sense based in the training distribution. By leveraging the hierarchical structure of a lexical ontology, we introduce a novel compositional symbolic representation for concepts based on their position in the taxonomical hierarchy. This representation provides richer semantic information and enhances interpretability. We introduce a neural “taxonomical” semantic parser to utilize this new representation system of predicates, and compare it with a standard neural semantic parser trained on the traditional meaning representation format, employing a novel challenge set and evaluation metric for evaluation. Our experimental findings demonstrate that the taxonomical model, trained on much richer and complex meaning representations, is slightly subordinate in performance to the traditional model using the standard metrics for evaluation, but outperforms it when dealing with out-of-vocabulary concepts. We further show through neural model probing that training on a taxonomic representation enhances the model’s ability to learn the taxonomical hierarchy. This finding is encouraging for research in computational semantics that aims to combine data-driven distributional meanings with knowledge-based symbolic representations.},
  archive      = {J_COLI},
  author       = {Zhang, Xiao and Bouma, Gosse and Bos, Johan},
  doi          = {10.1162/coli_a_00542},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {235-274},
  shortjournal = {Comput. Lingu.},
  title        = {Neural semantic parsing with extremely rich symbolic meaning representations},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating synthetic data generation from user generated
text. <em>COLI</em>, <em>51</em>(1), 191–233. (<a
href="https://doi.org/10.1162/coli_a_00540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User-generated content provides a rich resource to study social and behavioral phenomena. Although its application potential is currently limited by the paucity of expert labels and the privacy risks inherent in personal data, synthetic data can help mitigate this bottleneck. In this work, we introduce an evaluation framework to facilitate research on synthetic language data generation for user-generated text. We define a set of aspects for assessing data quality, namely, style preservation, meaning preservation, and divergence, as a proxy for privacy. We introduce metrics corresponding to each aspect. Moreover, through a set of generation strategies and representative tasks and baselines across domains, we demonstrate the relation between the quality aspects of synthetic user generated content, generation strategies, metrics, and downstream performance. To our knowledge, our work is the first unified evaluation framework for user-generated text in relation to the specified aspects, offering both intrinsic and extrinsic evaluation. We envisage it will facilitate developments towards shareable, high-quality synthetic language data.},
  archive      = {J_COLI},
  author       = {Chim, Jenny and Ive, Julia and Liakata, Maria},
  doi          = {10.1162/coli_a_00540},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {191-233},
  shortjournal = {Comput. Lingu.},
  title        = {Evaluating synthetic data generation from user generated text},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compositionality and sentence meaning: Comparing semantic
parsing and transformers on a challenging sentence similarity dataset.
<em>COLI</em>, <em>51</em>(1), 139–190. (<a
href="https://doi.org/10.1162/coli_a_00536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major outstanding questions in computational semantics is how humans integrate the meaning of individual words into a sentence in a way that enables understanding of complex and novel combinations of words, a phenomenon known as compositionality. Many approaches to modeling the process of compositionality can be classified as either “vector-based” models, in which the meaning of a sentence is represented as a vector of numbers, or “syntax-based” models, in which the meaning of a sentence is represented as a structured tree of labeled components. A major barrier in assessing and comparing these contrasting approaches is the lack of large, relevant datasets for model comparison. This article aims to address this gap by introducing a new dataset, STS3k, which consists of 2,800 pairs of sentences rated for semantic similarity by human participants. The sentence pairs have been selected to systematically vary different combinations of words, providing a rigorous test and enabling a clearer picture of the comparative strengths and weaknesses of vector-based and syntax-based methods. Our results show that when tested on the new STS3k dataset, state-of-the-art transformers poorly capture the pattern of human semantic similarity judgments, while even simple methods for combining syntax- and vector-based components into a novel hybrid model yield substantial improvements. We further show that this improvement is due to the ability of the hybrid model to replicate human sensitivity to specific changes in sentence structure. Our findings provide evidence for the value of integrating multiple methods to better reflect the way in which humans mentally represent compositional meaning.},
  archive      = {J_COLI},
  author       = {Fodor, James and Deyne, Simon De and Suzuki, Shinsuke},
  doi          = {10.1162/coli_a_00536},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {139-190},
  shortjournal = {Comput. Lingu.},
  title        = {Compositionality and sentence meaning: Comparing semantic parsing and transformers on a challenging sentence similarity dataset},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine translation meta evaluation through translation
accuracy challenge sets. <em>COLI</em>, <em>51</em>(1), 73–137. (<a
href="https://doi.org/10.1162/coli_a_00537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent machine translation (MT) metrics calibrate their effectiveness by correlating with human judgment. However, these results are often obtained by averaging predictions across large test sets without any insights into the strengths and weaknesses of these metrics across different error types. Challenge sets are used to probe specific dimensions of metric behavior but there are very few such datasets and they either focus on a limited number of phenomena or a limited number of language pairs. We introduce ACES , a contrastive challenge set spanning 146 language pairs, aimed at discovering whether metrics can identify 68 translation accuracy errors. These phenomena range from basic alterations at the word/character level to more intricate errors based on discourse and real-world knowledge. We conducted a large-scale study by benchmarking ACES on 47 metrics submitted to the WMT 2022 and WMT 2023 metrics shared tasks. We also measure their sensitivity to a range of linguistic phenomena. We further investigate claims that large language models (LLMs) are effective as MT evaluators, addressing the limitations of previous studies by using a dataset that covers a range of linguistic phenomena and language pairs and includes both low- and medium-resource languages. Our results demonstrate that different metric families struggle with different phenomena and that LLM-based methods are unreliable. We expose a number of major flaws with existing methods: Most metrics ignore the source sentence; metrics tend to prefer surface level overlap; and over-reliance on language-agnostic representations leads to confusion when the target language is similar to the source language. To further encourage detailed evaluation beyond singular scores, we expand ACES to include error span annotations, denoted as SPAN-ACES, and we use this dataset to evaluate span-based error metrics, showing that these metrics also need considerable improvement. Based on our observations, we provide a set of recommendations for building better MT metrics, including focusing on error labels instead of scores, ensembling, designing metrics to explicitly focus on the source sentence, focusing on semantic content rather than relying on the lexical overlap, and choosing the right pre-trained model for obtaining representations.},
  archive      = {J_COLI},
  author       = {Moghe, Nikita and Fazla, Arnisa and Amrhein, Chantal and Kocmi, Tom and Steedman, Mark and Birch, Alexandra and Sennrich, Rico and Guillou, Liane},
  doi          = {10.1162/coli_a_00537},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {73-137},
  shortjournal = {Comput. Lingu.},
  title        = {Machine translation meta evaluation through translation accuracy challenge sets},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ERST: A signaled graph theory of discourse relations and
organization. <em>COLI</em>, <em>51</em>(1), 23–72. (<a
href="https://doi.org/10.1162/coli_a_00538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article we present Enhanced Rhetorical Structure Theory (eRST), a new theoretical framework for computational discourse analysis, based on an expansion of Rhetorical Structure Theory (RST). The framework encompasses discourse relation graphs with tree-breaking, non-projective and concurrent relations, as well as implicit and explicit signals which give explainable rationales to our analyses. We survey shortcomings of RST and other existing frameworks, such as Segmented Discourse Representation Theory, the Penn Discourse Treebank, and Discourse Dependencies, and address these using constructs in the proposed theory. We provide annotation, search, and visualization tools for data, and present and evaluate a freely available corpus of English annotated according to our framework, encompassing 12 spoken and written genres with over 200K tokens. Finally, we discuss automatic parsing, evaluation metrics, and applications for data in our framework.},
  archive      = {J_COLI},
  author       = {Zeldes, Amir and Aoyama, Tatsuya and Liu, Yang Janet and Peng, Siyao and Das, Debopam and Gessler, Luke},
  doi          = {10.1162/coli_a_00538},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {23-72},
  shortjournal = {Comput. Lingu.},
  title        = {ERST: A signaled graph theory of discourse relations and organization},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MUCking in, or fifty years in information extraction.
<em>COLI</em>, <em>51</em>(1), 7–22. (<a
href="https://doi.org/10.1162/coli_a_00547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I want to thank the ACL for this Lifetime Achievement Award. I am deeply honored to be receiving it. I would also like to thank the students, faculty, and researchers who were members of the Proteus Project during most of my professional lifetime. It was an honor to serve that group.},
  archive      = {J_COLI},
  author       = {Grishman, Ralph},
  doi          = {10.1162/coli_a_00547},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {7-22},
  shortjournal = {Comput. Lingu.},
  title        = {MUCking in, or fifty years in information extraction},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Opening a new chapter for computational linguistics.
<em>COLI</em>, <em>51</em>(1), 1–5. (<a
href="https://doi.org/10.1162/coli_e_00552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By the end of 2024, the journal Computational Linguistics has reached a significant milestone: It has published exactly 50 volumes over the past half-century. As we launch the first issue of Volume 51, this is an opportune moment to reflect on the journal’s legacy, ongoing evolution, and the exciting changes that lie ahead. Together, we embark on a journey to open a new chapter for this storied publication.},
  archive      = {J_COLI},
  author       = {Lu, Wei},
  doi          = {10.1162/coli_e_00552},
  journal      = {Computational Linguistics},
  month        = {3},
  number       = {1},
  pages        = {1-5},
  shortjournal = {Comput. Lingu.},
  title        = {Opening a new chapter for computational linguistics},
  volume       = {51},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jmlr---1">JMLR - 1</h2>
<ul>
<li><details>
<summary>
(2025). Statistical inference of constrained stochastic optimization
via sketched sequential quadratic programming. <em>JMLR</em>,
<em>26</em>(33), 1–75. (<a
href="https://jmlr.org/papers/v26/24-0530.html">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider online statistical inference of constrained stochastic nonlinear optimization problems. We apply the Stochastic Sequential Quadratic Programming (StoSQP) method to solve these problems, which can be regarded as applying second-order Newton&#39;s method to the Karush-Kuhn-Tucker (KKT) conditions. In each iteration, the StoSQP method computes the Newton direction by solving a quadratic program, and then selects a proper adaptive stepsize $\bar{\alpha}_t$ to update the primal-dual iterate. To reduce dominant computational cost of the method, we inexactly solve the quadratic program in each iteration by employing an iterative sketching solver. Notably, the approximation error of the sketching solver need not vanish as iterations proceed, meaning that the per-iteration computational cost does not blow up. For the above StoSQP method, we show that under mild assumptions, the rescaled primal-dual sequence $1/\sqrt{\bar{\alpha}_t}\cdot (x_t -x^\star, \lambda_t - \lambda^\star)$ converges to a mean-zero Gaussian distribution with a nontrivial covariance matrix depending on the underlying sketching distribution. To perform inference in practice, we also analyze a plug-in covariance matrix estimator. We illustrate the asymptotic normality result of the method both on benchmark nonlinear problems in CUTEst test set and on linearly/nonlinearly constrained regression problems.},
  archive      = {J_JMLR},
  author       = {Sen Na and Michael Mahoney},
  journal      = {Journal of Machine Learning Research},
  number       = {33},
  pages        = {1-75},
  shortjournal = {J. Mach. Learn. Res.},
  title        = {Statistical inference of constrained stochastic optimization via sketched sequential quadratic programming},
  url          = {https://jmlr.org/papers/v26/24-0530.html},
  volume       = {26},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="neco---5">NECO - 5</h2>
<ul>
<li><details>
<summary>
(2025). Uncovering dynamical equations of stochastic decision models
using data-driven SINDy algorithm. <em>NECO</em>, <em>37</em>(3),
569–587. (<a href="https://doi.org/10.1162/neco_a_01736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision formation in perceptual decision making involves sensory evidence accumulation instantiated by the temporal integration of an internal decision variable toward some decision criterion or threshold, as described by sequential sampling theoretical models. The decision variable can be represented in the form of experimentally observable neural activities. Hence, elucidating the appropriate theoretical model becomes crucial to understanding the mechanisms underlying perceptual decision formation. Existing computational methods are limited to either fitting of choice behavioral data or linear model estimation from neural activity data. In this work, we made use of sparse identification of nonlinear dynamics (SINDy), a data-driven approach, to elucidate the deterministic linear and nonlinear components of often-used stochastic decision models within reaction time task paradigms. Based on the simulated decision variable activities of the models and assuming the noise coefficient term is known beforehand, SINDy, enhanced with approaches using multiple trials, could readily estimate the deterministic terms in the dynamical equations, choice accuracy, and decision time of the models across a range of signal-to-noise ratio values. In particular, SINDy performed the best using the more memory-intensive multi-trial approach while trial-averaging of parameters performed more moderately. The single-trial approach, although expectedly not performing as well, may be useful for real-time modeling. Taken together, our work offers alternative approaches for SINDy to uncover the dynamics in perceptual decision making and, more generally, for first-passage time problems.},
  archive      = {J_NECO},
  author       = {Lenfesty, Brendan and Bhattacharyya, Saugat and Wong-Lin, KongFatt},
  doi          = {10.1162/neco_a_01736},
  journal      = {Neural Computation},
  month        = {2},
  number       = {3},
  pages        = {569-587},
  shortjournal = {Neural Comput.},
  title        = {Uncovering dynamical equations of stochastic decision models using data-driven SINDy algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradual domain adaptation via normalizing flows.
<em>NECO</em>, <em>37</em>(3), 522–568. (<a
href="https://doi.org/10.1162/neco_a_01734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Standard domain adaptation methods do not work well when a large gap exists between the source and target domains. Gradual domain adaptation is one of the approaches used to address the problem. It involves leveraging the intermediate domain, which gradually shifts from the source domain to the target domain. In previous work, it is assumed that the number of intermediate domains is large and the distance between adjacent domains is small; hence, the gradual domain adaptation algorithm, involving self-training with unlabeled data sets, is applicable. In practice, however, gradual self-training will fail because the number of intermediate domains is limited and the distance between adjacent domains is large. We propose the use of normalizing flows to deal with this problem while maintaining the framework of unsupervised domain adaptation. The proposed method learns a transformation from the distribution of the target domains to the gaussian mixture distribution via the source domain. We evaluate our proposed method by experiments using real-world data sets and confirm that it mitigates the problem we have explained and improves the classification performance.},
  archive      = {J_NECO},
  author       = {Sagawa, Shogo and Hino, Hideitsu},
  doi          = {10.1162/neco_a_01734},
  journal      = {Neural Computation},
  month        = {2},
  number       = {3},
  pages        = {522-568},
  shortjournal = {Neural Comput.},
  title        = {Gradual domain adaptation via normalizing flows},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward a free-response paradigm of decision making in
spiking neural networks. <em>NECO</em>, <em>37</em>(3), 481–521. (<a
href="https://doi.org/10.1162/neco_a_01733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) have attracted significant interest in the development of brain-inspired computing systems due to their energy efficiency and similarities to biological information processing. In contrast to continuous-valued artificial neural networks, which produce results in a single step, SNNs require multiple steps during inference to achieve a desired accuracy level, resulting in a burden in real-time response and energy efficiency. Inspired by the tradeoff between speed and accuracy in human and animal decision-making processes, which exhibit correlations among reaction times, task complexity, and decision confidence, an inquiry emerges regarding how an SNN model can benefit by implementing these attributes. Here, we introduce a theory of decision making in SNNs by untangling the interplay between signal and noise. Under this theory, we introduce a new learning objective that trains an SNN not only to make the correct decisions but also to shape its confidence. Numerical experiments demonstrate that SNNs trained in this way exhibit improved confidence expression, reduced trial-to-trial variability, and shorter latency to reach the desired accuracy. We then introduce a stopping policy that can stop inference in a way that further enhances the time efficiency of SNNs. The stopping time can serve as an indicator to whether a decision is correct, akin to the reaction time in animal behavior experiments. By integrating stochasticity into decision making, this study opens up new possibilities to explore the capabilities of SNNs and advance SNNs and their applications in complex decision-making scenarios where model performance is limited.},
  archive      = {J_NECO},
  author       = {Zhu, Zhichao and Qi, Yang and Lu, Wenlian and Wang, Zhigang and Cao, Lu and Feng, Jianfeng},
  doi          = {10.1162/neco_a_01733},
  journal      = {Neural Computation},
  month        = {2},
  number       = {3},
  pages        = {481-521},
  shortjournal = {Neural Comput.},
  title        = {Toward a free-response paradigm of decision making in spiking neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving recall in sparse associative memories that use
neurogenesis. <em>NECO</em>, <em>37</em>(3), 437–480. (<a
href="https://doi.org/10.1162/neco_a_01732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The creation of future low-power neuromorphic solutions requires specialist spiking neural network (SNN) algorithms that are optimized for neuromorphic settings. One such algorithmic challenge is the ability to recall learned patterns from their noisy variants. Solutions to this problem may be required to memorize vast numbers of patterns based on limited training data and subsequently recall the patterns in the presence of noise. To solve this problem, previous work has explored sparse associative memory (SAM)—associative memory neural models that exploit the principle of sparse neural coding observed in the brain. Research into a subcategory of SAM has been inspired by the biological process of adult neurogenesis, whereby new neurons are generated to facilitate adaptive and effective lifelong learning. Although these neurogenesis models have been demonstrated in previous research, they have limitations in terms of recall memory capacity and robustness to noise. In this article, we provide a unifying framework for characterizing a type of SAM network that has been pretrained using a learning strategy that incorporated a simple neurogenesis model. Using this characterization, we formally define network topology and threshold optimization methods to empirically demonstrate greater than 10 4 times improvement in memory capacity compared to previous work. We show that these optimizations can facilitate the development of networks that have reduced interneuron connectivity while maintaining high recall efficacy. This paves the way for ongoing research into fast, effective, low-power realizations of associative memory on neuromorphic platforms.},
  archive      = {J_NECO},
  author       = {Warr, Katy and Hare, Jonathon and Thomas, David},
  doi          = {10.1162/neco_a_01732},
  journal      = {Neural Computation},
  month        = {2},
  number       = {3},
  pages        = {437-480},
  shortjournal = {Neural Comput.},
  title        = {Improving recall in sparse associative memories that use neurogenesis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Replay as a basis for backpropagation through time in the
brain. <em>NECO</em>, <em>37</em>(3), 403–436. (<a
href="https://doi.org/10.1162/neco_a_01735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How episodic memories are formed in the brain is a continuing puzzle for the neuroscience community. The brain areas that are critical for episodic learning (e.g., the hippocampus) are characterized by recurrent connectivity and generate frequent offline replay events. The function of the replay events is a subject of active debate. Recurrent connectivity, computational simulations show, enables sequence learning when combined with a suitable learning algorithm such as backpropagation through time (BPTT). BPTT, however, is not biologically plausible. We describe here, for the first time, a biologically plausible variant of BPTT in a reversible recurrent neural network, R2N2, that critically leverages offline replay to support episodic learning. The model uses forward and backward offline replay to transfer information between two recurrent neural networks, a cache and a consolidator, that perform rapid one-shot learning and statistical learning, respectively. Unlike replay in standard BPTT, this architecture requires no artificial external memory store. This approach outperforms existing solutions like random feedback local online learning and reservoir network. It also accounts for the functional significance of hippocampal replay events. We demonstrate the R2N2 network properties using benchmark tests from computer science and simulate the rodent delayed alternation T-maze task.},
  archive      = {J_NECO},
  author       = {Cheng, Huzi and Brown, Joshua W.},
  doi          = {10.1162/neco_a_01735},
  journal      = {Neural Computation},
  month        = {2},
  number       = {3},
  pages        = {403-436},
  shortjournal = {Neural Comput.},
  title        = {Replay as a basis for backpropagation through time in the brain},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="netn---21">NETN - 21</h2>
<ul>
<li><details>
<summary>
(2025). Firing rate distributions in plastic networks of spiking
neurons. <em>NETN</em>, <em>9</em>(1), 447–474. (<a
href="https://doi.org/10.1162/netn_a_00442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recurrent networks of leaky integrate-and-fire neurons, the mean-field theory has been instrumental in capturing the statistical properties of neuronal activity, like firing rate distributions. This theory has been applied to networks with either homogeneous synaptic weights and heterogeneous connections per neuron or vice versa. Our work expands mean-field models to include networks with both types of structural heterogeneity simultaneously, particularly focusing on those with synapses that undergo plastic changes. The model introduces a spike trace for each neuron, a variable that rises with neuron spikes and decays without activity, influenced by a degradation rate r p and the neuron’s firing rate ν . When the ratio α = ν / r p is significantly high, this trace effectively estimates the neuron’s firing rate, allowing synaptic weights at equilibrium to be determined by the firing rates of connected neurons. This relationship is incorporated into our mean-field formalism, providing exact solutions for firing rate and synaptic weight distributions at equilibrium in the high α regime. However, the model remains accurate within a practical range of degradation rates, as demonstrated through simulations with networks of excitatory and inhibitory neurons. This approach sheds light on how plasticity modulates both activity and structure within neuronal networks, offering insights into their complex behavior. Networks of spiking neurons are complex systems where the structure of connections and the activity patterns generated are deeply intertwined, a relationship often studied using mathematical approaches like the mean-field theory. However, previous studies have primarily focused on networks with limited structural variability, where either the connection strength is nearly identical across the network or the number of connections varies little from one neuron to another. This work takes a step forward by combining both types of structural variability and allowing connection strengths to adapt over time, thereby providing an extended mean-field theory. We derive exact solutions for the distribution of spiking rates and connection strengths at equilibrium and demonstrate their accuracy through numerical simulations, even beyond the defining parameter ranges, offering a more comprehensive and realistic perspective on the interplay between activity and structure in neuronal networks.},
  archive      = {J_NETN},
  author       = {Vegué, Marina and Allard, Antoine and Desrosiers, Patrick},
  doi          = {10.1162/netn_a_00442},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {447-474},
  shortjournal = {Netw. Neuroscience},
  title        = {Firing rate distributions in plastic networks of spiking neurons},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Validating MEG estimated resting-state connectome with
intracranial EEG. <em>NETN</em>, <em>9</em>(1), 421–446. (<a
href="https://doi.org/10.1162/netn_a_00441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetoencephalography (MEG) is widely used for studying resting-state brain connectivity. However, MEG source imaging is ill posed and has limited spatial resolution. This introduces source-leakage issues, making it challenging to interpret MEG-derived connectivity in resting states. To address this, we validated MEG-derived connectivity from 45 healthy participants using a normative intracranial EEG (iEEG) atlas. The MEG inverse problem was solved using the wavelet-maximum entropy on the mean method. We computed four connectivity metrics: amplitude envelope correlation (AEC), orthogonalized AEC (OAEC), phase locking value (PLV), and weighted-phase lag index (wPLI). We compared spatial correlation between MEG and iEEG connectomes across standard canonical frequency bands. We found moderate spatial correlations between MEG and iEEG connectomes for AEC and PLV. However, when considering metrics that correct/remove zero-lag connectivity (OAEC/wPLI), the spatial correlation between MEG and iEEG connectomes decreased. MEG exhibited higher zero-lag connectivity compared with iEEG. The correlations between MEG and iEEG connectomes suggest that relevant connectivity patterns can be recovered from MEG. However, since these correlations are moderate/low, MEG connectivity results should be interpreted with caution. Metrics that correct for zero-lag connectivity show decreased correlations, highlighting a trade-off; while MEG may capture more connectivity due to source-leakage, removing zero-lag connectivity can eliminate true connections. The ill-posed nature and low spatial resolution of EEG/magnetoencephalography (MEG) source imaging affects functional connectivity estimates, which become more complicated in the resting state due to the low signal-to-noise ratio. Several connectivity metrics have been proposed to address source leakage by removing zero-lag connectivity, although this can eliminate true neuronal zero-lag connections. Intracranial EEG (iEEG) is the gold standard for validating noninvasive measurements. In this study, we validated MEG-estimated connectivity for healthy subjects using the iEEG atlas of normal brain activity ( Frauscher et al., 2018 ) as ground truth at a group level. We employed two amplitude-based metrics and two phase-based metrics. Our findings highlight how MEG connectivity compares with the iEEG atlas and provide valuable insights for resting-state EEG/MEG connectomic studies, particularly in the choice of connectivity metrics.},
  archive      = {J_NETN},
  author       = {Afnan, Jawata and Cai, Zhengchen and Lina, Jean-Marc and Abdallah, Chifaou and Pellegrino, Giovanni and Arcara, Giorgio and Khajehpour, Hassan and Frauscher, Birgit and Gotman, Jean and Grova, Christophe},
  doi          = {10.1162/netn_a_00441},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {421-446},
  shortjournal = {Netw. Neuroscience},
  title        = {Validating MEG estimated resting-state connectome with intracranial EEG},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Whole-brain causal discovery using fMRI. <em>NETN</em>,
<em>9</em>(1), 392–420. (<a
href="https://doi.org/10.1162/netn_a_00438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant research, discovering causal relationships from fMRI remains a challenge. Popular methods such as Granger causality and dynamic causal modeling fall short in handling contemporaneous effects and latent common causes. Methods from causal structure learning literature can address these limitations but often scale poorly with network size and need acyclicity. In this study, we first provide a taxonomy of existing methods and compare their accuracy and efficiency on simulated fMRI from simple topologies. This analysis demonstrates a pressing need for more accurate and scalable methods, motivating the design of Causal discovery for Large-scale Low-resolution Time-series with Feedback (CaLLTiF). CaLLTiF is a constraint-based method that uses conditional independence between contemporaneous and lagged variables to extract causal relationships. On simulated fMRI from the macaque connectome, CaLLTiF achieves significantly higher accuracy and scalability than all tested alternatives. From resting-state human fMRI, CaLLTiF learns causal connectomes that are highly consistent across individuals, show clear top-down flow of causal effect from attention and default mode to sensorimotor networks, exhibit Euclidean distance dependence in causal interactions, and are highly dominated by contemporaneous effects. Overall, this work takes a major step in enhancing causal discovery from whole-brain fMRI and defines a new standard for future investigations. Discovering causal relationships from fMRI data is challenging due to contemporaneous effects and latent causes. Popular methods like Granger causality and dynamic causal modeling struggle with these issues, especially in large networks. To address this, we introduce Causal discovery for Large-scale Low-resolution Time-series with Feedback (CaLLTiF), a scalable method that uses both lagged and contemporaneous variables to identify causal relationships. CaLLTiF outperforms various existing techniques in accuracy and scalability on simulated fMRI data. When applied to human resting-state fMRI, it reveals consistent and biologically plausible patterns across individuals, with a clear top-down causal flow from attention and default mode networks to sensorimotor areas. Overall, this work advances the field of causal discovery in large-scale fMRI studies.},
  archive      = {J_NETN},
  author       = {Arab, Fahimeh and Ghassami, AmirEmad and Jamalabadi, Hamidreza and Peters, Megan A. K. and Nozari, Erfan},
  doi          = {10.1162/netn_a_00438},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {392-420},
  shortjournal = {Netw. Neuroscience},
  title        = {Whole-brain causal discovery using fMRI},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-retest reliability of dynamic functional connectivity
parameters for a two-state model. <em>NETN</em>, <em>9</em>(1), 371–391.
(<a href="https://doi.org/10.1162/netn_a_00437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability of imaging parameters is of pivotal importance for further correlation analyses. Here, we investigated the test-retest reliability of two dynamic functional connectivity (dFC) brain states and related parameters for different scan length, atlases with 116 versus 442 regions, and data centering in 23 participants and reproduced the findings in 501 subjects of the Human Connectome Project. Results showed an integrated and a segregated brain state with high intraclass correlation coefficient (ICC) values of the states between sessions (0.67 ≥ ICC ≥ 0.99). The most reliable dFC parameter was state prevalence with an ICC ≈ 0.5 for ∼15 min of uncentered data, while other parameters, such as mean dwell time, were much less reliable. While shorter scans and within-subject data centering further reduce reliability, the atlas choice had no effects. Spearman’s correlations among dFC parameters strongly depend on data centering. The effect of global signal regression and a higher number of states is discussed. In conclusion, we recommend formulating hypotheses on cross-sectional differences and correlations between dFC measures of brain integration and other subject-specific measures in terms of state prevalence, especially in small-scale studies. We investigated the reliability of popular parameters characterizing dynamic brain states in two datasets. We found high reliability of clustering results with a two-state model but only medium to low reliability of the parameters, of which state prevalence across different strategies was the most reliable.},
  archive      = {J_NETN},
  author       = {Fang, Xiaojing and Marxen, Michael},
  doi          = {10.1162/netn_a_00437},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {371-391},
  shortjournal = {Netw. Neuroscience},
  title        = {Test-retest reliability of dynamic functional connectivity parameters for a two-state model},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Translational network neuroscience: Nine roadblocks and
possible solutions. <em>NETN</em>, <em>9</em>(1), 352–370. (<a
href="https://doi.org/10.1162/netn_a_00435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Translational network neuroscience aims to integrate advanced neuroimaging and data analysis techniques into clinical practice to better understand and treat neurological disorders. Despite the promise of technologies such as functional MRI and diffusion MRI combined with network analysis tools, the field faces several challenges that hinder its swift clinical translation. We have identified nine key roadblocks that impede this process: (a) theoretical and basic science foundations; (b) network construction, data interpretation, and validation; (c) MRI access, data variability, and protocol standardization; (d) data sharing; (e) computational resources and expertise; (f) interdisciplinary collaboration; (g) industry collaboration and commercialization; (h) operational efficiency, integration, and training; and (i) ethical and legal considerations. To address these challenges, we propose several possible solution strategies. By aligning scientific goals with clinical realities and establishing a sound ethical framework, translational network neuroscience can achieve meaningful advances in personalized medicine and ultimately improve patient care. We advocate for an interdisciplinary commitment to overcoming translational hurdles in network neuroscience and integrating advanced technologies into routine clinical practice.},
  archive      = {J_NETN},
  author       = {Fekonja, Lucius S. and Forkel, Stephanie J. and Aydogan, Dogu Baran and Lioumis, Pantelis and Cacciola, Alberto and Lucas, Carolin Weiß and Tournier, Jacques-Donald and Vergani, Francesco and Ritter, Petra and Schenk, Robert and Shams, Boshra and Engelhardt, Melina Julia and Picht, Thomas},
  doi          = {10.1162/netn_a_00435},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {352-370},
  shortjournal = {Netw. Neuroscience},
  title        = {Translational network neuroscience: Nine roadblocks and possible solutions},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Individualized mouse brain network models produce asymmetric
patterns of functional connectivity after simulated traumatic injury.
<em>NETN</em>, <em>9</em>(1), 326–351. (<a
href="https://doi.org/10.1162/netn_a_00431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The functional and cognitive effects of traumatic brain injury (TBI) are poorly understood, as even mild injuries (concussion) can lead to long-lasting, untreatable symptoms. Simplified brain dynamics models may help researchers better understand the relationship between brain injury patterns and functional outcomes. Properly developed, these computational models provide an approach to investigate the effects of both computational and in vivo injury on simulated dynamics and cognitive function, respectively, for model organisms. In this study, we apply the Kuramoto model and an existing mesoscale mouse brain structural network to develop a simplified computational model of mouse brain dynamics. We explore how to optimize our initial model to predict existing mouse brain functional connectivity collected from mice under various anesthetic protocols. Finally, to determine how strongly the changes in our optimized models’ dynamics can predict the extent of a brain injury, we investigate how our simulations respond to varying levels of structural network damage. Results predict a mixture of hypo- and hyperconnectivity after experimental TBI, similar to results in TBI survivors, and also suggest a compensatory remodeling of connections that may have an impact on functional outcomes after TBI. Recent research has investigated the consequences of traumatic brain injuries by combining computational models of human brain activity and structural models of the whole human brain or cortex. As experimental injury research can only be conducted using animal models, we apply a simplified computational model of whole-brain dynamics, the Kuramoto model, to a mouse brain structural network. We tune our model to best predict measurements of functional connectivity recorded from 58 fMRI scans of mice and lesion the network model to explore the effects of injury. Our findings predict that functional connectivity may increase or decrease in various regions of the brain, even at a high injury level, which may aid in future predictions of cognitive impairments after brain injury.},
  archive      = {J_NETN},
  author       = {Rayfield, Adam C. and Wu, Taotao and Rifkin, Jared A. and Meaney, David F.},
  doi          = {10.1162/netn_a_00431},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {326-351},
  shortjournal = {Netw. Neuroscience},
  title        = {Individualized mouse brain network models produce asymmetric patterns of functional connectivity after simulated traumatic injury},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional brain networks predicting sustained attention are
not specific to perceptual modality. <em>NETN</em>, <em>9</em>(1),
303–325. (<a href="https://doi.org/10.1162/netn_a_00430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sustained attention is essential for daily life and can be directed to information from different perceptual modalities, including audition and vision. Recently, cognitive neuroscience has aimed to identify neural predictors of behavior that generalize across datasets. Prior work has shown strong generalization of models trained to predict individual differences in sustained attention performance from patterns of fMRI functional connectivity. However, it is an open question whether predictions of sustained attention are specific to the perceptual modality in which they are trained. In the current study, we test whether connectome-based models predict performance on attention tasks performed in different modalities. We show first that a predefined network trained to predict adults’ visual sustained attention performance generalizes to predict auditory sustained attention performance in three independent datasets ( N 1 = 29, N 2 = 60, N 3 = 17). Next, we train new network models to predict performance on visual and auditory attention tasks separately. We find that functional networks are largely modality general, with both model-unique and shared model features predicting sustained attention performance in independent datasets regardless of task modality. Results support the supposition that visual and auditory sustained attention rely on shared neural mechanisms and demonstrate robust generalizability of whole-brain functional network models of sustained attention. While previous work has demonstrated external validity of functional connectivity-based networks for the prediction of cognitive and attentional performance, testing generalization across visual and auditory perceptual modalities has been limited. The current study demonstrates robust prediction of sustained attention performance, regardless of perceptual modality models are trained or tested in. Results demonstrate that connectivity-based models may generalize broadly, capturing variance in sustained attention performance that is agnostic to the perceptual modality of model training.},
  archive      = {J_NETN},
  author       = {Corriveau, Anna and Ke, Jin and Terashima, Hiroki and Kondo, Hirohito M. and Rosenberg, Monica D.},
  doi          = {10.1162/netn_a_00430},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {303-325},
  shortjournal = {Netw. Neuroscience},
  title        = {Functional brain networks predicting sustained attention are not specific to perceptual modality},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional connectotomy of a whole-brain model reveals
tumor-induced alterations to neuronal dynamics in glioma patients.
<em>NETN</em>, <em>9</em>(1), 280–302. (<a
href="https://doi.org/10.1162/netn_a_00426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors can induce pathological changes in neuronal dynamics that are reflected in functional connectivity measures. Here, we use a whole-brain modeling approach to investigate pathological alterations to neuronal activity in glioma patients. By fitting a Hopf whole-brain model to empirical functional connectivity, we investigate glioma-induced changes in optimal model parameters. We observe considerable differences in neuronal dynamics between glioma patients and healthy controls, both on an individual and population-based level. In particular, model parameter estimation suggests that local tumor pathology causes changes in brain dynamics by increasing the influence of interregional interactions on global neuronal activity. Our approach demonstrates that whole-brain models provide valuable insights for understanding glioma-associated alterations in functional connectivity. This study investigates how gliomas affect neuronal activity and connectivity using a whole-brain computational model. By fitting this model to empirical data, we compare glioma patients with healthy individuals to uncover significant differences in brain dynamics. Our findings indicate that local tumor pathology enhances the influence of interregional interactions on overall neuronal activity. This approach underscores the utility of whole-brain computational models in revealing the complex alterations in functional connectivity associated with gliomas, advancing our understanding of their impact on brain function.},
  archive      = {J_NETN},
  author       = {Alexandersen, Christoffer G. and Douw, Linda and Zimmermann, Mona L. M. and Bick, Christian and Goriely, Alain},
  doi          = {10.1162/netn_a_00426},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {280-302},
  shortjournal = {Netw. Neuroscience},
  title        = {Functional connectotomy of a whole-brain model reveals tumor-induced alterations to neuronal dynamics in glioma patients},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal MRI accurately identifies amyloid status in
unbalanced cohorts in alzheimer’s disease continuum. <em>NETN</em>,
<em>9</em>(1), 259–279. (<a
href="https://doi.org/10.1162/netn_a_00423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Amyloid- β (A β ) plaques in conjunction with hyperphosphorylated tau proteins in the form of neurofibrillary tangles are the two neuropathological hallmarks of Alzheimer’s disease. It is well-known that the identification of individuals with A β positivity could enable early diagnosis. In this work, we aim at capturing the A β positivity status in an unbalanced cohort enclosing subjects at different disease stages, exploiting the underlying structural and connectivity disease-induced modulations as revealed by structural, functional, and diffusion MRI. Of note, due to the unbalanced cohort, the outcomes may be guided by those factors rather than amyloid accumulation. The partial views provided by each modality are integrated in the model, allowing to take full advantage of their complementarity in encoding the effects of the A β accumulation, leading to an accuracy of 0.762 ± 0.04. The specificity of the information brought by each modality is assessed by post hoc explainability analysis (guided backpropagation), highlighting the underlying structural and functional changes. Noteworthy, well-established biomarker key regions related to A β deposition could be identified by all modalities, including the hippocampus, thalamus, precuneus, and cingulate gyrus, witnessing in favor of the reliability of the method as well as its potential in shedding light on modality-specific possibly unknown A β deposition signatures. In this work, we employed a multimodal MRI-based deep learning framework for the classification of unbalanced cohorts relying on the amyloid- β status in the Alzheimer’s disease continuum. To this end, structural, functional, and diffusion MRI data were used to feed a 3D-convolutional neural network and two different graph neural networks, respectively, reaching an accuracy of 0.762 ± 0.04. Post hoc explainability analysis was performed to extract the most relevant regions that led to the outcome, highlighting the involvement of different cortical and subcortical regions. This work provides evidence of the added value brought by exploiting different imaging modalities in decrypting the nature and extent of brain alterations in the amyloid-guided classification outcome.},
  archive      = {J_NETN},
  author       = {Dolci, Giorgio and Ellis, Charles A. and Cruciani, Federica and Brusini, Lorenza and Abrol, Anees and Galazzo, Ilaria Boscolo and Menegaz, Gloria and Calhoun, Vince D. and for the Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1162/netn_a_00423},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {259-279},
  shortjournal = {Netw. Neuroscience},
  title        = {Multimodal MRI accurately identifies amyloid status in unbalanced cohorts in alzheimer’s disease continuum},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyzing the brain’s dynamic response to targeted
stimulation using generative modeling. <em>NETN</em>, <em>9</em>(1),
237–258. (<a href="https://doi.org/10.1162/netn_a_00433">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models of brain activity have been instrumental in testing hypothesized mechanisms underlying brain dynamics against experimental datasets. Beyond capturing the key mechanisms underlying spontaneous brain dynamics, these models hold an exciting potential for understanding the mechanisms underlying the dynamics evoked by targeted brain stimulation techniques. This paper delves into this emerging application, using concepts from dynamical systems theory to argue that the stimulus-evoked dynamics in such experiments may be shaped by new types of mechanisms distinct from those that dominate spontaneous dynamics. We review and discuss (a) the targeted experimental techniques across spatial scales that can both perturb the brain to novel states and resolve its relaxation trajectory back to spontaneous dynamics and (b) how we can understand these dynamics in terms of mechanisms using physiological, phenomenological, and data-driven models. A tight integration of targeted stimulation experiments with generative quantitative modeling provides an important opportunity to uncover novel mechanisms of brain dynamics that are difficult to detect in spontaneous settings. Generative models are important tools for testing hypothesized mechanisms of brain dynamics against experimental data. This review highlights an application of generative models in analyzing a form of brain activity evoked by emerging targeted stimulation techniques. We argue that analyzing targeted stimulation dynamics can uncover mechanisms that are hidden during commonly analyzed spontaneous dynamics and explore how integrating diverse targeted stimulation experiments with existing generative models offer a significant opportunity to uncover these novel mechanisms and thereby expand our mechanistic understanding of brain dynamics.},
  archive      = {J_NETN},
  author       = {Maran, Rishikesan and Müller, Eli J. and Fulcher, Ben D.},
  doi          = {10.1162/netn_a_00433},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {237-258},
  shortjournal = {Netw. Neuroscience},
  title        = {Analyzing the brain’s dynamic response to targeted stimulation using generative modeling},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A connectome manipulation framework for the systematic and
reproducible study of structure–function relationships through
simulations. <em>NETN</em>, <em>9</em>(1), 207–236. (<a
href="https://doi.org/10.1162/netn_a_00429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synaptic connectivity at the neuronal level is characterized by highly nonrandom features. Hypotheses about their role can be developed by correlating structural metrics to functional features. But, to prove causation, manipulations of connectivity would have to be studied. However, the fine-grained scale at which nonrandom trends are expressed makes this approach challenging to pursue experimentally. Simulations of neuronal networks provide an alternative route to study arbitrarily complex manipulations in morphologically and biophysically detailed models. Here, we present Connectome-Manipulator, a Python framework for rapid connectome manipulations of large-scale network models in Scalable Open Network Architecture TemplAte (SONATA) format. In addition to creating or manipulating the connectome of a model, it provides tools to fit parameters of stochastic connectivity models against existing connectomes. This enables rapid replacement of any existing connectome with equivalent connectomes at different levels of complexity, or transplantation of connectivity features from one connectome to another, for systematic study. We employed the framework in the detailed model of the rat somatosensory cortex in two exemplary use cases: transplanting interneuron connectivity trends from electron microscopy data and creating simplified connectomes of excitatory connectivity. We ran a series of network simulations and found diverse shifts in the activity of individual neuron populations causally linked to these manipulations.},
  archive      = {J_NETN},
  author       = {Pokorny, Christoph and Awile, Omar and Isbister, James B. and Kurban, Kerem and Wolf, Matthias and Reimann, Michael W.},
  doi          = {10.1162/netn_a_00429},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {207-236},
  shortjournal = {Netw. Neuroscience},
  title        = {A connectome manipulation framework for the systematic and reproducible study of structure–function relationships through simulations},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combined topological and spatial constraints are required to
capture the structure of neural connectomes. <em>NETN</em>,
<em>9</em>(1), 181–206. (<a
href="https://doi.org/10.1162/netn_a_00428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volumetric brain reconstructions provide an unprecedented opportunity to gain insights into the complex connectivity patterns of neurons in an increasing number of organisms. Here, we model and quantify the complexity of the resulting neural connectomes in the fruit fly, mouse, and human and unveil a simple set of shared organizing principles across these organisms. To put the connectomes in a physical context, we also construct contactomes, the network of neurons in physical contact in each organism. With these, we establish that physical constraints—either given by pairwise distances or the contactome—play a crucial role in shaping the network structure. For example, neuron positions are highly optimal in terms of distance from their neighbors. Yet, spatial constraints alone cannot capture the network topology, including the broad degree distribution. Conversely, the degree sequence alone is insufficient to recover the spatial structure. We resolve this apparent mismatch by formulating scalable maximum entropy models, incorporating both types of constraints. The resulting generative models have predictive power beyond the input data, as they capture several additional biological and network characteristics, like synaptic weights and graphlet statistics. We investigate the interplay of the spatial and topological structure of millimeter-scale neural connectomes in fly, mouse, and human. As a spatial observation, we demonstrate that the probability of synaptic connection decays exponentially with distance. Additionally, we show that the wiring length in neural connectomes is highly optimal. To quantify the physical constraints on synapse formation, we construct the physical contact network for each organism and demonstrate that contact edge probability follows the same exponential functional form as the connectome. At the same time, we show that spatial constraints are necessary but not sufficient to reconstruct the connectome topology. We present maximum-entropy models capturing key spatial and topological aspects of the connectomes and demonstrate their predictive power beyond the input data.},
  archive      = {J_NETN},
  author       = {Salova, Anastasiya and Kovács, István A.},
  doi          = {10.1162/netn_a_00428},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {181-206},
  shortjournal = {Netw. Neuroscience},
  title        = {Combined topological and spatial constraints are required to capture the structure of neural connectomes},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural network embedding of functional microconnectome.
<em>NETN</em>, <em>9</em>(1), 159–180. (<a
href="https://doi.org/10.1162/netn_a_00424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our brains operate as a complex network of interconnected neurons. To gain a deeper understanding of this network architecture, it is essential to extract simple rules from its intricate structure. This study aimed to compress and simplify the architecture, with a particular focus on interpreting patterns of functional connectivity in 2.5 hr of electrical activity from a vast number of neurons in acutely sliced mouse brains. Here, we combined two distinct methods together: automatic compression and network analysis. Firstly, for automatic compression, we trained an artificial neural network named NNE (neural network embedding). This allowed us to reduce the connectivity to features, be represented only by 13% of the original neuron count. Secondly, to decipher the topology, we concentrated on the variability among the compressed features and compared them with 15 distinct network metrics. Specifically, we introduced new metrics that had not previously existed, termed as indirect-adjacent degree and neighbor hub ratio. Our results conclusively demonstrated that these new metrics could better explain approximately 40%–45% of the features. This finding highlighted the critical role of NNE in facilitating the development of innovative metrics, because some of the features extracted by NNE were not captured by the currently existed network metrics. Neural network embedding can compress large connectivity and has led to new metrics like indirect-adjacency degree and neighbor hub ratio.},
  archive      = {J_NETN},
  author       = {Shirakami, Arata and Hase, Takeshi and Yamaguchi, Yuki and Shimono, Masanori},
  doi          = {10.1162/netn_a_00424},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {159-180},
  shortjournal = {Netw. Neuroscience},
  title        = {Neural network embedding of functional microconnectome},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complexity in speech and music listening via neural manifold
flows. <em>NETN</em>, <em>9</em>(1), 146–158. (<a
href="https://doi.org/10.1162/netn_a_00422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the complex neural mechanisms underlying speech and music perception remains a multifaceted challenge. In this study, we investigated neural dynamics using human intracranial recordings. Employing a novel approach based on low-dimensional reduction techniques, the Manifold Density Flow (MDF), we quantified the complexity of brain dynamics during naturalistic speech and music listening and during resting state. Our results reveal higher complexity in patterns of interdependence between different brain regions during speech and music listening compared with rest, suggesting that the cognitive demands of speech and music listening drive the brain dynamics toward states not observed during rest. Moreover, speech listening has more complexity than music, highlighting the nuanced differences in cognitive demands between these two auditory domains. Additionally, we validated the efficacy of the MDF method through experimentation on a toy model and compared its effectiveness in capturing the complexity of brain dynamics induced by cognitive tasks with another established technique in the literature. Overall, our findings provide a new method to quantify the complexity of brain activity by studying its temporal evolution on a low-dimensional manifold, suggesting insights that are invisible to traditional methodologies in the contexts of speech and music perception. Understanding how the human brain processes speech and music is a fascinating and complex challenge. Our study explores how brain activity changes when people listen to naturalistic speech compared to when they listen to music or when they are at rest. We found that both speech and music engage the brain in more complex patterns of activity than rest, with speech leading to even greater complexity. To achieve this, we used a novel method to study the brain&#39;s activity in a simplified, low-dimensional space, representing the dynamical evolution of brain activity across different regions. This approach highlights the demands placed on brain function during the perception of speech and music, providing new insights into how we process these auditory experiences.},
  archive      = {J_NETN},
  author       = {Runfola, Claudio and Neri, Matteo and Schön, Daniele and Morillon, Benjamin and Trébuchon, Agnès and Rabuffo, Giovanni and Sorrentino, Pierpaolo and Jirsa, Viktor},
  doi          = {10.1162/netn_a_00422},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {146-158},
  shortjournal = {Netw. Neuroscience},
  title        = {Complexity in speech and music listening via neural manifold flows},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic brain states underlying advanced concentrative
absorption meditation: A 7-t fMRI-intensive case study. <em>NETN</em>,
<em>9</em>(1), 125–145. (<a
href="https://doi.org/10.1162/netn_a_00432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced meditation consists of states and stages of practice that unfold with mastery and time. Dynamic functional connectivity (DFC) analysis of fMRI could identify brain states underlying advanced meditation. We conducted an intensive DFC case study of a meditator who completed 27 runs of jhāna advanced absorptive concentration meditation (ACAM-J), concurrently with 7-T fMRI and phenomenological reporting. We identified three brain states that marked differences between ACAM-J and nonmeditative control conditions. These states were characterized as a DMN-anticorrelated brain state, a hyperconnected brain state, and a sparsely connected brain state. Our analyses indicate higher prevalence of the DMN-anticorrelated brain state during ACAM-J than control states, and the prevalence increased significantly with deeper ACAM-J states. The hyperconnected brain state was also more common during ACAM-J and was characterized by elevated thalamocortical connectivity and somatomotor network connectivity. The hyperconnected brain state significantly decreased over the course of ACAM-J, associating with self-reports of wider attention and diminished physical sensations. This brain state may be related to sensory awareness. Advanced meditators have developed well-honed abilities to move in and out of different altered states of consciousness, and this study provides initial evidence that functional neuroimaging can objectively track their dynamics. Advanced meditation research investigates states and stages of practice that unfold with increasing mastery and time, which may include altered states of consciousness such as a diminished sense of self. In the current study, we examined a 7-T fMRI case study of jhāna , an advanced concentrative absorptive meditation (ACAM-J). Specifically, we examined the temporal properties of dynamic connectivity brain states that could reflect mental states and phenomena during ACAM-J. We identified two brain states that were more prevalent during ACAM-J than control conditions. One state, involving default-mode network anticorrelations with the rest of the brain, increased across ACAM-J. Another state, involving hyperconnectivity across many cortical networks, was correlated with reports of narrow attention and greater sensory awareness, as well as diminished across ACAM-J.},
  archive      = {J_NETN},
  author       = {Treves, Isaac N. and Yang, Winson F. Z. and Sparby, Terje and Sacchet, Matthew D.},
  doi          = {10.1162/netn_a_00432},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {125-145},
  shortjournal = {Netw. Neuroscience},
  title        = {Dynamic brain states underlying advanced concentrative absorption meditation: A 7-T fMRI-intensive case study},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cell-type-specific contributions to theta-gamma coupled
rhythms in the hippocampus. <em>NETN</em>, <em>9</em>(1), 100–124. (<a
href="https://doi.org/10.1162/netn_a_00427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distinct inhibitory cell types participate in cognitively relevant nested brain rhythms, and particular changes in such rhythms are known to occur in disease states. Specifically, the coexpression of theta and gamma rhythms in the hippocampus is believed to represent a general coding scheme, but cellular-based generation mechanisms for these coupled rhythms are currently unclear. We develop a population rate model of the CA1 hippocampus that encompasses circuits of three inhibitory cell types (bistratified cells and parvalbumin [PV]-expressing and cholecystokinin [CCK]-expressing basket cells) and pyramidal cells to examine this. We constrain parameters and perform numerical and theoretical analyses. The theory, in combination with the numerical explorations, predicts circuit motifs and specific cell-type mechanisms that are essential for the coexistence of theta and gamma oscillations. We find that CCK-expressing basket cells initiate the coupled rhythms and regularize theta, and PV-expressing basket cells enhance both theta and gamma rhythms. Pyramidal and bistratified cells govern the generation of theta rhythms, and PV-expressing basket and pyramidal cells play dominant roles in controlling theta frequencies. Our circuit motifs for the theta-gamma coupled rhythm generation could be applicable to other brain regions. There are many different types of inhibitory cells in our brains that are differentially affected in disease. Concomitantly, coupled rhythms change in particular ways with disease. To help understand cell-type-specific changes in coupled rhythms, we develop a mathematical network model that is both respective of the cell type and also amenable to analyses. We focus on theta-gamma coupled rhythms in the hippocampus and include three different inhibitory cell types in our model circuits. By combining a theoretical analysis and numerical explorations, we find distinct contributions of these inhibitory cell types to coupled rhythms and predict motifs that are essential for the expression of theta-gamma coupled rhythms. Moving forward, we can leverage our model insights to help unravel cell-type contributions in disease states.},
  archive      = {J_NETN},
  author       = {Sengupta, Spandan and Talidou, Afroditi and Lefebvre, Jeremie and Skinner, Frances K.},
  doi          = {10.1162/netn_a_00427},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {100-124},
  shortjournal = {Netw. Neuroscience},
  title        = {Cell-type-specific contributions to theta-gamma coupled rhythms in the hippocampus},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The control costs of human brain dynamics. <em>NETN</em>,
<em>9</em>(1), 77–99. (<a
href="https://doi.org/10.1162/netn_a_00425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain is a complex system with high metabolic demands and extensive connectivity that requires control to balance energy consumption and functional efficiency over time. How this control is manifested on a whole-brain scale is largely unexplored, particularly what the associated costs are. Using the network control theory, here, we introduce a novel concept, time-averaged control energy (TCE), to quantify the cost of controlling human brain dynamics at rest, as measured from functional and diffusion MRI. Importantly, TCE spatially correlates with oxygen metabolism measures from the positron emission tomography, providing insight into the bioenergetic footing of resting-state control. Examining the temporal dimension of control costs, we find that brain state transitions along a hierarchical axis from sensory to association areas are more efficient in terms of control costs and more frequent within hierarchical groups than between. This inverse correlation between temporal control costs and state visits suggests a mechanism for maintaining functional diversity while minimizing energy expenditure. By unpacking the temporal dimension of control costs, we contribute to the neuroscientific understanding of how the brain governs its functionality while managing energy expenses. Understanding how the brain balances functional efficiency with energy conservation is a central question in neuroscience. The network control theory (NCT) views this question from a network perspective where the brain manages signal propagations along its structural connections to transition across desired activity states. Our study thus presents a novel framework based on the NCT to analyze the costs associated with transitioning across resting states, revealing that regions with high control costs on average are also metabolically demanding in terms of oxygen use. Our findings further show that transitions between sensory and association states are infrequent due to high control costs, while transitions within these states are more common. This suggests that the brain employs a mechanism to preserve functional diversity while minimizing energy costs.},
  archive      = {J_NETN},
  author       = {Ceballos, Eric G. and Luppi, Andrea I. and Castrillon, Gabriel and Saggar, Manish and Misic, Bratislav and Riedl, Valentin},
  doi          = {10.1162/netn_a_00425},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {77-99},
  shortjournal = {Netw. Neuroscience},
  title        = {The control costs of human brain dynamics},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A telescopic independent component analysis on functional
magnetic resonance imaging dataset. <em>NETN</em>, <em>9</em>(1), 61–76.
(<a href="https://doi.org/10.1162/netn_a_00421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain function can be modeled as dynamic interactions between functional sources at different spatial scales, and each spatial scale can contain its functional sources with unique information, thus using a single scale may provide an incomplete view of brain function. This paper introduces a novel approach, termed “telescopic independent component analysis (TICA),” designed to construct spatial functional hierarchies and estimate functional sources across multiple spatial scales using fMRI data. The method employs a recursive independent component analysis (ICA) strategy, leveraging information from a larger network to guide the extraction of information about smaller networks. We apply our model to the default mode network (DMN), visual network (VN), and right frontoparietal network (RFPN). We investigate further on the DMN by evaluating the difference between healthy people and individuals with schizophrenia. We show that the TICA approach can detect the spatial hierarchy of the DMN, VN, and RFPN. In addition, the TICA revealed DMN-associated group differences between cohorts that may not be captured if we focus on a single-scale ICA. In sum, our proposed approach represents a promising new tool for studying functional sources.},
  archive      = {J_NETN},
  author       = {Mirzaeian, Shiva and Faghiri, Ashkan and Calhoun, Vince D. and Iraji, Armin},
  doi          = {10.1162/netn_a_00421},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {61-76},
  shortjournal = {Netw. Neuroscience},
  title        = {A telescopic independent component analysis on functional magnetic resonance imaging dataset},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tangent space functional reconfigurations in individuals at
risk for alcohol use disorder. <em>NETN</em>, <em>9</em>(1), 38–60. (<a
href="https://doi.org/10.1162/netn_a_00419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human brain function dynamically adjusts to ever-changing stimuli from the external environment. Studies characterizing brain functional reconfiguration are, nevertheless, scarce. Here, we present a principled mathematical framework to quantify brain functional reconfiguration when engaging and disengaging from a stop signal task (SST). We apply tangent space projection (a Riemannian geometry mapping technique) to transform the functional connectomes (FCs) of 54 participants and quantify functional reconfiguration using the correlation distance of the resulting tangent-FCs. Our goal was to compare functional reconfigurations in individuals at risk for alcohol use disorder (AUD). We hypothesized that functional reconfigurations when transitioning to/from a task would be influenced by family history of AUD (FHA) and other AUD risk factors. Multilinear regression models showed that engaging and disengaging functional reconfiguration were associated with FHA and recent drinking. When engaging in the SST after a rest condition, functional reconfiguration was negatively associated with recent drinking, while functional reconfiguration when disengaging from the SST was negatively associated with FHA. In both models, several other factors contributed to the functional reconfiguration. This study demonstrates that tangent-FCs can characterize task-induced functional reconfiguration and that it is related to AUD risk. Human brain function constantly adapts to the external environment stimuli and transitions between cognitive states, which can be hindered by alcohol misuse and family history of alcohol use disorder (AUD). In this work, we used a novel methodology that applies Riemannian geometry concepts to functional connectivity to quantify functional reconfiguration of rest-to-task (engaging) and task-to-rest (disengaging) transitions. We ultimately aimed to determine the relationship between AUD risk factors and functional reconfiguration. Our findings showed that engaging functional reconfiguration was diminished in participants with a family history of AUD, whereas disengaging functional reconfiguration was diminished with greater recent drinking behavior. This study suggests that analysis of functional reconfiguration using Riemannian geometry is a promising avenue to better understand rest-to-task and task-to-rest brain transitions.},
  archive      = {J_NETN},
  author       = {Moghaddam, Mahdi and Dzemidzic, Mario and Guerrero, Daniel and Liu, Mintao and Alessi, Jonathan and Plawecki, Martin H. and Harezlak, Jaroslaw and Kareken, David A. and Goñi, Joaquín},
  doi          = {10.1162/netn_a_00419},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {38-60},
  shortjournal = {Netw. Neuroscience},
  title        = {Tangent space functional reconfigurations in individuals at risk for alcohol use disorder},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Localization of the epileptogenic network from scalp EEG
using a patient-specific whole-brain model. <em>NETN</em>,
<em>9</em>(1), 18–37. (<a
href="https://doi.org/10.1162/netn_a_00418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational modeling is a key tool for elucidating the neuronal mechanisms underlying epileptic activity. Despite considerable progress, existing models often lack realistic accuracy in representing electrophysiological epileptic activity. In this study, we used a comprehensive human brain model based on a neural mass model, which is tailored to the layered structure of the neocortex and incorporates patient-specific imaging data. This approach allowed the simulation of scalp EEGs in an epileptic patient suffering from type 2 focal cortical dysplasia (FCD). The simulation specifically addressed epileptic activity induced by FCD, faithfully reproducing intracranial interictal epileptiform discharges (IEDs) recorded with electrocorticography. For constructing the patient-specific scalp EEG, we carefully defined a clear delineation of the epileptogenic zone by numerical simulations to ensure fidelity to the topography, polarity, and diffusion characteristics of IEDs. This nuanced approach improves the accuracy of the simulated EEG signal, provides a more accurate representation of epileptic activity, and enhances our understanding of the mechanism behind the epileptogenic networks. The accuracy of the model was confirmed by a postoperative reevaluation with a secondary EEG simulation that was consistent with the lesion’s removal. Ultimately, this personalized approach may prove instrumental in optimizing and tailoring epilepsy treatment strategies. This study aimed to create a neurophysiologically grounded computer model of focal epilepsy. This is a feature frequently lacking to simulations in this domain, making the translation from in silico to in vivo results questionable and difficult to understand for clinical electrophysiologists. We adapted a whole-brain neuronal mass model for EEG generation in various conscious states to replicate the EEG patterns of a type 2 focal cortical dysplasia (FCD), a condition associated with epilepsy. Our model successfully simulated both intracranial and scalp EEGs of a complex patient with type 2 FCD, who was later cured through surgery. Importantly, the simulated lesion location matched the patient’s epileptogenic zone, and removing this area in the model eliminated epileptic activity in the EEG, demonstrating the model’s accuracy.},
  archive      = {J_NETN},
  author       = {Maliia, Mihai Dragos and Köksal-Ersöz, Elif and Benard, Adrien and Calas, Tristan and Nica, Anca and Denoyer, Yves and Yochum, Maxime and Wendling, Fabrice and Benquet, Pascal},
  doi          = {10.1162/netn_a_00418},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {18-37},
  shortjournal = {Netw. Neuroscience},
  title        = {Localization of the epileptogenic network from scalp EEG using a patient-specific whole-brain model},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thalamocortical interactions reflecting the intensity of
flicker light–induced visual hallucinatory phenomena. <em>NETN</em>,
<em>9</em>(1), 1–17. (<a
href="https://doi.org/10.1162/netn_a_00417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aberrant thalamocortical connectivity occurs together with visual hallucinations in various pathologies and drug-induced states, highlighting the need to better understand how thalamocortical interactions may contribute to hallucinatory phenomena. Flicker light stimulation (FLS) at 10-Hz reliably and selectively induces transient visual hallucinations in healthy participants. Arrhythmic flicker elicits fewer hallucinatory effects while delivering equal amounts of visual stimulation, together facilitating a well-controlled experimental setup to investigate the neural correlates of visual hallucinations driven by flicker rhythmicity. Using rhythmic and arrhythmic FLS during fMRI scanning, we found that rhythmic FLS elicited stronger activation in higher order visual cortices compared with arrhythmic control. Consistently, we found that rhythmic flicker selectively increased connectivity between ventroanterior thalamic nuclei and higher order visual cortices, which was also positively associated with the subjective intensity of visual hallucinatory effects. As these thalamic and cortical areas do not receive primary visual inputs, it suggests that the thalamocortical connectivity changes relate to a higher order function of the thalamus, such as in the coordination of cortical activity. In sum, we present novel evidence for the role of specific thalamocortical interactions with ventroanterior nuclei within visual hallucinatory experiences. Importantly, this can inform future clinical research into the mechanistic underpinnings of pathologic hallucinations. Flicker light stimulation induces an intense transient experience of elementary visual hallucinations, such as colored geometric patterns, that has phenomenal similarities to the visual experience induced by psychedelic drugs or during psychopathology. During fMRI scanning, we found that increased connectivity between ventroanterior thalamic nuclei and higher order visual cortices was associated with the reported intensity of the flicker-induced visual effects. Our results suggest that the role of thalamocortical hyperconnectivity during hallucinatory experiences may relate to a higher order function of the thalamus, such as the regulation of cortical activity. This novel finding results from a highly controlled experimental setup, which can be extended to inform the mechanistic underpinnings of hallucinatory experiences during psychopathology.},
  archive      = {J_NETN},
  author       = {Amaya, Ioanna A. and Nierhaus, Till and Schmidt, Timo T.},
  doi          = {10.1162/netn_a_00417},
  journal      = {Network Neuroscience},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Netw. Neuroscience},
  title        = {Thalamocortical interactions reflecting the intensity of flicker light–induced visual hallucinatory phenomena},
  volume       = {9},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="tacl---9">TACL - 9</h2>
<ul>
<li><details>
<summary>
(2025). Transformers as transducers. <em>TACL</em>, <em>13</em>,
200–219. (<a href="https://doi.org/10.1162/tacl_a_00736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the sequence-to-sequence mapping capacity of transformers by relating them to finite transducers, and find that they can express surprisingly large classes of (total functional) transductions. We do so using variants of RASP, a programming language designed to help people “think like transformers,” as an intermediate representation. We extend the existing Boolean variant B-RASP to sequence-to-sequence transductions and show that it computes exactly the first-order rational transductions (such as string rotation). Then, we introduce two new extensions. B-RASP[ pos ] enables calculations on positions (such as copying the first half of a string) and contains all first-order regular transductions. S-RASP adds prefix sum, which enables additional arithmetic operations (such as squaring a string) and contains all first-order polyregular transductions. Finally, we show that masked average-hard attention transformers can simulate S-RASP.},
  archive      = {J_TACL},
  author       = {Strobl, Lena and Angluin, Dana and Chiang, David and Rawski, Jonathan and Sabharwal, Ashish},
  doi          = {10.1162/tacl_a_00736},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {200-219},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Transformers as transducers},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OPT-tree: Speculative decoding with adaptive draft tree
structure. <em>TACL</em>, <em>13</em>, 188–199. (<a
href="https://doi.org/10.1162/tacl_a_00735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autoregressive language models demonstrate excellent performance in various scenarios. However, the inference efficiency is limited by its one-step-one-word generation mode, which has become a pressing problem recently as the models become increasingly larger. Speculative decoding employs a “draft and then verify” mechanism to allow multiple tokens to be generated in one step, realizing lossless acceleration. Existing methods mainly adopt fixed heuristic draft structures, which do not adapt to different situations to maximize the acceptance length during verification. To alleviate this dilemma, we propose OPT-Tree, an algorithm to construct adaptive and scalable draft trees, which can be applied to any autoregressive draft model. It searches the optimal tree structure that maximizes the mathematical expectation of the acceptance length in each decoding step. Experimental results reveal that OPT-Tree outperforms the existing draft structures and achieves a speed-up ratio of up to 3.2 compared with autoregressive decoding. If the draft model is powerful enough and the node budget is sufficient, it can generate more than ten tokens in a single step. Our code is available at https://github.com/Jikai0Wang/OPT-Tree .},
  archive      = {J_TACL},
  author       = {Wang, Jikai and Su, Yi and Li, Juntao and Xia, Qingrong and Ye, Zi and Duan, Xinyu and Wang, Zhefeng and Zhang, Min},
  doi          = {10.1162/tacl_a_00735},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {188-199},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {OPT-tree: Speculative decoding with adaptive draft tree structure},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A confidence-based acquisition model for self-supervised
active learning and label correction. <em>TACL</em>, <em>13</em>,
167–187. (<a href="https://doi.org/10.1162/tacl_a_00734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised neural approaches are hindered by their dependence on large, meticulously annotated datasets, a requirement that is particularly cumbersome for sequential tasks. The quality of annotations tends to deteriorate with the transition from expert-based to crowd-sourced labeling. To address these challenges, we present CAMEL ( C onfidence-based A cquisition M odel for E fficient self-supervised active L earning), a pool-based active learning framework tailored to sequential multi-output problems. CAMEL possesses two core features: (1) it requires expert annotators to label only a fraction of a chosen sequence, and (2) it facilitates self-supervision for the remainder of the sequence. By deploying a label correction mechanism, CAMEL can also be utilized for data cleaning. We evaluate CAMEL on two sequential tasks, with a special emphasis on dialogue belief tracking, a task plagued by the constraints of limited and noisy datasets. Our experiments demonstrate that CAMEL significantly outperforms the baselines in terms of efficiency. Furthermore, the data corrections suggested by our method contribute to an overall improvement in the quality of the resulting datasets. 1},
  archive      = {J_TACL},
  author       = {Niekerk, Carel van and Geishauser, Christian and Heck, Michael and Feng, Shutong and Lin, Hsien-chin and Lubis, Nurul and Ruppik, Benjamin and Vukovic, Renato and Gašić, Milica},
  doi          = {10.1162/tacl_a_00734},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {167-187},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {A confidence-based acquisition model for self-supervised active learning and label correction},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning syntax without planting trees: Understanding
hierarchical generalization in transformers. <em>TACL</em>, <em>13</em>,
121–141. (<a href="https://doi.org/10.1162/tacl_a_00733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers trained on natural language data have been shown to exhibit hierarchical generalization without explicitly encoding any structural bias. In this work, we investigate sources of inductive bias in transformer models and their training that could cause such preference for hierarchical generalization. We extensively experiment with transformers trained on five synthetic, controlled datasets using several training objectives and show that, while objectives such as sequence-to-sequence modeling, classification, etc., often fail to lead to hierarchical generalization, the language modeling objective consistently leads to transformers generalizing hierarchically. We then study how different generalization behaviors emerge during the training by conducting pruning experiments that reveal the joint existence of subnetworks within the model implementing different generalizations. Finally, we take a Bayesian perspective to understand transformers’ preference for hierarchical generalization: We establish a correlation between whether transformers generalize hierarchically on a dataset and if the simplest explanation of that dataset is provided by a hierarchical grammar compared to regular grammars exhibiting linear generalization. Overall, our work presents new insights on the origins of hierarchical generalization in transformers and provides a theoretical framework for studying generalization in language models.},
  archive      = {J_TACL},
  author       = {Ahuja, Kabir and Balachandran, Vidhisha and Panwar, Madhur and He, Tianxing and Smith, Noah A. and Goyal, Navin and Tsvetkov, Yulia},
  doi          = {10.1162/tacl_a_00733},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {121-141},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Learning syntax without planting trees: Understanding hierarchical generalization in transformers},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating critical period effects in language
acquisition through neural language models. <em>TACL</em>, <em>13</em>,
96–120. (<a href="https://doi.org/10.1162/tacl_a_00725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans appear to have a critical period (CP) for language acquisition: Second language (L 2 ) acquisition becomes harder after early childhood, and ceasing exposure to a first language (L 1 ) after this period (but not before) typically does not lead to substantial loss of L 1 proficiency. It is unknown whether these CP effects result from innately determined brain maturation or as a stabilization of neural connections naturally induced by experience. In this study, we use language models (LMs) to test the extent to which these phenomena are peculiar to humans, or shared by a broader class of language learners. We vary the age of exposure by training LMs on language pairs in various experimental conditions, and find that LMs, which lack any direct analog to innate maturational stages, do not show CP effects when the age of exposure of L 2 is delayed. Our results contradict the claim that CP effects are an inevitable result of statistical learning, and they are consistent with an innate mechanism for CP effects. We show that we can reverse-engineer the CP by introducing a regularizer partway through training to simulate a maturational decrease in plasticity. All in all, our results suggest that L 1 learning on its own may not be enough to induce a CP, and additional engineering is necessary to make language models more cognitively plausible.},
  archive      = {J_TACL},
  author       = {Constantinescu, Ionut and Pimentel, Tiago and Cotterell, Ryan and Warstadt, Alex},
  doi          = {10.1162/tacl_a_00725},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {96-120},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Investigating critical period effects in language acquisition through neural language models},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Salute the classic: Revisiting challenges of machine
translation in the age of large language models. <em>TACL</em>,
<em>13</em>, 73–95. (<a
href="https://doi.org/10.1162/tacl_a_00730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The evolution of Neural Machine Translation (NMT) has been significantly influenced by six core challenges (Koehn and Knowles, 2017 ) that have acted as benchmarks for progress in this field. This study revisits these challenges, offering insights into their ongoing relevance in the context of advanced Large Language Models (LLMs): domain mismatch , amount of parallel data , rare word prediction , translation of long sentences , attention model as word alignment , and sub-optimal beam search . Our empirical findings show that LLMs effectively reduce reliance on parallel data for major languages during pretraining and significantly improve translation of long sentences containing approximately 80 words, even translating documents up to 512 words. Despite these improvements, challenges in domain mismatch and rare word prediction persist. While NMT-specific challenges like word alignment and beam search may not apply to LLMs, we identify three new challenges in LLM-based translation: inference efficiency, translation of low-resource languages during pretraining, and human-aligned evaluation.},
  archive      = {J_TACL},
  author       = {Pang, Jianhui and Ye, Fanghua and Wong, Derek Fai and Yu, Dian and Shi, Shuming and Tu, Zhaopeng and Wang, Longyue},
  doi          = {10.1162/tacl_a_00730},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {73-95},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Salute the classic: Revisiting challenges of machine translation in the age of large language models},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLAPnq: Cohesive long-form answers from passages in natural
questions for RAG systems. <em>TACL</em>, <em>13</em>, 53–72. (<a
href="https://doi.org/10.1162/tacl_a_00729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retrieval Augmented Generation (RAG) has become a popular application for large language models. It is preferable that successful RAG systems provide accurate answers that are supported by being grounded in a passage without any hallucinations. While considerable work is required for building a full RAG pipeline, being able to benchmark performance is also necessary. We present CLAPnq , a benchmark Long-form Question Answering dataset for the full RAG pipeline. CLAPnq includes long answers with grounded gold passages from Natural Questions (NQ) and a corpus to perform either retrieval, generation, or the full RAG pipeline. The CLAPnq answers are concise , 3x smaller than the full passage, and cohesive , meaning that the answer is composed fluently, often by integrating multiple pieces of the passage that are not contiguous. RAG models must adapt to these properties to be successful at CLAPnq . We present baseline experiments and analysis for CLAPnq that highlight areas where there is still significant room for improvement in grounded RAG. CLAPnq is publicly available at https://github.com/primeqa/clapnq .},
  archive      = {J_TACL},
  author       = {Rosenthal, Sara and Sil, Avirup and Florian, Radu and Roukos, Salim},
  doi          = {10.1162/tacl_a_00729},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {53-72},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {CLAPnq: Cohesive long-form answers from passages in natural questions for RAG systems},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SpiRit-LM: Interleaved spoken and written language model.
<em>TACL</em>, <em>13</em>, 30–52. (<a
href="https://doi.org/10.1162/tacl_a_00728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce SpiRit-LM , a foundation multimodal language model that freely mixes text and speech. Our model is based on a 7B pretrained text language model that we extend to the speech modality by continuously training it on text and speech units. Speech and text sequences are concatenated as a single stream of tokens, and trained with a word-level interleaving method using a small automatically curated speech-text parallel corpus. SpiRit-LM comes in two versions: a Base version that uses speech phonetic units (HuBERT) and an Expressive version that models expressivity using pitch and style units in addition to the phonetic units. For both versions, the text is encoded with subword BPE tokens. The resulting model displays both the semantic abilities of text models and the expressive abilities of speech models. Additionally, we demonstrate that SpiRit-LM can learn new tasks in a few-shot fashion across modalities (i.e., ASR, TTS, Speech Classification). We make available model weights and inference code. 1 , 2},
  archive      = {J_TACL},
  author       = {Nguyen, Tu Anh and Muller, Benjamin and Yu, Bokai and Costa-jussa, Marta R. and Elbayad, Maha and Popuri, Sravya and Ropers, Christophe and Duquenne, Paul-Ambroise and Algayres, Robin and Mavlyutov, Ruslan and Gat, Itai and Williamson, Mary and Synnaeve, Gabriel and Pino, Juan and Sagot, Benoît and Dupoux, Emmanuel},
  doi          = {10.1162/tacl_a_00728},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {30-52},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {SpiRit-LM: Interleaved spoken and written language model},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dolomites: Domain-specific long-form methodical tasks.
<em>TACL</em>, <em>13</em>, 1–29. (<a
href="https://doi.org/10.1162/tacl_a_00727">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experts in various fields routinely perform methodical writing tasks to plan, organize, and report their work. From a clinician writing a differential diagnosis for a patient, to a teacher writing a lesson plan for students, these tasks are pervasive, requiring to methodically generate structured long-form output for a given input. We develop a typology of methodical tasks structured in the form of a task objective, procedure, input, and output, and introduce DoLoMiTes, a novel benchmark with specifications for 519 such tasks elicited from hundreds of experts from across 25 fields. Our benchmark further contains specific instantiations of methodical tasks with concrete input and output examples (1,857 in total) which we obtain by collecting expert revisions of up to 10 model-generated examples of each task. We use these examples to evaluate contemporary language models, highlighting that automating methodical tasks is a challenging long-form generation problem, as it requires performing complex inferences, while drawing upon the given context as well as domain knowledge. Our dataset is available at https://dolomites-benchmark.github.io/ .},
  archive      = {J_TACL},
  author       = {Malaviya, Chaitanya and Agrawal, Priyanka and Ganchev, Kuzman and Srinivasan, Pranesh and Huot, Fantine and Berant, Jonathan and Yatskar, Mark and Das, Dipanjan and Lapata, Mirella and Alberti, Chris},
  doi          = {10.1162/tacl_a_00727},
  journal      = {Transactions of the Association for Computational Linguistics},
  month        = {2},
  pages        = {1-29},
  shortjournal = {Trans. Assoc. Comput. Lingu.},
  title        = {Dolomites: Domain-specific long-form methodical tasks},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="tmlr---115">TMLR - 115</h2>
<ul>
<li><details>
<summary>
(2025). Lognormal mutations and their use in detecting surreptitious
fake images. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=0RJvZY0h6O">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many cases, adversarial attacks against fake detectors employ algorithms specifically crafted for automatic image classifiers. These algorithms perform well, thanks to an excellent ad hoc distribution of initial attacks. However, these attacks are easily detected due to their specific initial distribution. Consequently, we explore alternative black-box attacks inspired by generic black-box optimization tools, particularly focusing on the \lognormal{} algorithm that we successfully extend to attack fake detectors. Moreover, we demonstrate that this attack evades detection by neural networks trained to flag classical adversarial examples. Therefore, we train more general models capable of identifying a broader spectrum of attacks, including classical black-box attacks designed for images, black-box attacks driven by classical optimization, and no-box attacks. By integrating these attack detection capabilities with fake detectors, we develop more robust and effective fake detection systems.},
  archive      = {J_TMLR},
  author       = {Olivier Teytaud and Mariia Zameshina and Tom Sander and Pierre Fernandez and Furong Ye and Laurent Najman and Thomas Bäck and Ismail Labiad},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Lognormal mutations and their use in detecting surreptitious fake images},
  url          = {https://openreview.net/forum?id=0RJvZY0h6O},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loss-to-loss prediction: Scaling laws for all datasets.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=1Avb4jYjLb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While scaling laws provide a reliable methodology for predicting train loss across compute scales for a single data distribution, less is known about how these predictions should change as we change the distribution. In this paper, we derive a strategy for predicting one loss from another and apply it to predict across different pre-training datasets and from pre-training data to downstream task data. Our predictions extrapolate well even at 20x the largest FLOP budget used to fit the curves. More precisely, we find that there are simple shifted power law relationships between (1) the train losses of two models trained on two separate datasets when the models are paired by training compute (train-to-train), (2) the train loss and the test loss on any downstream distribution for a single model (train-to-test), and (3) the test losses of two models trained on two separate train datasets (test-to-test). The results hold up for pre-training datasets that differ substantially (some are entirely code and others have no code at all) and across a variety of downstream tasks. Finally, we find that in some settings these shifted power law relationships can yield more accurate predictions than extrapolating single-dataset scaling laws.},
  archive      = {J_TMLR},
  author       = {David Brandfonbrener and Nikhil Anand and Nikhil Vyas and Eran Malach and Sham M. Kakade},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Loss-to-loss prediction: Scaling laws for all datasets},
  url          = {https://openreview.net/forum?id=1Avb4jYjLb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust high-dimensional mean estimation with low data size,
an empirical study. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=1QeI99nH9k">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust statistics aims to compute quantities to represent data where a fraction of it may be arbitrarily corrupted. The most essential statistic is the mean, and in recent years, there has been a flurry of theoretical advancement for efficiently estimating the mean in high dimensions on corrupted data. While several algorithms have been proposed that achieve near-optimal error, they all rely on large data size requirements as a function of dimension. In this paper, we perform an extensive experimentation over various mean estimation techniques where data size might not meet this requirement due to the high-dimensional setting. For data with inliers generated from a Gaussian with known covariance, we find experimentally that several robust mean estimation techniques can practically improve upon the sample mean, with the quantum entropy scaling approach from Dong \etal (NeurIPS 2019) performing consistently the best. However, this consistent improvement is conditioned on a couple of simple modifications to how the steps to prune outliers work in the high-dimension low-data setting, and when the inliers deviate significantly from Gaussianity. In fact, with these modifications, they are typically able to achieve roughly the same error as taking the sample mean of the uncorrupted inlier data, even with very low data size. In addition to controlled experiments on synthetic data, we also explore these methods on large language models, deep pretrained image models, and non-contextual word embedding models that do not necessarily have an inherent Gaussian distribution. Yet, in these settings, a mean point of a set of embedded objects is a desirable quantity to learn, and the data exhibits the high-dimension low-data setting studied in this paper. We show both the challenges of achieving this goal, and that our updated robust mean estimation methods can provide significant improvement over using just the sample mean. We additionally publish a library of Python implementations of robust mean estimation algorithms, allowing practitioners and researchers to apply these techniques and to perform further experimentation.},
  archive      = {J_TMLR},
  author       = {Cullen Anderson and Jeff M. Phillips},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust high-dimensional mean estimation with low data size, an empirical study},
  url          = {https://openreview.net/forum?id=1QeI99nH9k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DivIL: Unveiling and addressing over-invariance for out-of-
distribution generalization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2Zan4ATYsh">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-distribution generalization is a common problem that expects the model to perform well in the different distributions even far from the train data. A popular approach to addressing this issue is invariant learning (IL), in which the model is compiled to focus on invariant features instead of spurious features by adding strong constraints during training. However, there are some potential pitfalls of strong invariant constraints. Due to the limited number of diverse environments and over-regularization in the feature space, it may lead to a loss of important details in the invariant features while alleviating the spurious correlations, namely the over-invariance, which can also degrade the generalization performance. We theoretically define the over-invariance and observe that this issue occurs in various classic IL methods. To alleviate this issue, we propose a simple approach Diverse Invariant Learning (DivIL) by adding the unsupervised contrastive learning and the random masking mechanism compensatory for the invariant constraints, which can be applied to various IL methods. Furthermore, we conduct experiments across multiple modalities across 12 datasets and 6 classic models, verifying our over-invariance insight and the effectiveness of our DivIL framework. Our code is available at https://github.com/kokolerk/DivIL.},
  archive      = {J_TMLR},
  author       = {Jiaqi WANG and Yuhang Zhou and Zhixiong Zhang and Qiguang Chen and Yongqiang Chen and James Cheng},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DivIL: Unveiling and addressing over-invariance for out-of- distribution generalization},
  url          = {https://openreview.net/forum?id=2Zan4ATYsh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging causality, individual fairness, and adversarial
robustness in the absence of structural causal model. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=2nRcWy3RLM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the essential need for comprehensive considerations in responsible AI, factors such as robustness, fairness, and causality are often studied in isolation. Adversarial perturbation, used to identify vulnerabilities in models, and individual fairness, aiming for equitable treatment of similar individuals, despite initial differences, both depend on metrics to generate comparable input data instances. Previous attempts to define such joint metrics often lack general assumptions about data and were unable to reflect counterfactual proximity. To address this, our paper introduces a \emph{causal fair metric} formulated based on causal structures encompassing sensitive attributes and protected causal perturbation. To enhance the practicality of our metric, we propose metric learning as a method for metric estimation and deployment in real-world problems in the absence of structural causal models. We also demonstrate the applications of the causal fair metric in classifiers. Empirical evaluation of real-world and synthetic datasets illustrates the effectiveness of our proposed metric in achieving an accurate classifier with fairness, resilience to adversarial perturbations, and a nuanced understanding of causal relationships.},
  archive      = {J_TMLR},
  author       = {Ahmad Reza Ehyaei and Golnoosh Farnadi and Samira Samadi},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Bridging causality, individual fairness, and adversarial robustness in the absence of structural causal model},
  url          = {https://openreview.net/forum?id=2nRcWy3RLM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selective prediction via training dynamics. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=2wgnepQjyF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selective Prediction is the task of rejecting inputs a model would predict incorrectly on. This involves a trade-off between input space coverage (how many data points are accepted) and model utility (how good is the performance on accepted data points). Current methods for selective prediction typically impose constraints on either the model architecture or the optimization objective; this inhibits their usage in practice and introduces unknown interactions with pre-existing loss functions. In contrast to prior work, we show that state-of-the-art se- lective prediction performance can be attained solely from studying the (discretized) training dynamics of a model. We propose a general framework that, given a test input, monitors metrics capturing the instability of predictions from intermediate models (i.e., checkpoints) obtained during training w.r.t. the final model’s prediction. In particular, we reject data points exhibiting too much disagreement with the final prediction at late stages in training. The proposed rejection mechanism is domain-agnostic (i.e., it works for both discrete and real-valued prediction) and can be flexibly combined with existing selective prediction approaches as it does not require any train-time modifications. Our experimental evaluation on image classification, regression, and time series problems shows that our method beats past state-of-the-art accuracy/utility trade-offs on typical selective prediction benchmarks.},
  archive      = {J_TMLR},
  author       = {Stephan Rabanser and Anvith Thudi and Kimia Hamidieh and Adam Dziedzic and Israfil Bahceci and Akram Bin Sediq and HAMZA SOKUN and Nicolas Papernot},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Selective prediction via training dynamics},
  url          = {https://openreview.net/forum?id=2wgnepQjyF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). APR-CNN: Convolutional neural networks for the adaptive
particle representation of large microscopy images. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=5qKI2dkrjL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present APR-CNN, a novel class of convolutional neural networks designed for efficient and scalable three-dimensional microscopy image analysis. APR-CNNs operate natively on a sparse, multi-resolution image representation known as the Adaptive Particle Representation (APR). This significantly reduces memory and compute requirements compared to traditional pixel-based CNNs. We introduce APR-native layers for convolution, pooling, and upsampling, along with hybrid architectures that combine APR and pixel layers to balance accuracy and computational efficiency. We show in benchmarks that APR-CNNs achieve comparable segmentation accuracy to pixel-based CNNs while drastically reducing memory usage and inference time. We further showcase the potential of APR-CNNs in large-scale volumetric image analysis, reducing inference times from weeks to days. This opens up new avenues for applying deep learning to large, high-resolution, three-dimensional biomedical datasets with constrained computational resources.},
  archive      = {J_TMLR},
  author       = {Joel Jonsson and Bevan Leslie Cheeseman and Ivo Sbalzarini},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {APR-CNN: Convolutional neural networks for the adaptive particle representation of large microscopy images},
  url          = {https://openreview.net/forum?id=5qKI2dkrjL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SimPLR: A simple and plain transformer for efficient object
detection and segmentation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=6LO1y8ZE0F">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to detect objects in images at varying scales has played a pivotal role in the design of modern object detectors. Despite considerable progress in removing hand-crafted components and simplifying the architecture with transformers, multi-scale feature maps and pyramid designs remain a key factor for their empirical success. In this paper, we show that shifting the multiscale inductive bias into the attention mechanism can work well, resulting in a plain detector ‘SimPLR’ whose backbone and detection head are both non-hierarchical and operate on single-scale features. We find through our experiments that SimPLR with scale-aware attention is plain and simple architecture, yet competitive with multi-scale vision transformer alternatives. Compared to the multi-scale and single-scale state-of-the-art, our model scales better with bigger capacity (self-supervised) models and more pre-training data, allowing us to report a consistently better accuracy and faster runtime for object detection, instance segmentation, as well as panoptic segmentation. Code is released at \url{https://github.com/kienduynguyen/SimPLR}.},
  archive      = {J_TMLR},
  author       = {Duy Kien Nguyen and Martin R. Oswald and Cees G. M. Snoek},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {SimPLR: A simple and plain transformer for efficient object detection and segmentation},
  url          = {https://openreview.net/forum?id=6LO1y8ZE0F},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fair principal component analysis (PCA):
Minorization-maximization algorithms for fair PCA, fair robust PCA and
fair sparse PCA. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=6jTQrr3APY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a new iterative algorithm to solve the fair PCA (FPCA) problem. We start with the max-min fair PCA formulation originally proposed in \cite{samadi1} and derive a simple and efficient iterative algorithm which is based on the minorization-maximization (MM) approach. The proposed algorithm relies on the relaxation of a semi-orthogonality constraint which is proved to be tight at every iteration of the algorithm. The vanilla version of the proposed algorithm requires solving a semi-definite program (SDP) at every iteration, which can be further simplified to a quadratic program by formulating the dual of the surrogate maximization problem. We also propose two important reformulations of the fair PCA problem: a) fair robust PCA - which can handle outliers in the data, and b) fair sparse PCA - which can enforce sparsity on the estimated fair principal components. The proposed algorithms are computationally efficient and monotonically increase their respective design objectives at every iteration. An added feature of the proposed algorithms is that they do not require the selection of any hyperparameter (except for the fair sparse PCA case where a penalty parameter that controls the sparsity has to be chosen by the user). We numerically compare the performance of the proposed methods with two of the state-of-the-art approaches on synthetic data sets and real-life data sets.},
  archive      = {J_TMLR},
  author       = {Prabhu babu and Petre Stoica and Astha Saini},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Fair principal component analysis (PCA): Minorization-maximization algorithms for fair PCA, fair robust PCA and fair sparse PCA},
  url          = {https://openreview.net/forum?id=6jTQrr3APY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explaining explainability: Recommendations for effective use
of concept activation vectors. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=7CUluLpLxV">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept-based explanations translate the internal representations of deep learning models into a language that humans are familiar with: concepts. One popular method for finding concepts is Concept Activation Vectors (CAVs), which are learnt using a probe dataset of concept exemplars. In this work, we investigate three properties of CAVs: (1) inconsistency across layers, (2) entanglement with other concepts, and (3) spatial dependency. Each property provides both challenges and opportunities in interpreting models. We introduce tools designed to detect the presence of these properties, provide insight into how each property can lead to misleading explanations, and provide recommendations to mitigate their impact. To demonstrate practical applications, we apply our recommendations to a melanoma classification task, showing how entanglement can lead to uninterpretable results and that the choice of negative probe set can have a substantial impact on the meaning of a CAV. Further, we show that understanding these properties can be used to our advantage. For example, we introduce spatially dependent CAVs to test if a model is translation invariant with respect to a specific concept and class. Our experiments are performed on natural images (ImageNet), skin lesions (ISIC 2019), and a new synthetic dataset, Elements. Elements is designed to capture a known ground truth relationship between concepts and classes. We release this dataset to facilitate further research in understanding and evaluating interpretability methods.},
  archive      = {J_TMLR},
  author       = {Angus Nicolson and Lisa Schut and Alison Noble and Yarin Gal},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Explaining explainability: Recommendations for effective use of concept activation vectors},
  url          = {https://openreview.net/forum?id=7CUluLpLxV},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph neural networks through the lens of message
passing: A common perspective to homophily and architecture design.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8rxtL0kZnX">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the current learning methodologies and benchmarking datasets in the hypergraph realm are obtained by \emph{lifting} procedures from their graph analogs, leading to overshadowing specific characteristics of hypergraphs. This paper attempts to confront some pending questions in that regard: Q1 Can the concept of homophily play a crucial role in Hypergraph Neural Networks (HNNs)? Q2 How do models that employ unique characteristics of higher-order networks perform compared to lifted models? Q3 Do well-established hypergraph datasets provide a meaningful benchmark for HNNs? To address them, we first introduce a novel conceptualization of homophily in higher-order networks based on a Message Passing (MP) scheme, unifying both the analytical examination and the modeling of higher-order networks. Further, we investigate some natural strategies for processing higher-order structures within HNNs (such as keeping hyperedge-dependent node representations or performing node/hyperedge stochastic samplings), leading us to the most general MP formulation up to date --MultiSet. Finally, we conduct an extensive set of experiments that contextualize our proposals.},
  archive      = {J_TMLR},
  author       = {Lev Telyatnikov and Maria Sofia Bucarelli and Guillermo Bernardez and Olga Zaghen and Simone Scardapane and Pietro Lio},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Hypergraph neural networks through the lens of message passing: A common perspective to homophily and architecture design},
  url          = {https://openreview.net/forum?id=8rxtL0kZnX},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partially personalized federated learning: Breaking the
curse of data heterogeneity. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=8tMMCf4YYn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a partially personalized formulation of Federated Learning (FL) that strikes a balance between the flexibility of personalization and cooperativeness of global training. In our framework, we split the variables into global parameters, which are shared across all clients, and individual local parameters, which are kept private. We prove that under the right split of parameters, it is possible to find global parameters that allow each client to fit their data perfectly, and refer to the obtained problem as overpersonalized. For instance, the shared global parameters can be used to learn good data representations, whereas the personalized layers are fine-tuned for a specific client. Moreover, we present a simple algorithm for the partially personalized formulation that offers significant benefits to all clients. In particular, it breaks the curse of data heterogeneity in several settings, such as training with local steps, asynchronous training, and Byzantine-robust training.},
  archive      = {J_TMLR},
  author       = {Konstantin Mishchenko and Rustem Islamov and Eduard Gorbunov and Samuel Horváth},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Partially personalized federated learning: Breaking the curse of data heterogeneity},
  url          = {https://openreview.net/forum?id=8tMMCf4YYn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-pass detection of jailbreaking input in large
language models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=42v6I5Ut9a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defending aligned Large Language Models (LLMs) against jailbreaking attacks is a challenging problem, with existing approaches requiring multiple requests or even queries to auxiliary LLMs, making them computationally heavy. Instead, we focus on detecting jailbreaking input in a single forward pass. Our method, called SPD, leverages the information carried by the logits to predict whether the output sentence will be harmful. This allows us to defend in just a forward pass. SPD can not only detect attacks effectively on open-source models, but also minimizes the misclassification of harmless inputs. Furthermore, we show that SPD remains effective even without complete logit access in GPT-3.5 and GPT-4. We believe that our proposed method offers a promising approach to efficiently safeguard LLMs against adversarial attacks.},
  archive      = {J_TMLR},
  author       = {Leyla Naz Candogan and Yongtao Wu and Elias Abad Rocamora and Grigorios Chrysos and Volkan Cevher},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Single-pass detection of jailbreaking input in large language models},
  url          = {https://openreview.net/forum?id=42v6I5Ut9a},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analytical model for overparameterized learning under
class imbalance. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=69RntSRF5K">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study class-imbalanced linear classification in a high-dimensional Gaussian mixture model. We develop a tight, closed form approximation for the test error of several practical learning methods, including logit adjustment and class dependent temperature. Our approximation allows us to analytically tune and compare these methods, highlighting how and when they overcome the pitfalls of standard cross-entropy minimization. We test our theoretical findings on simulated data and imbalanced CIFAR10, MNIST and FashionMNIST datasets.},
  archive      = {J_TMLR},
  author       = {Eliav Mor and Yair Carmon},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {An analytical model for overparameterized learning under class imbalance},
  url          = {https://openreview.net/forum?id=69RntSRF5K},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relax and penalize: A new bilevel approach to mixed-binary
hyperparameter optimization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=A1R1cQ93Cb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, bilevel approaches have become very popular to efficiently estimate high-dimensional hyperparameters of machine learning models. However, to date, binary parameters are handled by continuous relaxation and rounding strategies, which could lead to inconsistent solutions. In this context, we tackle the challenging optimization of mixed-binary hyperparameters by resorting to an equivalent continuous bilevel reformulation based on an appropriate penalty term. We propose an algorithmic framework that, under suitable assumptions, is guaranteed to provide mixed-binary solutions. Moreover, the generality of the method allows to safely use existing continuous bilevel solvers within the proposed framework. We evaluate the performance of our approach for two specific machine learning problems, i.e., the estimation of the group-sparsity structure in regression problems and the data distillation problem. The reported results show that our method is competitive with state-of-the-art approaches based on relaxation and rounding.},
  archive      = {J_TMLR},
  author       = {Sara Venturini and Marianna De Santis and Jordan Patracone and Martin Schmidt and Francesco Rinaldi and Saverio Salzo},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Relax and penalize: A new bilevel approach to mixed-binary hyperparameter optimization},
  url          = {https://openreview.net/forum?id=A1R1cQ93Cb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density of states in neural networks: An in-depth
exploration of learning in parameter space. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=BLDtWlFKhn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning in neural networks critically hinges on the intricate geometry of the loss landscape associated with a given task. Traditionally, most research has focused on finding specific weight configurations that minimize the loss. In this work, born from the cross-fertilization of machine learning and theoretical soft matter physics, we introduce a novel approach to examine the weight space across all loss values. Employing the Wang-Landau enhanced sampling algorithm, we explore the neural network density of states -- the number of network parameter configurations that produce a given loss value -- and analyze how it depends on specific features of the training set. Using both real-world and synthetic data, we quantitatively elucidate the relation between data structure and network density of states across different sizes and depths of binary-state networks. This work presents and illustrates a novel, informative analysis method that aims at paving the way for a better understanding of the interplay between structured data and the networks that process, learn, and generate them.},
  archive      = {J_TMLR},
  author       = {Margherita Mele and Roberto Menichetti and Alessandro Ingrosso and Raffaello Potestio},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Density of states in neural networks: An in-depth exploration of learning in parameter space},
  url          = {https://openreview.net/forum?id=BLDtWlFKhn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning from simulated interactions via multitask
prospective rehearsal for bionic limb behavior modeling. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=Bmy82p2eez">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower limb amputations and neuromuscular impairments severely restrict mobility, necessitating advancements beyond conventional prosthetics. While motorized bionic limbs show promise, their effectiveness depends on replicating the dynamic coordination of human movement across diverse environments. In this paper, we introduce a model for human behavior in the context of bionic prosthesis control. Our approach leverages human locomotion demonstrations to learn the synergistic coupling of the lower limbs, enabling the prediction of the kinematic behavior of a missing limb during tasks such as walking, climbing inclines, and stairs. We propose a multitasking, continually adaptive model that anticipates and refines movements over time. At the core of our method is a technique which we call the multitask prospective rehearsal, that anticipates and synthesizes future movements based on the previous prediction and employs a corrective mechanism for subsequent predictions. Our evolving architecture merges lightweight, task-specific modules on a shared backbone, ensuring both specificity and scalability. We validate our model through experiments on real-world human gait datasets, including transtibial amputees, across a wide range of locomotion tasks. Results demonstrate that our approach consistently outperforms baseline models, particularly in scenarios with distributional shifts, adversarial perturbations, and noise.},
  archive      = {J_TMLR},
  author       = {Sharmita Dey and Benjamin Paassen and Sarath Ravindran Nair and Sabri Boughorbel and Arndt F. Schilling},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Continual learning from simulated interactions via multitask prospective rehearsal for bionic limb behavior modeling},
  url          = {https://openreview.net/forum?id=Bmy82p2eez},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning for graphs with heterogeneous node attribute
spaces for few-shot edge predictions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=CAkt3DsAZs">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of edges between nodes in graph data is useful for many applications, such as social network analysis and knowledge graph completion. Existing graph neural network-based approaches have achieved notable advancements, but encounter significant difficulty in building an effective model when there is an insufficient number of known edges in graphs. Although some meta-learning approaches were introduced to solve this problem, having an assumption that the nodes of training graphs and test graphs are in homogeneous attribute spaces, which limits the flexibility of applications. In this paper, we proposed a meta-learning method for edge prediction that can learn from graphs with nodes in heterogeneous attribute spaces. The proposed model consists of attribute-wise message-passing networks that transform information between connected nodes for each attribute, resulting in attribute-specific node embeddings. The node embeddings are obtained by calculating the mean of the attribute-specific node embeddings.The encoding operation can be repeated multiple times to capture complex patterns. The attribute-wise message-passing networks are shared across all graphs, allowing knowledge transfer between different graphs.The probabilities of edges are estimated by the Euclidian distance between node embeddings. Experimental results on 14 real-world data sets demonstrate that the proposed method outperforms existing methods in edge prediction problems with sparse edge information.},
  archive      = {J_TMLR},
  author       = {Zhong Chuang and Yusuke Tanaka and Tomoharu Iwata},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Meta-learning for graphs with heterogeneous node attribute spaces for few-shot edge predictions},
  url          = {https://openreview.net/forum?id=CAkt3DsAZs},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On memorization in diffusion models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=D3DBqvSDbj">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to their capacity to generate novel and high-quality samples, diffusion models have attracted significant research interest in recent years. Notably, the typical training objective of diffusion models, i.e., denoising score matching, has a closed-form optimal solution that can only generate training-data replicating samples. This indicates that a memorization behavior is theoretically expected, which contradicts the common generalization ability of state-of-the-art diffusion models, and thus calls for a deeper understanding. Looking into this, we first observe that memorization behaviors tend to occur on smaller-sized datasets, which motivates our definition of effective model memorization (EMM), a metric measuring the maximum size of training data at which a model approximates its theoretical optimum. Then, we quantify the impact of the influential factors on these memorization behaviors in terms of EMM, focusing primarily on data distribution, model configuration, and training procedure. Besides comprehensive empirical results identifying the influential factors, we surprisingly find that conditioning training data on uninformative random labels can significantly trigger the memorization in diffusion models. Our study holds practical significance for diffusion model users and offers clues to theoretical research in deep generative models.},
  archive      = {J_TMLR},
  author       = {Xiangming Gu and Chao Du and Tianyu Pang and Chongxuan Li and Min Lin and Ye Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On memorization in diffusion models},
  url          = {https://openreview.net/forum?id=D3DBqvSDbj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometry-aware visualization of high dimensional symmetric
positive definite matrices. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DYCSRf3vby">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetric Positive Definite (SPD) matrices are pervasive in machine learning, from data features (such as covariance matrices) to optimization process.These matrices induce a Riemannian structure, where the curvature plays a critical role in the success of approaches based on those geometries. Yet, for ML practitioners wanting to visualize SPD matrices, the existing (flat) Euclidean approaches will hide the curvature of the manifold. To overcome this lack of expressivity in the existing algorithms, we introduce Riemannian versions of two state-of-the-art techniques, namely t-SNE and Multidimensional Scaling. Therefore, we are able to reduce a set of $c \times c$ SPD matrices into a set of $2 \times 2$ SPD matrices in order to capture the curvature information and avoid any distortion induced by flattening the representation in an Euclidean setup. Moreover, our approaches pave the way for targeting more general dimensionality reduction applications while preserving the geometry of the data. We performed experiments on controlled synthetic dataset to ensure that the low-dimensional representation preserves the geometric properties of both SPD Gaussians and geodesics. We also conduct experiments on various real datasets, such as video, anomaly detection, brain signal and others.},
  archive      = {J_TMLR},
  author       = {Thibault de Surrel and Sylvain Chevallier and Fabien Lotte and Florian Yger},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Geometry-aware visualization of high dimensional symmetric positive definite matrices},
  url          = {https://openreview.net/forum?id=DYCSRf3vby},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wasserstein coreset via sinkhorn loss. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=DrMCDS88IL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coreset selection, a technique for compressing large datasets while preserving performance, is crucial for modern machine learning. This paper presents a novel method for generating high-quality Wasserstein coresets using the Sinkhorn loss, a powerful tool with computational advantages. However, existing approaches suffer from numerical instability in Sinkhorn&#39;s algorithm. We address this by proposing stable algorithms for the computation and differentiation of the Sinkhorn optimization problem, including an analytical formula for the derivative of the Sinkhorn loss and a rigorous stability analysis of our method. Extensive experiments demonstrate that our approach significantly outperforms existing methods in terms of sample selection quality, computational efficiency, and achieving a smaller Wasserstein distance.},
  archive      = {J_TMLR},
  author       = {Haoyun Yin and Yixuan Qiu and Xiao Wang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wasserstein coreset via sinkhorn loss},
  url          = {https://openreview.net/forum?id=DrMCDS88IL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust preference optimization through reward model
distillation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=E2zKNuwNDc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language model (LM) post-training (or alignment) involves maximizing a reward function that is derived from preference annotations. Direct Preference Optimization (DPO) is a popular offline alignment method that trains a policy directly on preference data without the need to train a reward model or apply reinforcement learning. However, the empirical evidence suggests that DPO typically assigns implicit rewards that overfit, and trend towards infinite magnitude. This frequently leads to degenerate policies, sometimes causing even the probabilities of the preferred generations to go to zero. In this work, we analyze this phenomenon and use distillation to get a better proxy for the true preference distribution over generation pairs: we train the LM such that its induced implicit reward, i.e., the scaled log-likelihood ratio of the model to the reference model, matches an explicit reward model trained on the preference data. Moreover, to account for uncertainty in the reward model we are distilling from, we optimize against a family of reward models that, as a whole, is likely to include at least one reasonable proxy for the preference distribution. Our results show that distilling from such a family of reward models leads to improved robustness to distribution shift in preference annotations, while preserving the simple supervised nature of DPO.},
  archive      = {J_TMLR},
  author       = {Adam Fisch and Jacob Eisenstein and Vicky Zayats and Alekh Agarwal and Ahmad Beirami and Chirag Nagpal and Peter Shaw and Jonathan Berant},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Robust preference optimization through reward model distillation},
  url          = {https://openreview.net/forum?id=E2zKNuwNDc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Producers equilibria and dynamics in engagement-driven
recommender systems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EWT4GxjGDS">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online platforms such as YouTube, Instagram heavily rely on recommender systems to decide what content to present to users. Producers, in turn, often create content that is likely to be recommended to users and have users engage with it. To do so, producers try to align their content with the preferences of their targeted user base. In this work, we explore the equilibrium behavior of producers who are interested in maximizing user engagement. We study two variants of the content-serving rule for the platform&#39;s recommender system, and provide a structural characterization of producer behavior at equilibrium: namely, each producer chooses to focus on a single embedded feature. We further show that specialization, defined as different producers optimizing for distinct types of content, naturally emerges from the competition among producers trying to maximize user engagement. We provide a heuristic for computing equilibria of our engagement game, and evaluate it experimentally. We highlight i) the performance and convergence of our heuristic, ii) the degree of producer specialization, and iii) the impact of the content-serving rule on producer and user utilities at equilibrium and provide guidance on how to set the content-serving rule.},
  archive      = {J_TMLR},
  author       = {Krishna Acharya and Juba Ziani and Jingyan Wang and Varun Vangala},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Producers equilibria and dynamics in engagement-driven recommender systems},
  url          = {https://openreview.net/forum?id=EWT4GxjGDS},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative risk minimization for out-of-distribution
generalization on graphs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=EcMVskXo1n">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-distribution (OOD) generalization on graphs aims at dealing with scenarios where the test graph distribution differs from the training graph distributions. Compared to i.i.d. data like images, the OOD generalization problem on graph-structured data remains challenging due to the non-i.i.d. property and complex structural information on graphs. Recently, several works on graph OOD generalization have explored extracting invariant subgraphs that share crucial classification information across different distributions. Nevertheless, such a strategy could be suboptimal for entirely capturing the invariant information, as the extraction of discrete structures could potentially lead to the loss of invariant information or the involvement of spurious information. In this paper, we propose an innovative framework, named Generative Risk Minimization (GRM), designed to generate an invariant subgraph for each input graph to be classified, instead of extraction. To address the challenge of optimization in the absence of optimal invariant subgraphs (i.e., ground truths), we derive a tractable form of the proposed GRM objective by introducing a latent causal variable, and its effectiveness is validated by our theoretical analysis. We further conduct extensive experiments across a variety of real-world graph datasets for both node-level and graph-level OOD generalization, and the results demonstrate the superiority of our framework GRM.},
  archive      = {J_TMLR},
  author       = {Song Wang and Zhen Tan and Yaochen Zhu and Chuxu Zhang and Jundong Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Generative risk minimization for out-of-distribution generalization on graphs},
  url          = {https://openreview.net/forum?id=EcMVskXo1n},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the regularization of learnable embeddings for time
series forecasting. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=F5ALCh3GWG">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In forecasting multiple time series, accounting for the individual features of each sequence can be challenging. To address this, modern deep learning methods for time series analysis combine a shared (global) model with local layers, specific to each time series, often implemented as learnable embeddings. Ideally, these local embeddings should encode meaningful representations of the unique dynamics of each sequence. However, when these are learned end-to-end as parameters of a forecasting model, they may end up acting as mere sequence identifiers. Shared processing blocks may then become reliant on such identifiers, limiting their transferability to new contexts. In this paper, we address this issue by investigating methods to regularize the learning of local learnable embeddings for time series processing. Specifically, we perform the first extensive empirical study on the subject and show how such regularizations consistently improve performance in widely adopted architectures. Furthermore, we show that methods attempting to prevent the co-adaptation of local and global parameters by means of embeddings perturbation are particularly effective in this context. In this regard, we include in the comparison several perturbation-based regularization methods, going as far as periodically resetting the embeddings during training. The obtained results provide an important contribution to understanding the interplay between learnable local parameters and shared processing layers: a key challenge in modern time series processing models and a step toward developing effective foundation models for time series.},
  archive      = {J_TMLR},
  author       = {Luca Butera and Giovanni De Felice and Andrea Cini and Cesare Alippi},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the regularization of learnable embeddings for time series forecasting},
  url          = {https://openreview.net/forum?id=F5ALCh3GWG},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Necessary and sufficient watermark for large language
models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=FcyHZ6Q4k0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) can now generate texts that are indistinguishable from those written by humans. Such remarkable performance of LLMs increases their risk of being used for malicious purposes. Thus, it is necessary to develop methods for distinguishing texts written by LLMs from those written by humans. Watermarking is one of the most powerful methods for achieving this. Although existing methods have successfully detected texts generated by LLMs, they inevitably degrade the text quality. In this study, we propose the Necessary and Sufficient Watermark (NS-Watermark) for inserting watermarks into generated texts with minimum text quality degradation. More specifically, we derive minimum constraints required to be imposed on the generated texts to distinguish whether LLMs or humans write the texts, and we formulate the NS-Watermark as a constrained optimization problem. Through the experiments, we demonstrate that the NS-Watermark can generate more natural texts than existing watermarking methods and distinguish more accurately between texts written by LLMs and those written by humans. Especially in machine translation tasks, the NS-Watermark can outperform the existing watermarking method by up to 30 BLEU scores.},
  archive      = {J_TMLR},
  author       = {Yuki Takezawa and Ryoma Sato and Han Bao and Kenta Niwa and Makoto Yamada},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Necessary and sufficient watermark for large language models},
  url          = {https://openreview.net/forum?id=FcyHZ6Q4k0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics-inspired structure hallucination for
protein-protein interaction modeling. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=GGHk5ukO6t">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein-protein interaction (PPI) represents a central challenge within the biology field, and accurately predicting the consequences of mutations in this context is crucial for drug design and protein engineering. Deep learning (DL) has shown promise in forecasting the effects of such mutations but is hindered by two primary constraints. First, the structures of mutant proteins are often elusive to acquire. Secondly, PPI takes place dynamically, which is rarely integrated into the DL architecture design. To address these obstacles, we present a novel framework named Refine-PPI with two key enhancements. First, we introduce a structure refinement module trained by a mask mutation modeling (MMM) task on available wild-type structures, which is then transferred to hallucinate the inaccessible mutant structures. Second, we employ a new kind of geometric network, called the probability density cloud network (PDC-Net), to capture 3D dynamic variations and encode the atomic uncertainty associated with PPI. Comprehensive experiments on SKEMPI.v2 substantiate the superiority of Refine-PPI over all existing tools for predicting free energy change. These findings underscore the effectiveness of our hallucination strategy and the PDC module in addressing the absence of mutant protein structure and modeling geometric uncertainty.},
  archive      = {J_TMLR},
  author       = {Fang Wu and Stan Z. Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Dynamics-inspired structure hallucination for protein-protein interaction modeling},
  url          = {https://openreview.net/forum?id=GGHk5ukO6t},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of best-of-n sampling strategies for language
model alignment. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=H4S4ETc8c9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Best-of-N (BoN) sampling with a reward model has been shown to be an effective strategy for aligning Large Language Models (LLMs) with human preferences at the time of decoding. BoN sampling is susceptible to a problem known as reward hacking. Since the reward model is an imperfect proxy for the true objective, an excessive focus on optimizing its value can lead to a compromise of its performance on the true objective. Previous work proposes Regularized BoN sampling (RBoN), a BoN sampling with regularization to the objective, and shows that it outperforms BoN sampling so that it mitigates reward hacking and empirically (Jinnai et al., 2024). However, Jinnai et al. (2024) introduce RBoN based on a heuristic and they lack the analysis of why such regularization strategy improves the performance of BoN sampling. The aim of this study is to analyze the effect of BoN sampling on regularization strategies. Using the regularization strategies corresponds to robust optimization, which maximizes the worst case over a set of possible perturbations in the proxy reward. Although the theoretical guarantees are not directly applicable to RBoN, RBoN corresponds to a practical implementation. This paper proposes an extension of the RBoN framework, called Stochastic RBoN sampling (SRBoN), which is a theoretically guaranteed approach to worst-case RBoN in proxy reward. We then perform an empirical evaluation using the AlpacaFarm and Anthropic’s hh-rlhf datasets to evaluate which factors of the regularization strategies contribute to the improvement of the true proxy reward. In addition, we also propose another simple RBoN method, the Sentence Length Regularized BoN, which has a better performance in the experiment as compared to the previous methods.},
  archive      = {J_TMLR},
  author       = {Yuki Ichihara and Yuu Jinnai and Tetsuro Morimura and Kenshi Abe and Kaito Ariu and Mitsuki Sakamoto and Eiji Uchibe},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluation of best-of-N sampling strategies for language model alignment},
  url          = {https://openreview.net/forum?id=H4S4ETc8c9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking spectral augmentation for contrast-based graph
self-supervised learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HjpD5kpfa3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent surge in contrast-based graph self-supervised learning has prominently featured an intensified exploration of spectral cues. Spectral augmentation, which involves modifying a graph&#39;s spectral properties such as eigenvalues or eigenvectors, is widely believed to enhance model performance. However, an intriguing paradox emerges, as methods grounded in seemingly conflicting assumptions regarding the spectral domain demonstrate notable enhancements in learning performance. Through extensive empirical studies, we find that simple edge perturbations - random edge dropping for node-level and random edge adding for graph-level self-supervised learning - consistently yield comparable or superior performance while being significantly more computationally efficient. This suggests that the computational overhead of sophisticated spectral augmentations may not justify their practical benefits. Our theoretical analysis of the InfoNCE loss bounds for shallow GNNs further supports this observation. The proposed insights represent a significant leap forward in the field, potentially refining the understanding and implementation of graph self-supervised learning.},
  archive      = {J_TMLR},
  author       = {Xiangru Jian and Xinjian Zhao and Wei Pang and Chaolong Ying and Yimu Wang and Yaoyao Xu and Tianshu Yu},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Rethinking spectral augmentation for contrast-based graph self-supervised learning},
  url          = {https://openreview.net/forum?id=HjpD5kpfa3},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the stability of gradient descent with second order
dynamics for time-varying cost functions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=HlzjI2fn2T">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient based optimization algorithms deployed in Machine Learning (ML) applications are often analyzed and compared by their convergence rates or regret bounds. While these rates and bounds convey valuable information they don’t always directly translate to stability guarantees. Stability and similar concepts, like robustness, will become ever more important as we move towards deploying models in real-time and safety critical systems. In this work we build upon the results in Gaudio et al. 2021 and Moreu &amp; Annaswamy 2022 for gradient descent with second order dynamics when applied to explicitly time varying cost functions and provide more general stability guarantees. These more general results can aid in the design and certification of these optimization schemes so as to help ensure safe and reliable deployment for real-time learning applications. We also hope that the techniques provided here will stimulate and cross-fertilize the analysis that occurs on the same algorithms from the online learning and stochastic optimization communities.},
  archive      = {J_TMLR},
  author       = {Travis E Gibson and Sawal Acharya and Anjali Parashar and Joseph Emilio Gaudio and Anuradha Annaswamy},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the stability of gradient descent with second order dynamics for time-varying cost functions},
  url          = {https://openreview.net/forum?id=HlzjI2fn2T},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nomic embed: Training a reproducible long context text
embedder. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=IPmzyQSiQE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This technical report describes the training of nomic-embed-text-v1, the first fully reproducible, open-source, open-weights, open-data, 8192 context length English text embedding model that outperforms both OpenAI Ada-002 and OpenAI text-embedding-3-small on the short-context MTEB benchmark and the long context LoCo benchmark. We release the training code and model weights under an Apache 2.0 license. In contrast with other open-source models, we release the full curated training data and code that allows for full replication of nomic-embed-text-v1. You can find code and data to replicate the model at \href{https://github.com/nomic-ai/contrastors}{https://github.com/nomic-ai/contrastors}},
  archive      = {J_TMLR},
  author       = {Zach Nussbaum and John Xavier Morris and Andriy Mulyar and Brandon Duderstadt},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Nomic embed: Training a reproducible long context text embedder},
  url          = {https://openreview.net/forum?id=IPmzyQSiQE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metalearning continual learning algorithms. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=IaUh7CSD3k">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {General-purpose learning systems should improve themselves in open-ended fashion in ever-changing environments. Conventional learning algorithms for neural networks, however, suffer from catastrophic forgetting (CF), i.e., previously acquired skills are forgotten when a new task is learned. Instead of hand-crafting new algorithms for avoiding CF, we propose Automated Continual Learning (ACL) to train self-referential neural networks to metalearn their own in-context continual (meta)learning algorithms. ACL encodes continual learning (CL) desiderata---good performance on both old and new tasks---into its metalearning objectives. Our experiments demonstrate that ACL effectively resolves &quot;in-context catastrophic forgetting,&quot; a problem that naive in-context learning algorithms suffer from; ACL learned algorithms outperform both hand-crafted learning algorithms and popular meta-continual learning methods on the Split-MNIST benchmark in the replay-free setting, and enables continual learning of diverse tasks consisting of multiple standard image classification datasets. We also discuss the current limitations of in-context CL by comparing ACL with state-of-the-art CL methods that leverage pre-trained models. Overall, we bring several novel perspectives into the long-standing problem of CL.},
  archive      = {J_TMLR},
  author       = {Kazuki Irie and Róbert Csordás and Jürgen Schmidhuber},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Metalearning continual learning algorithms},
  url          = {https://openreview.net/forum?id=IaUh7CSD3k},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What makes ImageNet look unlike LAION. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=IrBYuh9W3T">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ImageNet was famously created by querying several image search engines such as Flickr. What if we recreated ImageNet instead by searching the massive LAION dataset based on image captions alone? In this work, we carry out this counterfactual investigation. We find that the resulting ImageNet recreation, which we call LAIONet, looks distinctly unlike the original. Specifically, the intra-class similarity of images in the original ImageNet is dramatically higher than it is for LAIONet. Consequently, models trained on ImageNet perform significantly worse on LAIONet. We propose a rigorous explanation for the discrepancy in terms of a subtle, yet important, difference in two plausible causal data-generating processes for the respective datasets, that we support with systematic experimentation. In a nutshell, searching based on an image caption alone creates an information bottleneck that mitigates the selection bias otherwise present in image-based filtering. Our explanation formalizes a long-held intuition in the community that ImageNet images are stereotypical, unnatural, and overly simple representations of the class category. At the same time, it provides a simple and actionable takeaway for future dataset creation efforts.},
  archive      = {J_TMLR},
  author       = {Ali Shirali and Moritz Hardt},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {What makes ImageNet look unlike LAION},
  url          = {https://openreview.net/forum?id=IrBYuh9W3T},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fused gromov-wasserstein approach to subgraph contrastive
learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=J7cY9Jr9WM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning has become a key method for training deep learning models when labeled data is scarce or unavailable. While graph machine learning holds great promise across various domains, the design of effective pretext tasks for self-supervised graph representation learning remains challenging. Contrastive learning, a popular approach in graph self-supervised learning, leverages positive and negative pairs to compute a contrastive loss function. However, current graph contrastive learning methods often struggle to fully use structural patterns and node similarities. To address these issues, we present a new method called Fused Gromov-Wasserstein Subgraph Contrastive Learning (FOSSIL). Our method integrates node-level and subgraph-level contrastive learning, seamlessly combining a standard node-level contrastive loss with the Fused Gromov-Wasserstein distance. This combination helps our method capture both node features and graph structure together. Importantly, our approach works well with both homophilic and heterophilic graphs and can dynamically create views for generating positive and negative pairs. Through extensive experiments on benchmark graph datasets, we show that FOSSIL outperforms or achieves competitive performance compared to current state-of-the-art methods.},
  archive      = {J_TMLR},
  author       = {Amadou Siaka SANGARE and Nicolas Dunou and Jhony H. Giraldo and Fragkiskos D. Malliaros},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A fused gromov-wasserstein approach to subgraph contrastive learning},
  url          = {https://openreview.net/forum?id=J7cY9Jr9WM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). JoIN: Joint GANs inversion for intrinsic image
decomposition. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JEHIVfjmOf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrinsic Image Decomposition (IID) is a challenging inverse problem that seeks to decompose a natural image into its underlying intrinsic components such as albedo and shading. While recent image decomposition methods rely on learning-based priors on these components, they often suffer from component cross-contamination owing to joint training of priors; or from Sim-to-Real gap since the priors trained on synthetic data are kept frozen during the inference on real images. In this work, we propose to solve the intrinsic image decomposition problem using a bank of Generative Adversarial Networks (GANs) as priors where each GAN is independently trained only on a single intrinsic component, providing stronger and more disentangled priors. At the core of our approach is the idea that the latent space of a GAN is a well-suited optimization domain to solve inverse problems. Given an input image, we propose to jointly invert the latent codes of a set of GANs and combine their outputs to reproduce the input. Contrary to all existing GAN inversion methods that are limited to inverting only a single GAN, our proposed approach, JoIN, is able to jointly invert multiple GANs using only a single image as supervision while still maintaining distribution priors of each intrinsic component. We show that our approach is modular, allowing various forward imaging models, and that it can successfully decompose both synthetic and real images. Further, taking inspiration from existing GAN inversion approaches, we allow for careful fine-tuning of the generator priors during the inference on real images. This way, our method is able to achieve excellent generalization on real images even though it uses only synthetic data to train the GAN priors. We demonstrate the success of our approach through exhaustive qualitative and quantitative evaluations and ablation studies on various datasets.},
  archive      = {J_TMLR},
  author       = {Viraj Shah and Svetlana Lazebnik and Julien Philip},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {JoIN: Joint GANs inversion for intrinsic image decomposition},
  url          = {https://openreview.net/forum?id=JEHIVfjmOf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A strong baseline for molecular few-shot learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JQ0agisXny">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning has recently attracted significant interest in drug discovery, with a recent, fast-growing literature mostly involving convoluted meta-learning strategies. We revisit the more straightforward fine-tuning approach for molecular data, and propose a regularized quadratic-probe loss based on the the Mahalanobis distance. We design a dedicated block-coordinate descent optimizer, which avoid the degenerate solutions of our loss. Interestingly, our simple fine-tuning approach achieves highly competitive performances in comparison to state-of-the-art methods, while being applicable to black-box settings and removing the need for specific episodic pre-training strategies. Furthermore, we introduce a new benchmark to assess the robustness of the competing methods to domain shifts. In this setting, our fine-tuning baseline obtains consistently better results than meta-learning methods.},
  archive      = {J_TMLR},
  author       = {Philippe Formont and Hugo Jeannin and Pablo Piantanida and Ismail Ben Ayed},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A strong baseline for molecular few-shot learning},
  url          = {https://openreview.net/forum?id=JQ0agisXny},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards context and domain-aware algorithms for scene
analysis. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=JQGmbVK4Fr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpersonal interactions and social situations in multimedia content encompass a rich blend of visual, textual, audio and contextual cues as well. However, contextual data integration in multimodal scene analysis research has often been overlooked, leading to incomplete interpretations. For instance, recognizing that two combatants in a video are positioned within a designated ring with a dedicated referee drastically alters the perception from a simple scuffle to a structured martial arts contest. This paper presents an innovative approach to scene analysis in video content, which not only incorporates contextual data but also emphasizes the most significant features during training. Additionally, we introduce a methodology for integrating domain knowledge into our framework. We evaluate our proposed methodology using two comprehensive datasets, demonstrating promising results compared to a baseline study using one of the datasets. These findings underscore the importance of integrating contextual data into multimodal video analysis, while also recognizing the challenges associated with their utilization.},
  archive      = {J_TMLR},
  author       = {Ibrahim Serouis and Florence Sèdes},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards context and domain-aware algorithms for scene analysis},
  url          = {https://openreview.net/forum?id=JQGmbVK4Fr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provable quantum algorithm advantage for gaussian process
quadrature. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=K6CvWPtF62">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to develop novel quantum algorithms for Gaussian process quadrature methods. Gaussian process quadratures are numerical integration methods where Gaussian processes are used as functional priors for the integrands to capture the uncertainty arising from the sparse function evaluations. Quantum computers have emerged as potential replacements for classical computers, offering exponential reductions in the computational complexity of machine learning tasks. In this paper, we combine Gaussian process quadrature and quantum computing by proposing a quantum low-rank Gaussian process quadrature method based on a Hilbert space approximation of the Gaussian process kernel and enhancing the quadrature using a quantum circuit. The method combines the quantum phase estimation algorithm with the quantum principal component analysis technique to extract information up to a desired rank. Then, Hadamard and SWAP tests are implemented to find the expected value and variance that determines the quadrature. We use numerical simulations of a quantum computer to demonstrate the effectiveness of the method. Furthermore, we provide a theoretical complexity analysis that shows a polynomial advantage over classical Gaussian process quadrature methods. The code is available at https://github.com/cagalvisf/Quantum_HSGPQ.},
  archive      = {J_TMLR},
  author       = {Cristian A. Galvis-Florez and Ahmad Farooq and Simo Särkkä},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Provable quantum algorithm advantage for gaussian process quadrature},
  url          = {https://openreview.net/forum?id=K6CvWPtF62},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformalized credal regions for classification with
ambiguous ground truth. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=L7sQ8CW2FY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An open question in Imprecise Probabilistic Machine Learning is how to empirically derive a credal region (i.e., a closed and convex family of probabilities on the output space) from the available data, without any prior knowledge or assumption. In classification problems, credal regions are a tool that is able to provide provable guarantees under realistic assumptions by characterizing the uncertainty about the distribution of the labels. Building on previous work, we show that credal regions can be directly constructed using conformal methods. This allows us to provide a novel extension of classical conformal prediction to problems with ambiguous ground truth, that is, when the exact labels for given inputs are not exactly known. The resulting construction enjoys desirable practical and theoretical properties: (i) conformal coverage guarantees, (ii) smaller prediction sets (compared to classical conformal prediction regions) and (iii) disentanglement of uncertainty sources (epistemic, aleatoric). We empirically verify our findings on both synthetic and real datasets.},
  archive      = {J_TMLR},
  author       = {Michele Caprio and David Stutz and Shuo Li and Arnaud Doucet},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Conformalized credal regions for classification with ambiguous ground truth},
  url          = {https://openreview.net/forum?id=L7sQ8CW2FY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterated <span
class="math inline"><em>Q</em></span>-network: Beyond one-step bellman
updates in deep reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Lt2H8Bd8jF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vast majority of Reinforcement Learning methods is largely impacted by the computation effort and data requirements needed to obtain effective estimates of action-value functions, which in turn determine the quality of the overall performance and the sample-efficiency of the learning procedure. Typically, action-value functions are estimated through an iterative scheme that alternates the application of an empirical approximation of the Bellman operator and a subsequent projection step onto a considered function space. It has been observed that this scheme can be potentially generalized to carry out multiple iterations of the Bellman operator at once, benefiting the underlying learning algorithm. However, until now, it has been challenging to effectively implement this idea, especially in high-dimensional problems. In this paper, we introduce iterated $Q$-Network (i-QN), a novel principled approach that enables multiple consecutive Bellman updates by learning a tailored sequence of action-value functions where each serves as the target for the next. We show that i-QN is theoretically grounded and that it can be seamlessly used in value-based and actor-critic methods. We empirically demonstrate the advantages of i-QN in Atari $2600$ games and MuJoCo continuous control problems.},
  archive      = {J_TMLR},
  author       = {Théo Vincent and Daniel Palenicek and Boris Belousov and Jan Peters and Carlo D&#39;Eramo},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Iterated $Q$-network: Beyond one-step bellman updates in deep reinforcement learning},
  url          = {https://openreview.net/forum?id=Lt2H8Bd8jF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multi-step refinement network for robust point
cloud registration. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=M3SkSMfWcP">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point Cloud Registration (PCR) estimates the relative rigid transformation between two point clouds of the same scene. Despite significant progress with learning-based approaches, existing methods still face challenges when the overlapping region between the two point clouds is small. In this paper, we propose an adaptive multi-step refinement network that refines the registration quality at each step by leveraging the information from the preceding step. To achieve this, we introduce a training procedure and a refinement network. Firstly, to adapt the network to the current step, we utilize a generalized one-way attention mechanism, which prioritizes the last step&#39;s estimated overlapping region, and we condition the network on step indices. Secondly, instead of training the network to map either random transformations or a fixed pre-trained model&#39;s estimations to the ground truth, we train it on transformations with varying registration qualities, ranging from accurate to inaccurate, thereby enhancing the network&#39;s adaptiveness and robustness. Despite its conceptual simplicity, our method achieves state-of-the-art performance on both the 3DMatch/3DLoMatch and KITTI benchmarks. Notably, on 3DLoMatch, our method reaches 80.4% recall rate, with an absolute improvement of 1.2%.},
  archive      = {J_TMLR},
  author       = {Zhi Chen and Yufan Ren and Tong Zhang and Zheng Dang and Wenbing Tao and Sabine Susstrunk and Mathieu Salzmann},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adaptive multi-step refinement network for robust point cloud registration},
  url          = {https://openreview.net/forum?id=M3SkSMfWcP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REX: GPU-accelerated Sim2Real framework with delay and
dynamics estimation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=O4CQ5AM5yP">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sim2real, the transfer of control policies from simulation to the real world, is crucial for efficiently solving robotic tasks without the risks associated with real-world learning. However, discrepancies between simulated and real environments, especially due to unmodeled dynamics and latencies, significantly impact the performance of these transferred policies. In this paper, we address the challenges of sim2real transfer caused by latency and asynchronous dynamics in real-world robotic systems. Our approach involves developing a novel framework, REX (Robotic Environments with jaX), that uses a graph-based simulation model to incorporate latency effects while optimizing for parallelization on accelerator hardware. Our framework simulates the asynchronous, hierarchical nature of real-world systems, while simultaneously estimating system dynamics and delays from real-world data and implementing delay compensation strategies to minimize the sim2real gap. We validate our approach on two real-world systems, demonstrating its effectiveness in improving sim2real performance by accurately modeling both system dynamics and delays. Our results show that the proposed framework supports both accelerated simulation and real-time processing, making it valuable for robot learning.},
  archive      = {J_TMLR},
  author       = {Bas van der Heijden and Jens Kober and Robert Babuska and Laura Ferranti},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {REX: GPU-accelerated Sim2Real framework with delay and dynamics estimation},
  url          = {https://openreview.net/forum?id=O4CQ5AM5yP},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximum mean discrepancy on exponential windows for online
change detection. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=OGaTF9iOxi">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting changes is of fundamental importance when analyzing data streams and has many applications, e.g., in predictive maintenance, fraud detection, or medicine. A principled approach to detect changes is to compare the distributions of observations within the stream to each other via hypothesis testing. Maximum mean discrepancy (MMD), a (semi-)metric on the space of probability distributions, provides powerful non-parametric two-sample tests on kernel-enriched domains. In particular, MMD is able to detect any disparity between distributions under mild conditions. However, classical MMD estimators suffer from a quadratic runtime complexity, which renders their direct use for change detection in data streams impractical. In this article, we propose a new change detection algorithm, called Maximum Mean Discrepancy on Exponential Windows (MMDEW), that combines the benefits of MMD with an efficient computation based on exponential windows. We prove that MMDEW enjoys polylogarithmic runtime and logarithmic memory complexity and show empirically that it outperforms the state of the art on benchmark data streams.},
  archive      = {J_TMLR},
  author       = {Florian Kalinke and Marco Heyden and Georg Gntuni and Edouard Fouché and Klemens Böhm},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Maximum mean discrepancy on exponential windows for online change detection},
  url          = {https://openreview.net/forum?id=OGaTF9iOxi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DELTA: Dual consistency delving with topological uncertainty
for active graph domain adaptation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=P5y82LKGbY">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph domain adaptation has recently enabled knowledge transfer across different graphs. However, without the semantic information on target graphs, the performance on target graphs is still far from satisfactory. To address the issue, we study the problem of active graph domain adaptation, which selects a small quantitative of informative nodes on the target graph for extra annotation. This problem is highly challenging due to the complicated topological relationships and the distribution discrepancy across graphs. In this paper, we propose a novel approach named Dual Consistency Delving with Topological Uncertainty (DELTA) for active graph domain adaptation. Our DELTA consists of an edge-oriented graph subnetwork and a path-oriented graph subnetwork, which can explore topological semantics from complementary perspectives. In particular, our edge-oriented graph subnetwork utilizes the message passing mechanism to learn neighborhood information, while our path-oriented graph subnetwork explores high-order relationships from substructures. To jointly learn from two subnetworks, we roughly select informative candidate nodes with the consideration of consistency across two subnetworks. Then, we aggregate local semantics from its K-hop subgraph based on node degrees for topological uncertainty estimation. To overcome potential distribution shifts, we compare target nodes and their corresponding source nodes for discrepancy scores as an additional component for fine selection. Extensive experiments on benchmark datasets demonstrate that DELTA outperforms various state-of-the-art approaches. The code implementation of DELTA is available at https://github.com/goose315/DELTA.},
  archive      = {J_TMLR},
  author       = {Pengyun Wang and Yadi Cao and Chris Russell and Yanxin Shen and Junyu Luo and Ming Zhang and Siyu Heng and Xiao Luo},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DELTA: Dual consistency delving with topological uncertainty for active graph domain adaptation},
  url          = {https://openreview.net/forum?id=P5y82LKGbY},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the sample complexity of one hidden layer networks with
equivariance, locality and weight sharing. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Q7aXOnEGgU">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weight sharing, equivariance, and local filters, as in convolutional neural networks, are believed to contribute to the sample efficiency of neural networks. However, it is not clear how each one of these design choices contributes to the generalization error. Through the lens of statistical learning theory, we aim to provide insight into this question by characterizing the relative impact of each choice on the sample complexity. We obtain lower and upper sample complexity bounds for a class of single hidden layer networks. For a large class of activation functions, the bounds depend merely on the norm of filters and are dimension-independent. We also provide bounds for max-pooling and an extension to multi-layer networks, both with mild dimension dependence. We provide a few takeaways from the theoretical results. It can be shown that depending on the weight-sharing mechanism, the non-equivariant weight-sharing can yield a similar generalization bound as the equivariant one. We show that locality has generalization benefits, however the uncertainty principle implies a trade-off between locality and expressivity. We conduct extensive experiments and highlight some consistent trends for these models.},
  archive      = {J_TMLR},
  author       = {Arash Behboodi and Gabriele Cesa},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On the sample complexity of one hidden layer networks with equivariance, locality and weight sharing},
  url          = {https://openreview.net/forum?id=Q7aXOnEGgU},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Where do we stand with implicit neural representations? A
technical and performance survey. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=QTsJXSvAI2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit Neural Representations (INRs) have emerged as a paradigm in knowledge representation, offering exceptional flexibility and performance across a diverse range of applications. INRs leverage multilayer perceptrons (MLPs) to model data as continuous implicit functions, providing critical advantages such as resolution independence, memory efficiency, and generalisation beyond discretised data structures. Their ability to solve complex inverse problems makes them particularly effective for tasks including audio reconstruction, image representation, 3D object reconstruction, and high-dimensional data synthesis. This survey provides a comprehensive review of state-of-the-art INR methods, introducing a clear taxonomy that categorises them into four key areas: activation functions, position encoding, combined strategies, and network structure optimisation. We rigorously analyse their critical properties—such as full differentiability, smoothness, compactness, and adaptability to varying resolutions—while also examining their strengths and limitations in addressing locality biases and capturing fine details. Our experimental comparison offers new insights into the trade-offs between different approaches, showcasing the capabilities and challenges of the latest INR techniques across various tasks. In addition to identifying areas where current methods excel, we highlight key limitations and potential avenues for improvement, such as developing more expressive activation functions, enhancing positional encoding mechanisms, and improving scalability for complex, high-dimensional data. This survey serves as a roadmap for researchers, offering practical guidance for future exploration in the field of INRs. We aim to foster new methodologies by outlining promising research directions for INRs and applications.},
  archive      = {J_TMLR},
  author       = {Amer Essakine and Yanqi Cheng and Chun-Wun Cheng and Lipei Zhang and Zhongying Deng and Lei Zhu and Carola-Bibiane Schönlieb and Angelica I Aviles-Rivero},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Where do we stand with implicit neural representations? a technical and performance survey},
  url          = {https://openreview.net/forum?id=QTsJXSvAI2},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On space folds of ReLU neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=RfFqBXLDQk">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent findings suggest that the consecutive layers of ReLU neural networks can be understood geometrically as space folding transformations of the input space, revealing patterns of self-similarity. In this paper, we present the first quantitative analysis of this space folding phenomenon in ReLU neural networks. Our approach focuses on examining how straight paths in the Euclidean input space are mapped to their counterparts in the Hamming activation space. In this process, the convexity of straight lines is generally lost, giving rise to non-convex folding behavior. To quantify this effect, we introduce a novel measure based on range metrics, similar to those used in the study of random walks, and provide the proof for the equivalence of convexity notions between the input and activation spaces. Furthermore, we provide empirical analysis on a geometrical analysis benchmark (CantorNet) as well as an image classification benchmark (MNIST). Our work advances the understanding of the activation space in ReLU neural networks by leveraging the phenomena of geometric folding, providing valuable insights on how these models process input information.},
  archive      = {J_TMLR},
  author       = {Michal Lewandowski and Hamid Eghbalzadeh and Bernhard Heinzl and Raphael Pisoni and Bernhard A. Moser},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On space folds of ReLU neural networks},
  url          = {https://openreview.net/forum?id=RfFqBXLDQk},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised discovery of object-centric neural fields.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ScEv13W2f1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study inferring 3D object-centric scene representations from a single image. While recent methods have shown potential in unsupervised 3D object discovery, they are limited in generalizing to unseen spatial configurations. This limitation stems from the lack of translation invariance in their 3D object representations. Previous 3D object discovery methods entangle objects’ intrinsic attributes like shape and appearance with their 3D locations. This entanglement hinders learning generalizable 3D object representations. To tackle this bottleneck, we propose the unsupervised discovery of Object-Centric neural Fields (uOCF), which integrates translation invariance into the object representation. To allow learning object-centric representations from limited real-world images, we further introduce an object prior learning method that transfers object-centric prior knowledge from a synthetic dataset. To evaluate our approach, we collect four new datasets, including two real kitchen environments. Extensive experiments show that our approach significantly improves generalization and sample efficiency and enables unsupervised 3D object discovery in real scenes. Notably, uOCF demonstrates zero-shot generalization to unseen objects from a single real image. We attach our code in the supplementary file, and the project page is available at https://red-fairy.github.io/uOCF/},
  archive      = {J_TMLR},
  author       = {Rundong Luo and Hong-Xing Yu and Jiajun Wu},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Unsupervised discovery of object-centric neural fields},
  url          = {https://openreview.net/forum?id=ScEv13W2f1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preserving privacy in large language models: A survey on
current threats and solutions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Ss9MTTN7OL">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) represent a significant advancement in artificial intelligence, finding applications across various domains. However, their reliance on massive internet-sourced datasets for training brings notable privacy issues, which are exacerbated in critical domains (e.g., healthcare). Moreover, certain application-specific scenarios may require fine-tuning these models on private data. This survey critically examines the privacy threats associated with LLMs, emphasizing the potential for these models to memorize and inadvertently reveal sensitive information. We explore current threats by reviewing privacy attacks on LLMs and propose comprehensive solutions for integrating privacy mechanisms throughout the entire learning pipeline. These solutions range from anonymizing training datasets to implementing differential privacy during training or inference and machine unlearning after training. Our comprehensive review of existing literature highlights ongoing challenges, available tools, and future directions for preserving privacy in LLMs. This work aims to guide the development of more secure and trustworthy AI systems by providing a thorough understanding of privacy preservation methods and their effectiveness in mitigating risks.},
  archive      = {J_TMLR},
  author       = {Michele Miranda and Elena Sofia Ruzzetti and Andrea Santilli and Fabio Massimo Zanzotto and Sébastien Bratières and Emanuele Rodolà},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Preserving privacy in large language models: A survey on current threats and solutions},
  url          = {https://openreview.net/forum?id=Ss9MTTN7OL},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Over-parameterised shallow neural networks with asymmetrical
node scaling: Global convergence guarantees and feature learning.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Sx1khIIi95">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider gradient-based optimisation of wide, shallow neural networks, where the output of each hidden node is scaled by a positive parameter. The scaling parameters are non-identical, differing from the classical Neural Tangent Kernel (NTK) parameterisation. We prove that for large such neural networks, with high probability, gradient flow and gradient descent converge to a global minimum and can learn features in some sense, unlike in the NTK parameterisation. We perform experiments illustrating our theoretical results and discuss the benefits of such scaling in terms of prunability and transfer learning.},
  archive      = {J_TMLR},
  author       = {Francois Caron and Fadhel Ayed and Paul Jung and Hoil Lee and Juho Lee and Hongseok Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Over-parameterised shallow neural networks with asymmetrical node scaling: Global convergence guarantees and feature learning},
  url          = {https://openreview.net/forum?id=Sx1khIIi95},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ARVideo: Autoregressive pretraining for self-supervised
video representation learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TRKwzPnXWQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new self-supervised video representation learning framework \textbf{ARVideo}, which \textit{autoregressively} predict the next video token in a tailored sequence order. Two key designs are included. First, we organize autoregressive video tokens into clusters that span both \textit{spatially} and \textit{temporally}, thereby enabling a richer aggregation of contextual information compared to the standard spatial-only or temporal-only clusters. Second, we adopt a randomized spatiotemporal prediction order to facilitate learning from multi-dimensional data, addressing the limitations of a handcrafted spatial-first or temporal-first sequence order. Extensive experiments establish ARVideo as an effective paradigm for self-supervised video representation learning. For example, when trained with the ViT-B backbone, ARVideo competitively attains 81.2\% on Kinetics-400 and 70.9\% on Something-Something V2, which are on par with the strong benchmark set by VideoMAE. Importantly, ARVideo also demonstrates higher training efficiency, \ie, it trains 14\% faster and requires 58\% less GPU memory compared to VideoMAE.},
  archive      = {J_TMLR},
  author       = {Sucheng Ren and Hongru Zhu and Chen Wei and Yijiang Li and Alan Yuille and Cihang Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ARVideo: Autoregressive pretraining for self-supervised video representation learning},
  url          = {https://openreview.net/forum?id=TRKwzPnXWQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting benford’s law for weight regularization of deep
neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=TnT59yz7lc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic learning of Deep Neural Network (DNN) parameters is highly sensitive to training strategy, hyperparameters, and available training data. Many state-of-the-art solutions use weight regularization to adjust parameter distributions, prevent overfitting, and support generalization of DNNs. None of the existing regularization techniques have ever exploited a typical distribution of numerical datasets with respect to the first non-zero (or significant) digit, called Benford&#39;s Law (BL). In this paper, we show that the deviation of the significant digit distribution of the DNN weights from BL is closely related to the generalization of the DNN. In particular, when the DNN is presented with limited training data. To take advantage of this finding, we use BL to target the weight regularization of DNNs. Extensive experiments are performed on image, table, and speech data, considering convolutional (CNN) and Transformer-based neural network architectures with varying numbers of parameters. We show that the performance of DNNs is improved by minimizing the distance between the significant digit distributions of the DNN weights and the BL distribution along with L2 regularization. The improvements depend on the network architecture and how it deals with limited data. However, the proposed penalty term improves consistently and some CNN-based architectures gain up to $15\%$ test accuracy over the default training scheme with L2 regularization on subsets of CIFAR 100.},
  archive      = {J_TMLR},
  author       = {Julius Ott and Huawei Sun and Enrico Rinaldi and Gianfranco Mauro and Lorenzo Servadei and Robert Wille},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Exploiting benford&#39;s law for weight regularization of deep neural networks},
  url          = {https://openreview.net/forum?id=TnT59yz7lc},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using representation balancing to learn conditional-average
dose responses from clustered data. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=U8EMkndyq4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the response to an intervention with an associated dose conditional on a unit&#39;s covariates, the &quot;conditional-average dose response&quot; (CADR), is a relevant task in a variety of domains, from healthcare to business, economics, and beyond. Estimating such a response is challenging for several reasons: Firstly, it typically needs to be estimated from observational data, which can be confounded and negatively affect the performance of intervention response estimators used for counterfactual inference. Secondly, the continuity of the dose prevents the adoption of approaches used to estimate responses to binary-valued interventions. That is why the machine learning (ML) community has proposed several tailored CADR estimators. Yet, the proposal of most of these methods requires strong assumptions on the distribution of data and the assignment of interventions, which go beyond the standard assumptions in causal inference. Whereas previous works have so far focused on smooth shifts in covariate distributions across doses, in this work, we will study estimating CADR from clustered data and where different doses are assigned to different segments of a population. On a novel benchmarking dataset, we show the impacts of clustered data on model performance. Additionally, we propose an estimator, CBRNet, that enables the application of representation balancing for CADR estimation through clustering the covariate space and a novel loss function. CBRNet learns cluster-agnostic and hence dose-agnostic covariate representations through representation balancing for unbiased CADR inference. We run extensive experiments to illustrate the workings of our method and compare it with the state of the art in ML for CADR estimation.},
  archive      = {J_TMLR},
  author       = {Christopher Bockel-Rickermann and Toon Vanderschueren and Jeroen Berrevoets and Tim Verdonck and Wouter Verbeke},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Using representation balancing to learn conditional-average dose responses from clustered data},
  url          = {https://openreview.net/forum?id=U8EMkndyq4},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Score-based denoising diffusion models for photon-starved
image restoration problems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=UYXPt7HUdl">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Score-based denoising diffusion models have recently emerged as a powerful strategy to solve image restoration problems. Early diffusion models required problem-specific training. However, modern approaches can combine a likelihood function that is specified during test-time with a foundational pretrained diffusion model, which is used as an implicit prior in a Plug-and-Play (PnP) manner. This approach has been shown to deliver state-of-the-art performance in a wide range of image restoration problems involving Gaussian and mild Poisson noise. With extreme computer vision applications in mind, this paper presents the first PnP denoising diffusion method for photon-starved imaging problems. These problems arise in new quantum-enhanced imaging systems that exploit the particle nature of light to exceed the limitations of classical imaging. The problems involve highly challenging noise statistics, such as binomial, geometric, and low-intensity Poisson noise, which are difficult because of high uncertainty about the solution and because the models exhibit poor regularity properties (e.g., exploding scores, constraints). The proposed method is demonstrated on a series of challenging photon-starved imaging experiments with as little as 1 photon per pixel, where it delivers remarkably accurate solutions and outperforms alternative strategies from the state-of-the-art.},
  archive      = {J_TMLR},
  author       = {Savvas Melidonis and Yiming Xi and Konstantinos C. Zygalakis and Yoann Altmann and Marcelo Pereyra},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Score-based denoising diffusion models for photon-starved image restoration problems},
  url          = {https://openreview.net/forum?id=UYXPt7HUdl},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CNN interpretability with multivector tucker saliency maps
for self-supervised models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=VM8bNd5A09">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpreting the decisions of Convolutional Neural Networks (CNNs) is essential for understanding their behavior, yet it remains a significant challenge, particularly for self-supervised models. Most existing methods for generating saliency maps rely on reference labels, restricting their use to supervised tasks. EigenCAM is the only notable label-independent alternative, leveraging Singular Value Decomposition to generate saliency maps applicable across CNN models, but it does not fully exploit the tensorial structure of feature maps. In this work, we introduce the Tucker Saliency Map (TSM) method, which applies Tucker tensor decomposition to better capture the inherent structure of feature maps, producing more accurate singular vectors and values. These are used to generate high-fidelity saliency maps, effectively highlighting objects of interest in the input. We further extend EigenCAM and TSM into multivector variants—Multivec-EigenCAM and Multivector Tucker Saliency Maps (MTSM)—which utilize all singular vectors and values, further improving saliency map quality. Quantitative evaluations on supervised classification models demonstrate that TSM, Multivec-EigenCAM, and MTSM achieve competitive performance with label-dependent methods. Moreover, TSM enhances interpretability by approximately $50\%$ over EigenCAM for both supervised and self-supervised models. Multivec-EigenCAM and MTSM further advance state-of-the-art interpretability performance on self-supervised models, with MTSM achieving the best results.},
  archive      = {J_TMLR},
  author       = {Aymene Mohammed Bouayed and Samuel Deslauriers-gauthier and Adrian IACOVELLI and David Naccache},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {CNN interpretability with multivector tucker saliency maps for self-supervised models},
  url          = {https://openreview.net/forum?id=VM8bNd5A09},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Why is constrained neural language generation particularly
challenging? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Vwgjk5ysWn">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in deep neural language models combined with the capacity of large scale datasets have accelerated the development of natural language generation systems that produce fluent and coherent texts (to various degrees of success) in a multitude of tasks and application contexts. However, controlling the output of these models for desired user and task needs is still an open challenge. This is crucial not only to customizing the content and style of the generated language, but also to their safe and reliable deployment in the real world. We present an extensive survey on the emerging topic of constrained neural language generation in which we formally define and categorize the problems of natural language generation by distinguishing between conditions and constraints (the latter being testable conditions on the output text instead of the input), present constrained text generation tasks, and review existing methods and evaluation metrics for constrained text generation. Our aim is to highlight recent progress and trends in this emerging field, informing on the most promising directions and limitations towards advancing the state-of-the-art of constrained neural language generation research.},
  archive      = {J_TMLR},
  author       = {Cristina Garbacea and Qiaozhu Mei},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Why is constrained neural language generation particularly challenging?},
  url          = {https://openreview.net/forum?id=Vwgjk5ysWn},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instance-aware graph prompt learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=W50i7r3DHE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks stand as the predominant technique for graph representation learning owing to their strong expressive power, yet the performance highly depends on the availability of high-quality labels in an end-to-end manner. Thus the pretraining and fine-tuning paradigm has been proposed to mitigate the label cost issue. Subsequently, the gap between the pretext tasks and downstream tasks has spurred the development of graph prompt learning which inserts a set of graph prompts into the original graph data with minimal parameters while preserving competitive performance. However, the current exploratory works are still limited since they all concentrate on learning fixed task-specific prompts which may not generalize well across the diverse instances that the task comprises. To tackle this challenge, we introduce Instance-Aware Graph Prompt Learning (IA-GPL) in this paper, aiming to generate distinct prompts tailored to different input instances. The process involves generating intermediate prompts for each instance using a lightweight architecture, quantizing these prompts through trainable codebook vectors, and employing the exponential moving average technique to ensure stable training. Extensive experiments conducted on multiple datasets and settings showcase the superior performance of IA-GPL compared to state-of-the-art baselines.},
  archive      = {J_TMLR},
  author       = {Jiazheng Li and Jundong Li and Chuxu Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Instance-aware graph prompt learning},
  url          = {https://openreview.net/forum?id=W50i7r3DHE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data augmentation policy search for long-term forecasting.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Wnd0XY0twh">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation serves as a popular regularization technique to combat overfitting challenges in neural networks. While automatic augmentation has demonstrated success in image classification tasks, its application to time-series problems, particularly in long-term forecasting, has received comparatively less attention. To address this gap, we introduce a time-series automatic augmentation approach named TSAA, which is both efficient and easy to implement. The solution involves tackling the associated bilevel optimization problem through a two-step process: initially training a non-augmented model for a limited number of epochs, followed by an iterative split procedure. During this iterative process, we alternate between identifying a robust augmentation policy through Bayesian optimization and refining the model while discarding suboptimal runs. Extensive evaluations on challenging univariate and multivariate forecasting benchmark problems demonstrate that TSAA consistently outperforms several robust baselines, suggesting its potential integration into prediction pipelines. Code is available at this repository: \href{https://github.com/azencot-group/TSAA}{https://github.com/azencot-group/TSAA}.},
  archive      = {J_TMLR},
  author       = {Liran Nochumsohn and Omri Azencot},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Data augmentation policy search for long-term forecasting},
  url          = {https://openreview.net/forum?id=Wnd0XY0twh},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding LLM embeddings for regression. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=Wt6Iz5XNIO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of large language models (LLMs) for flexibly processing information as strings, a natural application is regression, specifically by preprocessing string representations into LLM embeddings as downstream features for metric prediction. In this paper, we provide one of the first comprehensive investigations into embedding-based regression and demonstrate that LLM embeddings as features can be better for high-dimensional regression tasks than using traditional feature engineering. This regression performance can be explained in part due to LLM embeddings over numeric data inherently preserving Lipschitz continuity over the feature space. Furthermore, we quantify the contribution of different model effects, most notably model size and language understanding, which we find surprisingly do not always improve regression performance.},
  archive      = {J_TMLR},
  author       = {Eric Tang and Bangding Yang and Xingyou Song},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Understanding LLM embeddings for regression},
  url          = {https://openreview.net/forum?id=Wt6Iz5XNIO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-based experience replay for task-agnostic
continual reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=WxHTSPS2pi">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based reinforcement learning uses a learned dynamics model to imagine actions and select those with the best expected outcomes. An experience replay buffer collects the outcomes of all actions executed in the environment, which is then used to iteratively train the dynamics model. However, as the complexity and scale of tasks increase, training times and memory requirements can grow drastically without necessarily retaining useful experiences. Continual learning proposes a more realistic scenario where tasks are learned in sequence, and the replay buffer can help mitigate catastrophic forgetting. However, it is not realistic to expect the buffer to infinitely grow as the sequence advances. Furthermore, storing every single experience executed in the environment does not necessarily provide a more accurate model. We argue that the replay buffer needs to have the minimal necessary size to retain relevant experiences that cover both common and rare states. Therefore, we propose using an uncertainty-based replay buffer filtering to enable an effective implementation of continual learning agents using model-based reinforcement learning. We show that the combination of the proposed strategies leads to reduced training times, smaller replay buffer size, and less catastrophic forgetting, all while maintaining performance.},
  archive      = {J_TMLR},
  author       = {Adrian Remonda and Cole Corbitt Terrell and Eduardo E. Veas and Marc Masana},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncertainty-based experience replay for task-agnostic continual reinforcement learning},
  url          = {https://openreview.net/forum?id=WxHTSPS2pi},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global convergence rate of deep equilibrium models with
general activations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XPREcQlAM0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a recent paper, Ling et al. investigated the over-parametrized Deep Equilibrium Model (DEQ) with ReLU activation. They proved that the gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. This paper shows that this fact still holds for DEQs with any general activation that has bounded first and second derivatives. Since the new activation function is generally non-homogeneous, bounding the least eigenvalue of the Gram matrix of the equilibrium point is particularly challenging. To accomplish this task, we need to create a novel population Gram matrix and develop a new form of dual activation with Hermite polynomial expansion.},
  archive      = {J_TMLR},
  author       = {Lan V. Truong},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Global convergence rate of deep equilibrium models with general activations},
  url          = {https://openreview.net/forum?id=XPREcQlAM0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-time adaptation with source based auxiliary tasks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=XWAXcxNg4n">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work tackles a key challenge in Test Time Adaptation~(TTA): adapting on limited data. This challenge arises naturally from two scenarios. (i) Current TTA methods are limited by the bandwidth with which the stream reveals data, since conducting several adaptation steps on each revealed batch from the stream will lead to overfitting. (ii) In many realistic scenarios, the stream reveals insufficient data for the model to fully adapt to a given distribution shift. We tackle the first scenario problem with auxiliary tasks where we leverage unlabeled data from the training distribution. In particular, we propose distilling the predictions of an originally pretrained model on clean data during adaptation. We found that our proposed auxiliary task significantly accelerates the adaptation to distribution shifts. We report a performance improvement over the state of the art by 1.5\% and 6\% on average across all corruptions on ImageNet-C under episodic and continual evaluation, respectively. To combat the second scenario of limited data, we analyze the effectiveness of combining federated adaptation with our proposed auxiliary task across different models even when different clients observe different distribution shifts. We find that not only federated averaging enhances adaptation, but combining it with our auxiliary task provides a notable 6\% performance gains over previous TTA methods.},
  archive      = {J_TMLR},
  author       = {Motasem Alfarra and Alvaro Correia and Bernard Ghanem and Christos Louizos},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Test-time adaptation with source based auxiliary tasks},
  url          = {https://openreview.net/forum?id=XWAXcxNg4n},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). What is the relationship between tensor factorizations and
circuits (and how can we exploit it)? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Y7dRmpGiHj">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper establishes a rigorous connection between circuit representations and tensor factorizations, two seemingly distinct yet fundamentally related areas. By connecting these fields, we highlight a series of opportunities that can benefit both communities. Our work generalizes popular tensor factorizations within the circuit language, and unifies various circuit learning algorithms under a single, generalized hierarchical factorization framework. Specifically, we introduce a modular “Lego block” approach to build tensorized circuit architectures. This, in turn, allows us to systematically construct and explore various circuit and tensor factorization models while maintaining tractability. This connection not only clarifies similarities and differences in existing models, but also enables the development of a comprehensive pipeline for building and optimizing new circuit/tensor factorization architectures. We show the effectiveness of our framework through extensive empirical evaluations, and highlight new research opportunities for tensor factorizations in probabilistic modeling.},
  archive      = {J_TMLR},
  author       = {Lorenzo Loconte and Antonio Mari and Gennaro Gala and Robert Peharz and Cassio de Campos and Erik Quaeghebeur and Gennaro Vessio and Antonio Vergari},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {What is the relationship between tensor factorizations and circuits (and how can we exploit it)?},
  url          = {https://openreview.net/forum?id=Y7dRmpGiHj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural lattice reduction: A self-supervised geometric deep
learning approach. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=YxXyRSlZ4b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattice reduction is a combinatorial optimization problem aimed at finding the most orthogonal basis in a given lattice. The Lenstra–Lenstra–Lovász (LLL) algorithm is the best algorithm in the literature for solving this problem. In light of recent research on algorithm discovery, in this work, we would like to answer this question: is it possible to parametrize the algorithm space for lattice reduction problem with neural networks and find an algorithm without supervised data? Our strategy is to use equivariant and invariant parametrizations and train in a self-supervised way. We design a deep neural model outputting factorized unimodular matrices and train it in a self-supervised manner by penalizing non-orthogonal lattice bases. We incorporate the symmetries of lattice reduction into the model by making it invariant to isometries and scaling of the ambient space and equivariant with respect to the hyperocrahedral group permuting and flipping the lattice basis elements. We show that this approach yields an algorithm with comparable complexity and performance to the LLL algorithm on a set of benchmarks. Additionally, motivated by certain applications for wireless communication, we extend our method to a convolutional architecture which performs joint reduction of spatially-correlated lattices arranged in a grid, thereby amortizing its cost over multiple lattices.},
  archive      = {J_TMLR},
  author       = {Giovanni Luca Marchetti and Gabriele Cesa and Kumar Pratik and Arash Behboodi},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Neural lattice reduction: A self-supervised geometric deep learning approach},
  url          = {https://openreview.net/forum?id=YxXyRSlZ4b},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized federated learning of probabilistic models: A
PAC-bayesian approach. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZMliWjMCor">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) aims to infer a shared model from private and decentralized data stored by multiple clients. Personalized FL (PFL) enhances the model’s fit for each client by adapting the global model to the clients. A significant level of personalization is required for highly heterogeneous clients but can be challenging to achieve, especially when clients’ datasets are small. We introduce PAC-PFL for PFL of probabilistic models. PAC-PFL infers a shared hyper-posterior and treats each client’s posterior inference as the personalization step. Unlike previous PFL algorithms, PAC-PFL does not regularize all personalized models towards a single shared model, thereby greatly enhancing its personalization flexibility. By establishing and minimizing a PAC-Bayesian generalization bound on the average true loss of clients, PAC-PFL effectively mitigates overfitting even in data-poor scenarios. Additionally, PAC-PFL provides generalization bounds for new clients joining later. PAC-PFL achieves accurate and well-calibrated predictions, as supported by our experiments.},
  archive      = {J_TMLR},
  author       = {Mahrokh Ghoddousi Boroujeni and Andreas Krause and Giancarlo Ferrari-Trecate},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalized federated learning of probabilistic models: A PAC-bayesian approach},
  url          = {https://openreview.net/forum?id=ZMliWjMCor},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TACO vision models can be efficiently specialized via
few-shot task-aware compression. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=Za9Tm07fig">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent vision architectures and self-supervised training methods have enabled training computer vision models that are extremely accurate, but come with massive computational costs. In settings such as identifying species in camera traps in the field, users have limited resources, and may fine-tune a pretrained model on (often limited) data from a small set of specific categories of interest. Such users may still wish to make use of highly-accurate large models, but are often constrained by the computational cost. To address this, we ask: can we quickly compress generalist models into accurate and efficient specialists given a small amount of data? Towards this goal, we propose a simple and versatile technique, which we call Few-Shot Task-Aware COmpression (TACO). Given a general-purpose model pretrained on a broad task, such as classification on ImageNet or iNaturalist datasets with thousands of categories, TACO produces a much smaller model that is accurate on specialized tasks, such as classifying across vehicle types or animal species, based only on a few examples from each target class. The method is based on two key insights - 1) a powerful specialization effect for data-aware compression, which we showcase for the first time; 2) a dedicated finetuning procedure with knowledge distillation, which prevents overfitting even in scenarios where data is very scarce. Specifically, TACO is applied in few-shot fashion, i.e. only a few task-specific samples are used for compression, and the procedure has low computational overhead. We validate this approach experimentally using highly-accurate ResNet, ViT/DeiT, and ConvNeXt models, originally trained on ImageNet and iNaturalist datasets, which we specialize and compress to a diverse set of ``downstream&#39;&#39; subtasks, with notable computational speedups on both CPU and GPU.},
  archive      = {J_TMLR},
  author       = {Denis Kuznedelev and Soroush Tabesh and Kimia Noorbakhsh and Elias Frantar and Sara Beery and Eldar Kurtic and Dan Alistarh},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {TACO vision models can be efficiently specialized via few-shot task-aware compression},
  url          = {https://openreview.net/forum?id=Za9Tm07fig},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stability-aware training of machine learning force fields
with differentiable boltzmann estimators. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ZckLMG00sO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning force fields (MLFFs) are an attractive alternative to ab-initio methods for molecular dynamics (MD) simulations. However, they can produce unstable simulations, limiting their ability to model phenomena occurring over longer timescales and compromising the quality of estimated observables. To address these challenges, we present Stability-Aware Boltzmann Estimator (StABlE) Training, a multi-modal training procedure which leverages joint supervision from reference quantum-mechanical calculations and system observables. StABlE Training iteratively runs many MD simulations in parallel to seek out unstable regions, and corrects the instabilities via supervision with a reference observable. We achieve efficient end-to-end automatic differentiation through MD simulations using our Boltzmann Estimator, a generalization of implicit differentiation techniques to a broader class of stochastic algorithms. Unlike existing techniques based on active learning, our approach requires no additional ab-initio energy and forces calculations to correct instabilities. We demonstrate our methodology across organic molecules, tetrapeptides, and condensed phase systems, using three modern MLFF architectures. StABlE-trained models achieve significant improvements in simulation stability, data efficiency, and agreement with reference observables. Crucially, the stability improvements cannot be matched by simply reducing the simulation timestep, meaning that StABlE Training effectively allows for larger timesteps in MD simulations. By incorporating observables into the training process alongside first-principles calculations, StABlE Training can be viewed as a general semi-empirical framework applicable across MLFF architectures and systems. This makes it a powerful tool for training stable and accurate MLFFs, particularly in the absence of large reference datasets. Our code is publicly available at https://github.com/ASK-Berkeley/StABlE-Training.},
  archive      = {J_TMLR},
  author       = {Sanjeev Raja and Ishan Amin and Fabian Pedregosa and Aditi S. Krishnapriyan},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Stability-aware training of machine learning force fields with differentiable boltzmann estimators},
  url          = {https://openreview.net/forum?id=ZckLMG00sO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shapley values of structured additive regression models and
application to RKHS weightings of functions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=aWRMvXTvPf">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shapley values are widely used in machine learning to interpret model predictions. However, they have an important drawback in their computational time, which is exponential in the number of variables in the data. Recent work has yielded algorithms that can efficiently and exactly calculate the Shapley values of specific model families, such as Decision Trees and Generalized Additive Models (GAMs). Unfortunately, these model families are fairly restricted. Consequently, we present STAR-SHAP, an algorithm for efficiently calculating the Shapley values of Structured Additive Regression (STAR) models, a generalization of GAMs which allow any number of variable interactions. While the computational cost of STAR-SHAP scales exponentially in the size of these interactions, it is independent of the total number of variables. This allows the interpretation of more complex and flexible models. As long as the variable interactions are moderately-sized, the computation of the Shapley values will be fast, even on high-dimensional datasets. Since STAR models with more than pairwise interactions (e.g. GA2Ms) are seldom used in practice, we also present a new class of STAR models built on the RKHS Weightings of Functions paradigm. More precisely, we introduce a new RKHS Weighting instantiation, and show how to transform it and other RKHS Weightings into STAR models. We therefore introduce a new family of STAR models, as well as the means to interpret their outputs in a timely manner.},
  archive      = {J_TMLR},
  author       = {Gabriel Dubé and Mario Marchand},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Shapley values of structured additive regression models and application to RKHS weightings of functions},
  url          = {https://openreview.net/forum?id=aWRMvXTvPf},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparing the information content of probabilistic
representation spaces. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=adhsMqURI1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic representation spaces convey information about a dataset and are shaped by factors such as the training data, network architecture, and loss function. Comparing the information content of such spaces is crucial for understanding the learning process, yet most existing methods assume point-based representations, neglecting the distributional nature of probabilistic spaces. To address this gap, we propose two information-theoretic measures to compare general probabilistic representation spaces by extending classic methods to compare the information content of hard clustering assignments. Additionally, we introduce a lightweight method of estimation that is based on fingerprinting a representation space with a sample of the dataset, designed for scenarios where the communicated information is limited to a few bits. We demonstrate the utility of these measures in three case studies. First, in the context of unsupervised disentanglement, we identify recurring information fragments within individual latent dimensions of VAE and InfoGAN ensembles. Second, we compare the full latent spaces of models and reveal consistent information content across datasets and methods, despite variability during training. Finally, we leverage the differentiability of our measures to perform model fusion, synthesizing the information content of weak learners into a single, coherent representation. Across these applications, the direct comparison of information content offers a natural basis for characterizing the processing of information.},
  archive      = {J_TMLR},
  author       = {Kieran A. Murphy and Sam Dillavou and Danielle Bassett},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Comparing the information content of probabilistic representation spaces},
  url          = {https://openreview.net/forum?id=adhsMqURI1},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving consistency in large language models through chain
of guidance. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=asiBW1bB9b">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consistency is a fundamental dimension of trustworthiness in Large Language Models (LLMs). For humans to be able to trust LLM-based applications, their outputs should be consistent when prompted with inputs that carry the same meaning or intent. Despite this need, there is no known mechanism to control and guide LLMs to be more consistent at inference time. In this paper, we introduce a novel alignment strategy to maximize semantic consistency in LLM outputs. Our proposal is based on \textbf{Chain of Guidance} (CoG), a multistep prompting technique that generates highly consistent outputs from LLMs. For closed-book question-answering (Q\&amp;A) tasks, when compared to direct prompting, the outputs generated using CoG show improved consistency. While other approaches like template-based responses and majority voting may offer alternative paths to consistency, our work focuses on exploring the potential of guided prompting. We use synthetic data sets comprised of consistent input-output pairs to fine-tune LLMs to produce consistent {\it and} correct outputs. Our fine-tuned models are more than twice as consistent compared to base models and show strong generalization capabilities by producing consistent outputs over datasets not used in the fine-tuning process. Code is available at \url{https://github.com/vijilAI/chain_of_guidance}.},
  archive      = {J_TMLR},
  author       = {Harsh Raj and Vipul Gupta and Domenic Rosati and Subhabrata Majumdar},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Improving consistency in large language models through chain of guidance},
  url          = {https://openreview.net/forum?id=asiBW1bB9b},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QPO: Query-dependent prompt optimization via multi-loop
offline reinforcement learning. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=bqMJToTkvT">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prompt engineering has demonstrated remarkable success in enhancing the performance of large language models (LLMs) across diverse tasks. However, most existing prompt optimization methods only focus on the task-level performance, overlooking the importance of query-preferred prompts, which leads to suboptimal performances. Additionally, these methods rely heavily on frequent interactions with LLMs to obtain feedback for guiding the optimization process, incurring substantial redundant interaction costs. In this paper, we introduce Query-dependent Prompt Optimization ($\textbf{QPO}$), which leverages multi-loop offline reinforcement learning to iteratively fine-tune a small pretrained language model to generate optimal prompts tailored to the input queries, thus significantly improving the prompting effect on the large target LLM. We derive insights from offline prompting demonstration data, which already exists in large quantities as a by-product of benchmarking diverse prompts on open-sourced tasks, thereby circumventing the expenses of online interactions. Furthermore, we continuously augment the offline dataset with the generated prompts in each loop, as the prompts from the fine-tuned model are supposed to outperform the source prompts in the original dataset. These iterative loops bootstrap the model towards generating optimal prompts. Experiments on various LLM scales and diverse NLP and math tasks demonstrate the efficacy and cost-efficiency of our method in both zero-shot and few-shot scenarios.},
  archive      = {J_TMLR},
  author       = {Yilun Kong and Hangyu Mao and Zhao Qi and Bin Zhang and Jingqing Ruan and Li Shen and Yongzhe Chang and Xueqian Wang and Rui Zhao and Dacheng Tao},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {QPO: Query-dependent prompt optimization via multi-loop offline reinforcement learning},
  url          = {https://openreview.net/forum?id=bqMJToTkvT},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label distribution shift-aware prediction refinement for
test-time adaptation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=c7AAHdEYz5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Test-time adaptation (TTA) is an effective approach to mitigate performance degradation of trained models when encountering input distribution shifts at test time. However, existing TTA methods often suffer significant performance drops when facing additional class distribution shifts. We first analyze TTA methods under label distribution shifts and identify the presence of class-wise confusion patterns commonly observed across different covariate shifts. Based on this observation, we introduce label Distribution shift-Aware prediction Refinement for Test-time adaptation (DART), a novel TTA method that refines the predictions by focusing on class-wise confusion patterns. DART trains a prediction refinement module during an intermediate time by exposing it to several batches with diverse class distributions using the training dataset. This module is then used during test time to detect and correct class distribution shifts, significantly improving pseudo-label accuracy for test data. Our method exhibits 5-18% gains in accuracy under label distribution shifts on CIFAR-10C, without any performance degradation when there is no label distribution shift. Extensive experiments on CIFAR, PACS, OfficeHome, and ImageNet benchmarks demonstrate DART&#39;s ability to correct inaccurate predictions caused by test-time distribution shifts. This improvement leads to enhanced performance in existing TTA methods, making DART a valuable plug-in tool.},
  archive      = {J_TMLR},
  author       = {Minguk Jang and Hye Won Chung},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Label distribution shift-aware prediction refinement for test-time adaptation},
  url          = {https://openreview.net/forum?id=c7AAHdEYz5},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The sparse matrix-based random projection: A study of binary
and ternary quantization. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dNJmJ8bh1M">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random projection is a simple yet effective technique for dimension reduction, widely used in various machine learning tasks. Following the projection step, quantization is often applied to further reduce the complexity of projected data. In general, quantized projections are expected to approximately preserve the pairwise distances between the original data points, to avoid significant performance degradation in subsequent tasks. While this distance preservation property has been investigated for Gaussian matrices, our work further extends the analysis to hardware-friendly $\{0,1\}$-binary matrices, particularly focusing on cases where the projections are quantized into two types of low bit-width codes: $\{0,1\}$-binary codes and $\{0,\pm1\}$-ternary codes. It is found that the distance preservation property tends to be better maintained, when the binary projection matrices exhibit sparse structures. This is validated through classification and clustering experiments, where extremely sparse binary matrices, with only one nonzero entry per column, achieve superior or comparable performance to other denser binary matrices and Gaussian matrices. This presents an opportunity to significantly reduce the computational and storage complexity of the quantized random projection model, without compromising, and potentially even improving its performance.},
  archive      = {J_TMLR},
  author       = {Weizhi Lu and Zhongzheng Li and Mingrui Chen and Weiyu Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The sparse matrix-based random projection: A study of binary and ternary quantization},
  url          = {https://openreview.net/forum?id=dNJmJ8bh1M},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced mixed-type tabular data synthesis with diffusion
models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=dvRysCqmYQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diffusion models have emerged as a robust framework for various generative tasks, including tabular data synthesis. However, current tabular diffusion models tend to inherit bias in the training dataset and generate biased synthetic data, which may influence discriminatory actions. In this research, we introduce a novel tabular diffusion model that incorporates sensitive guidance to generate fair synthetic data with balanced joint distributions of the target label and sensitive attributes, such as sex and race. The empirical results demonstrate that our method effectively mitigates bias in training data while maintaining the quality of the generated samples. Furthermore, we provide evidence that our approach outperforms existing methods for synthesizing tabular data on fairness metrics such as demographic parity ratio and equalized odds ratio, achieving improvements of over $10\%$. Our implementation is available at https://github.com/comp-well-org/fair-tab-diffusion.},
  archive      = {J_TMLR},
  author       = {Zeyu Yang and Han Yu and Peikun Guo and Khadija Zanna and Xiaoxue Yang and Akane Sano},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Balanced mixed-type tabular data synthesis with diffusion models},
  url          = {https://openreview.net/forum?id=dvRysCqmYQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative minibatching in graph neural networks.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=f6yMdmrD2g">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training large scale Graph Neural Networks (GNNs) requires significant computational resources, and the process is highly data-intensive. One of the most effective ways to reduce resource requirements is minibatch training coupled with graph sampling. GNNs have the unique property that items in a minibatch have overlapping data. However, the commonly implemented Independent Minibatching approach assigns each Processing Element (PE, i.e., cores and/or GPUs) its own minibatch to process, leading to duplicated computations and input data access across PEs. This amplifies the Neighborhood Explosion Phenomenon (NEP), which is the main bottleneck limiting scaling. To reduce the effects of NEP in the multi-PE setting, we propose a new approach called Cooperative Minibatching. Our approach capitalizes on the fact that the size of the sampled subgraph is a concave function of the batch size, leading to significant reductions in the amount of work as batch sizes increase. Hence, it is favorable for processors equipped with a fast interconnect to work on a large minibatch together as a single larger processor, instead of working on separate smaller minibatches, even though global batch size is identical. We also show how to take advantage of the same phenomenon in serial execution by generating dependent consecutive minibatches. Our experimental evaluations show up to 4x bandwidth savings for fetching vertex embeddings, by simply increasing this dependency without harming model convergence. Combining our proposed approaches, we achieve up to 64\% speedup over Independent Minibatching on single-node multi GPU systems, using same resources.},
  archive      = {J_TMLR},
  author       = {Muhammed Fatih Balin and Dominique LaSalle and Umit Catalyurek},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Cooperative minibatching in graph neural networks},
  url          = {https://openreview.net/forum?id=f6yMdmrD2g},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Counterfactual learning of stochastic policies with
continuous actions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=fC4bh1PmZr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterfactual reasoning from logged data has become increasingly important for many applications such as web advertising or healthcare. In this paper, we address the problem of learning stochastic policies with continuous actions from the viewpoint of counterfactual risk minimization (CRM). While the CRM framework is appealing and well studied for discrete actions, the continuous action case raises new challenges about modelization, optimization, and~offline model selection with real data which turns out to be particularly challenging. Our paper contributes to these three aspects of the CRM estimation pipeline. First, we introduce a modelling strategy based on a joint kernel embedding of contexts and actions, which overcomes the shortcomings of previous discretization approaches. Second, we empirically show that the optimization aspect of counterfactual learning is important, and we demonstrate the benefits of proximal point algorithms and smooth estimators. Finally, we propose an evaluation protocol for offline policies in real-world logged systems, which is challenging since policies cannot be replayed on test data, and we release a new large-scale dataset along with multiple synthetic, yet realistic, evaluation setups.},
  archive      = {J_TMLR},
  author       = {Houssam Zenati and Alberto Bietti and Matthieu Martin and Eustache Diemert and Pierre Gaillard and Julien Mairal},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Counterfactual learning of stochastic policies with continuous actions},
  url          = {https://openreview.net/forum?id=fC4bh1PmZr},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying axiomatic mathematical transformation steps
using tree-structured pointer networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gLQ801ewwp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification of mathematical relations has become a new area of research in deep learning. A major focus lies on determining mathematical equivalence. While previous work has simply approached the task as a binary classification without providing further insight into the underlying decision, we aim to iteratively find a sequence of necessary steps to transform a mathematical expression into an arbitrary equivalent form. Each step in this sequence is specified by an axiom together with its position of application. We denote this task as Stepwise Equation Transformation Identification (SETI) task. To solve the task efficiently, we further propose TreePointerNet, a novel architecture which exploits the inherent tree structure of mathematical equations and consists of three key building blocks: (i) a transformer model tailored to work on hierarchically tree-structured equations, making use of (ii) a copy-pointer mechanism to extract the exact location of a transformation in the tree and finally (iii) custom embeddings that map distinguishable occurrences of the same token type to a common embedding. In addition, we introduce new datasets of equations for the SETI task. We benchmark our model against various baselines and perform an ablation study to quantify the influence of our custom embeddings and the copy-pointer component. Furthermore, we test the robustness of our model on data of unseen complexity. Our results clearly show that incorporating the hierarchical structure, embeddings and copy-pointer into a single model is highly beneficial for solving the SETI task},
  archive      = {J_TMLR},
  author       = {Sebastian Wankerl and Jan Pfister and Andrzej Dulny and Gerhard Götz and Andreas Hotho},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Identifying axiomatic mathematical transformation steps using tree-structured pointer networks},
  url          = {https://openreview.net/forum?id=gLQ801ewwp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When precision meets position: BFloat16 breaks down RoPE in
long-context training. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=gwXfZ3xkUq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extending context window sizes allows large language models (LLMs) to process longer sequences and handle more complex tasks. Rotary Positional Embedding (RoPE) has become the de facto standard due to its relative positional encoding properties that benefit long-context training. However, we observe that using RoPE with BFloat16 format results in numerical issues, causing it to deviate from its intended relative positional encoding, especially in long-context scenarios. This issue arises from BFloat16&#39;s limited precision and accumulates as context length increases, with the first token contributing significantly to this problem. Despite its limitations, BFloat16 remains desirable for its computational efficiency, particularly given the substantial memory overhead required to extend the context window. To improve long-context training under BFloat16, we develop AnchorAttention, a plug-and-play attention method that enhances long-context capabilities, and speeds up training. AnchorAttention reduces unnecessary attention computations, maintains semantic coherence, and boosts computational efficiency by treating the first token as a shared anchor with a consistent position ID, making it visible to all documents within the training context. Experiments on three types of LLMs demonstrate that AnchorAttention significantly improves long-context performance and reduces training time by over 50\% compared to standard full attention mechanisms, while preserving the original LLM&#39;s capabilities on general tasks.},
  archive      = {J_TMLR},
  author       = {Haonan Wang and Qian Liu and Chao Du and Tongyao Zhu and Cunxiao Du and Kenji Kawaguchi and Tianyu Pang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {When precision meets position: BFloat16 breaks down RoPE in long-context training},
  url          = {https://openreview.net/forum?id=gwXfZ3xkUq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALTA: Compiler-based analysis of transformers.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=h751wl9xiR">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new programming language called ALTA and a compiler that can map ALTA programs to Transformer weights. ALTA is inspired by RASP, a language proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler from RASP programs to Transformer weights. ALTA complements and extends this prior work, offering the ability to express loops and to compile programs to Universal Transformers, among other advantages. ALTA allows us to constructively show how Transformers can represent length-invariant algorithms for computing parity and addition, as well as a solution to the SCAN benchmark of compositional generalization tasks, without requiring intermediate scratchpad decoding steps. We also propose tools to analyze cases where the expressibility of an algorithm is established, but end-to-end training on a given training set fails to induce behavior consistent with the desired algorithm. To this end, we explore training from ALTA execution traces as a more fine-grained supervision signal. This enables additional experiments and theoretical analyses relating the learnability of various algorithms to data availability and modeling decisions, such as positional encodings. We make the ALTA framework --- language specification, symbolic interpreter, and weight compiler --- available to the community to enable further applications and insights.},
  archive      = {J_TMLR},
  author       = {Peter Shaw and James Cohan and Jacob Eisenstein and Kenton Lee and Jonathan Berant and Kristina Toutanova},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {ALTA: Compiler-based analysis of transformers},
  url          = {https://openreview.net/forum?id=h751wl9xiR},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent space energy-based neural ODEs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=hCxtlfvL22">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces novel deep dynamical models designed to represent continuous-time sequences. Our approach employs a neural emission model to generate each data point in the time series through a non-linear transformation of a latent state vector. The evolution of these latent states is implicitly defined by a neural ordinary differential equation (ODE), with the initial state drawn from an informative prior distribution parameterized by an Energy-based model (EBM). This framework is extended to disentangle dynamic states from underlying static factors of variation, represented as time-invariant variables in the latent space. We train the model using maximum likelihood estimation with Markov chain Monte Carlo (MCMC) in an end-to-end manner. Experimental results on oscillating systems, videos and real-world state sequences (MuJoCo) demonstrate that our model with the learnable energy-based prior outperforms existing counterparts, and can generalize to new dynamic parameterization, enabling long-horizon predictions.},
  archive      = {J_TMLR},
  author       = {Sheng Cheng and Deqian Kong and Jianwen Xie and Kookjin Lee and Ying Nian Wu and Yezhou Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Latent space energy-based neural ODEs},
  url          = {https://openreview.net/forum?id=hCxtlfvL22},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The RealHumanEval: Evaluating large language models’
abilities to support programmers. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=hGaWq5Buj7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of large language models for code has primarily relied on static benchmarks, including HumanEval (Chen et al., 2021), or more recently using human preferences of LLM responses. As LLMs are increasingly used as programmer assistants, we study whether gains on existing benchmarks or more preferred LLM responses translate to programmer productivity when coding with LLMs, including time spent coding. We introduce RealHumanEval, a web interface to measure the ability of LLMs to assist programmers, through either autocomplete or chat support. We conducted a user study (N=243) using RealHumanEval in which users interacted with seven LLMs of varying base model performance. Despite static benchmarks not incorporating humans-in-the-loop, we find that improvements in benchmark performance lead to increased programmer productivity; however gaps in benchmark versus human performance are not proportional---a trend that holds across both forms of LLM support. In contrast, we find that programmer preferences do not correlate with their actual performance, motivating the need for better proxy signals. We open-source RealHumanEval to enable human-centric evaluation of new models and the study data to facilitate efforts to improve code models.},
  archive      = {J_TMLR},
  author       = {Hussein Mozannar and Valerie Chen and Mohammed Alsobay and Subhro Das and Sebastian Zhao and Dennis Wei and Manish Nagireddy and Prasanna Sattigeri and Ameet Talwalkar and David Sontag},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The RealHumanEval: Evaluating large language models’ abilities to support programmers},
  url          = {https://openreview.net/forum?id=hGaWq5Buj7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adapt then unlearn: Exploring parameter space semantics for
unlearning in generative adversarial networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jAHEBivObO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the growing concerns about privacy and regulatory compliance, it is desirable to regulate the output of generative models. To that end, the objective of this work is to prevent the generation of outputs containing undesired features from a pre-trained Generative Adversarial Network (GAN) where the underlying training data set is inaccessible. Our approach is inspired by the observation that the parameter space of GANs exhibits meaningful directions that can be leveraged to suppress specific undesired features. However, such directions usually result in the degradation of the quality of generated samples. Our proposed two-stage method, known as &#39;Adapt-then-Unlearn,&#39; excels at unlearning such undesirable features while also maintaining the quality of generated samples. In the initial stage, we adapt a pre-trained GAN on a set of negative samples (containing undesired features) provided by the user. Subsequently, we train the original pre-trained GAN using positive samples, along with a repulsion regularizer. This regularizer encourages the learned model parameters to move away from the parameters of the adapted model (first stage) while not degrading the generation quality. We provide theoretical insights into the proposed method. To the best of our knowledge, our approach stands as the first method addressing unlearning within the realm of high-fidelity GANs (such as StyleGAN). We validate the effectiveness of our method through comprehensive experiments, encompassing both class-level unlearning on the MNIST and AFHQ dataset and feature-level unlearning tasks on the CelebA-HQ dataset. Our code and implementation is available at: https://github.com/atriguha/Adapt_Unlearn.},
  archive      = {J_TMLR},
  author       = {Piyush Tiwary and Atri Guha and Subhodip Panda and Prathosh AP},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Adapt then unlearn: Exploring parameter space semantics for unlearning in generative adversarial networks},
  url          = {https://openreview.net/forum?id=jAHEBivObO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video-language critic: Transferable reward functions for
language-conditioned robotics. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jJOVpnNrEp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Natural language is often the easiest and most convenient modality for humans to specify tasks for robots. However, learning to ground language to behavior typically requires impractical amounts of diverse, language-annotated demonstrations collected on each target robot. In this work, we aim to separate the problem of what to accomplish from how to accomplish it, as the former can benefit from substantial amounts of external observation-only data, and only the latter depends on a specific robot embodiment. To this end, we propose Video-Language Critic, a reward model that can be trained on readily available cross-embodiment data using contrastive learning and a temporal ranking objective, and use it to score behavior traces from a separate actor. When trained on Open X-Embodiment data, our reward model enables 2x more sample-efficient policy training on Meta-World tasks than a sparse reward only, despite a significant domain gap. Using in-domain data but in a challenging task generalization setting on Meta-World, we further demonstrate more sample-efficient training than is possible with prior language-conditioned reward models that are either trained with binary classification, use static images, or do not leverage the temporal information present in video data.},
  archive      = {J_TMLR},
  author       = {Minttu Alakuijala and Reginald McLean and Isaac Woungang and Nariman Farsad and Samuel Kaski and Pekka Marttinen and Kai Yuan},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Video-language critic: Transferable reward functions for language-conditioned robotics},
  url          = {https://openreview.net/forum?id=jJOVpnNrEp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combating inter-task confusion and catastrophic forgetting
by metric learning and re-using a past trained model. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jRbKsQ3sYO">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the vast research on class-incremental learning (IL), the critical issues have not yet been fully addressed. In this paper, utilizing metric learning, we tackle two fundamental issues of class-incremental learning (class-IL), inter-task confusion and catastrophic forgetting, which have not been fully addressed yet in the literature. To mitigate the inter-task confusion, we propose an innovative loss by utilizing the centroids of previously learned classes as negatives and current data samples as positives in the embedding space, which reduces overlaps between the classes of the current and past tasks in the embedding space. To combat catastrophic forgetting, we also propose that the past trained model is stored and re-used for generating past data samples for only one previous task. Based on this, we further propose a novel knowledge distillation approach utilizing inter-class embedding clusters, intra-class embedding clusters, and mean square embedding distances. Extensive experiments performed on MNIST, CIFAR-10, CIFAR-100, Mini-ImageNet, and TinyImageNet show that our proposed exemplar-free metric class-IL method achieves the state-of-the-art performance, beating all baseline methods by notable margins. We release our codes as the supplementary materials.},
  archive      = {J_TMLR},
  author       = {Sayedmoslem Shokrolahi and IL MIN KIM},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Combating inter-task confusion and catastrophic forgetting by metric learning and re-using a past trained model},
  url          = {https://openreview.net/forum?id=jRbKsQ3sYO},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards measuring predictability: To which extent
data-driven approaches can extract deterministic relations from data
exemplified with time series prediction and classification.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jZBAVFGUUo">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimizing loss functions is one important ingredient for machine learning to fit parameters such that the machine learning models extract relations hidden in the data. The smaller the loss function value on various splittings of a dataset, the better the machine learning model is assumed to perform. However, datasets are usually generated by dynamics consisting of deterministic components, where relations are clearly defined and consequently learnable, as well as stochastic parts where outcomes are random and thus not predictable. Depending on the amplitude of the deterministic and stochastic processes, the best achievable loss function value varies and is usually not known in real data science scenarios. In this research, a statistical framework is developed that provides measures to address the predictability of a target given the available input data and, after training a machine learning model, how much of the deterministic relations have been missed by the model. Consequently, the presented framework allows to differentiate model errors into unpredictable parts regarding the given input and a systematic miss of deterministic relations. The work extends the definition of model success or failure as well as the convergence of a training process. Moreover, it is demonstrated how such measures can enrich the procedure of model training. The framework is showcased with time series data on different synthetic and real-world datasets. The code is available at https://github.com/Saleh-Gholam-Zadeh/predictability_measure.},
  archive      = {J_TMLR},
  author       = {Saleh GHOLAM ZADEH and Vaisakh Shaj and Patrick Jahnke and Gerhard Neumann and Tim Breitenbach},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Towards measuring predictability: To which extent data-driven approaches can extract deterministic relations from data exemplified with time series prediction and classification},
  url          = {https://openreview.net/forum?id=jZBAVFGUUo},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized negative reservoir for incremental learning in
recommender systems. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=jrUUk5Fskm">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems have become an integral part of online platforms. Every day the volume of training data is expanding and the number of user interactions is constantly increasing. The exploration of larger and more expressive models has become a necessary pursuit to improve user experience. However, this progression carries with it an increased computational burden. In commercial settings, once a recommendation system model has been trained and deployed it typically needs to be updated frequently as new client data arrive. Cumulatively, the mounting volume of data is guaranteed to eventually make full batch retraining of the model from scratch computationally infeasible. Naively fine-tuning solely on the new data runs into the well-documented problem of catastrophic forgetting. Despite the fact that negative sampling is a crucial part of training with implicit feedback, no specialized technique exists that is tailored to the incremental learning framework. In this work, we propose a personalized negative reservoir strategy, which is used to obtain negative samples for the standard triplet loss of graph-based recommendation systems. Our technique balances alleviation of forgetting with plasticity by encouraging the model to remember stable user preferences and selectively forget when user interests change. We derive the mathematical formulation of a negative sampler to populate and update the reservoir. We integrate our design in three SOTA and commonly used incremental recommendation models. We show that these concrete realizations of our negative reservoir framework achieve state-of-the-art results for standard benchmarks using multiple top-k evaluation metrics.},
  archive      = {J_TMLR},
  author       = {Antonios Valkanas and Yuening Wang and Yingxue Zhang and Mark Coates},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Personalized negative reservoir for incremental learning in recommender systems},
  url          = {https://openreview.net/forum?id=jrUUk5Fskm},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Verbalized machine learning: Revisiting machine learning
with language models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=k3Ab6RuJE9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the progress of large language models (LLMs), we introduce the framework of verbalized machine learning (VML). In contrast to conventional machine learning (ML) models that are typically optimized over a continuous parameter space, VML constrains the parameter space to be human-interpretable natural language. Such a constraint leads to a new perspective of function approximation, where an LLM with a text prompt can be viewed as a function parameterized by the text prompt. Guided by this perspective, we revisit classical ML problems, such as regression and classification, and find that these problems can be solved by an LLM-parameterized learner and optimizer. The major advantages of VML include (1) easy encoding of inductive bias: prior knowledge about the problem and hypothesis class can be encoded in natural language and fed into the LLM-parameterized learner; (2) automatic model class selection: the optimizer can automatically select a model class based on data and verbalized prior knowledge, and it can update the model class during training; and (3) interpretable learner updates: the LLM-parameterized optimizer can provide explanations for why an update is performed. We empirically verify the effectiveness of VML, and hope that VML can serve as a stepping stone to stronger interpretability.},
  archive      = {J_TMLR},
  author       = {Tim Z. Xiao and Robert Bamler and Bernhard Schölkopf and Weiyang Liu},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Verbalized machine learning: Revisiting machine learning with language models},
  url          = {https://openreview.net/forum?id=k3Ab6RuJE9},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FaAlGrad: Fairness through alignment of gradients across
different subpopulations. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=k4AxEwTaHq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing deployment of Machine Learning systems has increased interest in systems optimized for other important criteria along with the expected task performance. For instance, machine learning models often exhibit biases that lead to unfair outcomes for certain protected subpopulations. This work aims to handle the bias in machine learning models and enhance their fairness by aligning the loss gradients. Specifically, leveraging the meta-learning technique, we propose a novel training framework that aligns the gradients computed across different subpopulations for learning fair classifiers. Aligning the gradients enables our framework to regularize the training process, thereby prioritizing fairness over predictive accuracy. Our experiments on multiple benchmark datasets demonstrate significant improvements in fairness metrics without having any exclusive regularizers for fairness. Thus our work contributes to developing fairer machine learning models with broader societal benefits.},
  archive      = {J_TMLR},
  author       = {Nikita Malik and Konda Reddy Mopuri},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {FaAlGrad: Fairness through alignment of gradients across different subpopulations},
  url          = {https://openreview.net/forum?id=k4AxEwTaHq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maxwell’s demon at work: Efficient pruning by leveraging
saturation of neurons. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=nmBleuFzaN">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When training neural networks, dying neurons —units becoming inactive or saturated— are traditionally seen as harmful. This paper sheds new light on this phenomenon. By exploring the impact of various hyperparameter configurations on dying neurons during training, we gather insights on how to improve upon sparse training approaches to pruning. We introduce Demon Pruning (DemP), a method that controls the proliferation of dead neurons through a combination of noise injection on active units and a one-cycled schedule regularization strategy, dynamically leading to network sparsity. Experiments on CIFAR-10 and ImageNet datasets demonstrate that DemP outperforms existing dense-to-sparse structured pruning methods, achieving better accuracy-sparsity tradeoffs while speeding up training up to 3.56$\times$. These findings provide a novel perspective on dying neurons as a resource for efficient model compression and optimization.},
  archive      = {J_TMLR},
  author       = {Simon Dufort-Labbé and Pierluca D&#39;Oro and Evgenii Nikishin and Irina Rish and Pierre-Luc Bacon and Razvan Pascanu and Aristide Baratin},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Maxwell&#39;s demon at work: Efficient pruning by leveraging saturation of neurons},
  url          = {https://openreview.net/forum?id=nmBleuFzaN},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentially private source-target clustering.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ojeCoOKwWp">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a new private variant of the Source-Target Clustering (STC) setting, which was introduced by de Mathelin et al. (2022). In STC, there is a target dataset that needs to be clustered by selecting centers, in addition to centers that are already provided in a separate source dataset. The goal is to select centers from the target, such that the target clustering cost given the additional source centers is minimized. We consider private STC, in which the source dataset is private and should only be used under the constraint of differential privacy. This is motivated by scenarios in which the existing centers are private, for instance because they represent individuals in a social network. We derive lower bounds for the private STC objective, illustrating the theoretical limitations on worst-case guarantees for this setting. We then present a differentially private algorithm with asymptotically advantageous results under a data-dependent analysis, in which the guarantee depends on properties of the dataset, as well as more practical variants. We demonstrate in experiments the reduction in clustering cost that is obtained by our practical algorithms compared to baseline approaches.},
  archive      = {J_TMLR},
  author       = {Shachar Schnapp and Sivan Sabato},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Differentially private source-target clustering},
  url          = {https://openreview.net/forum?id=ojeCoOKwWp},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixture degree-corrected stochastic block model for
multi-group community detection in multiplex graphs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=p9KSFrTLx0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiplex graphs have emerged as a powerful tool for modeling complex data structures due to their ability to handle multiple relational layers. Clustering within a multiplex graph can involve merging vertices into communities that are consistent across all layers, grouping similar layers into clusters, or creating overlapping clusters among vertices and layers. However, a multiplex graph may exhibit distinct vertex communities based on the specific layers to which a vertex is connected. This scenario, termed multi-group community detection, significantly enhances the accuracy of clustering processes and aids in the interpretation of partitions. To date, the current literature on state-of-the-art community detection has not extensively addressed this modeling approach. In this paper, we introduce a novel methodology referred to as the &quot;Mixture Degree-Corrected Stochastic Block Model.&quot; This generative model, an extension of the widely utilized Degree-Corrected Stochastic Block Model (DCSBM), is designed to cluster similar layers by their community structures while simultaneously identifying communities within each layer&#39;s group. We provide a rigorous definition of the model and utilize an iterative technique to perform inference computations. Furthermore, we assess the identifiability of our proposed model and demonstrate the consistency of the maximum likelihood function through analytical analysis. The effectiveness of our method is evaluated using both real-word data sets and synthetic graphs.},
  archive      = {J_TMLR},
  author       = {Noureddine Henka and Mohamad Assaad and Sami Tazi},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Mixture degree-corrected stochastic block model for multi-group community detection in multiplex graphs},
  url          = {https://openreview.net/forum?id=p9KSFrTLx0},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On training-conditional conformal prediction and binomial
proportion confidence intervals. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=pSk5qyt1ob">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the expectation of a Bernoulli random variable based on $N$ independent trials is a classical problem in statistics, typically addressed using Binomial Proportion Confidence Intervals (BPCI). In the control systems community, many critical tasks—such as certifying the statistical safety of dynamical systems—can be formulated as BPCI problems. Conformal Prediction (CP), a distribution-free technique for uncertainty quantification, has gained significant attention in recent years and has been applied to various control systems problems, particularly to address uncertainties in learned dynamics or controllers. A variant known as training-conditional CP was recently employed to tackle the problem of safety certification. In this note, we highlight that the use of training-conditional CP in this context does not provide valid safety guarantees. We demonstrate why CP is unsuitable for BPCI problems and argue that traditional BPCI methods are better suited for statistical safety certification.},
  archive      = {J_TMLR},
  author       = {Rudi Coppola and Manuel Mazo Espinosa},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On training-conditional conformal prediction and binomial proportion confidence intervals},
  url          = {https://openreview.net/forum?id=pSk5qyt1ob},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AttnGCG: Enhancing jailbreaking attacks on LLMs with
attention manipulation. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=prVLANCshF">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the vulnerabilities of transformer-based Large Language Models (LLMs) to jailbreaking attacks, focusing specifically on the optimization-based Greedy Coordinate Gradient (GCG) strategy. We first observe a positive correlation between the effectiveness of attacks and the internal behaviors of the models. For instance, attacks tend to be less effective when models pay more attention to system prompts designed to ensure LLM safety alignment. Building on this discovery, we introduce an enhanced method that manipulates models&#39; attention scores to facilitate LLM jailbreaking, which we term AttnGCG. Empirically, AttnGCG shows consistent improvements in attack efficacy across diverse LLMs, achieving an average increase of ~7% in the Llama-2 series and ~10% in the Gemma series. Our strategy also demonstrates robust attack transferability against both unseen harmful goals and black-box LLMs like GPT-3.5 and GPT-4. Moreover, we note our attention-score visualization is more interpretable, allowing us to gain better insights into how our targeted attention manipulation facilitates more effective jailbreaking. We release the code at https://github.com/UCSC-VLAA/AttnGCG-attack.},
  archive      = {J_TMLR},
  author       = {Zijun Wang and Haoqin Tu and Jieru Mei and Bingchen Zhao and Yisen Wang and Cihang Xie},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {AttnGCG: Enhancing jailbreaking attacks on LLMs with attention manipulation},
  url          = {https://openreview.net/forum?id=prVLANCshF},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How does code pretraining affect language model task
performance? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=pxxmUKKgel">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models are increasingly trained on corpora containing both natural language and non-linguistic data like source code. Aside from aiding programming-related tasks, anecdotal evidence suggests that including code in pretraining corpora may improve performance on other, unrelated tasks, yet to date no work has been able to establish a causal connection by controlling between language and code data. Here we do just this. We pretrain language models on datasets which interleave natural language and code in two different settings: competitive, in which the total volume of data seen during pretraining is held constant; and additive, in which the volume of language data is held constant. We study how the pretraining mixture affects performance on (a) compositionality, measured by generalization accuracy on semantic parsing and syntactic transformation tasks, and more broadly on (b) downstream non-code-related objectives, measured by performance on tasks from the BigBench benchmark. We find that pretraining on higher proportions of code improves performance on compositional tasks involving structured output (like semantic parsing), and mathematics. Conversely, increase code mixture can harm performance on other tasks, including on tasks that requires sensitivity to linguistic structure such as syntax or morphology, and tasks measuring real-world knowledge.},
  archive      = {J_TMLR},
  author       = {Jackson Petty and Sjoerd van Steenkiste and Tal Linzen},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {How does code pretraining affect language model task performance?},
  url          = {https://openreview.net/forum?id=pxxmUKKgel},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Are large language models really robust to word-level
perturbations? <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=rWSiBknwQa">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift advancement in the scales and capabilities of Large Language Models (LLMs) positions them as promising tools for a variety of downstream tasks. In addition to the pursuit of better performance and the avoidance of violent feedback on a certain prompt, to ensure the responsibility of the LLMs, much attention is drawn to the robustness of LLMs. However, existing evaluation methods mostly rely on traditional question answering datasets with predefined supervised labels, potentially ignoring the superior generation capabilities of contemporary LLMs. To investigate the robustness of LLMs while using their generation ability, we propose a novel rational evaluation pipeline that leverages reward models as diagnostic tools to evaluate the long conversation generated from more challenging open questions by LLMs, which we refer to as the Reward Model for Reasonable Robustness Evaluation (TREvaL). Longer conversations manifest the comprehensive grasp of language models in terms of their proficiency in understanding questions, a capability not entirely encompassed by individual words or letters.Our extensive empirical experiments demonstrate that TREvaL provides an identification for the lack of robustness of nowadays LLMs.Notably, we are surprised to discover that robustness tends to decrease as fine-tuning (SFT and RLHF) is conducted, calling for more attention on the robustness during alignment process.},
  archive      = {J_TMLR},
  author       = {Haoyu Wang and Guozheng Ma and Cong Yu and Ning Gui and Linrui Zhang and Zhiqi Huang and Suwei Ma and Yongzhe Chang and Sen Zhang and Li Shen and Xueqian Wang and Peilin Zhao and Dacheng Tao},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Are large language models really robust to word-level perturbations?},
  url          = {https://openreview.net/forum?id=rWSiBknwQa},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty representations in state-space layers for deep
reinforcement learning under partial observability. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=rfPns0WJyg">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimal decision-making under partial observability requires reasoning about the uncertainty of the environment’s hidden state. However, most reinforcement learning architectures handle partial observability with sequence models that have no internal mechanism to incorporate uncertainty in their hidden state representation, such as recurrent neural networks, deterministic state-space models and transformers. Inspired by advances in probabilistic world models for reinforcement learning, we propose a standalone Kalman filter layer that performs closed-form Gaussian inference in linear state-space models and train it end-to-end within a model-free architecture to maximize returns. Similar to efficient linear recurrent layers, the Kalman filter layer processes sequential data using a parallel scan, which scales logarithmically with the sequence length. By design, Kalman filter layers are a drop-in replacement for other recurrent layers in standard model-free architectures, but importantly they include an explicit mechanism for probabilistic filtering of the latent state representation. Experiments in a wide variety of tasks with partial observability show that Kalman filter layers excel in problems where uncertainty reasoning is key for decision-making, outperforming other stateful models.},
  archive      = {J_TMLR},
  author       = {Carlos E. Luis and Alessandro Giacomo Bottero and Julia Vinogradska and Felix Berkenkamp and Jan Peters},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Uncertainty representations in state-space layers for deep reinforcement learning under partial observability},
  url          = {https://openreview.net/forum?id=rfPns0WJyg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class incremental learning from first principles: A review.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sZdtTJInUg">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning systems attempt to efficiently learn over time without forgetting previously acquired knowledge. In recent years, there has been an explosion of work on continual learning, mainly focused on the class-incremental learning (CIL) setting. In this review, we take a step back and reconsider the CIL problem. We reexamine the problem definition and describe its unique challenges, contextualize existing solutions by analyzing non-continual approaches, and investigate the implications of various problem configurations. Our goal is to provide an alternative perspective to existing work on CIL and direct attention toward unexplored aspects of the problem.},
  archive      = {J_TMLR},
  author       = {Neil Ashtekar and Jingxi Zhu and Vasant G Honavar},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Class incremental learning from first principles: A review},
  url          = {https://openreview.net/forum?id=sZdtTJInUg},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Increasing both batch size and learning rate accelerates
stochastic gradient descent. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=sbmp55k6iE">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of mini-batch stochastic gradient descent (SGD) strongly depends on setting the batch size and learning rate to minimize the empirical loss in training the deep neural network. In this paper, we present theoretical analyses of mini-batch SGD with four schedulers: (i) constant batch size and decaying learning rate scheduler, (ii) increasing batch size and decaying learning rate scheduler, (iii) increasing batch size and increasing learning rate scheduler, and (iv) increasing batch size and warm-up decaying learning rate scheduler. We show that mini-batch SGD using scheduler (i) does not always minimize the expectation of the full gradient norm of the empirical loss, whereas it does using any of schedulers (ii), (iii), and (iv). Furthermore, schedulers (iii) and (iv) accelerate mini-batch SGD. The paper also provides numerical results of supporting analyses showing that using scheduler (iii) or (iv) minimizes the full gradient norm of the empirical loss faster than using scheduler (i) or (ii).},
  archive      = {J_TMLR},
  author       = {Hikaru Umeda and Hideaki Iiduka},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Increasing both batch size and learning rate accelerates stochastic gradient descent},
  url          = {https://openreview.net/forum?id=sbmp55k6iE},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating the robustness of analogical reasoning in large
language models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=t5cy5v9wph">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have performed well on several reasoning benchmarks, including ones that test analogical reasoning abilities. However, there is debate on the extent to which they are performing general abstract reasoning versus employing shortcuts or other non-robust processes, such as ones that overly rely on similarity to what has been seen in their training data. Here we investigate the robustness of analogy-making abilities previously claimed for LLMs on three of four domains studied by Webb et al. (2023): letter-string analogies, digit matrices, and story analogies. For each of these domains we test humans and GPT models on robustness to variants of the original analogy problems—versions that test the same abstract reasoning abilities but that are likely dissimilar from tasks in the pre-training data. The performance of a system that uses robust abstract reasoning should not decline substantially on these variants. On simple letter-string analogies, we find that while the performance of humans remains high for two types of variants we tested, the GPT models’ performance declines sharply. This pattern is less pronounced as the complexity of these analogy problems is increased, as both humans and GPT models perform poorly on both the original and variant problems requiring more complex analogies. On digit-matrix problems, we find a similar pattern but only on one out of the two types of variants we tested. Lastly, we assess the robustness of humans and GPT models on story-based analogy problems, finding that, unlike humans, the performance of GPT models are susceptible to answer-order effects, and that GPT models also may be more sensitive than humans to paraphrasing. This work provides evidence that, despite previously reported successes of LLMs on zero-shot analogical reasoning, these models often lack the robustness of zero-shot human analogy- making, exhibiting brittleness on most of the variations we tested. More generally, this work points to the importance of carefully evaluating AI systems not only for accuracy but also robustness when testing their cognitive capabilities. Code, data, and results for all experiments is available at https://github.com/marthaflinderslewis/robust-analogy.},
  archive      = {J_TMLR},
  author       = {Martha Lewis and Melanie Mitchell},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluating the robustness of analogical reasoning in large language models},
  url          = {https://openreview.net/forum?id=t5cy5v9wph},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing remaining useful life prediction with ensemble
multi-term fourier graph neural networks. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tzFjcVqmxw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) prediction is crucial in predictive maintenance. Recently, deep learning forecasting methods, especially Spatio-Temporal Graph Neural Networks (ST-GNNs), have achieved remarkable performance in RUL prediction. Most existing ST-GNNs require searching for the graph structure before utilizing GNNs to learn spatial graph representation, and they necessitate a temporal model such as LSTM to leverage the temporal dependencies in a fixed lookback window. However, such an approach has several limitations. Firstly, it demands substantial computational resources to learn graph structures for the time series data. Secondly, independently learning spatial and temporal information disregards their inherent correlation, and thirdly, capturing information within a fixed lookback window ignores long-term dependencies across the entire time series. To mitigate the issues above, instead of treating the data within the lookback window as a sequence of graphs in ST-GNN methods, we regard it as a complete graph and employ a Fourier Graph Neural Network (FGN) to learn the spatiotemporal information within this graph in the frequency space. Additionally, we create training and test graphs with varying sizes of lookback windows, enabling the model to learn both short-term and long-term dependencies and provide multiple predictions for ensemble averaging. We also consider scenarios where sensor signals exhibit multiple operation conditions and design a sequence decomposition plugin to denoise input signals, aiming to enhance the performance of FGN. We evaluate the proposed model on two benchmark datasets, demonstrating its superior performance on the RUL prediction task compared to state-of-the-art approaches.},
  archive      = {J_TMLR},
  author       = {Ya Song and Laurens Bliek and Yaoxin Wu and Yingqian Zhang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Enhancing remaining useful life prediction with ensemble multi-term fourier graph neural networks},
  url          = {https://openreview.net/forum?id=tzFjcVqmxw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diffusion on graph: Augmentation of graph structure for node
classification. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=tzW948kU6x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph diffusion models have recently been proposed to synthesize entire graphs, such as molecule graphs. Although existing methods have shown great performance in generating entire graphs for graph-level learning tasks, no graph diffusion models have been developed to generate synthetic graph structures, that is, synthetic nodes and associated edges within a given graph, for node-level learning tasks. Inspired by the research in the computer vision literature using synthetic data for enhanced performance, we propose Diffusion on Graph (DoG), which generates synthetic graph structures to boost the performance of GNNs. The synthetic graph structures generated by DoG are combined with the original graph to form an augmented graph for the training of node-level learning tasks, such as node classification and graph contrastive learning (GCL). To improve the efficiency of the generation process, a Bi-Level Neighbor Map Decoder (BLND) is introduced in DoG. To mitigate the adverse effect of the noise introduced by the synthetic graph structures, a low-rank regularization method is proposed for the training of graph neural networks (GNNs) on the augmented graphs. Extensive experiments on various graph datasets for semi-supervised node classification and graph contrastive learning have been conducted to demonstrate the effectiveness of DoG with low-rank regularization. The code of DoG is available at \url{https://github.com/Statistical-Deep-Learning/DoG}.},
  archive      = {J_TMLR},
  author       = {Yancheng Wang and Changyu Liu and Yingzhen Yang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Diffusion on graph: Augmentation of graph structure for node classification},
  url          = {https://openreview.net/forum?id=tzW948kU6x},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PROXI: Challenging the GNNs for link prediction.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=u9EHndbiVw">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, Graph Neural Networks (GNNs) have transformed graph representation learning. In the widely adopted message-passing GNN framework, nodes refine their representations by aggregating information from neighboring nodes iteratively. While GNNs excel in various domains, recent theoretical studies have raised concerns about their capabilities. GNNs aim to address various graph-related tasks by utilizing such node representations, however, this one-size-fits-all approach proves suboptimal for diverse tasks. Motivated by these observations, we conduct empirical tests to compare the performance of current GNN models with more conventional and direct methods in link prediction tasks. Introducing our model, PROXI, which leverages proximity information of node pairs in both graph and attribute spaces, we find that standard machine learning (ML) models perform competitively, even outperforming cutting-edge GNN models when applied to these proximity metrics derived from node neighborhoods and attributes. This holds true across both homophilic and heterophilic networks, as well as small and large benchmark datasets, including those from the Open Graph Benchmark (OGB). Moreover, we show that augmenting traditional GNNs with PROXI significantly boosts their link prediction performance. Our empirical findings corroborate the previously mentioned theoretical observations and imply that there exists ample room for enhancement in current GNN models to reach their potential.},
  archive      = {J_TMLR},
  author       = {Astrit Tola and Jack Myrick and Baris Coskunuzer},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {PROXI: Challenging the GNNs for link prediction},
  url          = {https://openreview.net/forum?id=u9EHndbiVw},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepRRTime: Robust time-series forecasting with a
regularized INR basis. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=uDRzORdPT7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a simple, inexpensive, theoretically motivated regularization term to enhance the robustness of deep time-index models for time-series forecasting. Recently, DeepTime demonstrated that this class of models can rival state-of-the-art deep historical-value models on the long time-series forecasting (LTSF) benchmarks. The DeepTime framework comprises two key components: (1) a time-indexed basis parameterized as an implicit neural representation (INR), and (2) a meta-learning formulation that fits observed data to this basis via ridge regression, then extrapolates the result to generate forecasts. Our regularization term encourages the time-indexed basis elements to be more unit standardized and less mutually correlated, intended to enable more robust ridge regression. The regularized variant matches or outperforms DeepTime on all LTSF benchmarks. Moreover, it is significantly more resilient to missing values in the lookback window at test time, enhances forecast accuracy when applied to higher-frequency data than it was trained on, and boosts performance when trained on smaller datasets. Overall, we conclude that our regularized approach sets a new state-of-the-art for deep time-index models.},
  archive      = {J_TMLR},
  author       = {Chandramouli Shama Sastry and Mahdi Gilany and Kry Yik-Chau Lui and Martin Magill and Alexander Pashevich},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {DeepRRTime: Robust time-series forecasting with a regularized INR basis},
  url          = {https://openreview.net/forum?id=uDRzORdPT7},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Wonderful team: Zero-shot physical task planning with visual
LLMs. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=udVkqIDYSM">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce Wonderful Team, a multi-agent Vision Large Language Model (VLLM) framework for executing high-level robotic planning in a zero-shot regime. In our context, zero-shot high-level planning means that for a novel environment, we provide a VLLM with an image of the robot&#39;s surroundings and a task description, and the VLLM outputs the sequence of actions necessary for the robot to complete the task. Unlike previous methods for high-level visual planning for robotic manipulation, our method uses VLLMs for the entire planning process, enabling a more tightly integrated loop between perception, control, and planning. As a result, Wonderful Team&#39;s performance on real-world semantic and physical planning tasks often exceeds methods that rely on separate vision systems. For example, we see an average 40% success rate improvement on VimaBench over prior methods such as NLaP, an average 30% improvement over Trajectory Generators on tasks from the Trajectory Generator paper, including drawing and wiping a plate, and an average 70% improvement over Trajectory Generators on a new set of semantic reasoning tasks including environment rearrangement with implicit linguistic constraints. We hope these results highlight the rapid improvements of VLLMs in the past year, and motivate the community to consider VLLMs as an option for some high-level robotic planning problems in the future.},
  archive      = {J_TMLR},
  author       = {Zidan Wang and Rui Shen and Bradly C. Stadie},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Wonderful team: Zero-shot physical task planning with visual LLMs},
  url          = {https://openreview.net/forum?id=udVkqIDYSM},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating interpretable methods via geometric alignment of
functional distortions. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=ukLxqA8zXj">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability researchers face a universal question: without access to ground truth labels, how can the faithfulness of an explanation to its model be determined? Despite immense efforts to develop new evaluation methods, current approaches remain in a pre-paradigmatic state: fragmented, difficult to calibrate, and lacking cohesive theoretical grounding. Observ- ing the lack of a unifying theory, we propose a novel evaluative criterion entitled Generalised Explanation Faithfulness (GEF) which is centered on explanation-to-model alignment, and integrates existing perturbation-based evaluations to eliminate the need for singular, task-specific evaluations. Complementing this unifying perspective, from a geometric point of view, we reveal a prevalent yet critical oversight in current evaluation practice: the failure to account for the learned geometry, and non-linear mapping present in the model, and explanation spaces. To solve this, we propose a general-purpose, threshold-free faithfulness evaluator GEF that incorporates principles from differential geometry, and facilitates evaluation agnostically across tasks, and interpretability approaches. Through extensive cross-domain benchmarks on natural language processing, vision, and tabular tasks, we provide first-of-its-kind insights into the comparative performance of various interpretable methods. This includes local linear approximators, global feature visualisation methods, large language models as post-hoc explainers, and sparse autoencoders. Our contributions are important to the interpretability and AI safety communities, offering a principled, unified approach for evaluation.},
  archive      = {J_TMLR},
  author       = {Anna Hedström and Philine Lou Bommer and Thomas F Burns and Sebastian Lapuschkin and Wojciech Samek and Marina MC Höhne},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Evaluating interpretable methods via geometric alignment of functional distortions},
  url          = {https://openreview.net/forum?id=ukLxqA8zXj},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph-level representation learning with joint-embedding
predictive architectures. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=v47f4DwYZb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint-Embedding Predictive Architectures (JEPAs) have recently emerged as a novel and powerful technique for self-supervised representation learning. They aim to learn an energy-based model by predicting the latent representation of a target signal y from the latent representation of a context signal x. JEPAs bypass the need for negative and positive samples, traditionally required by contrastive learning while avoiding the overfitting issues associated with generative pretraining. In this paper, we show that graph-level representations can be effectively modeled using this paradigm by proposing a Graph Joint-Embedding Predictive Architecture (Graph-JEPA). In particular, we employ masked modeling and focus on predicting the latent representations of masked subgraphs starting from the latent representation of a context subgraph. To endow the representations with the implicit hierarchy that is often present in graph-level concepts, we devise an alternative prediction objective that consists of predicting the coordinates of the encoded subgraphs on the unit hyperbola in the 2D plane. Through multiple experimental evaluations, we show that Graph-JEPA can learn highly semantic and expressive representations, as shown by the downstream performance in graph classification, regression, and distinguishing non-isomorphic graphs. The code is available at https://github.com/geriskenderi/graph-jepa.},
  archive      = {J_TMLR},
  author       = {Geri Skenderi and Hang Li and Jiliang Tang and Marco Cristani},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Graph-level representation learning with joint-embedding predictive architectures},
  url          = {https://openreview.net/forum?id=v47f4DwYZb},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Minimax lower bounds for estimating distributions on
low-dimensional spaces. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wIgRV336hC">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent statistical analyses of Generative Adversarial Networks (GAN) suggest that the error in estimating the target distribution in terms of the $\beta$-H\&quot;{o}lder Integral Probability Metric (IPM) scales as $\mathcal{O}\left(n^{-\frac{\beta}{\overline{d}_{\mathbb{M}}+\delta}} \vee n^{-1/2} \log n \right)$. Here $\overline{d}_{\mathbb{M}}$ is the upper Minkowski dimension of the corresponding support $\mathbb{M}$ of the data distribution and $\delta$ is a positive constant. It is, however, unknown as to whether this rate is minimax optimal, i.e. whether there are estimators that achieve a better test-error rate. This paper demonstrates that the minimax rate for estimating unknown distributions in the $\beta$-H\&quot;{o}lder IPM on $\mathbb{M}$ scales as $\Omega\left(n^{-\frac{\beta}{\underline{d}_{\mathbb{M}}-\delta}} \vee n^{-1/2}\right)$, where $\underline{d}_{\mathbb{M}}$ is the lower Minkowski dimension of $\mathbb{M}$. Thus if the low-dimensional structure $\mathbb{M}$ is regular in the Minkowski sense, i.e. $\overline{d}_{\mathbb{M}} = \underline{d}_{\mathbb{M}}$, GANs are roughly minimax optimal in estimating distributions on $\mathbb{M}$. Further, the paper shows that the minimax estimation rate in the $p$-Wasserstein metric scales as $\Omega\left(n^{-\frac{1}{\underline{d}_{\mathbb{M}}-\delta}} \vee n^{-1/(2p)}\right)$.},
  archive      = {J_TMLR},
  author       = {Saptarshi Chakraborty},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Minimax lower bounds for estimating distributions on low-dimensional spaces},
  url          = {https://openreview.net/forum?id=wIgRV336hC},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The elusive pursuit of reproducing PATE-GAN: Benchmarking,
auditing, debugging. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=wcxrJcJ7vq">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic data created by differentially private (DP) generative models is increasingly used in real-world settings. In this context, PATE-GAN has emerged as one of the most popular algorithms, combining Generative Adversarial Networks (GANs) with the private training approach of PATE (Private Aggregation of Teacher Ensembles). In this paper, we set out to reproduce the utility evaluation from the original PATE-GAN paper, compare available implementations, and conduct a privacy audit. More precisely, we analyze and benchmark six open-source PATE-GAN implementations, including three by (a subset of) the original authors. First, we shed light on architecture deviations and empirically demonstrate that none reproduce the utility performance reported in the original paper. We then present an in-depth privacy evaluation, which includes DP auditing, and show that \textit{all implementations leak more privacy than intended}. Furthermore, we uncover \textit{19 privacy violations} and 5 other bugs in these six open-source implementations. Lastly, our codebase is available from: \url{https://github.com/spalabucr/pategan-audit}.},
  archive      = {J_TMLR},
  author       = {Georgi Ganev and Meenatchi Sundaram Muthu Selva Annamalai and Emiliano De Cristofaro},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The elusive pursuit of reproducing PATE-GAN: Benchmarking, auditing, debugging},
  url          = {https://openreview.net/forum?id=wcxrJcJ7vq},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpreting neurons in deep vision networks with language
models. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=x1dXvvElVd">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose Describe-and-Dissect (DnD), a novel method to describe the roles of hidden neurons in vision networks. DnD utilizes recent advancements in multimodal deep learning to produce complex natural language descriptions, without the need for labeled training data or a predefined set of concepts to choose from. Additionally, DnD is training-free, meaning we don’t train any new models and can easily leverage more capable general purpose models in the future. We have conducted extensive qualitative and quantitative analysis to show that DnD outperforms prior work by providing higher quality neuron descriptions. Specifically, our method on average provides the highest quality labels and is more than 2× as likely to be selected as the best explanation for a neuron than the best baseline. Finally, we present a use case providing critical insights into land cover prediction models for sustainability applications.},
  archive      = {J_TMLR},
  author       = {Nicholas Bai and Rahul Ajay Iyer and Tuomas Oikarinen and Akshay R. Kulkarni and Tsui-Wei Weng},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Interpreting neurons in deep vision networks with language models},
  url          = {https://openreview.net/forum?id=x1dXvvElVd},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The 2023 foundation model transparency index. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=x6fXnsM9Ez">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foundation models have rapidly permeated society, catalyzing a wave of generative AI applications spanning enterprise and consumer-facing contexts. While the societal impact of foundation models is growing, transparency is on the decline, mirroring the opacity that has plagued past digital technologies (e.g. social media). Reversing this trend is essential: transparency is a vital precondition for public accountability, scientific innovation, and effective governance. To assess the transparency of the foundation model ecosystem and help improve transparency over time, we introduce the Foundation Model Transparency Index. The Foundation Model Transparency Index specifies 100 fine-grained indicators that comprehensively codify transparency for foundation models, spanning the upstream resources used to build a foundation model (e.g data, labor, compute), details about the model itself (e.g. size, capabilities, risks), and the downstream use (e.g. distribution channels, usage policies, affected geographies). We score 10 major foundation model developers (e.g. OpenAI, Google, Meta) against the 100 indicators to assess their transparency. To facilitate and standardize assessment, we score developers in relation to their practices for their flagship foundation model (e.g. GPT-4 for OpenAI, PaLM 2 for Google, Llama 2 for Meta). We present 10 top-level findings about the foundation model ecosystem: for example, no developer currently discloses significant information about the downstream impact of its flagship model, such as the number of users, affected market sectors, or how users can seek redress for harm. Overall, the Foundation Model Transparency Index establishes the level of transparency today to drive progress on foundation model governance via industry standards and regulatory intervention.},
  archive      = {J_TMLR},
  author       = {Rishi Bommasani and Kevin Klyman and Shayne Longpre and Sayash Kapoor and Nestor Maslej and Betty Xiong and Daniel Zhang and Percy Liang},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {The 2023 foundation model transparency index},
  url          = {https://openreview.net/forum?id=x6fXnsM9Ez},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Faster diffusion through temporal attention decomposition.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xXs2GKXPnH">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the role of the attention mechanism during inference in text-conditional diffusion models. Empirical observations suggest that cross-attention outputs converge to a fixed point after several inference steps. The convergence time naturally divides the entire inference process into two phases: an initial phase for planning text-oriented visual semantics, which are then translated into images in a subsequent fidelity-improving phase. Cross-attention is essential in the initial phase but almost irrelevant thereafter. Self-attention, however, initially plays a minor role but becomes increasingly important in the second phase. These findings yield a simple and training-free method called TGATE which efficiently generates images by caching and reusing attention outputs at scheduled time steps. Experiments show TGATE’s broad applicability to various existing text-conditional diffusion models which it speeds up by 10-50%. The code of TGATE is available at https://github.com/HaozheLiu-ST/T-GATE.},
  archive      = {J_TMLR},
  author       = {Haozhe Liu and Wentian Zhang and Jinheng Xie and Francesco Faccio and Mengmeng Xu and Tao Xiang and Mike Zheng Shou and Juan-Manuel Perez-Rua and Jürgen Schmidhuber},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Faster diffusion through temporal attention decomposition},
  url          = {https://openreview.net/forum?id=xXs2GKXPnH},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partially frozen random networks contain compact strong
lottery tickets. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=xpnPYfufhz">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomly initialized dense networks contain subnetworks that achieve high accuracy without weight learning—strong lottery tickets (SLTs). Recently, Gadhikar et al. (2023) demonstrated that SLTs could also be found within a randomly pruned source network. This phenomenon can be exploited to further compress the small memory size required by SLTs. However, their method is limited to SLTs that are even sparser than the source, leading to worse accuracy due to unintentionally high sparsity. This paper proposes a method for reducing the SLT memory size without restricting the sparsity of the SLTs that can be found. A random subset of the initial weights is frozen by either permanently pruning them or locking them as a fixed part of the SLT, resulting in a smaller model size. Experimental results show that Edge-Popup (Ramanujan et al., 2020; Sreenivasan et al., 2022) finds SLTs with better accuracy-to-model size trade-off within frozen networks than within dense or randomly pruned source networks. In particular, freezing $70\%$ of a ResNet on ImageNet provides $3.3\times$ compression compared to the SLT found within a dense counterpart, raises accuracy by up to $14.12$ points compared to the SLT found within a randomly pruned counterpart, and offers a better accuracy-model size trade-off than both.},
  archive      = {J_TMLR},
  author       = {Hikari Otsuka and Daiki Chijiwa and Ángel López García-Arias and Yasuyuki Okoshi and Kazushi Kawamura and Thiem Van Chu and Daichi Fujiki and Susumu Takeuchi and Masato Motomura},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {Partially frozen random networks contain compact strong lottery tickets},
  url          = {https://openreview.net/forum?id=xpnPYfufhz},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LLaVA-OneVision: Easy visual task transfer. <em>TMLR</em>.
(<a href="https://openreview.net/forum?id=zKv8qULV6n">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present LLaVA-OneVision, a family of open large multimodal models (LMMs) developed by consolidating our insights into data, models, and visual representations in the LLaVA-NeXT blog series. Our experimental results demonstrate that LLaVA-OneVision is the first single model that can simultaneously push the performance boundaries of open LMMs in three important computer vision scenarios: single-image, multi-image, and video scenarios. Importantly, the design of LLaVA-OneVision allows strong transfer learning across different modalities/scenarios, yielding new emerging capabilities. In particular, strong video understanding and cross-scenario capabilities are demonstrated through task transfer from images to videos.},
  archive      = {J_TMLR},
  author       = {Bo Li and Yuanhan Zhang and Dong Guo and Renrui Zhang and Feng Li and Hao Zhang and Kaichen Zhang and Peiyuan Zhang and Yanwei Li and Ziwei Liu and Chunyuan Li},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {LLaVA-OneVision: Easy visual task transfer},
  url          = {https://openreview.net/forum?id=zKv8qULV6n},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural material point method for particle-based emulation.
<em>TMLR</em>. (<a
href="https://openreview.net/forum?id=zSK81A2hxQ">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mesh-free Lagrangian methods are widely used for simulating fluids, solids, and their complex interactions due to their ability to handle large deformations and topological changes. These physics simulators, however, require substantial computational resources for accurate simulations. To address these issues, deep learning emulators promise faster and scalable simulations, yet they often remain expensive and difficult to train, limiting their practical use. Inspired by the Material Point Method (MPM), we present NeuralMPM, a neural framework for particle-based emulation. NeuralMPM interpolates Lagrangian particles onto a fixed-size grid, computes updates on grid nodes using image-to-image neural networks, and interpolates back to the particles. Similarly to MPM, NeuralMPM benefits from the regular voxelized representation to simplify the computation of the state dynamics, while avoiding the drawbacks of mesh-based Eulerian methods. We demonstrate the advantages of NeuralMPM on 6 datasets, including fluid dynamics and fluid-solid interactions simulated with MPM and Smoothed Particles Hydrodynamics (SPH). Compared to GNS and DMCF, NeuralMPM reduces training time from 10 days to 15 hours, memory consumption by 10x-100x, and increases inference speed by 5x-10x, while achieving comparable or superior long-term accuracy, making it a promising approach for practical forward and inverse problems. A project page is available at https://neuralmpm.isach.be/.},
  archive      = {J_TMLR},
  author       = {Omer Rochman-Sharabi and Sacha Lewin and Gilles Louppe},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {A neural material point method for particle-based emulation},
  url          = {https://openreview.net/forum?id=zSK81A2hxQ},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On diffusion-based generative models and their error bounds:
The log-concave case with full convergence estimates. <em>TMLR</em>. (<a
href="https://openreview.net/forum?id=zjxKrb4ehr">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide full theoretical guarantees for the convergence behaviour of diffusion-based generative models under the assumption of strongly log-concave data distributions while our approximating class of functions used for score estimation is made of Lipschitz continuous functions avoiding any Lipschitzness assumption on the score function. We demonstrate via a motivating example, sampling from a Gaussian distribution with unknown mean, the powerfulness of our approach. In this case, explicit estimates are provided for the associated optimization problem, i.e. score approximation, while these are combined with the corresponding sampling estimates. As a result, we obtain the best known upper bound estimates in terms of key quantities of interest, such as the dimension and rates of convergence, for the Wasserstein-2 distance between the data distribution (Gaussian with unknown mean) and our sampling algorithm. Beyond the motivating example and in order to allow for the use of a diverse range of stochastic optimizers, we present our results using an $L^2$-accurate score estimation assumption, which crucially is formed under an expectation with respect to the stochastic optimizer and our novel auxiliary process that uses only known information. This approach yields the best known convergence rate for our sampling algorithm.},
  archive      = {J_TMLR},
  author       = {Stefano Bruno and Ying Zhang and Dongyoung Lim and Omer Deniz Akyildiz and Sotirios Sabanis},
  journal      = {Transactions on Machine Learning Research},
  month        = {2},
  shortjournal = {Trans. Mach. Learn. Res.},
  title        = {On diffusion-based generative models and their error bounds: The log-concave case with full convergence estimates},
  url          = {https://openreview.net/forum?id=zjxKrb4ehr},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
