<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ws_all</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h1 id="ws">WS</h1>
<h2 id="iet---5">IET - 5</h2>
<ul>
<li><details>
<summary>
(2025). A review of emerging technologies in wireless communication
systems. <em>IET</em>, <em>12</em>, 2550005. (<a
href="https://doi.org/10.1142/S2737599425500057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article reviews emerging technologies in wireless communication systems, focusing on their key concepts, principles, use cases, and challenges. It examines relevant studies in the telecommunication sector, with a focus on technologies that enhance connectivity, performance, and innovative applications across industries. The review highlights advancements such as fifth-generation (5G) networks, which offer faster data speeds, lower latency, and increased network capacity, enabling the development of applications like autonomous vehicles, smart cities, and Internet of Things (IoT) devices. IoT devices are increasingly connecting physical objects, driving innovation in sectors such as healthcare, agriculture, transportation, and manufacturing. Edge computing, by enabling real-time processing and reducing latency, supports IoT applications requiring immediate responses. Artificial intelligence (AI) and machine learning (ML) are being integrated to optimize network resources, improve spectrum management, and facilitate intelligent decision-making. Technologies such as massive multiple input, multiple output (MIMO) enhance spectral efficiency, network capacity, and interference reduction. Millimeter wave (mmWave) frequencies are being explored for high-speed wireless communication, enabling multi-gigabit data rates and applications in 5G, wireless backhaul, and ultra-high-definition video streaming. Software-defined networking (SDN) and network function virtualization (NFV) enable centralized management and greater network flexibility, while beam steering improves signal quality and coverage by directing wireless signals toward specific receivers. Quantum communication, leveraging quantum principles, provides secure communication channels, while quantum key distribution (QKD) ensures data confidentiality. Visible light communication (VLC) utilizes visible light for high-speed data transfer in environments where RF-based communication is not feasible. Despite the potential of these technologies, the article identifies challenges such as limited practical implementation, standardization issues, resource constraints, security and privacy concerns, and sustainability challenges. It concludes by discussing the practical implications of these emerging technologies, including enhanced data transfer speeds, improved network capacity, low-latency communication, IoT connectivity, ubiquitous coverage, industry transformation, and the security and privacy considerations that accompany these advancements.},
  archive      = {J_IET},
  author       = {Promise Elechi and Solomon Malcolm Ekolama and Ela Okowa and Shadrack Kukuchuku},
  doi          = {10.1142/S2737599425500057},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550005},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {A review of emerging technologies in wireless communication systems},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-driven healthcare systems: A personalized symptom-based
disease prognosis tool using RF, GNB, and SVC techniques. <em>IET</em>,
<em>12</em>, 2550003. (<a
href="https://doi.org/10.1142/S2737599425500033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) technology is being leveraged for multiple tasks in the healthcare sector, such as improving the diagnosis of disease, streamlining management services, and tailoring treatment procedures. Applying predictive analysis and performing robotic surgery helps patients in a way that reduces the burden on their caregivers. This study uses a healthcare disease prediction dataset using three robust machine learning algorithms: random forest (RF), Gaussian Naïve Bayes (GNB), and support vector classifier (SVC). The models learn to use other symptoms to detect the presence of various diseases. In model evaluation, cross-validation is done on the training set after data preprocessing is performed to ensure none of the groups is overrepresented in the final model. In both the training and the testing of each model, which were respectively 100%, the model was able to make perfect predictions. A vote of three classifiers reached the 100% precision mark over a test dataset on an ensemble model that combined all the classifiers. This research integrates the advances in AI technology into the healthcare setting in a bid to enhance healthcare delivery. Additionally, we created such a straightforward tool in the case of input symptoms and proposed a possible disease diagnosis. This study also adds to the expanding corpus of research on AI in healthcare by providing a practical method for symptom-based diagnosis.},
  archive      = {J_IET},
  author       = {Massoud Massoudi and Ruchika Malhotra},
  doi          = {10.1142/S2737599425500033},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550003},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {AI-driven healthcare systems: A personalized symptom-based disease prognosis tool using RF, GNB, and SVC techniques},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scrap steel price predictions for southwest china via
machine learning. <em>IET</em>, <em>12</em>, 2550002. (<a
href="https://doi.org/10.1142/S2737599425500021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasts of prices for a wide range of commodities have been a source of confidence for governments and investors throughout history. This study examines the difficult task of forecasting scrap steel prices, which are released every day for the southwest China market, leveraging time-series data spanning August 23, 2013 to April 15, 2021. Estimates have not been fully considered in previous studies for this important commodity price assessment. In this case, cross-validation procedures and Bayesian optimization techniques are used to develop Gaussian process regression strategies, and consequent price projections are built. Arriving at a relative root mean square error of 0.4691%, this empirical prediction approach yields fairly precise price projections throughout the out-of-sample stage spanning September 17, 2019 to April 15, 2021. Through the use of price research models, governments and investors may make well-informed judgments on regional markets of scrap steel.},
  archive      = {J_IET},
  author       = {Bingzi Jin and Xiaojie Xu},
  doi          = {10.1142/S2737599425500021},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550002},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Scrap steel price predictions for southwest china via machine learning},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Research of ultra-low concentration ion implantation on chip
substrates using film delamination method combined with semiconductor
simulation technology. <em>IET</em>, <em>12</em>, 2550001. (<a
href="https://doi.org/10.1142/S273759942550001X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research proposes a novel ion implantation technique that combines the film delamination method with semiconductor simulation technology to achieve low-dose, high-uniformity semiconductor doping. The method involves depositing a protective layer on the substrate, implanting ions into the layer, performing high-temperature pre-diffusion, delaminating the protective layer, and completing the diffusion process. By integrating semiconductor simulation software, such as Silvaco TCAD, the research aims to optimize parameters for the protective layer and achieve precise control of doping concentrations. This innovative approach addresses the challenges of uniformity and cost in traditional ion implantation equipment.},
  archive      = {J_IET},
  author       = {Zhiwei Yang and Asim Abas and Yuanxun Cao},
  doi          = {10.1142/S273759942550001X},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2550001},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Research of ultra-low concentration ion implantation on chip substrates using film delamination method combined with semiconductor simulation technology},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robotics in healthcare: A review. <em>IET</em>, <em>12</em>,
2530001. (<a href="https://doi.org/10.1142/S2737599425300016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From early industrial prototypes in the 1960s and 1970s to sophisticated systems integrated into contemporary medical practice, healthcare robotics has come a long way in the last 10 years. Human potential has been enhanced by robotics in many ways, most notably in the areas of safety, accuracy, and repeatability. When paired with artificial intelligence (AI), these developments have enormous potential for the healthcare industry in the 21st century. These days, robots help in various places, such as healthcare facilities, assisted living apartments, and rehabilitation centers. For example, Aethon’s TUG robots carry supplies throughout hospitals effectively and lessen the effort of hospital staff. The main applications of healthcare robotics, including telepresence, rehabilitation, and operating rooms, are outlined in this chapter. Giraff and other telepresence robots allow doctors to observe patients from a distance. Hugo TM RAS system from Medtronic has recently garnered notice because of its availability as a modular minimally invasive surgery solution that directly competes with the Da Vinci System in hospitals across the globe. Taking a focus on surgery rooms, telemedicine, and assistive care, this manuscript offers a broad review of the most recent advancements in healthcare robotics. It highlights the difficulties in properly integrating these technologies into the medical field.},
  archive      = {J_IET},
  author       = {Dinesh Bhatia and Tania Acharjee and Agnila Sengupta},
  doi          = {10.1142/S2737599425300016},
  journal      = {Innovation and Emerging Technologies},
  pages        = {2530001},
  shortjournal = {Innov. Emerg. Technol.},
  title        = {Robotics in healthcare: A review},
  volume       = {12},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijcia---13">IJCIA - 13</h2>
<ul>
<li><details>
<summary>
(2025). Calendar of events. <em>IJCIA</em>, <em>24</em>(1), 2583001.
(<a href="https://doi.org/10.1142/S1469026825830019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJCIA},
  doi          = {10.1142/S1469026825830019},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2583001},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Calendar of events},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective deep learning-based intrusion detection system
for the healthcare environment. <em>IJCIA</em>, <em>24</em>(1), 2450033.
(<a href="https://doi.org/10.1142/S1469026824500330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the medical field, Internet of Things (IoT) applications allow for real-time diagnosis and remote patient monitoring, commonly called Internet of Health Things (IoHT). However, cybersecurity attacks may interrupt hospital operations and threaten patients’ health and well-being due to this integration. Hence, developing an Intrusion Detection System (IDS) suited explicitly for healthcare systems is essential to ensure efficiency and accuracy. Nevertheless, it is challenging to integrate anomaly-based IDS frameworks in healthcare systems as they necessitate additional processing time, temporal feature retention, and increased complexity. Therefore, a deep learning system based on SqueezeNet and NasNet is presented in this paper to detect intrusions in a healthcare setting. In this, SqueezeNet is employed to extract more significant features. On the other hand, network breaches while data transmission across distinct locations are detected by the NasNet-based classifier. In addition, the Rider Optimization Algorithm (ROA) is applied to adjust the classifier’s hyperparameters, guaranteeing that it would accurately detect attacks. Moreover, the Auxiliary Classifier Generative Adversarial Network (ACGAN) approach is integrated into the proposed framework to avoid data imbalance. Applying different performance constraints, the proposed approach is thoroughly assessed on three publicly available datasets (TON-IoT, ECU-IoHT, and WUSTL-EHMS). The results show that the proposed deep learning-based cybersecurity model outperforms traditional methods and produces better outcomes.},
  archive      = {J_IJCIA},
  author       = {K. Balaji and S. Satheesh Kumar and D. Vivek and S. Prem Kumar Deepak and K. V. Daya Sagar and S. Thabassum Khan},
  doi          = {10.1142/S1469026824500330},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450033},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {An effective deep learning-based intrusion detection system for the healthcare environment},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RN-STLSTM-GAN: Spatiotemporal-guided generative adversarial
network for time-evolving precipitation downscaling. <em>IJCIA</em>,
<em>24</em>(1), 2450032. (<a
href="https://doi.org/10.1142/S1469026824500329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) have been widely applied in the field of meteorological research, particularly in the downscaling of images due to their ability to generate super-resolution images. In recent years, numerous researchers have combined GANs with recurrent neural networks (RNNs) to address the issue of meteorological super-resolution. However, these models do not take into account the spatial variations of meteorological sequences. In this paper, we propose a super-resolution method named RN-STLSTM-GAN, which combines GANs with RN-STLSTM and ESA networks to learn the spatiotemporal features of meteorological sequences. Specifically, we first apply the RN-STLSTM at the initialization of the generator and discriminator to learn the spatiotemporal relationships between sequential images. Second, an ESA network is combined with the RN-STLSTM structure to enhance the learning of spatial features. Thirdly, LeakyReLU is used as the activation function for both the generator and discriminator to minimize the loss of image data during model training. Experiments conducted on the NJU-CPOL datasets demonstrate that our proposed method outperforms other existing methods and can generate realistic and temporally consistent super-resolution sequences for datasets at different heights.},
  archive      = {J_IJCIA},
  author       = {Meng Li and Ziting Xu and Zhengjie Li and Yajie Qi},
  doi          = {10.1142/S1469026824500329},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450032},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {RN-STLSTM-GAN: Spatiotemporal-guided generative adversarial network for time-evolving precipitation downscaling},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing the hybrid feature selection in the DNA
microarray for cancer diagnosis using fuzzy entropy and the giza pyramid
construction algorithm. <em>IJCIA</em>, <em>24</em>(1), 2450031. (<a
href="https://doi.org/10.1142/S1469026824500317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biotechnological analysis of DNA microarray genes provides valuable insights into the discovery and treatment of diseases such as cancer. It may also be crucial for the prevention and treatment of other genetic diseases. However, due to the large number of features and dimensions in a DNA microarray, the “curse of dimensions” problem is very common. Many machine learning methods require an effective subset of input genes to achieve high accuracy. Unfortunately, extracting features (genes) is an inherently NP-hard problem. Recently, the use of metaheuristics to overcome the NP-hardness of the feature extraction problem has attracted the attention of many researchers. In this paper, we use the combination of fuzzy entropy and Giza Pyramid Construction (GPC) for feature selection. First, redundant features in the microarray dataset are removed using the fuzzy entropy approach. GPC is then used to reduce the execution time. This results in the selection of a near-optimal subset of genes for cancer detection. Dimensionality reduction with GPC followed by classification with Convolutional Neural Network (CNN) creates a synergy to increase efficiency. The proposed method is tested on five well-known cancer patient datasets: leukemia, lymphoma, MLL, ovarian, and SRBCT. The performance of CNN was also measured with four well-known classifiers, including K-nearest neighbor, naïve Bayesian, decision tree, and logistic regression. Our results show that, on average, CNN has the highest accuracy, recall, precision, and F-measure in all datasets.},
  archive      = {J_IJCIA},
  author       = {Masoumeh Motevalli and Madjid Khalilian and Azam Bastanfard},
  doi          = {10.1142/S1469026824500317},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450031},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Optimizing the hybrid feature selection in the DNA microarray for cancer diagnosis using fuzzy entropy and the giza pyramid construction algorithm},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adadelta-CSA: Adadelta-chameleon swarm algorithm for
EEG-based epileptic seizure detection. <em>IJCIA</em>, <em>24</em>(1),
2450030. (<a href="https://doi.org/10.1142/S1469026824500305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is referred to as a neurological disorder, which is detected via examination and manual comprehension of Electroencephalogram (EEG) signals. In deep learning schemes, various enhancements have emerged to efficiently address complex issues by end-to-end learning. The major objective of this research is to propose a new seizure detection approach from EEG signals using a deep learning-based classification technique. The pre-processing is the initial stage, where denoising is performed using a Short-Time Fourier Transform (STFT). Subsequently, the statistical features, time-domain features and spectral features are extracted from the pre-processed signal. Finally, an efficient optimization approach, named Adadelta-Chameleon Swarm Algorithm (Adadelta-CSA), is proposed and employed to train Deep Neural Network (DNN) to carry out the precise seizure prediction. Here, the integration of the Adadelta concept in the Chameleon Swarm Algorithm (CSA) has resulted in Adadelta-CSA. At last, the performance of the Adadelta-CSA scheme-based DNN is compared with the existing techniques by considering accuracy, sensitivity and specificity, and it is found to produce better values of 0.951, 0.966, and 0.935, respectively.},
  archive      = {J_IJCIA},
  author       = {G. Indu Salini and I. Sowmy},
  doi          = {10.1142/S1469026824500305},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450030},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Adadelta-CSA: Adadelta-chameleon swarm algorithm for EEG-based epileptic seizure detection},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised image aesthetic assessment based on
transformer. <em>IJCIA</em>, <em>24</em>(1), 2450029. (<a
href="https://doi.org/10.1142/S1469026824500299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual aesthetics has always been an important area of computational vision, and researchers have continued exploring it. To further improve the performance of the image aesthetic evaluation task, we introduce a Transformer into the image aesthetic evaluation task. This paper pioneers a novel self-supervised image aesthetic evaluation model founded upon Transformers. Meanwhile, we expand the pretext task to capture rich visual representations, adding a branch for inpainting the masked images in parallel with the tasks related to aesthetic quality degradation operations. Our model’s refinement employs the innovative uncertainty weighting method, seamlessly amalgamating three distinct losses into a unified objective. On the AVA dataset, our approach surpasses the efficacy of prevailing self-supervised image aesthetic assessment methods. Remarkably, we attain results approaching those of supervised methods, even while operating with a limited dataset. On the AADB dataset, our approach improves the aesthetic binary classification accuracy by roughly 16% compared to other self-supervised image aesthetic assessment methods and improves the prediction of aesthetic attributes.},
  archive      = {J_IJCIA},
  author       = {Minrui Jia and Guangao Wang and Zibei Wang and Shuai Yang and Yongzhen Ke and Kai Wang},
  doi          = {10.1142/S1469026824500299},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450029},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Self-supervised image aesthetic assessment based on transformer},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-stream fusion network for human energy expenditure
estimation with wearable sensor. <em>IJCIA</em>, <em>24</em>(1),
2450028. (<a href="https://doi.org/10.1142/S1469026824500287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing awareness of health, using wearable sensors to monitor individual activities and accurately estimate energy expenditure has become a current research focus. However, existing research encounters challenges including low estimation accuracy, a deficiency of frequency domain features, and difficulty in integrating time domain and frequency domain features. To address these issues, we propose an innovative framework called the Dual-Stream Fusion Network (DSFN). This framework combines the Time Domain Encoding (TDE) module, the Frequency Domain Hierarchical-Split Encoding (FDHSE) module, and a Two-Stage Feature Fusion (TSF) module. Specifically, the temporal stream of the framework employs the TDE module to capture deep temporal features that reflect the complex dynamic variations in time-series data. The frequency domain stream introduces the FDHSE module, which extracts frequency domain features using a multi-level, multi-scale approach, ensuring a comprehensive and diverse representation of frequency information. Through this dual-stream architecture, our model effectively learns both time and frequency domain features, addressing the limitations of frequency domain features observed in prior studies. Additionally, we propose the TSF module to fully integrate time and frequency domain features, effectively overcoming the challenge of fusing these two types of features. We conducted experiments on two public datasets, namely the GOTOV dataset (elderly people) and the JSI dataset (young people). Experimental results demonstrate that our method achieves excellent performance across different age groups. Compared to the baseline models, the proposed DSFN significantly improves the accuracy of human energy expenditure estimation.},
  archive      = {J_IJCIA},
  author       = {Shuo Xiao and Zhiyu Wang and Chaogang Tang and Zhenzhen Huang},
  doi          = {10.1142/S1469026824500287},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450028},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A dual-stream fusion network for human energy expenditure estimation with wearable sensor},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rural tourist attractions recommendation model based on
multi-feature fusion graph neural networks. <em>IJCIA</em>,
<em>24</em>(1), 2450027. (<a
href="https://doi.org/10.1142/S1469026824500275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth of the rural tourism industry, traditional tourism recommendation technologies can no longer meet the necessary requirements. To address the issue of rural tourist attraction recommendations, a rural tourist attraction recommendation model is constructed based on a multi-feature fusion graph neural network. First, construct a feature map based on the relationship between tourists’ preferences and tourist attractions, and incorporate the attention mechanism to enhance the model’s learning capabilities. Second, utilize a two-part graph model to extract positive and negative preference features of tourists, and a conversation graph model to extract tourists’ transfer preference features. Finally, various features are utilized to generate suggested content by computing scores for tourists’ travel preferences. To address the problem of recommending tourist groups, suitable features for random group matching are collected and the cosine function is employed to identify users with similar random group features. Finally, the multi-features are merged, and the tourists’ interest preferences are scored to arrive at content recommendations. In the experiment on individualized attraction recommendations, data from the Chengdu area were used to test the proposed model. The accuracy of the model’s recommendations was 0.822 for five recommendations which outperformed the other models. In the experiment for group-based attraction recommendations, this experiment tested the Chengdu dataset. The proposed model achieved the highest accuracy of 0.972 when the group size was 70, outperforming the other two models. Additionally, with regards to different numbers of recommendations, the proposed model’s accuracy was 0.5241, which was the best performance among the three models when the number of recommendations was set to five. The proposed recommendation model performs optimally in suggesting tourist attractions and meets the needs of rural tourism. The research content provides crucial technical references for tourist traveling and rural tourism development.},
  archive      = {J_IJCIA},
  author       = {Xiangrong Zhang and Xueying Wang},
  doi          = {10.1142/S1469026824500275},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450027},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Rural tourist attractions recommendation model based on multi-feature fusion graph neural networks},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Music generation using dual interactive wasserstein fourier
acquisitive generative adversarial network. <em>IJCIA</em>,
<em>24</em>(1), 2450026. (<a
href="https://doi.org/10.1142/S1469026824500263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Music composition, an intricate blend of human creativity and emotion, presents substantial challenges when generating melodies from lyrics which hinders effective learning in neural networks and the inadequate depiction of harmonic structure that fails to encapsulate the complex relationships between lyrics and melodies. The existing methods often struggle to balance emotional depth and structural coherence, leading to compositions that lack both the intended emotional resonance and musical consistency. To overcome these issues, this research introduces a novel approach named Dual Interactive Wasserstein Fourier Acquisitive Generative Adversarial Network (DIWFA-GAN), which integrates innovative techniques like swish activation functions and the Giant Trevally Optimizer (GTO) for parameter optimization. Meanwhile, the GTO, inspired by the movement patterns of the Giant Trevally fish, provides efficient and effective parameter optimization, improving the model’s convergence speed and accuracy. Comparative analysis against recent existing models reveals superior performance for both the LMD-full MIDI and Reddit MIDI datasets, with impressive metrics including inception scores of 9.36 and 2.98, Fréchet inception distances of 35.29 and 135.54 and accuracies of 99.98% and 99.95%, respectively. The DIWFA-GAN significantly outperforms existing models in generating high-fidelity melodies, as evidenced by superior inception scores, Fréchet inception distances, and accuracies on both datasets.},
  archive      = {J_IJCIA},
  author       = {Tarannum Shaikh and Ashish Jadhav},
  doi          = {10.1142/S1469026824500263},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450026},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Music generation using dual interactive wasserstein fourier acquisitive generative adversarial network},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bi-population competition adaptive interior search
algorithm based on reinforcement learning for flexible job shop
scheduling problem. <em>IJCIA</em>, <em>24</em>(1), 2450025. (<a
href="https://doi.org/10.1142/S1469026824500251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a bi-population competition adaptive interior search algorithm (BCAISA) based on a reinforcement learning strategy is proposed for the classical flexible job shop scheduling problem (FJSP) to optimize the makespan. First, the scheduling solution is represented using a machine-job-based two-segment integer encoding method, and various heuristic rules are then applied to generate the initial population. Secondly, a bi-population mechanism is introduced to partition the population into two distinct sub-populations. These sub-populations are specifically tailored for machine assignment and operation permutation, employing different search strategies respectively, aiming to facilitate an efficient implementation of parallel search. A competition mechanism is introduced to facilitate the information exchange between the two sub-populations. Thirdly, the ISA is adapted for the discrete scheduling problem by discretizing a series of search operators, which include composition optimization, mirror search, and random walk. A Q-learning-based approach is proposed to dynamically adjust a key parameter, aiming to strike a balance between the capacity for global exploration and local exploitation. Finally, extensive experiments are conducted based on 10 well-known benchmark instances of the FJSP. The design of the experiment (DOE) method is employed to determine the algorithm’s parameters. Based on the computational results, the effectiveness of four improvement strategies is first validated. The BCAISA is then compared with fifteen published algorithms. The comparative data demonstrate that our algorithm outperforms other algorithms in 50% of benchmark instances. Additionally, according to the relative percentage deviation (RPD) from the state-of-the-art results, the BCAISA also exhibits superior performance. This highlights the effectiveness of our algorithm for solving the classical FJSP. To enhance the practical application, the scope of the ISA will be broadened in future work to more complex problems in real-world scenarios.},
  archive      = {J_IJCIA},
  author       = {Tianhua Jiang and Lu Liu},
  doi          = {10.1142/S1469026824500251},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450025},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {A bi-population competition adaptive interior search algorithm based on reinforcement learning for flexible job shop scheduling problem},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modified genetic algorithm for efficient high-utility
itemset mining. <em>IJCIA</em>, <em>24</em>(1), 2450024. (<a
href="https://doi.org/10.1142/S146902682450024X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In pattern mining, high-utility itemset mining (HUIM) is useful for discovering high-utility patterns. The study of HUIM using heuristic techniques reflects issues in producing better offspring. It is ineffective in terms of search space organization, population diversity, and utility calculation, which impact runtime and accuracy. It is observed that very few researchers have experimented with genetic algorithm (GA) and are still facing the same issues as mentioned before. To overcome these problems, a novel approach is proposed for HUIM using modified GA and optimized local search (HUIM-MGALS) with six potential contributions. First is linking the utility with the Bitmap dataset to reduce utility access time, leading to effective search space organization. Second, HUIM-MGALS employs a fitness scaling strategy to avoid redundancy. Third, a high-utility itemset (HUI) revision strategy is employed to explore significant HUIs. Modified population diversity maintenance strategy and iterative crossover help to preserve significant HUIs and improve search capability as fourth and fifth contributions. Sixth, the use of multiple mutations refines the wasted individuals to boost accuracy. Extensive experimentation showed that HUIM-MGALS significantly outperforms the presented algorithms, up to 8.6 times faster. It also demonstrates superior HUI discovery capabilities for both sparse and dense datasets. This is supported by the modified population diversity maintenance strategy, which is proved to be the most impactful modification for HUI discovery in HUIM-MGALS.},
  archive      = {J_IJCIA},
  author       = {Eduardus Hardika Sandy Atmaja and Kavita Sonawane},
  doi          = {10.1142/S146902682450024X},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450024},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Modified genetic algorithm for efficient high-utility itemset mining},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Student apartment access control system based on
MTCNN-FaceNet algorithm. <em>IJCIA</em>, <em>24</em>(1), 2450022. (<a
href="https://doi.org/10.1142/S1469026824500226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the security management issues of student apartments, a study is conducted on a student apartment access control system based on multitasking cascaded convolutional networks and FaceNet. Firstly, a face detection model is built based on an improved multi-task cascaded convolutional network, and then a face recognition model is built using FaceNet. The results showed that the detection accuracy of the multi-task cascaded convolutional network using the improved non-maximum suppression algorithm was 98.7%, which was higher than the traditional multi-task cascaded convolutional network and effectively improved the detection performance of the multi-task cascaded convolutional network. The face detection model based on the improved multi-task cascaded convolutional network had the shortest average detection time of 361 s, the highest average detection accuracy of 90.3%, an accuracy of 99%, a recall rate of 98.5%, and an F 1 value of 99%. While maintaining high detection efficiency, it also ensured the accuracy of detection. The average accuracy of the mask detection method based on the MobileNet V2 network was relatively high, at 98.96%. The facial recognition model based on FaceNet achieved a recognition accuracy of 99.15% for faces without masks and 92.04% for faces with masks, with the highest accuracy and recall rates of 99.3% and 99.6%. The model constructed in the study has good application effects in face detection, which helps to improve the security of the student apartment access control system.},
  archive      = {J_IJCIA},
  author       = {Jing Zhang},
  doi          = {10.1142/S1469026824500226},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450022},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Student apartment access control system based on MTCNN-FaceNet algorithm},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative adversarial network optimization algorithm based
on adaptive data augmentation. <em>IJCIA</em>, <em>24</em>(1), 2450021.
(<a href="https://doi.org/10.1142/S1469026824500214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the research of deep learning, an Unsupervised deep convolution-generated Generated Adversarial Network (UGAN) usually needs a large number of data samples to train. However, when faced with some small samples, the performance of the algorithm is often degraded due to over-fitting. Combined with specially designed data enhancement methods, a generated adversarial network optimization algorithm based on adaptive data augmentation (AdauGAN) is proposed. The adaptive data augmentation module is added before the discriminant network, and a spatial transformation is carried out simultaneously at the probability distribution level of generated data and real data. To alleviate the over-fitting phenomenon in the training process, the current enhancement intensity is adjusted adaptively after the over-fitting occurs. The proposed algorithm is verified on SVHN, CelebA and CIFAR-10 data sets. The Frechet Inception Distance (FID) values of AdauGAN achieve 22.10, 23.94, 34.87, respectively, which is close to or even higher than the training results of Deep Convolution Generated Adversarial Network (DCGAN) under all data. Extensive experiment results show that the proposed Adaugan has an excellent performance in small samples. Besides, in some cases, it can catch up with the large sample results of existing algorithms.},
  archive      = {J_IJCIA},
  author       = {Yanan Yu and Dunhuang Shi and Qi Pan},
  doi          = {10.1142/S1469026824500214},
  journal      = {International Journal of Computational Intelligence and Applications},
  number       = {1},
  pages        = {2450021},
  shortjournal = {Int. J. Comput. Intell. Appl.},
  title        = {Generative adversarial network optimization algorithm based on adaptive data augmentation},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijfcs---6">IJFCS - 6</h2>
<ul>
<li><details>
<summary>
(2025). Some special perfect c-nonlinear functions on ℤn.
<em>IJFCS</em>, <em>36</em>(1), 97–110. (<a
href="https://doi.org/10.1142/S0129054124500096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The notion of c -differential uniformity was proposed by Ellingsen et al. , which generalizes the classical differential uniformity measuring the resistance against differential cryptanalysis. Since then, the research of functions with low c -differential uniformity over finite fields attracted many researchers’ attention. However, it seems that there is no study of function with low c -differential uniformity over integer rings modulo n . In this paper, we give an extension of the c -differential uniformity concept to rings of integers module some n &gt; 0 , and we present several perfect c -nonlinear polynomial functions on the integer ring ℤ n for the different integer n .},
  archive      = {J_IJFCS},
  author       = {Yan-Ping Wang and Wei-Guo Zhang},
  doi          = {10.1142/S0129054124500096},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {97-110},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Some special perfect c-nonlinear functions on ℤn},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed independent sets in interval and segment
intersection graphs. <em>IJFCS</em>, <em>36</em>(1), 67–95. (<a
href="https://doi.org/10.1142/S0129054124500084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Maximum Independent Set problem is well-studied in graph theory and related areas. An independent set of a graph is a subset of non-adjacent vertices of the graph. A maximum independent set is an independent set of maximum size. This paper studies the Maximum Independent Set problem in some classes of geometric intersection graphs in a distributed setting. More precisely, we study the Maximum Independent Set problem on two geometric intersection graphs, interval and axis-parallel segment intersection graphs, and present deterministic distributed algorithms in a model that is similar but a little weaker than the local communication model. We compute the maximum independent set on interval graphs in O ( k ) rounds and O ( n ) messages, where k is the size of the maximum independent set and n is the number of nodes in the graph. We provide a matching lower bound of Ω ( k ) on the number of rounds, whereas Ω ( n ) is a trivial lower bound on message complexity. Thus, our algorithm is both time and message-optimal. We also study the Maximum Independent Set problem in interval count l graphs, a special case of the interval graphs where the intervals have exactly l different lengths. We propose an 1 2 -approximation algorithm that runs in O ( l ) round. For axis-parallel segment intersection graphs, we design an 1 2 -approximation algorithm that obtains a solution in O ( D ) rounds. The results in this paper extend the results of Molla et al. [J. Parallel Distrib. Comput. 2019].},
  archive      = {J_IJFCS},
  author       = {Nirmala Bhatt and Barun Gorain and Kaushik Mondal and Supantha Pandit},
  doi          = {10.1142/S0129054124500084},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {67-95},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Distributed independent sets in interval and segment intersection graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear complexity of r-ary sequences derived from euler
quotient modulo pq. <em>IJFCS</em>, <em>36</em>(1), 49–66. (<a
href="https://doi.org/10.1142/S0129054124500072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a generic construction of r -ary sequences with period p q 2 based on the Euler quotient modulo p q , where p and q are odd primes satisfying that p divides q − 1 and r is any prime less than q . The minimal polynomial and the linear complexity of the proposed sequences are determined in most cases under the assumption that r q − 1 ≢ 1 ( mod q 2 ) . The result shows that each of the sequences has large linear complexity.},
  archive      = {J_IJFCS},
  author       = {Zibi Xiao and Zepeng Li and Bo Yang and Jinmei Fan},
  doi          = {10.1142/S0129054124500072},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {49-66},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Linear complexity of r-ary sequences derived from euler quotient modulo pq},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Limit law for zagreb and wiener indices of random
exponential recursive trees. <em>IJFCS</em>, <em>36</em>(1), 35–48. (<a
href="https://doi.org/10.1142/S0129054124500060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Wiener index is the sum of distances of all pairs of nodes in a graph; and the Zagreb index is defined as the sum of squares of the degrees of nodes in a rooted tree. In this note, we calculate the first two moments of the Wiener and Zagreb indices of random exponential recursive trees (random ERTs) from two systems of recurrence relations. Then, by an application of the contraction method, we characterize the limit law for a scaled Zagreb index of ERTs. Via the martingale convergence theorem, we also show the almost sure convergence and quadratic mean convergence of an appropriately scaled Wiener index that is indicative of the distance of two randomly chosen nodes.},
  archive      = {J_IJFCS},
  author       = {Ali Q. M. Al-Saedi and Ramin Imany Nabiyyi and Mehri Javanian},
  doi          = {10.1142/S0129054124500060},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {35-48},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Limit law for zagreb and wiener indices of random exponential recursive trees},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algorithmic aspects of outer-independent double roman
domination in graphs. <em>IJFCS</em>, <em>36</em>(1), 25–34. (<a
href="https://doi.org/10.1142/S0129054124500059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G = ( V , E ) be graph. For any function h : V → { 0 , 1 , 2 , 3 } , let V i = { v ∈ V : h ( v ) = i } , 0 ≤ i ≤ 3 . The function h is called an outer-independent double Roman dominating function (OIDRDF) if the following conditions are satisfied. The outer-independent double Roman domination number of G is defined by γ o i d R ( G ) = min ∑ v ∈ V h ( v ) : h is an OIDRDF OF G . We prove that the decision problem MOIDRDP, corresponding to γ o i d R ( G ) is NP-complete for split graphs. We also show that it is linear time solvable for connected threshold graphs and bounded treewidth graphs. Finally, we show that the MOIDRDP and domination are not equivalent in computational complexity aspects.},
  archive      = {J_IJFCS},
  author       = {Amit Sharma and P. Venkata Subba Reddy and S. Arumugam and Jakkepalli Pavan Kumar},
  doi          = {10.1142/S0129054124500059},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {25-34},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Algorithmic aspects of outer-independent double roman domination in graphs},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge-disjoint hamiltonian cycles in balanced hypercubes with
applications to fault-tolerant data broadcasting. <em>IJFCS</em>,
<em>36</em>(1), 1–24. (<a
href="https://doi.org/10.1142/S0129054124500047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existence of multiple edge-disjoint Hamiltonian cycles (EDHCs for short) is a desirable property of interconnection networks. These parallel cycles can provide an advantage for algorithms that require a ring structure. Additionally, EDHCs can enhance all-to-all data broadcasting and edge fault tolerance in network communications. In this paper, we investigate the construction of EDHCs in the balanced hypercube, which is a variant of the hypercube with many attractive properties, such as strong connectivity, regularity, and symmetry. In particular, each processor in the balanced hypercube has a backup processor that shares the common neighbors, enabling fault tolerance and efficient system reconfiguration. In 2019, Lü et al. provided an algorithm to construct two EDHCs in an n -dimensional balanced hypercube B H n for n ≥ 2 . We further study this topic and give some construction schemes to construct 2 ⌊ log 2 n ⌋ EDHCs in B H n for n ≥ 2 . Since B H n is 2 n -regular, our result is optimal for n = 2 r ( r ≥ 1 ). In addition, we simulate the fault-tolerant data broadcasting through these parallel cycles as transmission channels.},
  archive      = {J_IJFCS},
  author       = {Shuai Liu and Yan Wang and Jianxi Fan and Baolei Cheng},
  doi          = {10.1142/S0129054124500047},
  journal      = {International Journal of Foundations of Computer Science},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Int. J. Found. Comput. Sci},
  title        = {Edge-disjoint hamiltonian cycles in balanced hypercubes with applications to fault-tolerant data broadcasting},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijns---6">IJNS - 6</h2>
<ul>
<li><details>
<summary>
(2025). Autism spectrum disorder detection using prominent
connectivity features from electroencephalography. <em>IJNS</em>,
<em>35</em>(3), 2550011. (<a
href="https://doi.org/10.1142/S012906572550011X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism Spectrum Disorder (ASD) is a disorder of brain growth with great variability whose clinical presentation initially shows up during early stages or youth, and ASD follows a repetitive pattern of behavior in most cases. Accurate diagnosis of ASD has been difficult in clinical practice as there is currently no valid indicator of ASD. Since ASD is regarded as a neurodevelopmental disorder, brain signals specially electroencephalography (EEG) are an effective method for detecting ASD. Therefore, this research aims at developing a method of extracting features from EEG signal for discriminating between ASD and control subjects. This study applies six prominent connectivity features, namely Cross Correlation (XCOR), Phase Locking Value (PLV), Pearson’s Correlation Coefficient (PCC), Mutual Information (MI), Normalized Mutual Information (NMI) and Transfer Entropy (TE), for feature extraction. The Connectivity Feature Maps (CFMs) are constructed and used for classification through Convolutional Neural Network (CNN). As CFMs contain spatial information, they are able to distinguish ASD and control subjects better than other features. Rigorous experimentation has been performed on the EEG datasets collected from Italy and Saudi Arabia according to different criteria. MI feature shows the best result for categorizing ASD and control participants with increased sample size and segmentation.},
  archive      = {J_IJNS},
  author       = {Zahrul Jannat Peya and Mahfuza Akter Maria and Sk Imran Hossain and M. A. H. Akhand and Nazmul Siddique},
  doi          = {10.1142/S012906572550011X},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550011},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Autism spectrum disorder detection using prominent connectivity features from electroencephalography},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label zero-shot learning via contrastive label-based
attention. <em>IJNS</em>, <em>35</em>(3), 2550010. (<a
href="https://doi.org/10.1142/S0129065725500108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label zero-shot learning (ML-ZSL) strives to recognize all objects in an image, regardless of whether they are present in the training data. Recent methods incorporate an attention mechanism to locate labels in the image and generate class-specific semantic information. However, the attention mechanism built on visual features treats label embeddings equally in the prediction score, leading to severe semantic ambiguity. This study focuses on efficiently utilizing semantic information in the attention mechanism. We propose a contrastive label-based attention method (CLA) to associate each label with the most relevant image regions. Specifically, our label-based attention, guided by the latent label embedding, captures discriminative image details. To distinguish region-wise correlations, we implement a region-level contrastive loss. In addition, we utilize a global feature alignment module to identify labels with general information. Extensive experiments on two benchmarks, NUS-WIDE and Open Images, demonstrate that our CLA outperforms the state-of-the-art methods. Especially under the ZSL setting, our method achieves 2.0% improvements in mean Average Precision (mAP) for NUS-WIDE and 4.0% for Open Images compared with recent methods.},
  archive      = {J_IJNS},
  author       = {Shixuan Meng and Rongxin Jiang and Xiang Tian and Fan Zhou and Yaowu Chen and Junjie Liu and Chen Shen},
  doi          = {10.1142/S0129065725500108},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550010},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Multi-label zero-shot learning via contrastive label-based attention},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unraveling the differential efficiency of dorsal and ventral
pathways in visual semantic decoding. <em>IJNS</em>, <em>35</em>(3),
2550009. (<a href="https://doi.org/10.1142/S0129065725500091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual semantic decoding aims to extract perceived semantic information from the visual responses of the human brain and convert it into interpretable semantic labels. Although significant progress has been made in semantic decoding across individual visual cortices, studies on the semantic decoding of the ventral and dorsal cortical visual pathways remain limited. This study proposed a graph neural network (GNN)-based semantic decoding model on a natural scene dataset (NSD) to investigate the decoding differences between the dorsal and ventral pathways in process various parts of speech, including verbs, nouns, and adjectives. Our results indicate that the decoding accuracies for verbs and nouns with motion attributes were significantly higher for the dorsal pathway as compared to those for the ventral pathway. Comparative analyses reveal that the dorsal pathway significantly outperformed the ventral pathway in terms of decoding performance for verbs and nouns with motion attributes, with evidence showing that this superiority largely stemmed from higher-level visual cortices rather than lower-level ones. Furthermore, these two pathways appear to converge in their heightened sensitivity toward semantic content related to actions. These findings reveal unique visual neural mechanisms through which the dorsal and ventral cortical pathways segregate and converge when processing stimuli with different semantic categories.},
  archive      = {J_IJNS},
  author       = {Wei Huang and Ying Tang and Sizhuo Wang and Jingpeng Li and Kaiwen Cheng and Hongmei Yan},
  doi          = {10.1142/S0129065725500091},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550009},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Unraveling the differential efficiency of dorsal and ventral pathways in visual semantic decoding},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel state space model with dynamic graphic neural
network for EEG event detection. <em>IJNS</em>, <em>35</em>(3), 2550008.
(<a href="https://doi.org/10.1142/S012906572550008X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalography (EEG) is a widely used physiological signal to obtain information of brain activity, and its automatic detection holds significant research importance, which saves doctors’ time, improves detection efficiency and accuracy. However, current automatic detection studies face several challenges: large EEG data volumes require substantial time and space for data reading and model training; EEG’s long-term dependencies test the temporal feature extraction capabilities of models; and the dynamic changes in brain activity and the non-Euclidean spatial structure between electrodes complicate the acquisition of spatial information. The proposed method uses range-EEG (rEEG) to extract time-frequency features from EEG to reduce data volume and resource consumption. Additionally, the next-generation state-space model Mamba is utilized as a temporal feature extractor to effectively capture the temporal information in EEG data. To address the limitations of state space models (SSMs) in spatial feature extraction, Mamba is combined with Dynamic Graph Neural Networks, creating an efficient model called DG-Mamba for EEG event detection. Testing on seizure detection and sleep stage classification tasks showed that the proposed method improved training speed by 10 times and reduced memory usage to less than one-seventh of the original data while maintaining superior performance. On the TUSZ dataset, DG-Mamba achieved an AUROC of 0.931 for seizure detection and in the sleep stage classification task, the proposed model surpassed all baselines.},
  archive      = {J_IJNS},
  author       = {Xinying Li and Shengjie Yan and Yonglin Wu and Chenyun Dai and Yao Guo},
  doi          = {10.1142/S012906572550008X},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550008},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A novel state space model with dynamic graphic neural network for EEG event detection},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the versatility of spiking neural networks:
Applications across diverse scenarios. <em>IJNS</em>, <em>35</em>(3),
2550007. (<a href="https://doi.org/10.1142/S0129065725500078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few decades, Artificial Neural Networks have become more and more important, evolving into a powerful tool to implement learning algorithms. Spiking neural networks represent the third generation of Artificial Neural Networks; they have earned growing significance due to their remarkable achievements in pattern recognition, finding extensive utility across diverse domains such as e.g. diagnostic medicine. Usually, Spiking Neural Networks are slightly less accurate than other Artificial Neural Networks, but they require a reduced amount of energy to perform calculations; this amount of energy further reduces in a very significant manner if they are implemented on hardware specifically designed for them, like neuromorphic hardware. In this work, we focus on exploring the versatility of Spiking Neural Networks and their potential applications across a range of scenarios by exploiting their adaptability and dynamic processing capabilities, which make them suitable for various tasks. A first rough network is designed based on the dataset’s general attributes; the network is then refined through an extensive grid search algorithm to identify the optimal values for hyperparameters. This dual-step process ensures that the Spiking Neural Network can be tailored to diverse and potentially very different situations in a direct and intuitive manner. We test this by considering three different scenarios: epileptic seizure detection, both considering binary and multi-classification tasks, as well as wine classification. The proposed methodology turned out to be highly effective in binary class scenarios: the Spiking Neural Networks models achieved significantly lower energy consumption compared to Artificial Neural Networks while approaching nearly 100% accuracy. In the case of multi-class classification, the model achieved an accuracy of approximately 90%, thus indicating that it can still be further improved.},
  archive      = {J_IJNS},
  author       = {Matteo Cavaleri and Claudio Zandron},
  doi          = {10.1142/S0129065725500078},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550007},
  shortjournal = {Int. J. Neural Syst.},
  title        = {Exploring the versatility of spiking neural networks: Applications across diverse scenarios},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A context-dependent CNN-based framework for multiple
sclerosis segmentation in MRI. <em>IJNS</em>, <em>35</em>(3), 2550006.
(<a href="https://doi.org/10.1142/S0129065725500066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite several automated strategies for identification/segmentation of Multiple Sclerosis (MS) lesions in Magnetic Resonance Imaging (MRI) being developed, they consistently fall short when compared to the performance of human experts. This emphasizes the unique skills and expertise of human professionals in dealing with the uncertainty resulting from the vagueness and variability of MS, the lack of specificity of MRI concerning MS, and the inherent instabilities of MRI. Physicians manage this uncertainty in part by relying on their radiological, clinical, and anatomical experience. We have developed an automated framework for identifying and segmenting MS lesions in MRI scans by introducing a novel approach to replicating human diagnosis, a significant advancement in the field. This framework has the potential to revolutionize the way MS lesions are identified and segmented, being based on three main concepts: (1) Modeling the uncertainty; (2) Use of separately trained Convolutional Neural Networks (CNNs) optimized for detecting lesions, also considering their context in the brain, and to ensure spatial continuity; (3) Implementing an ensemble classifier to combine information from these CNNs. The proposed framework has been trained, validated, and tested on a single MRI modality, the FLuid-Attenuated Inversion Recovery (FLAIR) of the MSSEG benchmark public data set containing annotated data from seven expert radiologists and one ground truth. The comparison with the ground truth and each of the seven human raters demonstrates that it operates similarly to human raters. At the same time, the proposed model demonstrates more stability, effectiveness and robustness to biases than any other state-of-the-art model though using just the FLAIR modality.},
  archive      = {J_IJNS},
  author       = {Giuseppe Placidi and Luigi Cinque and Gian Luca Foresti and Francesca Galassi and Filippo Mignosi and Michele Nappi and Matteo Polsinelli},
  doi          = {10.1142/S0129065725500066},
  journal      = {International Journal of Neural Systems},
  number       = {3},
  pages        = {2550006},
  shortjournal = {Int. J. Neural Syst.},
  title        = {A context-dependent CNN-based framework for multiple sclerosis segmentation in MRI},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijprai---11">IJPRAI - 11</h2>
<ul>
<li><details>
<summary>
(2025). Multi-target detection method of intelligent driving traffic
scene based on faster r-CNN++. <em>IJPRAI</em>, <em>39</em>(1), 2459019.
(<a href="https://doi.org/10.1142/S0218001424590195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current multi-objective detection methods are plagued by several issues, including insufficient detection efficiency, slow speeds, and difficulties in deciphering driving rules. To address these challenges, we introduce a traffic scene classification method that utilizes Improved Faster Regions with Convolutional Neural Network features (Faster R-CNN++). Initially, the shared convolutional layer and the Recurrent Criss-Cross Attention (RCCA) layer are employed to extract features from the input image. Subsequently, the derived feature map is fed into the Region Proposal Network (RPN) to generate detection boxes, and the Region of Interest Align (RoI Align) layer selects features corresponding to each Region of Interest (RoI) on the feature map, guided by the RPN’s output. Ultimately, we adopt an alternating training approach. Simulation experiments confirm the effectiveness of our method in multi-scene object detection. Our method has demonstrated significant improvements over existing algorithms and has delivered outstanding performance on the BDD-100 K, ApolloScape, and NuScenes datasets. The results indicate that our deep learning-based traffic scene classification method can accurately discern the behavioral characteristics of various traffic participants.},
  archive      = {J_IJPRAI},
  author       = {Qiangqiang Xu and Junhua Guo},
  doi          = {10.1142/S0218001424590195},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2459019},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Multi-target detection method of intelligent driving traffic scene based on faster R-CNN++},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance improvement in MIMO-OFDM VLC systems through
combined adaptive modulation and coding with symbol decomposition.
<em>IJPRAI</em>, <em>39</em>(1), 2458007. (<a
href="https://doi.org/10.1142/S0218001424580072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the visible light communication (VLC) system, adaptive symbol decomposition technology is one of the methods to reduce peak-to-average power ratio (PAPR) and suppress LED nonlinear distortion. However, at high symbol variances, there still exists a high PAPR, leading to a higher number of decomposed symbols, which in turn reduces the information rate and increases the bit error rate (BER) performance. Therefore, a combined approach of adaptive modulation, adaptive symbol decomposition serial transmission (ASDST), and space–time block code and orthogonal cyclic matrix transform (STBC-OCT) coding is proposed. The characteristics of PAPR, symbol decomposition and BER under different approaches through Monte Carlo simulation were analyzed. The simulation results show that when using 4-Quadrate Amplitude Modulation (4QAM) modulation and CCDF= 2 × 1 0 − 4 , the STBC-OCT-ASDST scheme gains a 5 dB improvement compared to ASDST alone. At a BER of 3 × 1 0 − 2 , STBC-OCT-ASDST achieves a 10 dBm gain in symbol variance compared to ASDST. Moreover, when the symbol variance of STBC-OCT-ASDST is less than 34 dBm, the BER remains below the 7% threshold of forward error correction (FEC) error rate.},
  archive      = {J_IJPRAI},
  author       = {Na Zhang and JianQiang He and Jiao Liu and YuanYuan Wang},
  doi          = {10.1142/S0218001424580072},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2458007},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Performance improvement in MIMO-OFDM VLC systems through combined adaptive modulation and coding with symbol decomposition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing brain tumor diagnosis: A comprehensive model
integrating VGG19 and LSTM for accurate MRI classification.
<em>IJPRAI</em>, <em>39</em>(1), 2457015. (<a
href="https://doi.org/10.1142/S0218001424570155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnosing brain tumors is particularly difficult because they can grow in unpredictable ways and look very different on MRI scans. The current methods used to automatically identify these tumors often struggle because of the wide variety of tumor types and the complex structure of the brain. As a result, these methods don’t always classify tumors accurately, which can affect patient treatment and outcomes. The main problems with these methods are that they find it hard to distinguish between different types of tumors accurately and to deal with the various ways tumors can appear on MRI scans. To improve this situation, our study integrates the robust image classification capabilities of VGG19 with the sequential data processing strengths of LSTM. This synergistic approach enhances our model’s ability to accurately classify various types of brain tumors from MRI scans, addressing the inherent challenges associated with tumor heterogeneity in medical imaging. VGG19, a deep convolutional neural network, is employed to extract detailed features from MRI scans, facilitating precise tumor characterization based on visual patterns and LSTM complements VGG19 by capturing temporal dependencies in the sequential data of MRI scans, enabling the model to discern subtle variations in tumor appearances over time. By leveraging the combined power of VGG19 and LSTM architectures, our study achieves significant advancements in the accurate classification of brain tumors from MRI images. This approach not only enhances diagnostic precision but also lays the groundwork for future improvements in neuro-oncological imaging diagnostics. Our study includes 1000 patients evaluated with MRI for brain tumors. We achieved an overall accuracy of 98.32% demonstrating the efficacy of our VGG19-LSTM model in accurate tumor classification. By using both, our model aims to get better at understanding MRI scans and, as a result, be more accurate at identifying brain tumors. This combination is a new step forward in making brain tumor diagnosis more precise through a detailed and cooperative approach using neural networks.},
  archive      = {J_IJPRAI},
  author       = {Chandrasekar Venkatachalam and M. Umamaheswari and Priyanka Shah and Arastu Thakur},
  doi          = {10.1142/S0218001424570155},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2457015},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Revolutionizing brain tumor diagnosis: A comprehensive model integrating VGG19 and LSTM for accurate MRI classification},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-frequency based EEG features for classification of
human emotions. <em>IJPRAI</em>, <em>39</em>(1), 2457014. (<a
href="https://doi.org/10.1142/S0218001424570143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human emotion classification without bias and unfairness is challenging because most existing image-based methods are directly or indirectly affected by subjectivity. Therefore, we propose an EEG (Electroencephalogram) based model for an accurate emotion classification without the effect of subjectivity. The captured EEG signals are converted into Delta, Theta, Alpha, Beta, and Gama frequency bands. As emotions change, the frequency bands change and provide unique patterns for each emotion irrespective of different persons. With this observation, the statical features, namely, mean, standard deviation, variance, and kurtosis, and frequency-based features, namely, Power Spectral Density (PSD) and Petrosian Fractal Dimension (PFD) are extracted. To integrate the strength of spatial and frequency-based features, the features are supplied to quadratic discriminative analysis for the final classification. The experiments on the benchmark datasets, DEAP and SEED-IV, achieve 99.40% and 91.97% accuracy, respectively. A comparison with state-of-the-art methods shows that the method performs very well on some datasets.},
  archive      = {J_IJPRAI},
  author       = {Shivanand S. Gornale and Shivakumara Palaiahnakote and Amruta Unki and Sunil Vadera},
  doi          = {10.1142/S0218001424570143},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2457014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Spatial-frequency based EEG features for classification of human emotions},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization-enabled shepard convolutional quantum neural
network for brain tumor detection using MRI image. <em>IJPRAI</em>,
<em>39</em>(1), 2457013. (<a
href="https://doi.org/10.1142/S0218001424570131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumors develop when abnormal cells grow within or near the brain. Determining the extent of the tumor is crucial for effective treatment. Magnetic Resonance Imaging (MRI) has emerged as a non-ionizing radiation tool for diagnosing brain tumors. Segmenting brain tumors manually is a tedious process so the performance depends on the experience of the operator. To overcome the above-mentioned problem, in this research project, brain tumor detection is classified by the proposed Shepard Convolutional Quantum Neural Network (ShCQNN) using MRI images. Initially, pre-processing of the input image is carried out with a Mean filter and the process of segmentation is executed by LinkNet. Here, the proposed Chicken Swarm Stock Exchange Trading Optimization (CSSETO) is used to train LinkNet. This CSSETO is formed from Stock Exchange Trading Optimization (SETO) and Chicken Swarm Optimization (CSO). Further, image augmentation includes rotation, random erasing, brightness or contrast adjustment, and shearing. Moreover, the extraction of features is done next to image augmentation, where some important features such as Local Ternary Pattern (LTP), Convolutional Neural Network (CNN), and Local Optimal Oriented Pattern (LOOP) are obtained. In the last stage, a brain tumor is detected using ShCQNN which is the amalgamation of Shepard Convolutional Neural Network (ShCNN) along with Quantum Neural Network (QNN). The two benchmark datasets, namely Multimodal Brain Tumor Segmentation Challenge 2018 (BraTS2018) database and the Figshare dataset are used to assess the performance of the proposed model using performance measures, such as specificity, accuracy, and sensitivity. Also, the performance of the proposed method has been compared with existing models, such as VGG Stacked Classifier Network (VGG-SCNet), Whale Harris Hawks Optimization (WHHO), CNN model, and EfficientNet-B0 and the results revealed that the proposed method provided superior performance than other existing methods. The proposed method obtains the accuracy of 0.925, sensitivity of 0.915, and specificity of 0.915. Regarding the accuracy, the performance improvement of the devised ShCQNN technique is 19.14%, 18.60%, 10.81%, and 2.70% higher than the existing methods VGG-SCNet, WHHO, CNN model, and EfficientNet-B0.},
  archive      = {J_IJPRAI},
  author       = {Swaminathan Balasubramanian and Veerraju Gampala and Alok Misra and Telu Venkata Madhusudhana Rao},
  doi          = {10.1142/S0218001424570131},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2457013},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Optimization-enabled shepard convolutional quantum neural network for brain tumor detection using MRI image},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight and efficient wheat spike detection for small
targets. <em>IJPRAI</em>, <em>39</em>(1), 2455014. (<a
href="https://doi.org/10.1142/S0218001424550140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wheat spike detection is a crucial component of wheat yield prediction. In this study, n lightweight and efficient wheat spike detection model is proposed. The model employs a novel Wheat Spike Net Block (WSNB) within a lightweight network architecture, integrating Depth-Wise Convolution (DW-Conv) and Efficient Window Multi-Head Self-Attention (EW-MHSA) to rapidly process images and accurately identify wheat spikes, even under compact small target conditions. The model is equipped with four detection heads to effectively handle targets of varying scales and incorporates the innovative EMF-IOU loss function for refined bounding box estimation. Tested on a self-constructed Shangluo winter wheat dataset, the model achieves a detection speed of 96.1 FPS on NVIDIA Tesla V100 and mAP@0.5 of 95.3%, surpassing YOLOv5, EfficientV2, YOlOX,transformer, and MobileVIt3 in terms of accuracy and efficiency. The model’s performance across diverse hardware platforms highlights its potential for practical implementation in real-time wheat yield estimation and precision agriculture.},
  archive      = {J_IJPRAI},
  author       = {Bo Wang and Yawen Li and Jun Zhang and Liqiong Huang},
  doi          = {10.1142/S0218001424550140},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2455014},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight and efficient wheat spike detection for small targets},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel infogain and multi-axial wavelet-based transformer
for personality trait question answering. <em>IJPRAI</em>,
<em>39</em>(1), 2451023. (<a
href="https://doi.org/10.1142/S0218001424510236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual Question Answering (VQA) is one of the attractive topics in the field of multimedia, affective, and empathic computing to garner user interest. Unlike existing models which aim at addressing challenges of VQA for the scene images, this work aims at developing a new model for Personality Trait Question Answering (PQA). It uses Twitter account information, which includes shared images, profile pictures, banners, text in the images, and descriptions of the images. Motivated by the accomplishments of the transformer, for encoding visual features of the images, a new InfoGain Multi-Axial Wavelet Vision Transformer (IgMaWaViT) is explored here. For encoding textual features in the images and descriptions, a new Information Gain BERT (InfoBert) method is introduced, which can handle the variable length encoding of text by choosing the optimal discriminator. Furthermore, the model fuses encodings of images and text according to the questions on different personality traits for question answering. The model is called InfoGain Multi-Axial Wavelet Vision Transformer for Personality Traits Question Answering (IgMaWaViT-PQA). To validate the efficacy of the proposed model, a dataset has been constructed, and it is used along with standard datasets for experimentation. Comprehensive experiments show that the proposed model is better than the state-of-the-art models. The code is available at the link: https://github.com/biswaskunal29/InfoGain_MultiAxial_PQA .},
  archive      = {J_IJPRAI},
  author       = {Kunal Biswas and Shivakumara Palaiahnakote and Saumik Bhattacharya and Umapada Pal and Ram Sarkar},
  doi          = {10.1142/S0218001424510236},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2451023},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A novel infogain and multi-axial wavelet-based transformer for personality trait question answering},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of specialized deep-learning models for crop
freshness assessment to mitigate post-harvest loss. <em>IJPRAI</em>,
<em>39</em>(1), 2451022. (<a
href="https://doi.org/10.1142/S0218001424510224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for evaluating crop ripeness are critiqued for their inefficiency and potential harm to produce. The use of image-processing and deep-learning techniques can solve these issues as a trend in non-destructive methods. However, an overfitting problem arises when optimization and generalization are used to estimate the parameters of the next epoch. In this paper, we develop specialized models with a high volume of training images for a single type of crop to achieve the goal of 100% accuracy for both test and validation datasets. This development contributes insights into leveraging deep learning for crop assessment, emphasizing its potential application in diverse agricultural scenarios. Experimental results show that the proposed models are superior to several existing available methods.},
  archive      = {J_IJPRAI},
  author       = {Wellington Cunha and Arashdeep Kaur and Frank Y. Shih},
  doi          = {10.1142/S0218001424510224},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2451022},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Development of specialized deep-learning models for crop freshness assessment to mitigate post-harvest loss},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). XAttentionHAR ensemble: Leveraging cross-modal attention for
enhanced activity recognition. <em>IJPRAI</em>, <em>39</em>(1), 2450026.
(<a href="https://doi.org/10.1142/S0218001424500265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition (HAR) is pivotal in ubiquitous computing, offering benefits to human-centric services such as health monitoring, smart homes, and eldercare systems. HAR leverages smartphones, smartwatches, and other wearable devices to collect sensory data annotated with activity labels, which are then used to train machine learning or deep learning models for automatic activity recognition. Effective HAR systems must integrate information from multiple modalities to accurately assist users. This paper introduces the XAttentionHAR model, an innovative cross-modality attention-based ensemble model for HAR. Our approach utilizes a self-attention module to extract features within each modality and an inter-domain cross-attention module to capture and integrate long-term dependencies across domains. The cross-modality attention mechanism enhances the fusion of diverse modalities, enriching the semantic information. We conducted extensive experiments on the WISDM public dataset, which includes accelerometer and gyroscope data from smartwatches and smartphones. Our results demonstrate that XAttentionHAR outperforms other state-of-the-art methods in activity recognition, achieving 98.48% accuracy for smartphone-based HAR and 98.73% accuracy for smartwatch-based HAR, paving the way for improved human-centric services.},
  archive      = {J_IJPRAI},
  author       = {Sarita Sahni and Sweta Jain and Sri Khetwat Saritha},
  doi          = {10.1142/S0218001424500265},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2450026},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {XAttentionHAR ensemble: Leveraging cross-modal attention for enhanced activity recognition},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A newly adopted YOLOv9 model for detecting mould regions
inside of buildings. <em>IJPRAI</em>, <em>39</em>(1), 2450025. (<a
href="https://doi.org/10.1142/S0218001424500253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Molds on wall and ceiling surfaces in damp indoor environments especially in houses with poor insulation and ventilation are common in the UK. Since it releases toxic chemicals as it grows, it is a serious health hazard for occupants who live in such houses. For example, eye irritation, sneezing, nose bleeds, respiratory infections, and skin irritations. Furthermore, there are chances of developing serious medical conditions like lung infections and respiratory diseases which may even lead to death. The main challenge here is that due to their irregular patterns, camouflaged with the background, it is not so easy to detect with our naked eyes in the early stage and often confused as stains. Therefore, inspired by the accomplishments of the Yolo architecture for object detection, the Yolov9 model is explored for mold detection by considering mold region as an object in this work. The overall result shows a promising 76% average classification rate. Since the mold does not have a shape, specific pattern, or color, adapting the Yolov9 for accurate mold detection is challenging. To the best of our knowledge, this is the first of its kind compared to existing methods. Since it is the first work, we constructed a dataset to perform experiments and evaluate the proposed method. To demonstrate the proposed method’s effectiveness, the results were also compared with the results of the Yolov8 and Yolov10 models.},
  archive      = {J_IJPRAI},
  author       = {Taha Mansouri and Md. Shadab Mashuk and Shivakumara Palaiahnakote and Aaron Chacko and Lawrence Sykes and Ali Alameer},
  doi          = {10.1142/S0218001424500253},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2450025},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {A newly adopted YOLOv9 model for detecting mould regions inside of buildings},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lightweight safety activity recognition algorithm for
railway field personnel based on portable cards. <em>IJPRAI</em>,
<em>39</em>(1), 2450024. (<a
href="https://doi.org/10.1142/S0218001424500241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, railway construction has been plagued by frequent safety accidents, with workers’ safety during the construction process remaining a major concern. To mitigate this issue, intelligent monitoring of railway workers’ activity has been proposed as a means of improving the safety coefficient of construction. Human activity recognition (HAR) based on wearable devices holds significant application value in areas such as health monitoring, motion analysis, and intelligent assistance. Recently, convolutional neural networks (CNNs) have gained extensive adoption and demonstrated outstanding performance in HAR. However, current HAR research still faces some challenges, including problems with establishing spatial–temporal dependencies and addressing the demand for lightweight models. To address the above issues, we propose a lightweight dual-stream convolution model (LDSC) based on deformable convolution and hierarchical segmentation. The model adaptively captures significant variations in sensor readings over time from portable cards of railway personnel through a temporal stream and learns the interactive information among sensor channels over a spatial stream. LDSC consists of three lightweight convolutional modules that combine deep convolution and point convolution to reduce model parameters, thus meeting the demand for a lightweight model. Experiments and ablation studies are conducted on three available datasets (UCI-HAR, UniMiB-SHAR, and WISDM) to evaluate the proposed model. The experimental results indicate that our model outperforms existing state-of-the-art methods in terms of recognition accuracy, validating the effectiveness and feasibility of LDSC. In addition, theoretical analysis and ablation experiments demonstrate that the proposed LDSC embodies lightweight characteristics.},
  archive      = {J_IJPRAI},
  author       = {Hailu Zuo and Jiukai Deng and Zihan Liu and Guangjun Tian and Shuo Xiao},
  doi          = {10.1142/S0218001424500241},
  journal      = {International Journal of Pattern Recognition and Artificial Intelligence},
  number       = {1},
  pages        = {2450024},
  shortjournal = {Int. J. Pattern Recognit. Artif. Intell.},
  title        = {Lightweight safety activity recognition algorithm for railway field personnel based on portable cards},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijseke---6">IJSEKE - 6</h2>
<ul>
<li><details>
<summary>
(2025). Mining fine-grained code change patterns using multiple
feature analysis. <em>IJSEKE</em>, <em>35</em>(1), 111–138. (<a
href="https://doi.org/10.1142/S0218194024500505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maintaining high code quality is a crucial concern in software development. Existing studies demonstrated that developers frequently face recurrent bugs and adopt similar fix measures, known as code change patterns. As an essential static analysis technique, code pattern mining supports various tasks, including code refactoring, automated program repair, and defect prediction, thus significantly improving software development processes. A prevalent approach to identifying code patterns involves translating code changes to edit actions into a Bag-of-Words (BoW) model. However, when applied to open-source projects, this method exhibits several limitations. For instance, it overlooks function call information and disregards feature word order. This study introduces MIFA, a novel technique for mining code change patterns using multiple feature analysis. MIFA extends existing BoW methods by incorporating analysis of function calls and overall changes in the Abstract Syntax Tree (AST) structure. We selected 20 popular Python projects and evaluated MIFA in both intra-project and cross-project scenarios. The experimental results indicate that: (1) MIFA achieved higher silhouette coefficients and F1 scores compared to other state-of-the-art methods, demonstrating a superior accuracy; (2) MIFA can assist developers in detecting unique change patterns more earlier, with an efficiency improvement of over 40% compared to random sampling. Additionally, we discussed critical parameters for measuring the similarity of code changes, guiding users to apply our method effectively.},
  archive      = {J_IJSEKE},
  author       = {Di Liu and Yang Feng},
  doi          = {10.1142/S0218194024500505},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {111-138},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Mining fine-grained code change patterns using multiple feature analysis},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Code recommendation for schema evolution of mimic storage
systems. <em>IJSEKE</em>, <em>35</em>(1), 89–110. (<a
href="https://doi.org/10.1142/S0218194024500499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schema evolution of mimic storage systems is a time-consuming and error-prone task due to the redundant development of heterogeneous executors. The ORM-based proxy requires an entire class to represent the structure of a data table. There lacks domain-specific code recommendation techniques to boost storage development. To address this issue, we design a novel type of code context, i.e. schema context, that combines features of code text, syntax and structure. Regarding the requirements of class-level granularity, we focus on behavior and attribute in code syntax, and use element position and structural metrics to mine the hidden relationships. Based on schema context and an existing inference mode, we propose SchemaRec to recommend ORM-related class for the database executors once one of them has been changed. We conduct experiments with 110 open-source projects, and the results show that SchemaRec obtains more accurate results than Lucene, DeepCS, QobCS and SEA in terms of Top-1, Top-10 and MRR accuracy due to the better ability of context representation. We also find that code syntax is the most important information because it involves behavior and attribute information of ORM-related classes.},
  archive      = {J_IJSEKE},
  author       = {Xianglong Kong and Zhuo Lv and Cen Chen and Hao Chang and Nuannuan Li and Fan Zhang},
  doi          = {10.1142/S0218194024500499},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {89-110},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Code recommendation for schema evolution of mimic storage systems},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The trustworthiness metric model of interface based on
defects. <em>IJSEKE</em>, <em>35</em>(1), 59–88. (<a
href="https://doi.org/10.1142/S0218194024500487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interface is a crucial element in component-based software, enabling the linkage of distinct components to facilitate interaction. Defects within the interface can significantly impact the overall trustworthiness of the system. Therefore, it is essential to assess the interface trustworthiness based on a defect-centric approach. This paper introduces a novel model for evaluating interface trustworthiness, anchored in defect analysis. First, the defect types are formalized based on interface specifications. Then, the comprehensive weight allocation method is established to characterize the importance degree of each interface defect type by combining the G1 and CRITIC methods. Subsequently, the attributes of the interface are evaluated by defect value analysis, and the trustworthiness measurement model of the interface is proposed based on these attributes. Furthermore, to evaluate the trustworthiness of the whole system, the trustworthiness measure models under different combination structure of components are established. Finally, the model’s’ applicability is demonstrated through an illustrative example. This trustworthiness evaluation from the interface view can guide interface designers to obtain high-quality interfaces and improve the trustworthiness of the entire software.},
  archive      = {J_IJSEKE},
  author       = {Yanfang Ma and Xiaotong Gao},
  doi          = {10.1142/S0218194024500487},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {59-88},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {The trustworthiness metric model of interface based on defects},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing translation validation of compiler transformations
with large language models. <em>IJSEKE</em>, <em>35</em>(1), 45–57. (<a
href="https://doi.org/10.1142/S0218194024500475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework that integrates Large Language Models (LLMs) into translation validation, targeting LLVM compiler transformations where formal verification tools fall short. Our framework utilizes the existing tools, like Alive2, to perform initial validation. For transformations deemed unsolvable by traditional methods, our approach leverages fine-tuned LLMs to predict soundness or unsoundness, with subsequent fuzzing applied to identify counterexamples for unsound transformations. Our approach has proven effective in complex scenarios, such as deep-learning accelerator designs, enhancing the reliability of compiler transformations.},
  archive      = {J_IJSEKE},
  author       = {Yanzhao Wang and Fei Xie},
  doi          = {10.1142/S0218194024500475},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {45-57},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Enhancing translation validation of compiler transformations with large language models},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An empirical study of fault localization on novice programs
and addressing the tie problem. <em>IJSEKE</em>, <em>35</em>(1), 19–44.
(<a href="https://doi.org/10.1142/S0218194024500426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Programming education is becoming increasingly popular in universities. However, due to a lack of debugging experience, novices often encounter numerous difficulties in the programming process. Automatic fault localization techniques have emerged as a promising solution to address this issue. Among these techniques, Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) have been widely used in industrial programs. However, there is a significant difference between industrial and novice programs and the performance of these methods on novice programs has not been extensively studied. To fill this gap, we conducted an empirical study to evaluate the fault localization performance and execution overhead of SBFL and MBFL in a typical novice programming environment. Our study specifically examined how different program characteristics, including code coverage and mutation score, affect the accuracy of these localization methods. Additionally, during the study, we identified the tie problem in both methods and further investigated its impact on fault localization techniques in novice programs. To remove the impact of the tie problem, we proposed using PageRank scores as weights for the suspiciousness, sorting, and locating faults based on the weighted suspiciousness. The PageRank algorithm is based on statement coverage information and constructs a directed graph. From the directed graph, a transition matrix generates the weight scores (PageRank scores) for each statement. Our research demonstrates that both SBFL and MBFL are effective for fault localization in novice programs, with MBFL showing significantly better performance in our tests. In TOP- N ( N = 1 , 3 , 5 ) , MBFL accurately locates 67, 96 and 114 faults, respectively, indicating superior performance. Additionally, calculating weighted suspiciousness significantly alleviates the tie problem.},
  archive      = {J_IJSEKE},
  author       = {Yuxing Liu and Jiaxin Zhong and Qihua Hei and Xuchuan Zhou and Jingzhong Xiao},
  doi          = {10.1142/S0218194024500426},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {19-44},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {An empirical study of fault localization on novice programs and addressing the tie problem},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using peer assessment leveraging large language models in
software engineering education. <em>IJSEKE</em>, <em>35</em>(1), 1–18.
(<a href="https://doi.org/10.1142/S0218194024500359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the integration of generative AI and large language models into the realm of software engineering education and training, with a specific focus on the transformation of traditional peer assessment methodologies. The motivation stems from the growing demand for innovative educational techniques that can effectively engage and empower learners in mastering Software Engineering principles. The proposed approach involves presenting students with modeling exercises solved by ChatGPT, prompting them to critically evaluate and provide constructive feedback on the generated solutions. By engaging students in a dialogue with the AI model, we aim to foster a dynamic learning environment where learners can articulate their considerations and insights, thereby enhancing their comprehension of software engineering principles, critical thinking and self evaluation skills. Preliminary results from pilot implementations indicate promising outcomes, suggesting that this approach not only enhances the quality of peer feedback but also contributes to a more interactive and engaging educational experience.},
  archive      = {J_IJSEKE},
  author       = {Marco Fiore and Marina Mongiello},
  doi          = {10.1142/S0218194024500359},
  journal      = {International Journal of Software Engineering and Knowledge Engineering},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Int. J. Soft. Eng. Knowl. Eng.},
  title        = {Using peer assessment leveraging large language models in software engineering education},
  volume       = {35},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijufks---6">IJUFKS - 6</h2>
<ul>
<li><details>
<summary>
(2025). Interval methods in knowledge representation.
<em>IJUFKS</em>, <em>33</em>(1), 141–142. (<a
href="https://doi.org/10.1142/S0218488525970013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJUFKS},
  author       = {Vladik Kreinovich},
  doi          = {10.1142/S0218488525970013},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {141-142},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Interval methods in knowledge representation},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Risk index based uncertain portfolio selection with monotone
increasing multiplicative background risk. <em>IJUFKS</em>,
<em>33</em>(1), 119–140. (<a
href="https://doi.org/10.1142/S0218488525500059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investors usually invest not only in risky assets but also in risk-free assets and face not only portfolio risk but also background risk. This paper discusses an uncertain portfolio selection problem in risky assets and risk-free assets with monotone increasing multiplicative background risk (MBR), which is prevalent but less research has been done. To do so, we first propose an uncertain mean-risk index model based on uncertainty theory where the security return and MBR are regarded as uncertain variables and give the deterministic form of the model. Then for further analysis, we discuss the critical constraint and optimality condition of the model. Based on the discussion, we study the influence of uncertain MBR on the investors’ decisions. Finally, we provide the case analysis to illustrate the application of our method and the analysis results.},
  archive      = {J_IJUFKS},
  author       = {Di Ma and Xiaoxia Huang and Kwang-Il Choe},
  doi          = {10.1142/S0218488525500059},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {119-140},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Risk index based uncertain portfolio selection with monotone increasing multiplicative background risk},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ICE: Incremental subspace clustering of high-dimensional
categorical data. <em>IJUFKS</em>, <em>33</em>(1), 87–118. (<a
href="https://doi.org/10.1142/S0218488525500047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subspace clustering is an effective way to analyze high-dimensional data. The main problems of the conventional subspace clustering techniques are as follows: first, conventional clustering methods can not describe categorical attribute space in more detail; second, most subspace-clustering techniques failure to process dynamic data effectively; finally, lack of effective noise recognition leads to the decline of the efficiency of incremental subspace-clustering analysis. We address the above problems by an incremental subspace-clustering algorithm — called ICE . With attribute subspace constructed by a rough set-based weight computing method, ICE obtains clustering results through initial and incremental clustering stage. Utilizing the original cluster results generated from initial clustering stage, we adopt merging and splitting operation to dynamic adjust cluster-structure in incremental clustering stage. Before achieving the final results, a polymerization-based noise recognition technique is employed to automatically identify noise from sparse clusters without human threshold intervention. We implement ICE on synthetic and real-world datasets. The experimental results reveal that incremental subspace-clustering method can achieves satisfactory performance on extensibility, accuracy and robustness.},
  archive      = {J_IJUFKS},
  author       = {Ning Pang and Chaowei Zhang and Jifu Zhang and Xiao Qin},
  doi          = {10.1142/S0218488525500047},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {87-118},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {ICE: Incremental subspace clustering of high-dimensional categorical data},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized feature selection approach with elicit conditional
generative adversarial network based class balancing approach for
multimodal sentiment analysis in car reviews. <em>IJUFKS</em>,
<em>33</em>(1), 55–86. (<a
href="https://doi.org/10.1142/S0218488525500035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Sentiment Analysis (MSA) is a growing area of emotional computing that involves analyzing data from three different modalities. Gathering data from Multimodal Sentiment analysis in Car Reviews (MuSe-CaR) is challenging due to data imbalance across modalities. To address this, an effective data augmentation approach is proposed by combining dynamic synthetic minority oversampling with a multimodal elicitation conditional generative adversarial network for emotion recognition using audio, text, and visual data. The balanced data is then fed into a granular elastic-net regression with a hybrid feature selection method based on dandelion fick’s law optimization to analyze sentiments. The selected features are input into a multilabel wavelet convolutional neural network to classify emotion states accurately. The proposed approach, implemented in python, outperforms existing methods in terms of trustworthiness (0.695), arousal (0.723), and valence (0.6245) on the car review dataset. Additionally, the feature selection method achieves high accuracy (99.65%), recall (99.45%), and precision (99.66%). This demonstrates the effectiveness of the proposed MSA approach, even with three modalities of data.},
  archive      = {J_IJUFKS},
  author       = {Sri Raman Kothuri and N. R. Rajalakshmi},
  doi          = {10.1142/S0218488525500035},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {55-86},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Optimized feature selection approach with elicit conditional generative adversarial network based class balancing approach for multimodal sentiment analysis in car reviews},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An intelligent optimized compression framework for columnar
database. <em>IJUFKS</em>, <em>33</em>(1), 29–53. (<a
href="https://doi.org/10.1142/S0218488525500023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instead of storing data in rows, a columnar database is a type of Database Management System (DBMS). To speed up the processing and reply to a question, a columnar database’s job is to efficiently write and read data to and from hard disc storage. One of the most crucial methods in the creation of column-oriented database systems is compression. For columns with Zero-length string types, all heavier and light-in-weight compression techniques have limitations. Processing of transactions online, these databases are substantially more effective for online analytical processing than for online transactional processing. This indicates that although they are made to examine transactions, they are not very effective at updating them. To overcome these issues a Zero Length Recurrent based Fruit Fly Optimization (ZLRFF) model is used. Additionally, a reduction technique is known as ZLRFF was designed to achieve a high compression ratio and allow straight lookups on compressed material without decompression first. ZLRFF’s main goal is to divide a Zero-length string written column vertically into smaller columns that can each be compressed using a separate lightweight compression technique. To search directly on compressed data, we also provide a search technique we call FF-search. Extensive testing demonstrates that ZLRFF supports direct searching on compressed data in addition to achieving a decent compression ratio, which enhances query performance.},
  archive      = {J_IJUFKS},
  author       = {B. A. Jadhawar and Narendra Sharma},
  doi          = {10.1142/S0218488525500023},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {29-53},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {An intelligent optimized compression framework for columnar database},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and development of schema for schemaless databases.
<em>IJUFKS</em>, <em>33</em>(1), 1–28. (<a
href="https://doi.org/10.1142/S0218488525500011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A schema database functions as a repository for interconnected data points, facilitating comprehension of data structures by organizing information into tables with rows and columns. These databases utilize established connections to arrange data, with attribute values linking related tuples. This integrated approach to data management and distributed processing enables schema databases to maintain models even when the working set size surpasses available RAM. However, challenges such as data quality, storage, scarcity of data science professionals, data validation, and sourcing from diverse origins persist. Notably, while schema databases excel at reviewing transactions, they often fall short in updating them effectively. To address these issues, a Chimp-based radial basis neural model (CbRBNM) is employed. Initially, the Schemaless database was considered and integrated into the Python system. Subsequently, compression functions were applied to both schema and schema-less databases to optimize relational data size by eliminating redundant files. Performance validation involved calculating compression parameters, with the proposed method achieving memory usage of 383.37 Mb, a computation time of 0.455 s, a training time of 167.5 ms, and a compression rate of 5.60%. Extensive testing demonstrates that CbRBNM yields a favorable compression ratio and enables direct searching on compressed data, thereby enhancing query performance.},
  archive      = {J_IJUFKS},
  author       = {Ashwini Mandale and Neeraj Sharma},
  doi          = {10.1142/S0218488525500011},
  journal      = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Int. J. Uncertain. Fuzziness Knowl.-Based. Syst.},
  title        = {Design and development of schema for schemaless databases},
  volume       = {33},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
