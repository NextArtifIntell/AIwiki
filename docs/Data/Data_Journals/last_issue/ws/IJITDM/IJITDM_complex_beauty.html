<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJITDM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijitdm---11">IJITDM - 11</h2>
<ul>
<li><details>
<summary>
(2025). Reject inference using discriminative dual stack sparse
auto-encoders for consumer credit risk evaluation. <em>IJITDM</em>,
<em>24</em>(1), 327–353. (<a
href="https://doi.org/10.1142/S0219622025500038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit risk evaluation has gained substantial attention within financial institutions, serving as a pivotal tool to predict borrower repayment behavior and provide precise credit risk estimations. Traditional credit risk approaches discarded rejected applicants and were built only on accepted applicants, which posed sample selection bias issue. Previous reject inference methods solved the bias issue by incorporating information of rejected applicants. However, these methods assumed that the accepted and rejected samples had identical dimensions. In practical financial scenarios, financial institutions often encounter situations where the dimensions of accepted samples were larger than those of the rejected samples. Therefore, the additional features in accepted samples might not be fully utilized in the previous reject inference. In this study, we proposed a discriminative dual stack sparse auto-encoder (DD-SSAE) reject inference method that was suitable for the real scenarios. The proposed DD-SSAE has the following characteristics: (1) rejected samples were filtered based on our selection mechanism; (2) a stack sparse auto-encoder (SSAE), within a self-taught learning framework, was carried out to incorporate information of the selected rejected samples into the common features of accepted samples; and (3) a data fusion module, consisting of another SSAE network and a data fusion layer, was introduced to combine extra features with common features for accepted samples. The proposed method was verified on a Chinese consumer dataset and the findings illustrated its superiority over four conventional credit scoring models and five previous reject inference models.},
  archive      = {J_IJITDM},
  author       = {Gang Kou and Siqi Weng and Feng Shen and Fahd Saleh S. Alotaibi},
  doi          = {10.1142/S0219622025500038},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {327-353},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Reject inference using discriminative dual stack sparse auto-encoders for consumer credit risk evaluation},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple risks and uncertain portfolio management.
<em>IJITDM</em>, <em>24</em>(1), 297–325. (<a
href="https://doi.org/10.1142/S0219622023500190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies comparative static effects under uncertainty when investors face a portfolio decision problem with both an endogenous risk and a background risk. Since the security market is complex, there exists situation where security return and background asset return are given by experts’ estimates when they cannot be reflected by historical data. Focusing on such a situation, an uncertain mean-chance model with background risk for optimal portfolio selection is developed, in which the use of chance of portfolio return failing to reach the threshold can help investors easily determine their tolerance toward risk and thus facilitate a decision making. Then we analyze the solution of the programming problem under different threshold return level, i.e., how different degrees of threshold return will affect allocation between risky asset and risk-free asset. Furthermore, we discuss the effects of changes in mean and standard deviation of risky asset and background asset on investment decisions when security return and background asset return follow normal uncertainty distributions. Finally, a real portfolio selection example is given as illustration.},
  archive      = {J_IJITDM},
  author       = {Guowei Jiang and Xiaoxia Huang and Tingting Yang},
  doi          = {10.1142/S0219622023500190},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {297-325},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multiple risks and uncertain portfolio management},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Megale: A metadata-driven graph-based system for data lake
exploration. <em>IJITDM</em>, <em>24</em>(1), 259–295. (<a
href="https://doi.org/10.1142/S0219622024500135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data lakes are storage repositories that contain large amounts of data (big data) in its native format; encompassing structured, semi-structured or unstructured. Data lakes are open to a wide range of use cases, such as carrying out advanced analytics and extracting knowledge patterns. However, the sheer dumping of data into a data lake would only lead to a data swamp. To prevent such a situation, enterprises can adopt best practices, among which to manage data lake metadata. A growing body of research has focused on proposing metadata systems and models for data lakes with a special interest on model genericness. However, existing models fail to cover all aspects of a data lake, due to their static modeling approach. Besides, they do not fully cover essential features for an effective metadata management, namely governance, visibility and uniform treatment of data lake concepts. In this paper, we propose a dynamic modeling approach to meet these features, based on two main constructs: data lake concept and data lake relationship . We showcase our approach by Megale, a graph-based metadata system for NoSQL data lake exploration. We present a proof-of-concept implementation of Megale and we show its effectiveness and efficiency in exploring the data lake.},
  archive      = {J_IJITDM},
  author       = {Doulkifli Boukraa and Meriem Bouraoui and Chaima Grine and Racha Ouahab},
  doi          = {10.1142/S0219622024500135},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {259-295},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Megale: A metadata-driven graph-based system for data lake exploration},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The impact of trade credit on financing strategy in a dual
capital-constrained supply chain. <em>IJITDM</em>, <em>24</em>(1),
223–257. (<a href="https://doi.org/10.1142/S0219622022500687">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study analyzes the financing strategy of a two-echelon supply chain, consisting of a manufacturer and a retailer, both subject to capital constraints. Specifically, the bank provides loans to the manufacturer, who then grants trade credit to the retailer. Based on the three-party game analysis framework of the bank, manufacturer, and retailer, this paper constructs a supply chain financing model under the information symmetry and information asymmetry structures, respectively; measures the maximum financing ability of the manufacturer; and discusses the influence of trade credit, moral hazard, and information structure on the manufacturer’s and bank’s strategies. The results show that under the trade credit situation, it is critical for the bank to provide loan to manufacturer who does not have moral hazard. The maximum financing capacity of the manufacturer is affected by the rate of return on moral hazard and the intensity of trade credit default. The increase of trade credit default intensity and risk exposure will lead to the increase of the interest rate of bank loan, and in the case of information asymmetry, the bank will often ask for a higher interest rate to deal with the information disadvantage. The strategy for the bank to make the credit line is more complex, and the degree of information asymmetry plays a positive moderating effect on the influence of trade credit on the credit line. Our findings provide implications for participants who implement financing actions to improve their financial performance and control the moral hazard and default risk along a supply chain.},
  archive      = {J_IJITDM},
  author       = {Xiaofeng Xie and Yang Yang and Xingyang Lyu and Fengying Zhang and Xiuying Hu and Zongfang Zhou},
  doi          = {10.1142/S0219622022500687},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {223-257},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {The impact of trade credit on financing strategy in a dual capital-constrained supply chain},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dwarf mongoose chimp optimization enabled RMDL for sentiment
categorization using cell phone data. <em>IJITDM</em>, <em>24</em>(1),
197–222. (<a href="https://doi.org/10.1142/S0219622025500026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is the process of looking through digital text to determine if the emotional tone of a text is positive, negative, or neutral. It helps companies improve their product, but a serious problem arises in classifying the polarity of certain texts with information, sentences or features to forecast their opinion. Therefore, sentiment classification should be done using new technology that classifies reviews as positive or negative so that users can make effective decisions. This research paper develops an effective model to classify sentiment using cell phone data. Initially, the Amazon phone document is passed to the BERT tokenization stage to split the acquired reviews. Then, the Aspect Term Extraction (ATE) is applied and the Term Frequency-Inverse Document Frequency (TF-IDF) is extracted as the first output. Afterward, Wordnet ontology features are extricated as the second output. Moreover, features like statistical, sarcasm linguistic, and N -gram features are extracted from BERT tokenization and considered as the third output. Finally, the sentiment is classified by subjecting the obtained three outputs to Random Multimodal Deep Learning (RMDL), which is tuned by Dwarf Mongoose Chimp Optimization (DMCO). DMCO is created by the combination of the Dwarf Mongoose Optimization (DMO) and the Chimp Optimization Algorithm (ChOA). The developed DMCO-RMDL approach attained high accuracy, True Positive Rate (TPR), True Negative Rate (TNR), precision, recall, and F 1-score values of 93%, 92.8%, 92.2%, 91.5%, 94.1%, and 94.8%, respectively.},
  archive      = {J_IJITDM},
  author       = {Minu P. Abraham and K. R. Udaya Kumar Reddy},
  doi          = {10.1142/S0219622025500026},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {197-222},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Dwarf mongoose chimp optimization enabled RMDL for sentiment categorization using cell phone data},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The best evaluation sequence method and application based on
quantum cognitive theory. <em>IJITDM</em>, <em>24</em>(1), 169–196. (<a
href="https://doi.org/10.1142/S0219622025500014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the credit risk evaluation process, considering that the decision maker’s irrational behavior may cause the interference effect between evaluation information, and further decrease the reliability of evaluation results. To solve this problem, the best evaluation sequence method and its application in credit risk evaluation based on quantum cognitive theory is proposed in this paper. First, the quantum cognition theory and the evaluation information given by the decision maker are used to get the interference degree between evaluation information. Second, the interference degree between evaluation information is aggregated to obtain the comprehensive interference degree of each alternative. Third, according to the idea that the greater the comprehensive interference degree of the alternative, the more backward the evaluation sequence of the alternative is, we determine the best evaluation sequence of alternatives. Finally, our proposed method is applied to obtain the best evaluation sequence of commercial bank credit risk.},
  archive      = {J_IJITDM},
  author       = {Wangwang Yu and Xinwang Liu and Yingping Zi},
  doi          = {10.1142/S0219622025500014},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {169-196},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {The best evaluation sequence method and application based on quantum cognitive theory},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision modeling approach for data acquisition systems of
the vehicle industry based on interval-valued linear diophantine fuzzy
set. <em>IJITDM</em>, <em>24</em>(1), 89–168. (<a
href="https://doi.org/10.1142/S0219622023500487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling data acquisition systems (DASs) can support the vehicle industry in the development and design of sophisticated driver assistance systems. Modeling DASs on the basis of multiple criteria is considered as a multicriteria decision-making (MCDM) problem. Although literature reviews have provided models for DASs, the issue of imprecise, unclear, and ambiguous information remains unresolved. Compared with existing MCDM methods, the robustness of the fuzzy decision by opinion score method II (FDOSM II) and fuzzy weighted with zero inconsistency II (FWZIC II) is demonstrated for modeling the DASs. However, these methods are implemented in an intuitionistic fuzzy set environment that restricts the ability of experts to provide membership and nonmembership degrees freely, simulate real-world ambiguity efficiently, utilize a narrow fuzzy number space, and deal with interval data. Thus, this study used a more efficient fuzzy environment interval-valued linear Diophantine fuzzy set (IVLDF) with FWZIC II for criterion weighting and IVLDF with FDOSM for DAS modeling to address the issues and support industrial community characteristics in the design and implementation of advanced driver assistance systems in vehicles. The proposed methodology comprises two consecutive phases. The first phase involves adapting a decision matrix that intersects DAS alternatives and criteria. The second phase (development phase) proposes a decision modeling approach based on formulation of IVLD-FWZIC II and IVLD-FDOSM II to model DASs. A total of 14 DASs were modeled on the basis of 15 DAS criteria, including seven subcriteria for “comprehensive complexity assessment” and eight subcriteria for “design and implementation,” which had a remarkable effect on the DAS design when implemented by industrial communities. Systematic ranking, sensitivity analysis, and modeling checklists were conducted to demonstrate that the modeling results were subject to systematic ranking, as indicated by the high correlations across all described scenarios of changing criterion weight values, supporting the most important research points, and proposing a value-adding process in modeling the most desirable DAS.},
  archive      = {J_IJITDM},
  author       = {M. J. Baqer and H. A. AlSattar and Sarah Qahtan and A. A. Zaidan and Mohd Azri Mohd Izhar and Iraq T. Abbas},
  doi          = {10.1142/S0219622023500487},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {89-168},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {A decision modeling approach for data acquisition systems of the vehicle industry based on interval-valued linear diophantine fuzzy set},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multidimensional analysis of investment priorities for
circular economy with quantum spherical fuzzy hybrid modeling.
<em>IJITDM</em>, <em>24</em>(1), 61–87. (<a
href="https://doi.org/10.1142/S021962202350075X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular economy aims recycling in the production process instead of destroying the products. With the help of this situation, waste can be considered in the remanufacturing process so that the rate of consumption of natural resources can be decreased. It is necessary to focus on certain investment issues to achieve a circular economy, but all investments have some risks. Hence, the economies should make priority analysis to take efficient actions. Investment priorities are identified to have circular economy. A novel fuzzy decision-making model has been created for this purpose. In the first stage, balanced scorecard criteria are evaluated with the help of multi stepwise weight assessment ratio analysis (M-SWARA). Later, the multidimensional investment priorities of circular economy are ranked. In this context, elimination and choice translating reality (ELECTRE) approach is taken into consideration. The main contribution of the paper is that a new methodology is created by the name of M-SWARA. Owing to these new improvements, cause and effect relationship among the items can be analyzed. It is identified that financial issues play the most crucial role for investments to improve circular economy. On the other side, it is also concluded that remanufacturing is the most significant investment alternative to develop circular economy. For the sustainability of the investment to improve circular economy, necessary financial analysis should be performed. With the help of this situation, these substances can be reintroduced into the production process in the form of raw materials. With the increase of remanufacturing, it will be possible to reduce waste and save scarce material resources.},
  archive      = {J_IJITDM},
  author       = {Hasan Dinçer and Serhat Yüksel and Umit Hacıoglu and Babek Erdebilli},
  doi          = {10.1142/S021962202350075X},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {61-87},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Multidimensional analysis of investment priorities for circular economy with quantum spherical fuzzy hybrid modeling},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stage integrated dynamic assessment method for urban
resilience based on multisource data. <em>IJITDM</em>, <em>24</em>(1),
29–59. (<a href="https://doi.org/10.1142/S0219622024410013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban resilience assessment (URA) is challenging because of urban system complexity and dynamic resilience variability. This paper develops a URA method with comprehensive feature consideration and integrated data use and then constructs a hierarchical URA criteria system. Subsequently, a two-stage integrated dynamic assessment method based on multisource data is presented, wherein the subjective–objective combination weights are determined, and the dimensional and overall urban resilience (UR) indexes are constructed. The applicability and superiority of the proposed method to existing methods are verified using a case study in Beijing. The results showed that UR in Beijing has improved substantially in 2016–2020; social and ecological dimensions are important for UR improvement; and synergies exist between different UR dimensions, which are crucial for resilient urban development. This study provides a systematic solution for URA that features a dynamic perspective, multisource data utilization, and subjective–objective combination weights, enhancing URA comprehensiveness and accuracy.},
  archive      = {J_IJITDM},
  author       = {Lulu Shen and Jianping Li and Xiaolei Sun and Weilan Suo},
  doi          = {10.1142/S0219622024410013},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {29-59},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Two-stage integrated dynamic assessment method for urban resilience based on multisource data},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linear step-adjusting programming in factor space.
<em>IJITDM</em>, <em>24</em>(1), 7–28. (<a
href="https://doi.org/10.1142/S0219622023410018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent behavior that appears in a decision process can be treated as a point y , the dynamic state observed and controlled by the agent, moving in a factor space impelled by the goal factor and blocked by the constraint factors. Suppose that the feasible region is cut by a group of hyperplanes, when point y reaches the region’s wall, a hyperplane will block the moving, and the agent needs to adjust the moving direction such that the target is pursued as faithfully as possible. Since the wall is not able to be represented by a differentiable function, the gradient method cannot be applied to describe the adjusting process. We, therefore, suggest a new model, named linear step-adjusting programming (LSP) in this paper. LSP is similar to a kind of relaxed linear programming (LP). The difference between LP and LSP is that the former aims to find the ultimate optimal point, while the latter just does a direct action in a short period. Where will a blocker encounter? How do you adjust the moving direction? Where further blockers may be encountered next, and how should the direction be adjusted again? … If the ultimate best is found, that’s a blessing; if not, that’s fine. We request at least an adjustment should be got at the first time. However, the former is idealism, and the latter is realism. In place of a gradient vector, the projection of goal direction g in a subspace plays a core role in LSP. If a hyperplane block y goes ahead along with the direction d , then we must adjust the new direction d ′ as the projection of g in the blocking plane. Suppose there is only one blocker at a time. In that case, it is straightforward to calculate the projection, but how to calculate the projection when more than one blocker is encountered simultaneously? It is still an open problem for LP researchers. We suggest a projection calculation using the Hat matrix in the paper. LSP will attract interest in economic restructuring, financial prediction, and reinforcement learning.},
  archive      = {J_IJITDM},
  author       = {Jing He and Hui Zheng and Rozbeh Zarei and Ho-Chung Lui and Qi-Wei Kong and Yi-Mu Ji and Xingsen Li and Hailong Yang and Baorui Du and Yong Shi and Pingjiang Wang and Andre van Zundert},
  doi          = {10.1142/S0219622023410018},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {7-28},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Linear step-adjusting programming in factor space},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editor’s introduction. <em>IJITDM</em>, <em>24</em>(1), 1–5.
(<a href="https://doi.org/10.1142/S0219622025030014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_IJITDM},
  author       = {Yong Shi},
  doi          = {10.1142/S0219622025030014},
  journal      = {International Journal of Information Technology &amp; Decision Making},
  number       = {1},
  pages        = {1-5},
  shortjournal = {Int. J. Inf. Tech. Decis.},
  title        = {Editor’s introduction},
  volume       = {24},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
