<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COMCOM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="comcom---21">COMCOM - 21</h2>
<ul>
<li><details>
<summary>
(2025). Research on intelligent ship resilient network architecture
based on SDN. <em>COMCOM</em>, <em>236</em>, 108151. (<a
href="https://doi.org/10.1016/j.comcom.2025.108151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the extensive adoption of information and communication technology (ICT) in the maritime field, intelligent ships are increasingly dependent on system integration, control, and data collection from devices. Real-time data transmission is essential for ensuring stable ship system operations. However, communication link failures frequently become key factors impacting data transmission. To this end, we propose an SDN-based intelligent ship network architecture, SDN-Intelligent Ship Network Architecture (SDISN), to simplify network management and enable centralized control of intelligent ships. On this basis, we design a link failure recovery model tailored for different maritime communication services to address the issue of sudden communication link failures. The model begins by collecting the status of the intelligent ship network and pre-defining backup flow rules for different maritime communication service flows. Considering the service flow characteristics, the optimization aims to minimize transmission delay and maximize switch TCAM utilization for life-safety communication flows and ship operational communication flows, respectively. For life-safety communication flows, we introduce a heuristic algorithm that progressively relaxes constraints. Meanwhile, we preload backup flow rules into switches. For ship operational communication flows, we apply a two-stage optimization algorithm, storing the relevant backup flow rules in the controller. Additionally, we propose a backup storage strategy for commercial communication flows based on dynamically adjusting the memory load of switches. Compared to existing approaches, the SDISN satisfies the need for real-time data transmission in intelligent ships while balancing resource consumption and fault response time in its link failure recovery mechanism. Lastly, experiments conduct on a testbed in a real network environment further validate the model&#39;s efficacy and efficiency.},
  archive      = {J_COMCOM},
  author       = {Qing Hu and Jiabing Liu and Zhengfei Wang and Haoyu Si and Sinian Jin and Ying Zhang and Jinhai Li},
  doi          = {10.1016/j.comcom.2025.108151},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108151},
  shortjournal = {Comput. Commun.},
  title        = {Research on intelligent ship resilient network architecture based on SDN},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LBMDTE: Multi-domain traffic engineering in distributed
software-defined networks. <em>COMCOM</em>, <em>236</em>, 108147. (<a
href="https://doi.org/10.1016/j.comcom.2025.108147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale Software-Defined Networks (SDN) applications rely on a distributed control architecture to manage network resources collaboratively among multiple subdomains. This requires multi-domain traffic engineering (TE) for reliable, comprehensive, and efficient traffic scheduling. However, the impact of control message traffic on link load has been ignored in previous multi-domain TE studies. Here, we explore a multi-objective load balancing scheme to address the traffic scheduling imbalance problem for the flat distributed architecture. First, we introduce four types of control message traffic and rules for intra-domain and inter-domain communication. Second, we develop a traffic optimization model to balance the controller load and minimize the maximum link utilization. Third, we propose a hierarchical routing algorithm to compute inter-domain routing, and then propose a heuristic Load Balancing Based Multi-Domain Traffic Engineering (LBMDTE) algorithm to address the optimization objective. Experiments conducted on three real networks and one synthetic network demonstrate that the control link traffic accounts for up to 11.32% of the total link traffic. Our proposed LBMDTE is able to jointly balance the controller load and the link load in comparison with other TE mechanisms.},
  archive      = {J_COMCOM},
  author       = {Kun Wang and Guanghong Lv},
  doi          = {10.1016/j.comcom.2025.108147},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108147},
  shortjournal = {Comput. Commun.},
  title        = {LBMDTE: Multi-domain traffic engineering in distributed software-defined networks},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey of network digital twin architecture,
capabilities, challenges, and requirements for edge–cloud continuum.
<em>COMCOM</em>, <em>236</em>, 108144. (<a
href="https://doi.org/10.1016/j.comcom.2025.108144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Digital Twin (NDT) collects data from physical, virtual, and software components and supports real-time network performance analysis, emulation, and intelligent physical network control. This paper surveys the current state of NDT specifications and explores NDT benefits for Network Operators (NOs) and its possible roles in future network management. It discusses the NDT key components, architecture, and integration of Machine Learning and Artificial Intelligence models in the NDT. Further, it covers virtualization technology management, suitability of Software-Defined Networking capabilities, and simulation tools to empower NDT. Two perspectives make the position of this survey different from existing studies; first, it highlights NDT limitations regarding Edge–Cloud Continuum (ECC) contextualization. ECC is a purposeful trending integration of Edge and Cloud Computing, involving multiple stakeholders like Service Providers, Customers, and Platform or Infrastructure Providers. However, current NDT specifications have not mentioned the ways to benefit stakeholders other than NOs. We also discuss notable computing and communication technologies transformations necessary to consider during NDT modeling, the existing data models, and reusable vocabularies that can be extended to achieve a detailed ECC representation for all stakeholders, essentially for Service Providers and Customers. Secondly, a data model is proposed that covers descriptive and prescriptive features and aims to provide a granular representation of ECC components to meet stakeholders’ requirements and render particular user information views. Different explored NDT perspectives, and proposed data model reduces the impact of existing NDT limitations in ECC representation.},
  archive      = {J_COMCOM},
  author       = {Syed Mohsan Raza and Roberto Minerva and Noel Crespi and Maira Alvi and Manoj Herath and Hrishikesh Dutta},
  doi          = {10.1016/j.comcom.2025.108144},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108144},
  shortjournal = {Comput. Commun.},
  title        = {A comprehensive survey of network digital twin architecture, capabilities, challenges, and requirements for Edge–Cloud continuum},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). INT-LLPP: Lightweight in-band network-wide telemetry with
low-latency and low-overhead path planning. <em>COMCOM</em>,
<em>236</em>, 108142. (<a
href="https://doi.org/10.1016/j.comcom.2025.108142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of networks, network telemetry becomes a critical part of network management. However, existing network telemetry systems still suffer from excessive control overhead, forwarding overhead, and latency. In this paper, we propose INT-LLPP, a novel in-band network-wide telemetry system with low-latency and low-overhead path planning. The network telemetry architecture of INT-LLPP is unique in that it only requires a set of probes to collect telemetry items for multiple service flows. Moreover, the proposed Probe Path Generation (PPG) algorithm optimizes the probe paths to reduce the forwarding overhead and achieve full network coverage. To balance the telemetry latency and control overhead, we propose an efficient algorithm called the Simulated Annealing Maximum Latency Setting (SAMLS) algorithm, which controls the length of the probe paths. Simulation results show that INT-LLPP can reduce network telemetry control overhead by over 50% and reduce forwarding overhead by 5% to 10%. Moreover, INT-LLPP can lower telemetry latency by 30% to 40%.},
  archive      = {J_COMCOM},
  author       = {Penghui Zhang and Hua Zhang and Yuqi Dai and Cheng Zeng and Jingyu Wang and Jianxin Liao},
  doi          = {10.1016/j.comcom.2025.108142},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108142},
  shortjournal = {Comput. Commun.},
  title        = {INT-LLPP: Lightweight in-band network-wide telemetry with low-latency and low-overhead path planning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient paths determining strategies in mobile
crowd-sensing networks with AI-based sensors forwarding data.
<em>COMCOM</em>, <em>236</em>, 108138. (<a
href="https://doi.org/10.1016/j.comcom.2025.108138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting a sufficient number of mobile users to collect and upload collected data to the server is a critical issue in the Mobile Crowd-sensing Networks (MCN). Previous studies have assumed that mobile users upload collected data over cellular networks, which could cause heavily burden to users. This work focus on how to forward collected data by pre-deployed wireless sensors which can fuse collected data and operate as edge nodes. Specifically, given the reward paid to each mobile user depends on the time he spends on data collection and uploading, this work investigates the problem how to select Points of Interest (PoIs) and edge nodes for participants who already have schedules with the objective of minimizing the total reward paid to all participants. We boil down this problem to the problem of determining path for each participant which connects participant’s initial location to PoI, then to an edge node and finally to participant’s destination. We formulate it as Paths determination with Cost Minimization problem. We can prove that this problem is an NP-Complete problem. Considering that the sensors acted as edge nodes which may be rechargeable or have limited energy, we design three heuristic algorithms: Minimum Cost Algorithm (MCA), Minimum Cost with Energy Consideration Algorithm (MCECA), and Energy Balance Algorithm (EBA) to address this problem. Finally, we conduct extensive simulations to validate the efficiency of the proposed algorithms. The results demonstrate that MCA finds paths for users with lower cost, while EBA effectively balances the energy consumption of edge nodes.},
  archive      = {J_COMCOM},
  author       = {Jiaoyan Chen and Jin Liu and Zhehao Cheng and Laurence Tianruo Yang and Xianjun Deng and Yihong Chen},
  doi          = {10.1016/j.comcom.2025.108138},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108138},
  shortjournal = {Comput. Commun.},
  title        = {Efficient paths determining strategies in mobile crowd-sensing networks with AI-based sensors forwarding data},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDSLS: An approximation SINR-based shortest link scheduling
algorithm with power control. <em>COMCOM</em>, <em>236</em>, 108137. (<a
href="https://doi.org/10.1016/j.comcom.2025.108137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine the Shortest Link Scheduling (SLS) issue in wireless networks within the context of the Signal-to-Interference-plus-Noise-Ratio ( SINR ) interference model with oblivious power control, and propose an approximation Diamond-based SLS with Power control (PDSLS) algorithm. Given that numerous nodes within wireless networks operate on battery power, minimizing the transmission power not only reduces interference but also conserves energy. We adopt a novel link classification approach, reducing nodes’ transmission power without generating “black and gray” links. We schedule links belonging to each class by dividing the link deployment plane into diamonds. The validity and efficacy of our algorithm are demonstrated through theoretical analysis and simulation outcomes. Numerical analysis shows that our approximation ratio is tighter than the best known ones in state-of-the-art algorithms. Simulation results demonstrate that the proposed algorithm effectively reduces the transmission power and the number of required time slots compared to the state-of-the-art algorithms.},
  archive      = {J_COMCOM},
  author       = {Neda Mohammadi and Bahram Sadeghi Bigham and Mehdi Kadivar},
  doi          = {10.1016/j.comcom.2025.108137},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108137},
  shortjournal = {Comput. Commun.},
  title        = {PDSLS: An approximation SINR-based shortest link scheduling algorithm with power control},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-powered resilience: A dual-approach for outage management
in dense cellular networks. <em>COMCOM</em>, <em>236</em>, 108129. (<a
href="https://doi.org/10.1016/j.comcom.2025.108129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As 5G evolves to 6G, network management faces growing challenges with increasing base station density, leading to more frequent outages. To address this, we introduce a robust, automated two-tier framework for outage management. The first tier involves an artificial intelligence-based outage detection scheme using an enhanced XGBoost model (Impv-XGBoost), which incorporates autoencoder outputs for hyperparameter tuning. The analysis shows Impv-XGBoost’s superior performance in high shadowing conditions and with sparse data, outperforming existing methods. The second tier adopts an actor–critic reinforcement learning strategy for outage compensation by adjusting the tilt of the neighboring base station and power. To prevent service declines to connected user equipment, our compensation scheme accounts for both outage-affected users and those connected to compensating base stations. We design a reward scheme that combines Jain’s fairness index and the geometric mean of the reference signal received power to ensure fairness and enhance convergence. Performance evaluations for single and multiple base station failures show coverage improvements for outage-affected users without compromising the coverage of the users in compensating base stations.},
  archive      = {J_COMCOM},
  author       = {Waseem Raza and Muhammad Umar Bin Farooq and Aneeqa Ijaz and Marvin Manalastas and Ali Imran},
  doi          = {10.1016/j.comcom.2025.108129},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108129},
  shortjournal = {Comput. Commun.},
  title        = {AI-powered resilience: A dual-approach for outage management in dense cellular networks},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SQID: A deep learning and network design synergy for
next-generation IoT resource allocation management. <em>COMCOM</em>,
<em>236</em>, 108128. (<a
href="https://doi.org/10.1016/j.comcom.2025.108128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of mobile broadband and Internet of Things (IoT) devices has pushed traditional IoT models to their operational limits, necessitating more efficient data management strategies. This research introduces the SQID framework, a solution that integrates advanced techniques, including Sierpinski triangle design (STD) for network optimization, quantum density peak clustering (QDPC) for intelligent device clustering, and improved deep deterministic policy gradient (IDDPG) for deep learning-driven traffic prediction. By utilizing STD to optimize device communication, the framework applies the QDPC algorithm to efficiently cluster devices, ensuring balanced packet distribution and minimizing latency. Additionally, IDDPG enhances network performance by enabling accurate traffic prediction and resource allocation, optimizing data transmission. Extensive simulations reveal that SQID outperforms existing methods in critical metrics such as time efficiency, latency reduction, throughput maximization, and packet loss. These results indicate that SQID has the potential to significantly improve data management in IoT networks, paving the way for next-generation IoT advancements.},
  archive      = {J_COMCOM},
  author       = {Ali. M.A. Ibrahim and Zhigang Chen and Yijie Wang and Hala A. Eljailany},
  doi          = {10.1016/j.comcom.2025.108128},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108128},
  shortjournal = {Comput. Commun.},
  title        = {SQID: A deep learning and network design synergy for next-generation IoT resource allocation management},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target wake time in IEEE 802.11 WLANs: Survey, challenges,
and opportunities. <em>COMCOM</em>, <em>236</em>, 108127. (<a
href="https://doi.org/10.1016/j.comcom.2025.108127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi has become the most widely used Wireless Local Area Network (WLAN) technology, but as the density of WLAN deployments and the number of devices per network increase, congestion has become a significant issue. Scheduling features in Wi-Fi have the potential to alleviate these issues by managing medium access more efficiently. While there have been other scheduling features in Wi-Fi in the past, none were widely adopted and were limited in functionality. Target Wake Time (TWT) introduces powerful scheduling capabilities to Wi-Fi as part of Wi-Fi 6, representing a fundamental shift in how Wi-Fi Access Points (APs) manage channel access for Stations (STAs) while improving energy efficiency. TWT is extremely versatile and is poised to play a crucial role in reducing contention and enhancing performance, especially in dense network environments. The potential benefits are particularly valuable for Internet of Things (IoT) scenarios, where low power consumption and efficient medium access are essential due to the large number of connected devices. This paper presents an in-depth survey of the research on TWT, categorizing and analyzing existing literature while identifying practical challenges often overlooked due to idealized assumptions. We introduce comprehensive models of infrastructure-mode APs and STAs to facilitate discussions of current and future work. We provide a detailed analysis of the challenges and issues that must be addressed to fully realize the performance gains promised by TWT. Furthermore, we explore the potential future applications of TWT, particularly in conjunction with upcoming features in IEEE 802.11 such as multi-link operation (MLO) and multi-AP coordination, offering insights into novel uses of TWT for enhancing Wi-Fi performance.},
  archive      = {J_COMCOM},
  author       = {Shyam Krishnan Venkateswaran and Ching-Lun Tai and Atif Ahmed and Raghupathy Sivakumar},
  doi          = {10.1016/j.comcom.2025.108127},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108127},
  shortjournal = {Comput. Commun.},
  title        = {Target wake time in IEEE 802.11 WLANs: Survey, challenges, and opportunities},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards green networking: Efficient dynamic radio resource
management in open-RAN slicing using deep reinforcement learning and
transfer learning. <em>COMCOM</em>, <em>236</em>, 108126. (<a
href="https://doi.org/10.1016/j.comcom.2025.108126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next Generation Wireless Networks (NGWNs) are characterized by agility and flexibility. It introduces new technologies such as network slicing (NS) and Open Radio Access Network (O-RAN). NS supports multiple services with different requirements whereas O-RAN supports different network suppliers and provides Mobile Network Operators (MNOs) more intelligent control. Deep Reinforcement Learning (DRL) techniques have been presented to address resource management and other problems in NGWNs in recent years. However, instability and lateness in convergence are the main obstacles against their adoption in live networks. Moreover, deep learning models consume lots of energy and emit significant amounts of carbon dioxide which badly impacts climate. This paper addresses solving the dynamic radio resource management (RRM) problem in O-RAN slicing with DRL and Transfer Learning (TL), focusing on proposing a green model that minimizes power and energy consumption, decreasing the carbon footprint. A new latency-and-reliability-based reward function is designed. Then, a variable threshold action filtration mechanism is proposed, and a policy TL approach is proposed to accelerate the performance in commercial networks. Compared with the state-of-the-art, this work significantly improved exploration stability, convergence speed, Quality of Service (QoS) satisfaction, power and energy consumption, and emitted carbon footprint.},
  archive      = {J_COMCOM},
  author       = {Heba Sherif and Eman Ahmed and Amira M. Kotb},
  doi          = {10.1016/j.comcom.2025.108126},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108126},
  shortjournal = {Comput. Commun.},
  title        = {Towards green networking: Efficient dynamic radio resource management in open-RAN slicing using deep reinforcement learning and transfer learning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IoT edge network interoperability. <em>COMCOM</em>,
<em>236</em>, 108125. (<a
href="https://doi.org/10.1016/j.comcom.2025.108125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network interoperability is crucial for achieving seamless communication across Internet of Things (IoT) environments. IoT comprises heterogeneous devices and systems supporting diverse technologies, protocols, and manufacturers. Enabling devices to communicate and exchange data effectively, regardless of underlying protocols, is key to building cohesive and integrated IoT networks. IoT has transformed multiple sectors ranging from home automation to healthcare—by harnessing a vast array of sensors and actuators that communicate through cloud, fog, and edge layers. However, the variety in device manufacturing and communication standards demands interoperable interfaces, and most current solutions depend on cloud-based centralised architectures. These architectures introduce latency and scalability challenges, particularly for resource-constrained IoT devices that often struggle to communicate with the cloud due to limited resources. This paper addresses network interoperability at the IoT edge level, focusing on resource-efficient communication by integrating Wi-Fi and Bluetooth, two commonly used protocols in IoT ecosystems. We have implemented a network edge interoperability solution that supports effective data exchange between devices operating on these distinct protocols, enhancing the overall efficiency, flexibility, and scalability of IoT systems. Our approach allows devices interoperate by addressing network latency and bandwidth limitations, incorporating an integrated controller to facilitate broader applications and enhance performance across IoT networks. Our findings illustrate how bridging protocol differences can foster more resilient and adaptable IoT solutions, advancing the deployment of IoT applications across various domains and use cases.},
  archive      = {J_COMCOM},
  author       = {Tanzima Azad and M.A. Hakim Newton and Jarrod Trevathan and Abdul Sattar},
  doi          = {10.1016/j.comcom.2025.108125},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108125},
  shortjournal = {Comput. Commun.},
  title        = {IoT edge network interoperability},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic analysis of the gasper protocol.
<em>COMCOM</em>, <em>236</em>, 108123. (<a
href="https://doi.org/10.1016/j.comcom.2025.108123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ethereum has recently switched to a Proof of Stake consensus protocol called Gasper. We analyze Gasper using PRISM+ , an extension of the probabilistic model checker PRISM with primitives for modeling blockchain data types. PRISM+ is therefore used to rapidly and automatically analyze the robustness of Gasper when tuning, up or down, several basic parameters of the protocol, such as network latencies and number of validators. We also study the effectiveness of Gasper in updating stakes and its resilience to three attacks: the balance, bouncing and time attacks.},
  archive      = {J_COMCOM},
  author       = {Cosimo Laneve and Adele Veschetti},
  doi          = {10.1016/j.comcom.2025.108123},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108123},
  shortjournal = {Comput. Commun.},
  title        = {A stochastic analysis of the gasper protocol},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy efficient LEO satellite communications: Traffic-aware
payload switch-off techniques. <em>COMCOM</em>, <em>236</em>, 108122.
(<a href="https://doi.org/10.1016/j.comcom.2025.108122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low Earth orbit (LEO) satellite constellations have a pivotal role in shaping the future of communication networks by providing extensive global coverage. However, ensuring the long-term viability of LEO constellations relies on addressing significant challenges, particularly in the domains of energy efficiency and maximizing the lifespan of satellites. This paper introduces a novel approach that considers user traffic demands to optimize power consumption. By implementing a traffic-aware strategy, redundant satellites can be intelligently switched-off, resulting in significant power savings within the LEO constellation. To accomplish this objective, we formulate the problem of joint satellite beam assignment and beam power allocation as a mixed binary integer optimization problem while carefully considering the constraints imposed by satellite-user visibility and the need to fulfill the data traffic requirements of all ground users. To tackle the formulated problem, we employ a framework called the Difference of Convex Programming and Multiplier Penalty (DCMP) based convexification approach, which ensures convergence to a local optimum. The reformulated convex problem is solved using the low-complexity iterative algorithm, Successive Convex Approximation (SCA). Additionally, we propose a heuristic algorithm based on slant distance, which offers a simplified and efficient solution to the joint problem. To corroborate the effectiveness and validity of the proposed techniques, we assess and compare their performance via simulations, considering practical constellation patterns and realistic user traffic distribution. It has been shown that approximately 43% of the satellite nodes can be switched-off for energy saving, and thus, extending the constellation lifetime and reducing the aggregated interference from multi-beam satellites.},
  archive      = {J_COMCOM},
  author       = {Vaibhav Kumar Gupta and Hayder Al-Hraishawi and Eva Lagunas and Symeon Chatzinotas},
  doi          = {10.1016/j.comcom.2025.108122},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108122},
  shortjournal = {Comput. Commun.},
  title        = {Energy efficient LEO satellite communications: Traffic-aware payload switch-off techniques},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A defense mechanism for federated learning in AIoT through
critical gradient dimension extraction. <em>COMCOM</em>, <em>236</em>,
108114. (<a href="https://doi.org/10.1016/j.comcom.2025.108114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging the distributed nature of the Internet of Things (IoT), Federated Learning (FL) facilitates knowledge transfer among heterogeneous IoT devices, enhancing the capabilities of Artificial Intelligence of Things (AIoT) while preserving data privacy. However, FL is susceptible to poisoning attacks such as label flipping, Gaussian, and backdoor attacks. Most existing defense strategies rely on robust aggregation algorithms that use the statistical properties of gradient vectors to counteract poisoning attacks, however, they often overlook the non-independent and identically distributed (non-iid) nature of client data, limiting their effectiveness in the IoT. We propose a method that combines cross-node Top-k gradient vector compression and Principal Component Analysis (PCA) dimensionality reduction to extract critical gradient dimensions. By clustering these essential dimensions and performing filtering, our approach effectively distinguishes malicious from benign clients in non-iid data scenarios. Additionally, we introduce a client trust-score assessment mechanism that continuously monitors client behavior and applies secondary filtering, further improving the identification of malicious clients. Experimental results on the CIFAR-10, MNIST, DomainNet, and Flowers102 datasets demonstrate that our method achieves higher model accuracy and robustness in non-iid data settings compared to existing defense strategies.},
  archive      = {J_COMCOM},
  author       = {Jian Xu and Bing Guo and Fei Chen and Yan Shen and Shengxin Dai and Cheng Dai and Yuchuan Hu},
  doi          = {10.1016/j.comcom.2025.108114},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108114},
  shortjournal = {Comput. Commun.},
  title        = {A defense mechanism for federated learning in AIoT through critical gradient dimension extraction},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing UAV delivery for pervasive systems through
blockchain integration and adversarial machine learning.
<em>COMCOM</em>, <em>236</em>, 108113. (<a
href="https://doi.org/10.1016/j.comcom.2025.108113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs), play a significant role in the advancement of pervasive systems by providing efficient, scalable, and innovative solutions in various sectors, such as smart cities or location-based services. However, the current UAV delivery scenario presents various challenges for recipients, including lengthy identity verification processes, privacy concerns, and risks of fraud and theft. In response to these issues, this paper proposes an innovative system that leverages Blockchain technology and Adversarial Machine Learning (AML) to tackle these problems effectively. The proposed system streamlines the verification process, enhances privacy safeguards, and reduces fraud risks. The integration of AML is crucial as it enables users to have greater control over their personal data, boosting privacy and security. AML also plays a critical role in this system by creating test scenarios that reinforce the machine learning model against adversarial threats, ensuring its precision and dependability in the face of malicious manipulations. The paper also provides details on the practical implementation and evaluation of this system in real-life adversarial situations. The evaluation results demonstrate superior performance on selected metrics, highlighting the potential of this system as an effective solution for verifying recipients in UAV delivery.},
  archive      = {J_COMCOM},
  author       = {Chengzu Dong and Shantanu Pal and Aiting Yao and Frank Jiang and Shiping Chen and Xiao Liu},
  doi          = {10.1016/j.comcom.2025.108113},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108113},
  shortjournal = {Comput. Commun.},
  title        = {Optimizing UAV delivery for pervasive systems through blockchain integration and adversarial machine learning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized coordination for resilient federated learning:
A blockchain-based approach with smart contracts and decentralized
storage. <em>COMCOM</em>, <em>236</em>, 108112. (<a
href="https://doi.org/10.1016/j.comcom.2025.108112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning (ML) in distributed environments increasingly deals with sensitive data (like healthcare or financial records) that cannot be centrally stored or processed due to privacy concerns. Federated Learning (FL) addresses this by enabling model training across decentralized devices, but faces significant challenges including system reliability, node failures, and trust issues among participants. Traditional FL approaches often rely on centralized coordinators, creating single points of failure and potential security vulnerabilities. This paper presents a novel approach to FL that leverages smart contracts, blockchain, and decentralized storage to enhance the traceability and reliability of the learning process. Our proposed system architecture is fully decentralized, eliminating single points of failure and promoting cooperation through a rewarding mechanism. Unlike previous approaches that neglect node fault tolerance, we introduce a smart contract based scheme for managing node failures and electing the aggregator node. The presence of the smart contract, executed on a decentralized permissioned blockchain, provides reliability guarantees and eliminates the need for costly distributed algorithms in terms of message exchange. An experimental study is conducted to evaluate various aspects of the FL system. We present results related to the accuracy and effectiveness of the FL system on ML models. We also examine the performance related to the distribution of the weights of the ML model based on the use of IPFS. Furthermore, we analyze the performance of the smart contract in terms of gas consumption. Lastly, we investigate the impact of failures combined with incentive policies and aggregator election algorithms on the FL system. Our findings demonstrate the viability of the proposed approach, paving the way for more robust, reliable, and efficient FL systems.},
  archive      = {J_COMCOM},
  author       = {Stefano Ferretti and Lorenzo Cassano and Gabriele Cialone and Jacopo D’Abramo and Filippo Imboccioli},
  doi          = {10.1016/j.comcom.2025.108112},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108112},
  shortjournal = {Comput. Commun.},
  title        = {Decentralized coordination for resilient federated learning: A blockchain-based approach with smart contracts and decentralized storage},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resiliency focused proactive lifecycle management for
stateful microservices in multi-cluster containerized environments.
<em>COMCOM</em>, <em>236</em>, 108111. (<a
href="https://doi.org/10.1016/j.comcom.2025.108111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Containerization has become fundamental to deploying cloud-native applications, allowing for the packaging and independent execution of applications. This approach speeds up deployment processes and facilitates the creation of various environments for feature testing. However, the ephemeral nature of containers poses a significant challenge to data persistence, especially during container restarts or migrations across different hosts. This paper proposes a proactive zero-touch management solution for stateful microservices applications, ensuring seamless application lifecycle management. Our solution integrates seamlessly with container platforms such as Kubernetes and supports multi-cluster environments, enhancing fault tolerance and data persistence in stateful applications. The solution has been thoroughly tested on different hardware configurations in the public cloud and with our on-premises servers.},
  archive      = {J_COMCOM},
  author       = {Abd Elghani Meliani and Mohamed Mekki and Adlen Ksentini},
  doi          = {10.1016/j.comcom.2025.108111},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108111},
  shortjournal = {Comput. Commun.},
  title        = {Resiliency focused proactive lifecycle management for stateful microservices in multi-cluster containerized environments},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Authenticated data visualization for hybrid blockchain-based
digital product passports. <em>COMCOM</em>, <em>236</em>, 108110. (<a
href="https://doi.org/10.1016/j.comcom.2025.108110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Digital Product Passport (DPP), introduced by the European Green Deal in 2022, is a key innovation designed to improve product sustainability and circularity by enabling secure and transparent communication among stakeholders. Despite its potential, existing blockchain-based implementations of the DPP face significant limitations, such as scalability challenges and usability issues, which hinder widespread adoption. To address these shortcomings, this paper proposes a hybrid blockchain-based implementation of the DPP that enhances data transparency, integrity, and accessibility while minimizing common drawbacks. The proposed solution utilizes a hybrid blockchain architecture, where data is collected and managed within a private blockchain network and notarized on a public blockchain. Additionally, the central problem of authenticated blockchain data visualization is addressed by proposing a new solution that not only ensures the provenance, integrity, and history consistency of DPP data, but also preserves these properties throughout data processing and visualization. Our experiments demonstrates the effectiveness of our approach, achieving low time consumption and storage overhead. To further promote transparency and collaboration, a selection of the implementation has been made available as open-source projects. We show that hybrid blockchains offer a promising path for realizing the full potential of the Digital Product Passport.},
  archive      = {J_COMCOM},
  author       = {Domenico Tortola and Claudio Felicioli and Andrea Canciani and Fabio Severino},
  doi          = {10.1016/j.comcom.2025.108110},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108110},
  shortjournal = {Comput. Commun.},
  title        = {Authenticated data visualization for hybrid blockchain-based digital product passports},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active queue management in 5G and beyond cellular networks
using machine learning. <em>COMCOM</em>, <em>236</em>, 108108. (<a
href="https://doi.org/10.1016/j.comcom.2025.108108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a state-of-the-art framework for adapting Active Queue Management (AQM) in 5G and beyond cellular networks with disaggregated Radio Access Network (RAN) deployments. While existing AQM algorithms effectively mitigate bufferbloat in monolithic RAN deployments, their potential in disaggregated ones remains largely unexplored. This gap particularly relates to AQM algorithms relying on communication between layers distributed across distinct network entities to operate. Our research explores the current literature on AQM, identifies the gaps regarding disaggregated deployments, and introduces a comprehensive framework that employs Artificial Intelligence (AI) and Machine Learning (ML) within the RAN Intelligent Controller (RIC) for adapting AQM in such deployments. We evaluate our novel solution on a previously proposed AQM algorithm which requires cross-layer communication, using OpenAirInterface5G (OAI5G) to deploy a disaggregated RAN and a connected User Equipment (UE) that experiences realistic network conditions, including noise and mobility. Finally, we assess its accuracy through the Quality of Service (QoS) achieved for our disaggregated deployment on the NITOS testbed.},
  archive      = {J_COMCOM},
  author       = {Alexandros Stoltidis and Kostas Choumas and Thanasis Korakis},
  doi          = {10.1016/j.comcom.2025.108108},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108108},
  shortjournal = {Comput. Commun.},
  title        = {Active queue management in 5G and beyond cellular networks using machine learning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-time conditional handover for B5G/6G. <em>COMCOM</em>,
<em>236</em>, 108107. (<a
href="https://doi.org/10.1016/j.comcom.2025.108107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional Handover (CHO) by the 3rd Generation Partnership Project (3GPP) enables efficient user mobility between Base Stations (BSs) by preselecting and preparing Target BSs (T-BSs). However, CHO relies on signal strength for T-BS selection, leading to resource blocking on multiple T-BSs due to signal fluctuations. Existing state-of-the-art methods use deep learning to narrow the list of T-BSs but still lack an effective method for resource reservation timing. This paper presents in-time CHO (iCHO) which exploits historical mobility data to estimate user dwell time at the current BS to reduce resource reservation duration. The proposed iCHO employs a Multivariate Multi-output Single-step Prediction (MMSP) model that leverages a multi-task learning approach to simultaneously predict the minimal list of required T-BSs together with the user dwell time. The model demonstrates remarkable performance across two mobility datasets of different scales, achieving T-BS prediction accuracies of 98% and 95%. It also ensures a 100% handover success rate with a minimum of three and four predicted T-BSs for both datasets, respectively, significantly limiting the list of T-BSs. Moreover, the MMSP model achieves a Mean Absolute Error (MAE) of 19 s and 45 s when predicting the user’s dwell time at the current BS. By utilizing these predictions, iCHO reserves resources at the minimum number of T-BSs immediately before handover. Thus, iCHO can save up to 99% of resources from blockage as compared to the CHO, enabling operators to increase revenue by serving up to eighteen more users with the saved resources.},
  archive      = {J_COMCOM},
  author       = {Sardar Jaffar Ali and Syed M. Raza and Huigyu Yang and Duc Tai Le and Rajesh Challa and Moonseong Kim and Hyunseung Choo},
  doi          = {10.1016/j.comcom.2025.108107},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108107},
  shortjournal = {Comput. Commun.},
  title        = {In-time conditional handover for B5G/6G},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the ACME protocol to automate the management of
all x.509 web certificates (extended version). <em>COMCOM</em>,
<em>236</em>, 108106. (<a
href="https://doi.org/10.1016/j.comcom.2025.108106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X.509 Public Key Infrastructures (PKIs) are widely used for managing X.509 Public Key Certificates (PKCs) to allow for secure communications and authentication on the Internet. PKCs are issued by a trusted third-party Certification Authority (CA), which is responsible for verifying the certificate requester’s information. Recent developments in web PKI show a high proliferation of Domain Validated (DV) certificates but a decline in Extended Validated (EV) certificates, indicating poor authentication of the entities behind web services. The ACME protocol facilitates the deployment of Web Certificates by automating their management. However, it is only limited to DV certificates. This paper proposes an enhancement to the ACME protocol for automating all types of Web X.509 PKCs by using W3C Verifiable Credentials (VCs) to assert a requester’s claims. We argue that any CA’s requirements for issuing a PKC can be expressed as a set of VCs returned in a Verifiable Presentation (VP) that could facilitate the issuance of high-profile certificates such as EV certificates. We also propose a generic communication workflow to request and present VPs, which interact with our ACME enhancement. In this regard, we present proof of our approach by using the OpenID for Verifiable Presentation protocol (OID4VP) to request and present VPs. To assess the feasibility of our solution, we conduct a complexity analysis, evaluating both computational and communication overhead compared to the standard ACME protocol. Finally, we present an implementation of our solution as proof-of-concept.},
  archive      = {J_COMCOM},
  author       = {David A. Cordova Morales and Ahmad Samer Wazan and David W. Chadwick and Romain Laborde and April Rains Reyes Maramara},
  doi          = {10.1016/j.comcom.2025.108106},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108106},
  shortjournal = {Comput. Commun.},
  title        = {Enhancing the ACME protocol to automate the management of all x.509 web certificates (Extended version)},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
