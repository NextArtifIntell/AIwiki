<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai---69">EAAI - 69</h2>
<ul>
<li><details>
<summary>
(2025). Multimodal data imputation and fusion for trustworthy fault
diagnosis of mechanical systems. <em>EAAI</em>, <em>150</em>, 110663.
(<a href="https://doi.org/10.1016/j.engappai.2025.110663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of missing values in the collected data due to sensor failure, communication interruption, or environmental interference can greatly diminishes the trustworthiness of fault diagnosis for mechanical systems. Therefore, this study proposes and evaluates a novel multimodal data imputation and fusion method to perform the trustworthy fault diagnosis of mechanical systems. First, a generative adversarial imputation network, termed as the L2 regularization temporal–spatial generative adversarial imputation network (L2-TSGAIN), is developed. This L2-TSGAIN network, based on a temporal–spatial feature extraction module and L2 regularization loss function, can comprehensively extract data features from both temporal and spatial perspectives, thus achieving high-quality imputation of anomalous sensor data. Subsequently, a multi-input single-output autoencoder (MISO-AE) is designed to extract a universal representation of the imputed data from different modalities and recover features in the fusion data. Finally, the fusion data from different health states of mechanical systems are input into a convolutional neural network classifier to perform fault diagnosis. Experiment validations, considering the presence of missing values in sensor data, have been carried out on the planetary transmission system and gearbox test bench. Compared with several mainstream data imputation methods for fault diagnosis, the optimal diagnostic accuracy of 99.68 % and 100 % on these two datasets can be obtained using the proposed method, respectively, confirming its superior performance and reliability. Thus, the proposed method can provide a trustworthy fault diagnosis tool for mechanical systems in industrial scenarios considering anomalous sensor data.},
  archive      = {J_EAAI},
  author       = {Jie Zhang and Yun Kong and Qinkai Han and Tianyang Wang and Mingming Dong and Hui Liu and Fulei Chu},
  doi          = {10.1016/j.engappai.2025.110663},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110663},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal data imputation and fusion for trustworthy fault diagnosis of mechanical systems},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Atrous spatial pyramid pooling with swin transformer model
for classification of gastrointestinal tract diseases from videos with
enhanced explainability. <em>EAAI</em>, <em>150</em>, 110656. (<a
href="https://doi.org/10.1016/j.engappai.2025.110656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and early identification of gastrointestinal (GI) lesions is crucial for treating and preventing GI diseases, including cancer. Automated computer-aided diagnosis methods can assist physicians in early and accurate detection. Video classification of GI endoscopic videos is challenging due to the complexity and variability of visual data. This research proposes a novel method for classifying GI diseases using endoscopic videos. Leveraging the public HyperKvasir dataset, we applied preprocessing algorithms to enhance GI frames by removing noise and artifacts with morphological opening and closing techniques, ensuring high-quality visuals. We addressed dataset imbalance by proposing a novel algorithm. Our hybrid model, Atrous Spatial Pyramid Pooling with Swin Transformer (ASPPST), combines advanced Convolutional Neural Networks and the Swin Transformer to classify GI videos into 30 distinct classes. We incorporated Gradient-Class Activation Mapping (Grad-CAM) in ASPPST&#39;s final layer to improve model explainability. The proposed model achieved 97.49 % accuracy in classifying 30 GI diseases, outperforming other transfer learning models and transformers by 8.04 % and 3.99 %, respectively. It also demonstrated a precision of 97.80 %, recall of 97.77 %, and an F1 score of 97.75 %, showcasing robustness across metrics. The high accuracy of ASPPST makes it suitable for real-world use, delivering fewer errors and more precise results in GI endoscopy video classification. Our approach advances artificial intelligence (AI) in computer vision and deep learning for biomedical engineering applications. Grad-CAM integration enhances transparency, boosting clinician trust and adoption of AI tools in diagnostic workflows.},
  archive      = {J_EAAI},
  author       = {Arefin Ittesafun Abian and Mohaimenul Azam Khan Raiaan and Mirjam Jonkman and Sheikh Mohammed Shariful Islam and Sami Azam},
  doi          = {10.1016/j.engappai.2025.110656},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110656},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Atrous spatial pyramid pooling with swin transformer model for classification of gastrointestinal tract diseases from videos with enhanced explainability},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solution and application of two-dimensional seismic
wavefield evolution based on physics-informed neural networks.
<em>EAAI</em>, <em>150</em>, 110652. (<a
href="https://doi.org/10.1016/j.engappai.2025.110652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINN) integrate partial differential equations, initial conditions, and boundary conditions into the loss function to predict the solutions of partial differential equations, and have already demonstrated their value in solving two-dimensional (2D) seismic wavefields. However, when dealing with wave problems involving boundary conditions, the added complexity of boundary conditions can lead to imbalanced convergence rates among different loss terms, which may affect both the efficiency and accuracy of the computations. Moreover, the need to retrain the model for different problems limits the flexibility of its application. Therefore, this paper introduces an adaptive weight balancing method and presents a 2D wave simulation based on Self-Adaptive PINN (SA-PINN). This method automatically adjusts the weights in the loss function, improving the solving performance. Additionally, to improve the computational efficiency of PINN in solving similar wave problems, a transfer learning strategy is adopted. By leveraging the similarities between the PINN models of related wave problems, this strategy enhances the generalization ability of PINN when dealing with variations in source location and medium wave speed. Numerical examples in semi-infinite domains and V-shaped valleys demonstrate that this method effectively achieves intelligent and efficient simulation of 2D seismic wavefields, providing a more efficient and intelligent solution for complex seismic wave problems.},
  archive      = {J_EAAI},
  author       = {Zhihui Zhu and Zong Wang and Yang Feng and Weiqi Zheng},
  doi          = {10.1016/j.engappai.2025.110652},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110652},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solution and application of two-dimensional seismic wavefield evolution based on physics-informed neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive human in the loop system for identifying
non-optimal states in natural product manufacturing process.
<em>EAAI</em>, <em>150</em>, 110650. (<a
href="https://doi.org/10.1016/j.engappai.2025.110650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the extraction of natural products, the identification of non-optimal production states is pivotal for ensuring consistent product quality. Currently, there is a deficiency in online, automated detection methods. This study introduces an online machine vision strategy in a real industrial setting to maintain optimal production state. Specifically, the strategy incorporates an adaptive human in the loop deep learning approach to select high-value samples. This method achieves over 90 % accuracy with fewer training samples, effectively addressing the challenges posed by the low-value density characteristic of industrial data. Additionally, a convolutional neural networks-transformer framework is employed as a classifier for video data to meet the demands of time-series data. To enhance the efficiency of processing multiple video streams, we have implemented a knowledge distillation technique to lighten the model. Finally, this model has been deployed in an actual industrial environment for online monitoring of three extraction devices. The system encapsulates the expertise of engineers to standardize the criteria for assessing production states. This integration of innovative technologies ensures a more reliable and efficient extraction process, meeting the industry&#39;s need for consistent product quality.},
  archive      = {J_EAAI},
  author       = {Qilong Xue and Yang Yu and Shixin Cen and Yequan Yan and Jiping Pang and Ping Li and Yehan Hou and Lei Wang and Zheng Li},
  doi          = {10.1016/j.engappai.2025.110650},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110650},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive human in the loop system for identifying non-optimal states in natural product manufacturing process},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A chinese medical named entity recognition method
considering length diversity of entities. <em>EAAI</em>, <em>150</em>,
110649. (<a
href="https://doi.org/10.1016/j.engappai.2025.110649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting clinical entity concepts from professional medical materials is crucial for medical information analysis and knowledge extraction. Whereas, the Chinese medical named entity recognition (CMNER) task faces challenges due to the knowledge specialization and the diversity in entity lengths. To address these challenges, a novel method by considering length diversity of entities for CMNER is proposed, focusing on the integration of local information based on the predominance of large language models (LLMs). The method pre-trains a bidirectional encoder representation from transformers (BERT) based on open Chinese medical texts and designs a multi-dimensional convolutional residual module to enhance the semantic information for characters. This module effectively mines local information across various ranges and employs a local channel self-attention block to integrate this information, establishing a link between local information and entity length. Meanwhile, an adaptive optimization strategy for a learning rate is designed to improve the method&#39;s ability to search for the optimal solution. Experimental results reveal that, compared with state-of-the-art models, our approach achieves the optimal Recall and F1 , especially Recalls achieve 94.50 % (p &lt; 0.05) and 93.51 % (p &lt; 0.05) with effective performance in current task. The ablation results suggest that incorporating local information within 1–7 characters effectively addresses the challenges mentioned, highlighting the potential of our method to advance CMNER task.},
  archive      = {J_EAAI},
  author       = {Hongyu Zhang and Long Lyu and Weifu Chang and Yuexin Zhao and Xiaoqing Peng},
  doi          = {10.1016/j.engappai.2025.110649},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110649},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A chinese medical named entity recognition method considering length diversity of entities},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving weak magnetic detection of ferromagnetic material
defects diagnostics via transfer learning-enhanced residual networks.
<em>EAAI</em>, <em>150</em>, 110647. (<a
href="https://doi.org/10.1016/j.engappai.2025.110647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of weak magnetic detection technology to identify defect sizes in ferromagnetic materials poses significant challenges due to the large volume of data and the relatively low prediction accuracy of conventional methods. Therefore, this paper proposes an improved Residual Networks (ResNet18) model that integrates transfer learning and channel attention mechanisms. Compared to traditional methods, the following improvements have been made: First, transfer learning has significantly reduced the data volume and time cost required for training from scratch, enhancing the model&#39;s generalization capability. Second, we have added a channel attention mechanism to the ResNet18 model, which involves calculating the importance of each channel through adaptive average pooling and fully connected layers, and generating channel weights using a Sigmoid function. This improvement allows the model to more accurately focus on features with higher relevance to defect sizes. Experimental results demonstrate that for grayscale images with defect lengths of 50 mm, depths of 2 mm, and widths of 1, 2, 3, 4, and 5 mm, the prediction accuracies reached 100 %, 100 %, 98.84 %, 99.58 %, and 100 %, respectively. For grayscale images with defect lengths of 50 mm, widths of 2 mm, and depths of 1, 2, 3, 4, and 5 mm, the prediction accuracies were 99.68 %, 100 %, 99.63 %, 100 %, and 99.60 %, respectively. Compared to the traditional ResNet18 model, the improved model not only enhances the accuracy of defect size prediction but also exhibits greater robustness, providing a new and effective method for defect classification in weak magnetic detection of ferromagnetic materials.},
  archive      = {J_EAAI},
  author       = {Yu Chen and Liangliang Li and Zhengxiang Ma and Xinling Wen and Jiabao Pang and Weitao Yuan},
  doi          = {10.1016/j.engappai.2025.110647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving weak magnetic detection of ferromagnetic material defects diagnostics via transfer learning-enhanced residual networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptive production scheduling for discrete
manufacturing workshop using multi-agent cyber physical system.
<em>EAAI</em>, <em>150</em>, 110638. (<a
href="https://doi.org/10.1016/j.engappai.2025.110638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the production control process of a discrete manufacturing workshop is characterized by high concurrency, mixed production lines and difficulty in prediction, which lead to uncertainty caused by dynamic disturbances and challenges in production control. Traditional system architectures struggle to handle these uncertainties flexibly and adaptively. To address these issues, an adaptive production scheduling system for the workshop is proposed, utilizing the Multi-agent Cyber Physical System (CPS-MAS) framework. This system integrates self-organization mechanisms and self-adaptive decision-making mechanisms to achieve cooperative optimal control of manufacturing resources. Using multi-agent technology, the resource model in the information space is encapsulated into an intelligent Cyber Physical System (CPS)-Agent model with cognitive interaction and autonomous decision-making capabilities. The improved contract network protocol (CNP) is utilized to the constructed agent, enabling their collaboration and competition to support the self-organization, negotiation, and assignment of manufacturing tasks. Based on multi-agent real-time perception and interactive negotiation, an adaptive control model of the manufacturing process is constructed based on Proportion Integration Differentiation (PID) control principle. This model is trained with the multi-layer perceptron that integrates an attention mechanism. The production strategy and parameters of the agent cooperative network are dynamically adjusted to enable dynamic decision-making optimization under disturbances. The proposed method is verified by experiments in scenarios involving machine failure, emergency order insertion and due date changes, proving its effectiveness.},
  archive      = {J_EAAI},
  author       = {Jie Chen and Zequn Zhang and Liping Wang and Dunbing Tang and Qixiang Cai and Kai Chen},
  doi          = {10.1016/j.engappai.2025.110638},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110638},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-adaptive production scheduling for discrete manufacturing workshop using multi-agent cyber physical system},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A pencil lead break-triggered, adversarial autoencoder-based
approach for rapid and robust rail damage detection. <em>EAAI</em>,
<em>150</em>, 110637. (<a
href="https://doi.org/10.1016/j.engappai.2025.110637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting early-stage damage is essential for railway maintenance, ruling out potential risks that could undermine railway ride comfort and safety. Ultrasonic testing methods, featuring high precision and non-destructive characteristics, have gained widespread use for on-site inspections in modern railway systems. However, current ultrasonic testing remains a highly complex technique that requires expensive ultrasonic devices and trained professionals for operation. This study presents a novel approach for rail damage detection utilizing a disposable mechanical pencil. By intentionally breaking the pencil lead on rail surface, the accumulated potential energy is released in the form of ultrasonic bursts which are acquired by sensors mounted on the rail. The rail damage diagnosis is empowered by an adversarial autoencoder (AAE) which learns representations of ultrasonic signals induced by pencil lead break (PLB). A damage-sensitive indicator is developed based on the Jensen-Shannon Divergence (JSD) between the AAE model output distributions of the baseline and an unknown signal, facilitating rapid and accurate damage diagnosis. Both laboratory experiments and on-site verifications were conducted to validate the proposed approach. The results demonstrate the effectiveness of the damage detection framework in identifying rail damage, exhibiting excellent robustness and reliability. Comparative studies are also conducted to demonstrate the adaptability and effectiveness of the proposed method against field testing environments. The research outcomes of this study will significantly contribute to the development of more efficient on-site inspection techniques for railway maintenance and sustainability.},
  archive      = {J_EAAI},
  author       = {Da-Zhi Dang and Bo-Yang Su and You-Wu Wang and Wai Kei Ao and Yi-Qing Ni},
  doi          = {10.1016/j.engappai.2025.110637},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110637},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A pencil lead break-triggered, adversarial autoencoder-based approach for rapid and robust rail damage detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional temperature field prediction with in-situ
data in metal additive manufacturing using physics-informed neural
networks. <em>EAAI</em>, <em>150</em>, 110636. (<a
href="https://doi.org/10.1016/j.engappai.2025.110636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting the temperature field in metal additive manufacturing (AM) processes is critical for preventing overheating, adjusting process parameters, and ensuring process stability. While physics-based computational models offer precision, they are often time-consuming and unsuitable for real-time predictions. Machine learning models, on the other hand, rely heavily on high-quality datasets, which can be costly and difficult to obtain in the metal AM domain. Existing studies on physics-informed neural networks (PINNs) have made progress in integrating physics with machine learning but often lack in-situ data integration, which is essential for capturing real-time thermal dynamics. Additionally, their methodologies are typically heavily dependent on specific process characteristics, limiting their flexibility. Our work addresses these gaps by introducing a PINN-based framework specifically designed for temperature field prediction in metal AM. The framework incorporates in-situ temperature data gathered during the manufacturing process, combining it with physics-informed inputs and a custom loss function. The approach is demonstrated through two case studies. In the first case, using a small set of experimental data, the model achieves an error below 3 % with a mean absolute error (MAE) of 11 °C. In the second case, using simulation data, the model achieves an error below 1 % with an MAE of 7 °C. In addition, the framework shows promising adaptability for different metal AM scenarios with different geometries, deposition patterns, and process parameters.},
  archive      = {J_EAAI},
  author       = {Pouyan Sajadi and Mostafa Rahmani Dehaghani and Yifan Tang and G. Gary Wang},
  doi          = {10.1016/j.engappai.2025.110636},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110636},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-dimensional temperature field prediction with in-situ data in metal additive manufacturing using physics-informed neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time onboard compressor stall warning method based on
attention multiple sensors fusion and lightweight network.
<em>EAAI</em>, <em>150</em>, 110635. (<a
href="https://doi.org/10.1016/j.engappai.2025.110635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressor stall is one of the critical faults in aero-engines. An effective stall warning model can assist operators and aviation power systems in taking timely measures to avoid or minimize the impact of compressor stall on flight. Real-time onboard stall warning systems for compressors demand models that possess sufficient accuracy, high reliability, and fast execution speed. Therefore, this paper proposes a novel lightweight network based on attention mechanism for multiple sensors feature fusion, named attention feature fusion lightweight network (AFF-LWNet). Specifically, the network first accomplishes multi-sensor feature fusion through an attention feature fusion block. It then learns input features through a lightweight network with two lightweight feature extraction units and finally employs a multi-layer perceptron (MLP) to output stall warning signals. To verify the feasibility of this approach, the proposed method is evaluated on the aero-engine compressor stall dataset. The results demonstrate that the proposed method achieves an average testing accuracy of 99.453 % and an actual average lead time of 241.87ms on the stall dataset, which surpasses the other five competing methods. Therefore, we believe that the proposed method can effectively achieve real-time onboard stall warning for aero-engine compressors with outstanding performance.},
  archive      = {J_EAAI},
  author       = {Huijie Jin and Yong-Ping Zhao and Zhiqiang Wang},
  doi          = {10.1016/j.engappai.2025.110635},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110635},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time onboard compressor stall warning method based on attention multiple sensors fusion and lightweight network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable graph convolutional network based on catastrophe
theory and its application to group activity recognition. <em>EAAI</em>,
<em>150</em>, 110634. (<a
href="https://doi.org/10.1016/j.engappai.2025.110634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (graph models for short) are crucial for understanding model decisions through mathematical white-box interpretation, which can radically improve the performance and credibility of downstream artificial intelligence applications. To address the limitations of existing interpretability of over-smoothing and over-squashing, we propose an explainable graph model based on nonlinear catastrophe theory and apply it to group activity recognition to validate the usefulness of interpretability. (1) We introduce catastrophe mathematical theory to explore the internal processes of graph models and construct the explainable dynamical equations of the graph convolutional network; (2) When graph node features lose uniqueness, leading to over-smoothing, which reduces the discriminative power of the graph model, we propose a mathematical method to predict over-smoothing; (3) In response to the over-squashing of the node feature values that is excessively compressed, we design a channel expansion unit to extend the transmission paths of graph nodes and alleviate the over-squashing in the graph structure. Finally, we apply our model to group activity recognition tasks to capture complex interactions within groups. We obtain the competitive results on five publicly available graph structure datasets (Actor, Chameleon, Texas, Cornell, Cora) and our self-built group activity dataset. Our model can effectively capture node and graph-level features with stronger generalization capabilities. For complex and diverse real-world group activity data, our model offers intuitive graph-level explanations for group activity analysis. Through the analysis of over-smoothing and over-squashing, our method extends new theoretical approaches in explainable artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Junpeng Kang and Jing Zhang and Lin Chen and Hui Zhang and Li Zhuo},
  doi          = {10.1016/j.engappai.2025.110634},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110634},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable graph convolutional network based on catastrophe theory and its application to group activity recognition},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge graph for the vulnerability of construction
safety system in megaprojects based on accident inversion.
<em>EAAI</em>, <em>150</em>, 110630. (<a
href="https://doi.org/10.1016/j.engappai.2025.110630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing vulnerability of construction safety systems in megaprojects (CSSMs) poses significant challenges to their safety management and control. To address this obstacle, this study retrodicts the accidents based on text mining using the Bidirectional Encoder Repre-sentations from Transformers Topic (BER-Topic) model to uncover topic and topic words related to the vulnerabilities of CSSMs. The vulnerability indicator system (VIS) is established by considering the exposure, sensitivity, and adaptability of the vulnerability of CSSMs. Subsequently, an improved Decision-making Trial and Evaluation Laboratory (DEMATEL) method based on association rules is proposed to reduce the subjectivity in assigning weights to vulnerability indicators, and a topological network based on complex network is constructed to identify the characteristics of VIS. Based on this, a knowledge graph of vulnerabilities in CSSMs is developed. Finally, taking into account the occurrence probability and the actual losses incurred of vulnerability indicators, a vulnerability assessment model for CSSMs is proposed. The research findings are: 1) Based on the BER-Topic model, 32 topics and topic words related to the vulnerability of CSSMs are mined. 2) A VIS for CSSMs is constructed, including 42 indicators across three dimensions of exposure (19), sensitivity (14), and adaptability (9), involving four aspects: humans, machines, environment, and management. 3) The key points for vulnerability management and control in CSSMs are Inaccurate implementation of geological remediation plans, Rusting of connecting components, and Unlicensed personnel operating, among others, which have strong intermediary roles.},
  archive      = {J_EAAI},
  author       = {Yingliu Yang and Pengcheng Xiang},
  doi          = {10.1016/j.engappai.2025.110630},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110630},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A knowledge graph for the vulnerability of construction safety system in megaprojects based on accident inversion},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust sparse discriminative least squares regression for
image classification. <em>EAAI</em>, <em>150</em>, 110626. (<a
href="https://doi.org/10.1016/j.engappai.2025.110626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discriminative Least Squares Regression (DLSR) is a method used for multi-class classification tasks that expands the distance between different classes through an ε -dragging technique. However, it also amplifies the differences in intra-class regression targets. Moreover, the samples contain a significant amount of noise, which negatively affect the classification performance. To mitigate these problems, we propose Robust Sparse Discriminative Least Squares Regression (RSDLSR) approach to enhance the model&#39;s discriminative power. Firstly, we maintain the original data structure by matrix decomposition in the label space. Secondly, the noise is fitted using sparse constrained noise matrix to enhance the model&#39;s denoising ability. Furthermore, we select important features from label space using a linear discriminant analysis criterion to minimize the influence of redundant features. Finally, l 2 , 1 norm constraint is imposed on the relaxation matrix to improve the sparsity and robustness of the model. Comparative evaluations demonstrate that our proposed method exhibits significant advantages over various existing methods across different classification tasks.},
  archive      = {J_EAAI},
  author       = {Zhangjing Yang and Dingan Wang and Pu Huang and Minghua Wan and Fanlong Zhang},
  doi          = {10.1016/j.engappai.2025.110626},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110626},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust sparse discriminative least squares regression for image classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics informed convolution neural network for
spatiotemporal temperature analysis of concrete dams. <em>EAAI</em>,
<em>150</em>, 110624. (<a
href="https://doi.org/10.1016/j.engappai.2025.110624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring is indispensable throughout the life cycle of dams, and the loading conditions determines the reliability of the assessment. Among them, temperature plays an important role on the behavior of arch dams, which are sparsely monitored in practice. How to use these sparsely measured data to obtain the accurate spatiotemporal temperature field becomes a critical problem. This study proposes a physics informed convolutional neural network for spatiotemporal temperature field of arch dams. A dual thread convolutional neural network considers the effects of spatiotemporal and temporal variables distinctively. The proposed model is validated using measured data from an existing arch dam. Compared with applied convolutional neural network, the proposed model improves the accuracy of temperature field reconstruction by 18 % and reduces reliance on measured data. Benefit of consideration of the continuity and heat transfer, the spatial distribution of the temperature field is more reasonable in continuity, and can retain accuracy even with limited monitoring data. The proposed model can provide the actual spatiotemporal non-uniform temperature field of the arch dam, providing basic data for the analysis and safety evaluation of arch dams throughout their life-cycle.},
  archive      = {J_EAAI},
  author       = {Jiaqi Yang and Jinting Wang and Feng Jin and Jianwen Pan},
  doi          = {10.1016/j.engappai.2025.110624},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110624},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A physics informed convolution neural network for spatiotemporal temperature analysis of concrete dams},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision modeling approach for the development of
sustainable transportation oil companies. <em>EAAI</em>, <em>150</em>,
110623. (<a
href="https://doi.org/10.1016/j.engappai.2025.110623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing sustainable transportation infrastructure to address climate change by reducing carbon dioxide and greenhouse gas emissions is unfeasible without the involvement of international oil companies (IOCs). Identifying the most sustainable IOC can significantly enhance legitimacy, corporate image, brand value, transparency, and reputation. The environmental impact of oil transportation is crucial to the sector&#39;s long-term growth, and modeling IOCs can guide decision-making that aligns with regulatory, environmental, and societal expectations, ensuring successful project implementation. Modeling IOCs presents multiple-attribute decision-analysis (MADA) challenges. Previous research proposed a decision matrix that crossed IOC alternatives with attributes, sub-attributes, and measurement items, utilizing assessments from 483 experts across 11 IOCs based on 2 attributes, 9 sub-attributes, and 47 measurements. Despite the literature review, challenges such as score deviations in the ranking method, as well as informational vagueness, ambiguity, and uncertainty in both weighting and ranking processes, remain unsolved, and early MADA methods exhibit theoretical flaws. This study aims to formulate and develop a decision modeling approach using multi-attribute ideal-real comparative analysis (MAIRCA) and fuzzy weighted zero inconsistency (FWZIC) within a homogeneous interval-valued intuitionistic fuzzy rough set (IIFRS) environment. This solution addresses the limitations in the literature and effectively handles the complexity of the decision matrix. The findings reveal that cost leadership under a hybrid competitive strategy (HCS-CL) emerged as the most sensitive attribute, holding the highest weight, highlighting the importance of cost efficiency and competitive pricing. IOC11 ranked highest, followed by IOC3 and IOC10, providing benchmarks for other companies. Lesser-ordered companies, such as IOC4, preserve employ these comprehensions to recognize intentional gaps and embrace best attempts from extraordinary-ordered participants. Sensitivity-analysis, Spearman&#39;s-correlation, and comparative-analysis proven the robustness of the proposed approach. The study highlights the require for oil and gas administrators to spotlight cost leadership advantages, raise-efficiency, lower-production costs, and influence economies of ratio to maintain a reasonable edge and enhance-market-positioning.},
  archive      = {J_EAAI},
  author       = {Hassan A. Alsattar and Sarah Qahtan and Nahia Mourad and A.A. Zaidan and Muhammet Deveci and Dragan Pamucar and Jurgita Antucheviciene and Weiping Ding},
  doi          = {10.1016/j.engappai.2025.110623},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110623},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A decision modeling approach for the development of sustainable transportation oil companies},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving model calibration in bone marrow cell
classification through mixup and center loss fusion. <em>EAAI</em>,
<em>150</em>, 110620. (<a
href="https://doi.org/10.1016/j.engappai.2025.110620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of bone marrow cell morphology is essential for the accurate diagnosis of hematological disorders. Traditional manual classification methods are time-consuming and labor-intensive. Although current automatic deep learning techniques mitigate these issues, they may still present significant risks in critical medical diagnostics due to overconfidence in predictions. To tackle these challenges, this paper proposes a novel calibration method called MixCL (Mix-Center Loss). MixCL combines the simple and effective data augmentation method Mixup with deep metric learning Center Loss, achieved through the design of a new loss function. By utilizing Mixup to generate mixing centers that enrich the feature sampling in the feature space, and leveraging the clustering effect of Center Loss to enhance the grouping of similar samples, MixCL combines the strengths of both methods. The effectiveness of MixCL is validated using three real bone marrow cell image datasets, demonstrating significant reductions in Expected Calibration Error (ECE) and Overconfidence Error (OE) for in-distribution samples. For example, in Shifted Windows Transformer model, ECE and OE metrics decreased across all datasets, with reductions averaging 1.72% in ECE and 2.10% in OE. The confidence Kernel Density Estimation (KDE) plot reveals that models using MixCL more effectively manage uncertainty in out-of-distribution samples, ensuring better differentiation between in-distribution and out-of-distribution samples. Thus, the proposed method effectively improves the calibration performance of the model while exhibiting better generalization performance, significantly improved when compared with current advanced bone marrow cell classification methods. Moreover, it has potential applications in various image classification fields, providing reliable confidence estimates.},
  archive      = {J_EAAI},
  author       = {Shuming Cheng and Qinghang Lu and Qianhang Guo and Yunqi Lin and Mingxin Li and Xingyu Zhao and Liang Guo and Jiaming Li and Jie Li and Qingmao Zhang and Qiongxiong Ma},
  doi          = {10.1016/j.engappai.2025.110620},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110620},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving model calibration in bone marrow cell classification through mixup and center loss fusion},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise step counting algorithm for pedestrians using
ultra-low-cost foot-mounted accelerometer. <em>EAAI</em>, <em>150</em>,
110619. (<a
href="https://doi.org/10.1016/j.engappai.2025.110619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-velocity update (ZUPT) is one of the most widely used step counting methods in pedestrian inertial navigation. Existing accelerometer-based methods encounter issues with misjudgments of zero velocity and step counting errors in various activities. To tackle these challenges, we present a precise step counting algorithm leveraging ultra-low-cost foot-mounted accelerometer for pedestrians with extremely low complexity. This algorithm mainly contains two key points: adaptive acceleration threshold selection and state vector update, implemented by twice zero-velocity detections (ZVD, generating state vectors to depict pedestrian&#39;s status) and length comparisons. Accelerations undergo gravity correction, magnitude calculation, data smoothing, and parameters initialization. Subsequently, the zero-acceleration threshold is adaptively selected through ZVD, and the length of state intervals (LSI) is compared with the first length threshold. Then, the state vector is updated by ZVD, and the LSI is compared with the second length threshold. Finally, the number of state intervals is interpreted as step counts. Step counting experiments were conducted utilizing three diverse datasets, which comprised a self-constructed ultra-low-cost accelerometer-based dataset and two public datasets. These datasets covered various activities, such as normal walking, fast walking, running, multiple turns in a corridor, stationary stepping, and upstairs/downstairs. The proposed algorithm could achieve an accuracy of 100 % under the above situations. Compared to long short term memory (LSTM) and other algorithms, it exhibited an accuracy improvement of at least 13.05 %, with a processing time only 0.07 % of that required by LSTM. The proposed algorithm enables accurate step counting across a range of activities performed by different pedestrians with high precision, low complexity, and robust applicability.},
  archive      = {J_EAAI},
  author       = {Jingxue Bi and Jianhui Wang and Baoguo Yu and Guobiao Yao and Yunjia Wang and Hongji Cao and Lu Huang and Huaqiao Xing},
  doi          = {10.1016/j.engappai.2025.110619},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110619},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Precise step counting algorithm for pedestrians using ultra-low-cost foot-mounted accelerometer},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stream structure-oriented neighbor enhancement network
for dental model segmentation. <em>EAAI</em>, <em>150</em>, 110618. (<a
href="https://doi.org/10.1016/j.engappai.2025.110618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of digital orthodontic treatment is to achieve accurate tooth segmentation of the three-dimensional (3D) dental mesh model obtained from oral scanning equipment. However, current advanced deep learning-based methods often consolidate all features into a single vector during the feature learning process, thus overlooking the distinct information among features and subsequently weakening their complementary roles. To address this issue, we propose a two-stream structure-oriented neighbor enhancement network (TSNEN) to improve the complementary effect among different features. Specifically, TSNEN develops an input-specific two-stream structure and feature enhancement modules to emphasize the geometric disparities among various meshes and achieve the complementary enhancement of different features, respectively. Furthermore, the self-attention module is modified to fully integrate the local features derived from the branches of the two streams, which effectively balances the data differences among different features to mitigate feature confusion, and ultimately achieves accurate segmentation of the dental model. The real dental model dataset is analyzed to verify the effectiveness and capability of the proposed method which reached an overall accuracy (OA) at 96.83 % and mean over union (mIoU) at 92.06 %. Finally, the comparative analysis is implemented and the results further show that the proposed method has better performance both in prediction accuracy and robustness.},
  archive      = {J_EAAI},
  author       = {Zhihua Liu and Hao Tang and Jiutao Xue and Yuhe Liao},
  doi          = {10.1016/j.engappai.2025.110618},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110618},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-stream structure-oriented neighbor enhancement network for dental model segmentation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time prediction of axial force in concrete-filled steel
tubular columns under fire conditions using modular artificial
intelligence techniques. <em>EAAI</em>, <em>150</em>, 110617. (<a
href="https://doi.org/10.1016/j.engappai.2025.110617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The axial force plays a critical role in assessing the functional integrity of columns within a building in fire. However, it cannot be measured directly and is influenced by factors such as temperature, load ratio, and axial restraint. This study proposes a real-time methodology to predict the axial force of restrained concrete-filled steel tubular (CFST) columns exposed to real fires, utilizing modular artificial intelligence. A module is developed that combines a convolutional neural network (CNN) and long short-term memory (LSTM) networks to predict the temperature field of CFST columns caused by fire in real time. This module estimates the current temperature field using past data and the current surface temperature, which is continuously monitored with inherent noise. It effectively mitigates noise interference, achieving an R 2 of 0.97 on the test dataset, which ensures accurate estimations. Additionally, a separate LSTM module with a skip connection is employed to predict the axial force ratio, integrating temperature predictions and real-time measurements of axial deformation. Finally, the accuracy of this modular model demonstrates better performance in predicting real-time axial force compared to the conventional integrated deep learning model, achieving an R 2 of 0.99. The proposed approach enables accurate prediction of axial force in restrained CFST columns across various fire scenarios and structural conditions, aiming at increasing the scientificity of fire rescue decisions.},
  archive      = {J_EAAI},
  author       = {Hong-Hui Qi and Guo-Qiang Li and Shaojun Zhu},
  doi          = {10.1016/j.engappai.2025.110617},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110617},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time prediction of axial force in concrete-filled steel tubular columns under fire conditions using modular artificial intelligence techniques},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time prediction model for instantaneous dam-break
flood evolution of concrete gravity dams based on attention mechanism
and spatiotemporal multiple features. <em>EAAI</em>, <em>150</em>,
110616. (<a
href="https://doi.org/10.1016/j.engappai.2025.110616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating the flood evolution following the sudden breach of concrete gravity dams is crucial for enabling prompt emergency flood control decisions. The real-time performance and reliability of these flood propagation simulations are essential for improving the accuracy and speed of emergency responses. This study introduces a deep learning model that integrates an attention mechanism to predict flood evolution parameters in real time. Initially, parameters such as water depth and flow rate were measured under 32 distinct dam-break scenarios using a hydrodynamic model. By combining terrain data with time-series flood discharge data, we compiled a dataset containing 1984 entries, enhanced through reduced-order methods. A novel deep learning model, the Flood-Swin-Transformer, was then developed to predict the spatiotemporal evolution of dam-break floods. This model was benchmarked against 11 baseline models and four state-of-the-art deep learning models. The results indicate: (1) Baseline models accurately predict water depth but are less effective at predicting flow rate parameters; (2) Deep learning models outperform baseline models in both accuracy and classification capabilities for water depth and flow rate parameters, showing robust performance; (3) Extensive analyses, including error, classification accuracy, effectiveness, robustness, and flood parameter error mapping, demonstrate the superior performance of the proposed model; (4) The proposed model predicts flood evolution up to 43.75 times faster than traditional hydrodynamic models, facilitating real-time prediction capabilities.},
  archive      = {J_EAAI},
  author       = {Chao Wang and Yaofei Zhang and Sherong Zhang and Xiaohua Wang and Xingbo Zhou and Yishu Lai},
  doi          = {10.1016/j.engappai.2025.110616},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110616},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time prediction model for instantaneous dam-break flood evolution of concrete gravity dams based on attention mechanism and spatiotemporal multiple features},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dialogue response coherency evaluation with feature
sensitive negative sample using multi list-wise ranking loss.
<em>EAAI</em>, <em>150</em>, 110609. (<a
href="https://doi.org/10.1016/j.engappai.2025.110609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic evaluation of dialogue coherency is crucial for developing high-quality dialogue systems. However, traditional evaluation metrics such as Bilingual Evaluation Understudy (BLEU) and Recall-Oriented Understudy for Gisting Evaluation (ROUGE) have limitations when it comes to assessing diverse and creative responses because they heavily rely on reference responses. For learnable metrics which utilize contrastive learning, challenges are encountered due to the use of randomly selected negative samples that do not reflect conversational features (i.e. topic, emotion, intention) and the lack of granularity in assessing response appropriateness. To address these limitations, we propose the Feature sensitive Multi-Listwise Ranking (FMListR) response coherency evaluation model. This model aims to evaluate dialogue coherency in degrees while considering conversational sensitive features. This approach involves sampling feature-sensitive responses that share conversational features with ground truth responses and utilizing them as hard negative samples. The model is trained using Multi-Listwise Ranking (MListR) loss, which is designed to learn the ranking between negative samples and identify response features. The experimental results demonstrate that Feature sensitive Multi-Listwise Ranking exhibits stronger correlations with human judgment compared to other response coherency evaluation metrics. By considering conversational features and training the model using a specialized loss function, FMListR provides a more robust and accurate evaluation of dialogue coherency.},
  archive      = {J_EAAI},
  author       = {YeongJun Hwang and Dongjun Kang and JinYeong Bak},
  doi          = {10.1016/j.engappai.2025.110609},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110609},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dialogue response coherency evaluation with feature sensitive negative sample using multi list-wise ranking loss},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive assessment of failure mode and shear capacity
of reinforced concrete circular columns based on data-driven machine
learning methods. <em>EAAI</em>, <em>150</em>, 110603. (<a
href="https://doi.org/10.1016/j.engappai.2025.110603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforced concrete (RC) columns are critical elements in frame structures. A common challenge in structural engineering is estimating the seismic capacity of circular RC columns, as existing methods typically require transforming circular columns into equivalent square sections due to the absence of direct formulas. To address this, this study introduces data-driven machine learning (ML) methods to directly assess both failure modes and seismic shear capacity of circular RC columns. With the help of automated machine learning (AutoML), seven ML algorithms were selected and fine-tuned, resulting in 40 distinct models that were analyzed and compared in detail. The results indicate that the Multilayer Perceptron (MLP) model outperforms others in predicting seismic failure modes, achieving a high accuracy of 88 %. For seismic shear capacity predictions, the Weighted Ensemble (WE) model achieved the best performance with Root Mean Squared Error of 53.49, Mean Absolute Error of 39.23, Coefficient of Determination of 0.88 and Mean Squared Error of 2861.18 among all the ML models. Furthermore, the results (the predicted maximum lateral force/the experimental results) of the WE model, with a mean value of 0.98, a standard deviation of 0.11, and a coefficient of variation (mean/standard deviation) of 12.8 %, surpass those of traditional theoretical and empirical models. Besides, the ML models offer fast, accurate seismic performance evaluations for circular RC columns, eliminating the need for complex and time-consuming calculations. Furthermore, SHapley Additive exPlanations (SHAP) analysis provided visual insights into parameter contributions, enhancing model transparency and trust for engineering applications.},
  archive      = {J_EAAI},
  author       = {Yue Wen and Shiqiao Zhou and Gaochuang Cai and Zhili He and Amir Si Larbi},
  doi          = {10.1016/j.engappai.2025.110603},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110603},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive assessment of failure mode and shear capacity of reinforced concrete circular columns based on data-driven machine learning methods},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging large language models to examine the interaction
between investor sentiment and stock performance. <em>EAAI</em>,
<em>150</em>, 110602. (<a
href="https://doi.org/10.1016/j.engappai.2025.110602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the relationship between investor sentiment and stock performance is crucial in dynamic financial markets. Existing researches often focus on financial news and stock prices, while studies on investor sentiment typically rely on traditional machine learning models that require extensive data labeling. Additionally, most researches focus on single stock indices, overlooking the impact of brand popularity. To address these gaps, this study proposes a novel framework to analyze the interaction between investor sentiment and stock performance, using Chinese Baijiu industry stocks as a case example. It further explores how brand popularity influences this relationship, offering insights for informed investment decisions through artificial intelligence technology. In this study, we leverage Generative Pre-trained Transformer 4 (GPT-4), a state-of-the-art black-box large language model, to process vast volumes of unstructured text data from stock forums. By employing in-context learning with human-labeled examples, GPT-4 generates weak labels that are subsequently used to fine-tune Large Language Model Meta AI (LLaMA), a smaller and more efficient open-source LLM from Meta AI, thereby enabling sentiment-driven decision-making in real-world scenarios. To construct a comprehensive sentiment indicator, we integrate both direct and indirect factors influencing sentiment and use principal component analysis to combine them effectively. To examine interaction between sentiment and stock yield, we apply the Granger causality test and vector autoregression models across stocks with different brand popularity levels. The results show that our framework achieves state-of-the-art performance investor sentiment analysis. Moreover, with brand popularity significantly amplifying the interaction between investor sentiment and stock yield, it leads to bidirectional Granger causality in highly popular brands.},
  archive      = {J_EAAI},
  author       = {Yong Zhuang and Feilong Wang and Dickson K.W. Chiu and Kevin K.W. Ho},
  doi          = {10.1016/j.engappai.2025.110602},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110602},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leveraging large language models to examine the interaction between investor sentiment and stock performance},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lane change trajectory planning based on improved model
predictive control with artificial potential field for autonomous
vehicles in medium-high speed scenarios. <em>EAAI</em>, <em>150</em>,
110601. (<a
href="https://doi.org/10.1016/j.engappai.2025.110601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design of a lane change control system for autonomous vehicles (AVs) in medium-high speed scenarios. A lane change trajectory planning method based on the combination of artificial potential field (APF) and model predictive control (MPC), referred to as APF-MPC, is proposed. To ensure a smooth transition at the beginning and end of the lane change, a reference trajectory based on a sinusoidal curve is designed. The obstacle potential field, constructed using a two-dimensional joint probability density function, is combined with the road potential field to enhance lane change safety. The potential field function is integrated into the MPC optimal control problem, which is constructed based on the point-mass model. This problem is then solved to obtain the planned trajectory within the predicted time domain. The lateral and longitudinal tracking controllers, designed using linear MPC, are employed to track the planned trajectory in real-time, thereby demonstrating the real-time performance of this method. The feasibility of the APF-MPC method is verified through a co-simulation platform. The simulation results indicate that the trajectories planned by the APF-MPC method meet the requirements of safety, occupant comfort, and lane change efficiency. In different scenarios, the front wheel angle of the AV during the lane change ranges from -2 to 2 degrees. Compared with non-adaptive APF and traditional MPC methods, the maximum lateral acceleration, maximum lateral velocity, and maximum front wheel steering angle of the AV during lane changing are reduced by more than 40%.},
  archive      = {J_EAAI},
  author       = {Zhaojun Zhang and Jiale Qin and Simeng Tan and Hongjie Luo},
  doi          = {10.1016/j.engappai.2025.110601},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110601},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lane change trajectory planning based on improved model predictive control with artificial potential field for autonomous vehicles in medium-high speed scenarios},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Input parameterized physics informed neural networks for de
noising, super-resolution, and imaging artifact mitigation in time
resolved three dimensional phase-contrast magnetic resonance imaging.
<em>EAAI</em>, <em>150</em>, 110600. (<a
href="https://doi.org/10.1016/j.engappai.2025.110600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivation: Hemodynamic analysis is crucial for diagnosing and predicting cardiovascular diseases. However, methods relying on fluid flow simulations or blood flow imaging are complex, time-consuming, and require specialized expertise, limiting their clinical use. Goal: This research aims to automate the enhancement of blood flow images, providing clinicians with a fast, accurate tool for hemodynamic analysis without requiring advanced expertise. Objectives: A software tool based on physics-constrained neural networks was developed to enable clinicians to easily select and process regions of interest (ROIs) in time-resolved three-dimensional phase contrast magnetic resonance imaging (4D-Flow MRI) blood flow images for quick, accurate analysis. Methods: The Input Parameterized Physics-Informed Neural Network (IP-PINN) was introduced to improve the spatio-temporal resolution of 4D-Flow MRI. IP-PINN mitigates noise, velocity aliasing, and phase errors. A convolutional neural network processes ROI data into latent vectors, which are then used to predict velocity, pressure, and spin density via a multi-layer perceptron. The method is trained with synthetic blood flow data using an innovative loss function that addresses noise and artifacts. Results: IP-PINN successfully enhanced image resolution, reducing noise and artifacts when tested on synthetic 4D-Flow MRI data derived from blood flow simulations of intracranial aneurysms. For data with 20 decibels (dB) signal-to-noise ratio, results closely matched the ground truth with less than 5.5% relative error. Processing took under two minutes. The method also has the potential to reduce data acquisition time by 25%. Conclusions: IP-PINN could significantly enhance the clinical use of 4D-Flow MRI for personalized hemodynamic analysis in cardiovascular diseases.},
  archive      = {J_EAAI},
  author       = {Amin Pashaei Kalajahi and Hunor Csala and Zayeed Bin Mamun and Sangeeta Yadav and Omid Amili and Amirhossein Arzani and Roshan M. D’Souza},
  doi          = {10.1016/j.engappai.2025.110600},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110600},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Input parameterized physics informed neural networks for de noising, super-resolution, and imaging artifact mitigation in time resolved three dimensional phase-contrast magnetic resonance imaging},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing machine learning algorithms for fault
classification in rolling bearings: A bayesian optimization approach.
<em>EAAI</em>, <em>150</em>, 110597. (<a
href="https://doi.org/10.1016/j.engappai.2025.110597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern power machinery is inherently complex and operates under dynamic operating conditions, so they demand advanced solutions based on deep learning to diagnose bearing faults inside rotating equipment that cause unplanned downtime and safety issues, leading to operational challenges. However, most deep learning approaches aim to improve performance by incorporating hybrid neural networks that rely on multiple convolutional and temporal units, often overlooking optimizing the large number of hyperparameters that define the structure and performance of hybrid models along with the associated computational constraints. To address this gap, this study presents an innovative approach for the detection and classification of bearing faults by integrating an optimized sparse deep autoencoder (DAE) with a Bidirectional Long Short-Term Memory model (Bi-LSTM). The optimal network structure and hyperparameters are determined through Bayesian optimization (BO) with parallel settings, which automatically searches for network configurations that improve the feature extraction ability of the DAE and the generalization ability of the Bi-LSTM for more efficient fault classification in rolling bearings. Parallel optimization accelerates network structure and hyperparameter tuning by evaluating multiple configurations at once. It leverages the full potential of available multi-core Central Processing Units (CPUs)/Graphics Processing Units (GPUs) in conjunction with a lightweight BO surrogate model. This autonomous and user-friendly framework generates inputs from principal component analysis for linear and BO-DAE for non-linear feature extraction and selection, which are then used to train a BO-enhanced Bi-LSTM. This three-stage optimized method effectively captures spatial and temporal dependencies in vibrational signals, achieving superior efficiency, accuracy, and reliability compared to shallow and deep learning models. Evaluation metrics, including macro precision (99.50 %), recall (99.60 %), F1-Score (99.57 %), and Cohen&#39;s Kappa metric (Cκ = 99.53 %), demonstrate the efficacy of our approach for bearing fault classification in industrial applications.},
  archive      = {J_EAAI},
  author       = {Muhammad Zain Yousaf and Josep M. Guerrero and Muhammad Tariq Sadiq},
  doi          = {10.1016/j.engappai.2025.110597},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110597},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing machine learning algorithms for fault classification in rolling bearings: A bayesian optimization approach},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic scheduling in flexible and hybrid disassembly
systems with manual and automated workstations using reward-shaping
enhanced reinforcement learning. <em>EAAI</em>, <em>150</em>, 110588.
(<a href="https://doi.org/10.1016/j.engappai.2025.110588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As e-waste grows at an alarming rate, efficient disassembly systems have become crucial for sustainable production practices. Existing disassembly systems rely heavily on fixed automation and limited manual intervention, making it challenging to adapt to dynamic issues such as workstation failures and system bottlenecks, leading to inefficiencies and suboptimal resource allocation. To address these issues, a hybrid disassembly system is developed that integrates manual and automated workstations, allowing for the flexible variation of manual resources as needed to optimize the disassembly process, with a focus on reducing time and maximizing profit. Through the proposal of a Proximal Policy Optimization (PPO) algorithm enhanced with Reward-Shaping, the research effectively tackles key challenges of uncertainty and dynamic conditions in disassembly systems, including workstation failures and system bottlenecks. These issues are explored through a refrigerator disassembly simulation model. The results demonstrate that the PPO algorithm significantly outperforms traditional rule-based methods and two other reinforcement learning techniques in managing complex dynamic scheduling and resource allocation tasks, offering greater efficiency and flexibility. These findings contribute to the advancement of automated disassembly processes and their integration into modern industrial systems.},
  archive      = {J_EAAI},
  author       = {Jinlong Wang and Qihuiyang Liang and Min Li and Zelin Qu and Yuanyuan Zhang},
  doi          = {10.1016/j.engappai.2025.110588},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110588},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic scheduling in flexible and hybrid disassembly systems with manual and automated workstations using reward-shaping enhanced reinforcement learning},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft actor-critic enhanced nonsingular terminal synergetic
control for serial manipulators with quantized input and state.
<em>EAAI</em>, <em>150</em>, 110587. (<a
href="https://doi.org/10.1016/j.engappai.2025.110587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synergetic control is vulnerable to model uncertainty, which affects control performances and stability. In addition, quantized sensor measurements and control signals compound these challenges. Equally important, a unique problem in serial manipulator robots is the varying control response across joints, which affects the end effector’s pose when moving to the desired position. The mentioned challenges motivate this study to propose soft actor-critic reinforcement learning as a novel adaptive approach for nonsingular terminal synergetic control on a 4-degree-of-freedom serial manipulator robot. The control law is designed based on the nonsingular terminal synergetic control evolution constraint, manifold, and macrovariable. Subsequently, the soft actor-critic reinforcement learning dynamically adjusts the evolution constraint parameters, adapting to the changing state of the environment. The Lyapunov stability theorem proves the control law stability. This study also introduces a novel reinforcement learning reward function that encourages state convergence using the Cauchy probability density function and macrovariable. The agent training environment accounts for state and input quantization, enabling a seamless sim-to-real transition. The simulations and physical experiments validate the effectiveness of the proposed controller in improving transient response, tracking response, and uniform performance across joints. Additionally, online training validates the safe exploration property of the proposed adaptive control.},
  archive      = {J_EAAI},
  author       = {Muhammad Auzan and Yong-Lin Kuo},
  doi          = {10.1016/j.engappai.2025.110587},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110587},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Soft actor-critic enhanced nonsingular terminal synergetic control for serial manipulators with quantized input and state},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial neural networks for finger vein recognition: A
survey. <em>EAAI</em>, <em>150</em>, 110586. (<a
href="https://doi.org/10.1016/j.engappai.2025.110586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finger vein recognition is an emerging biometric recognition technology. Different from the other biometric features on the body surface, the venous vascular tissue of the fingers is buried deep inside the skin. Due to this advantage, finger vein recognition is highly stable and private. Finger veins are virtually impossible to steal and difficult to interfere with by external conditions. Unlike the finger vein recognition methods based on traditional machine learning, the artificial neural network technique, especially deep learning, does not rely on feature engineering and has superior performance. To summarize the development of finger vein recognition based on artificial neural networks,this paper collects 174 related papers. First, we introduce the background of finger vein recognition and the motivation for this survey. Then, the development history of artificial neural networks and the representative networks on finger vein recognition tasks are introduced. The public datasets widely used in finger vein recognition are then described. After that, we summarize the related finger vein recognition tasks based on classical neural networks and deep neural networks, respectively. Finally, the challenges and potential development directions in finger vein recognition are discussed. This paper provides a comprehensive and novel summary of the application of artificial neural networks in the finger vein recognition field.},
  archive      = {J_EAAI},
  author       = {Yimin Yin and Renye Zhang and Pengfei Liu and Wanxia Deng and Dayu Hu and Siliang He and Chen Li and Jinghua Zhang},
  doi          = {10.1016/j.engappai.2025.110586},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110586},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural networks for finger vein recognition: A survey},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-module cooperative control method for on-ramp area in
heterogeneous traffic flow using reinforcement learning. <em>EAAI</em>,
<em>150</em>, 110584. (<a
href="https://doi.org/10.1016/j.engappai.2025.110584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the on-ramp area, vehicle conflicts significantly reduce traffic efficiency and increase collision risks. This study introduces a novel dual-module cooperative control approach designed for on-ramps that accommodate heterogeneous traffic flows, including connected and automated vehicles (CAVs) and human driving vehicles (HDVs). By utilizing reinforcement learning techniques, the approach aims to enhance both traffic efficiency and safety. The approach comprises two key modules: the merging control module and the lane-changing control module. The merging control module facilitates cooperation between mainline and ramp vehicles, while the lane-changing control module assists mainline CAVs in making informed lane-change decisions. Agents within these modules are trained using the proximal policy optimization algorithm, known for its strong convergence properties. After 100 to 200 training episodes, the agents achieve stable peak average rewards. Simulation results demonstrate significant improvements in traffic efficiency and safety with the dual-module control method in on-ramp areas, especially in scenarios involving CAV-HDV heterogeneous traffic flows. With a CAV penetration rate of just 0.2, average vehicle delay is reduced by 26 %. Furthermore, from a safety perspective, when the CAV penetration rate reaches or exceeds 0.3, the time-exposed time-to-collision decreases by approximately 45 %. Transferability analysis indicates that integrating reinforcement learning agents into the control strategy produces positive results across varying maximum speeds and flow rates. In heterogeneous traffic environments, it is advisable to train agents at high CAV penetration rates. Comparative studies further show that the proposed method significantly enhances traffic efficiency and safety, maintaining robust performance even at lower CAV penetration rates.},
  archive      = {J_EAAI},
  author       = {Wenzhang Yang and Changyin Dong and Ziqian Zhang and Xu Chen and Hao Wang},
  doi          = {10.1016/j.engappai.2025.110584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dual-module cooperative control method for on-ramp area in heterogeneous traffic flow using reinforcement learning},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class imbalance-aware domain specific transfer learning
approach for medical image classification: Application on COVID-19
detection. <em>EAAI</em>, <em>150</em>, 110583. (<a
href="https://doi.org/10.1016/j.engappai.2025.110583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) show promise in medical image classification; however, their effectiveness is often constrained by the availability of large, annotated datasets, which are not always accessible. Additionally, the lack of medically relevant transfer models limits the potential of Transfer Learning (TL) in addressing this challenge. Existing TL methods typically employ conventional approaches that result in suboptimal performance and exhibit issues related to network bias, especially in imbalanced datasets. To overcome these limitations, we introduce a novel class imbalance-aware, domain-specific transfer learning framework (CIDSTL-Net) designed specifically for medical imaging tasks. CIDSTL-Net adopts a two-stage training approach: initially developing domain-specific models followed by fine-tuning on targeted medical datasets. This method incorporates an innovative class weighting strategy in its loss calculation to address dataset bias and enhances the transfer head network with a novel combination of fully connected, batch normalization, and dropout layers. Additionally, CIDSTL-Net employs cyclically scheduled learning rates to optimize parameter exploration and exploitation during training. We have rigorously evaluated CIDSTL-Net on four publicly available COVID-related datasets, covering chest X-ray and Computed Tomography (CT) images for the classification of COVID, Non-COVID, Normal, Pneumonia, and Lung Opacity conditions. The results demonstrate state-of-the-art performance with 5-fold cross-validation mean accuracies of 96.87 %, 96.50 %, 99.70 %, and 99.55 % for the respective datasets, marking significant improvements over existing methods. Among various CNN architectures tested, DenseNet-121 proved to be the most effective, offering superior accuracy with fewer parameters. Given the pressing global challenge posed by the COVID-19 pandemic, CIDSTL-Net holds significant potential to aid medical practitioners in the rapid and accurate classification of COVID-19 cases.},
  archive      = {J_EAAI},
  author       = {Marut Jindal and Birmohan Singh},
  doi          = {10.1016/j.engappai.2025.110583},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110583},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Class imbalance-aware domain specific transfer learning approach for medical image classification: Application on COVID-19 detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent evaluation of pavement friction at high speeds
with artificial intelligence powered three-dimensional laser imaging
technology. <em>EAAI</em>, <em>150</em>, 110580. (<a
href="https://doi.org/10.1016/j.engappai.2025.110580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate non-contact pavement friction evaluation at high speeds faces many challenges when using low-resolution (LR) three-dimensional (3D) texture images or other deficient texture data. With artificial intelligence (AI) powered 0.1-mm (0.1-mm) 3D laser imaging technology, this paper proposed a two-step deep learning (DL) network, named Friction-8KNet, for accurate and intelligent non-contact pavement friction evaluation at high speeds. Particularly, a 3D laser imagining device was employed to collect LR texture images at a speed of 30 mph, which were processed via a DL-based super-resolution (SR) algorithm to obtain 0.1 mm high-resolution (HR) images with a size of 8192 × 4096 (8K) pixels. The Friction-8KNet comprises a network backbone for texture feature extraction in Step 1 and a triple attention network for friction evaluation in Step 2. The network backbone is developed to precisely extract features of an HR image without requiring large graphics processing unit (GPU) memory. The triple attention net is designed with three function-specific attention modules to utterly mine the extracted features for accurate friction prediction. Experimental results show that Friction-8KNet can achieve 99.19 % prediction accuracy and transcends models using other texture data, including small HR 3D images, LR 3D images, and two-dimensional (2D) texture profiles. This research promotes an accurate and efficient measurement of pavement friction for production level in a non-contact manner in the future.},
  archive      = {J_EAAI},
  author       = {Guolong Wang and Kelvin C.P. Wang and Guangwei Yang},
  doi          = {10.1016/j.engappai.2025.110580},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110580},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent evaluation of pavement friction at high speeds with artificial intelligence powered three-dimensional laser imaging technology},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “understanding the disparities in mathematics
performance: An interpretability-based examination” [eng. Appl. Artif.
Intell. 133 part b (2024) 108109]. <em>EAAI</em>, <em>150</em>, 110579.
(<a href="https://doi.org/10.1016/j.engappai.2025.110579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Ismael Gómez-Talal and Luis Bote-Curiel and José Luis Rojo-Álvarez},
  doi          = {10.1016/j.engappai.2025.110579},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110579},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Corrigendum to “Understanding the disparities in mathematics performance: An interpretability-based examination” [Eng. appl. artif. intell. 133 part b (2024) 108109]},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Standalone and hybrid machine learning approaches to predict
sediment load in an alluvial channel. <em>EAAI</em>, <em>150</em>,
110578. (<a
href="https://doi.org/10.1016/j.engappai.2025.110578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant amount of sediment transported in an alluvial river can alter the morphology and shape of the river. Accurate prediction of sediment load is essential in studying the change in geomorphology and dynamics of rivers and also to evaluate its impact on aquatic ecosystems, infrastructure, and human activities dependent on water resources. The present study demonstrates framework for predicting sediment load in alluvial channels using both standalone and hybrid machine learning (ML) models. Multiple datasets collected from various river surveys and flume studies were used to evaluate the significance of key variables such as friction slope ( Sf ), channel discharge ( Q ), and bed shear stress ( τ b ) affecting the sediment transport employing ML models (Bagging (BA), Random Committee (RC)) and the standalone ML models (Multi-Layer Perceptron Regression (MLPR) and Reduced Error Pruning Tree (REPT). The hybrid Bagging-REPT (BA-REPT) model outperformed other models with a Nash-Sutcliffe Efficiency (NSE) of 0.915, followed by RC-REPT (NSE = 0.906). Among the various variables, friction slope ( S f ) was identified as the most influential variable affecting sediment transport behavior. It was also observed that Hybrid models can predict sediment transport behavior more accurately as compared to standalone models and empirical equations. The findings of the study thus demonstrate the importance of hybrid learning in addressing the nonlinear complexity of sediment transport processes.},
  archive      = {J_EAAI},
  author       = {Sanjit Kumar and Vishal Deshpande and Mayank Agarwal},
  doi          = {10.1016/j.engappai.2025.110578},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110578},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Standalone and hybrid machine learning approaches to predict sediment load in an alluvial channel},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight vision transformer with embedded hybrid
attention for quick response code defect classification. <em>EAAI</em>,
<em>150</em>, 110575. (<a
href="https://doi.org/10.1016/j.engappai.2025.110575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quick Response (QR) code label printing quality is crucial to product control. Due to the limited number of defect samples, unclear features, and the need to detect a large number of labels in real time, automated visual inspection faces challenges. For efficient and accurate automated visual defect recognition of printed QR code production, we propose a lightweight Vision Transformer network, Vision Transformer with Embedded Hybrid Attention (ViT-EHA). First, the Mixed Depthwise Convolution Block (MDConvBlock) is introduced to capture QR code defect details and feature information. This method additionally reduces the number of model parameters and computational costs. Furthermore, the LeAttention-Local Convolution-Multilayer Perceptron (LeALCM) module is proposed to enhance the ability to capture global information of the model and improve the effect of minor defect recognition. Ultimately, a hybrid attention (HA) module has been integrated to enhance the processing of low-level image features and to strengthen the interplay between shallow and deep features. To verify the validity and generalization of the model, the experimental results show that the proposed ViT-EHA method achieved an accuracy of 99.00% and a parameter count of 4.198 million (M) on the self-constructed dataset Code-10 (QR Code Dataset with 10 Classes), and the accuracy reached 98.33% and 97.73% on the public datasets NEU-CLS (Northeastern University Classification Dataset) and NEU-CLS-64 (Northeastern University Classification Dataset with 64 × 64 images), respectively.},
  archive      = {J_EAAI},
  author       = {Dianlu Hu and Lun Zhao and Yu Ren and Sen Wang and Xuanlin Ye and Haohan Zhang and Changqing Peng},
  doi          = {10.1016/j.engappai.2025.110575},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110575},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight vision transformer with embedded hybrid attention for quick response code defect classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating pre-trained convolutional neural networks and
foundation models as feature extractors for content-based medical image
retrieval. <em>EAAI</em>, <em>150</em>, 110571. (<a
href="https://doi.org/10.1016/j.engappai.2025.110571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image retrieval refers to the task of finding similar images for given query images in a database, with applications such as diagnosis support. While traditional medical image retrieval relied on clinical metadata, content-based medical image retrieval (CBMIR) depends on image features, which can be extracted automatically or semi-automatically. Many approaches have been proposed for CBMIR, and among them, using pre-trained convolutional neural networks (CNNs) is a widely utilized approach. However, considering the recent advances in the development of foundation models for various computer vision tasks, their application for CBMIR can also be investigated. In this study, we used several pre-trained feature extractors from well-known pre-trained CNNs and pre-trained foundation models and investigated the CBMIR performance on eight types of two-dimensional (2D) and three-dimensional (3D) medical images. Furthermore, we investigated the effect of image size on the CBMIR performance. Our results show that, overall, for the 2D datasets, foundation models deliver superior performance by a large margin compared to CNNs, with the general-purpose self-supervised model for computational pathology (UNI) providing the best overall performance across all datasets and image sizes. For 3D datasets, CNNs and foundation models deliver more competitive performance, with contrastive learning from captions for histopathology model (CONCH) achieving the best overall performance. Moreover, our findings confirm that while using larger image sizes (especially for 2D datasets) yields slightly better performance, competitive CBMIR performance can still be achieved even with smaller image sizes. Our codes to reproduce the results are available at: https://github.com/masih4/MedImageRetrieval .},
  archive      = {J_EAAI},
  author       = {Amirreza Mahbod and Nematollah Saeidi and Sepideh Hatamikia and Ramona Woitek},
  doi          = {10.1016/j.engappai.2025.110571},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110571},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluating pre-trained convolutional neural networks and foundation models as feature extractors for content-based medical image retrieval},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal image-guided complementary masking with multiscale
fusion for multi-spectral image semantic segmentation. <em>EAAI</em>,
<em>150</em>, 110569. (<a
href="https://doi.org/10.1016/j.engappai.2025.110569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of visible and thermal image is a kind of significant method for harsh environments. Most existing works focus on designing a multi-modal feature fusion module. However, these works may result in over-dependence on a specific modality and a lack of consideration for local and global context-aware information. Motivated by these issues, (1) a thermal image-guided complementary masking strategy is proposed to encourage the network to focus on regions with abundant semantic information; (2) a multi-modal fusion module is developed to integrate both local and global information and ensure consistency for semantic segmentation; (3) a self-distillation loss between unmasked and masked input modalities is introduced to enhance the robustness and consistency of the network. Particularly, the proposed masking strategy can force the network to concentrate on the meaningful area in all modalities, and thus the network can enhance the ability to connect context information. Experimental results on three public datasets demonstrate the superiority of our model.},
  archive      = {J_EAAI},
  author       = {Zeyang Chen and Mingnan Hu and Bo Chen},
  doi          = {10.1016/j.engappai.2025.110569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal image-guided complementary masking with multiscale fusion for multi-spectral image semantic segmentation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An electric vehicle sales hybrid forecasting method based on
improved sentiment analysis model and secondary decomposition.
<em>EAAI</em>, <em>150</em>, 110561. (<a
href="https://doi.org/10.1016/j.engappai.2025.110561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift proliferation of electric vehicles has triggered profound shifts in consumer behavior, emphasizing the critical role of precise sales forecasts as the cornerstone for data-driven policy and production planning by both governments and electric vehicle manufacturers. However, extant forecasting models face challenges in accurately capturing consumer sentiment conveyed by online reviews and effectively extracting multiscale features of high-frequency sequences. Therefore, an electric vehicle sales hybrid forecasting method based on BERT-Bi-LSTM (Bidirectional Encoder Representations from Transformers-Bidirectional long short-term memory) sentiment analysis and secondary decomposition is proposed. First, the BERT-Bi-LSTM model is developed to perform sentiment analysis on online reviews. The model can better capture the relationship between each word and its surrounding words in text information. Second, a secondary decomposition model is constructed to decompose multisource data series, it can extract the seasonal components of the series and high-frequency complex data features, also solve potential issues of incomplete decomposition that may arise from a single decomposition. Finally, machine learning methods are utilized for hybrid forecasting. To verify the effectiveness of the proposed model, multiple sets of comparative experiments are conducted. The empirical results indicate the proposed model has higher prediction accuracy and robustness.},
  archive      = {J_EAAI},
  author       = {Jinpei Liu and Hui Pan and Rui Luo and Huayou Chen and Zhifu Tao and Zhijing Wu},
  doi          = {10.1016/j.engappai.2025.110561},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110561},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An electric vehicle sales hybrid forecasting method based on improved sentiment analysis model and secondary decomposition},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal explanation of nitrogen oxide emission predictions
for fluid catalytic cracking unit based on convergent cross mapping:
Predict the future and explain how. <em>EAAI</em>, <em>150</em>, 110560.
(<a href="https://doi.org/10.1016/j.engappai.2025.110560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial chemical processes are inherently intricate, characterized by prolonged operational sequences and correlations among features. Solely utilizing temporal information limits the prediction precision of deep learning methods. Moreover, causative features identified based on data may not align with the principles of chemical process. To solve these problems, this study proposes a spatial–temporal information based deep learning method, attention-based temporal graph convolutional network and convergent cross mapping (ATGCN-CCM). The devices are abstracted as nodes in a computational graph (CG) to represent the process, enabling the incorporation of spatial information into the predictive model. Attention mechanism is conducted within each node to dynamically weight the features. The CG is also used to select input features for causal analysis, ensuring that the identified causative features are not only consistent with the characteristics of the data, but also with the prior knowledge of the process. ATGCN-CCM is applied to datasets from industrial fluid catalytic cracking (FCC) units for nitrogen oxides (NOx) concentration prediction and causative feature identification. The prediction results demonstrate superior precision of ATGCN-CCM compared to some state-of-the-art spatial feature based, temporal feature based and hybrid methods. The identified features exhibit strong alignment with the principles of the chemical processes and the field experiences, thereby significantly enhancing model interpretability. The proposed ATGCN-CCM method illustrate its advanced capabilities in both precision and robustness, compared with attention-based methods and other causal analysis methods.},
  archive      = {J_EAAI},
  author       = {Han Jiang and Shucai Zhang and Jingru Liu and Xin Peng and Weimin Zhong},
  doi          = {10.1016/j.engappai.2025.110560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Causal explanation of nitrogen oxide emission predictions for fluid catalytic cracking unit based on convergent cross mapping: Predict the future and explain how},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Keypoint-guided feature enhancement and alignment for
cross-resolution vehicle re-identification. <em>EAAI</em>, <em>150</em>,
110557. (<a
href="https://doi.org/10.1016/j.engappai.2025.110557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resolution mismatch between low-resolution query images and high-resolution gallery images in vehicle re-identification is rarely studied but ubiquitous in real-world applications. An intuitive approach to solving cross-resolution vehicle re-identification is to utilize super-resolution algorithms to recover detailed information from low-resolution query images. However, vehicle super-resolution algorithms not only recover the detailed information of the vehicle but also enhance the background noise, which would degrade the re-identification performance. In addition, the view mismatch problem also significantly limits the performance of vehicle re-identification. To handle these problems, we propose a novel Keypoint Guiding Network, which simultaneously addresses the problems of resolution mismatch and view mismatch from the perspective of keypoints in an end-to-end learning framework, for cross-resolution vehicle re-identification. In particular, we first generate a set of vehicle keypoints via an effective Gaussian localization method, and then adaptively construct two keypoint-based guidances using attention models. We integrate these two guidances into vehicle super-resolution and view alignment to handle the problems of resolution mismatch and view mismatch respectively. Moreover, to alleviate the heterogeneity between super-resolution query images and high-resolution gallery ones, we design a dual-path teacher–student distillation scheme to narrow their feature distributions. Comprehensive experiments on two down-sampled benchmark datasets demonstrate the effectiveness of our Keypoint Guiding Network against the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Aihua Zheng and Longfei Zhang and Weijun Zhang and Zi Wang and Chenglong Li and Xiaofei Sheng},
  doi          = {10.1016/j.engappai.2025.110557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Keypoint-guided feature enhancement and alignment for cross-resolution vehicle re-identification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Runner system geometry prediction using variational
autoencoder deep learning model. <em>EAAI</em>, <em>150</em>, 110555.
(<a href="https://doi.org/10.1016/j.engappai.2025.110555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novelty of this article is the choice of the architecture of neural networks for fluid channel topology optimization and its application in the design of multi-cavity injection molds. A generative deep learning model was developed to extract characteristics representing the inverse field of the permeability of a fluid in a porous medium, which in turn represents the runner system geometry of a thermoplastic injection mold. The model comprises a variational autoencoder network and multilayer perceptron. The characteristics extracted from the variational autoencoder are used as a set of multilayer perceptron output vectors, whereas the input data are determined by the positions of the input and outputs of the injection channels. The field of the inverse permeability in each case was obtained by topology optimization using a heuristic algorithm. The trained model displayed statistical metrics indicating good performance and task generalizability. The mean absolute error was 0.0106 for the entire dataset. Speed up compared to traditional computational fluid dynamics software was 625 times faster in one case. For 150 cases, it was 76907 times faster⁠. The purpose of generating a deep learning model in this area is to reduce the design time of injection molds and the computational requirements. The developed neural network reduces the runner system volume by 16% or its hydraulic resistance by 25%.},
  archive      = {J_EAAI},
  author       = {Evgenii Kurkin and Jose Gabriel Quijada Pioquinto and Vladislava Chertykovtseva and Evgenii Minaev},
  doi          = {10.1016/j.engappai.2025.110555},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110555},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Runner system geometry prediction using variational autoencoder deep learning model},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection considering synergy between features based
on soft neighborhood rough sets. <em>EAAI</em>, <em>150</em>, 110553.
(<a href="https://doi.org/10.1016/j.engappai.2025.110553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood entropy-based measures provide a powerful framework for feature selection to select features that are more useful for classification. However, most of these feature selection methods do not pay attention to the complementarities and synergies between features, as well as the interactions between them. In addition, most existing neighborhood rough sets are subjective in the determination of neighborhood radius when dealing with classification problems, which may lead to the omission of useful information. To solve these problems, a soft neighborhood rough set model-based feature selection method (SNCMI) is proposed. Firstly, the method dynamically adjusts the neighborhood radius, significantly minimizing its influence on the uncertainty measurement. Secondly, it comprehensively considers the correlation, redundancy, complementarity, and synergy between features through soft neighborhood uncertainty measures. Thirdly, an innovative objective evaluation function is introduced to evaluate the interactions between features. Finally, we compare the proposed SNCMI algorithm with several well-known feature selection algorithms on twenty public datasets and demonstrate the effectiveness of SNCMI.},
  archive      = {J_EAAI},
  author       = {Lubin Chen and Jinkun Chen and Yaojin Lin},
  doi          = {10.1016/j.engappai.2025.110553},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110553},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature selection considering synergy between features based on soft neighborhood rough sets},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting train travel times of china–europe railway
express through a hybrid deep learning model optimized with a
bandit-based approach. <em>EAAI</em>, <em>150</em>, 110552. (<a
href="https://doi.org/10.1016/j.engappai.2025.110552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the globalization of economic trade, the China–Europe Railway Express (CRE) has emerged as a crucial means of international freight transportation. However, since the travel process of CRE trains is subject to various factors (e.g., customs clearance efficiency, weather changes, etc.), existing models struggle to handle the complex nonlinear characteristics of the travel time data, failing to achieve accurate train travel time predictions. This significantly affects the scheduling and utilization of capacity resources along the CRE routes. To address this issue, this study proposes a novel hybrid deep learning model, i.e., Discrete Wavelet Transform (DWT)-Convolutional Neural Networks (CNN)-Bidirectional Gated Recurrent Unit (BiGRU) (DWT-CNN-BiGRU). Specifically, the DWT technique is first used to preprocess historical train travel time data to reduce noise interference and improve data quality. Then, the CNN module focuses on extracting local spatial features from the data, whereas the BiGRU module emphasizes its long-term temporal dependencies. Furthermore, a bandit-based approach is applied to hyperparameter optimization to further exploit model potentials. By testing on a real-life CRE dataset, the DWT-CNN-BiGRU model demonstrates superior prediction accuracy with root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) values respectively equal to 10.7347 h, 7.5482 h, and 2.2034%, and it outperforms the other ten popular baseline models. In conclusion, the proposed DWT-CNN-BiGRU model features a lightweight structure and strong robustness, offering reliable technical support to alleviate capacity resource shortages and improve the service quality of CRE.},
  archive      = {J_EAAI},
  author       = {Yongxiang Zhang and Liting Gu and Jingwei Guo and Xu Yan and Xin Hu and Zhen-Song Chen},
  doi          = {10.1016/j.engappai.2025.110552},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110552},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting train travel times of China–Europe railway express through a hybrid deep learning model optimized with a bandit-based approach},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid architecture of sparse convolutional neural
network-transformer for enhanced spatial-geometric feature learning in
surface reconstruction. <em>EAAI</em>, <em>150</em>, 110550. (<a
href="https://doi.org/10.1016/j.engappai.2025.110550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based methods have garnered significant attention in indoor scene reconstruction tasks. However, researchers have often overlooked the crucial role of the surface prediction stage. Our study specifically focuses on this phase. According to our experiments and analysis, this phase primarily addresses spatial voxel occupancy and geometric structure maintenance. Simple structural designs are insufficient to effectively solve these problems. To address these challenges, we propose a hybrid model, which combines the strengths of Convolution Neural Networks and Transformer architectures for fine reconstruction. Additionally, we introduce several new techniques, including the Sparse Positional Attention mechanism, Sparse Channel Decoding Block, and Mixed Feature Fusion mechanism. These techniques, leveraging the characteristics of sparse computation, enhance feature utilization in both spatial and channel dimensions. With limited training and testing resources, our network achieves optimal results on the ScanNet dataset, improving precision and F-score by 2.1% and 1.6%, respectively, and reducing the Chamfer distance to 0.055 m. To our knowledge, our model is the first use of hybrid structures in the surface prediction phase of an indoor scene reconstruction task. Moreover, we hope that our design and analysis can provide a new paradigm for task network design in this phase.},
  archive      = {J_EAAI},
  author       = {Mingyang Li and Wei Zhang and Yanyan Liu and Xiang Feng and Changsong Liu and Yimeng Fan and Lixue Xu},
  doi          = {10.1016/j.engappai.2025.110550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid architecture of sparse convolutional neural network-transformer for enhanced spatial-geometric feature learning in surface reconstruction},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing pose estimation for mobile robots: A comparative
analysis of deep reinforcement learning algorithms for adaptive extended
kalman filter-based estimation. <em>EAAI</em>, <em>150</em>, 110548. (<a
href="https://doi.org/10.1016/j.engappai.2025.110548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Extended Kalman Filter (EKF) is a widely used algorithm for state estimation in control systems. However, its lack of adaptability limits its performance in dynamic and uncertain environments. To address this limitation, we used an approach that leverages Deep Reinforcement Learning (DRL) to achieve adaptive state estimation in the EKF. By integrating DRL techniques, we enable the state estimator to autonomously learn and update the values of the system dynamics and measurement noise covariance matrices, Q and R, based on observed data, which encode environmental changes or system failures. In this research, we compare the performance of four DRL algorithms, namely Deep Deterministic Policy Gradient (DDPG), Twin Delayed Deep Deterministic Policy Gradient (TD3), Soft Actor-Critic (SAC), and Proximal Policy Optimization (PPO), in optimizing the EKF’s adaptability. The experiments are conducted in both simulated and real-world settings using the Gazebo simulation environment and the Robot Operating System (ROS). The results demonstrate that the DRL-based adaptive state estimator outperforms traditional methods in terms of estimation accuracy and robustness. The comparative analysis provides insights into the strengths and limitations of different DRL agents, showing that the TD3 and the DDPG are the most effective algorithms, with TD3 achieving superior performance, resulting in a 91% improvement over the classic EKF, due to its delayed update mechanism that reduces training noise. This research highlights the potential of DRL to advance state estimation algorithms, offering valuable insights for future work in adaptive estimation techniques.},
  archive      = {J_EAAI},
  author       = {Islem Kobbi and Abdelhak Benamirouche and Mohamed Tadjine},
  doi          = {10.1016/j.engappai.2025.110548},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110548},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing pose estimation for mobile robots: A comparative analysis of deep reinforcement learning algorithms for adaptive extended kalman filter-based estimation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks with scattering transform for network
anomaly detection. <em>EAAI</em>, <em>150</em>, 110546. (<a
href="https://doi.org/10.1016/j.engappai.2025.110546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As cyber-attacks become increasingly sophisticated and frequent, the demand for advanced and proactive Network Intrusion Detection Systems (NIDS) has become more urgent than ever. To address critical shortcomings in existing NIDS approaches, such as high false-positive rates that trigger unnecessary alerts, inability to capture complex relationships between network nodes, and oversimplified node representation initialization that fails to reflect real-world network behaviors, we introduce a novel solution called Scattering Transform Edge Graph (STEG). STEG harnesses the wavelet scattering transform to extract edge feature information and employs a graph-based representation to effectively capture the topological relationships between network nodes. Additionally, we enhance STEG by incorporating node embedding techniques like DeepWalk for initializing node representations, moving beyond conventional uniform initialization methods. Comprehensive evaluations on benchmark NIDS datasets reveal that STEG outperforms current state-of-the-art methods. Moreover, the integration of Node2Vec-based initialization further boosts performance, marking a significant advancement in the effectiveness of network intrusion detection systems.},
  archive      = {J_EAAI},
  author       = {Abdeljalil Zoubir and Badr Missaoui},
  doi          = {10.1016/j.engappai.2025.110546},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110546},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural networks with scattering transform for network anomaly detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative analysis and evaluation of ageing forecasting
methods for semiconductor devices in online health monitoring.
<em>EAAI</em>, <em>150</em>, 110545. (<a
href="https://doi.org/10.1016/j.engappai.2025.110545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semiconductor devices, especially MOSFETs (Metal–oxide–semiconductor field-effect transistor), are crucial in power electronics, but their reliability is affected by ageing processes influenced by cycling and temperature. The primary ageing mechanism in discrete semiconductors and power modules is the bond wire lift-off, caused by crack growth due to thermal fatigue. The process is empirically characterized by exponential growth and an abrupt end of life, making long-term ageing forecasts challenging. This research presents a comprehensive comparative assessment of different forecasting methods for MOSFET failure forecasting applications. Classical tracking, statistical forecasting and Neural Network (NN) based forecasting models are implemented along with novel Temporal Fusion Transformers (TFTs). A comprehensive comparison is performed assessing their MOSFET ageing forecasting ability for different forecasting horizons. For short-term predictions, all algorithms result in acceptable results, with the best results produced by classical NN forecasting models at the expense of higher computations. For long-term forecasting, only the TFT is able to produce valid outcomes owing to the ability to integrate covariates from the expected future conditions. Additionally, TFT attention points identify key ageing turning points, which indicate new failure modes or accelerated ageing phases.},
  archive      = {J_EAAI},
  author       = {Adrian Villalobos and Iban Barrutia and Rafael Peña-Alzola and Tomislav Dragicevic and Jose I. Aizpurua},
  doi          = {10.1016/j.engappai.2025.110545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparative analysis and evaluation of ageing forecasting methods for semiconductor devices in online health monitoring},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the flexural strength and elastic modulus of
cementitious materials reinforced with carbon nanotubes: An approach
with artificial intelligence. <em>EAAI</em>, <em>150</em>, 110544. (<a
href="https://doi.org/10.1016/j.engappai.2025.110544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, researchers investigated incorporating carbon nanotubes (CNTs) to improve the mechanical properties of cementitious materials. Recently, few studies developed Machine Learning (ML)-based predictive models to maximize insights from limited experimental data. However, these models often fail to identify key parameters and their complex correlations with mechanical properties. This study aims to improve the prediction of the mechanical properties of CNT-reinforced cementitious materials, specifically, elastic modulus and flexural strength, by leveraging multiple predictive Artificial Intelligence (AI)-based models. Deep Neural Networks (DNN), ensemble-bagging, and Support Vector Regression (SVR) were proposed and rigorously tested to predict the flexural strength and elastic modulus of the composite material. The feature selection was performed based on the domain knowledge and the informative metrics including the permutation importance analyses and Pearson&#39;s correlation analyses. The research identified several parameters that have traditionally been overlooked but proved to be critical. With a total of nineteen input parameters analyzed, the findings indicate that the mechanical properties of the composite material are primarily influenced by surfactant-to-CNT mass ratio, CNT content and physical properties, as well as ultrasonication process. Conversely, sand type and CNT purity are found to have minimal importance to the change in mechanical properties. In addition, the proposed DNN models outperform other ML models in predicting both flexural strength and elastic modulus, achieving R-squared values of 0.93 and 0.86 with mean absolute percentage errors of 8.16% and 7.22%, respectively.},
  archive      = {J_EAAI},
  author       = {Mahyar Ramezani and Do-Eun Choe and Abdur Rasheed},
  doi          = {10.1016/j.engappai.2025.110544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of the flexural strength and elastic modulus of cementitious materials reinforced with carbon nanotubes: An approach with artificial intelligence},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reparameterization convolutional neural networks for
handling imbalanced datasets in solar panel fault classification.
<em>EAAI</em>, <em>150</em>, 110541. (<a
href="https://doi.org/10.1016/j.engappai.2025.110541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar photovoltaic technology has grown significantly as a renewable energy, with unmanned aerial vehicles equipped with thermal infrared cameras effectively inspecting solar panels. However, long-distance capture and low-resolution infrared cameras make the targets small, complicating feature extraction. Additionally, the large number of normal photovoltaic modules results in a significant imbalance in the dataset. Furthermore, limited computing resources on unmanned aerial vehicles further challenge real-time fault classification. These factors limit the performance of current fault classification systems for solar panels. The multi-scale and multi-branch Reparameterization of convolutional neural networks can improve model performance while reducing computational demands at the deployment stage, making them suitable for practical applications. This study proposes an efficient framework based on reparameterization for infrared solar panel fault classification. We propose a Proportional Balanced Weight asymmetric loss function to address the class imbalance and employ multi-branch, multi-scale convolutional kernels for extracting tiny features from low-resolution images. The designed models were trained with Exponential Moving Average for better performance and reparameterized for efficient deployment. We evaluated the designed models using the Infrared Solar Module dataset. The proposed framework achieved an accuracy of 83.8% for the 12-Class classification task and 74.0% for the 11-Class task, both without data augmentation to enhance generalization. The accuracy improvements of up to 16.4% and F1-Score gains of up to 18.7%. Additionally, we achieved an inference speed that is 3.4 times faster than the training speed, while maintaining high fault classification performance.},
  archive      = {J_EAAI},
  author       = {Jielong Guo and Chak Fong Chong and Pedro Henriques Abreu and Chao Mao and Jiaxuan Li and Chan-Tong Lam and Benjamin K. Ng},
  doi          = {10.1016/j.engappai.2025.110541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reparameterization convolutional neural networks for handling imbalanced datasets in solar panel fault classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain data with ransomware detection based on deep feed
forward maxout network. <em>EAAI</em>, <em>150</em>, 110538. (<a
href="https://doi.org/10.1016/j.engappai.2025.110538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of the internet and technology has become more common and essential in daily life. The main risk to the network is malware, and ransomware is considered a destructive kind of malware. The ransomware resulted in massive data losses and produced huge financial losses. In order to overcome this issue, the Deep Feed Forward Maxout Network (DFFMN) is developed to detect ransomware using blockchain data in this study. To accomplish this, initially, the input data from the blockchain is given to feature extraction to extract features. Then, data normalization is performed and the extracted features are fused together using a Deep Belief Network (DBN) with Lorentzian similarity. Lastly, ransomware detection is executed by utilizing the DFFMN technique, which is created by the integration of Deep Maxout Network and Deep Feedforward Neural Network. The experimental results exemplify that the proposed DFFMN acquired accuracy value of 91.57 %, sensitivity value of 91.04 %, precision value of 89.35 %, False Negative Rate (FNR) of 0.086, False Positive Rate (FPR) of 0.090 and F-Measure of 89.44 %.},
  archive      = {J_EAAI},
  author       = {Vemireddi Srinadh and Buddi Padmaja and Dhanunjaya Rao Chigurukota and Mallikharjuna Rao Karreddula and Balajee Maram and Smritilekha Das},
  doi          = {10.1016/j.engappai.2025.110538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Blockchain data with ransomware detection based on deep feed forward maxout network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-branch crack segmentation network with multi-shape
kernel based on convolutional neural network and mamba. <em>EAAI</em>,
<em>150</em>, 110536. (<a
href="https://doi.org/10.1016/j.engappai.2025.110536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cracks are one of the most common pavement diseases. If not promptly repaired, they will hasten the deterioration of the road. Semantic segmentation is the most convenient pavement crack detection method to assess the damage level. Convolutional neural networks (CNN) excel at extracting local spatial information, but they have limitations in capturing global contextual information. Therefore, a dual-branch crack segmentation network (DBCNet) with Mamba and multi-shape convolutional kernels is proposed. First, a dual-branch encoder is employed to extract both spatial and contextual information, consisting of the spatial branch and the context branch. The cross-like block (CrossBlock) that excels in extracting spatial information horizontally and vertically from cracks is proposed. Multiple CrossBlocks are stacked to construct a lightweight network as a spatial branch. The improved Visual State Space Model (VMamba) serves as a context branch for modeling long-range dependencies for more accurate pixel-by-pixel segmentation. Second, the Feature Fusion Module (FFM), based on squeeze-and-excitation attention, is constructed to dynamically fuse the features from the two branches layer by layer. Third, a Cross-aware Mamba Module (CMM) with the hybrid CNN-Mamba architecture is proposed to compose the decoder. Fourth, comprehensive evaluations were conducted on three public datasets. Performs on multiple metrics achieved considerable progress, outperforming the seven state-of-the-art models. The mean intersection over union (mIoU) on Deepcrack, CrackTree 260, and CFD reached 87.87%, 85.34%, and 81.35%, respectively. Code and data will be available at https://github.com/name191/DBCNet .},
  archive      = {J_EAAI},
  author       = {Jianming Zhang and Dianwen Li and Zhigao Zeng and Rui Zhang and Jin Wang},
  doi          = {10.1016/j.engappai.2025.110536},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110536},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-branch crack segmentation network with multi-shape kernel based on convolutional neural network and mamba},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FA-SconvAE-LSTM: Feature-aligned stacked convolutional
autoencoder with long short-term memory network for soft sensor
modeling. <em>EAAI</em>, <em>150</em>, 110535. (<a
href="https://doi.org/10.1016/j.engappai.2025.110535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of soft sensor technology has enabled the real-time estimation of critical parameters in complex industrial processes, where direct measurement through hardware sensors is often infeasible. Industrial process data typically exhibit both spatial correlations and temporal dependencies, necessitating sophisticated modeling approaches to capture these characteristics effectively. In this study, a spatio-temporal model, termed the feature-aligned stacked convolutional autoencoder with long short-term memory, is proposed to develop soft sensors for nonlinear dynamic industrial processes. The proposed model begins with the systematic training of a stacked convolutional autoencoder using a layer-by-layer pre-training technique. This approach facilitates the extraction of high-level spatial feature representations from the process variables. To address the issue of feature misalignment in the spatial features extracted by the stacked convolutional autoencoder, a feature alignment strategy is implemented, ensuring that the extracted spatial features are properly aligned. Subsequently, the aligned spatial features are fed into a long short-term memory network to capture temporal dependencies, with quality variables serving as the output for soft sensor development. The effectiveness and superiority of the proposed method are demonstrated through experiments conducted on two industrial processes: the sulfur recovery unit and the multiphase flow process. Comparative analyses with other state-of-the-art methods reveal that the proposed model achieves the highest performance, with R 2 values of 0.86222 for the sulfur recovery unit and 0.94307 for the multiphase flow process, outperforming all compared methods.},
  archive      = {J_EAAI},
  author       = {Ping Wu and Zengdi Miao and Ke Wang and Jinfeng Gao and Xujie Zhang and Siwei Lou and Chunjie Yang},
  doi          = {10.1016/j.engappai.2025.110535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FA-SconvAE-LSTM: Feature-aligned stacked convolutional autoencoder with long short-term memory network for soft sensor modeling},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted motion planning and layout design of
robotic cellular manufacturing systems. <em>EAAI</em>, <em>150</em>,
110530. (<a
href="https://doi.org/10.1016/j.engappai.2025.110530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A surrogate-assisted multi-objective evolutionary algorithm is proposed for simultaneous optimization of robot motion planning and layout design in robotic cellular manufacturing systems. A sequence-pair is used to represent the layout of components in a robotic cell to avoid overlapping in the evolutionary computation. The robot motion planning with Rapidly exploring Random Trees Star (RRT*) is applied to compute the total operation time of a robot arm for each layout. Non-dominated Sorting Genetic Algorithm II (NSGA-II) is used to minimize the total required layout area and the operation time for a robot arm. The proposed surrogate model can estimate the robot’s operation time with 98% of accuracy without explicit computations of the motion planning algorithm. The experimental results with a physical 6 Degree of Freedom (DOF) manipulator show that the total computation time is approximately 1/400, significantly shorter than the conventional methods.},
  archive      = {J_EAAI},
  author       = {Tomoya Kawabe and Tatsushi Nishi and Ziang Liu and Tomofumi Fujiwara},
  doi          = {10.1016/j.engappai.2025.110530},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110530},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surrogate-assisted motion planning and layout design of robotic cellular manufacturing systems},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-labeled framework with semi-supervised ball k-means
clustering-based synthetic example generation for semi-supervised
classification in industrial applications. <em>EAAI</em>, <em>150</em>,
110528. (<a
href="https://doi.org/10.1016/j.engappai.2025.110528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While self-labeled methods can exploit labeled and unlabeled instances to train classifiers, they are severely restricted by the labeled instance number and distribution. One category of the existing solutions tends to combine oversampling techniques, with the goal of creating labeled synthetic instances to improve the labeled instance number and distribution. The synthetic example generation-based framework for semi-supervised classification (SEG-SSC) is the only state-of-the-art instance of the above category. Nevertheless, it still suffers from the following issues: a) relying on 7 hyper-parameters, b) ineffectively improving the labeled instance number and distribution in sparser regions with fewer labeled instances, and c) having a relatively high time complexity of O ( nlogn + G×n ). To this end, a self-labeled framework with semi-supervised ball k -means clustering-based synthetic example generation (SEGBallKmeans-SSC), having only one hyper-parameter and the time complexity of O ( n ), is proposed for semi-supervised classification. The main uniqueness is that: a) firstly, a semi-supervised ball k -means clustering (SSBallKmeans) with a compact-cluster assumption is proposed to divide semi-supervised data into compact ball clusters, intending to reveal regions with different labeled instance numbers; b) secondly, an SSBallKmeans-based oversampling method (OMSSBallKmean) is proposed to create more labeled synthetic instances on compact ball clusters with fewer labeled instances, intending to improve the labeled instance number and distribution, especially on sparser regions with fewer labeled instances. After that, any self-labeled method are executed on improved labeled instances and unlabeled instances to train more accurate classifiers. Experiments have proven that SEGBallKmeans-SSC outperforms 7 state-of-the-art self-labeled frameworks on extensive benchmark datasets from various industrial applications.},
  archive      = {J_EAAI},
  author       = {Junnan Li and Lufeng Wang and Shun Fu ( Revision ) and Wei Fu and Xin Pan},
  doi          = {10.1016/j.engappai.2025.110528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-labeled framework with semi-supervised ball K-means clustering-based synthetic example generation for semi-supervised classification in industrial applications},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based sentiment flow analysis model for
predicting financial risk of listed companies. <em>EAAI</em>,
<em>150</em>, 110522. (<a
href="https://doi.org/10.1016/j.engappai.2025.110522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of natural language processing technology, more studies are applying deep learning models to extract features from unstructured data and predict corporate financial risk through horizontal comparisons. This paper proposes the Sentiment Flow Analysis (SFA) model designed to capture the nuanced emotional dynamics present in corporate annual reports and analyst reports from a longitudinal perspective. By leveraging advanced contextual embeddings from a Transformer architecture and employing a sophisticated recurrent neural network, the model effectively processes sequential data, allowing for a comprehensive understanding of sentiment trends over a five-year period. The effectiveness of our model was validated through experiments predicting the removal of special treatment (ST) status for 344 listed companies under special treatment in 2022 and 2023, achieving a prediction accuracy of up to 82.27%. Compared to state-of-the-art models in the same field, our model demonstrates improvements in prediction accuracy and recall, showcasing the application of Artificial Intelligence (AI) in financial risk assessment.},
  archive      = {J_EAAI},
  author       = {Feifei Tao and Wenya Wang and Rongke Lu},
  doi          = {10.1016/j.engappai.2025.110522},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110522},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning-based sentiment flow analysis model for predicting financial risk of listed companies},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient self-learning disturbance-resistant control for
high-speed flight vehicle based on dual heuristic dynamic programming.
<em>EAAI</em>, <em>150</em>, 110521. (<a
href="https://doi.org/10.1016/j.engappai.2025.110521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in high-speed flight vehicles (HSFVs) have sparked significant interest due to their strategic importance and emerging civilian applications. These vehicles exhibit strong nonlinearities and multi-axis interactions and are usually influenced by uncertainties such as modeling errors, parameter perturbations, and external disturbances. Neglecting these challenges in attitude controller design can lead to trajectory tracking deviations and potential mission failure due to instability. Motivated by this issue, an efficient disturbance-resistant control method with online self-learning capability is proposed. Firstly, a feedback linearization baseline controller combined with finite-time extended state observers (FESOs) is designed to ensure stability. Next, a dual heuristic dynamic programming (DHP) controller with critic-only structure is developed for online performance optimization. Update laws of the critic neural network (NN) are derived based on policy iteration, and zero-sum game (ZSG) theory is incorporated to enhance the system’s adaptive capacity to uncertainties. Lyapunov theory is subsequently employed to validate the convergence of network weights and the system stability. The proposed method, compared to common adaptive dynamic programming (ADP) approaches for attitude control, demonstrates superior learning efficiency and guarantees the convergence of online learning without the necessity for pre-training. Simulation results indicate that the method equips the HSFV with robust dynamic performance throughout a broad flight envelope, with attitude tracking errors constrained to less than 0.5°. Future research will focus on developing fault-tolerant and prescribed performance control frameworks with online learning ability, representing an advancement in the current technique.},
  archive      = {J_EAAI},
  author       = {Xu Huang and Jiarun Liu and Yue Peng and Yuan Zhang and Zhaolei Wang and Weimin Bao},
  doi          = {10.1016/j.engappai.2025.110521},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110521},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient self-learning disturbance-resistant control for high-speed flight vehicle based on dual heuristic dynamic programming},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remote sensing scene classification with relation-aware
dynamic graph neural networks. <em>EAAI</em>, <em>150</em>, 110513. (<a
href="https://doi.org/10.1016/j.engappai.2025.110513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing scene classification (RSSC) is challenging due to the complexity and diversity of scenes. Existing methods need help to capture long-range and structural relationships among image regions, limiting their performance. This paper proposes a novel graph-based model that learns relation-aware dynamic graph representations for remote sensing scene classification tasks. The proposed model consists of three main components: Multi-Scale Feature Extraction (MSFE), Relation-Aware Graph Processing (RAGP), and Scene Classification with Weighted Pooling (SCWP). MSFE uses a multi-scale feature extraction strategy to generate low-level feature nodes from remote sensing images. RAGP applies several cascaded graph processing blocks to dynamically learn the relations between nodes in high-level semantic spaces using relation-aware graph convolutional and node feature update operators. SCWP performs weighted pooling on the learned node features from RAGP to obtain global representations of remote sensing images and makes scene decisions using a fully feed-forward network-based classifier. We evaluate our model on three benchmark datasets and compare it with state-of-the-art RSSC methods. Our experimental results show that our model outperforms existing methods on all three datasets, demonstrating the effectiveness of a graph-based model with the proposed techniques for RSSC tasks.},
  archive      = {J_EAAI},
  author       = {Qionghao Huang and Fan Jiang and Changqin Huang},
  doi          = {10.1016/j.engappai.2025.110513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Remote sensing scene classification with relation-aware dynamic graph neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning adaptive distractor-aware-suppression appearance
model for visual tracking. <em>EAAI</em>, <em>150</em>, 110511. (<a
href="https://doi.org/10.1016/j.engappai.2025.110511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some algorithms based on Siamese networks aim to improve the representation of target by combining background and target information, but they seldom consider adjusting the influence of background distractors on appearance modeling. In this paper, we propose an adaptive distractor suppression appearance model for robust visual tracking. Firstly, to fully utilize the valuable clues provided by the background, a new distractor model is specially designed to determine the weight of each distractor based on the similarity between the distractor and the target. This model adaptively fuses the distractors according to their weights, thereby focusing on distractors that are highly similar to the target. Secondly, a distractor model transformation strategy is constructed to rank the influence of the distractor model on appearance modeling, which mines the similarity relationship between the background distractor and target using regularized linear regression, effectively controlling the influence of the distractor model. Finally, we unify them into a learning adaptive distractor-aware-suppression appearance model for improving the discriminant ability of the appearance model, which selectively introduces the distractor model to suppress distractors according to the intensity of the distractor, achieving robust tracking in the presence of background interference. Experimental results on six benchmarks demonstrate that the proposed tracker achieves excellent performance in various challenging tracking tasks, particularly when facing background interference, where the tracking precision and success rate of our algorithm reach state-of-the-art levels.},
  archive      = {J_EAAI},
  author       = {Huanlong Zhang and Linwei Zhu and Yanchun Zhao and Fusheng Li and Deshuang Huang},
  doi          = {10.1016/j.engappai.2025.110511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning adaptive distractor-aware-suppression appearance model for visual tracking},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiagent architecture for industrial internet of things
safety applications. <em>EAAI</em>, <em>150</em>, 110495. (<a
href="https://doi.org/10.1016/j.engappai.2025.110495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) is a key technological pillar of the Fourth Industrial Revolution, also known as Industry 4.0. In this context, an area of considerable interest is human safety technology. Solutions rely on multiple sensors connected to a central monitoring system and supported with software to autonomously or semi-autonomously identify safety hazards. To this end, Computer vision systems are leveraged. However, streaming continuous video from numerous sensors can strain network resources, risking timely hazard response in large industrial setups. This work proposes a reference IIoT architecture based on Multi-Agent Systems to manage safety risks. It allows for scalable sensor integration and dynamically assesses sensor input based on risk levels. To prevent network overload, the architecture uses sensor-level intelligence at the edge layer to assess situational risks and decide whether to forward video signals to a centralized local cloud agent. The central cloud agent, using strategies like ensemble learning, selectively requests additional data from distributed edge agents based on the diagnosed risk. This approach was tested in monitoring safety during aircraft assembly, showing that edge processing reduces network load by limiting unnecessary data transmission without compromising accuracy. This architecture effectively distributes processing to the edge, maintaining detection accuracy while minimizing network traffic compared to continuous centralized video transmission.},
  archive      = {J_EAAI},
  author       = {Gibson Barbosa and Djamel F.H. Sadok and Judith Kelner and Luis Ribeiro},
  doi          = {10.1016/j.engappai.2025.110495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multiagent architecture for industrial internet of things safety applications},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of end-to-end framework for contactless
fingerprint recognition: Techniques, challenges, and future directions.
<em>EAAI</em>, <em>150</em>, 110493. (<a
href="https://doi.org/10.1016/j.engappai.2025.110493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contactless fingerprint biometrics have seen rapid advancements in the recent years due to its intrinsic advantages such as resilience against latent fingerprints, and enhanced hygiene due to the absence of physical contact between a finger and the sensor. These advantages boosted the development of novel techniques for contactless fingerprint recognition. An exponentially increasing number of publications related to these developments are becoming part of the literature. However, no systematic review that consolidates these developments has been presented to date, thereby leaving a significant void. Hence, there is a need to fill this void by presenting a comprehensive review of contactless fingerprint biometric technology. A review of this kind will be highly beneficial for individuals keen on pursuing research in this domain. This study presents a systematic review of the methods used in an end-to-end framework for contactless fingerprint recognition, including acquisition, segmentation, enhancement, feature extraction, and matching, using both traditional and deep learning techniques. As per the review protocol and inclusion-exclusion criteria, 112 papers have been finally included in this review. The primary focus of the review is to present the underlying methods, their reported performance outcomes, and their strengths and weaknesses. The review evaluates the recent research findings, highlights the research issues that have been effectively addressed, presents the biases in the studies, identifies ongoing challenges that remain in the field, and provides the future research directions.},
  archive      = {J_EAAI},
  author       = {Pooja Kaplesh and Aastha Gupta and Divya Bansal and Sanjeev Sofat and Ajay Mittal},
  doi          = {10.1016/j.engappai.2025.110493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic review of end-to-end framework for contactless fingerprint recognition: Techniques, challenges, and future directions},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thoughtful and cautious reasoning: A fine-tuned knowledge
graph-based multi-hop question answering framework. <em>EAAI</em>,
<em>150</em>, 110479. (<a
href="https://doi.org/10.1016/j.engappai.2025.110479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of Knowledge Graph Question Answering (KGQA) is to find the answer entity by utilizing the Knowledge Graph (KG). Despite remarkable successes in recent years, the existing multi-hop KGQA research still faces numerous challenges. First, a multi-hop question often contains multiple entities and their relationships, and the semantic information is complex. The current methods extract the semantics of the question through an encoder that cannot completely extract the complex and rich semantic information in the multi-hop questions. Second, current question answering models use the coarse information filtering mechanism in the process of reasoning, which lead to the loss of effective information and introduce additional noise. To address these issues, we propose a Thoughtful and Cautious Reasoning framework for Knowledge Graph Question Answering (TCR-KGQA). We design a new question encoder that can extract and fully fuse the local semantic information of the question at different levels, focusing on the unique local features of the multi-hop question text. Based on the advantages of Gated Recurrent Unit (GRU) for information filtering, we propose a loop instruction update framework based on residual-GRU to effectively capture key information in the reasoning process. Extensive experiments on three broad benchmark datasets demonstrate the effectiveness of our model on KGQA tasks, and it also yields excellent results in the case of incomplete knowledge graphs with missing question–answer pairs.},
  archive      = {J_EAAI},
  author       = {Yinghao Zheng and Ling Lu and Yang Hu and Yinong Chen and Aijuan Wang},
  doi          = {10.1016/j.engappai.2025.110479},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110479},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thoughtful and cautious reasoning: A fine-tuned knowledge graph-based multi-hop question answering framework},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assist quasi-affine transformation evolutionary
for multi-objective optimization of empty train deployment on heavy-haul
railways. <em>EAAI</em>, <em>150</em>, 110475. (<a
href="https://doi.org/10.1016/j.engappai.2025.110475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms have become increasingly popular for solving expensive and time-consuming single-objective and multi-objective problems. However, in multi-objective optimization, the Pareto non-dominated solution set space can quickly become computationally intractable, making it challenging to select which samples to evaluate using the expensive fitness function. In this paper, we propose a Surrogate-Assist Quasi-Affine Transformation Evolutionary algorithm (SA-QUATRE/MO) for solving multi-objective optimization problems. The SA-QUATRE/MO algorithm uses a radial basis function network as a surrogate model to improve the speed of the algorithm operation by replacing the expensive fitness evaluation with the surrogate model. To ensure the excellence and diversity of the selected samples while keeping the archived sample space fixed, we propose a technique called Vector Space Sampling, which samples objective points in the current set of non-dominated solutions by dividing several sub-vector spaces. Additionally, we propose an uncertain sample infilling strategy to select samples for real fitness evaluation using a designed uncertainty function. We compare the SA-QUATRE/MO algorithm with three state-of-the-art algorithms for multi-objective problems in three test function suites. Finally, we applied the SA-QUATRE/MO algorithm to optimize empty train deployment in a heavy-haul railway at the loading end and build a model based on the S12 section of a specific railway. The final experimental results demonstrate the practicality and effectiveness of our proposed method.},
  archive      = {J_EAAI},
  author       = {Zhi-Gang Du and Jeng-Shyang Pan and He-Ying Xu and Shu-Chuan Chu and Shao-Quan Ni},
  doi          = {10.1016/j.engappai.2025.110475},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110475},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A surrogate-assist quasi-affine transformation evolutionary for multi-objective optimization of empty train deployment on heavy-haul railways},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating beyond the training set: A deep learning
framework for inverse design of architected composite materials.
<em>EAAI</em>, <em>150</em>, 110473. (<a
href="https://doi.org/10.1016/j.engappai.2025.110473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a deep learning (DL)-based inverse design framework for two-phase composite materials. The artificial intelligence (AI) contribution lies in the integration of Deep Convolutional Generative Adversarial Networks (DCGAN) and Convolutional Neural Networks (CNN) into a framework that enhances material discovery and design, particularly for out-of-distribution (OOD) targets. The major contribution is the development of a strategy that balances latent space exploration and optimization, achieving low design errors – below 10% – for targeted properties located in near- and extreme-OOD regions of the material property space (MPS). The engineering application focuses on designing composites with tailored linear elastic properties, accelerating inverse design and reducing reliance on traditional simulation-based approaches. An image dataset of 12,000 Representative Unit Cells (RUCs) was assembled using a parametric Voronoi diagram generator, with elastic responses computed through finite element (FE) simulations. The DCGAN generated synthetic samples with novel features not present in the original dataset, demonstrating interpolation and extrapolation capabilities. A single round of Active Learning (AL) and Transfer Learning (TL) enhanced the CNN’s predictive accuracy on synthetic data. The framework offers significant computational efficiency, with optimization complexity O ( m ⋅ n 2 ) , where m is the number of iterations and n the latent vector dimensionality. This complexity is considerably lower than that of direct FE-based topology optimization, which ranges from O ( m ⋅ N 4 ) to O ( m ⋅ N 6 ) , where N × N represents the RUC grid size. These findings demonstrate the scalability and adaptability of the framework for advanced material design and engineering applications.},
  archive      = {J_EAAI},
  author       = {José Pablo Quesada-Molina and Hossein Mofatteh and Abdolhamid Akbarzadeh and Stefano Mariani},
  doi          = {10.1016/j.engappai.2025.110473},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110473},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Navigating beyond the training set: A deep learning framework for inverse design of architected composite materials},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal buckling of graphene platelets reinforced
microplates with piezoelectric layers using artificial neural network.
<em>EAAI</em>, <em>150</em>, 110469. (<a
href="https://doi.org/10.1016/j.engappai.2025.110469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functionally graded microplates are extensively employed in advanced engineering applications, including aerospace, micro-electromechanical systems, and smart structures, due to their exceptional mechanical performance, thermal resistance, and adaptability to multifunctional environments. This study examines the thermal buckling behavior of functionally graded graphene platelet-reinforced composite microplates integrated with piezoelectric layers under externally applied voltage. The modified couple stress theory is utilized to account for micro-scale effects, and the material properties of the composite layers are determined using the Halpin-Tsai micromechanical model. The governing equations based on first shear deformation theory are solved using the Ritz method to generate training data for an artificial neural network (ANN). To address computational challenges inherent in conventional methods, an ANN-based framework, leveraging the Levenberg-Marquardt algorithm, is developed to predict the critical buckling temperature with high precision and significantly reduced computational effort. The nanofiller dimensions, weight fraction, and piezoelectric layer thickness serve as inputs, while the thermal buckling load is the output. The obtained results show that the ANN offers a significant reduction in computational time, achieving speed improvements of over 85% across all cases. Also, the ANN reliably predicts the critical buckling temperatures, achieving a maximum discrepancy of only 0.26% when compared with the Ritz method. The novelty of this work lies in combining modified couple stress theory with ANN-assisted prediction models for efficient thermal buckling analysis. This methodology offers a practical solution for the rapid and reliable design of graphene platelet-reinforced composite microplates integrated with piezoelectric layers in applications demanding high precision and performance under thermal loading.},
  archive      = {J_EAAI},
  author       = {Hongxia Liu and Qiyu Wang and Zilin Zhang},
  doi          = {10.1016/j.engappai.2025.110469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal buckling of graphene platelets reinforced microplates with piezoelectric layers using artificial neural network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization strategy for batch-stochastic configuration
network models and their application in component content prediction.
<em>EAAI</em>, <em>150</em>, 110461. (<a
href="https://doi.org/10.1016/j.engappai.2025.110461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenges of inefficiency and uncertain quality in incrementally adding hidden layer nodes to a stochastic configuration network (SCN). An optimized approach for batch-wise stochastic configuration network (BSCN) using an enhanced differential evolution (DE)algorithm is introduced. Initially, the inequality constraints of SCN is studied to analyze and establish the correlation between objective parameters and network residuals. Subsequently, to speed the network’s training velocity, a BSCN is utilized for developing the regression model. Combining the DE algorithm with regional contraction and greedy selection strategies. Specifically it leverages the robust global search prowess of the standard DE while mitigating its limitations in local search and ensuring global convergence. The formulation of this enhanced DE, termed regional contraction and greedy selection differential evolution (SGDE), is elaborated in detail, and an analysis and validation of its global convergence are conducted. Comparative experiments with the conventional DE underscore the superior optimization efficacy of SGDE. The applicability of SGDE enhanced BSCN (SGDE-BSCN) is corroborated through six real-world regression tasks. These tasks demonstrate that SGDE-BSCN not only excels in configuring hidden layer nodes but also exhibits enhanced error minimization and superior generalization capabilities with an equivalent number of hidden layer nodes. Additionally, a practical case study focused on predicting component content in rare earth extraction processes validates the effectiveness of the proposed method. The empirical results show that the application of SGDE-BSCN to artificial intelligence (AI) and artificial intelligence in the field of rare earth extraction shows high prediction accuracy and fast processing speed.},
  archive      = {J_EAAI},
  author       = {RongXiu Lu and XingRong Hu and Cong Pei and Hui Yang and WenHao Dai and JianYong Zhu},
  doi          = {10.1016/j.engappai.2025.110461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization strategy for batch-stochastic configuration network models and their application in component content prediction},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning for behavior-based driver identification.
<em>EAAI</em>, <em>150</em>, 110459. (<a
href="https://doi.org/10.1016/j.engappai.2025.110459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior-based Driver Identification is an emerging technology that recognizes drivers based on their unique driving behaviors, offering important applications such as vehicle theft prevention and personalized driving experiences. However, most studies fail to account for the real-world challenges of deploying Deep Learning models within vehicles. These challenges include operating under limited computational resources, adapting to new drivers, and changes in driving behavior over time. The objective of this study is to evaluate if Continual Learning (CL) is well-suited to address these challenges, as it enables models to retain previously learned knowledge while continually adapting with minimal computational overhead and resource requirements. We tested several CL techniques across three scenarios of increasing complexity based on a well-known dataset for the Driver Identification problem. This work provides an important step forward in scalable driver identification solutions, demonstrating that CL approaches, such as Dark Experience Replay (DER), can obtain strong performance with only an 11% reduction in accuracy compared to the static scenario. Furthermore, to enhance the performance, we propose two new methods, Smooth Experience Replay (SmooER) and Smooth Dark Experience Replay (SmooDER), that leverage the temporal continuity of driver identity over time to enhance classification accuracy. Our novel method, SmooDER, achieves optimal results with only a 2% accuracy reduction compared to the 11% of the DER approach. In conclusion, this study proves the feasibility of CL approaches to address the challenges of Driver Identification in dynamic environments, making them suitable for deployment on cloud infrastructure or directly within vehicles.},
  archive      = {J_EAAI},
  author       = {Mattia Fanan and Davide Dalle Pezze and Emad Efatinasab and Ruggero Carli and Mirco Rampazzo and Gian Antonio Susto},
  doi          = {10.1016/j.engappai.2025.110459},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110459},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continual learning for behavior-based driver identification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised contrastive representation learning for
classifying internet of things malware. <em>EAAI</em>, <em>150</em>,
110299. (<a
href="https://doi.org/10.1016/j.engappai.2025.110299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase in malware prevalence poses a substantial security threat to Internet of Things (IoT) devices. Classifying IoT malware has emerged as a crucial area, essential for identifying attack patterns and developing effective defense strategies. Many methods for classifying malware utilize supervised learning. However, supervised learning in malware classification requires a considerable amount of labeled samples, which poses challenges and costs in acquiring and labeling malware samples. Furthermore, Some malware classification models struggle to fully extract features. This article proposes a self-supervised contrastive learning framework. Initially, the malware is converted to greyscale. The encoder is then pre-trained by self-supervised contrastive learning. The encoder with the new structure is able to extract features more comprehensively, while the projection header with attention is enabled to project features into the low-dimensional space more efficiently. Finally, the pre-trained encoder and classifier are fine-tuned to form a classification model using labeled samples. Experiments have shown that the proposed method has better accuracy regardless of the number of labeled samples. Experiments conducted using the publicly benchmarked datasets, Malware Image (Malimg) and the Microsoft Malware Classification Challenge (BIG2015), demonstrate that our framework outperforms state-of-the-art deep learning models and traditional methods in terms of accuracy, with achieved rates of 99.46% and 99.22%, respectively. Using only 5% of the labels from BIG2015, the proposed framework produces an impressive accuracy of 94.76%. Furthermore, it also outperforms baseline methods in identifying evolving malware, as indicated by its accuracy of 79% in a benchmarked dataset for trustworthy malware family classification (BenchMFC-G1P1P2).},
  archive      = {J_EAAI},
  author       = {Fangwei Wang and Yinhe Chen and Hongfeng Gao and Qingru Li and Changguang Wang},
  doi          = {10.1016/j.engappai.2025.110299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised contrastive representation learning for classifying internet of things malware},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid rough aggregation approach for the selection of
artificial intelligence-based industrial cleaning robots used in public
spaces from the perspective of urban waste management. <em>EAAI</em>,
<em>150</em>, 109566. (<a
href="https://doi.org/10.1016/j.engappai.2024.109566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Waste management is becoming increasingly complex and challenging, especially in megacities with large populations. Unlike the past, when urban waste was simply collected and disposed of, modern waste management requires careful planning and execution of collection, separation, recycling, and reuse processes. Effective management of this complex system now needs more than just human effort. Integrating artificial intelligence (AI)-based systems into waste management can enhance waste reduction, reuse, and recycling effectiveness and efficiency. Selecting suitable AI-based cleaning robots (AI-ICR) for crowded public spaces, such as stations, train stations, and airports, poses complex decision-making challenges. The primary challenge is the novelty of the technology, which leads to uncertainties in selecting AI-ICRs. To address this challenge, we have developed a decision-making approach based on rough Archimedean-Dombi partitioned aggregation. This approach, termed “rough Archimedean-Dombi partitioned aggregation,” combines the flexibility of Archimedean operators, the smoothness of Dombi operators, and the structured decomposition of Partitioned operators. This model is mainly chosen for its ability to handle the uncertainty and complexity inherent in multiple criteria decision-making (MCDM) processes. Leveraging rough numbers provides a robust framework for evaluating AI-ICRs under uncertain conditions. The main advantage of this model is its robustness, consistency, stability, and ability to handle complex uncertainties. We applied the proposed model to assess four AI-ICR alternatives identified through extensive research. We evaluated these alternatives using eighteen criteria established through comprehensive field studies. Based on the results, “Recycling cost (B12)” emerged as the most crucial criterion for selecting AI-ICRs. Additionally, the research identifies the SD45 manufactured by Peppermint Robotics Co. as the optimal AI-ICR candidate. Finally, the sensitivity and benchmark analyses to validate the proposed model confirm its robustness, consistency, and reliability.},
  archive      = {J_EAAI},
  author       = {Ömer Faruk Görçün and Abhijit Saha and Pydimarri Venkata Ravi Kumar and Bijoy Krishna Debnath},
  doi          = {10.1016/j.engappai.2024.109566},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {109566},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid rough aggregation approach for the selection of artificial intelligence-based industrial cleaning robots used in public spaces from the perspective of urban waste management},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on sustainable system for managing municipal solid
waste through a multi-criteria group decision-making technique.
<em>EAAI</em>, <em>150</em>, 109393. (<a
href="https://doi.org/10.1016/j.engappai.2024.109393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Municipal solid waste management, a unique aspect of sustainable development, is a crucial social-ecological system that intersects with the economy, society, and environment. The introduction of volume-based waste fees in some developed countries has been a step towards promoting recycling and waste reduction. However, the sustainability of high recycling targets and the impact of public satisfaction on waste management efficiency are areas that demand further exploration. A review of the literature on municipal solid waste management and technology selection from various countries reveals that many studies need more precise justification and a resolution to the ambiguity in decision-making. Meanwhile, some researchers have developed the fuzzy multi-criteria decision-making technique in the context of waste management. However, significant performance criteria for ’5R’s (refuse, reduce, reuse, repurpose, recycle)’ waste management technology selection and cause-and-effect group criteria still need to be identified. This study strongly emphasizes the potential of the ’5R’s’ waste management system to revolutionize waste management practices. The ’5R’s’ waste management system uses a multi-criteria group decision-making technique using fuzzy-based artificial intelligence methods, employing the novel fuzzy technique for order of preference by similarity to the ideal solution. This study also proposes a new way to rank generalized interval type-2 trapezoidal fuzzy numbers and defuzzifies them to address the uncertainties that arise when using fuzzy linguistic terms to make decisions. Finally, a numerical example of the ’5R’s’ waste management problem is discussed with new ranking methods and compared with existing methods, underscoring the significant potential of the ’5R’s’ waste management system.},
  archive      = {J_EAAI},
  author       = {Marimuthu Dharmalingam and Daekook Kang},
  doi          = {10.1016/j.engappai.2024.109393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {109393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A study on sustainable system for managing municipal solid waste through a multi-criteria group decision-making technique},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
