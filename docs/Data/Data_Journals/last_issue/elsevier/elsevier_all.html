<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>elsevier_all</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h1 id="elsevier">ELSEVIER</h1>
<h2 id="aij---3">AIJ - 3</h2>
<ul>
<li><details>
<summary>
(2025). ICCMA 2023: 5th international competition on computational
models of argumentation. <em>AIJ</em>, <em>342</em>, 104311. (<a
href="https://doi.org/10.1016/j.artint.2025.104311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study of computational models of argumentation and the development of practical automated approaches to reasoning over the models has developed into a vibrant area of artificial intelligence research in recent years. The series of International Competitions on Computational Models of Argumentation (ICCMA) aims at nurturing research and development of practical reasoning algorithms for models of argumentation. Organized biennially, the ICCMA competitions provide a snapshot of the current state of the art in algorithm implementations for central fundamental reasoning tasks over models of argumentation. The year 2023 marked the 5th instantiation of International Competitions on Computational Models of Argumentation, ICCMA 2023. We provide a comprehensive overview of ICCMA 2023, including details on the various new developments introduced in 2023, overview of the participating solvers, extensive details on the competition benchmarks and results, as well as lessons learned.},
  archive      = {J_AIJ},
  author       = {Matti Järvisalo and Tuomo Lehtonen and Andreas Niskanen},
  doi          = {10.1016/j.artint.2025.104311},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104311},
  shortjournal = {Artif. Intell.},
  title        = {ICCMA 2023: 5th international competition on computational models of argumentation},
  volume       = {342},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lifted inference beyond first-order logic. <em>AIJ</em>,
<em>342</em>, 104310. (<a
href="https://doi.org/10.1016/j.artint.2025.104310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted First Order Model Counting (WFOMC) is fundamental to probabilistic inference in statistical relational learning models. As WFOMC is known to be intractable in general (#P-complete), logical fragments that admit polynomial time WFOMC are of significant interest. Such fragments are called domain liftable . Recent works have shown that the two-variable fragment of first order logic extended with counting quantifiers (C 2 ) is domain-liftable. However, many properties of real-world data, like acyclicity in citation networks and connectivity in social networks, cannot be modeled in C 2 , or first order logic in general. In this work, we expand the domain liftability of C 2 with multiple such properties. We show that any C 2 sentence remains domain liftable when one of its relations is restricted to represent a directed acyclic graph, a connected graph, a tree (resp. a directed tree) or a forest (resp. a directed forest). All our results rely on a novel and general methodology of counting by splitting . Besides their application to probabilistic inference, our results provide a general framework for counting combinatorial structures. We expand a vast array of previous results in discrete mathematics literature on directed acyclic graphs, phylogenetic networks, etc.},
  archive      = {J_AIJ},
  author       = {Sagar Malhotra and Davide Bizzaro and Luciano Serafini},
  doi          = {10.1016/j.artint.2025.104310},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104310},
  shortjournal = {Artif. Intell.},
  title        = {Lifted inference beyond first-order logic},
  volume       = {342},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). (Re)conceptualizing trustworthy AI: A foundation for change.
<em>AIJ</em>, <em>342</em>, 104309. (<a
href="https://doi.org/10.1016/j.artint.2025.104309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developers and academics have grown increasingly interested in developing “trustworthy” artificial intelligence (AI). However, this aim is difficult to achieve in practice, especially given trust and trustworthiness are complex, multifaceted concepts that cannot be completely guaranteed nor built entirely into an AI system. We have drawn on the breadth of trust-related literature across multiple disciplines and fields to synthesize knowledge pertaining to interpersonal trust, trust in automation, and risk and trust. Based on this review we have (re)conceptualized trustworthiness in practice as being both (a) perceptual, meaning that a user assesses whether, when, and to what extent AI model output is trustworthy, even if it has been developed in adherence to AI trustworthiness standards, and (b) context-dependent, meaning that a user&#39;s perceived trustworthiness and use of an AI model can vary based on the specifics of their situation (e.g., time-pressures for decision-making, high-stakes decisions). We provide our reconceptualization to nuance how trustworthiness is thought about, studied, and evaluated by the AI community in ways that are more aligned with past theoretical research.},
  archive      = {J_AIJ},
  author       = {Christopher D. Wirz and Julie L. Demuth and Ann Bostrom and Mariana G. Cains and Imme Ebert-Uphoff and David John Gagne II and Andrea Schumacher and Amy McGovern and Deianna Madlambayan},
  doi          = {10.1016/j.artint.2025.104309},
  journal      = {Artificial Intelligence},
  month        = {5},
  pages        = {104309},
  shortjournal = {Artif. Intell.},
  title        = {(Re)Conceptualizing trustworthy AI: A foundation for change},
  volume       = {342},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="amc---13">AMC - 13</h2>
<ul>
<li><details>
<summary>
(2025). Game strategy analysis on e-commerce platform supply chain
with shared logistics service: A chaos perspective. <em>AMC</em>,
<em>499</em>, 129414. (<a
href="https://doi.org/10.1016/j.amc.2025.129414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study explores a distinctive scenario within the e-commerce platform supply chain. To assess the performance of these entities, we develop models for both centralized and decentralized decision-making frameworks. Furthermore, we investigate the stability and dynamic behavior of the system during prolonged decentralized model interactions. We found that centralized decision-making has a significant advantage in terms of retail prices and profits within this supply chain. Additionally, the dynamic complexity analysis underscores the challenges of managing an e-commerce supply chain under the decentralized model framework, where finding equilibrium points for decision variables proves complex and the stable ranges for these parameters are notably limited. Higher commission rates incentivize entities to adopt more aggressive strategies, with the most pronounced impact on logistics services and wholesale prices. This adjustment can lead to a substantial decrease in platform profit when the commission rate is raised.},
  archive      = {J_AMC},
  author       = {Yuanyuan Zhang and Shaochuan Fu and Shucheng Fan and Fangfang Ma},
  doi          = {10.1016/j.amc.2025.129414},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129414},
  shortjournal = {Appl. Math. Comput.},
  title        = {Game strategy analysis on E-commerce platform supply chain with shared logistics service: A chaos perspective},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anti-windup design for networked time-delay systems subject
to saturating actuators under round-robin protocol. <em>AMC</em>,
<em>499</em>, 129413. (<a
href="https://doi.org/10.1016/j.amc.2025.129413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the anti-windup design for networked time-delay systems subject to saturating actuators under the round-robin protocol. Firstly, the actual measurement output is represented by the model that is dependent on a periodic function. Then, using the generalized delay-dependent sector condition, the augmented periodic Lyapunov-Krasovskii functional together with certain inequalities, an anti-windup design criterion is derived based on linear matrix inequalities under which the closed-loop systems have the desirable properties such as boundedness, H ∞ performance, and asymptotic stability. The corresponding results are also presented for the case of constant delay and the case of no time delay. Moreover, the relevant optimizations in the main results are discussed. In the end, two numerical examples illustrate the availability and advantages of the proposed results.},
  archive      = {J_AMC},
  author       = {Yonggang Chen and Yaxue Zhao and Zhou Gu and Xinfen Yang},
  doi          = {10.1016/j.amc.2025.129413},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129413},
  shortjournal = {Appl. Math. Comput.},
  title        = {Anti-windup design for networked time-delay systems subject to saturating actuators under round-robin protocol},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Variable-coefficient BDF methods with fully-geometric grid
for linear nonhomogeneous neutral pantograph equations. <em>AMC</em>,
<em>499</em>, 129412. (<a
href="https://doi.org/10.1016/j.amc.2025.129412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with numerical computation and analysis for the initial value problems (IVPs) of linear nonhomogeneous neutral pantograph equations. For solving this kind of IVPs, a class of extended k -step variable-coefficient backward differentiation formula (BDF) methods with fully-geometric grid are constructed. It is proved under the suitable conditions that an extended k -step variable-coefficient BDF method can arrive at k -order accuracy and is asymptotically stable. With a series of numerical experiments, the computational effectiveness and theoretical results of the presented methods are further confirmed.},
  archive      = {J_AMC},
  author       = {Zhixiang Jin and Chengjian Zhang},
  doi          = {10.1016/j.amc.2025.129412},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129412},
  shortjournal = {Appl. Math. Comput.},
  title        = {Variable-coefficient BDF methods with fully-geometric grid for linear nonhomogeneous neutral pantograph equations},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nonlinear immersed boundary method for weighted compact
nonlinear schemes. <em>AMC</em>, <em>499</em>, 129410. (<a
href="https://doi.org/10.1016/j.amc.2025.129410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weighted compact nonlinear schemes are a class of high-order finite difference schemes that are widely used in applications. The schemes are flexible in the choice of numerical fluxes. When applied to complex configurations, curvilinear grids are often applied, where the symmetric conservative metric method can be used to ensure geometric conservation laws. However, for complex configurations it may be difficult to generate high quality curvilinear grids. Thus, we confine the study in this paper to Cartesian grids and develop a nonlinear immersed boundary method to deal with the boundary. The developed method is applicable to different kinds of boundary conditions. In addition, compared with the traditional immersed boundary method, this new method can handle problems with shocks near boundary. Both one- and two-dimensional cases are studied into details, with corresponding numerical results showing the validity of the proposed method.},
  archive      = {J_AMC},
  author       = {Tianchu Hao and Yaming Chen and Lingyan Tang and Songhe Song},
  doi          = {10.1016/j.amc.2025.129410},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129410},
  shortjournal = {Appl. Math. Comput.},
  title        = {A nonlinear immersed boundary method for weighted compact nonlinear schemes},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential stabilization for spatial multiple-fractional
advection-diffusion-reaction system. <em>AMC</em>, <em>499</em>, 129409.
(<a href="https://doi.org/10.1016/j.amc.2025.129409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential stabilization for spatial multiple-fractional advection-diffusion-reaction system (SMFADRS) is considered, and for the disturbed SMFADRS, the finite-time H ∞ stabilization is investigated. To ensure the considered system to achieve the desired performance, a distributed controller is designed to be located in the sub-intervals of the whole spatial domain. Then, by deriving an improved fractional Poincare&#39;s inequality and resorting to the Lyapunov functional method, the sufficient criteria of exponential stability and finite-time H ∞ performance are obtained. Besides, we also explore the effect of the space domain and its division, the control gain, the distribution of controller and the fractional order on the stability. Moreover, we apply the obtained theoretical results to address the control problem of the groundwater pollution, and the corresponding numerical simulations are performed to show the effectiveness of our results.},
  archive      = {J_AMC},
  author       = {Xing-Yu Li and Kai-Ning Wu and Zhan-Wen Yang},
  doi          = {10.1016/j.amc.2025.129409},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129409},
  shortjournal = {Appl. Math. Comput.},
  title        = {Exponential stabilization for spatial multiple-fractional advection-diffusion-reaction system},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral properties of flipped toeplitz matrices and
computational applications. <em>AMC</em>, <em>499</em>, 129408. (<a
href="https://doi.org/10.1016/j.amc.2025.129408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the spectral properties of flipped Toeplitz matrices of the form H n ( f ) = Y n T n ( f ) , where T n ( f ) is the n × n Toeplitz matrix generated by the function f and Y n is the n × n exchange (or flip) matrix having 1 on the main anti-diagonal and 0 elsewhere. In particular, under suitable assumptions on f , we establish an alternating sign relationship between the eigenvalues of H n ( f ) , the eigenvalues of T n ( f ) , and the quasi-uniform samples of f . Moreover, after fine-tuning a few known theorems on Toeplitz matrices, we use them to provide localization results for the eigenvalues of H n ( f ) . Our study is motivated by the convergence analysis of the minimal residual (MINRES) method for the solution of real non-symmetric Toeplitz linear systems of the form T n ( f ) x = b after pre-multiplication of both sides by Y n , as suggested by Pestana and Wathen [26] . A selection of numerical experiments is provided to illustrate the theoretical results and to show how to use the spectral localizations for predicting the MINRES performance on linear systems with coefficient matrix H n ( f ) .},
  archive      = {J_AMC},
  author       = {Giovanni Barbarino and Sven-Erik Ekström and Carlo Garoni and David Meadon and Stefano Serra-Capizzano and Paris Vassalos},
  doi          = {10.1016/j.amc.2025.129408},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129408},
  shortjournal = {Appl. Math. Comput.},
  title        = {Spectral properties of flipped toeplitz matrices and computational applications},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Observer-based finite-time h∞ fault-tolerant control for
uncertain markov jump systems against generally bounded transition
probabilities via two-step dynamic event-triggered approach.
<em>AMC</em>, <em>499</em>, 129407. (<a
href="https://doi.org/10.1016/j.amc.2025.129407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of finite-time H ∞ fault-tolerant control for uncertain Markov jump systems with generally bounded transition probabilities using a two-step dynamic event-triggered approach. A novel framework is proposed to optimize data transmission and improve fault tolerance via this approach. First, a dynamic event-triggered mechanism and an observer are introduced where a virtual observer is designed to enhance accuracy and mitigate fault impact. The actual H ∞ observer is then constructed by processing unmeasurable information. Second, based on the obtained estimates, a co-design method for the dynamic event-triggered mechanism and the H ∞ fault-tolerant controller is developed. Finally, comparative experiments and two simulation examples validate the effectiveness and superiority of the proposed method.},
  archive      = {J_AMC},
  author       = {Guochen Pang and Xiang Pan and Xiangyong Chen and Jinde Cao and Yang Liu and Jianlong Qiu},
  doi          = {10.1016/j.amc.2025.129407},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129407},
  shortjournal = {Appl. Math. Comput.},
  title        = {Observer-based finite-time h∞ fault-tolerant control for uncertain markov jump systems against generally bounded transition probabilities via two-step dynamic event-triggered approach},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A co-evolutionary model of information, behavior, and
epidemics in multiplex networks: Incorporating subjective and objective
factors. <em>AMC</em>, <em>499</em>, 129406. (<a
href="https://doi.org/10.1016/j.amc.2025.129406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dissemination of information and the adoption of immunization behaviors are vital for preventing infection during epidemics. Positive and negative information have different influences on the decision to accept immunization behaviors, and individuals make decisions about whether to accept immunization based on both subjective cognizance and objective environmental factors. A three-layer propagation model is proposed to explore the co-evolutionary dynamics of competitive information, immunization behavior, and epidemics in multiplex networks. We consider the competitive transmission of positive and negative information under the effect of individual cognitive preference and the effect of the subjective cognizance and objective environmental factors. For the objective environmental factors, the Prospect Theory is introduced to describe the risk-related costs. Furthermore, we investigate the local group immunity phenomenon. Utilizing the MMCA (microscopic Markov chain approach) for theoretical analysis, our findings indicate that the dynamics of epidemic transmission can indeed undergo multi-stage phase transitions when there exists a competing propagation of positive and negative information. Improving individual cognitive preference for positive information is essential for making the right judgments when engaging in the immunization game process and reducing the epidemic transmission scale. In addition, individuals are encouraged to reduce the free-rider strategy and adopt immunization behavior timely during epidemic transmission, as this contributes to overall emergency management.},
  archive      = {J_AMC},
  author       = {Yue Yu and Liang&#39;an Huo},
  doi          = {10.1016/j.amc.2025.129406},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129406},
  shortjournal = {Appl. Math. Comput.},
  title        = {A co-evolutionary model of information, behavior, and epidemics in multiplex networks: Incorporating subjective and objective factors},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Proper conflict-free 6-coloring of planar graphs without
short cycles. <em>AMC</em>, <em>499</em>, 129405. (<a
href="https://doi.org/10.1016/j.amc.2025.129405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A proper conflict-free l -coloring of a graph G is a proper l -coloring satisfying that for any non-isolated vertex v ∈ V ( G ) , there exists a color appearing exactly once in N G ( v ) . The proper conflict-free chromatic number, denoted by χ p c f ( G ) , is the minimal integer l so that G admits a proper conflict-free l -coloring. This notion was proposed by Fabrici et al. in 2022. They focus mainly on proper conflict-free coloring of outerplanar graphs and planar graphs. They constructed a planar graph that has no proper conflict-free 5-coloring and conjectured every planar graph G has χ p c f ( G ) ≤ 6 . In this paper, we confirm this conjecture for planar graphs without cycles of lengths 3, 5 or 6.},
  archive      = {J_AMC},
  author       = {Yunlong Wang and Weifan Wang and Runrun Liu},
  doi          = {10.1016/j.amc.2025.129405},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129405},
  shortjournal = {Appl. Math. Comput.},
  title        = {Proper conflict-free 6-coloring of planar graphs without short cycles},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A macroscopic pedestrian model with variable maximal
density. <em>AMC</em>, <em>499</em>, 129404. (<a
href="https://doi.org/10.1016/j.amc.2025.129404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a novel macroscopic (fluid dynamics) model for describing pedestrian flow in low and high density regimes. The model is characterized by the fact that the maximal density reachable by the crowd – usually a fixed model parameter – is instead a state variable. To do that, the model couples a conservation law, devised as usual for tracking the evolution of the crowd density, with a Burgers-like PDE with a nonlocal term describing the evolution of the maximal density. The variable maximal density is used here to describe the effects of the psychological/physical pushing forces which are observed in crowds during competitive or emergency situations. Specific attention is also dedicated to the fundamental diagram, i.e., the function which expresses the relationship between crowd density and flux. Although the model needs a well defined fundamental diagram as known input parameter, it is not evident a priori which relationship between density and flux will be actually observed, due to the time-varying maximal density. An a posteriori analysis shows that the observed fundamental diagram has an elongated “tail” in the congested region, thus resulting similar to the concave/concave fundamental diagram with a “double hump” observed in real crowds. The main features of the model are investigated through 1D and 2D numerical simulations. The numerical code for the 1D simulation is freely available on this Gitlab repository .},
  archive      = {J_AMC},
  author       = {Laura Bartoli and Simone Cacace and Emiliano Cristiani and Roberto Ferretti},
  doi          = {10.1016/j.amc.2025.129404},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129404},
  shortjournal = {Appl. Math. Comput.},
  title        = {A macroscopic pedestrian model with variable maximal density},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Isospectral reductions of non-negative matrices.
<em>AMC</em>, <em>499</em>, 129402. (<a
href="https://doi.org/10.1016/j.amc.2025.129402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Isospectral reduction is an important tool for network/matrix analysis as it reduces the dimension of a matrix/network while preserving its eigenvalues and eigenvectors. The main contribution of this manuscript is a proposed algorithmic scheme to approximate the stationary measure of a stochastic matrix based on isospectral reductions. We run numerical experiments that indicate this scheme is advantageous when there is more than one eigenvalue near 1, precisely the case where iterative methods perform poorly. We give a partial explanation why this scheme should work well, showing that in some situations isospectral reduction improves the spectral gap.},
  archive      = {J_AMC},
  author       = {Alexandre Baraviera and Pedro Duarte and Longmei Shu and Maria Joana Torres},
  doi          = {10.1016/j.amc.2025.129402},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129402},
  shortjournal = {Appl. Math. Comput.},
  title        = {Isospectral reductions of non-negative matrices},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularized directional do-nothing boundary conditions for
the navier-stokes equations: Analytical and numerical study.
<em>AMC</em>, <em>499</em>, 129398. (<a
href="https://doi.org/10.1016/j.amc.2025.129398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the steady 2D and 3D Navier-Stokes equations with homogeneous mixed boundary conditions and the action of an external force. The classical do-nothing (CDN) boundary condition is replaced by a regularized directional do-nothing (RDDN) condition which depends on a parameter 0 &lt; δ ≪ 1 . After establishing the well-posedness of the Navier-Stokes equations with RDDN condition, we prove the convergence, as δ → 0 , to the solution of the Navier-Stokes equations with directional do-nothing (DDN) condition. The use of the RDDN condition in comparison with the CDN and DDN conditions is illustrated with 2D numerical simulations. The theoretical convergence result as δ → 0 is also confirmed by our numerical results.},
  archive      = {J_AMC},
  author       = {Pedro Nogueira and Ana L. Silvestre},
  doi          = {10.1016/j.amc.2025.129398},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129398},
  shortjournal = {Appl. Math. Comput.},
  title        = {Regularized directional do-nothing boundary conditions for the navier-stokes equations: Analytical and numerical study},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of time-varying validity of individual interaction on
co-evolution of awareness and epidemics in a multiplex high-order
network. <em>AMC</em>, <em>499</em>, 129396. (<a
href="https://doi.org/10.1016/j.amc.2025.129396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individual interactions play a crucial role in the co-evolution process of awareness and epidemics; these interactions involve pairwise and higher-order types. Previous research usually assumed that individual interactions are all valid and static, overlooking the fact that some interactions may be invalid and time-varying. Notably, diffusion phenomena cannot occur if interactions lose their validity. To address this gap, a novel coupled model is proposed to study the effect of time-varying interaction validity on the co-evolution of awareness and epidemics in a multiplex high-order network. Individual activity and life-cycle theory are employed to model the time-varying validity of interactions, which is further characterized using threshold functions. Simulation experiments reveal that increasing individual activity will increase the validity of interactions, which then leads to the prevalence of epidemics. In addition, maximizing epidemic control can be achieved by increasing activity in the virtual layer while reducing activity in the physical layer. Moreover, the results in more densely interacted communities suggest that more stringent control measures are required to bring the epidemic to extinction.},
  archive      = {J_AMC},
  author       = {Ming Li and Liang&#39;an Huo},
  doi          = {10.1016/j.amc.2025.129396},
  journal      = {Applied Mathematics and Computation},
  month        = {8},
  pages        = {129396},
  shortjournal = {Appl. Math. Comput.},
  title        = {Effect of time-varying validity of individual interaction on co-evolution of awareness and epidemics in a multiplex high-order network},
  volume       = {499},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="artmed---13">ARTMED - 13</h2>
<ul>
<li><details>
<summary>
(2025). Sum of similarity-regularized squared correlations for
enhancing SSVEP detection. <em>ARTMED</em>, <em>162</em>, 103100. (<a
href="https://doi.org/10.1016/j.artmed.2025.103100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain-computer interface (BCI) provides a direct control pathway between human brain and external devices. Steady-state visual evoked potential based BCI (SSVEP-BCI) has been proven to be a valuable solution due to its advantages of high information transfer rate (ITR) and minimal calibration requirement. Recently, some methods have been proposed based on calibration-training techniques to compute optimal spatial filters from covariances, and have achieved good detection performance. However, these methods ignore the temporally-varying and spatially-coupled characteristics of the EEG signals, which is essentially an important clue for enhancing ITR. More importantly, existing methods cannot well deal with intrinsic noise components of electroencephalogram (EEG) signals, greatly affecting their detection performance. In this paper, we propose a novel method, termed as S um of S imilarity- R egularized S quared C orrelations (SSRSC), which is extended and regularized from the sum of squared correlations. We simultaneously compute the squared correlations for both calibration data and sine-cosine harmonics templates, and mitigate variations by the similarity regularization. Moreover, we extend the SSRSC by adopting the ranking weighted ensemble strategy, termed as weSSCOR. Extensive experiments have been conducted on two benchmark SSVEP datasets, and the results demonstrated that the proposed SSRSC/weSSRSC can significantly improve accuracy and ITR of SSVEP detection with less calibration data, which has great potential in designing high ITR SSVEP-BCIs with less calibration efforts.},
  archive      = {J_ARTMED},
  author       = {Tian-jian Luo and Tao Wu},
  doi          = {10.1016/j.artmed.2025.103100},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103100},
  shortjournal = {Artif. Intell. Med.},
  title        = {Sum of similarity-regularized squared correlations for enhancing SSVEP detection},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TDMFS: Tucker decomposition multimodal fusion model for
pan-cancer survival prediction. <em>ARTMED</em>, <em>162</em>, 103099.
(<a href="https://doi.org/10.1016/j.artmed.2025.103099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated analysis of multimodal data offers a more comprehensive view for cancer survival prediction, yet it faces challenges like computational intensity, overfitting, and challenges in achieving a unified representation due to data heterogeneity. To address the above issues, the first Tucker decomposition multimodal fusion model was hereby proposed for pan-cancer survival prediction (TDMFS). The model employed Tucker decomposition to limit complex tensor parameters during fusion, achieving deep modality integration with reduced computational cost and lower overfitting risk. The individual modality-specific representations were then fully exploited by signal modulation mechanisms in a bilinear pooling decomposition to serve as complementary information for the deep fusion representation. Furthermore, the performance of TDMFS was evaluated using a 5-fold cross-validation method with two modal data, gene expression (GeneExpr), and copy number variation (CNV), for 33 cancers from The Cancer Genome Atlas (TCGA) database. The experiments demonstrated that the proposed TDMFS model achieved an average C-index of 0.757 across 33 cancer datasets, with a C-index exceeding 0.80 on 10 of these datasets. Survival curves for both high and low risk patients plotted on 27 cancer datasets were statistically significant. The TDMFS model demonstrated superior performance in survival prediction, outperforming models like LinearSum and Multimodal Factorisation Higher Order Pooling, making it a valuable asset for advancing clinical cancer research.},
  archive      = {J_ARTMED},
  author       = {Jinchao Chen and Pei Liu and Chen Chen and Ying Su and Enguang Zuo and Min Li and Jiajia Wang and Ziwei Yan and Xinya Chen and Cheng Chen and Xiaoyi Lv},
  doi          = {10.1016/j.artmed.2025.103099},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103099},
  shortjournal = {Artif. Intell. Med.},
  title        = {TDMFS: Tucker decomposition multimodal fusion model for pan-cancer survival prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint segmentation of retinal layers and fluid lesions in
optical coherence tomography with cross-dataset learning.
<em>ARTMED</em>, <em>162</em>, 103096. (<a
href="https://doi.org/10.1016/j.artmed.2025.103096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and objectives Age-related macular degeneration (AMD) is the leading cause of irreversible vision loss among people over 50 years old, which manifests in the retina through various changes of retinal layers and pathological lesions. The accurate segmentation of optical coherence tomography (OCT) image features is crucial for the identification and tracking of AMD. Although the recent developments in deep neural network have brought profound progress in this area, accurately segmenting retinal layers and pathological lesions remains a challenging task because of the interaction between these two tasks. Methods In this study, we propose a three-branch, hierarchical multi-task framework that enables joint segmentation of seven retinal layers and three types of pathological lesions. A regression guidance module is introduced to provide explicit shape guidance between sub-tasks. We also propose a cross-dataset learning strategy to leverage public datasets with partial labels. The proposed framework was evaluated on a clinical dataset consisting of 140 OCT B-scans with pixel-level annotations of seven retinal layers and three types of lesions. Additionally, we compared its performance with the state-of-the-art methods on two public datasets. Results Comprehensive ablation showed that the proposed hierarchical architecture significantly improved performance for most retinal layers and pathological lesions, achieving the highest mean DSC of 76.88 %. The IRF also achieved the best performance with a DSC of 68.15 %. Comparative studies demonstrated that the hierarchical multi-task architecture could significantly enhance segmentation accuracy and outperform state-of-the-art methods. Conclusion The proposed framework could also be generalized to other medical image segmentation tasks with interdependent relationships.},
  archive      = {J_ARTMED},
  author       = {Xiayu Xu and Hualin Wang and Yulei Lu and Hanze Zhang and Tao Tan and Feng Xu and Jianqin Lei},
  doi          = {10.1016/j.artmed.2025.103096},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103096},
  shortjournal = {Artif. Intell. Med.},
  title        = {Joint segmentation of retinal layers and fluid lesions in optical coherence tomography with cross-dataset learning},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised learning from EEG data for epilepsy: A
systematic literature review. <em>ARTMED</em>, <em>162</em>, 103095. (<a
href="https://doi.org/10.1016/j.artmed.2025.103095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and objectives Epilepsy is a neurological disorder characterized by recurrent epileptic seizures, whose neurophysiological signature is altered electroencephalographic (EEG) activity. The use of artificial intelligence (AI) methods on EEG data can positively impact the management of the disease, significantly improving diagnostic and prognostic accuracy as well as treatment outcomes. Our work aims to systematically review the available literature on the use of unsupervised machine learning methods on EEG data in epilepsy, focusing on methodological and clinical differences in terms of algorithms used and clinical applications. Methods Following the PRISMA guidelines, a systematic literature search was performed in several databases for papers published in the last 10 years. Studies employing both unsupervised and self-supervised methods for the classification of EEG data in epilepsy patients were included. The main outcomes of the study were: (i) to provide an overview of the datasets used as input to train the algorithms; (ii) to identify trends in pre-processing, algorithm architectures, validation, and metrics for performance estimation; (iii) to identify and review the clinical applications of AI in epilepsy patients. Results A total of 108 studies met the inclusion criteria. Of them, 86 (79.6 %) have been published in the last 5 years and 60 (55.5 %) in the last two years. The most used validation methods were: hold-out in 37 (34.2 %), k-fold-cross validation in 35 (32.4 %), and leave-one-out in 19 (17.6 %) studies, respectively. Accuracy, sensitivity, and specificity were the most used performance metrics being reported in 71 (65.7 %), 62 (57.4 %), and 42 (39.8 %) studies, respectively, followed by F1-score (27 studies; 25 %), precision (26 studies; 24 %), area under the curve (25 studies; 23.1 %), and false positive rate (22 studies; 20.3 %). Furthermore, 42 (38.9 %) compared to 63 (58.3 %) studies used individual patient versus multiple patients models, respectively. Finally, concerning the clinical applications of unsupervised learning methods on epilepsy patients, we identified six main fields of interest: seizure detection (69 studies; 63.9 %), seizure prediction (27 studies; 25 %), signal propagation and characterization (2 studies; 1.8 %), seizure localization (4 studies; 3.7 %), and seizure classification (22 studies; 20.3 %), respectively. Conclusion The results of this review suggest that the interest in the use of unsupervised learning methods in epilepsy has significantly increased in recent years. From a methodological perspective, the input EEG datasets used for training and testing the algorithms remain the hardest challenge. From a clinical standpoint, the vast majority of studies addressed seizure detection, prediction, and classification whereas studies focusing on seizure characterization and localization are lacking. Future work that can potentially improve the performance of these algorithms includes the use of context information via reinforcement learning and a focus on model explainability.},
  archive      = {J_ARTMED},
  author       = {Alexandra-Maria Tautan and Alexandra-Georgiana Andrei and Carmelo Luca Smeralda and Giampaolo Vatti and Simone Rossi and Bogdan Ionescu},
  doi          = {10.1016/j.artmed.2025.103095},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103095},
  shortjournal = {Artif. Intell. Med.},
  title        = {Unsupervised learning from EEG data for epilepsy: A systematic literature review},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDMentor: A virtual reality-based intelligent tutoring
system for surgical decision making in dentistry. <em>ARTMED</em>,
<em>162</em>, 103092. (<a
href="https://doi.org/10.1016/j.artmed.2025.103092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background While VR simulation has already had a significant impact on training of psychomotor surgical skills, there is still a lack of work on the use of VR simulation to teach surgical decision making. Since surgical decision making is a cognitive process, a simulation for teaching it must be able to not only accurately simulate the surgical environment but to also represent and reason about the cognitive aspects involved. Materials and methods This paper presents and evaluates SDMentor, a virtual training environment that integrates high-fidelity VR simulation with an intelligent tutoring system for teaching surgical decision making in dentistry. SDMentor provides a virtual dental operating room with 3D stereoscopic graphics and with haptic feedback to realistically render the interaction of dental tools with the patient teeth. The intelligent tutor evaluates the student&#39;s actions and generates a variety of tutorial feedback. To evaluate the teaching effectiveness of the system, we carried out a randomized controlled trial in the domain of root canal treatment. Results In all three aspects of scores: situation awareness ability, procedural knowledge, and overall performance; the post-test scores showed significant improvement over the pre-test scores of students in the same group ( P &lt; .05). The students from the experimental group had significantly higher learning gains than the students in the control group (P &lt; .05). Conclusions The integration of high-fidelity VR simulation with intelligent tutoring is a promising approach to teaching surgical decision making and could be useful for teaching decision making in other high-precision psychomotor tasks.},
  archive      = {J_ARTMED},
  author       = {Narumol Vannaprathip and Peter Haddawy and Holger Schultheis and Siriwan Suebnukarn},
  doi          = {10.1016/j.artmed.2025.103092},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103092},
  shortjournal = {Artif. Intell. Med.},
  title        = {SDMentor: A virtual reality-based intelligent tutoring system for surgical decision making in dentistry},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-stage multi-modal learning algorithm with adaptive
multimodal fusion for improving multi-label skin lesion classification.
<em>ARTMED</em>, <em>162</em>, 103091. (<a
href="https://doi.org/10.1016/j.artmed.2025.103091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is frequently occurring and has become a major contributor to both cancer incidence and mortality. Accurate and timely diagnosis of skin cancer holds the potential to save lives. Deep learning-based methods have demonstrated significant advancements in the screening of skin cancers. However, most current approaches rely on a single modality input for diagnosis, thereby missing out on valuable complementary information that could enhance accuracy. Although some multimodal-based methods exist, they often lack adaptability and fail to fully leverage multimodal information. In this paper, we introduce a novel uncertainty-based hybrid fusion strategy for a multi-modal learning algorithm aimed at skin cancer diagnosis. Our approach specifically combines three different modalities: clinical images, dermoscopy images, and metadata, to make the final classification. For the fusion of two image modalities, we employ an intermediate fusion strategy that considers the similarity between clinical and dermoscopy images to extract features containing both complementary and correlated information. To capture the correlated information, we utilize cosine similarity, and we employ concatenation as the means for integrating complementary information. In the fusion of image and metadata modalities, we leverage uncertainty to obtain confident late fusion results, allowing our method to adaptively combine the information from different modalities. We conducted comprehensive experiments using a popular publicly available skin disease diagnosis dataset, and the results of these experiments demonstrate the effectiveness of our proposed method. Our proposed fusion algorithm could enhance the clinical applicability of automated skin lesion classification, offering a more robust and adaptive way to make automatic diagnoses with the help of uncertainty mechanism. Code is available at https://github.com/Zuo-Lihan/CosCatNet-Adaptive_Fusion_Algorithm .},
  archive      = {J_ARTMED},
  author       = {Lihan Zuo and Zizhou Wang and Yan Wang},
  doi          = {10.1016/j.artmed.2025.103091},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103091},
  shortjournal = {Artif. Intell. Med.},
  title        = {A multi-stage multi-modal learning algorithm with adaptive multimodal fusion for improving multi-label skin lesion classification},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic multivariate feature learning in higher-order
heterogeneous networks for drug–disease prediction. <em>ARTMED</em>,
<em>162</em>, 103090. (<a
href="https://doi.org/10.1016/j.artmed.2025.103090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {New drug discovery has always been a costly, time-consuming process with a high failure rate. Repurposing existing drugs offers a valuable alternative and reduces the risks associated with developing new drugs. Various experimental methods have been employed to facilitate drug repositioning; however, associations prediction between drugs and diseases through biological experiments is both expensive and time-consuming. Consequently, it is imperative to develop efficient and highly precise computational methods for predicting these associations. Based on this, we propose a drug–disease associations prediction method based on H yperbolic M ultivariate feature L earning in H igh-order H eterogeneous Networks for Drug–Disease Prediction, called H 3 ML. Our approach begins by mining high-order information from protein–disease and drug–protein networks to construct high-order heterogeneous networks. Subsequently, we employ multivariate feature learning to create hyperbolic representations, and then enhance the features of the heterogeneous network. Finally, we utilize a hyperbolic graph attention network in the hyperbolic space to aggregate neighbor information and perform the final prediction task. In addition, we evaluate the performance of H 3 ML by comparing it with some state-of-the-art methods across different datasets. The case study further validate the effectiveness of H 3 ML. Our implementation will be publicly available at: https://github.com/jianruichen/H-3ML .},
  archive      = {J_ARTMED},
  author       = {Jiamin Li and Jianrui Chen and Junjie Huang and Xiujuan Lei},
  doi          = {10.1016/j.artmed.2025.103090},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103090},
  shortjournal = {Artif. Intell. Med.},
  title        = {Hyperbolic multivariate feature learning in higher-order heterogeneous networks for drug–disease prediction},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence-driven approaches in antibiotic
stewardship programs and optimizing prescription practices: A systematic
review. <em>ARTMED</em>, <em>162</em>, 103089. (<a
href="https://doi.org/10.1016/j.artmed.2025.103089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Antimicrobial stewardship programs (ASPs) are essential in optimizing the use of antibiotics to address the global concern of antimicrobial resistance (AMR). Artificial intelligence (AI) and machine learning (ML) have emerged as promising tools for enhancing ASPs efficiency by improving antibiotic prescription accuracy, resistance prediction, and dosage optimization. This systematic review evaluated the application of AI-driven ASPs, focusing on their methodologies, outcomes, and challenges. We searched all of the databases in PubMed, Scopus, Web of Science, and Embase using keywords related to “AI” and “antibiotic.” We only included studies that used AI and ML algorithms in ASPs, with the main criteria being empirical antibiotic selection, dose adjustment, and ASP adherence. There were no limits on time, setting, or language. Two authors independently screened studies for inclusion and assessed their risk of bias using the Newcastle Ottawa Scale (NOS) Assessment tool for observational studies. Implementation studies underscored AI&#39;s potential for improving antimicrobial stewardship programs. Two studies showed that logistic regression, boosted-tree models, and gradient-boosting machines could effectively describe the difference between patients who needed to change their antibiotic regimen and those who did not. Twenty-four studies have confirmed the role of machine learning in optimizing empirical antibiotic selection, predicting resistance, and enhancing therapy appropriateness, all of which have the potential to reduce mortality rates. Additionally, machine learning algorithms showed promise in optimizing antibiotic dosing, particularly for vancomycin. This systematic review aimed to highlight various AI models, their applications in ASPs, and the resulting impact on healthcare outcomes. Machine learning and AI models effectively enhance antibiotic stewardship by optimizing patient interventions, empirical antibiotic selection, resistance prediction, and dosing. However, it subtly draws attention to the differences between high-income countries (HICs) and low- and middle-income countries (LMICs), highlighting the structural difficulties that LMICs confront while simultaneously highlighting the progress made in HICs.},
  archive      = {J_ARTMED},
  author       = {Hamid Harandi and Maryam Shafaati and Mohammadreza Salehi and Mohammad Mahdi Roozbahani and Keyhan Mohammadi and Samaneh Akbarpour and Ramin Rahimnia and Gholamreza Hassanpour and Yasin Rahmani and Arash Seifi},
  doi          = {10.1016/j.artmed.2025.103089},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103089},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence-driven approaches in antibiotic stewardship programs and optimizing prescription practices: A systematic review},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence non-invasive methods for neonatal
jaundice detection: A review. <em>ARTMED</em>, <em>162</em>, 103088. (<a
href="https://doi.org/10.1016/j.artmed.2025.103088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neonatal jaundice is a common and potentially fatal health condition in neonates, especially in low and middle income countries, where it contributes considerably to neonatal morbidity and death. Traditional diagnostic approaches, such as Total Serum Bilirubin (TSB) testing, are invasive and could lead to discomfort, infection risk, and diagnostic delays. As a result, there is a rising interest in non-invasive approaches for detecting jaundice early and accurately. An in-depth analysis of non-invasive techniques for detecting neonatal jaundice is presented by this review, exploring several AI-driven techniques, such as Machine Learning (ML) and Deep Learning (DL), which have demonstrated the ability to enhance diagnostic accuracy by evaluating complex patterns in neonatal skin color and other relevant features. It is identified that AI models incorporating variants of neural networks achieve an accuracy rate of over 90% in detecting jaundice when compared to traditional methods. Furthermore, satisfactory outcomes in field settings have been demonstrated by mobile-based applications that use smartphone cameras to estimate bilirubin levels, providing a practical alternative for resource-constrained areas. The potential impact of AI-based solutions on reducing neonatal morbidity and mortality is evaluated by this review, with a focus on real-world clinical challenges, highlighting the effectiveness and practicality of AI-based strategies as an assistive tool in revolutionizing neonatal care through early jaundice diagnosis, while also addressing the ethical and practical implications of integrating these technologies in clinical practice. Future research areas, such as the development of new imaging technologies and the incorporation of wearable sensors for real-time bilirubin monitoring, are recommended by the paper.},
  archive      = {J_ARTMED},
  author       = {Fati Oiza Salami and Muhammad Muzammel and Youssef Mourchid and Alice Othmani},
  doi          = {10.1016/j.artmed.2025.103088},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103088},
  shortjournal = {Artif. Intell. Med.},
  title        = {Artificial intelligence non-invasive methods for neonatal jaundice detection: A review},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving unified information extraction in chinese mental
health domain with instruction-tuned LLMs and type-verification
component. <em>ARTMED</em>, <em>162</em>, 103087. (<a
href="https://doi.org/10.1016/j.artmed.2025.103087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Extracting psychological counseling help-seeker information from unstructured text is crucial for providing effective mental health support. This task involves identifying personal emotions, psychological states, and underlying psychological issues but faces significant challenges. These challenges include the sensitivity of mental health data, the lack of Chinese instruction datasets, and the difficulties large language models (LLMs) encounter with complex natural language understanding tasks. Objective: This study aims to address these challenges by developing a unified information extraction framework for Chinese mental health texts. Specifically, it leverages instruction-tuned LLMs and incorporates a novel type-verification (TV) component to improve performance while minimizing computational demands. Methods: We first constructed a Chinese mental health domain instruction dataset for mental health information extraction using synthetic data generated by ChatGPT, guided by psychology experts. This dataset includes self-reported statements from psychological counseling help-seekers, capturing their personal situations, emotions, thoughts, and experiences. Subsequently, we fine-tuned open-source LLMs on this dataset to perform named entity recognition, relation extraction, and event extraction. To address errors and omissions in the extracted information, we introduced a type-verification component. This component employs a lightweight model with significantly fewer parameters to verify the extracted types. The verification results were then fed back into LLMs for further refinement. Results: Experimental results demonstrate that our framework achieves outstanding performance in mental health information extraction. The type-verification component significantly enhances extraction accuracy while reducing computational resource requirements through the use of a lightweight model. By combining robust instruction-tuned LLMs with an efficient type-verification component, our approach delivers exceptional results. Conclusion: This study presents a novel and efficient framework for tackling the challenges of mental health information extraction in Chinese texts. By integrating instruction-tuned LLMs with a lightweight type-verification component, our approach significantly improves extraction accuracy and computational efficiency. This framework holds promise for supporting scalable, automated mental health support systems, advancing both research and practical applications in the mental health domain.},
  archive      = {J_ARTMED},
  author       = {Zijie Cai and Hui Fang and Jianhua Liu and Ge Xu and Yunfei Long and Yin Guan and Tianci Ke},
  doi          = {10.1016/j.artmed.2025.103087},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103087},
  shortjournal = {Artif. Intell. Med.},
  title        = {Improving unified information extraction in chinese mental health domain with instruction-tuned LLMs and type-verification component},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BDFormer: Boundary-aware dual-decoder transformer for skin
lesion segmentation. <em>ARTMED</em>, <em>162</em>, 103079. (<a
href="https://doi.org/10.1016/j.artmed.2025.103079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmenting skin lesions from dermatoscopic images is crucial for improving the quantitative analysis of skin cancer. However, automatic segmentation of skin lesions remains a challenging task due to the presence of unclear boundaries, artifacts, and obstacles such as hair and veins, all of which complicate the segmentation process. Transformers have demonstrated superior capabilities in capturing long-range dependencies through self-attention mechanisms and are gradually replacing CNNs in this domain. However, one of their primary limitations is the inability to effectively capture local details, which is crucial for handling unclear boundaries and significantly affects segmentation accuracy. To address this issue, we propose a novel boundary-aware dual-decoder transformer that employs a single encoder and dual-decoder framework for both skin lesion segmentation and dilated boundary segmentation. Within this model, we introduce a shifted window cross-attention block to build the dual-decoder structure and apply multi-task distillation to enable efficient interaction of inter-task information. Additionally, we propose a multi-scale aggregation strategy to refine the extracted features, ensuring optimal predictions. To further enhance boundary details, we incorporate a dilated boundary loss function, which expands the single-pixel boundary mask into planar information. We also introduce a task-wise consistency loss to promote consistency across tasks. Our method is evaluated on three datasets: ISIC2018, ISIC2017, and PH 2 , yielding promising results with excellent performance compared to state-of-the-art models. The code is available at https://github.com/Yuxuan-Ye/BDFormer .},
  archive      = {J_ARTMED},
  author       = {Zexuan Ji and Yuxuan Ye and Xiao Ma},
  doi          = {10.1016/j.artmed.2025.103079},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103079},
  shortjournal = {Artif. Intell. Med.},
  title        = {BDFormer: Boundary-aware dual-decoder transformer for skin lesion segmentation},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Empowering large language models for automated clinical
assessment with generation-augmented retrieval and hierarchical
chain-of-thought. <em>ARTMED</em>, <em>162</em>, 103078. (<a
href="https://doi.org/10.1016/j.artmed.2025.103078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Understanding and extracting valuable information from electronic health records (EHRs) is important for improving healthcare delivery and health outcomes. Large language models (LLMs) have demonstrated significant proficiency in natural language understanding and processing, offering promises for automating the typically labor-intensive and time-consuming analytical tasks with EHRs. Despite the active application of LLMs in the healthcare setting, many foundation models lack real-world healthcare relevance. Applying LLMs to EHRs is still in its early stage. To advance this field, in this study, we pioneer a generation-augmented prompting paradigm “GAPrompt” to empower generic LLMs for automated clinical assessment, in particular, quantitative stroke severity assessment, using data extracted from EHRs. Methods: The GAPrompt paradigm comprises five components: (i) prompt-driven selection of LLMs, (ii) generation-augmented construction of a knowledge base, (iii) summary-based generation-augmented retrieval (SGAR); (iv) inferencing with a hierarchical chain-of-thought (HCoT), and (v) ensembling of multiple generations. Results: GAPrompt addresses the limitations of generic LLMs in clinical applications in a progressive manner. It efficiently evaluates the applicability of LLMs in specific tasks through LLM selection prompting, enhances their understanding of task-specific knowledge from the constructed knowledge base, improves the accuracy of knowledge and demonstration retrieval via SGAR, elevates LLM inference precision through HCoT, enhances generation robustness, and reduces hallucinations of LLM via ensembling. Experiment results demonstrate the capability of our method to empower LLMs to automatically assess EHRs and generate quantitative clinical assessment results. Conclusion: Our study highlights the applicability of enhancing the capabilities of foundation LLMs in medical domain-specific tasks, i.e. , automated quantitative analysis of EHRs, addressing the challenges of labor-intensive and often manually conducted quantitative assessment of stroke in clinical practice and research. This approach offers a practical and accessible GAPrompt paradigm for researchers and industry practitioners seeking to leverage the power of LLMs in domain-specific applications. Its utility extends beyond the medical domain, applicable to a wide range of fields.},
  archive      = {J_ARTMED},
  author       = {Zhanzhong Gu and Wenjing Jia and Massimo Piccardi and Ping Yu},
  doi          = {10.1016/j.artmed.2025.103078},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103078},
  shortjournal = {Artif. Intell. Med.},
  title        = {Empowering large language models for automated clinical assessment with generation-augmented retrieval and hierarchical chain-of-thought},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finger-aware artificial neural network for predicting
arthritis in patients with hand pain. <em>ARTMED</em>, <em>162</em>,
103077. (<a href="https://doi.org/10.1016/j.artmed.2025.103077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arthritis is an inflammatory condition associated with joint damage, the incidence of which is increasing worldwide. In severe cases, arthritis can result in the restriction of joint movement, thereby affecting daily activities; as such, early and accurate diagnosis crucial to ensure effective treatment and management. Advances in imaging technologies used for arthritis diagnosis, particularly Single Photon Emission Computed Tomography/Computed Tomography (SPECT/CT), have enabled the quantitative measurement of joint inflammation using SUV max . To the best of our knowledge, this is the first study to apply deep learning to SUV max to predict the development of hand arthritis. We developed a transformer-based Finger-aware Artificial Neural Network (FANN) to predict arthritis in patients experiencing hand pain, including finger embedding, and to share unique finger-specific information between hands. Compared to conventional machine learning models, the FANN model demonstrated superior performance, achieving an area under the receiver operating characteristic curve of 0.85, accuracy of 0.79, precision of 0.87, recall of 0.79, and F1-score of 0.83. Furthermore, analysis using the SHapley Additive exPlanations (SHAP) algorithm revealed that the FANN predictions were most significantly influenced by the proximal interphalangeal joints of the right hand, in which arthritis is the most clinically prevalent. These findings indicate that the FANN significantly enhances arthritis prediction, representing a promising tool for clinical decision-making in arthritis diagnosis.},
  archive      = {J_ARTMED},
  author       = {Hwa-Ah-Ni Lee and Geun-Hyeong Kim and Seung Park and In Ah Choi and Hyun Woo Kwon and Hansol Moon and Jae Hyun Jung and Chulhan Kim},
  doi          = {10.1016/j.artmed.2025.103077},
  journal      = {Artificial Intelligence in Medicine},
  month        = {4},
  pages        = {103077},
  shortjournal = {Artif. Intell. Med.},
  title        = {Finger-aware artificial neural network for predicting arthritis in patients with hand pain},
  volume       = {162},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="asoc---79">ASOC - 79</h2>
<ul>
<li><details>
<summary>
(2025). Data preprocessing techniques and neural networks for
trended time series forecasting. <em>ASOC</em>, <em>174</em>, 113063.
(<a href="https://doi.org/10.1016/j.asoc.2025.113063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on time series forecasting continues to attract significant attention, particularly in the use of Artificial Neural Networks (ANN) due to their ability to model nonlinear behaviors. However, forecasting economic time series with steep upward trends presents challenges, often leading to poorly fitting predictions. This study addresses the issue by applying differentiation as a preprocessing step. Three real-world time series exhibiting this behavior were analyzed and forecasted using two neural network models—Long Short-Term Memory (LSTM) and Multilayer Perceptron (MLP)—with and without preprocessing. The differentiated series were further processed using techniques such as Empirical Mode Decomposition (EMD) and trend-fluctuation decomposition via Moving Average of Wavelet Transform. The results demonstrate that differentiation significantly enhances forecasting accuracy across all tested models, reducing errors by up to 30 % compared to models without preprocessing. This approach effectively mitigates trend-related distortions, leading to more reliable predictions in complex economic time series.},
  archive      = {J_ASOC},
  author       = {Ana Lazcano and Miguel A. Jaramillo-Morán},
  doi          = {10.1016/j.asoc.2025.113063},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113063},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Data preprocessing techniques and neural networks for trended time series forecasting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling authenticity with diffusion-based face retouching
reversal. <em>ASOC</em>, <em>174</em>, 113062. (<a
href="https://doi.org/10.1016/j.asoc.2025.113062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unveiling the real appearance of retouched faces to prevent malicious users from deceptive advertising and economic fraud has been an increasing concern in the era of digital economics. This article makes the first attempt to investigate the face retouching reversal (FRR) problem. We first build an FRR dataset, named deepFRR, by collecting 50,000 StyleGAN-generated high-resolution (1024 × 1024) facial images and retouching them via a commercial online API. Then, we present a novel diffusion-based FRR network (FRRffusion) for the FRR task. Our FRRffusion consists of a coarse-to-fine two-stage architecture: A diffusion-based Facial Morpho-Architectonic Restorer (FMAR) is constructed to generate the basic contours of low-resolution faces in the first stage, while a Transformer-based Hyperrealistic Facial Detail Generator (HFDG) is designed to create high-resolution facial details in the second stage. Tested on deepFRR, our FRRffusion surpasses the state-of-the-art image restoration method with 22%, 11%, 20%, and 6% performance improvement in SSIM, PSNR, VGGS, and CLIPS, respectively. Especially, the de-retouched images by our FRRffusion are visually much closer to the raw face images than both the retouched face images and those restored by the state-of-the-art, like GP-UNIT and Stable Diffusion, in terms of qualitative evaluation with 85 subjects. These results sufficiently validate the efficacy of our FRRffusion, bridging the gap between the FRR and generic image restoration tasks. The code is available at https://github.com/GZHU-DVL/FRRffusion .},
  archive      = {J_ASOC},
  author       = {Fengchuang Xing and Xiaowen Shi and Yuan-Gen Wang and Chunsheng Yang},
  doi          = {10.1016/j.asoc.2025.113062},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113062},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unveiling authenticity with diffusion-based face retouching reversal},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nested deep learning with learned network embeddings for
software defect prediction. <em>ASOC</em>, <em>174</em>, 113057. (<a
href="https://doi.org/10.1016/j.asoc.2025.113057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing software (SW) defect prediction approaches and the models are majorly based on features extracted from the code of the software to build defect datasets for predictive modeling. However, these models fail to sufficiently capture the complex, latent dependencies within the software components, which acts as a hindrance in achieving higher predictive accuracy. This study introduces an improved defect prediction model, the Nested Deep Learning (NDL) model, that leverages network embeddings from call graphs for enhanced representation of intricate hierarchical class dependencies and interactions. This work evaluates six network-embedding algorithms by applying them to call graphs of 10 real software projects, generating embeddings of dimensions 32 and 128. A total of 50 NDL models—with and without dropout layers—are developed, and a comparative evaluation of these models is conducted against traditional classifier-based models. This evaluation demonstrated the superiority of the NDL model with dropout, achieving a mean AUC of 0.87, an 8.98 % improvement over the traditional classifier-based models. Among the evaluated embedding methods, LINE embeddings outperformed others, and integrating network embeddings with software metrics led to a 15.85 % AUC improvement over using software metrics alone. The optimal configuration—combining software metrics with LINE embeddings (dimension 128) in an NDL model with three deep learning layers and dropout—achieved a mean AUC of 0.93, surpassing all other configurations by 3.33–14.81 % . This study is the first to validate the effectiveness of a nested deep learning framework for modeling call graph dependencies through network embeddings, providing a scalable and robust approach for improving software defect prediction.},
  archive      = {J_ASOC},
  author       = {Sweta Mehta and Lov Kumar and Sanjay Misra and K.Sridhar Patnaik and Vikram Singh},
  doi          = {10.1016/j.asoc.2025.113057},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113057},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Nested deep learning with learned network embeddings for software defect prediction},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view self-supervised learning on heterogeneous graphs
for recommendation. <em>ASOC</em>, <em>174</em>, 113056. (<a
href="https://doi.org/10.1016/j.asoc.2025.113056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have significantly contributed to data mining but face challenges due to sparse graph data and lack of labels. Typically, GNNs rely on simple feature aggregation to leverage unlabeled information, neglecting the richness inherent in unlabeled data within graphs. Graph self-supervised learning methods effectively capitalize on unlabeled information. Nevertheless, most existing graph self-supervised learning methods focus on homogeneous graphs, ignoring the heterogeneity of graphs and mainly considering the graph structure from a single perspective. These methods cannot fully capture the complex semantics and correlations in heterogeneous graphs. It is challenging to design self-supervised learning tasks that can fully capture and represent complex relationships in heterogeneous graphs. In order to address the above problems, we investigate the problem of self-supervised HGNN and propose a new self-supervised learning mechanism for HGNN called Multi-view Self-supervised Learning on Heterogeneous Graphs for Recommendation (MSRec). We introduce a maximum entropy path sampler to help sample meta-paths containing structural context. Encoding information from diverse views defined by various meta-paths, decoding it into a semantic space different from own and optimizing tasks in both local-view and global-view contrastive learning, which facilitates collaborative and mutually supervisory interactions between the two views, leveraging unlabeled information for node embedding learning effectively. According to experimental results, our method demonstrates an optimal performance improvement of approximately 7% in NDCG@10 and about 8% in Prec@10 compared to state-of-the-art models. The experimental results on three real-world datasets demonstrate the superior performance of MSRec compared to state-of-the-art recommendation methods.},
  archive      = {J_ASOC},
  author       = {Yunjia Zhang and Yihao Zhang and Weiwen Liao and Xiaokang Li and Xibin Wang},
  doi          = {10.1016/j.asoc.2025.113056},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113056},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-view self-supervised learning on heterogeneous graphs for recommendation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-branch attention coupled convolutional domain
adaptation network for bearing intelligent fault recognition under
unlabeled sample scenarios. <em>ASOC</em>, <em>174</em>, 113053. (<a
href="https://doi.org/10.1016/j.asoc.2025.113053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing intelligent fault recognition is important to maintain the healthy and stable operation of mechanical equipment. However, it is difficult to have a consistent distribution of the acquired source and target domain data due to the constantly changing operating state of the equipment. Moreover, the acquisition of sufficient labeled data is constrained by both time and economic costs. Most of the existing recognition methods are difficult to perform effective fault recognition when faced with inconsistent data distribution and unlabeled small sample data. To address these issues, this paper proposes a multi-branch attention coupled convolutional domain adaptation network (MACCDAN) for unsupervised cross-domain fault recognition, which contains three unique parts. A cross-attention coupled module (CACM) is firstly designed between two parallel feature extraction branches to guide the intertwined coupling of the two branch features through a dual synergetic attention mechanism. A global feature aggregation module (GFAM) is further presented to conduct the global information fusion, which integrates the dependencies between different branch features and enhances the perception of key features. Additionally, the maximum-similarity minimum-discrepancy adversarial loss (MSMDAL) is formulated as an optimization objective to reduce the discrepancy between the source and target domain, and promote the learning of domain-invariant and discriminative features. The results of the four performance evaluation metrics (i.e., accuracy, precision, recall and F1 score) of the proposed method are all 1.0000 on two datasets. The F1 score of the proposed method is improved by at least 0.03 compared to other methods.},
  archive      = {J_ASOC},
  author       = {Maoyou Ye and Xiaoan Yan and Dong Jiang and Ning Chen},
  doi          = {10.1016/j.asoc.2025.113053},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113053},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-branch attention coupled convolutional domain adaptation network for bearing intelligent fault recognition under unlabeled sample scenarios},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A morphological difference and statistically sparse
transformer-based deep neural network for medical image segmentation.
<em>ASOC</em>, <em>174</em>, 113052. (<a
href="https://doi.org/10.1016/j.asoc.2025.113052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation plays a pivotal role in enhancing disease diagnosis and treatment planning. However, existing methods often struggle with the complexity of lesion boundaries and the computational demands of Transformer-based approaches. To address these challenges, we propose a morphological difference and statistically sparse Transformer-based deep neural network for medical image segmentation, termed MD-SSFormer. It comprises two critical modules: the dual branch encoder (DBEncoder) module, and the morphological difference catcher (MDC). To extract abundant information at different aspects, a novel DBEncoder module integrates the capability of the convolutional neural network-based method in capturing local texture and the ability of the Transformer-based method in modeling global information. Compared to the conventional feature extraction methods, DBEncoder achieves comprehensive improvement. Furthermore, the statistics-based sparse Transformer (SSFormer) module develops an innovative statistical analysis and an adaptive patch-dividing strategy to perform attention-computing, which addresses the computational challenges associated with conventional Transformer-based models. Finally, considering the impacts of the blurry and complex boundaries, the MDC module employs the morphological operation and differential information extractor to refine the details, which achieves high-precision boundary understanding. Experimental results on five public datasets demonstrate MD-SSFormer&#39;s superior performance, achieving state-of-the-art Dice scores of 83.60 % on ISIC 2017, 79.52 % on Kvasir-SEG, 61.89 % on BUSI, 78.62 % on BraTS21, and 85.85 % on 3DIRCADb, outperforming other methods in accuracy, precision, and computational efficiency respectively.},
  archive      = {J_ASOC},
  author       = {Dongxu Cheng and Zifang Zhou and Hao Li and Jingwen Zhang and Yan Yang},
  doi          = {10.1016/j.asoc.2025.113052},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113052},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A morphological difference and statistically sparse transformer-based deep neural network for medical image segmentation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heuristic-based multi-stage machine learning-based model
to design a sustainable, resilient, and agile reverse corn supply chain
by considering third-party recycling. <em>ASOC</em>, <em>174</em>,
113042. (<a href="https://doi.org/10.1016/j.asoc.2025.113042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the reverse supply chain configuration problem for the agri-food sector with agility, resilience, and sustainability aspects. To do this, this article proposes a heuristic-based multi-stage machine learning-based model to design a corn reverse logistics based on agility, resilience, and sustainability features. In this way, at the first stage, the performance of the potential recycling partners is evaluated by combining the Categorical Boosting Algorithm (CatBoost) method. In the next stage, a multi-objective model is suggested to configure the corn reverse logistics in which the resilience, agility, and sustainability dimensions are incorporated. Afterwards, we deal with uncertainty by developing a data-driven method based on the chance-constrained fuzzy programming method and the seasonal autoregressive integrated moving average approach. Finally, by choosing a real-world case study, the suggested model is solved by developing a heuristic-based solution procedure. The obtained results showed that the developed heuristic-based solution approach able to find optimal and near-optimal solution in a reasonable time. Based on the achieved outputs, increasing the capacity parameter has a positive impact in the efficiency of the supply chain. Also, results show that when the amount of the initial waste increases, the total profit and environmental impacts of the supply chain have increased, too. Also, the achieved outputs confirm the robustness and efficiency of the developed machine learning-based approach. Then, several sensitivity analyses are presented to examine the role of the key parameters in the research problem. Finally, the managerial insights are provided.},
  archive      = {J_ASOC},
  author       = {Fardin Rezaei Zeynali and Mohammad Parvin and Ali Akbar ForouzeshNejad and Emaad Jeyzanibrahimzade and Mohssen Ghanavati-Nejad and AmirReza Tajally},
  doi          = {10.1016/j.asoc.2025.113042},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113042},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A heuristic-based multi-stage machine learning-based model to design a sustainable, resilient, and agile reverse corn supply chain by considering third-party recycling},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multidimensional fitness function based heuristic
algorithm for set covering problems. <em>ASOC</em>, <em>174</em>,
113038. (<a href="https://doi.org/10.1016/j.asoc.2025.113038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The set covering problem (SCP) is a conventional integer programming challenge in combinatorial optimization, with applications spanning fields such as transportation, logistics, and location problems. Solving SCPs efficiently is crucial for optimizing operations in these domains, particularly in location problems, where traditional algorithms often struggle with multidimensional objective spaces. To address such challenges, this study proposes a novel problem-dependent heuristic algorithm to solve SCPs, featuring a new multi-dimensional fitness function, which was evaluated by benchmarking against other heuristic and metaheuristic algorithms. A collection of reproduced and selected OR-library problems of various scales were chosen as benchmark instances to assess the performance of the algorithm. The performance of the algorithm was confirmed as it constructs solutions by leveraging a novel fitness function to address the limitations of time complexity, applicability, and scalability. Computational results demonstrate that the developed algorithm offers competitive solutions for SCPs, showing improvements of up to 88 % and 20 % in terms of time compared to simulated annealing and a preliminary heuristic algorithm, respectively. In terms of quality, the developed algorithm achieved cost reductions of up to 21 % and 11 % compared to these algorithms, respectively.},
  archive      = {J_ASOC},
  author       = {Ahmad Hashemi and Hamed Gholami and Xavier Delorme and Kuan Yew Wong},
  doi          = {10.1016/j.asoc.2025.113038},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113038},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multidimensional fitness function based heuristic algorithm for set covering problems},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the industry 4.0 strategies in the automobile
manufacturing firm using a combined compromise solution-based ranking
method. <em>ASOC</em>, <em>174</em>, 113037. (<a
href="https://doi.org/10.1016/j.asoc.2025.113037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implementing industry 4.0 (I4.0) strategies in automobile manufacturing firm leads to the higher demand for newer services, drives innovation, continuously innovates to meet the changing needs and expectations of customers, and enables the development of sustainable solutions. This paper develops a q-rung orthopair fuzzy information (q-ROFI)-based decision support tool to evaluate I4.0 strategies in the automobile manufacturing firm. The proposed framework firstly calculates weight of decision expert using a procedure considering the q-rung orthopair fuzzy set (q-ROFS). Next, an individual opinions of decision experts are aggregated into single decision through q-ROF weighted averaging operator. Further, criteria weights are computed by a combined weighting procedure involving objective weighting through entropy-based procedure and subjective weighting by stepwise weight assessment ratio analysis (SWARA) model with q-ROFI. In the following purpose, new entropy is introduced based on the cross entropy of q-ROFS and new score function is proposed for q-ROFS to evade the limitation of existing q-ROF-score function. On the basis of these steps, a modified combined compromise solution (CoCoSo) approach is presented to assess and prioritize the alternatives under q-ROFS context. Finally, the proposed framework is applied to a case study of I4.0 strategies evaluation problem in automobile manufacturing firm. According to the outcomes, the most suitable strategy among the other strategies over considered twenty-five evaluation criteria for assessing I4.0 strategies in the automobile manufacturing firms is as new business models development strategies (0.319), improving information systems strategies (0.273) and human resource management (HRM) strategies (0.210), respectively. The most significant criteria for assessing I4.0 strategies in the automobile manufacturing firms are technology (0.055), coordination (0.052), and legal problems (0.048), respectively. Moreover, comparison with different existing methods is presented to validate the robustness of introduced method.},
  archive      = {J_ASOC},
  author       = {Arunodaya Raj Mishra and Pratibha Rani and Ahmad M. Alshamrani and Adel Fahad Alrasheedi and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.113037},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113037},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Assessing the industry 4.0 strategies in the automobile manufacturing firm using a combined compromise solution-based ranking method},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feature engineering based model architecture for modeling
initial public offerings. <em>ASOC</em>, <em>174</em>, 113035. (<a
href="https://doi.org/10.1016/j.asoc.2025.113035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a model architecture for modeling Initial Public Offerings (IPOs) by incorporating a diverse range of data sources, encompassing both textual and numerical inputs. Language models, machine learning models, and deep learning architectures are combined to make the final ensemble predictions. Several rich features are engineered and interpreted while providing scope for debugging using the game theory-based Shapley Additive exPlanations (SHAP) values. The study results indicate that the feature-engineering is highly eloquent in IPO performance modelling. The study findings have high economic implications range from detecting the market trends to overall market stability.},
  archive      = {J_ASOC},
  author       = {Durga Vaidynathan and Parthajit Kayal and Moinak Maiti},
  doi          = {10.1016/j.asoc.2025.113035},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113035},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A feature engineering based model architecture for modeling initial public offerings},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-reference super-resolution reconstruction of remote
sensing images based on hierarchical similarity mapping. <em>ASOC</em>,
<em>174</em>, 113027. (<a
href="https://doi.org/10.1016/j.asoc.2025.113027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make full use of the details from multi-reference images and improve the quality of super-resolution reconstruction of remote sensing images, a multi-reference super-resolution reconstruction of remote sensing images based on hierarchical similarity mapping is proposed. It is very important in both military and civilian fields. Firstly, one low resolution image and three reference images are used as the input of VGG network to extract their feature maps at 4 × , 2 × , and 1 × scales. These feature maps at each scale are respectively blocked and used as a set of inputs in subsequent operations. Specifically, the low resolution features are divided into N i blocks, and each block is further divided into N c sub-feature-blocks. And the N m reference image features are divided into N r sub-feature-blocks. Then the N c low-resolution sub-feature blocks are mapped for similarity with the reference features within the range of all reference sub-feature blocks, individual reference features, and all reference image features. The outputs of each layer are then iteratively mapped with the low-resolution features as inputs for next layers. Thus the final features include information from all the reference images and low-resolution image. Subsequently, an adaptive transfer module with multi-reference features and channel attention is used to match and transfer the information of each reference image, while achieving edge smoothing and noise filtering between different reference features. Finally, the quadruple super-resolution reconstruct result is got from the multi-scale feature fusion module and decoder. Experimental results show that our improvements can reconstruct better super-resolution results with more details for utilizing information of multi-reference images, which is superior to single image super-resolution methods and single reference super-resolution methods.},
  archive      = {J_ASOC},
  author       = {Fuzhen Zhu and Qi Zhang and Bing Zhu and Chen Wang},
  doi          = {10.1016/j.asoc.2025.113027},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113027},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-reference super-resolution reconstruction of remote sensing images based on hierarchical similarity mapping},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flight anomaly detection and localization based on flight
data fusion and random channel masking. <em>ASOC</em>, <em>174</em>,
113023. (<a href="https://doi.org/10.1016/j.asoc.2025.113023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flight anomaly detection and localization are critical for enhancing aircraft safety through effective analysis of flight data. However, existing methods only detect the timing of anomalies, failing to identify and recover the specific abnormal parameters necessary for assisting flight control systems in correcting the aircraft&#39;s state. To address these limitations, this paper proposes a novel anomaly detection and localization method based on random channel masking (RCM). The proposed approach integrates a multi-node synchronous prediction (MNSP) model, which combines graph attention networks and convolutional neural networks to extract both normal and anomalous patterns from extensive flight data. RCM is employed to generate pseudo-anomalous data, enabling the MNSP model to accurately localize and recover affected parameters. The effectiveness of proposed method is validated using real flight data from unmanned aerial vehicle, achieving an average anomaly detection accuracy of 95 % across four distinct types of anomalies. Furthermore, the method successfully localizes specific abnormal parameters with a localization accuracy of no less than 92.5 % across three different anomaly scenarios. In single-parameter anomaly scenarios, the mean squared error of data recovery remains below 0.000082. The study also explores the boundaries of anomaly localization in multi-parameter scenarios, highlighting the algorithm&#39;s robustness and applicability under diverse conditions.},
  archive      = {J_ASOC},
  author       = {Jie Zhong and Heng Zhang and Qiang Miao},
  doi          = {10.1016/j.asoc.2025.113023},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113023},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Flight anomaly detection and localization based on flight data fusion and random channel masking},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A quantum entanglement-based optimization method for complex
expensive engineering problems. <em>ASOC</em>, <em>174</em>, 113019. (<a
href="https://doi.org/10.1016/j.asoc.2025.113019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the computational costliness and time-consuming nature of complex and expensive engineering (CEE) problems, this paper proposes a genetic algorithm based on quantum entanglement to address these challenges. This method encodes individuals into quantum genes, where each gene bit stores not 0 or 1, but a superposition state of both. By leveraging the uncertainty of the superposition state during the collapse, this method effectively preserves population diversity even with a very small population size. A smaller population size implies fewer calls to time-consuming simulations. Additionally, quantum entangled states are created for parts of an individual&#39;s gene, utilizing the characteristic that entangled states instantly affect each other upon collapse, to achieve parallel evolution of parts of the genes in multiple individuals. This parallel evolution significantly increases the search speed of the algorithm, thereby reducing the number of iterations. Fewer iterations also mean fewer calls to simulations. Benchmark function experiments demonstrate that the proposed method is significantly superior to other similar algorithms in a 30D solution space with a population size of 20 and also has certain advantages in a 100D solution space.},
  archive      = {J_ASOC},
  author       = {Fengling Peng and Xing Chen},
  doi          = {10.1016/j.asoc.2025.113019},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113019},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A quantum entanglement-based optimization method for complex expensive engineering problems},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State-space recurrent neural networks for predictive
analytics and latent state estimation. <em>ASOC</em>, <em>174</em>,
113017. (<a href="https://doi.org/10.1016/j.asoc.2025.113017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework to predict the remaining life (RL) of degrading systems under sensor condition monitoring. By integrating state-space modeling with stochastic recurrent neural networks, our approach efficiently processes condition-monitoring time-series data and models systems’ latent degradation states. We propose a stochastic model that captures dependencies among latent degradation states, sensor outputs, and RL in a causally coherent manner and utilizes stochastic neural networks to navigate the inherent uncertainties of system dynamics. To enhance the interpretability of RL estimation and latent state modeling, we propose interpretable regularization terms. These terms are incorporated into the loss function to optimize both the prediction precision of estimating remaining life and latent states and control the monotonic behavior of their estimates, thereby improving the model’s overall performance and interpretability. Our methodology is validated through numerical experiments and comparison with benchmark models, demonstrating its potential to improve predictive maintenance strategies by effectively estimating the remaining life and monitoring the state of latent degradation over time.},
  archive      = {J_ASOC},
  author       = {Ramin Moghaddass and Cheng-Bang Chen},
  doi          = {10.1016/j.asoc.2025.113017},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113017},
  shortjournal = {Appl. Soft. Comput.},
  title        = {State-space recurrent neural networks for predictive analytics and latent state estimation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-label learning for fault diagnosis of pumping units
with one positive label. <em>ASOC</em>, <em>174</em>, 113014. (<a
href="https://doi.org/10.1016/j.asoc.2025.113014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault diagnosis using the indicator diagram is a fundamental method to evaluate the working status of pumping units. In applications, human experts typically identify only one fault for each indicator diagram. However, multiple types of faults may occur simultaneously. In this paper, we propose a Single-Positive Multi-label learning for Fault Diagnosis of Pumping Units (SPM-FDPU) algorithm to address this issue. Although trained on single-label data, it is capable of multi-label prediction. First, HU invariant moments and convolutional neural networks are used to extract common and label-specific features, respectively. Second, instance, feature, and label correlations are injected into the training process by feature and label manifolds to enhance supervised information. Third, the manifold is used to augment the latent label matrix to help explore discriminant information. Experiments are conducted on the three real indicator diagram data of an oil field and sixteen multi-label benchmark datasets. The results show that the accuracy of the proposed method has achieved 98% in diagnosing multiple faults on indicator diagram datasets, and the mean rank of the proposed method is optimal in terms of six popular evaluation metrics on multi-label benchmark datasets. The source code is available at github.com/Kqian2020/SPM-FDPU .},
  archive      = {J_ASOC},
  author       = {Kun Qian and Jinyu Tang and Qimei Zhao and Shu Zhao and Fan Min},
  doi          = {10.1016/j.asoc.2025.113014},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113014},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-label learning for fault diagnosis of pumping units with one positive label},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent modeling for indoor fire risk prediction during
evacuation based on cellular automata and artificial neural network.
<em>ASOC</em>, <em>174</em>, 113013. (<a
href="https://doi.org/10.1016/j.asoc.2025.113013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fire cases have always posed threats to human lives and property safety, and new approaches have been developed to investigate how people behave during the fire process. Understanding the underlying mechanism under specific scenarios and conditions is critical to find possible ways of reducing social losses. Here, we propose a coupled model that combines FDS and CA, to assess fire risks in a multi-story dormitory building at a university. For this real target case, the settings of automatic sprinklers and temperature alarms will be considered in our coupled model. The aim is to investigate how pedestrians behave under the fire emergencies and how fire safety facilities (exits) shape final evacuation outcomes. To analysis the final outcomes and related factors, we use Event Tree and BP neural network methods to assess and predict individual risk levels. It suggests that controlling the number of people in each dormitory will effectively reduce the fire risk, and the existence of safety facilities can significantly contain fire risks. Early fire warning systems and quick response times are critical to reduce casualties during the evacuation process. Individual risk levels can be efficiently calculated by Event Tree method, and BP neural network can accurately predict fire risk levels. By integrating technologies such as FDS, CA, ETA, and BP neural networks, our model can effectively simulate the dynamic process of the fire evacuation while accurately predicting the fire risks, which establishes an effective link between environmental factors and fire risk assessment. This provides a methodological reference for future fire risk assessment research.},
  archive      = {J_ASOC},
  author       = {Peng Lu},
  doi          = {10.1016/j.asoc.2025.113013},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113013},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent modeling for indoor fire risk prediction during evacuation based on cellular automata and artificial neural network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term forecasting of electricity price using ensemble
deep kernel based random vector functional link network. <em>ASOC</em>,
<em>174</em>, 113012. (<a
href="https://doi.org/10.1016/j.asoc.2025.113012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term electricity price forecasting in a deregulated electrical market is a difficult task as the electricity price exhibits high nonlinearity, sharp price spikes, and seasonality in different frequencies, etc. Thus, this study presents a new approach using an Ensemble Deep Kernel Random Vector Functional Link Network (EDKRVFLN) model hybridized with a Chaotic Sine Cosine Improved Firefly Algorithm (CSCIFA) for short-term electricity price forecasting with better generalization capacity, simple structure, and significant accuracy. Unlike the Ensemble Deep Random Vector Functional Link Network (EDRVFLN) where each stacked layer requires proper choice of the number of hidden nodes and manual tuning of random weights and biases along with the pseudoinverse solution of the output weights in each layer leading to suboptimal model generalization. However, the choice of random weights and biases along with the number of hidden neurons in the proposed EDKRVFLN model can be dispensed by using kernel-based transformation and representation learning. Further each stacked layer of the proposed model utilizes kernel based linear features from the direct links and nonlinearly transformed features from the enhancement nodes from the preceding layers of the prediction model. Also, each layer produces an output by simple invertible kernel matrix inversion based on generalized least squares, and the final output is the ensemble of the outputs from each layer, thus simultaneously producing an ensemble and deep learning framework. Seven electricity price datasets are examined to confirm the supremacy of the proposed model in comparison to several benchmark models.},
  archive      = {J_ASOC},
  author       = {Someswari Perla and Ranjeeta Bisoi and P.K. Dash and A.K. Rout},
  doi          = {10.1016/j.asoc.2025.113012},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113012},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term forecasting of electricity price using ensemble deep kernel based random vector functional link network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing AI safety of machine unlearning for ensembled
models. <em>ASOC</em>, <em>174</em>, 113011. (<a
href="https://doi.org/10.1016/j.asoc.2025.113011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, machine unlearning (MU) has received significant attention for its ability to remove specific undesired knowledge from a trained model, thereby ensuring AI safety. Furthermore, efforts have been made to integrate MU into existing Machine Learning as a Service (MLaaS), allowing users to raise requests to remove the influence of their data used in the training phase, after which the server conducts MU to remove its influence based on the unlearning requests. However, previous research reveals that malicious users may manipulate the requests so that the model utility may be significantly compromised after unlearning, which is known as malicious unlearning. In addition, privacy leakage may be exploited by malicious users by analyzing inference results obtained from the original model and the unlearned model. In this connection, we investigate these potential risks, specifically in ensemble models, which are widely adopted in MU because of their efficiency in unlearning and robustness in learning. However, despite these advantages, their vulnerabilities to malicious unlearning and privacy leakage remain largely unexplored. Our work explores malicious unlearning and malicious inference in ensemble settings. We propose a method in which malicious unlearning requests can trigger hidden poisons in ensembles, causing target images to be misclassified as intended by adversaries. Additionally, we introduce a privacy leakage attack where adversaries with black-box access to voting outputs can infer the unlearned label by analyzing the differences between the original and unlearned ensemble outputs. Experimental results demonstrate that these attacks can be highly stealthy and achieve a high success rate. Furthermore, comparative experiments reveal that these attacks present slightly lower stealthiness in ensemble settings compared to single-model scenarios, suggesting that ensemble models have advantages in detecting such malicious activities. These findings reveal that ensemble models are vulnerable to malicious unlearning and privacy leakage and highlight the urgent need for more robust MU designs to ensure AI safety.},
  archive      = {J_ASOC},
  author       = {Huanyi Ye and Jiale Guo and Ziyao Liu and Yu Jiang and Kwok-Yan Lam},
  doi          = {10.1016/j.asoc.2025.113011},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113011},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhancing AI safety of machine unlearning for ensembled models},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual degradation image inpainting method via adaptive
feature fusion and u-net network. <em>ASOC</em>, <em>174</em>, 113010.
(<a href="https://doi.org/10.1016/j.asoc.2025.113010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing image inpainting methods are designed to address a single specific task, such as super-resolution, denoising, or colorization, with few models capable of handling dual degradation simultaneously. Moreover, current algorithms that tackle multiple image degradation problems often suffer from complex structures, prolonged training times, and high labor costs. In this paper, we propose a Dual Degradation Network via Adaptive Feature Fusion and U-Net (AFFU). The network employs a Self-Guided Module (SGM) to fuse multi-scale image information, effectively eliminating certain defects in the image. A coder-decoder module with null convolution is utilized to consolidate the semantic information of the image, enabling intermediate image colorization. Additionally, an Adaptive Multi-feature Fusion Module (AMF) and Information Transfer Mechanism (ITM) are introduced to link these two major structures, adaptively selecting and retaining image features during network progression to prevent the loss of useful information. Experimental results demonstrate that the proposed dual image degradation restoration network model, based on adaptive multi-feature fusion, achieves optimal visual generation. Evaluations on CelebA dataset and Landscape dataset show that the proposed method outperforms comparable approaches in terms of Structural Similarity (SSIM) and Learned Perceptual Image Patch Similarity (LPIPS).},
  archive      = {J_ASOC},
  author       = {Yuantao Chen and Runlong Xia and Kai Yang and Ke Zou},
  doi          = {10.1016/j.asoc.2025.113010},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113010},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual degradation image inpainting method via adaptive feature fusion and U-net network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-aware graph contrastive learning with topological
relationship for recommendation. <em>ASOC</em>, <em>174</em>, 113008.
(<a href="https://doi.org/10.1016/j.asoc.2025.113008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are a vital tool to guide the overwhelming amount of online information for users, which has been successfully applied to online retail platforms, social networks, etc. Recently, contrastive learning has revealed outstanding performance in recommendation by data augmentation strategies to handle highly sparse data. Most existing work fails to leverage the original network’s topology to construct attention-aware modules that identify user–item interaction importance for guiding node aggregation while preserving key semantics and reducing noise in the reconstructed graph during data augmentation. In this paper, our work proposes an At t e ntion-aware G raph C ontrastive L earning architecture with Topological Relationship (AteGCL) for recommendation. In particular, our AteGCL proposes an attention-aware mechanism with topological relationships to learn the importance between users and items for extracting the local graph dependency, which identifies the importance between nodes by constructing an attention-aware matrix into graph convolutional networks using a random walk with a restart strategy for generating node feature aggregation. We then employ principal component analysis (PCA) for contrastive augmentation and utilize the attention-aware matrix to ease noise from the reconstructed graph generated by PCA and to generate a new view with global collaborative relationships and less noise. Comprehensive experiments on three real-world user–item networks reveal the superiority of our AteGCL over diverse state-of-the-art recommendation approaches. Our code is available at https://github.com/ZZHCodeZera/AteGCL .},
  archive      = {J_ASOC},
  author       = {Xian Mo and Jun Pang and Zihang Zhao},
  doi          = {10.1016/j.asoc.2025.113008},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113008},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Attention-aware graph contrastive learning with topological relationship for recommendation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Category-level pipe pose and size estimation via
geometry-aware adaptive curvature convolution. <em>ASOC</em>,
<em>174</em>, 113006. (<a
href="https://doi.org/10.1016/j.asoc.2025.113006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipe pose estimation provides crucial positional information for robots, enhancing assembly efficiency and precision, while its accuracy critically impacts the final product&#39;s reliability and quality. To handle unseen pipes, we propose a category-level pipe pose and size estimation network via Normalized Object Coordinate Space (NOCS) representation. Given an RGB image and its corresponding depth map, our network predicts class labels, bounding boxes and instance masks for detection, as well as NOCS maps for pose estimation. Then these predictions are aligned with the depth map to estimate pipe’s pose and size. To better extract complex and variable pipe morphology, geometry-aware adaptive curvature convolution is introduced to dynamically adapt to the slender structure and improve segmentation performance. Facing the lack of pipe pose datasets with enough instances, pose, clutter, occlusion, and illumination variation, we propose a novel domain randomization mixed reality approach to efficiently generate synthetic data, which addresses the limitations of training datasets, making data generation more time- and effort-efficient. Experimental results demonstrate that our Geometry-Aware Adaptive Convolutional Network (GACNet) outperforms other methods and robustly estimates the pose and size of unseen pipes in real-world environments.},
  archive      = {J_ASOC},
  author       = {Jia Hu and Jianhua Liu and Shaoli Liu and Lifeng Wang},
  doi          = {10.1016/j.asoc.2025.113006},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {113006},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Category-level pipe pose and size estimation via geometry-aware adaptive curvature convolution},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete differentiated creative search for traveling
salesman problem. <em>ASOC</em>, <em>174</em>, 112998. (<a
href="https://doi.org/10.1016/j.asoc.2025.112998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel population-based Discrete Differentiated Creative Search (DDCS) is proposed in this paper for solving the traveling salesman problem (TSP). DDCS introduces greedy beam search to adaptively initialize the population and improve the quality of the initial solutions. Second, a multi-edge construction operator, edge-based mathematical operations and a similarity attraction operator are used to guide individuals from different population categories towards higher-quality solutions based on the current solutions. Finally, a random nearest neighbor replacement strategy is used to replace individuals with the same distance heuristically, reducing the assimilation rate of the population. DDCS is tested with 50 instances from TSPLIB and compared with a variety of state-of-the-art and variants of classical algorithms. The results demonstrate that DDCS exhibits superior optimization capability and higher stability.},
  archive      = {J_ASOC},
  author       = {Qi Xu and Kewen Xia and Xiaoyu Chu},
  doi          = {10.1016/j.asoc.2025.112998},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112998},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Discrete differentiated creative search for traveling salesman problem},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-short term cross echo state network for time series
forecasting task. <em>ASOC</em>, <em>174</em>, 112997. (<a
href="https://doi.org/10.1016/j.asoc.2025.112997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investigating the dynamics of time series in nonlinear systems has become a prominent research focus in both theoretical and practical domains. Unveiling the intrinsic characteristics of nonlinear time series can significantly enhance the understanding and modelling of nonlinear systems. Among the various time prediction models, Reservoir Computing (RC) has garnered widespread attention due to its distinctive hidden layer architecture. The Echo State Network (ESN) is one of the most representative instances within the RC framework. However, most existing ESNs do not explicitly capture the fixed multi-scale dependencies in time series, and their short-term memory (STM) cannot meet the needs of specific time series. To address these limitations, this paper introduces a novel Echo State Network with a heterogeneous topology, named the Long-short Term Cross Echo State Network (LS-CrossESN). The overall architecture of this model consists of three different types of reservoirs in parallel. And it incorporates a heterogeneous topology structure known as the cross architecture, which merges those of the first reservoir with the state characteristics of the second reservoir, so that the information between the two reservoirs can be transmitted to each other. At the same time, a time-delay operator is inserted in the second reservoir, so that the fused characteristics would not be immediately input to the next layer but transmitted to the deep layer. In this way, the characteristics of input would not decay with the update of the layers. The structure of third reservoir captures the influence of recent historical memory through a specific sliding window technology, and finally the multi-scale states from each layer would be collected for combined prediction. To optimize parameters in this model, an Improved Salp Swarm Algorithm (ISSA) is proposed. The model was tested of eight datasets spanning three categories: Mackey-Glass series, Lorenz chaotic series, Sunspot series, airport temperature series, and two real network traffic datasets. The experimental results demonstrate that the STM of LS-CrossESN is significantly improved compared with Deep-ESN, LS-ESN, DATDR and ADRC. Across all eight datasets, the model exhibits robust performance in both one-step-ahead and multi-step predictions.},
  archive      = {J_ASOC},
  author       = {Dongchen Jiang and Li Cui and Yi Zeng and Meiming You and Guoqiang Wang},
  doi          = {10.1016/j.asoc.2025.112997},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112997},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Long-short term cross echo state network for time series forecasting task},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A crude oil price forecasting framework based on constraint
guarantee and pareto fronts shrinking strategy. <em>ASOC</em>,
<em>174</em>, 112996. (<a
href="https://doi.org/10.1016/j.asoc.2025.112996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of crude oil prices is essential for making informed energy policy decisions and ensuring energy security. However, crude oil price forecasting is inherently challenging due to the volatile, nonlinear, and complex nature of the market. While ensemble learning approaches have shown promise in enhancing forecasting accuracy, many existing models rely on multi-objective optimization techniques that generate a Pareto frontier of optimal solutions, often making it difficult to select the best solution for practical application. This issue is exacerbated by the fact that some Pareto-optimal solutions are not suitable for real-world decision-making, leading to inefficiencies in model performance. To address these limitations, this research proposes a novel ensemble learning framework that incorporates a Constraint Guarantee Strategy (CGS) and a Pareto Front Shrinking Strategy (PFSS) to enhance both the accuracy and stability of crude oil price forecasting models. The CGS filters out inferior solutions during the optimization process, ensuring that the ensemble model outperforms individual models in terms of forecasting accuracy. The PFSS helps decision-makers select the most relevant solutions from the Pareto frontier by balancing trade-offs between objectives and narrowing down the set of solutions. Our framework is evaluated on three widely used datasets: Brent, WTI, and Dubai crude oil prices, and compared with state-of-the-art models from both the general time-series forecasting domain and crude oil price forecasting. It improves prediction accuracy by approximately 23.2% on the Brent dataset, 4.0% on the WTI dataset, and 21.7% on the Dubai dataset, based on improvements in MAPE. Ablation studies confirm the effectiveness of each component. The discussion further emphasizes the practical applicability and robustness of the framework, confirming its potential for real-world crude oil price forecasting.},
  archive      = {J_ASOC},
  author       = {Yujie Chen and Zhirui Tian},
  doi          = {10.1016/j.asoc.2025.112996},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112996},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A crude oil price forecasting framework based on constraint guarantee and pareto fronts shrinking strategy},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating competitive framework into differential
evolution: Comprehensive performance analysis and application in brain
tumor detection. <em>ASOC</em>, <em>174</em>, 112995. (<a
href="https://doi.org/10.1016/j.asoc.2025.112995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an efficient and effective optimizer based on the Success History Adaptive DE (SHADE) named Competitive Framework DE (CFDE). We integrate three tailored strategies into CFDE: (1) the competitive framework to identify and prioritize potential individuals, (2) the novel DE/loser-to-best/loser-to-winner mutation scheme to fully leverage the information from the population and competition to construct high-quality offspring individuals, and (3) the random memory initialization to diversify the search patterns of the individual. We conduct comprehensive numerical experiments on CEC2017, CEC2020, CEC2022, and eight engineering problems against eleven state-of-the-art optimizers to confirm the superiority and competitiveness of CFDE. Moreover, the sensitivity experiments on hyperparameters validate the robustness of CFDE, and the ablation experiments practically prove the independent contribution of integrated components. Furthermore, we propose a hybrid model named DenseNet-CFDE-ELM for brain tumor detection, where DenseNet-169 is employed for feature selection and CFDE-optimized Extreme Learning Machine (ELM) classifies the brain tumors in MRI scans. Experimental results on the brain tumor dataset downloaded from Kaggle confirm that the proposed DenseNet-CFDE-ELM achieves improvements in accuracy with 1.794%, precision with 1.696%, recall with 1.794%, and F1 score with 1.812% against the second-best ResNet-18 model. These results reveal the potential of CFDE in extensive real-world optimization scenarios. The source code of this research can be downloaded from https://github.com/RuiZhong961230/CFDE .},
  archive      = {J_ASOC},
  author       = {Rui Zhong and Zhongmin Wang and Yujun Zhang and Junbo Jacob Lian and Jun Yu and Huiling Chen},
  doi          = {10.1016/j.asoc.2025.112995},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112995},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Integrating competitive framework into differential evolution: Comprehensive performance analysis and application in brain tumor detection},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fuzzy AHP-based trust management mechanism for
self-sovereign identity in the metaverse. <em>ASOC</em>, <em>174</em>,
112994. (<a href="https://doi.org/10.1016/j.asoc.2025.112994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-sovereign identity (SSI) technology has advantages and potential for application in the metaverse. However, the decentralization and anonymous interaction of SSI create convenience for malicious attacks, frauds, and conspiracies in the metaverse. It leads to various trust risks and threats to the meta-universe system. To address these challenges, we analyze the risks of SSI systems and constructed a reputation index system. Moreover, we propose a blockchain-based reputation management framework (BBRMF), which can constrain users from engaging in illegal activities such as forgery, fraud, and conspiracy, thereby guaranteeing the security and trustworthiness of the entities involved in the metaverse. In BBRMF, we constructed a reputation evaluation model based on fuzzy analytical hierarchy process (FAHP) to assess the user’s reputation in three dimensions: reliability, trustworthiness and security. To motivate users to accumulate more positive reputation, we set the user’s reputation score into a reputation credential in the form of non-fungible token (NFT), through which users can obtain more benefits and opportunities. Finally, we calculated the reputation value of SSI related entities from multiple perspectives through simulation experiments and comparative analysis. The feasibility of the proposed method is verified, and it is proved that it can effectively resist the interference and attack of malicious scoring nodes. Moreover, the scheme adopts multi-dimensional evaluation indexes and behavioral feature values, which significantly improves the comprehensiveness and accuracy of the reputation assessment. Meanwhile, the weights of the evaluation indexes are derived through objective calculation, ensuring the fairness of the evaluation results, and improving the credibility and repeatability of the reputation assessment.},
  archive      = {J_ASOC},
  author       = {Xiaoling Song and Guangxia Xu and Yongfei Huang},
  doi          = {10.1016/j.asoc.2025.112994},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112994},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A fuzzy AHP-based trust management mechanism for self-sovereign identity in the metaverse},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combination weighting method using z-numbers for
multi-criteria decision-making. <em>ASOC</em>, <em>174</em>, 112992. (<a
href="https://doi.org/10.1016/j.asoc.2025.112992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a hybrid approach to determining criteria weights in Multi-Criteria Decision Making (MCDM), combining subjective weight methods with objective weighting techniques based on Z-number theory. The methodology is applied in a practical context involving the establishment of a bank&#39;s call center data analysis platform. Leveraging the inherent uncertainty and reliability considerations in decision-making processes, the hybrid method offers a robust framework for decision support. Through empirical validation and case study analysis, the effectiveness of the proposed approach is demonstrated, highlighting its ability to balance theoretical robustness with practical applicability. The study underscores the importance of ongoing research in MCDM, particularly in developing innovative methods to address the complexities of decision-making environments. Insights from this research provide valuable guidance for practitioners and researchers seeking to enhance MCDM processes across diverse domains.},
  archive      = {J_ASOC},
  author       = {Huan-Jyh Shyur},
  doi          = {10.1016/j.asoc.2025.112992},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112992},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Combination weighting method using Z-numbers for multi-criteria decision-making},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A three-way decision-based model for occupational risk
assessment and classification in the healthcare industry. <em>ASOC</em>,
<em>174</em>, 112991. (<a
href="https://doi.org/10.1016/j.asoc.2025.112991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, occupational health and safety risk assessment (OHSRA) has gained more importance since occupational hazards can cause loss of life, injuries, delays, and cost overruns in an organization. The OHSRA is a critical activity for identifying, analyzing and reducing the potential occupational hazards arising from workplace for corrective actions. In this study, a new OHSRA model is proposed for the risk assessment and classification of occupational hazards by utilizing the criteria importance through inter-criteria correlation (CRITIC) method and three-way decision (TWD). First, the 2-tuple linguistic variables are utilized to express the complex and uncertain risk assessments of occupational hazards provided by experts. Second, an extended CRITIC method is employed to compute the weights of risk criteria by considering their interactions. Then the TWD is improved to determine the risk classifications of occupational hazards by considering their correlations. Finally, a practical case in the healthcare industry is provided to illustrate the feasibility and strengths of the proposed OHSRA model. The results show that the proposed OHSRA model can generate more credible risk classifications of occupational hazards and offer a flexible way for analyzing the risk of occupational hazards.},
  archive      = {J_ASOC},
  author       = {Ran Liu and Hu-Chen Liu and Qi-Zhen Zhang and Hua Shi},
  doi          = {10.1016/j.asoc.2025.112991},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112991},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A three-way decision-based model for occupational risk assessment and classification in the healthcare industry},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive encoding and comprehensive attention decoding
network for medical image segmentation. <em>ASOC</em>, <em>174</em>,
112990. (<a href="https://doi.org/10.1016/j.asoc.2025.112990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation involves partitioning different tissues or lesion areas within medical images. Achieving automatic segmentation can markedly improve efficiency and accuracy, which is significant for biomedical clinical diagnosis. With the rapid development of deep convolutional neural networks (DCNN), U-Net has been widely used in medical image segmentation due to its encoder-decoder structure and skip connection. However, it is still hard for U-Net to handle certain challenging cases. In this study, we propose an adaptive encoding and comprehensive attention decoding network (AA-Net), which is derived from U-Net to address the issues of the semantic gap as well as the loss of spatial information during convolutions. AA-Net takes into account the different characteristics of the encoder and decoder. In the encoder, we design a simple Adaptive Calibration Module (ACM) to improve the representation ability of candidate features. In the decoder, we introduce a Comprehensive Attention Feature Extraction (CAFE) module, which employs multiple attention mechanisms after feature fusion to alleviate the semantic gap. Benefiting from CAFE, AA-Net can better handle the challenging cases where the segmentation targets vary in position, size, and scale. Additionally, we suggest a weighted hybrid loss function for precise boundary segmentation. We validate the effectiveness of AA-Net and each component on three biomedical image datasets. The results demonstrate that our method outperforms state-of-the-art methods in different medical segmentation tasks, proving it is lightweight, efficient, and general.},
  archive      = {J_ASOC},
  author       = {Xin Shu and Aoping Zhang and Zhaoyang Xu and Feng Zhu and Wei Hua},
  doi          = {10.1016/j.asoc.2025.112990},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112990},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Adaptive encoding and comprehensive attention decoding network for medical image segmentation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A nondominated sorting simplified swarm optimization with
local search mechanisms for multi-objective vehicle routing problems
with time windows. <em>ASOC</em>, <em>174</em>, 112989. (<a
href="https://doi.org/10.1016/j.asoc.2025.112989">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In addressing the complexities of modern logistics, this study introduces a novel multi-objective formulation for vehicle routing problems with time windows (MO-VRPTW), targeting minimizing travel distance, enhancing customer satisfaction, and equalizing driver workloads. We introduce an innovative hybrid multi-objective evolutionary algorithm (MOEA) leveraging nondominated sorting simplified swarm optimization to effectively merge the advantages of various optimization strategies. A key aspect of this advancement is the incorporation of the Lin−Kernighan − Helsgaun (LKH) heuristic, which delivers a superior initial solution, thereby markedly enhancing the speed of convergence. Additionally, we pioneered a local search method inspired by the A* algorithm designed to refine the search process&#39;s exploration and exploitation stages. Solomon&#39;s benchmark instances, a recognized standard in the VRPTW field, were used to validate our algorithm&#39;s effectiveness. Our algorithm demonstrated superior performance in addressing MO-VRPTW through meticulous statistical analysis, outperforming state-of-the-art algorithms, such as MOPSO, NSGA-II, MOEA/D, and SPEA2, regarding efficiency and solution diversity. This study not only advances algorithmic performance but also thoughtfully considers the interests of key supply chain stakeholders.},
  archive      = {J_ASOC},
  author       = {Chyh-Ming Lai and Chun-Chih Chiu and Tzu-Li Chen},
  doi          = {10.1016/j.asoc.2025.112989},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112989},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A nondominated sorting simplified swarm optimization with local search mechanisms for multi-objective vehicle routing problems with time windows},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cluster-based prepositioning network for enhanced recovery
resilience of critical infrastructure system using multiplex network.
<em>ASOC</em>, <em>174</em>, 112987. (<a
href="https://doi.org/10.1016/j.asoc.2025.112987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient restoration of critical infrastructures for high-impact-low-frequency events heavily relies on pre-disaster restoration resource prepositioning and post-disaster assignment. To find proper locations of restoration resource depots and optimal assignment schemes, a multiplex network approach is proposed to simultaneously model the critical infrastructure network and restoration resource prepositioning network as a coupled multi-layered network. The proposed approach consists of load-weighted critical infrastructure network modeling, cluster-based restoration resource prepositioning network modeling and recovery resilience optimization of a multiplex network from the two networks. Tested on the Hangzhou metro network located in China, experimental results show that resilience loss optimized based on the proposed cluster-based multiplex network is lower than that based on four centrality-guaranteed competitors for all attack scenarios and significantly lower under random severe attacks representing the most severe scenarios. Link flow fluctuations and higher-order of resilience metrics are discussed to provide an insightful suggestion on the design and intervention decisions of infrastructure restoration.},
  archive      = {J_ASOC},
  author       = {Ying Wang and Ou Zhao and Limao Zhang},
  doi          = {10.1016/j.asoc.2025.112987},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112987},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Cluster-based prepositioning network for enhanced recovery resilience of critical infrastructure system using multiplex network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent reinforcement learning system framework based on
topological networks in fourier space. <em>ASOC</em>, <em>174</em>,
112986. (<a href="https://doi.org/10.1016/j.asoc.2025.112986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, multi-agent reinforcement learning (MARL) has been applied to various domains such as communications, network management, power systems, and autonomous driving, showcasing broad application scenarios and significant research potential. However, in complex decision-making environments, agents that rely solely on temporal value functions often struggle to capture and extract hidden features and dependencies within long sequences in multi-agent settings. Each agent’s decisions are influenced by a sequence of prior states and actions, leading to complex spatiotemporal dependencies that are challenging to analyze directly in the time domain. Addressing these challenges requires a paradigm shift to analyze such dependencies from a novel perspective. To this end, we propose a Multi-Agent Reinforcement Learning system framework based on Fourier Topological Space from the foundational level. This method involves transforming each agent’s value function into the frequency domain for analysis. Additionally, we design a lightweight weight calculation method based on historical topological relationships in the Fourier topological space. This addresses issues of instability and poor reproducibility in attention weights, along with various other interpretability challenges. The effectiveness of this method is validated through experiments in complex environments such as the StarCraft Multi-Agent Challenge (SMAC) and Google Football. Furthermore, in the Non-monotonic Matrix Game, our method successfully overcame the limitations of non-monotonicity, further proving its wide applicability and superiority. On the application level, the proposed algorithm is also applicable to various multi-agent system domains, such as robotics and factory robotic arm control. The algorithm can control each joint in a coordinated manner to accomplish tasks such as enabling a robot to stand upright or controlling the movements of robotic arms.},
  archive      = {J_ASOC},
  author       = {Licheng Sun and Ao Ding and Hongbin Ma},
  doi          = {10.1016/j.asoc.2025.112986},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112986},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multi-agent reinforcement learning system framework based on topological networks in fourier space},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic light optimization in vertical farming using an
IoT-driven digital twin framework and artificial intelligence.
<em>ASOC</em>, <em>174</em>, 112985. (<a
href="https://doi.org/10.1016/j.asoc.2025.112985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global agricultural sector faces mounting challenges from climate change, population growth, urbanization, and environmental degradation, necessitating innovative solutions to ensure food security. Urban and peri-urban agriculture, particularly vertical farming, offers a sustainable approach to increase food production while minimizing land use, reducing environmental impact, and enhancing resource efficiency. Unlike conventional vertical farming systems that rely on static spectral recipes with fixed light compositions (e.g., Red-to-Blue ratios derived from historical data), this study introduces an Internet of Things-enabled smart vertical farming system that leverages digital twin technology and a genetic algorithm (GA) to dynamically optimize lettuce growth by adjusting RGB LED spectra throughout the crop cycle. The system monitors and controls key environmental parameters within a growth tower, including temperature, humidity, and lighting. A digital twin facilitates real-time data exchange between physical and virtual components, while the GA iteratively refines the light composition. Over a 34-day cultivation period, the algorithm identified an optimal RGB configuration (R:211, G:169, B:243; maximum intensity: 255) that aligns with spectral values reported in literature for lettuce, despite not directly measuring photobiological metrics such as Photosynthetic Photon Flux Density. To our knowledge, this is the first study to implement a dynamic, GA-driven spectral optimization strategy in vertical farming. While the objective was not to surpass traditional static lighting recipes, the results validate that adaptive methods can reliably converge to established optima. The IoT platform demonstrated robust capabilities in data collection, processing, and actuation, underscoring the promise of adaptive lighting strategies for controlled agriculture. Future research will focus on incorporating additional spectra (e.g., deep red, ultraviolet), automating data collection via image recognition, and analyzing energy efficiency to enhance scalability.},
  archive      = {J_ASOC},
  author       = {Rafael Gomes Alves and Fábio Lima and Ítalo Moraes Rocha Guedes and Salvador Pinillos Gimenez},
  doi          = {10.1016/j.asoc.2025.112985},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112985},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic light optimization in vertical farming using an IoT-driven digital twin framework and artificial intelligence},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural priority model for agile earth observation
satellite scheduling using deep reinforcement learning. <em>ASOC</em>,
<em>174</em>, 112984. (<a
href="https://doi.org/10.1016/j.asoc.2025.112984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The agile earth observation satellite scheduling problem (AEOSSP) is a time-dependent and complex combinatorial optimization challenge that has spurred extensive research for decades. Traditional methods have primarily relied on iterative searching processes to approximate near-optimal solutions, but their efficiency remains limited. To address this issue, we propose a Priority Construction Model (PCM) based on deep reinforcement learning (DRL), forming a learning-based, two-stage construction heuristic. The PCM integrates a Priority Construction Neural Network (PCNN) alongside a Backward-Slacken and Top-Insert (BS-TI) scheduling algorithm. In PCM, the PCNN sequences observation requests, while the BS-TI schedules each sequenced request in accordance with specific constraints, thus freeing the neural policy from the burden of complex constraint checking. Experimental results indicate that following a policy-gradient-based DRL training process, PCM outperforms the state-of-the-art AEOSSP iterative algorithm, achieving better average profits within an exceptionally short construction time in most scenarios. The model study further reveals that PCNN outperforms other DRL policies in terms of priority policy representation, while the PCM exhibits superior generalization capabilities across varying scales and distributions. Therefore, our proposed model presents a valuable reference solution that not only meets the large-scale and rapid response requirements of the AEOSSP but also holds potential for application in upcoming large constellations and emerging management paradigms. More importantly, we introduce a novel framework that separates the DRL optimization process from constraint management, lowering the entry barrier for applying DRL to complex problems. This makes the model adaptable to various optimization challenges in engineering and operations research, thus extending its applicability beyond the AEOSSP domain.},
  archive      = {J_ASOC},
  author       = {Ming Chen and Luona Wei and Jie Chun and Lei He and Shang Xiang and Lining Xing and Yingwu Chen},
  doi          = {10.1016/j.asoc.2025.112984},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112984},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A neural priority model for agile earth observation satellite scheduling using deep reinforcement learning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transferable adversarial attacks against face recognition
using surrogate model fine-tuning. <em>ASOC</em>, <em>174</em>, 112983.
(<a href="https://doi.org/10.1016/j.asoc.2025.112983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks have significantly advanced Face Recognition performance yet remain susceptible to adversarial attacks, posing significant security and user privacy threats in real-world applications. In recent years, black box attacks have attracted wide attention to craft highly transferable adversarial examples by training surrogate models. However, most of these methods primarily depend on stealing knowledge by accessing the soft label from the target model using either synthetic training data or data free without awareness of the knowledge type, which can affect the improvement of transferability between the surrogate and the target models. Additionally, these attacks still need to improve the surrogate model’s accuracy without using many queries. To this end, we propose Tune2Transfer, a novel attack method that enhances adversarial transferability by fine-tuning the surrogate model with different types of knowledge with limited queries on the target model by the hard label only. Specifically, it collects a small face image dataset, considering the adversary’s limited knowledge. To overcome the challenge of knowledge type, Tune2Transfer imposes three sampling assumptions: clean images only, the perturbed images, or combining both, generating images on the surrogate model, and then feeding them to the target model to obtain the hard label. The perturbed images are generated by perturbing them using the Covariance Matrix Adaptation Evolution Strategy or Momentum Iteration Fast Gradient Sign Method. Besides, we leverage pre-trained models to fine-tune surrogate models to avoid large queries. In this way, we could leverage knowledge transferred from the target model, resulting in superior transferability. Extensive experiments conducted on two typical datasets demonstrate the efficacy of Tune2Transfer, increasing the attack success rates significantly.},
  archive      = {J_ASOC},
  author       = {Yasmeen M. Khedr and Xin Liu and Haobo Lu and Kun He},
  doi          = {10.1016/j.asoc.2025.112983},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112983},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Transferable adversarial attacks against face recognition using surrogate model fine-tuning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semi-supervised non-negative matrix factorization model
for scRNA-seq data analysis. <em>ASOC</em>, <em>174</em>, 112982. (<a
href="https://doi.org/10.1016/j.asoc.2025.112982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-cell RNA sequencing (scRNA-seq) technology enables the measurement of cellular gene expression at the single-cell level, thus facilitating cell clustering at the gene level. Despite numerous dimensionality reduction methods developed for scRNA-seq data, many are limited to analyzing individual gene expression matrices and struggle to address false positives and false zero expression entries effectively. Moreover, existing methods often underutilize prior knowledge of similarity and dissimilarity between multi-omics data, leading to the loss of intercellular correlations and shared structural information, thus hindering desired dimensionality reduction outcomes. To address these limitations, a novel model termed joint non-negative matrix factorization with similarity and dissimilarity constraints (SDJNMF) was proposed to tailor for scRNA-seq data clustering. The model leverages prior knowledge of similarity and dissimilarity across multiple gene expression matrices, facilitating joint non-negative matrix factorization to extract common features from multi-omics data. By preserving shared structural and cellular relevance information, SDJNMF enhances the clustering of similar cells while effectively separating dissimilar ones. Furthermore, the SDJNMF model incorporates sparse Singular Value Decomposition during initialization to mitigate noise and redundancy and ensure robust dimensionality reduction. The experimental results demonstrate that the SDJNMF model exhibits superior performance on the 10 datasets, not only outperforming the other 14 algorithms in terms of clustering accuracy on the 9 datasets, but also enhancing the A R I of SDJNMF by an average of 0.0687 in comparison to the second-best algorithm on each dataset. In the visual representation, the model is able to efficiently and accurately cluster similar cells and effectively discriminate different classes of cells from each other. Additionally, the SDJNMF model was applied to identify informative genes and conduct enrichment analysis, validating that genes identified by SDJNMF significantly influence biological processes. Overall, the SDJNMF offers innovative tools for cell cluster identification and advances biological research. The source code of SDJNMF is available online at https://github.com/Jindsmu/SDJNMF .},
  archive      = {J_ASOC},
  author       = {Junjie Lan and Xiaoling Zhuo and Siman Ye and Jin Deng},
  doi          = {10.1016/j.asoc.2025.112982},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112982},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A semi-supervised non-negative matrix factorization model for scRNA-seq data analysis},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdvGrid: A multi-view black-box attack on infrared
pedestrian detectors in the physical world. <em>ASOC</em>, <em>174</em>,
112981. (<a href="https://doi.org/10.1016/j.asoc.2025.112981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical adversarial attacks in the visible spectrum have been extensively studied, but research on infrared attacks remains limited. Infrared pedestrian detectors are crucial for modern applications yet vulnerable to adversarial attacks, posing significant security risks. Existing methods using physical perturbations like light bulb arrays or hot/cold patches for black-box attacks have shown limitations in practicality and multi-view support. To address these challenges, we introduce Adversarial Infrared Grid (AdvGrid), a novel approach that models perturbations in a grid format and employs a genetic algorithm for black-box optimization. AdvGrid cyclically applies perturbations to various parts of a pedestrian’s clothing, enabling effective multi-view black-box attacks on infrared detectors. Our extensive experiments demonstrate AdvGrid’s superior performance: Effectiveness: Achieves 80.00% attack success rate in digital environments and 91.86% in physical environments. Stealthiness: Maintains high stealthiness, making it difficult for observers to identify the adversarial patterns. Robustness: Exceeds 50% average attack success rate against mainstream detectors, showcasing its robustness across different scenarios. We also conduct ablation studies, transfer attacks, and adversarial defense evaluations, further confirming AdvGrid’s superiority over baseline methods. Our findings highlight AdvGrid as a powerful tool for advancing the understanding and mitigation of adversarial threats in infrared detection systems.},
  archive      = {J_ASOC},
  author       = {Kalibinuer Tiliwalidi and Chengyin Hu and Guangxi Lu and Ming Jia and Weiwen Shi},
  doi          = {10.1016/j.asoc.2025.112981},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112981},
  shortjournal = {Appl. Soft. Comput.},
  title        = {AdvGrid: A multi-view black-box attack on infrared pedestrian detectors in the physical world},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Series clustering and dynamic periodic patching-based
transformer for multivariate time series forecasting. <em>ASOC</em>,
<em>174</em>, 112980. (<a
href="https://doi.org/10.1016/j.asoc.2025.112980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting (MTSF) is widely employed in research-intensive domains, such as weather forecasting. Recently, Transformer-based models have outstanding ability to achieve SOTA performance, benefiting from its self-attention mechanism. However, existing models fall short in capturing multivariate inter-dependencies and local semantic representations. To tackle the above limitations, we propose a series clustering and dynamic periodic patching-based Transformer model named CMDPPformer, with two distinctive characteristics: (1) A channel-mixing module based on series clustering is proposed which can strengthen the association between variables with high sequence similarity, and weaken the effect of uncorrelated variables. Concretely, we use whole-time series clustering to group multivariate time series into clusters. After that, variables in the same cluster share the same Transformer backbone while variables in different clusters do not affect each other. (2) A dynamic periodic patching module is introduced which can better capture semantic information and improve Transformer’s local semantic representation. Concretely, multivariate time series after clustering are dynamically segmented into periodic patches as Transformer’s input token. Experimental results show that CMDPPformer can achieve an overall 13.76% and 10.16% relative improvements than SOTA Transformer-based models on seven benchmarks, covering four real-world applications: energy, weather, illness and economic.},
  archive      = {J_ASOC},
  author       = {Yijie Wang and Xiao Wu and Jiaying Zhang and Weiping Wang and Linjiang Zheng and Jiaxing Shang},
  doi          = {10.1016/j.asoc.2025.112980},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112980},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Series clustering and dynamic periodic patching-based transformer for multivariate time series forecasting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic trend fusion module for traffic flow prediction.
<em>ASOC</em>, <em>174</em>, 112979. (<a
href="https://doi.org/10.1016/j.asoc.2025.112979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is essential for applications like transport logistics but remains challenging due to complex spatio-temporal correlations and non-linear traffic patterns. Existing methods often model spatial and temporal dependencies separately, failing to effectively fuse them. To overcome this limitation, the D ynamic S patial- T emporal T rend Trans former ( DST 2 former ) is proposed to capture spatio-temporal correlations through adaptive embedding and to fuse dynamic and static information for learning multi-view dynamic features of traffic networks. The approach employs the D ynamic T rend R epresentation Trans former ( DTRformer ) to generate dynamic trends using encoders for both temporal and spatial dimensions, fused via Cross Spatial-Temporal Attention. Predefined graphs are compressed into a representation graph to extract static attributes and reduce redundancy. Experiments on four real-world traffic datasets demonstrate that our framework achieves state-of-the-art performance.},
  archive      = {J_ASOC},
  author       = {Jing Chen and Haocheng Ye and Zhian Ying and Yuntao Sun and Wenqiang Xu},
  doi          = {10.1016/j.asoc.2025.112979},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112979},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic trend fusion module for traffic flow prediction},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing a forecasting model for time series based on
clustering and deep learning algorithms. <em>ASOC</em>, <em>174</em>,
112977. (<a href="https://doi.org/10.1016/j.asoc.2025.112977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a new forecasting model for time series based on the improvement and combination of the cluster analysis (CA) algorithm and deep learning with Convolutional Neural Network (CNN) and Bi-Long Short Term Memory (BiLSTM) model. The proposed model is considered pioneering in this research direction with significant contributions to three main phases. For the first phase, the original series is converted into the percentage change series and is divided into clusters of an appropriate number using the CA algorithm. The next phase involves extracting the features of the new series based on the CNN with suitable parameters and input data enhancement from the results of the first phase. In the final phase, the BiLSTM model is applied to the series established from the second phase, and the forecasting principle for the future is established. The proposed model is detailed in the implementation steps, proving convergence, illustrated by numerical examples, and can be applied to real series using a Matlab procedure. The effectiveness of the proposed model is quite impressive as it surpasses many strong forecasting models on reputable benchmark datasets , including the M3-Competition dataset with 3,003 series, and M4-Competition dataset with 100,000 series.},
  archive      = {J_ASOC},
  author       = {Luan Nguyen-Huynh and Tai Vo-Van},
  doi          = {10.1016/j.asoc.2025.112977},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112977},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Developing a forecasting model for time series based on clustering and deep learning algorithms},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of international market entry strategies for
mineral oil companies using a neutrosophic SWARA-CRADIS methodology.
<em>ASOC</em>, <em>174</em>, 112976. (<a
href="https://doi.org/10.1016/j.asoc.2025.112976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Businesses encounter risks when entering new countries, but there are also opportunities. The strategy a business employs when opting to enter a new market is directly tied to its success. In this regard, the study provides an approach for evaluating new market entry strategies for businesses facilitating in the mineral oil sector and manufacturing industries. The approach includes the development of the type 2 neutrosophic step-wise weight assessment ratio analysis (SWARA)-compromise ranking of alternatives from distance to ideal solution (CRADIS) methodology, which aims to solve the problem by determining the candidate strategies and the criteria to be utilized in their evaluation. The findings revealed that market conditions are the most crucial criterion in selecting strategies for mineral oil companies intending to enter new markets. The magnitude and development potential of the new market to be entered, as well as the status of the actors, all have an impact on market conditions, which are critical for businesses. Moreover, foreign direct investment is found to be the best market entry strategy. This strategy arises because businesses aim to maximize the potential in the market they have recently entered, as well as other factors such as government incentives. The study is expected to benefit production enterprises, the mineral oil sector, the marketing field, and the literature by identifying criteria and option sets, finding the importance degrees of the criteria, selecting the ideal entry strategy, and proposing a methodology for handling uncertain data.},
  archive      = {J_ASOC},
  author       = {Ahmet Aytekin and Hilal Öztürk Küçük and Makbule Aytekin and Vladimir Simic and Dragan Pamucar},
  doi          = {10.1016/j.asoc.2025.112976},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112976},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Evaluation of international market entry strategies for mineral oil companies using a neutrosophic SWARA-CRADIS methodology},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic environment adaptive online learning with fairness
awareness via dual disentanglement. <em>ASOC</em>, <em>174</em>, 112975.
(<a href="https://doi.org/10.1016/j.asoc.2025.112975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of Artificial Intelligence (AI) comes with the necessity to consider and mitigate discrimination in machine learning algorithms. Most existing fair machine learning methods are only suitable for short-term and static scenarios, and thus cannot adapt to dynamically changing environments or meet the needs for real-time updates. In open dynamic scenarios, data arriving in batches needs processing in real-time, and the constantly changing environment will lead to data distribution shifts, making it difficult to ensure the fairness of models in the long run. To achieve long-term fairness of models, we propose an online dual disentanglement method that captures fair representations of non-sensitive core information in real-time within constantly changing environments, thereby enhancing the robustness of fair models. Firstly, learned representations are disentangled from environment-specific variation factors through a constrained optimization setup to ensure semantic invariance. Further, a bias disentanglement method based on supervised contrastive learning is designed. While keeping the non-sensitive core information unchanged, the sensitive information is hidden from semantic representations and the spurious correlation with target labels is cut off, so as to achieve the long-term fairness of the model decision. By formulating the fairness-aware online learning problem in dynamic environments as an online optimization problem with the long-term fairness constraint, and theoretically proving that the algorithm achieves sublinear dynamic regret and sublinear violation of cumulative unfairness under certain assumptions. Experimental evaluations on real-world datasets demonstrate the effectiveness of the proposed method, which maintains overall fairness above 80% without compromising utility, outperforming state-of-the-art baseline methods.},
  archive      = {J_ASOC},
  author       = {Qiuling Chen and Ayong Ye and Chuan Huang and Fengyu Wu},
  doi          = {10.1016/j.asoc.2025.112975},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112975},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dynamic environment adaptive online learning with fairness awareness via dual disentanglement},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring coordinated motion patterns of facial landmarks
for deepfake video detection. <em>ASOC</em>, <em>174</em>, 112974. (<a
href="https://doi.org/10.1016/j.asoc.2025.112974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rich geometric and motion information they contain, recent studies indicate that facial landmark clues have significant potential for deepfake video detection. In this paper, we make a key observation that there exist coordinated motions among different facial landmarks for real individuals. While the forgery methods focus more on appearance realism, thus likely to disrupt the underlying coordinated motion patterns. Inspired by this observation, this paper explores how to leverage coordinated motion patterns among facial landmarks to enhance deepfake detection. First, we introduce a coordinated motion landmarks mining strategy (CMLMS), to effectively identify correlated landmarks. Utilizing these correlations, we propose a landmark temporal dynamic relation module (LTDRM), which focuses on the coordinated motion patterns between landmarks while extracting their spatiotemporal features. Specifically, LTDRM constructs an adjacency matrix based on the correlated landmarks and uses graph convolution to selectively aggregate information between correlated landmarks. Additionally, LTDRM is a plug-and-play module and can boost the performance of existing deepfake detection methods with minimal computational overhead. Experimental results validate the effectiveness and generalizability of our method.},
  archive      = {J_ASOC},
  author       = {Yue Zhang and Run Niu and Xianlin Zhang and Siqi Chen and Mingdao Wang and Xueming Li},
  doi          = {10.1016/j.asoc.2025.112974},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112974},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Exploring coordinated motion patterns of facial landmarks for deepfake video detection},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generative fuzzer-driven vulnerability detection in the
internet of things networks. <em>ASOC</em>, <em>174</em>, 112973. (<a
href="https://doi.org/10.1016/j.asoc.2025.112973">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) paradigm has displayed tremendous growth in recent years, driving innovations such as Industry 4.0 and the creation of smart environments that enhance efficiency and asset management and enable intelligent decision-making. However, these benefits come with considerable cybersecurity risks due to inherent vulnerabilities within IoT ecosystems. Introducing potentially vulnerable IoT devices into secure environments, like smart airports, introduces new attack surfaces and vectors for exploitation. Identifying such vulnerabilities is challenging, and while traditional methods like penetration testing and vulnerability identification offer solutions, they often fall short due to IoT’s unique data diversity, hardware constraints, and complexity. We propose an intelligent mutation-based fuzzer for IoT vulnerability detection in networks to address these limitations, demonstrated through a smart airport case study. This method leverages Generative Adversarial Network (GAN)-based mutation, utilizing legitimate network communications (i.e., payloads) to produce fuzzed payloads that expose vulnerabilities. Additionally, we incorporate a large language model (LLM)-based risk assessment framework to evaluate the likelihood and impact of identified vulnerabilities, which is crucial for effectively prioritizing threats in interconnected IoT environments. This dual approach of vulnerability detection and LLM-driven risk assessment provides comprehensive insights into IoT security, enabling prioritized response actions. Experiments conducted in the UNSW Canberra IoT testbed confirm that our approach outperforms conventional vulnerability identification methods, offering a scalable solution for effective vulnerability detection and risk prioritization in complex IoT networks.},
  archive      = {J_ASOC},
  author       = {Mohammed Tanvir Masud and Nickolaos Koroniotis and Marwa Keshk and Benjamin Turnbull and Shabnam Kasra Kermanshahi and Nour Moustafa},
  doi          = {10.1016/j.asoc.2025.112973},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112973},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Generative fuzzer-driven vulnerability detection in the internet of things networks},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target temperature field prediction via a thermodynamic
knowledge-based artificial neural network. <em>ASOC</em>, <em>174</em>,
112972. (<a href="https://doi.org/10.1016/j.asoc.2025.112972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence, representation-supervised neural networks have been widely used in the fast solution of physical field. However, a large number of temperature prediction networks do not take environmental parameters into account, or only use parameters as simple input conditions, which greatly reduces the accuracy of their results. This paper proposes an accurate and low-cost method for adding the conditional parameters to intelligent prediction networks. A novel parameter encoder block is designed based on the heat transfer theory achieving thermodynamic knowledge-based parameter feature extraction. Meanwhile, an improved method for inputting time condition is proposed to characterize the temporal characteristics, which can reduce the requirement of dataset for transient temperature prediction, compared with LSTM. In addition, a thermal loss for temperature images is introduced to accelerate the convergence process in the model. Moreover, a CycleGAN-based temperature prediction network (CBTPN) is constructed for fast temperature prediction of a cube or different tanks. Temperature or infrared images predicted by our network exhibit MAE of less than 2.33 % and SSIM of more than 80.21 %. By embedding physical mechanisms into neural networks, this study this study pioneers a structured approach to refining physical parameters into thermodynamic knowledge-based signals for improved image generation, addressing the accuracy and efficiency limitations of data-driven algorithms caused by their insufficient understanding of parameter mechanisms. Finally, parameter cognitive evaluation proves that our approach can not only recognize the accurate semantics of heat transfer parameters, but also sense the meteorological laws.},
  archive      = {J_ASOC},
  author       = {Jincheng Chen and Feiding Zhu and Yuge Han and Dengfeng Ren},
  doi          = {10.1016/j.asoc.2025.112972},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112972},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Target temperature field prediction via a thermodynamic knowledge-based artificial neural network},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning in produce perception of harvesting robots: A
comprehensive review. <em>ASOC</em>, <em>174</em>, 112971. (<a
href="https://doi.org/10.1016/j.asoc.2025.112971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the global demand for produce has surged, alongside labor shortages, driving the development of agricultural automation, particularly in harvesting robots. Deep learning-based computer vision algorithms have become key to produce perception, demonstrating significant potential. We systematically review the current application of deep learning in produce perception for harvesting robots, providing an in-depth analysis of existing public datasets, with a focus on 2D produce recognition and 3D produce localization. Furthermore, we review and analyze the existing algorithms, highlighting their limitations and challenges. In addition, we explore future research directions of deep learning in produce perception, aiming to promote the continued advancement and innovation of technologies in this area.},
  archive      = {J_ASOC},
  author       = {Yuhao Jin and Xiaoyu Xia and Qizhong Gao and Yong Yue and Eng Gee Lim and Prudence Wong and Weiping Ding and Xiaohui Zhu},
  doi          = {10.1016/j.asoc.2025.112971},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112971},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Deep learning in produce perception of harvesting robots: A comprehensive review},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unmanned aerial vehicle takeoff point search algorithm with
information sharing strategy of random trees for multi-area coverage
task. <em>ASOC</em>, <em>174</em>, 112970. (<a
href="https://doi.org/10.1016/j.asoc.2025.112970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study proposes a novel approach to optimize full-coverage search in distributed task areas using a single Unmanned Ground Vehicle (UGV) to deliver an Unmanned Aerial Vehicle (UAV) to the takeoff points of each task area along the shortest possible path. Unlike the traditional Traveling Salesman Problem (TSP), task areas are not fixed nodes, and obstacles must be considered. To address these challenges, a probability-based Rapid-exploration Random Tree ( p -RRT) with an information-sharing strategy is introduced, significantly improving the efficiency of locating takeoff points in complex environments. A dual optimization method further reduces the number of nodes and path length planned by the D* algorithm, achieving up to an 80 % reduction in nodes and improving path efficiency. Additionally, a simulated annealing (SA) algorithm optimizes the connection sequence of takeoff points, reducing total path length by 35.05 % compared to the initial path and 22.66 % compared to the traditional Random Sampling Method (RSM). Experiments confirm that the proposed algorithms can effectively enhance UGV-UAV collaboration with reducing path complexity and improving energy efficiency, and thus streamline multi-area coverage tasks.},
  archive      = {J_ASOC},
  author       = {Shouwen Yao and Xiaoyu Wang and Siqi Huang and Renjie Xu and Yinghua Zhao},
  doi          = {10.1016/j.asoc.2025.112970},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112970},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Unmanned aerial vehicle takeoff point search algorithm with information sharing strategy of random trees for multi-area coverage task},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive heuristic algorithm with a collaborative search
framework for multi-UAV inspection planning. <em>ASOC</em>,
<em>174</em>, 112969. (<a
href="https://doi.org/10.1016/j.asoc.2025.112969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-UAV inspection path planning has become an important research topic for completing inspection tasks before the data acquisition deadline. In this study, we propose an adaptive heuristic algorithm with a collaborative search framework named Sa-VCO to solve the multi-UAV inspection path planning problem. Our study includes three main novelties. First, we design a region-gridding disperse approach that transforms the primitive target regions into a set of standard target subregions, allowing the target regions with greater costs to be inspected by multiple UAVs. Second, we propose an adaptive initial solution generation strategy using the information of graph structure constructed by all targets to reduce redundant computing. Third, we established a collaborative search framework to enhance search efficiency and increase population diversity. A large number of multiple-perspective comparative experiments are provided to test Sa-VCO&#39;s performance, and the comparison results demonstrate that Sa-VCO achieves better results than other advanced algorithms, especially on large-scale data sets.},
  archive      = {J_ASOC},
  author       = {Chang He and Haibin Ouyang and Weiqing Huang and Steven Li and Chunliang Zhang and Weiping Ding and Zhi-Hui Zhan},
  doi          = {10.1016/j.asoc.2025.112969},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112969},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptive heuristic algorithm with a collaborative search framework for multi-UAV inspection planning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiency analysis of binary metaheuristic optimization
algorithms for uncapacitated facility location problems. <em>ASOC</em>,
<em>174</em>, 112968. (<a
href="https://doi.org/10.1016/j.asoc.2025.112968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces binary adaptations of four metaheuristic optimization algorithms: the Binary Coati Optimization Algorithm (BCOA), Binary Mexican Axolotl Optimization Algorithm (BMAO), Binary Dynamic Hunting Leadership Optimization (BDHL), and Binary Aquila Optimizer (BAO). These algorithms were evaluated for their effectiveness in solving Uncapacitated Facility Location (UFL) problems, which aim to minimize total costs associated with customer-facility allocations and facility opening expenses by determining the optimal number of open facilities. Using 15 UFL problem instances from the OR-Lib dataset, the study assessed algorithm performance across 17 transfer functions (TFs), including S-shaped, V-shaped, and other variants, to address the binary nature of these problems. Performance metrics such as the best, worst, average, standard deviation, and GAP values were analyzed for each binary algorithm. Additionally, statistical analyses were conducted to further assess algorithmic performance. The Kolmogorov-Smirnov (KS) normality test was applied to determine the distribution characteristics of the results, followed by either ANOVA or Kruskal-Wallis tests, depending on the normality of the distributions. These statistical tests revealed significant differences in algorithm performance across different problem instances. Rank values were calculated based on GAP values and CPU times to facilitate comparisons across algorithm versions for the 15 UFL problems. Results underscored the critical role of TF selection in optimizing algorithm efficiency: BCOA performed best with TF11, BMAO with TF16 and TF17, BAO with TF10, and BDHL with TF15. Finally, a performance comparison on GAP values was conducted with two state-of-the-art PSO variants adapted for binary optimization. The proposed algorithms demonstrated either superior or competitive performance in solving UFL problems, validating their efficacy in complex optimization tasks and highlighting the influence of TFs on their performance.},
  archive      = {J_ASOC},
  author       = {Tahir Sag and Aysegul Ihsan},
  doi          = {10.1016/j.asoc.2025.112968},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112968},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Efficiency analysis of binary metaheuristic optimization algorithms for uncapacitated facility location problems},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph convolutional networks with multi-scale dynamics for
traffic speed forecasting. <em>ASOC</em>, <em>174</em>, 112966. (<a
href="https://doi.org/10.1016/j.asoc.2025.112966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic speed forecasting remains challenging due to complex and variable road conditions. Prior research often overlooks both coarse-grained and fine-grained features in traffic data, hindering a comprehensive capture of traffic data&#39;s temporal dependencies. While graph convolutional networks (GCNs) are commonly employed to extract spatial dependencies in traffic networks, they typically view these networks from a static standpoint, failing to consider the dynamic nature of traffic network structures. This limitation restricts their effectiveness in modeling traffic networks. To address these issues, this study introduces a novel deep learning-based spatial-temporal model for precise traffic speed forecasting. This model incorporates a newly developed multi-scale transformation method, which enhances the coarse-grained and fine-grained features in traffic speed data by transforming and fusing traffic speed data, and enabling a more thorough modeling of its temporal dependencies. Additionally, we propose an innovative graph interaction strategy, combines the generated graphs with a dynamic graph convolutional network, to effectively mine the dynamic characteristics of traffic network structures, thereby enhancing the model&#39;s accuracy. Extensive experiments on two real-world datasets have demonstrated the robustness and superior performance of the proposed model, with improvements ranging from 2.2 % to 6.1 % over state-of-the-art baselines.},
  archive      = {J_ASOC},
  author       = {Dongping Zhang and Hao Lan and Mengting Wang and Jiabin Yu and Xinghao Jiang and Shifeng Zhang},
  doi          = {10.1016/j.asoc.2025.112966},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112966},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Graph convolutional networks with multi-scale dynamics for traffic speed forecasting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LOSS-GAT: Label propagation and one-class semi-supervised
graph attention network for fake news detection. <em>ASOC</em>,
<em>174</em>, 112965. (<a
href="https://doi.org/10.1016/j.asoc.2025.112965">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s world of social networks, fake news spreads quickly and causes serious problems. This has made it crucial to develop automated systems to detect and combat disinformation. Machine learning and deep learning are often used to identify fake news, but they struggle due to the lack of labeled news datasets. To address this, the One-Class Learning (OCL) approach uses a small set of labeled data. On the other hand, representing data as a graph enables access to diverse content and structural information, and label propagation methods on graphs can be effective in predicting node labels. In this paper, we adopt a graph-based model for data representation and introduce a semi-supervised and one-class approach for fake news detection, called LOSS-GAT. Initially, we employ a two-step label propagation algorithm, utilizing Graph Neural Networks (GNNs) as an initial classifier to categorize news into two groups: interest (fake) and non-interest (real). Subsequently, we enhance the graph structure using structural augmentation techniques. Ultimately, we predict the final labels for all unlabeled data using a GNN that induces randomness within the local neighborhood of nodes through the aggregation function. We evaluate our proposed method on six common datasets and compare the results against a set of baseline models, including both OCL and binary labeled models. The results demonstrate that LOSS-GAT achieves a significant improvement in performance, with enhancements ranging from 5% (on the FEVER dataset) to 20% (on the FakeNewsNet dataset) in terms of the Macro-F1 metric, all while utilizing only a limited set of labeled fake news data. Noteworthy, LOSS-GAT even outperforms binary labeled models.},
  archive      = {J_ASOC},
  author       = {Batool Lakzaei and Mostafa Haghir Chehreghani and Alireza Bagheri},
  doi          = {10.1016/j.asoc.2025.112965},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112965},
  shortjournal = {Appl. Soft. Comput.},
  title        = {LOSS-GAT: Label propagation and one-class semi-supervised graph attention network for fake news detection},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Art style classification via self-supervised dual-teacher
knowledge distillation. <em>ASOC</em>, <em>174</em>, 112964. (<a
href="https://doi.org/10.1016/j.asoc.2025.112964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Art style classification plays a crucial role in computational aesthetics. Traditional deep learning-based methods for art style classification typically require a large number of labeled images, which are scarce in the art domain. To address this challenge, we propose a self-supervised learning method specifically tailored for art style classification. Our method effectively learns image style features using unlabeled images. Specifically, we introduce a novel self-supervised learning approach based on the popular contrastive learning framework, incorporating a unique dual-teacher knowledge distillation technique. The two teacher networks provide complementary guidance to the student network. Each teacher network focuses on extracting distinct features, offering diverse perspectives. This collaborative guidance enables the student network to learn detailed and robust representations of art style attributes. Furthermore, recognizing the Gram matrix’s capability to capture image style through feature correlations, we explicitly integrate it into our self-supervised learning framework. We propose a relation alignment loss to train the network, leveraging image relationships. This loss function has shown promising results compared to the commonly used InfoNCE loss. To validate our proposed method, we conducted extensive experiments on three publicly available datasets: WikiArt, Pandora18k, and Flickr. The experimental results demonstrate the superiority of our method, significantly outperforming state-of-the-art self-supervised learning methods. Additionally, when compared with supervised methods, our approach shows competitive results, notably surpassing supervised learning methods on the Flickr dataset. Ablation experiments further verify the efficacy of each component of our proposed network. The code is publicly available at: https://github.com/lm-oc/dual_signal_gram_matrix .},
  archive      = {J_ASOC},
  author       = {Mei Luo and Li Liu and Yue Lu and Ching Y. Suen},
  doi          = {10.1016/j.asoc.2025.112964},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112964},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Art style classification via self-supervised dual-teacher knowledge distillation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Saccade inspired attentive visual patch transformer for
image sentiment analysis. <em>ASOC</em>, <em>174</em>, 112963. (<a
href="https://doi.org/10.1016/j.asoc.2025.112963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generation of image-evoked emotion is usually regarded as a transient process in the image sentiment analysis. However, according to the saccade mechanism of the human visual system, the evoked emotion generated during the saccade process changes over time and attention. Based on above analysis, we propose an Attentive Visual Patch Transformer (AVPT), using visual attention sequence to represent the sentiment context of images and predict the possible distribution of sentiment. In AVPT, the spatial structure in the form of patches are reconstructed and reorganized by visual attention shift sequentially. Simultaneously, the temporal characteristics of attention shift are introduced to the relative position encoding, and merged in a self-attention manner to form a spatial–temporal process similarly to the human visual system. Specifically, we propose a sequence attention shift module to simulate the saccade process, which obtains sequence attention and reduces the computational effort by group attentive convolutional gate recurrent unit. Then, a spatial–temporal correlation encoder module is proposed to encode temporal attention with spatial visual features and obtain the sequential visual features of saccade. Finally, a self-attention fusion module is used to extract the correlation hidden in the relative encoding features. Our proposed AVPT achieves excellent performance on visual sentiment distribution prediction and is comparable to state-of-the-art methods, as demonstrated by extensive experiments on the Flickr_LDL and Twitter_LDL datasets.},
  archive      = {J_ASOC},
  author       = {Jing Zhang and Jixiang Zhu and Han Sun and Xinzhou Zhang and Jiangpei Liu},
  doi          = {10.1016/j.asoc.2025.112963},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112963},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Saccade inspired attentive visual patch transformer for image sentiment analysis},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual linear latent space constrained generative adversarial
networks for hyperspectral image classification. <em>ASOC</em>,
<em>174</em>, 112962. (<a
href="https://doi.org/10.1016/j.asoc.2025.112962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image classification is a critical challenge in remote sensing due to the high dimensionality of the data and the scarcity of labeled samples. In this study, we propose a novel Dual-Line Latent Space Constrained Generative Adversarial Network (DLC-GAN) that integrates spatial and spectral feature extraction through dual pathways and incorporates latent space constraints to enhance classification robustness. Unlike existing methods, the DLC-GAN employs a bilinear structure to extract complementary information, improving both feature representation and classification accuracy. The model was evaluated on benchmark datasets such as Indian Pines, Pavia University, and Salinas, achieving state-of-the-art performance. Specifically, the DLC-GAN demonstrated improvements in overall accuracy by 5–11 % compared to recent methods and exhibited superior adaptability to limited training data. These findings underscore the potential of DLC-GAN in addressing critical challenges in hyperspectral image classification, with promising applications in environmental monitoring, agricultural management, and urban planning.},
  archive      = {J_ASOC},
  author       = {Kefen Mou and Sha Gao and Muhammet Deveci and Seifedine Kadry},
  doi          = {10.1016/j.asoc.2025.112962},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112962},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual linear latent space constrained generative adversarial networks for hyperspectral image classification},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inter-block ladder-style transformer model with
multi-subspace feature adjustment for object re-identification.
<em>ASOC</em>, <em>174</em>, 112961. (<a
href="https://doi.org/10.1016/j.asoc.2025.112961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object re-identification aims to retrieve specific objects across multiple cameras and has garnered significant attention. Currently, transformer-based methods have taken a dominant position. However, most approaches embed inherent transformer encoders for feature extraction directly. These methods handle all patch tokens uniformly, failing to distinguish salient and non-salient patch tokens for discriminative feature expression. To this end, this work proposes a novel inter-block ladder-style transformer (IBLSFormer) for object re-identification. Firstly, a multi-subspace feature adjustment (MSFA) module is designed to adjust the patch features via class-patch interaction in multiple subspaces including Euclidean distance subspace, cosine distance subspace, and KL divergence subspace. The MSFA module can enhance the salient patch tokens and weaken the non-salient patch tokens simultaneously to focus on discriminative patches. Afterwards, an IBLSFormer is designed by inserting MSFA modules with distinct configurations into the vision transformer. The narrow-to-wide ladder-style constraints are embedded in MSFA modules based on embedding depth to highlight the feature differences across different levels and ameliorate the feature learning. Our method achieves mAP/Rank-1 of 88.7%/95.3%, 81.4%/90.4%, 80.0%/97.1%, and 89.4%/83.6% on four object re-identification datasets. Extensive experiments show IBLSFormer is superior to other methods in learning discriminative and robust representations for object re-identification.},
  archive      = {J_ASOC},
  author       = {Zhi Yu and Zhiyong Huang and Mingyang Hou and Jiaming Pei and Daming Sun},
  doi          = {10.1016/j.asoc.2025.112961},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112961},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Inter-block ladder-style transformer model with multi-subspace feature adjustment for object re-identification},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometrical invariant generative invisible hyperlinks based
on feature points. <em>ASOC</em>, <em>174</em>, 112959. (<a
href="https://doi.org/10.1016/j.asoc.2025.112959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To enhance the visual diversity of Quick Response (QR) codes while ensuring their robust decoding capabilities, this paper introduces an innovative invisible hyperlink generation system. The system can use a message sequence to directly generate a hyperlink image. By harnessing the latent space of a suggested feature point generation network, the system extends the robustness of image feature points to the hyperlink images it generates. Specially, an image generation network is first designed to synthesize high-quality images based on feature point data. Subsequently, a set of lightweight message encoder and decoder are introduced to embed message bits into the latent space of the image generation network. Experimental results show that the proposed invisible hyperlink generation system can successfully generate images containing hyperlinks, exhibiting remarkable resilience against common signal processing and geometric distortions. It harbors diverse potential applications, encompassing website URLs, contact information, product specifics, and numerous other use cases.},
  archive      = {J_ASOC},
  author       = {Zecheng Peng and Bingwen Feng and Xiaotao Xu and Jilian Zhang and Donghong Cai and Wei Lu},
  doi          = {10.1016/j.asoc.2025.112959},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112959},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Geometrical invariant generative invisible hyperlinks based on feature points},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sentiment analysis and emotion recognition in social media:
A comprehensive survey. <em>ASOC</em>, <em>174</em>, 112958. (<a
href="https://doi.org/10.1016/j.asoc.2025.112958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment Analysis (SA) and emotion recognition is the fundamental dialogue system that recently gained more attention. It is applied in many scenarios like mining the opinions of the speaker’s conversation and enhancing the feedback of the robot agent. Furthermore, the live conversation is used to generate the talks through certain sentiments to enhance the human-machine interaction. This survey focuses the researchers on handling the SA and classification of various sentences in social media by reviewing various approaches. This analysis explains the 50 research articles from different methods used for SA and sentiment classification in social media. Finally, the evaluation of this survey is performed based on the publication year, various approaches, evaluation metrics, and tools. Moreover, the collected 50 research papers are categorized into different techniques, such as deep learning (DL) based methods, machine learning (ML) based methods, lexicon-based methods, hybrid-based methods, and dependency-based methods. Therefore, from this survey, it is clearly shown that the DL-based method is the most utilized approach in many research papers. Similarly, python is the most used tool for SA and classification, and real-time dataset is a commonly used dataset for SA and classification. Likewise, accuracy is repeatedly employed in metrics with the highest value.},
  archive      = {J_ASOC},
  author       = {Mrunmayee Bachate and Suchitra S},
  doi          = {10.1016/j.asoc.2025.112958},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112958},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sentiment analysis and emotion recognition in social media: A comprehensive survey},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term forecasting for port throughput time series based
on multi-modal fuzzy information granule. <em>ASOC</em>, <em>174</em>,
112957. (<a href="https://doi.org/10.1016/j.asoc.2025.112957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Port throughput forecasting is a crucial task that enables port managers to efficiently plan operations, optimize resource utilization, and manage risks. Simultaneously, accurate throughput predictions can prevent port congestion, reduce logistics delays, and enhance cargo handling efficiency, thereby improving port operational efficiency and customer satisfaction. While the existing models often show poor prediction accuracy, because they fail to capture data information comprehensive and produce the iterative errors in short-term forecasting. To address these challenges, a novel short-term time series prediction model is designed, fuzzy information granule (FIG) based model. Different from the existing models, our model incorporates an algorithm based on l 1 -trend filtering to dissect port throughput data into linear trend series and random series, effectively revealing the multi-modal information within data--linear modality and non-linear modality. These multiple modalities allow for a better understanding of throughput changes. Following such multi-modal characteristics, the multi-modal FIG, comprising Gaussian polynomial FIG and Gaussian FIG, is constructed, where the former reflects data linear modality and the latter reflects non-linear modality. Through meticulous data information mining and description, the innovative model achieves short-term forecasting at the granular level, reducing the cumulative errors in iteration. The novel designed FIG based model demonstrates superior accuracy and reliability compared to other 10 models across four metrics, mean absolute error, root mean squared error, mean absolute percentage error, and Wilcoxon signed rank test, which are tested on the data from ports including Ningbo, New York, Shanghai, Singapore, Qingdao, and Malaysia. The application of our model in short-term port throughput forecasting holds significant potential impact in both port operations management and computer science domains.},
  archive      = {J_ASOC},
  author       = {Fang Li and Wen Tong and Xiyang Yang},
  doi          = {10.1016/j.asoc.2025.112957},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112957},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Short-term forecasting for port throughput time series based on multi-modal fuzzy information granule},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiplex network influence maximization based on
representation learning method. <em>ASOC</em>, <em>174</em>, 112956. (<a
href="https://doi.org/10.1016/j.asoc.2025.112956">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization based on representation learning has garnered significant attention in recent years, with numerous studies focusing on monolayer networks. However, given the inherent complexity and multiplicity of social networks, addressing the Multiplex network Influence Maximization (MIM) problem is more practical. The MIM problem aims to find a set of seed nodes to maximize the spread of influence throughout the multiplex network. To tackle this issue, this paper introduces a reverse random walk centrality method based on multiplex network representation learning. This method leverages multiplex network representation learning to derive node embeddings across different layers of the network. By calculating similarity weights between nodes within each layer, a reverse random walk is performed to quantify node importance based on the frequency of visits. The top-k nodes with the highest visit counts are then selected as seed nodes. Both single influence propagation and a coupled spread model that integrates competitive and cooperative influence dynamics are considered. Extensive experiments on several real-world datasets demonstrate that the proposed method outperforms existing techniques in terms of effectiveness, providing robust seed node selection for influence maximization. These findings highlight the efficiency and applicability of the proposed method for practical multiplex network scenarios.},
  archive      = {J_ASOC},
  author       = {Hegui Zhang and Dapeng Zhang and Yun Wan and Renbin Pan and Gang Kou},
  doi          = {10.1016/j.asoc.2025.112956},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112956},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multiplex network influence maximization based on representation learning method},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal fine-grained reasoning for post quality
evaluation. <em>ASOC</em>, <em>174</em>, 112955. (<a
href="https://doi.org/10.1016/j.asoc.2025.112955">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate assessment of post quality frequently necessitates complex relational reasoning skills that emulate human cognitive processes, thereby requiring the modeling of nuanced relationships. However, existing research on post-quality assessment suffers from the following problems: (1) They are often categorization tasks that rely solely on unimodal data, which inadequately captures information in multimodal contexts and fails to differentiate the quality of students’ posts finely. (2) They ignore the noise in the multimodal deep fusion between posts and topics, which may produce misleading information for the model. (3) They do not adequately capture the complex and fine-grained relationships between post and topic, resulting in an inaccurate evaluation, such as relevance and comprehensiveness. Based on the above challenges, the Multimodal Fine-grained Topic-post Relational Reasoning(MFTRR) framework is proposed for modeling fine-grained cues by simulating the human thinking process. It consists of the local–global semantic correlation reasoning module and the multi-level evidential relational reasoning module. Specifically, MFTRR addresses the challenge of unimodal and categorization task limitations by framing post-quality assessment as a ranking task and integrating multimodal data to more effectively distinguish quality differences. To capture the most relevant semantic relationships, the Local–Global Semantic Correlation Reasoning Module enables deep interactions between posts and topics at both local and global scales. It is complemented by a topic-based maximum information fusion mechanism to filter out noise. Furthermore, to model complex and subtle relational reasoning, the Multi-Level Evidential Relational Reasoning Module analyzes topic-post relationships at both macro and micro levels by identifying critical cues and delving into granular relational cues. MFTRR is evaluated using three newly curated multimodal topic-post datasets, in addition to the publicly available Lazada-Home dataset. Experimental results indicate that MFTRR outperforms state-of-the-art baselines, achieving a 9.52% improvement in the NDCG@3 metric compared to the best text-only method on the Art History course dataset.},
  archive      = {J_ASOC},
  author       = {Xiaoxu Guo and Siyan Liang and Yachao Cui and Juxiang Zhou and Lei Wang and Han Cao},
  doi          = {10.1016/j.asoc.2025.112955},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112955},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Multimodal fine-grained reasoning for post quality evaluation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A method based on generative adversarial networks for
disentangling physical and chemical properties of stars in astronomical
spectra. <em>ASOC</em>, <em>174</em>, 112954. (<a
href="https://doi.org/10.1016/j.asoc.2025.112954">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents the design of an autoencoder architecture that uses adversarial training in the context of astrophysical spectral analysis. We aim to develop a middle representation of stellar spectra in which the influence of the most prominent physical properties, such as surface temperature and gravity, is effectively removed. This allows the variance within the representation to primarily reflect the effects of the star’s chemical composition on the spectrum. We apply a scheme of deep learning to unravel in the latent space the desired parameters of the rest of the information contained in the data. This work proposes a version of adversarial training that uses one discriminator per parameter to be disentangled, avoiding the exponential combination that occurs when using a single discriminator. Synthetic astronomical data from the APOGEE and Gaia surveys were used to test the method’s effectiveness. Our approach demonstrates a marked improvement in disentangling, reflected in an improvement in the R 2 score of up to 0.7. Additionally, we introduce an ad-hoc framework, GANDALF, designed to facilitate visualization and adaptation of the methodology to other domains in astronomical spectroscopy.},
  archive      = {J_ASOC},
  author       = {Raúl Santoveña and Carlos Dafonte and Minia Manteiga},
  doi          = {10.1016/j.asoc.2025.112954},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112954},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A method based on generative adversarial networks for disentangling physical and chemical properties of stars in astronomical spectra},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral image classification based on ConvGRU and
spectral–spatial joint attention. <em>ASOC</em>, <em>174</em>, 112949.
(<a href="https://doi.org/10.1016/j.asoc.2025.112949">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In hyperspectral image classification, methods based on spectral–spatial joint attention mechanisms have demonstrated the ability to effectively enhance feature extraction. However, existing approaches still face limitations: spectral attention mechanisms often lack local–global feature interaction, spatial attention fails to fully exploit multi-scale information, and the joint modeling of spectral and spatial features remains insufficiently explored. To address these issues, this paper proposes a spectral–spatial joint attention network based on Convolutional Gated Recurrent Units (ConvGRU). First, a Local-Global Spectral Attention (LGSA) mechanism is designed, where one-dimensional convolution extracts local spectral features and fully connected layers enable global feature interaction. Second, a Multi-Scale Spatial Attention (MSSA) mechanism is introduced, employing three convolutional branches with different receptive fields to capture spatial features, followed by hierarchical feature fusion via 1 × 1 convolution. Finally, a channel-level feature fusion strategy based on ConvGRU is proposed, leveraging sequence modeling to achieve channel-wise joint enhancement of LGSA and MSSA, thereby enabling deep coupling of spectral and spatial features. Comparative experiments on three public datasets demonstrate that the proposed method outperforms seven state-of-the-art algorithms in terms of classification performance.},
  archive      = {J_ASOC},
  author       = {Ronghua Shang and Jie Yang and Jie Feng and Yangyang Li and Songhua Xu},
  doi          = {10.1016/j.asoc.2025.112949},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112949},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Hyperspectral image classification based on ConvGRU and spectral–spatial joint attention},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptation framework with unified embedding
reconstruction for cross-corpus speech emotion recognition.
<em>ASOC</em>, <em>174</em>, 112948. (<a
href="https://doi.org/10.1016/j.asoc.2025.112948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging for speech emotion recognition (SER) to maintain robustness under cross-domain scenarios. Unsupervised domain adaptation (UDA) algorithms have been explored to address the domain shift in SER without relying on emotion labels in the target domain. As a promising framework in UDAs, self-supervised learning (SSL)-based domain exploration (SDE) investigates the domain and structural information within the target domain, aligning domain discrepancies while preserving the model’s emotion discrimination capability. However, SSL often inadvertently introduces emotion-irrelevant information, adversely affecting the UDA performance. To resolve this, we introduce a novel UDA framework called unified SDE (U-SDE), where both source and target domains conduct a unified SSL task. In the source domain, U-SDE guides the source SSL to focus on emotion-related information due to supervised emotion classification constraints. Simultaneously, in the target domain, shared network weights enable the target SSL branch to concentrate on intrinsic emotional and domain features. However, simply using existing SSL algorithms to implement this framework might disrupt the training of the supervised SER branch. To overcome this, we propose the embedding reconstruction of masked speech (ERMS) algorithm. In ERMS, the emotion encoder transforms the embedding of the masked speech to match the embedding of its corresponding unmasked speech, thereby capturing the emotion discriminative feature within the sample. Finally, we employ ERMS to realize the proposed U-SDE paradigm, termed unified ERMS (U-ERMS). We conducted systematic cross-domain SER experiments by designing 52 scenarios using seven well-known datasets. Experimental results showed that the proposed U-ERMS achieved state-of-the-art performance in cross-domain SERs.},
  archive      = {J_ASOC},
  author       = {Ruiteng Zhang and Jianguo Wei and Xugang Lu and Yongwei Li and Wenhuan Lu and Lin Zhang and Junhai Xu},
  doi          = {10.1016/j.asoc.2025.112948},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112948},
  shortjournal = {Appl. Soft. Comput.},
  title        = {An adaptation framework with unified embedding reconstruction for cross-corpus speech emotion recognition},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grey prediction evolution algorithm with a dominator
guidance strategy for solving multi-level image thresholding.
<em>ASOC</em>, <em>174</em>, 112947. (<a
href="https://doi.org/10.1016/j.asoc.2025.112947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-level thresholding (MLT) stands as a pivotal method for extracting target information from images. Meta-heuristic algorithms provide an efficient way to implement MLT and retains more research space for accuracy optimization of high-dimensional multi-level thresholding (HDMLT) of images than they do for low-dimensional multi-level thresholding (LDMIT). In order to improve the algorithmic accuracy in solving the high-dimensional problems, a grey prediction evolution algorithm with a dominator guidance strategy (GPEdg) is proposed in this paper. GPEdg employs Otsu’s method as its objective function to find the best threshold configuration. The novel operator in the algorithm, i.e., a dominator guidance (dg) strategy, uses a linear combination of three difference vectors to guide the top 50% individuals of populations to learn from the top 20% of them. An efficient balance of search abilities suitable for solving HDMLT problems is expected to be achieved by injecting the local search capability of the dg strategy into GPE’s powerful global search capability. Furthermore, a thresholding morphological profile based method (TMP) leverages the thresholding results generated by GPEdg to train a support vector machine (SVM) for hyperspectral image classification. Numerical experiments are conducted for the newly proposed algorithm and five state-of-the-art algorithms on three image datasets to compare the performance in six metrics, i.e., peak signal-to-noise ratio, structural similarity index, features similarity index, objective function value, stability and time consumption. Overall accuracy and average accuracy are tested on two commonly used hyperspectral image data. The results show that GPEdg exhibits outstanding thresholding performance while TMP enhances the classification accuracy of these images. If this paper is accepted, Matlab_codes associated with this paper will be uploaded to https://github.com/Zhongbo-Hu/Prediction-Evolutionary-Algorithm-HOMEPAGE},
  archive      = {J_ASOC},
  author       = {Peixin Yang and Zhongbo Hu and Yang Zhou and Qinghua Su and Wentao Xiong},
  doi          = {10.1016/j.asoc.2025.112947},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112947},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Grey prediction evolution algorithm with a dominator guidance strategy for solving multi-level image thresholding},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo-deep unsupervised model-based clustering for brain
tumor detection in magnetic resonance images. <em>ASOC</em>,
<em>174</em>, 112940. (<a
href="https://doi.org/10.1016/j.asoc.2025.112940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel unsupervised pseudo-deep algorithm, Mixtures of Factor Analyzers based on Rows Iterative Clustering with Image Rotation according to Dimension (MFARICIRD), for accurate and automatic detection of brain tumors in grayscale magnetic resonance images. The main goal is to extract the region of interest (ROI) containing tumors using a pseudo-deep framework with iterative clustering. This framework incorporates a layer by layer structure inspired by deep learning, using a mixture of agent analysts to optimize the clustering process. In each computational layer, the algorithm first rotates the image 90 degrees clockwise if the number of rows is greater than the number of columns. Then, it performs clustering on the image using the estimated parameters of optimal clusters and the optimal number of clusters until the tumor-containing cluster is identified. The identified cluster is used as input for the next layer. These computational processes are iterated layer by layer until the proposed convergence criterion, which acts as the stopping rule, is satisfied. The algorithm uses fuzzy c-mean clustering to binarize the output cluster of the final layer (ROI), enabling the exact extraction of the tumor shape. Finally, it localizes the detected tumor within the original image. A comprehensive evaluation of the effectiveness of the proposed algorithm is presented on the BraTS2020, BraTS2019, and BraTS2018 datasets, demonstrating exceptional performance in detecting tumors with different locations, sizes, and complexities. The algorithm achieved an accuracy and Dice similarity coefficient of 99.96 + 0.0073 % and 98.97 % on the BraTS2018, 99.97 + 0.0087 % and 99.22 + 0.0051 % on the BraTS2019, and 99.98 + 0.0038 % and 99.33 + 0.0072 % on the BraTS2020. The results highlight the remarkable capability of the algorithm in dealing with complex and high-dimensional images, especially in detecting small and unclear tumors. Moreover, it outperforms existing diagnostic methods, significantly improving the accuracy and reliability of brain tumor detection.},
  archive      = {J_ASOC},
  author       = {Rahman Farnoosh and Fatemeh Aghagoli},
  doi          = {10.1016/j.asoc.2025.112940},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112940},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Pseudo-deep unsupervised model-based clustering for brain tumor detection in magnetic resonance images},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mindful human digital twins: Integrating theory of mind with
multi-agent reinforcement learning. <em>ASOC</em>, <em>174</em>, 112939.
(<a href="https://doi.org/10.1016/j.asoc.2025.112939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Agent Reinforcement Learning (MARL) is focused on enabling autonomous agents to learn and adapt to complex environments through interactions with their surroundings and other agents. A key challenge in MARL is developing agents with the human-like capacity to understand, predict, and respond to the intentions and mental states of their peers. This capability, commonly referred to as the Theory of Mind (ToM), is central to fostering more sophisticated and realistic interactions among autonomous agents. In this paper, we propose a novel approach that leverages Theory-Theory (TT) and Simulation-Theory (ST) to enhance ToM within the MARL framework. Building on the Digital Twins (DT) framework, we introduce the Mindful Human Digital Twin (MHDT). These intelligent systems enriched with ToM capabilities bridge the gap between artificial agents and human-like interactions. In this work, we utilized OpenAI Gymnasium to perform simulations and evaluate the effectiveness of our approach. This work represents a significant step forward in Artificial Intelligence (AI), resulting in socially intelligent systems capable of natural and intuitive interactions with both their environment and other agents. This approach is particularly effective in addressing critical social challenges such as school bullying. This research not only advances the growing field of MARL but also paves the way for sophisticated AI systems with enhanced ToM abilities, tailored for complex and sensitive real-world applications.},
  archive      = {J_ASOC},
  author       = {Luis Zhinin-Vera and Elena Pretel and Víctor López-Jaquero and Elena Navarro and Pascual González},
  doi          = {10.1016/j.asoc.2025.112939},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112939},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Mindful human digital twins: Integrating theory of mind with multi-agent reinforcement learning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A particle swarm optimization and constraint
programming-based approach for integrated process planning and
scheduling with lot streaming problem. <em>ASOC</em>, <em>174</em>,
112938. (<a href="https://doi.org/10.1016/j.asoc.2025.112938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the integrated process planning and scheduling with lot streaming (IPPS-LS) problem, which consists of lot splitting, process planning, and shop scheduling. Although the IPPS-LS problem is common in the manufacturing of flexible process products, it has not been extensively studied due to its high complexity. Hence, this study develops an enhanced particle swarm optimization algorithm based on constraint programming (CP) to minimize makespan. The proposed algorithm employs finite condition and relaxation models for particle reconfiguration and re-optimization. To achieve it, two types of relaxation models are constructed by decomposing the multiple constraints of the CP model. The algorithm dynamically updates particle encoding sequences based on model accuracy, effectively reducing invalid searches and accelerating the search process. The proposed algorithm is compared with models and other metaheuristic algorithms on 120 test instances. The impact of the relaxed CP strategy and particle swarm optimization algorithm on the proposed algorithm performance is also analyzed. Finally, a significance of difference validation is performed. Computational experiments demonstrate the efficiency of the proposed algorithm in solving the IPPS-LS problem of varying scales. In addition, the relaxed CP strategy exhibits a more significant improvement effect for medium-scale problems compared to small and large-scale problems.},
  archive      = {J_ASOC},
  author       = {Mengya Zhang and Xinyu Li and Liang Gao and Qihao Liu},
  doi          = {10.1016/j.asoc.2025.112938},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112938},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A particle swarm optimization and constraint programming-based approach for integrated process planning and scheduling with lot streaming problem},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heuristic-aided fusion serial cascaded deep network for
handwritten character recognition from handwritten images using
optimization strategy. <em>ASOC</em>, <em>174</em>, 112937. (<a
href="https://doi.org/10.1016/j.asoc.2025.112937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten Character Recognition (HCR) identifies and interprets handwritten text, converting it into machine-readable characters. However, it faces challenges with South Indian languages due to their complex scripts and intricate characters. So, in this work, a novel HCR model was introduced for automatic recognition of handwritten characters in South Indian languages. At first, required Telugu and Kannada handwritten images are collected from standard sources, and given into the segmentation phase using Active Contour. Then, the textural pattern generation is performed using the Adaptive Local Weber Pattern (ALWP). The weights in the ALWP are optimally tuned using the Improved Snow Leopard Optimization Algorithm (ISLOA). Finally, the ALWP generates a textural pattern, and then the generated textural pattern is given to the Hybrid Serial Cascaded Deep Network (HSCDNet) for the final handwritten character recognition process. Here, the Convolutional Autoencoder (CAE) and Deep Belief Network (DBN) are serially connected to the network. Finally, the implemented HCR model’s performance is evaluated by comparing it with various traditional approaches. The developed model attained the accuracy of dataset 1 is 93.45 %, dataset 2 is 93.11 %, and dataset 3 is 94.13 %. Thus, it proved that the developed model can effectively and easily recognize the curves in the Telugu and Kannada handwritten scripts, making it suitable for a wide range of applications.},
  archive      = {J_ASOC},
  author       = {Triveni Banavatu and Govindaswamy Parthasarathy},
  doi          = {10.1016/j.asoc.2025.112937},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112937},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Heuristic-aided fusion serial cascaded deep network for handwritten character recognition from handwritten images using optimization strategy},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized echo state network for error compensation based on
transfer learning. <em>ASOC</em>, <em>174</em>, 112935. (<a
href="https://doi.org/10.1016/j.asoc.2025.112935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Echo State Network (ESN) is widely applied in nonlinear system modeling, but its performance is often limited by a lack of error autocorrelation analysis, leading to reduced modeling accuracy. Existing extensions, such as SR-ESN and ERBM, primarily focus on structural optimization or feature representation but fail to effectively address autocorrelation errors. To overcome these limitations, we propose a Transfer Learning-based Echo State Network (TLESN) that compensates for errors in realtime to enhance prediction accuracy. The TLESN integrates a computing layer based on ESN and a compensation layer employing transfer learning, which dynamically adjusts output weights. To validate the proposed model, experiments are conducted on the Mackey-Glass time series, a practical Sunspot dataset, and a real-world industrial dataset. Results demonstrate that TLESN effectively mitigates autocorrelation errors, achieving at least a 17% improvement in prediction accuracy compared to existing ESN extensions.},
  archive      = {J_ASOC},
  author       = {Yingqin Zhu and Yue Liu and Zhaozhao Zhang and Wen Yu},
  doi          = {10.1016/j.asoc.2025.112935},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112935},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Optimized echo state network for error compensation based on transfer learning},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptive person re-identification with noise
optimization and dynamic weighting. <em>ASOC</em>, <em>174</em>, 112932.
(<a href="https://doi.org/10.1016/j.asoc.2025.112932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptive person re-identification (Re-ID) faces challenges due to inherent noise from limited domain transferability and the uncertainty in pseudo-label generation. To address this, we propose NODW (Noise Optimization and Dynamic Weighting), a comprehensive domain adaptive person Re-ID framework that systematically tackles these issues through quantitative noise assessment and dynamic optimization. Our method proposes: (1) an enhanced ResNet50-pro backbone specifically designed for cross-domain feature extraction, (2) a silhouette coefficient-based module for pseudo-label quality assessment with dynamic weighting, (3) a Maximum Mean Discrepancy (MMD)-based module for minimizing domain transferability limitations, and (4) a robust consistency supervision mechanism to ensure stable feature learning. Extensive experiments demonstrate state-of-the-art performance across multiple domain transfer tasks, achieving mAP scores of 73.8% (Market to Duke), 84.7% (Duke to Market), 34.2% (Market to MSMT), and 35.6% (Duke to MSMT). These results represent significant improvements over existing methods, particularly in challenging scenarios with large domain gaps, validating the effectiveness of our noise-aware adaptation strategy.},
  archive      = {J_ASOC},
  author       = {Zhengyang Wang and Xiufen Ye and Xue Shang and Shuxiang Guo},
  doi          = {10.1016/j.asoc.2025.112932},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112932},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Domain adaptive person re-identification with noise optimization and dynamic weighting},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Software and hardware synergy for accelerated plant disease
identification. <em>ASOC</em>, <em>174</em>, 112926. (<a
href="https://doi.org/10.1016/j.asoc.2025.112926">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plant diseases are one of the main causes of reduced crop yields. Therefore, it is necessary to adopt timely and effective identification methods and take corresponding measures. Some physical and biological detection methods have been proposed by researchers, but these methods require specialized techniques and expensive detection costs. Furthermore, the limited number of skilled technicians means that disease identification is not always timely or effective. To achieve real-time identification of plant diseases in remote areas where network and circuit are not well connected, We adopted a hardware and software co-acceleration approach to implement the design. First, we designed a lightweight convolutional neural network (CNN) and trained this network using a knowledge distillation approach. Then, we quantified the model parameters into int8 type using a method of model quantization to further compress the model size. After compression, the model size of the network is 0.035 MB and the recognition accuracy is 94.06% on the test set of the experiment. In order to deploy the proposed network on resource constrained Field-Programmable Gate Array (FPGA) devices, we used time-division multiplexing and feature map segmentation to deploy the network. Finally, our design is implemented on ZYNQ7020 with an inference speed of 35.73ms/frame and a power consumption of 1.97 W. The experimental results show that our design has the advantages of consuming less FPGA resources, low power consumption, high speed and portability. It can be used for disease recognition in multiple plant classes.},
  archive      = {J_ASOC},
  author       = {Hongxing Wen and Chuandong Li and Xinpei Wang and Ling Chen},
  doi          = {10.1016/j.asoc.2025.112926},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112926},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Software and hardware synergy for accelerated plant disease identification},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced function approximation and applications to image
scaling: A new family of exponential sampling neural network kantorovich
operators. <em>ASOC</em>, <em>174</em>, 112923. (<a
href="https://doi.org/10.1016/j.asoc.2025.112923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel family of exponential sampling type neural network Kantorovich operators, extending the work of Bajpeyi and Kumar (2021) and Bajpeyi (2023). Unlike previous research focused on approximating continuous functions, our operators are designed to handle Lebesgue integrable functions, offering enhanced versatility. We establish convergence theorems, analyze asymptotic behavior, and demonstrate the effectiveness of linear combinations for improving convergence rates. Our analysis extends to the multivariate setting, highlighting the operators’ capability in approximating a wide range of functions. To evaluate the practical performance of our proposed operators, we conducted numerical experiments with different sigmoidal functions and parameter values. Our findings reveal that operators activated by the Parametric sigmoid function consistently outperform those activated by other sigmoidal functions, achieving up to 20.70% reduction in maximum absolute error and 10.03% reduction in root mean squared errors. When applied to image scaling, our operators demonstrated superior performance compared to state-of-the-art methods like nearest neighbor, bilinear, and bicubic interpolation. For the ’Baboon’ image, we observed up to 5.62% increase in Peak Signal-to-Noise Ratio (PSNR) and 5.25% increase in Structural Similarity Index Measure (SSIM). Similar enhancements were observed for the ’Flowers’ and ’Retina’ images. The paper includes a detailed description of the image processing algorithm, along with a flowchart illustrating the implementation. These results underscore the operators’ potential in various machine learning tasks, motivating further research into their applications and optimization.},
  archive      = {J_ASOC},
  author       = {P.N. Agrawal and Behar Baxhaku and Artan Berisha},
  doi          = {10.1016/j.asoc.2025.112923},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112923},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Enhanced function approximation and applications to image scaling: A new family of exponential sampling neural network kantorovich operators},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust ensemble classifier for imbalanced data via
adaptive variety oversampling and embedded sampling rate. <em>ASOC</em>,
<em>174</em>, 112922. (<a
href="https://doi.org/10.1016/j.asoc.2025.112922">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel hybrid approach for addressing imbalanced data classification. The core concept involves devising a data-based oversampling algorithm to partially re-balance the data and employing an ensemble algorithm to enhance model performance. The merits of the proposed hybrid method can be highlighted as follows: (1) rather than re-balancing the data completely, an incomplete yet rational sampling rate is adopted to synthesize new samples, which can reduce the extreme imbalance ratio as well as avoid the overlap and redundancy by the complete re-balance. After oversampling, an improved adaptive boosting method is used to further contribute to the classification result; (2) with the help of temporarily generating samples in a triangular region of four selected target samples, a new synthesizing method is provided, which contributes greatly to the diversity of the new synthetic samples and the guarantee of the correctness and safety; (3) besides the number of correctly classified minority samples, the imbalance ratio of raw data is considered to make the ensemble classifier serve a further focus on minority samples and proved theoretically effective in mitigating the skew of the classification hyperplane on minority samples.},
  archive      = {J_ASOC},
  author       = {Jun Dou and Yan Song and Guoliang Wei and Xinchen Guo},
  doi          = {10.1016/j.asoc.2025.112922},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112922},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A robust ensemble classifier for imbalanced data via adaptive variety oversampling and embedded sampling rate},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting time series using convolutional neural network
with multiplicative neuron. <em>ASOC</em>, <em>174</em>, 112921. (<a
href="https://doi.org/10.1016/j.asoc.2025.112921">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are proven to be efficient in time series forecasting, however architectural selection remains a challenging task. This work aims to propose CNN, utilizing single multiplicative neuron model in forecasting time series, intended to eliminate architectural complexities of classical CNN ensuring its computational efficiency. Applicability of proposed approach is employed on financial time series datasets such as Index, Stocks, Cryptocurrencies and a commodity in evaluating the model’s performance on the basis of RMSE, MAE and R 2 values. Further, time-delay effects were also observed in datasets which has been analyzed to improve the accuracy of the proposed model. Based on the lowest RMSE and MAE values, and higher R 2 values, the optimal delay value has been analyzed which has been used for forecasting. The result demonstrates that in data sets like NIFTY50, SBI, Bitcoin, and Natural Gas, the forecasting efficiency is improved when compared to classical CNN. The results obtained can be used to draw valuable insights for decision making, which will enable future studies and facilitate easy adaptation in analyzing time series.},
  archive      = {J_ASOC},
  author       = {Shobhit Nigam},
  doi          = {10.1016/j.asoc.2025.112921},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112921},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Forecasting time series using convolutional neural network with multiplicative neuron},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised partially labeled heterogeneous feature
selection based on information-theoretic three-way decision model.
<em>ASOC</em>, <em>174</em>, 112880. (<a
href="https://doi.org/10.1016/j.asoc.2025.112880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection plays an increasingly vital role in addressing large-scale partially labeled heterogeneous data. Three-way decision (TWD) theory is an important extension of classical two-way decision, which provides an approach to acquire a ternary classification of the universe as acceptance region, rejection region and boundary region, respectively, while the boundary region can capture the uncertain information. In this paper, taking consideration of heterogeneous data possessing tremendous unlabeled samples, we present two kinds of feature representation metric based on unlabeled sample selection mechanism to construct more effective feature selection models. Specifically, a generalized variable-precision neighborhood rough set model is first proposed based on a TWD model developed by optimal threshold pair, which describes the relationships between features and labels from a more fine-grained level. Second, a unlabeled sample selection framework is proposed to comprehensively measure the importance of unlabeled samples based on their uncertainty, graph density and label transfer ability. We then define six TWD-based measures which reveal nonlinear correlation and inconsistency between features and labels by extended information entropy and complementary entropy, respectively. Furthermore, the unified feature measures are established to boost global feature selection in partially labeled heterogeneous datasets. Finally, the corresponding feature selection algorithm is designed, and the comparative experiments demonstrate the effectiveness and efficiency.},
  archive      = {J_ASOC},
  author       = {Qianqian Sun and Hongying Zhang and Weiping Ding},
  doi          = {10.1016/j.asoc.2025.112880},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112880},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Semi-supervised partially labeled heterogeneous feature selection based on information-theoretic three-way decision model},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse-view planar 3D reconstruction method based on
hierarchical token pooling transformer. <em>ASOC</em>, <em>174</em>,
112833. (<a href="https://doi.org/10.1016/j.asoc.2025.112833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse-view planar 3D reconstruction aims to recover scene information from limited camera frames, which poses a fundamental problem in computer vision. Although previous methods have made significant improvements in this field, they have not adequately considered the multi-scale properties of the surrounding environment, thus limiting the reconstruction performance. Additionally, the conventional feed-forward network in the vanilla Transformer is constructed using fully connected layers, lacking the ability to capture local information from image features. To address these two problems, this paper proposes a sparse-view planar 3D reconstruction method based on hierarchical token pooling Transformer ( i.e . HTP-Formers). Specifically, we utilize average pooling layers with various ratios in Transformer model to capture multi-scale features. Subsequently, we propose a depth-wise convolution based inverted residual feed-forward network to enhance local information extraction performance at negligible computational cost. To demonstrate the effectiveness of HTP-Formers on planar 3D reconstruction tasks, we thoroughly evaluate the proposed model on Matterport3D public dataset. Especially, HTP-Formers improves performance by 6.1% and 18.3% in translational and rotational errors, respectively, outperforming most existing planar 3D reconstruction methods in terms of planar correspondence inference and relative camera pose estimation.},
  archive      = {J_ASOC},
  author       = {Jiahui Zhang and Jinfu Yang and Fuji Fu and Jiaqi Ma},
  doi          = {10.1016/j.asoc.2025.112833},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112833},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Sparse-view planar 3D reconstruction method based on hierarchical token pooling transformer},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-path geometric relation-aware transformer for point
cloud classification and segmentation. <em>ASOC</em>, <em>174</em>,
112801. (<a href="https://doi.org/10.1016/j.asoc.2025.112801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud analysis is a challenging task due to the disorder and irregularity of the point cloud data. Traditional methods focus on constructing local or global geometric feature extractors to leverage the geometric features of the point cloud. However, traditional methods have the disadvantage of high time complexity and consume numerous resources because of the sophisticated extractors. This paper proposes a dual-path geometric relation-aware transformer network (DuGREAT) to aggregate local and global features, which balances computational cost, efficiency, and accuracy. DuGREAT constructs a channel adaptive multi-layer perceptron module by expanding channels of residual blocks to reinforce the local feature extraction. To obtain the geometric relation of a 3D object, we design a geometric point disentangler to categorize the point cloud into key and non-key points, respectively represented by an object’s local and global regions. With a relation-aware transformer network, the global path processes the non-key points to extract deep-level global features, and the local path focuses on the key points to calculate the difference between the local and global features. To the best of our knowledge, this is one of the successful attempts to capture and enhance geometric relations and feature fusion between key and non-key points, which provides insights for point cloud classification and segmentation. Fitted with a soft geometric affine module to alleviate the irregularity of the point cloud, DuGREAT acts better than several state-of-the-art methods on multiple datasets. Specifically, our DuGREAT achieves 94.6% accuracy on the ModelNet40 classification task and 87.3% accuracy on the ScanObjectNN classification task, outperforming the other transformer models. DuGREAT-simple, a simple version with fewer FLOPs, attains 94.2% and 87.0% accuracy on the ModelNet40 classification and ScanObjectNN classification tasks, respectively, while maintaining a faster inference speed (595.7 samples/s). Furthermore, we validate the effectiveness of the modules in DuGREAT and achieve instance mean Intersection over Union (mIoU) of 86.5% (DuGREAT) and 86.1% (DuGREAT-simple) on the ShapeNetPart segmentation task.},
  archive      = {J_ASOC},
  author       = {Xiangli Li and Qifan Wang and Baozhi Qiu},
  doi          = {10.1016/j.asoc.2025.112801},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112801},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Dual-path geometric relation-aware transformer for point cloud classification and segmentation},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-objective multi-task evolutionary algorithm based on
source task transfer. <em>ASOC</em>, <em>174</em>, 112732. (<a
href="https://doi.org/10.1016/j.asoc.2025.112732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the real world, many optimization problems often do not exist in isolation, they usually have complex interactions and dependencies, and have multiple optimization goals. In order to improve the performance of individual task solving, an evolutionary multi-task multi-objective optimization algorithm (MTMOO) is proposed. However, most of the current evolutionary algorithms are based on the assumption that the prior knowledge (experience in solving optimization problems) is zero, which makes the ability of the algorithm to solve problems cannot be improved with the increase of historical experience, and greatly limits the adaptability and learning ability of the algorithm. In order to overcome this limitation, this paper proposed a multi-objective and multi-task adaptive migration Evolutionary algorithm (MOMFEA-STT). The algorithm constructs the parameter sharing model of historical task and target task online. By identifying the degree of association between different tasks, the intensity of cross-task knowledge transfer is automatically adjusted to maximize the capture, sharing and utilization of common useful knowledge to solve related tasks. In addition, in order to strengthen the exploration and exploitation ability of the algorithm and avoid the problem that the algorithm is easy to fall into the local optimum, the MOMFEA-STT adopts a new method of generation of children, generates children by using spiral search mode, and constantly adjusts the search direction of the algorithm. Experimental results show that the proposed method outperforms the existing algorithms on the multi-task optimization benchmark problems.},
  archive      = {J_ASOC},
  author       = {Zheng-Yi Chai and ying Nie and Yan-Lun Li},
  doi          = {10.1016/j.asoc.2025.112732},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112732},
  shortjournal = {Appl. Soft. Comput.},
  title        = {A multi-objective multi-task evolutionary algorithm based on source task transfer},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Calculating forgotten effects using fuzzy numbers based on
embedded experton structures. <em>ASOC</em>, <em>174</em>, 112720. (<a
href="https://doi.org/10.1016/j.asoc.2025.112720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The method of calculating Forgotten Effects is designed to process a single source of information, preventing the use of multiple sources, which can generate bias in the results and avoid the wide use of this methodology in the investigations. This research aims to establish a mechanism for processing Expertons as structured data in their natural form, without decreasing entropy within the matrices of the Forgotten Effects, and thus be able to process information from many sources. This process aims to maintain the original values during the whole calculating process and avoid distorted information. The presented algorithm for calculating Forgotten Effects in decision-making under uncertainty utilizes fuzzy numbers in Expertons embedded and constitutes an innovative approach. This approach complements conventional methodologies that often rely on averages or weights to derive a single value and confirm hypotheses. This model has a different paradigm, as it detects relationships that are not visible for systematic analysis. Additionally, this research introduces various types of focus based on risk profiles for calculation strategies, yielding prudent, optimistic, and pessimistic scenarios. Moreover, the proposed algorithm provides the flexibility to choose between uncertainty or precision-focused processing to adapt to the specific approach of each context. Ultimately, an applied example is presented to validate the effectiveness and validity of the proposed model. As a contribution, this research offers the novelty of being able to calculate forgotten effects, not only based on one expert but also with an unlimited number by using the algorithm designed through the Expertons.},
  archive      = {J_ASOC},
  author       = {Darley Biviana Pacheco Cubillos and Josefa Boria Reverter and Jaime Gil Lafuente},
  doi          = {10.1016/j.asoc.2025.112720},
  journal      = {Applied Soft Computing},
  month        = {4},
  pages        = {112720},
  shortjournal = {Appl. Soft. Comput.},
  title        = {Calculating forgotten effects using fuzzy numbers based on embedded experton structures},
  volume       = {174},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="autom---33">AUTOM - 33</h2>
<ul>
<li><details>
<summary>
(2025). External bias and opinion clustering in cooperative
networks. <em>AUTOM</em>, <em>175</em>, 112224. (<a
href="https://doi.org/10.1016/j.automatica.2025.112224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we consider a group of n agents which interact with each other in a cooperative framework. A Laplacian-based model is proposed to govern the evolution of opinions in the group when the agents are subjected to external biases like agents’ traits, news, etc . The objective of the paper is to design a control input which leads to any desired opinion clustering even in the presence of external bias factors. Further, we also determine the conditions which ensure the reachability to any arbitrary opinion states. Note that all of these results hold for any kind of graph structure. Finally, some numerical simulations are discussed to validate these results.},
  archive      = {J_AUTOM},
  author       = {Akshay Nagesh Kamthe and Vishnudatta Thota and Aashi Shrinate and Twinkle Tripathy},
  doi          = {10.1016/j.automatica.2025.112224},
  journal      = {Automatica},
  month        = {5},
  pages        = {112224},
  shortjournal = {Automatica},
  title        = {External bias and opinion clustering in cooperative networks},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal transport of linear systems over equilibrium
measures. <em>AUTOM</em>, <em>175</em>, 112222. (<a
href="https://doi.org/10.1016/j.automatica.2025.112222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the optimal transport problem over convex costs arising from optimal control of linear time-invariant(LTI) systems when the initial and target measures are assumed to be supported on the set of equilibrium points of the LTI system. In this case, the probability measures are singular with respect to the Lebesgue measure, thus not considered in previous results on optimal transport of linear systems. This problem is motivated by applications, such as robotics, where the initial and target configurations of robots, represented by measures, are in equilibrium or stationary. Despite the singular nature of the measures, for many cases of practical interest, we show that the Monge problem has a solution by applying classical optimal transport results. Moreover, the problem is computationally tractable even if the state space of the LTI system is moderately high in dimension, provided the equilibrium set lives in a low dimensional space. In fact, for an important subclass of minimum energy problems, such as control of the double integrator with minimum energy cost, the optimal transport map happens to coincide with that of the square Euclidean cost. We demonstrate our results by computing the optimal transport map for the minimum energy cost for a two dimensional double integrator, despite the fact that the state space is four dimensional due to position and velocity variables.},
  archive      = {J_AUTOM},
  author       = {Karthik Elamvazhuthi and Matt Jacobs},
  doi          = {10.1016/j.automatica.2025.112222},
  journal      = {Automatica},
  month        = {5},
  pages        = {112222},
  shortjournal = {Automatica},
  title        = {Optimal transport of linear systems over equilibrium measures},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian framework for nonlinear state estimation with
stochastic event-trigger and packet losses. <em>AUTOM</em>,
<em>175</em>, 112220. (<a
href="https://doi.org/10.1016/j.automatica.2025.112220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear state estimation with stochastic event-trigger and packet losses is studied in this paper. To handle the nonlinearity and the uncertainty of the available information, the recursive probability density functions (PDFs) are characterized as Gaussian. Then, an event-trigger and packet losses induced Gaussian filter (EPGF) and its Gaussian smoother (EPGS) are derived to develop a new Gaussian framework. This developed framework is an extension of the standard Gaussian one and suitable for both linear and nonlinear systems. The key to its implementation is calculating a series of integrals with the Gaussian weight form, which can be approximated by various numerical techniques. In addition, according to the rule of three-degree spherical-radial cubature, two specific filtering and smoothing algorithms of the proposed framework are presented. Finally, a numerical simulation illustrates the effectiveness of the developed scheme.},
  archive      = {J_AUTOM},
  author       = {Weijun Lv and Chang Liu and Yong Xu and Renquan Lu and Ling Shi},
  doi          = {10.1016/j.automatica.2025.112220},
  journal      = {Automatica},
  month        = {5},
  pages        = {112220},
  shortjournal = {Automatica},
  title        = {Gaussian framework for nonlinear state estimation with stochastic event-trigger and packet losses},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State prediction using a high-gain distributed scheme.
<em>AUTOM</em>, <em>175</em>, 112219. (<a
href="https://doi.org/10.1016/j.automatica.2025.112219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time delays pose unique challenges in control engineering, as inherent delays can introduce instabilities and compromise system performance. To overcome these complexities, the concept of predictors or compensators has been instrumental in stabilising closed-loop systems. Still, it requires an accurate delayed state estimation through the design and implementation of predictors. In this paper, we delve into the design of novel prediction architectures tailored to nonlinear systems with input and output delays that not only ensure stability but also bolster robustness, emphasising their ability to preserve stability despite measurement noises or external perturbations.},
  archive      = {J_AUTOM},
  author       = {Mathieu Bajodek and Fernando Castaños and Sabine Mondié},
  doi          = {10.1016/j.automatica.2025.112219},
  journal      = {Automatica},
  month        = {5},
  pages        = {112219},
  shortjournal = {Automatica},
  title        = {State prediction using a high-gain distributed scheme},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A critical escape probability formulation for enhancing the
transient stability of power systems with system parameter design.
<em>AUTOM</em>, <em>175</em>, 112217. (<a
href="https://doi.org/10.1016/j.automatica.2025.112217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the enhancement of the transient stability of power systems, the key is to define a quantitative optimization formulation with system parameters as decision variables. In this paper, we model the disturbances by Gaussian noise and define a metric named Critical Escape Probability (CREP) based on the invariant probability measure of a linearized stochastic process. CREP characterizes the probability of the state escaping from a critical set. CREP involves all the system parameters and reflects the size of the basin of attraction of the nonlinear systems. An optimization framework that minimizes CREP with the system parameters as decision variables is presented. Simulations show that the mean of the first hitting time when the state hits the boundary of the critical set, that is often used to describe the stability of nonlinear systems, is dramatically increased by minimizing CREP. This indicates that the transient stability of the system is effectively enhanced. It is also shown that suppressing the state fluctuations only is insufficient for enhancing the transient stability. In addition, the famous Braess’ paradox which also exists in power systems is revisited. Surprisingly, it turned out that the paradoxes identified by the traditional metric may not exist according to CREP. This new metric opens a new avenue for the transient stability analysis of future power systems integrated with large amounts of renewable energy.},
  archive      = {J_AUTOM},
  author       = {Xian Wu and Kaihua Xi and Aijie Cheng and Chenghui Zhang and Hai Xiang Lin},
  doi          = {10.1016/j.automatica.2025.112217},
  journal      = {Automatica},
  month        = {5},
  pages        = {112217},
  shortjournal = {Automatica},
  title        = {A critical escape probability formulation for enhancing the transient stability of power systems with system parameter design},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal spatial–temporal triangulation for bearing-only
cooperative motion estimation. <em>AUTOM</em>, <em>175</em>, 112216. (<a
href="https://doi.org/10.1016/j.automatica.2025.112216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based cooperative motion estimation is an important problem for many multi-robot systems such as cooperative aerial target pursuit. This problem can be formulated as bearing-only cooperative motion estimation, where the visual measurement is modeled as a bearing vector pointing from the camera to the target. The conventional approaches for bearing-only cooperative estimation are mainly based on the framework of distributed Kalman filtering (DKF). In this paper, we propose a new optimal bearing-only cooperative estimation algorithm, named spatial–temporal triangulation, based on the method of distributed recursive least squares. The design of the algorithm fully incorporates all the available information and the specific triangulation geometric constraint. As a result, the algorithm has superior estimation performance than the state-of-the-art DKF algorithms in terms of both accuracy and convergence speed as verified by numerical simulation. We rigorously prove the exponential convergence of the proposed algorithm. Moreover, to verify the effectiveness of the proposed algorithm under practical challenging conditions, we develop a vision-based cooperative aerial target pursuit system, which is the first of such fully autonomous systems up to now to the best of our knowledge.},
  archive      = {J_AUTOM},
  author       = {Canlun Zheng and Yize Mi and Hanqing Guo and Huaben Chen and Zhiyun Lin and Shiyu Zhao},
  doi          = {10.1016/j.automatica.2025.112216},
  journal      = {Automatica},
  month        = {5},
  pages        = {112216},
  shortjournal = {Automatica},
  title        = {Optimal spatial–temporal triangulation for bearing-only cooperative motion estimation},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible-step model predictive control based on generalized
lyapunov functions. <em>AUTOM</em>, <em>175</em>, 112215. (<a
href="https://doi.org/10.1016/j.automatica.2025.112215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel nonlinear model predictive control (MPC) scheme with relaxed stability criteria, based on the idea of generalized discrete-time control Lyapunov functions. These functions need to satisfy an average descent over a finite window of time, rather than a descent at every time step. One feature of this scheme is that it allows for implementing a flexible number of control inputs in each iteration, in a computationally attractive manner, while guaranteeing recursive feasibility and stability. The benefits of our flexible-step implementation are also demonstrated in an application to nonholonomic systems, where the one-step standard implementation may suffer from lack of asymptotic convergence.},
  archive      = {J_AUTOM},
  author       = {Annika Fürnsinn and Christian Ebenbauer and Bahman Gharesifard},
  doi          = {10.1016/j.automatica.2025.112215},
  journal      = {Automatica},
  month        = {5},
  pages        = {112215},
  shortjournal = {Automatica},
  title        = {Flexible-step model predictive control based on generalized lyapunov functions},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maxentropic continuous-time homogeneous markov chains.
<em>AUTOM</em>, <em>175</em>, 112214. (<a
href="https://doi.org/10.1016/j.automatica.2025.112214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the notion of entropy rate and its maximization for continuous-time time-homogeneous irreducible finite-state Markov chains. The definitions available in continuous-time suffer from an apparent paradox, as they do not properly account for the role of the average commutation frequency. In fact, we show that the entropy rate is the sum of a finite and an infinite component, the latter depending on the average commutation frequency. Thus, entropy maximization is meaningful only between chains that share the same average frequency. After settling this issue, we address entropy rate maximization under different constraints on the stationary probability: unconstrained, completely fixed, partially fixed. Closed-form solutions and provably convergent iterative algorithms are provided. The results are illustrated through several examples, including chains with string and lattice graph topology. Interesting connections with quantum mechanics topics (particle-in-a-box model, Born rule, and Anderson localization property) are highlighted.},
  archive      = {J_AUTOM},
  author       = {Paolo Bolzern and Patrizio Colaneri and Giuseppe De Nicolao},
  doi          = {10.1016/j.automatica.2025.112214},
  journal      = {Automatica},
  month        = {5},
  pages        = {112214},
  shortjournal = {Automatica},
  title        = {Maxentropic continuous-time homogeneous markov chains},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed optimal coordination of multi-agent systems with
coupled objective functions: A fixed-time estimation-based approach.
<em>AUTOM</em>, <em>175</em>, 112213. (<a
href="https://doi.org/10.1016/j.automatica.2025.112213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores a class of distributed optimal coordination problems with coupled objectives, incorporating features of distributed optimization and non-cooperative game. In this context, the local objective functions of agents depend on their own decisions as well as the decisions made by other agents. The objective of the agents is to achieve optimal coordination by minimizing the team objective function, which represents the average of all agents’ local objective functions. The main challenge lies in obtaining the partial derivatives of the team objective function, which are aggregations of all local objective functions’ partial derivatives and cannot be directly obtained by the agents. To tackle this problem, distributed optimal coordination control laws based on fixed-time estimation are developed. These control laws utilize distributed fixed-time estimators that enable agents to estimate the team decision and partial derivatives of the team objective function within a fixed time. The proposed distributed optimal coordination control laws guarantee the exponential convergence of the agents to the optimal states when the constraint sets are independent. Under the condition of a common constraint set, the proposed laws further ensure fixed-time optimal coordination. A numerical example involving coordinated dynamic positioning of a multi-agent system is presented to demonstrate the effectiveness of the proposed algorithms.},
  archive      = {J_AUTOM},
  author       = {Xiao Fang and Guanghui Wen},
  doi          = {10.1016/j.automatica.2025.112213},
  journal      = {Automatica},
  month        = {5},
  pages        = {112213},
  shortjournal = {Automatica},
  title        = {Distributed optimal coordination of multi-agent systems with coupled objective functions: A fixed-time estimation-based approach},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stochastic dissipativity for systems with probabilistic
input delays. <em>AUTOM</em>, <em>175</em>, 112212. (<a
href="https://doi.org/10.1016/j.automatica.2025.112212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work considers stochastic operators in Hilbert spaces, and in particular, systems with stochastically time-varying input delays of a known probability distribution. Stochastic dissipativity and stability are defined from an operator-theoretic perspective, and the well-known open-loop dissipativity conditions for closed-loop/network stability are extended to the stochastic case. Criteria are derived to identify dissipative nonlinear systems with stochastic input delays, and this result is used to find delay-distribution-dependent linear matrix inequality conditions for stochastic dissipativity of a linear system with input delays of a known probability distribution. A numerical experiment demonstrates the utility of the resulting criteria for robust plant analysis and controller design, highlighting significantly reduced conservatism compared to deterministic methods.},
  archive      = {J_AUTOM},
  author       = {Ethan J. LoCicero and Amy K. Strong and Leila J. Bridgeman},
  doi          = {10.1016/j.automatica.2025.112212},
  journal      = {Automatica},
  month        = {5},
  pages        = {112212},
  shortjournal = {Automatica},
  title        = {Stochastic dissipativity for systems with probabilistic input delays},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projection-free computation of robust controllable sets with
constrained zonotopes. <em>AUTOM</em>, <em>175</em>, 112211. (<a
href="https://doi.org/10.1016/j.automatica.2025.112211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of computing robust controllable sets for discrete-time linear systems with additive uncertainty. We propose a tractable and scalable approach to inner- and outer-approximate robust controllable sets using constrained zonotopes, when the additive uncertainty set is a symmetric, convex, and compact set. Our least-squares-based approach uses novel closed-form approximations of the Pontryagin difference between a constrained zonotopic minuend and a symmetric, convex, and compact subtrahend. We obtain these approximations using two novel canonical representations for full-dimensional constrained zonotopes. Unlike existing approaches, our approach does not rely on convex optimization solvers, and is projection-free for ellipsoidal and zonotopic uncertainty sets. We also propose a least-squares-based approach to compute a convex, polyhedral outer-approximation to constrained zonotopes, and characterize sufficient conditions under which all these approximations are exact. We demonstrate the computational efficiency and scalability of our approach in several case studies, including the design of abort-safe rendezvous trajectories for a spacecraft in near-rectilinear halo orbit under uncertainty. Our approach can inner-approximate a 20-step robust controllable set for a 100-dimensional linear system in under 15 s on a standard computer.},
  archive      = {J_AUTOM},
  author       = {Abraham P. Vinod and Avishai Weiss and Stefano Di Cairano},
  doi          = {10.1016/j.automatica.2025.112211},
  journal      = {Automatica},
  month        = {5},
  pages        = {112211},
  shortjournal = {Automatica},
  title        = {Projection-free computation of robust controllable sets with constrained zonotopes},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accelerated forward–backward and douglas–rachford splitting
dynamics. <em>AUTOM</em>, <em>175</em>, 112210. (<a
href="https://doi.org/10.1016/j.automatica.2025.112210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine convergence properties of continuous-time variants of accelerated Forward–Backward (FB) and Douglas–Rachford (DR) splitting algorithms for nonsmooth composite optimization problems. When the objective function is given by the sum of a quadratic and a nonsmooth term, we establish accelerated sublinear and exponential convergence rates for convex and strongly convex problems, respectively. Moreover, for FB splitting dynamics, we demonstrate that accelerated exponential convergence rate carries over to general strongly convex problems. In our Lyapunov-based analysis we exploit the variable-metric gradient interpretations of FB and DR splittings to obtain smooth Lyapunov functions that allow us to establish accelerated convergence rates. We provide computational experiments to demonstrate the merits and the effectiveness of our analysis},
  archive      = {J_AUTOM},
  author       = {Ibrahim K. Ozaslan and Mihailo R. Jovanović},
  doi          = {10.1016/j.automatica.2025.112210},
  journal      = {Automatica},
  month        = {5},
  pages        = {112210},
  shortjournal = {Automatica},
  title        = {Accelerated forward–backward and Douglas–Rachford splitting dynamics},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven dynamic optimal allocation for uncertain
over-actuated linear systems. <em>AUTOM</em>, <em>175</em>, 112208. (<a
href="https://doi.org/10.1016/j.automatica.2025.112208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamic control allocation problem for LTI systems is addressed in an uncertain setting. In the presence of unstructured uncertainties affecting the underlying plant, a completely data-driven strategy is envisioned to optimally allocate the control action in the presence of non-constant steady-state behavior of the plant, while leaving untouched the regulated output response induced by an a priori given controller. Compared with the current state of the art, the proposed solution exhibits several appealing features. Such features are: complete invisibility of the allocator’s action (after a training interval if the plant is unknown), exact optimization of the periodic steady-state evolution, arbitrary speed of the allocation action; while all of them are achieved even for unknown plants in this paper, in the current literature they are impossible to achieve or just obtainable for a perfectly known plant.},
  archive      = {J_AUTOM},
  author       = {Sergio Galeani and Roberto Masocco and Mario Sassano},
  doi          = {10.1016/j.automatica.2025.112208},
  journal      = {Automatica},
  month        = {5},
  pages        = {112208},
  shortjournal = {Automatica},
  title        = {Data-driven dynamic optimal allocation for uncertain over-actuated linear systems},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive non-cooperative differential games with a
regulator. <em>AUTOM</em>, <em>175</em>, 112201. (<a
href="https://doi.org/10.1016/j.automatica.2025.112201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers linear–quadratic non-cooperative non-zero-sum stochastic differential games with a regulator and analyzes the adaptive problem when the systems matrices are unknown to both the regulator and the players. It is a typical problem of game-based control systems(GBCS) introduced and studied recently, which have a hierarchical decision-making structure. The main purpose of the paper is to study how the adaptive strategies can be designed to make the GBCS globally stable and at the same time to ensure a Nash equilibrium reached by both the regulator and the players. Under some suitable conditions on the system matrices, it is shown that the closed-loop adaptive GBCS will be globally stable, and at the same time reach a Nash equilibrium by both the regulator and the players, where the adaptive strategies are constructed based on the least squares estimator, the switching method and the diminishing excitation.},
  archive      = {J_AUTOM},
  author       = {Nian Liu and Shaolin Tan and Ye Tao and Jinhu Lü},
  doi          = {10.1016/j.automatica.2025.112201},
  journal      = {Automatica},
  month        = {5},
  pages        = {112201},
  shortjournal = {Automatica},
  title        = {Adaptive non-cooperative differential games with a regulator},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed online path-length-independent algorithm for
noncooperative games over unbalanced digraphs. <em>AUTOM</em>,
<em>175</em>, 112200. (<a
href="https://doi.org/10.1016/j.automatica.2025.112200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies online noncooperative games with dynamic regrets. Existing online noncooperative games rely on the sublinear growth of the path-length of Nash equilibrium sequences when considering dynamic regrets, which implies that their cost functions cannot be rapidly time-varying. Moreover, most of related results depend on undirected communication graphs. However, in many engineering practices, the cost functions may change greatly over time and the communication graphs may be directed. Here our problem involves rapidly time-varying cost functions, i.e., the path-length of Nash equilibrium sequences at least linearly grows, and the interaction topologies are unbalanced digraphs. In order to make decisions online without regrets, we develop a distributed algorithm based on multi-step mirror descents. Under the algorithm, sublinear dynamic regret bounds are established. More importantly, the dynamic regrets are independent of the path-length of Nash equilibrium sequences, compared with existing results. Finally, the simulation results validate the effectiveness of our algorithm, and demonstrate that our algorithm has better performance than other related algorithms.},
  archive      = {J_AUTOM},
  author       = {Zhenhua Deng},
  doi          = {10.1016/j.automatica.2025.112200},
  journal      = {Automatica},
  month        = {5},
  pages        = {112200},
  shortjournal = {Automatica},
  title        = {Distributed online path-length-independent algorithm for noncooperative games over unbalanced digraphs},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Power and bit scheduling of markov jump systems with
convergence rate as an optimization index. <em>AUTOM</em>, <em>175</em>,
112199. (<a
href="https://doi.org/10.1016/j.automatica.2025.112199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing power and bit scheduling algorithms mostly focus on open-loop system performance, i.e., improving estimation accuracy. This paper focuses on the scheduling methods for the closed-loop Markov jump systems in the unreliable transmission environments to improve the system stability and save energy. First, a control unit including feedback controller and predictive controller is proposed which improves the system performance while reducing the complexity of predictive controller design. Second, we design a novel optimization indicator based on time-varying convergence rate and sensor energy consumption. Third, by analyzing the relationship between Lyapunov function and the system state, an explicit expression of the time-varying convergence rate is gained. Next, a constant χ is introduced to obtain the effective power set, in which the convergence rate is always less than 1, thereby ensuring the system stability. Based on this, the optimal power and bit scheduling algorithm is obtained, which improves the system convergence speed while reducing energy consumption. Last, a two-tanks system is used to verify the effectiveness and superiority of the main algorithms.},
  archive      = {J_AUTOM},
  author       = {Jingjing Yan and Yuanqing Xia and Xinjing Wang and Li Ma},
  doi          = {10.1016/j.automatica.2025.112199},
  journal      = {Automatica},
  month        = {5},
  pages        = {112199},
  shortjournal = {Automatica},
  title        = {Power and bit scheduling of markov jump systems with convergence rate as an optimization index},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DualBi: A dual bisection algorithm for non-convex problems
with a scalar complicating constraint. <em>AUTOM</em>, <em>175</em>,
112198. (<a
href="https://doi.org/10.1016/j.automatica.2025.112198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses non-convex constrained optimization problems that are characterized by a scalar complicating constraint. We propose an iterative bisection method for the dual problem (DualBi Algorithm) that recovers a feasible primal solution, with a performance that progressively improves throughout iterations. Application to multi-agent problems with a scalar coupling constraint results in a decentralized resolution scheme where a central unit is in charge of updating the (scalar) dual variable while agents compute their local primal variables. In the case of multi-agent MILPs, simulations showcase the performance of the proposed method compared with state-of-the-art duality-based approaches.},
  archive      = {J_AUTOM},
  author       = {Lucrezia Manieri and Alessandro Falsone and Maria Prandini},
  doi          = {10.1016/j.automatica.2025.112198},
  journal      = {Automatica},
  month        = {5},
  pages        = {112198},
  shortjournal = {Automatica},
  title        = {DualBi: A dual bisection algorithm for non-convex problems with a scalar complicating constraint},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Direct data-driven discounted infinite horizon linear
quadratic regulator with robustness guarantees. <em>AUTOM</em>,
<em>175</em>, 112197. (<a
href="https://doi.org/10.1016/j.automatica.2025.112197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a one-shot learning approach with performance and robustness guarantees for the linear quadratic regulator (LQR) control of stochastic linear systems. Even though data-based LQR control has been widely considered, existing results suffer either from data hungriness due to the inherently iterative nature of the optimization formulation (e.g., value learning or policy gradient reinforcement learning algorithms) or from a lack of robustness guarantees in one-shot non-iterative algorithms. To avoid data hungriness while ensuing robustness guarantees, an adaptive dynamic programming formalization of the LQR is presented that relies on solving a Bellman inequality. The control gain and the value function are directly learned by using a control-oriented approach that characterizes the closed-loop system using data and a decision variable from which the control is obtained. This closed-loop characterization is noise-dependent. The effect of the closed-loop system noise on the Bellman inequality is considered to ensure both robust stability and suboptimal performance despite ignoring the measurement noise. To ensure robust stability, it is shown that this system characterization leads to a closed-loop system with multiplicative and additive noise, enabling the application of distributional robust control techniques. The analysis of the suboptimality gap reveals that robustness can be achieved by construction without the need for regularization or parameter tuning. The simulation results on the active car suspension problem demonstrate the superiority of the proposed method in terms of robustness and performance gap compared to existing methods.},
  archive      = {J_AUTOM},
  author       = {Ramin Esmzad and Hamidreza Modares},
  doi          = {10.1016/j.automatica.2025.112197},
  journal      = {Automatica},
  month        = {5},
  pages        = {112197},
  shortjournal = {Automatica},
  title        = {Direct data-driven discounted infinite horizon linear quadratic regulator with robustness guarantees},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the detection of markov decision processes.
<em>AUTOM</em>, <em>175</em>, 112196. (<a
href="https://doi.org/10.1016/j.automatica.2025.112196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the detection problem for a finite set of Markov decision processes (MDPs) where the MDPs have the same state and action spaces but possibly different probabilistic transition functions. Any one of these MDPs could be the model for some underlying controlled stochastic process, but it is unknown a priori which MDP is the ground truth. We investigate whether it is possible to asymptotically detect the ground truth MDP model perfectly based on a single observed history (state–action sequence). Since the generation of histories depends on the policy adopted to control the MDPs, we discuss the existence and synthesis of policies that allow for perfect detection. We start with the case of two MDPs and establish a necessary and sufficient condition for the existence of policies that lead to perfect detection. Based on this condition, we then develop an algorithm that efficiently (in time polynomial in the size of the MDPs) determines the existence of policies and synthesizes one when they exist. We further extend the results to the more general case where there are more than two MDPs in the candidate set, and we develop a policy synthesis algorithm based on the breadth-first search and recursion. We demonstrate the effectiveness of our algorithms through numerical examples.},
  archive      = {J_AUTOM},
  author       = {Xiaoming Duan and Yagiz Savas and Rui Yan and Zhe Xu and Ufuk Topcu},
  doi          = {10.1016/j.automatica.2025.112196},
  journal      = {Automatica},
  month        = {5},
  pages        = {112196},
  shortjournal = {Automatica},
  title        = {On the detection of markov decision processes},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physics-informed neural network lyapunov functions: PDE
characterization, learning, and verification. <em>AUTOM</em>,
<em>175</em>, 112193. (<a
href="https://doi.org/10.1016/j.automatica.2025.112193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide a systematic investigation of using physics-informed neural networks to compute Lyapunov functions. We encode Lyapunov conditions as a partial differential equation (PDE) and use this for training neural network Lyapunov functions. We analyze the analytical properties of the solutions to the Lyapunov and Zubov PDEs. In particular, we show that employing the Zubov equation in training neural Lyapunov functions can lead to verifiable approximate regions of attraction close to the true domain of attraction. We also examine approximation errors and the convergence of neural approximations to the unique solution of Zubov’s equation. We then provide sufficient conditions for the learned neural Lyapunov functions that can be readily verified by satisfiability modulo theories (SMT) solvers, enabling formal verification of both local stability analysis and region-of-attraction estimates in the large. Through a number of nonlinear examples, ranging from low to high dimensions, we demonstrate that the proposed framework can outperform traditional sum-of-squares (SOS) Lyapunov functions obtained using semidefinite programming (SDP).},
  archive      = {J_AUTOM},
  author       = {Jun Liu and Yiming Meng and Maxwell Fitzsimmons and Ruikun Zhou},
  doi          = {10.1016/j.automatica.2025.112193},
  journal      = {Automatica},
  month        = {5},
  pages        = {112193},
  shortjournal = {Automatica},
  title        = {Physics-informed neural network lyapunov functions: PDE characterization, learning, and verification},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling-based stabilization for networked stochastic
systems with control-dependent noise. <em>AUTOM</em>, <em>175</em>,
112192. (<a
href="https://doi.org/10.1016/j.automatica.2025.112192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication constraint is prominent under the networked architecture, for which the scheduling problem needs to be considered. This paper aims at validating scheduling-based stabilization for networked stochastic systems (NSSs) characterized by the presence of control-dependent noise. Remarkably, control-dependent noise has never been taken into account in the context of scheduling-based control. Such noise has intricate impact on system stability, and should not be simply treated as an unfavorable factor. As such, sophisticated analysis is entailed for scheduling-based control in the stochastic setting. However, no available theory on stochastic stability could support the application of dynamic scheduling protocols confronted with control-dependent noise, while the case via static scheduling protocols can resort to the existing results on stochastic differential equations with bounded-delay dependent diffusion coefficients. As the main contribution, a framework of scheduling-based stabilization is established for the NSSs, covering the architecture where a certain dynamic protocol rules the scheduling of sensor-to-controller information transmission. Crucially, a distinct pattern of stability analysis is proposed based on delicate comparison between the solutions under scheduling-based (discrete-time) and network-free (continuous-time) controls. As a consequence, an intrinsic relation between the system stability rendered by two types of controls is revealed, with the network-induced error on measured output suitably exploited. Based on the relation, we further propose several directly-verifiable conditions of achieving almost sure exponential stability for the NSSs with scheduling-based control via try-once-discard protocol, the most typical one among dynamic scheduling protocols. Particularly, incorporating the underlying positive effect of the stochastic noise, one of the conditions allows the Lyapunov function candidates to have non-negative infinitesimal under corresponding continuous-time control, while no counterpart exists in the non-stochastic setting.},
  archive      = {J_AUTOM},
  author       = {Fengzhong Li and Yungang Liu},
  doi          = {10.1016/j.automatica.2025.112192},
  journal      = {Automatica},
  month        = {5},
  pages        = {112192},
  shortjournal = {Automatica},
  title        = {Scheduling-based stabilization for networked stochastic systems with control-dependent noise},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust model reference adaptive control for square MIMO LTI
systems with uniform vector relative degree of zero. <em>AUTOM</em>,
<em>175</em>, 112190. (<a
href="https://doi.org/10.1016/j.automatica.2025.112190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a systematic procedure for robust model reference adaptive control design for uncertain square multiple-input multiple-output (MIMO) continuous-time linear time-invariant (LTI) systems that admit uniform vector relative degree of zero, under the assumptions of minimum phase and that the upper bounds for the observability indices of all measurement channels are known. We assume that the unknown parameter vector lies in a convex compact set such that the high-frequency gain matrix remains invertible for any parameter vector value in the set. These assumptions allow for a successful design of a robust model reference adaptive controller. A numerical example is included to fully illustrate the controller design and the effectiveness of the controller. As compared with the recent paper Pan and Başar (2023), the problem with uniform vector relative degree of zero allows us to relieve the block diagonally identical backbone structure for the measurement channels, choose a general quadratic cost structure that weighs the tracking errors arbitrarily, and achieve optimality for the control design.},
  archive      = {J_AUTOM},
  author       = {Zigang Pan and Sheng Zeng and Tamer Başar},
  doi          = {10.1016/j.automatica.2025.112190},
  journal      = {Automatica},
  month        = {5},
  pages        = {112190},
  shortjournal = {Automatica},
  title        = {Robust model reference adaptive control for square MIMO LTI systems with uniform vector relative degree of zero},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online mixed discrete and continuous optimization:
Algorithms, regret analysis and applications. <em>AUTOM</em>,
<em>175</em>, 112189. (<a
href="https://doi.org/10.1016/j.automatica.2025.112189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study an online mixed discrete and continuous optimization problem where a decision maker interacts with an unknown environment over T rounds. At each round, the decision maker needs to jointly choose a discrete action and a continuous action and receives a reward associated with the chosen actions. The decision maker seeks to maximize the accumulative reward after T rounds. We propose algorithms to solve the online mixed discrete and continuous optimization problem that yield regret sublinear in T . We apply our algorithms to solve some important applications in practice with regret guarantees. We validate our theoretical results with numerical experiments.},
  archive      = {J_AUTOM},
  author       = {Lintao Ye and Ming Chi and Zhi-Wei Liu and Xiaoling Wang and Vijay Gupta},
  doi          = {10.1016/j.automatica.2025.112189},
  journal      = {Automatica},
  month        = {5},
  pages        = {112189},
  shortjournal = {Automatica},
  title        = {Online mixed discrete and continuous optimization: Algorithms, regret analysis and applications},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simultaneous distributed localization and formation tracking
control via matrix-weighted position constraints. <em>AUTOM</em>,
<em>175</em>, 112188. (<a
href="https://doi.org/10.1016/j.automatica.2025.112188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of 3-D relative-measurement-based leader–follower simultaneous distributed localization and formation tracking control. The position information is only available to the leaders, and the followers have inter-agent relative measurements and communication with their neighbors. The key contribution is the development of a weight-matrix-based position constraint, which can make use of relative measurements such as bearing, ratio-of-distance, angle, distance, relative position and their mixture to describe the position relationship among each follower and its neighbors in 3-D space. A bearing-based distributed protocol is proposed for each follower to estimate its position and track its target position, which can drive the followers from their unlocalizable positions to localizable positions. The proposed algorithm is then extended to the case that both bearing and ratio-of-distance measurements are available, where the followers are localizable at all times if the followers and their neighbors are not collocated. In addition, the proposed method is also applicable to homogeneous or heterogeneous angle, distance, and relative position measurements as the ratio-of-distances or bearings can be obtained indirectly by these relative measurements. A remarkable advantage is that the proposed method can be implemented without persistently exciting motions. Some illustrative simulations are presented to verify the theoretical results.},
  archive      = {J_AUTOM},
  author       = {Xu Fang and Lihua Xie and Dimos V. Dimarogonas},
  doi          = {10.1016/j.automatica.2025.112188},
  journal      = {Automatica},
  month        = {5},
  pages        = {112188},
  shortjournal = {Automatica},
  title        = {Simultaneous distributed localization and formation tracking control via matrix-weighted position constraints},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust moving horizon estimation for nonlinear systems: From
perfect to imperfect optimization. <em>AUTOM</em>, <em>175</em>, 112187.
(<a href="https://doi.org/10.1016/j.automatica.2025.112187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines the robust stability of moving-horizon estimators for nonlinear discrete-time systems that are detectable in the sense of incremental input/output-to-state stability and are affected by disturbances. The estimate of a moving-horizon estimator is derived from the on-line solution of a least-squares minimization problem at each time instant. The resulting stability guarantees depend on the optimization tolerance in solving these minimization problems. Specifically, two main contributions are established: (i) the robust stability of the estimation error, assuming the on-line minimization problem is solved exactly; (ii) the practical robust stability of the estimation error with state estimates obtained through imperfect minimization. Finally, the construction of such robust moving-horizon estimators and the performance resulting from the design based on the theoretical findings are showcased with two numerical examples.},
  archive      = {J_AUTOM},
  author       = {Angelo Alessandri},
  doi          = {10.1016/j.automatica.2025.112187},
  journal      = {Automatica},
  month        = {5},
  pages        = {112187},
  shortjournal = {Automatica},
  title        = {Robust moving horizon estimation for nonlinear systems: From perfect to imperfect optimization},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A delay-derivative-dependent switched system model method
for stability analysis of linear systems with time-varying delay.
<em>AUTOM</em>, <em>175</em>, 112183. (<a
href="https://doi.org/10.1016/j.automatica.2025.112183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the issue of delay- and its derivative-dependent stability of a linear system with a time-varying delay. Based on the sign of the delay derivative, the time-varying delay is divided into two modes, namely a monotone increasing mode and a monotone decreasing mode. Then the original delay system is described as a switched system with two modes. This description motivates to construct a monotone-mode-based switching Lyapunov–Krasovskii functional, which allows different Lyapunov matrices for each mode in stability analysis of time-delay systems. By employing the average dwell time technique, several sufficient stability criteria are presented for the system under study. Over two extensively studied examples, we demonstrate that the proposed stability criteria can deliver larger delay upper bounds than some existing methods.},
  archive      = {J_AUTOM},
  author       = {Hong-Bing Zeng and Yu-Jie Chen and Yong He and Xian-Ming Zhang},
  doi          = {10.1016/j.automatica.2025.112183},
  journal      = {Automatica},
  month        = {5},
  pages        = {112183},
  shortjournal = {Automatica},
  title        = {A delay-derivative-dependent switched system model method for stability analysis of linear systems with time-varying delay},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditions for global synchronization in networks of
heterogeneous kuramoto oscillators. <em>AUTOM</em>, <em>175</em>,
112180. (<a
href="https://doi.org/10.1016/j.automatica.2025.112180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kuramoto model is essential for studying synchronization. In this work, we present sufficient conditions for global synchronization in networks of heterogeneous Kuramoto oscillators in the absence of homoclinic and heteroclinic cycles. The result is established by constructing a suitable Leonov function candidate for the Kuramoto model, which provides sufficient conditions for almost global synchronization in networks with acyclic and meshed topologies. The synchronization property is accompanied by necessary and sufficient conditions to guarantee the existence of equilibria, which are satisfied if the conditions for synchronization hold. The implications of the main conditions and their relationship with the network topology and parameters are discussed. Finally, the results are illustrated via a numerical example.},
  archive      = {J_AUTOM},
  author       = {Angel Mercado-Uribe and Jesus Mendoza-Avila and Denis Efimov and Johannes Schiffer},
  doi          = {10.1016/j.automatica.2025.112180},
  journal      = {Automatica},
  month        = {5},
  pages        = {112180},
  shortjournal = {Automatica},
  title        = {Conditions for global synchronization in networks of heterogeneous kuramoto oscillators},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed fault-tolerant control of multi-UAV formation
for dynamic leader tracking: A lyapunov-based MPC framework.
<em>AUTOM</em>, <em>175</em>, 112179. (<a
href="https://doi.org/10.1016/j.automatica.2025.112179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the formation tracking control problem of multiple unmanned aerial vehicles (UAVs) interconnected through a directed communication graph. The objective is to ensure that the vehicles attain a predetermined geometric configuration while simultaneously tracking a dynamic virtual leader in the presence of unexpected actuator faults. A novel distributed model predictive control (MPC) framework is proposed, where each UAV is equipped with an individual controller that adopts a hierarchical architecture comprising three sequentially connected control layers. The outer layer, integrating the Lyapunov-based MPC method with an adaptive parameter estimator, determines translation tracking control actions. The intermediate layer enforces the convergence of actual rotation angles toward the desired ones determined by the outer layer. The inner layer generates the torque control commands for rapid convergence of the angular velocities. The closed-loop stability of the entire multi-UAV system is rigorously analyzed, and sufficient conditions regarding the selection of user-defined parameters are established. Simulation results are provided to demonstrate the effectiveness of the proposed design.},
  archive      = {J_AUTOM},
  author       = {Binyan Xu and Yufan Dai and Afzal Suleman and Yang Shi},
  doi          = {10.1016/j.automatica.2025.112179},
  journal      = {Automatica},
  month        = {5},
  pages        = {112179},
  shortjournal = {Automatica},
  title        = {Distributed fault-tolerant control of multi-UAV formation for dynamic leader tracking: A lyapunov-based MPC framework},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “identification of ARMA models with
binary-valued observations” [automatica 149(2023) 110832].
<em>AUTOM</em>, <em>175</em>, 112177. (<a
href="https://doi.org/10.1016/j.automatica.2025.112177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AUTOM},
  author       = {Xin Li and Ting Wang and Jin Guo and Yanlong Zhao},
  doi          = {10.1016/j.automatica.2025.112177},
  journal      = {Automatica},
  month        = {5},
  pages        = {112177},
  shortjournal = {Automatica},
  title        = {Corrigendum to “Identification of ARMA models with binary-valued observations” [Automatica 149(2023) 110832]},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). General multi-step value iteration for optimal learning
control. <em>AUTOM</em>, <em>175</em>, 112168. (<a
href="https://doi.org/10.1016/j.automatica.2025.112168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning control methods have been widely enhanced by reinforcement learning, but it is challenging to analyze the effects of incorporating extra system information. This paper presents a novel multi-step framework that utilizes extra multi-step system information to solve optimal control problems. Within this framework, we establish and classify general multi-step value iteration (MsVI) algorithms based on the uniformity between policy evaluation and improvement stages. According to this uniformity concept, the convergence condition and the acceleration conclusion are analyzed for different kinds of MsVI algorithms. Besides, we introduce a swarm policy optimizer to relieve limitations of the traditional gradient optimizer. Specifically, we implement general MsVI using an actor–critic scheme, where the swarm optimizer and neural networks are employed for policy improvement and evaluation, respectively. Furthermore, the approximation error caused by the approximator is also considered to verify the advantage of using multi-step system information. Finally, we apply the proposed method to a nonlinear benchmark system, demonstrating superior learning ability and control performance compared to traditional methods.},
  archive      = {J_AUTOM},
  author       = {Ding Wang and Jiangyu Wang and Derong Liu and Junfei Qiao},
  doi          = {10.1016/j.automatica.2025.112168},
  journal      = {Automatica},
  month        = {5},
  pages        = {112168},
  shortjournal = {Automatica},
  title        = {General multi-step value iteration for optimal learning control},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential synchronization of networked systems under
asynchronous sampled-data coupling. <em>AUTOM</em>, <em>175</em>,
112157. (<a
href="https://doi.org/10.1016/j.automatica.2025.112157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach towards synchronization analysis of nonlinear networked systems, directionally coupled via a generic network topology, under asynchronous, aperiodic sampled-data linear coupling. The synchronization dynamics of the networked system is remodelled as a feedback-interconnection of an operator that captures the continuous-time synchronization dynamics, i.e., in the absence of sampled data transmission, and an operator that accounts for these communication constraints. By studying the properties of this feedback-interconnection in the framework of dissipativity theory, we provide a novel criterion that guarantees exponential synchronization. The provided criterion also aids in deciding the trade-off between bounds on time-varying, uncertain sampling intervals, the coupling gain, and the desired transient rate of synchronization, while taking into account the network topology. The theoretical results are illustrated using a networked FitzHugh–Nagumo neuron system.},
  archive      = {J_AUTOM},
  author       = {Jijju Thomas and Erik Steur and Christophe Fiter and Laurentiu Hetel and Nathan van de Wouw},
  doi          = {10.1016/j.automatica.2025.112157},
  journal      = {Automatica},
  month        = {5},
  pages        = {112157},
  shortjournal = {Automatica},
  title        = {Exponential synchronization of networked systems under asynchronous sampled-data coupling},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A rolling horizon game considering network effect in cluster
forming for dynamic resilient multiagent systems. <em>AUTOM</em>,
<em>175</em>, 112137. (<a
href="https://doi.org/10.1016/j.automatica.2025.112137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A two-player game-theoretic problem on resilient graphs in a multiagent consensus setting is formulated. An attacker is capable to disable some of the edges of the network with the objective to divide the agents into clusters by emitting jamming signals while, in response, the defender recovers some of the edges by increasing the transmission power for the communication signals. Specifically, we consider repeated games between the attacker and the defender where the optimal strategies for the two players are derived in a rolling horizon fashion based on utility functions that take both the agents’ states and the sizes of clusters (known as network effect) into account. The players’ actions at each discrete-time step are constrained by their energy for transmissions of the signals, with a less strict constraint for the attacker. Necessary conditions and sufficient conditions of agent consensus are derived, and the number of clusters of agents at infinite time in the face of attacks and recoveries is also characterized. Simulation results are provided to demonstrate the effects of players’ actions on the cluster forming and to illustrate the players’ performance for different horizon parameters.},
  archive      = {J_AUTOM},
  author       = {Yurid E. Nugraha and Ahmet Cetinkaya and Tomohisa Hayakawa and Hideaki Ishii and Quanyan Zhu},
  doi          = {10.1016/j.automatica.2025.112137},
  journal      = {Automatica},
  month        = {5},
  pages        = {112137},
  shortjournal = {Automatica},
  title        = {A rolling horizon game considering network effect in cluster forming for dynamic resilient multiagent systems},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level scheduling schemes for minimizing estimation
error: A game-theoretic approach. <em>AUTOM</em>, <em>175</em>, 112014.
(<a href="https://doi.org/10.1016/j.automatica.2024.112014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs scheduling schemes for a sensor with multiple power levels to minimize estimation error over a finite time. Under the sensor energy constraint, two algorithms are proposed to design scheduling schemes. One is a dynamic programming algorithm that constructs optimal scheduling schemes, but it is time-consuming and sensitive to the initial estimation error covariance. To address this, the second algorithm based on Nash equilibrium is developed to construct approximately optimal schemes. This algorithm not only ensures time-efficient but also allows for changes in the initial estimation error covariance. Finally, one numerical example illustrates the superiority of our proposed algorithms.},
  archive      = {J_AUTOM},
  author       = {Kaiyun Xie and Junlin Xiong},
  doi          = {10.1016/j.automatica.2024.112014},
  journal      = {Automatica},
  month        = {5},
  pages        = {112014},
  shortjournal = {Automatica},
  title        = {Multi-level scheduling schemes for minimizing estimation error: A game-theoretic approach},
  volume       = {175},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cma---5">CMA - 5</h2>
<ul>
<li><details>
<summary>
(2025). A non-convex and non-smooth weighted image denoising model.
<em>CMA</em>, <em>187</em>, 85–105. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to provide a more effective method to describe the local structure of the degraded image and to enhance the robustness of the denoising, we propose a non-convex total variational image denoising model that combines the non-convex log function with an adaptive weighted matrix within the total variation framework. In the proposed model, the weighted matrix is capable of effectively describing the primary direction of the edge structure, based on the coupling of the gradient operator of the denoising image and the diagonal matrix. As the proposed model is a non-convex and non-smooth optimisation problem, the iterative reweighted ℓ 1 algorithm and alternating direction multiplier method are employed to decompose it into a number of readily solvable sub-problems. The results obtained from numerical experiments demonstrate that the proposed model is capable of effectively suppressing the noise while maintaining the local structure of the image.},
  archive      = {J_CMA},
  author       = {Huayu Fan and Qiqi Feng and Rui Chen and Xiangyang Cao and Zhi-Feng Pang},
  doi          = {10.1016/j.camwa.2025.03.010},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {85-105},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A non-convex and non-smooth weighted image denoising model},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-implicit lax-wendroff kinetic scheme for multi-scale
phonon transport. <em>CMA</em>, <em>187</em>, 72–84. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast and accurate predictions of the spatiotemporal distributions of temperature are crucial to the multi-scale thermal management and safe operation of microelectronic devices. To realize it, an efficient semi-implicit Lax-Wendroff kinetic scheme is developed for numerically solving the transient phonon Boltzmann transport equation (BTE) from the ballistic to diffusive regime. The biggest innovation of the present scheme is that the finite difference method is used to solve the phonon BTE for the reconstruction of the interfacial distribution function at the half-time step, where the second-order numerical schemes are used for both the temporal and spatial discretization. Consequently, the phonon scattering and migration are coupled together within one time step, and the evolution process of phonon distribution function follows the actual physical law even if the time step is much longer than the relaxation time. Numerical results show that the present scheme could accurately predict the steady/unsteady heat conduction in solid materials from the ballistic to diffusive regime, and its time step or cell size is not limited by the relaxation time or phonon mean free path. The present work could provide a useful tool for the efficient predictions of the macroscopic spatiotemporal distributions in the multi-scale thermal engineering.},
  archive      = {J_CMA},
  author       = {Shuang Peng and Songze Chen and Hong Liang and Chuang Zhang},
  doi          = {10.1016/j.camwa.2025.03.019},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {72-84},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Semi-implicit lax-wendroff kinetic scheme for multi-scale phonon transport},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lattice-boltzmann inspired finite volume solver for
compressible flows. <em>CMA</em>, <em>187</em>, 50–71. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lattice Boltzmann method (LBM) for compressible flow is characterized by good numerical stability and low dissipation, while the conventional finite volume solvers have intrinsic conversation and flexibility in using unstructured meshes for complex geometries. This paper proposes a strategy to combine the advantages of the two kinds of solvers by designing a finite volume solver to mimic the LBM algorithm. It assumes an ideal LBM that can recover all desired higher-order moments. Time-discretized moment equations with second-order temporal accuracy and physically consistent dissipation terms are derived from the ideal LBM. By solving the recovered moment equations, a finite volume solver that can be applied to nonuniform meshes naturally, enabling body-fitted mass-conserving simulations, is proposed. Numerical tests show that the proposed solver can achieve good numerical stability from subsonic to hypersonic flows, and low dissipation for a long-distance entropy spot convection. For the challenging direct simulations of acoustic waves, its dissipation can be significantly reduced compared with the Lax-Wendroff solver of the same second-order spatial and temporal accuracy, while only remaining higher than that of the LBM on coarse meshes. The analysis implies that approximations of third-order temporal accuracy are required to recover the low dissipation of LBM further.},
  archive      = {J_CMA},
  author       = {Jinhua Lu and Song Zhao and Pierre Boivin},
  doi          = {10.1016/j.camwa.2025.03.007},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {50-71},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A lattice-boltzmann inspired finite volume solver for compressible flows},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatiotemporal numerical simulation of breast cancer tumors
in one-dimensional nonlinear moving boundary models via temporal-spatial
spectral collocation method. <em>CMA</em>, <em>187</em>, 30–49. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research article, we have simulated the solutions of three types of (classical) moving boundary models in ductal carcinoma in situ by an efficient temporal-spatial spectral collocation method. In all of these three classical models, the associated fixed (spatial) boundary equations are localized by the numerical scheme. In the numerical scheme, Laguerre polynomials and Hermite polynomials are implemented to approximate the temporal and spatial variables (of unknown solutions), respectively. Then, as a generalization of the first classical model, we have considered a space-fractional moving boundary model and then transformed it, again, to the corresponding fixed boundary space-fractional equation for a straightforward discretization. Due to the impossibility of transforming of the time-fractional moving boundary model into its fixed boundary variant, we localized the time-fractional moving boundary model directly by the proposed method. The results in this category are also very satisfactory and the accuracy is again in a spectral rate. Moreover, (temporal) multi-step version of our method is applied for the considered models and the results are very accurate with respect to the single-step one, especially when the boundary of tumor is diverging in practice. In this regard, an adaptive strategy is connected to the temporal multi-step approach for a better simulation. Extensive test problems are provided to verify the accuracy of the method, with full consideration given to iterative tools for solving the final system of nonlinear algebraic equations.},
  archive      = {J_CMA},
  author       = {Yin Yang and Sayyed Ehsan Monabbati and Emran Tohidi and Atena Pasban},
  doi          = {10.1016/j.camwa.2025.03.006},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {30-49},
  shortjournal = {Comput. Meth. Appl.},
  title        = {Spatiotemporal numerical simulation of breast cancer tumors in one-dimensional nonlinear moving boundary models via temporal-spatial spectral collocation method},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decoupled, convergent and fully linear algorithm for the
landau–lifshitz–gilbert equation with magnetoelastic effects.
<em>CMA</em>, <em>187</em>, 1–29. (<a
href="https://doi.org/10.1016/j.camwa.2025.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the coupled system of the Landau–Lifshitz–Gilbert equation and the conservation of linear momentum law to describe magnetic processes in ferromagnetic materials including magnetoelastic effects in the small-strain regime. For this nonlinear system of time-dependent partial differential equations, we present a decoupled integrator based on first-order finite elements in space and an implicit one-step method in time. We prove unconditional convergence of the sequence of discrete approximations towards a weak solution of the system as the mesh size and the time-step size go to zero. Compared to previous numerical works on this problem, for our method, we prove a discrete energy law that mimics that of the continuous problem and, passing to the limit, yields an energy inequality satisfied by weak solutions. Moreover, our method does not employ a nodal projection to impose the unit length constraint on the discrete magnetisation, so that the stability of the method does not require weakly acute meshes. Furthermore, our integrator and its analysis hold for a more general setting, including body forces and traction, as well as a more general representation of the magnetostrain. Numerical experiments underpin the theory and showcase the applicability of the scheme for the simulation of the dynamical processes involving magnetoelastic materials at submicrometer length scales.},
  archive      = {J_CMA},
  author       = {Hywel Normington and Michele Ruggeri},
  doi          = {10.1016/j.camwa.2025.03.008},
  journal      = {Computers &amp; Mathematics with Applications},
  month        = {6},
  pages        = {1-29},
  shortjournal = {Comput. Meth. Appl.},
  title        = {A decoupled, convergent and fully linear algorithm for the Landau–Lifshitz–Gilbert equation with magnetoelastic effects},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cmame---27">CMAME - 27</h2>
<ul>
<li><details>
<summary>
(2025). Multi-fidelity physics-informed machine learning framework
for fatigue life prediction of additive manufactured materials.
<em>CMAME</em>, <em>439</em>, 117924. (<a
href="https://doi.org/10.1016/j.cma.2025.117924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development direction of high reliability and longer serviceable life for major equipment requires accurate fatigue life predictions of additively manufactured (AM) components. However, small samples and high scatter of fatigue performance have become significant challenges in accurately modeling the fatigue failure behavior of AM components. To overcome the limitation of traditional fatigue life prediction models, a multi-fidelity physics-informed machine learning (PIML) framework is proposed. In this framework, the uncertainty quantification of fatigue performance and the fitting low-fidelity fatigue data with physical consistency are achieved through a physics-guided Wasserstein generative adversarial network with gradient penalty (WGAN-GP). The introduced concept of transfer learning allows training a physics-informed neural network (PiNN) using multi-fidelity fatigue data during the training process. Embedding the effect of manufacturing defects on fatigue performance as physical constraints can ensure the physical consistency of the overall multi-fidelity framework. Compared with traditional neural network (NN) and PiNN, the multi-fidelity framework has significant advantages in strong prediction performance, generalization ability and effectiveness. Moreover, the results of deep feature transfer demonstrate that the proposed multi-fidelity framework is expected to be a unified fatigue life prediction framework for AM materials.},
  archive      = {J_CMAME},
  author       = {Lanyi Wang and Shun-Peng Zhu and Borui Wu and Zijian Xu and Changqi Luo and Qingyuan Wang},
  doi          = {10.1016/j.cma.2025.117924},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117924},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Multi-fidelity physics-informed machine learning framework for fatigue life prediction of additive manufactured materials},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of damage evolution in CMCs considering the real
microstructures through a deep-learning scheme. <em>CMAME</em>,
<em>439</em>, 117923. (<a
href="https://doi.org/10.1016/j.cma.2025.117923">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real microstructures of ceramic matrix composites (CMCs) play a crucial role in determining their damage behavior. However, considering the real microstructure within the high-fidelity numerical simulation usually leads to expensive computational costs. In this study, an end-to-end deep-learning (DL) framework is proposed to predict the evolution of damage fields for CMCs from their real microstructures, which are characterized through computed tomography (CT). Three sub-networks, including the microstructure processing network (MPN), elastic deformation prediction network (EPN), and damage sequence prediction network (DPN), are used to construct a two-stage DL model. In the first stage, the geometrical characteristics of real microstructure are precisely captured by the MPN with over 92 % precision for the yarns and matrix. In the second stage, the elastic deformation predicted by the EPN is taken as the intermediate variable to motivate the damage prediction of DPN with the MPN-predicted microstructure as input. The damage evolution of real microstructure is finally predicted with a mean relative error of 10.8 % for the primary damage variable fields. The high-damage regions in the microstructure can also be accurately captured with a mean precision of 87.9 %. The proposed model is further validated by the in-situ tensile experiment. The micro-cracks are proven to initiate and propagate in the high-damage regions. Compared with the high-fidelity numerical methods, this DL-based method can predict the damage evolution on the fly, avoiding time-consuming computation and poor convergence during the damage analysis.},
  archive      = {J_CMAME},
  author       = {Rongqi Zhu and Guohao Niu and Panding Wang and Chunwang He and Zhaoliang Qu and Daining Fang},
  doi          = {10.1016/j.cma.2025.117923},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117923},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Prediction of damage evolution in CMCs considering the real microstructures through a deep-learning scheme},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Projection-based model order reduction of embedded boundary
models for CFD and nonlinear FSI. <em>CMAME</em>, <em>439</em>, 117920.
(<a href="https://doi.org/10.1016/j.cma.2025.117920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedded boundary methods (EBMs) for Computational Fluid Dynamics (CFD) and nonlinear fluid–structure interaction (FSI) – also known as immersed boundary methods, Cartesian methods, or fictitious domain methods – are the most robust methods for the solution of flow problems past obstacles that undergo large relative motions, significant deformations, large shape modifications, and/or surface topology changes. They can also introduce a high degree of automation in the task of grid generation and significant flexibility in the gridding of complex geometries. However, just like in the case of their counterpart body-fitted methods, their application to parametric flow computations at high Reynolds numbers remains today impractical in most engineering environments. For body-fitted CFD, the state of the art of projection-based model order reduction (PMOR) has significantly advanced during the last decade and demonstrated a remarkable success at reducing the dimensionality and wall-clock time of high Reynolds number models, while maintaining a desirable level of accuracy. For non-body-fitted CFD however, PMOR is still in its infancy, primarily because EBMs dynamically partition the computational fluid domain into real and ghost subdomains, which complicates the collection of solution snapshots and their compression into a reduced-order basis. In an attempt to fill this gap, this paper presents a robust computational framework for PMOR in the context of high Reynolds number flows and in the EBM setting of CFD/FSI (PMOR-EBM). The framework incorporates a hyperreduction approach based on the energy-conserving sampling and weighting (ECSW) method to accelerate the evaluation of the repeated projections arising in nonlinear implicit computations; and a piecewise-affine approach for constructing a nonlinear low-dimensional approximation of the solution to mitigate the Kolmogorov n -width barrier to the reducibility of transport models. The paper also assesses the performance of the proposed computational framework PMOR-EBM for two unsteady turbulent flow problems whose predictions necessitate or benefit from the application of an EBM; and two shape-parametric steady-state studies of the academic type but of relevance to design analysis and optimization.},
  archive      = {J_CMAME},
  author       = {Noah B. Youkilis and Charbel Farhat},
  doi          = {10.1016/j.cma.2025.117920},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117920},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Projection-based model order reduction of embedded boundary models for CFD and nonlinear FSI},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective loss balancing for physics-informed deep
learning. <em>CMAME</em>, <em>439</em>, 117914. (<a
href="https://doi.org/10.1016/j.cma.2025.117914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINN) are deep learning algorithms that leverage physical laws by including partial differential equations together with a respective set of boundary and initial conditions as penalty terms in their loss function. In this work, we observe the significant role of correctly weighting the combination of multiple competitive loss functions for training PINNs effectively. To this end, we implement and evaluate different methods aiming at balancing the contributions of multiple terms of the PINN’s loss function and their gradients. After reviewing three existing loss scaling approaches (Learning Rate Annealing, GradNorm and SoftAdapt), we propose a novel self-adaptive loss balancing scheme for PINNs named ReLoBRaLo (Relative Loss Balancing with Random Lookback). We extensively evaluate the performance of the aforementioned balancing schemes by solving both forward as well as inverse problems on three benchmark PDEs for PINNs: Burgers’ equation, Kirchhoff’s plate bending equation, Helmholtz’s equation and over 20 PDEs from the ”PINNacle” collection. The results show that ReLoBRaLo is able to consistently outperform the baseline of existing scaling methods in terms of accuracy while also inducing significantly less computational overhead for a variety of PDE classes.},
  archive      = {J_CMAME},
  author       = {Rafael Bischof and Michael A. Kraus},
  doi          = {10.1016/j.cma.2025.117914},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117914},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Multi-objective loss balancing for physics-informed deep learning},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A data-driven modeling framework for nonlinear static
aeroelasticity. <em>CMAME</em>, <em>439</em>, 117911. (<a
href="https://doi.org/10.1016/j.cma.2025.117911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the multiphysical coupling between a deformable structural body and the forces imposed on that body from a surrounding fluid can be a challenging and computationally expensive task, especially when the structure, fluid, or both exhibit nonlinear behavior. Consequently, there exists a need for novel reduced-order static aeroelasticity analysis techniques that make efficient use of high-fidelity computational models, especially for preliminary design of next-generation aerostructures with high-aspect ratio lifting surfaces exhibiting large deformations or in situ geometric reconfigurations driven by nonlinear mechanisms. This work presents the compositional static aeroelastic analysis method: an embarrassingly parallelizable data-driven modeling technique that seeks to construct a system-level aeroelastic surrogate model representing the function composition of high-fidelity structural and fluid models in terms of shape parameters characterizing a reduced-order geometric description of the deformed fluid–structure interface. By formulating the static aeroelasticity problem as a fixed point problem, the proposed reduced-order modeling framework removes the need for a reduced-order representation of the traction field acting on the structure, unlike previous data-driven methods that independently train separate fluid and structural surrogate models. Additionally, by replacing the iterative exchange of full-order aeroelastic coupling variables with a statistical exploration of a reduced-order shape parameter space, the minimum computational time for approximating a static aeroelastic response is equivalent to one set of high-fidelity fluid and structural model evaluations. The following work presents the theoretical development of the proposed compositional method and demonstrates its use in two case studies, one of which involves a cantilevered baffle comprised of linear and nonlinear material with large deformations exceeding 35%. Numerical results show close agreement with a conventional partitioned analysis scheme, where tip displacement error is less than 1% in both material cases. It is also demonstrated how traction field information can be reused when considering structural modifications to circumvent the need for additional computationally expensive fluid model evaluations.},
  archive      = {J_CMAME},
  author       = {Trent White and Darren Hartl},
  doi          = {10.1016/j.cma.2025.117911},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117911},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A data-driven modeling framework for nonlinear static aeroelasticity},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A finite element-based simulation of microstructure
evolution through a 3D finite strain cosserat phase-field model.
<em>CMAME</em>, <em>439</em>, 117900. (<a
href="https://doi.org/10.1016/j.cma.2025.117900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A computational framework for microstructure evolution in metallic polycrystals is achieved by coupling large deformation Cosserat isotropic hyperelasticity with a phase-field model to take into account grain boundary formation and motion. Each material point has an associated crystal lattice orientation described by the Cosserat microrotation, which can evolve due to deformation or grain boundary migration. The analysis is restricted to transformations in the solid state. The numerical treatment of the proposed model requires some consideration. Discretization by finite elements leads to a strongly nonlinear, coupled system. The microrotation is parametrized to facilitate the numerical treatment of incremental updates of the Cosserat degrees of freedom. In order to reduce computation time and effort, a parallel computing mechanism based on domain decomposition is adopted together with an iterative staggered scheme to avoid the ill-conditioning inherent to the monolithic coupled system of equations.},
  archive      = {J_CMAME},
  author       = {Jad Doghman and Christophe Bovet and Anna Ask},
  doi          = {10.1016/j.cma.2025.117900},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117900},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A finite element-based simulation of microstructure evolution through a 3D finite strain cosserat phase-field model},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FCA method for predicting effective viscosity of particle
reinforced thermoplastic melt and a metric for measuring clusters.
<em>CMAME</em>, <em>439</em>, 117899. (<a
href="https://doi.org/10.1016/j.cma.2025.117899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effective viscosity of particle reinforced thermoplastic melt shows strongly anisotropic behavior and is also shear rate-dependent. The traditional homogenization method may face challenge due to extremely expensive computational cost, when the non-linear effective viscosities on all the directions of Particle Reinforced Thermoplastics (PRT) are demanded. This paper approaches this challenge with the FEM-Cluster based reduced order Analysis (FCA) method [1]. The governing equations are solved by minimizing a cluster-based dual formulation of the dissipating energy, where the cluster-wise Admissible Shear Stress (ASS) set is obtained by FCA together with a Spectrum Analysis Algorithm (SAA). In addition, considering the fact that there is a lack of effective method for determining the proper number of clusters, a cluster metric is developed, which relates the given number of clusters and the prediction accuracy of FCA method. This metric can be easily used in the offline stage to pre-estimate the applicability of the obtained clusters on the given loading conditions with a small amount of additional computation.},
  archive      = {J_CMAME},
  author       = {Zheng Li and Yinghao Nie and Gengdong Cheng},
  doi          = {10.1016/j.cma.2025.117899},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117899},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {FCA method for predicting effective viscosity of particle reinforced thermoplastic melt and a metric for measuring clusters},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A coupled immersed boundary method and isogeometric shell
analysis for fluid–structure interaction of flexible and lightweight
shells in high-reynolds number flows. <em>CMAME</em>, <em>439</em>,
117898. (<a href="https://doi.org/10.1016/j.cma.2025.117898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents an efficient numerical framework for simulating fluid–structure interactions (FSIs) involving flexible, lightweight shells subjected to high-Reynolds-number flows. By combining the immersed boundary method (IBM) and isogeometric analysis (IGA), the framework incorporates three major innovations: (1) a wall-modeling, direct-forcing, diffused-interface IBM tailored for FSI simulations with high-Reynolds-number turbulent flows, employing non-equilibrium explicit wall functions; (2) integration of the interface quasi-Newton inverse least-squares (IQN-ILS) method into the IBM/IGA framework to enhance the accuracy and efficiency of iterative Gauss–Seidel coupling in strongly coupled FSI scenarios; and (3) high-order solvers for both fluid and structural domains, featuring a sixth-order compact finite difference method (FDM) for fluid dynamics and isogeometric shell formulations for structural analysis. The framework is validated through four numerical test cases, including simulations of a hinged flag, an inverted flag, a membrane airfoil, and an air-supported membrane structure. The results demonstrate good agreement with reference data, showing the framework’s efficiency, accuracy, and applicability for solving large-scale shell-related FSI problems across diverse engineering and scientific domains.},
  archive      = {J_CMAME},
  author       = {Keye Yan and Yue Wu and Qiming Zhu and Boo Cheong Khoo},
  doi          = {10.1016/j.cma.2025.117898},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117898},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A coupled immersed boundary method and isogeometric shell analysis for fluid–structure interaction of flexible and lightweight shells in high-reynolds number flows},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient flow based phase-field modeling using separable
neural networks. <em>CMAME</em>, <em>439</em>, 117897. (<a
href="https://doi.org/10.1016/j.cma.2025.117897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Allen–Cahn equation is a reaction–diffusion equation and is widely used for modeling phase separation. Machine learning methods for solving the Allen–Cahn equation in its strong form suffer from inaccuracies in collocation techniques, errors in computing higher-order spatial derivatives, and the large system size required by the space–time approach. To overcome these challenges, we propose solving the L 2 gradient flow of the Ginzburg–Landau free energy functional, which is equivalent to the Allen–Cahn equation, thereby avoiding the second-order spatial derivatives associated with the Allen–Cahn equation. A minimizing movement scheme is employed to solve the gradient flow problem, eliminating the complexities of a space–time approach. We utilize a separable neural network that efficiently represents the phase field through low-rank tensor decomposition. As we use the minimizing movement scheme to numerically solve the gradient flow problem, we thus, refer to the proposed method as the Separable Deep Minimizing Movement (SDMM) method. The evaluation of the functional in the minimizing movement scheme using the Gauss quadrature technique bypasses the inaccuracies associated with collocation techniques traditionally used to solve partial differential equations. A hyperbolic tangent transformation is introduced on the phase field prior to the evaluation of the functional to ensure that it remains strictly bounded within the values of the two phases. For this transformation, theoretical guarantee for energy stability of the minimizing movement scheme is established. Our results suggest that this transformation helps to improve the accuracy and efficiency significantly. The proposed method resolves the challenges faced by state-of-the-art machine learning techniques, outperforming them in both accuracy and efficiency. It is also the first machine learning method to achieve an order of magnitude speed improvement over the finite element method. In addition to its formulation and computational implementation, several case studies illustrate the applicability of the proposed method. 1},
  archive      = {J_CMAME},
  author       = {Revanth Mattey and Susanta Ghosh},
  doi          = {10.1016/j.cma.2025.117897},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117897},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Gradient flow based phase-field modeling using separable neural networks},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Path-following strategy with consistent jacobian for
periodic solutions in multi-DOF nonlinear dynamic systems.
<em>CMAME</em>, <em>439</em>, 117896. (<a
href="https://doi.org/10.1016/j.cma.2025.117896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an enhanced pseudo-arclength path-following technique for recovering periodic solutions in high-dimensional nonlinear dynamic systems using the Poincaré map method. The key innovation is the direct computation of the Jacobian matrix within the time-marching algorithm used to obtain periodic orbits, including both the monodromy matrix and derivatives with respect to the continuation parameter. For smooth problems, the resulting Jacobian matrix is algorithmically exact: while the equations of motion are approximated using a user-selected time-integration scheme, the differentiation of the computed solution is performed exactly. This approach eliminates the need for numerical differentiation, significantly improving both the efficiency and robustness of the path-following process. Although the theoretical framework assumes differentiability, the method effectively handles piecewise smooth problems as well. Numerical tests demonstrate the superior performance of the proposed approach compared to traditional techniques that rely on numerical differentiation. To further validate its effectiveness and versatility, we present numerical examples involving the Finite Element discretization of three-dimensional problems, including shell structures.},
  archive      = {J_CMAME},
  author       = {Domenico Magisano and Giovanni Formica},
  doi          = {10.1016/j.cma.2025.117896},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117896},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Path-following strategy with consistent jacobian for periodic solutions in multi-DOF nonlinear dynamic systems},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive multi-patch isogeometric analysis for heat transfer
in three-dimensional solid. <em>CMAME</em>, <em>439</em>, 117895. (<a
href="https://doi.org/10.1016/j.cma.2025.117895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an adaptive multi-patch isogeometric framework for modeling heat conduction in isotropic/orthotropic media. The proposed adaptive scheme is a novel combination of local mesh refinement and adaptive time-stepping to improve the calculation efficiency and reduce meshing burden. The local adaptive refinement is driven by a recovery-based error estimator. Truncated hierarchical NURBS (TH-NURBS) are utilized for local adaptive mesh refinement due to their excellent properties, such as linear independence, partition-of-unity, and exact description of complex geometry. Multi-patch technique is applied to model complex structures, with Nitsche’s method as the coupling strategy. The computational accuracy of the proposed model is verified through several 3D numerical examples. The high efficiency of the adaptive scheme is demonstrated by comparing with uniform refinement method and fixed time-stepping method separately.},
  archive      = {J_CMAME},
  author       = {Lin Wang and Tiantang Yu and Sundararajan Natarajan and Weihua Fang and Zhiwei Zhou},
  doi          = {10.1016/j.cma.2025.117895},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117895},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Adaptive multi-patch isogeometric analysis for heat transfer in three-dimensional solid},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Region-optimal gaussian process surrogate model via
dirichlet process for cold-flow and combustion emulations.
<em>CMAME</em>, <em>439</em>, 117894. (<a
href="https://doi.org/10.1016/j.cma.2025.117894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate modeling plays an increasingly important role in engineering design. The present work develops a novel surrogate model, region-optimal Gaussian process (roGP), to accurately emulate cold-flow and combustion fields in a significantly short time period. The model leverages an advanced statistical approach, Dirichlet process (DP) mixture model, to partition the entire spatial domain of concern into discrete subregions in a physics-informed manner. Each subregion contains the common features embedded in the collected dataset and is modeled by a Gaussian process (GP) with shared hyperparameters. Additionally, an active learning strategy iteratively refines the training dataset by prioritizing high-uncertainty regions, further enhancing predictive accuracy. The roGP model is evaluated on three representative cases of increasing complexity, consistently outperforming conventional GP-based surrogates. Results show that roGP effectively mitigates overfitting in independent GP models and reduces information loss in proper-orthogonal-decomposition GP models. In all test cases, roGP achieves superior spatial prediction accuracy, with relative root mean square errors below 5.5 %. A unique characteristic of the roGP model is that the DP-optimized subregions of roGP connect physics-alike coordinates among sampling design points. The entire pressure field in cold-flow case is effectively described by five subregions, while physical fields in two combustion cases require the elevated number of subregions due to their increased complexity. roGP achieves substantial acceleration in prediction time, up to eight orders of magnitude faster than numerical simulations. The developed surrogate model can be implemented to emulate a range of high-dimensional engineering applications with high accuracy and efficiency.},
  archive      = {J_CMAME},
  author       = {Mingshuo Zhou and Ruiye Zuo and Chih-Li Sung and Yanjie Tong and Xingjian Wang},
  doi          = {10.1016/j.cma.2025.117894},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117894},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Region-optimal gaussian process surrogate model via dirichlet process for cold-flow and combustion emulations},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explicit dual-mesh virtual element method for 2D nonlinear
dynamic problems. <em>CMAME</em>, <em>439</em>, 117893. (<a
href="https://doi.org/10.1016/j.cma.2025.117893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel explicit Dual-Mesh virtual element method (DM-VEM) for two dimensional nonlinear dynamic problems is proposed. The DM-VEM employs an Eulerian background grid to solve the momentum equation of the virtual element method (VEM), which significantly improves the spatial stability and the temporal stability of the VEM. An explicit critical time step formula is first developed for one dimensional problems and then extended to two dimensional problems, which takes the effect of vertex position and neighboring cell interaction into consideration. An efficient Lagrangian multiplier contact method based on the background grid is also proposed to deal with contact phenomena. Several numerical examples are studied to verify the proposed explicit DM-VEM in nonlinear dynamic problems.},
  archive      = {J_CMAME},
  author       = {Ruopu Zhou and Zhixin Zeng and Xiong Zhang},
  doi          = {10.1016/j.cma.2025.117893},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117893},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Explicit dual-mesh virtual element method for 2D nonlinear dynamic problems},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A coupled thermo-chemo-mechanical peridynamic model for
predicting process-induced residual stress in fiber-reinforced polymer
composites. <em>CMAME</em>, <em>439</em>, 117891. (<a
href="https://doi.org/10.1016/j.cma.2025.117891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fiber reinforced polymer (FRP) composites have extensive applications in aerospace, automobile, marine and sports industries, however, the process-induced residual stress developed during the cure process can lead to microcracks and weaken the macroscopic mechanical performance. In this work, we developed a multiscale PD framework for modeling thermo-chemo-mechanical behaviors of FRP composites for the first time. The whole cure process is modeled by a macroscale thermo-chemical coupling behavior of the FRP specimen followed by a microscale thermo-chemo-mechanical coupling process of the representative volume element (RVE) taken from the macro specimen. After the multiscale cure modeling, the resulted residual stress distribution is maintained when applying the mechanical loading. The proposed PD framework was validated by examining the temperature and degree of cure histories and the stress-strain curves against experimental data. The effects of periodic boundary condition (PBC) treatments, fiber content, fiber distribution and chemical shrinkage are explored. Cure-induced residual stress can amplify the local stress concentration and damage in the fiber‒matrix interfaces. Results show that PBC treatments have negligible influence on the final damage distribution while the fiber content and distribution can pose huge impact on the strain and stress history of the RVE. In addition, chemical shrinkage can complicate the stress state and impact the mechanical response of composites. This model can serve as a potential tool for predicting the process-induced residual stress and damage and contributes to improved composites designs.},
  archive      = {J_CMAME},
  author       = {Weikang Sun and Jiaxiang Liew and Zhifei Tan and Yang Zhang and Binbin Yin},
  doi          = {10.1016/j.cma.2025.117891},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117891},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A coupled thermo-chemo-mechanical peridynamic model for predicting process-induced residual stress in fiber-reinforced polymer composites},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compatible finite element interpolated neural networks.
<em>CMAME</em>, <em>439</em>, 117889. (<a
href="https://doi.org/10.1016/j.cma.2025.117889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We extend the finite element interpolated neural network (FEINN) framework from partial differential equations (PDEs) with weak solutions in H 1 to PDEs with weak solutions in H ( curl ) or H ( div ) . To this end, we consider interpolation trial spaces that satisfy the de Rham Hilbert subcomplex, providing stable and structure-preserving neural network discretisations for a wide variety of PDEs. This approach, coined compatible FEINNs, has been used to accurately approximate the H ( curl ) inner product. We numerically observe that the trained network outperforms finite element solutions by several orders of magnitude for smooth analytical solutions. Furthermore, to showcase the versatility of the method, we demonstrate that compatible FEINNs achieve high accuracy in solving surface PDEs such as the Darcy equation on a sphere. Additionally, the framework can integrate adaptive mesh refinements to effectively solve problems with localised features. We use an adaptive training strategy to train the network on a sequence of progressively adapted meshes. Finally, we compare compatible FEINNs with the adjoint neural network method for solving inverse problems. We consider a one-loop algorithm that trains the neural networks for unknowns and missing parameters using a loss function that includes PDE residual and data misfit terms. The algorithm is applied to identify space-varying physical parameters for the H ( curl ) model problem from partial, noisy, or boundary observations. We find that compatible FEINNs achieve accuracy and robustness comparable to, if not exceeding, the adjoint method in these scenarios.},
  archive      = {J_CMAME},
  author       = {Santiago Badia and Wei Li and Alberto F. Martín},
  doi          = {10.1016/j.cma.2025.117889},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117889},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Compatible finite element interpolated neural networks},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kolmogorov–arnold PointNet: Deep learning for prediction of
fluid fields on irregular geometries. <em>CMAME</em>, <em>439</em>,
117888. (<a href="https://doi.org/10.1016/j.cma.2025.117888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kolmogorov–Arnold Networks (KANs) have emerged as a promising alternative to traditional Multilayer Perceptrons (MLPs) in deep learning. KANs have already been integrated into various architectures, such as convolutional neural networks, graph neural networks, and transformers, and their potential has been assessed for predicting physical quantities. However, the combination of KANs with point-cloud-based neural networks (e.g., PointNet) for computational physics has not yet been explored. To address this, we present Kolmogorov–Arnold PointNet (KA-PointNet) as a novel supervised deep learning framework for the prediction of incompressible steady-state fluid flow fields in irregular domains, where the predicted fields are a function of the geometry of the domains. In KA-PointNet, we implement shared KANs in the segmentation branch of the PointNet architecture. We utilize Jacobi polynomials to construct shared KANs. As a benchmark test case, we consider incompressible laminar steady-state flow over a cylinder, where the geometry of its cross-section varies over the data set. We investigate the performance of Jacobi polynomials with different degrees as well as special cases of Jacobi polynomials such as Legendre polynomials, Chebyshev polynomials of the first and second kinds, and Gegenbauer polynomials, in terms of the computational cost of training and accuracy of prediction of the test set. Furthermore, we examine the robustness of KA-PointNet in the presence of noisy training data and missing points in the point clouds of the test set. Additionally, we compare the performance of PointNet with shared KANs (i.e., KA-PointNet) and PointNet with shared MLPs. It is observed that when the number of trainable parameters is approximately equal, PointNet with shared KANs (i.e., KA-PointNet) outperforms PointNet with shared MLPs. Moreover, KA-PointNet predicts the pressure and velocity distributions along the surface of cylinders more accurately, resulting in more precise computations of lift and drag.},
  archive      = {J_CMAME},
  author       = {Ali Kashefi},
  doi          = {10.1016/j.cma.2025.117888},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117888},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Kolmogorov–Arnold PointNet: Deep learning for prediction of fluid fields on irregular geometries},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Output probability distribution estimation of stochastic
static and dynamic systems using laplace transform and maximum entropy.
<em>CMAME</em>, <em>439</em>, 117887. (<a
href="https://doi.org/10.1016/j.cma.2025.117887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectively estimating output probability distributions in stochastic static and dynamic systems with a limited number of simulations is a significant challenge, especially for complex distributions with multi-modality and heavy tails. To address this challenge, this work explores the potential of the Laplace Transform (LT) and its inversion. First, the statistical information embedded in the derivatives of the LT is analysed, establishing the theoretical foundation for recovering output probability distributions. Subsequently, a novel analytical expression for the response probability density function (PDF) is derived by decomposing its inverse LT (ILT) using Euler’s formula. Building on the numerically estimated LT, a non-parametric numerical solution, termed the Numerical Decomposed ILT (NDILT) algorithm, is developed to flexibly estimate the main body of complex PDFs with limited samples. Second, the Taylor expansion of the real component of LT (RCLT) reveals its rich statistical content. Exploiting this property, another parametric method, the LT-based Maximum Entropy Method (LT-MEM), is proposed, incorporating estimated RCLT as constraints of the maximum entropy principle. By solving an optimization problem, LT-MEM can effectively reconstruct complex PDFs across their entire distribution domain using a small sample size. The proposed methods rediscover and harness the power of the LT and ILT to reconstruct complex-shaped probability distributions, offering a valuable alternative. Parameter selection strategies for NDILT and LT-MEM are provided, and their robust accuracy is validated through analytical and numerical examples across various challenging distributions.},
  archive      = {J_CMAME},
  author       = {Yang Zhang and Chao Dang and Jun Xu and Michael Beer},
  doi          = {10.1016/j.cma.2025.117887},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117887},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Output probability distribution estimation of stochastic static and dynamic systems using laplace transform and maximum entropy},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An analytical exact, locking free element formulation for
thin-walled composite timoshenko beams. <em>CMAME</em>, <em>439</em>,
117886. (<a href="https://doi.org/10.1016/j.cma.2025.117886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial truss structures represent a robust, cost-effective, and efficient lightweight design, especially when isotropic materials are substituted with lightweight materials such as composites. During early design phases, truss structures are often subject to optimisations. In order to achieve this in an efficient manner, it is essential to employ a precise yet cost-effective computational model. The most common methodology for the analysis of spatial truss structures employs hinged joints in conjunction with struts that are only subject to tension or compression. However, this approach does not account for the bending and coupling effects inherent to struts manufactured from composite materials. In particular, when employing asymmetric laminates, these effects can no longer be ignored. In order to incorporate these effects, it is common practice to use Finite Element Analysis tools. Particularly for large spatial truss structures comprising struts with slender and thin-walled cross-sections, a large number of solid or shell elements is required, which results in time-consuming simulations. This contribution presents a fully analytical thin-walled composite beam element, applicable to an arbitrarily shaped, closed cross-section. The beam model incorporates two distinct composite material models, namely the Classical Laminate Plate Theory and the First Order Shear Deformation Theory. Moreover, it is capable of simulating asymmetric laminates and modelling the coupling effects within these laminates. Utilising the exact third-order solution of a composite Timoshenko - Ehrenfest beam enables the locking-free representation of an individual strut with a single beam element. In comparison to the conventional shell / solid Finite Element Analysis, this approach results in a substantial reduction in the number of degrees of freedom, by a factor of several orders of magnitude. As a result, the required computational time is significantly reduced. In the case of a single strut, the computational time is reduced by a factor between 160 and 430. For an exemplary truss structure comprising 64 struts, a reduction in computational time of approximately 100 000 times is reached. The numerical comparisons presented in this contribution demonstrate that the model is highly accurate, particularly for tubular and elliptical cross-sections including symmetric and asymmetric laminates.},
  archive      = {J_CMAME},
  author       = {Michael Jäger and Jacqueline Albertsen and Sandro Wartzack},
  doi          = {10.1016/j.cma.2025.117886},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117886},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {An analytical exact, locking free element formulation for thin-walled composite timoshenko beams},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locking and stabilization free hybrid virtual elements for
the coarse mesh analysis of elastic thick plates. <em>CMAME</em>,
<em>439</em>, 117883. (<a
href="https://doi.org/10.1016/j.cma.2025.117883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a Virtual Element formulation (VE) for shear-deformable elastic plates. In particular, the Hybrid Virtual Element Method (HVEM) is adopted, which assumes a self-equilibrated stress interpolation and an energy-based projection, eliminating the need for stabilization terms. This choice, together with a cubic linked interpolation for displacement and rotations, makes the approach free from locking, even for very thin plates and highly distorted element geometries. These features enable the proposed VE to achieve high accuracy even for coarse meshes, yielding low errors when compared to analytical solutions and providing a smooth reconstruction of all the stress field components. Furthermore, low error in both the displacement and stress fields are obtained in the challenging case of single element polygonal discretization. The same performance are guaranteed in presence of bulk loads, thanks to a consistent treatment within the projection operation that a-priori assumes equilibrium for the stress field interpolation. A random-based benchmark is proposed for assessing numerically the absence of spurious modes in concave and convex distorted elements. The proposed HVEM for plate is validated in classical benchmark problems, demonstrating the superior accuracy of polygonal meshes compared to the quadrilateral ones, for an equivalent number of degrees of freedom. This result is relevant in all the applications where polygonal element shapes are necessary. In addition, it opens up the way to new modeling scenarios where polygonal meshes are preferred not only for their versatility but also for their enhanced accuracy.},
  archive      = {J_CMAME},
  author       = {F. Liguori and A. Madeo and S. Marfia and G. Garcea and E. Sacco},
  doi          = {10.1016/j.cma.2025.117883},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117883},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Locking and stabilization free hybrid virtual elements for the coarse mesh analysis of elastic thick plates},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nonlinear dynamic substructuring in the frequency domain.
<em>CMAME</em>, <em>439</em>, 117882. (<a
href="https://doi.org/10.1016/j.cma.2025.117882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a nonlinear dynamic substructuring technique to efficiently evaluate nonlinear systems with localized nonlinearities in the frequency domain. A closed-form equation is derived from coupling the dynamics of substructures and nonlinear connections. The method requires the linear frequency response functions of the substructures, which can be calculated independently using reduced-order methods. Increasing the number of linear bases in the reduction method for substructures does not affect the number of nonlinear equations, unlike in component mode synthesis techniques. The performance of the method is evaluated through three case studies: a lumped parameter system with cubic nonlinearity, bars with a small gap (normal contact), and a plate with a couple of nonlinear energy sinks. The results demonstrate promising accuracy with significantly reduced computational cost.},
  archive      = {J_CMAME},
  author       = {Hossein Soleimani and Niels Aage},
  doi          = {10.1016/j.cma.2025.117882},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117882},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Nonlinear dynamic substructuring in the frequency domain},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A clustering-based multiscale topology optimization
framework for efficient design of porous composite structures.
<em>CMAME</em>, <em>439</em>, 117881. (<a
href="https://doi.org/10.1016/j.cma.2025.117881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization design of the microstructures and their macro distribution in porous composite structures (PCS) offers significant potential for achieving both lightweight and functional performance. This paper proposes a novel optimization design framework for PCS with varying densities and multiple microstructures. Initially, components topology optimization (TO-Components) using ordered SIMP interpolation is applied to determine the type and density distribution of void, solid and porous materials. Following this, element stress state analysis calculates the stress-to-density ratio ( s e ) for each porous material element. A two-level k-means++ clustering method, based on s e and density, then replaces the widely used manual partitioning, enabling optimal subregion division for the specified number of microstructure types. This approach identifies representative unit cells (RUCs) for the subsequent topology optimization of RUCs (TO-RUCs). The TO-RUCs process designs the microstructures of each RUC using homogenization theory to minimize strain energy. Three benchmark numerical examples take only 1 to 2 min to complete the full-scale design. Additionally, the scalability of the design for both uniform and variable density PCS is explored. The comparison examples demonstrate that the proposed method reduces optimization time by an order of magnitude while maintaining consistent full-scale compliance, using the same material quantity, compared to existing methods. Finally, additive manufacturing and mechanical testing of the optimized structures confirm the performance benefits.},
  archive      = {J_CMAME},
  author       = {Jinlong Liu and Zhiqiang Zou and Zeyang Li and Min Zhang and Jie Yang and Kang Gao and Zhangming Wu},
  doi          = {10.1016/j.cma.2025.117881},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117881},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {A clustering-based multiscale topology optimization framework for efficient design of porous composite structures},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-stabilized virtual element modeling of 2D mixed-mode
cohesive crack propagation in isotropic elastic solids. <em>CMAME</em>,
<em>439</em>, 117880. (<a
href="https://doi.org/10.1016/j.cma.2025.117880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive strategy for the simulation of mixed-mode cohesive crack propagation in a mesh of originally self-stabilized Virtual Elements (VEs) is proposed. Exploiting the VEs substantial insensitivity to mesh distortion, the propagating cohesive crack is accommodated within existing self-stabilized first-order quadrilateral VEs by simply adding new edges separated by a cohesive interface. The added edges make however the VE unstable and a new procedure for the stabilization of initially stable VE is developed. The method is formulated within a recently proposed Hu–Washizu variational framework, allowing for a higher order, independent modeling of stresses. In this way, a more accurate estimate of the stress at the tip of the cohesive process zone can be achieved allowing for a more accurate assessment of crack propagation conditions and direction. The proposed method is validated by application to several benchmark problems.},
  archive      = {J_CMAME},
  author       = {Y. Chen and D. Sun and Q. Li and U. Perego},
  doi          = {10.1016/j.cma.2025.117880},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117880},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Self-stabilized virtual element modeling of 2D mixed-mode cohesive crack propagation in isotropic elastic solids},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On efficient simulation of self-assembling diblock
copolymers using a peridynamic-enhanced fourier spectral method.
<em>CMAME</em>, <em>439</em>, 117878. (<a
href="https://doi.org/10.1016/j.cma.2025.117878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a computational framework for simulating the self-assembly of diblock copolymers using a novel peridynamic (PD)-enhanced Fourier spectral method (FSM). Diblock copolymers, composed of two distinct polymer blocks, are capable of forming nanostructured domains with applications in nanoelectronics, photonics, and advanced membranes. Current simulation techniques face challenges in capturing the multiscale dynamics of polymer systems and are often limited by computational inefficiencies. Our approach combines a phase-field model with FSM for spatial discretization and leverages a PD-based diffusion operator to overcome the stability restrictions of explicit time-stepping schemes. This integration allows for larger time steps, ensuring both stability and computational efficiency. The method’s scalability is enhanced through parallel implementation using C++ and OpenMP, optimized for multi-core CPUs. Validation through phase diagrams of copolymer melts and simulations of evaporation-induced self-assembly (EISA) processes demonstrates the capability of the proposed method to accurately capture large-scale, dynamic morphologies. Our approach provides a versatile framework and was found in certain examples to improve computational efficiency by more than a factor of 6 compared to forward-Euler FSM approach.},
  archive      = {J_CMAME},
  author       = {Farshid Mossaiby and Gregor Häfner and Arman Shojaei and Alexander Hermann and Christian Cyron and Marcus Müller and Stewart Silling},
  doi          = {10.1016/j.cma.2025.117878},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117878},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {On efficient simulation of self-assembling diblock copolymers using a peridynamic-enhanced fourier spectral method},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Similarity equivariant graph neural networks for
homogenization of metamaterials. <em>CMAME</em>, <em>439</em>, 117867.
(<a href="https://doi.org/10.1016/j.cma.2025.117867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft, porous mechanical metamaterials exhibit pattern transformations that may have important applications in soft robotics, sound reduction and biomedicine. To design these innovative materials, it is important to be able to simulate them accurately and quickly, in order to tune their mechanical properties. Since conventional simulations using the finite element method entail a high computational cost, in this article we aim to develop a machine learning-based approach that scales favorably to serve as a surrogate model. To ensure that the model is also able to handle various microstructures, including those not encountered during training, we include the microstructure as part of the network input. Therefore, we introduce a graph neural network that predicts global quantities (energy, stress, stiffness) as well as the pattern transformations that occur (the kinematics) in hyperelastic, two-dimensional, microporous materials. Predicting these pattern transformations means predicting the displacement field. To make our model as accurate and data-efficient as possible, various symmetries are incorporated into the model. The starting point is an E ( n ) -equivariant graph neural network (which respects translation, rotation and reflection) that has periodic boundary conditions (i.e., it is in-/equivariant with respect to the choice of RVE), is scale in-/equivariant, can simulate large deformations, and can predict scalars, vectors as well as second and fourth order tensors (specifically energy, stress and stiffness). The incorporation of scale equivariance makes the model equivariant with respect to the similarities group, of which the Euclidean group E ( n ) is a subgroup. We show that this network is more accurate and data-efficient than graph neural networks with fewer symmetries. To create an efficient graph representation of the finite element discretization, we use only the internal geometrical hole boundaries from the finite element mesh to achieve a better speed-up and scaling with the mesh size.},
  archive      = {J_CMAME},
  author       = {Fleur Hendriks and Vlado Menkovski and Martin Doškář and Marc G.D. Geers and Ondřej Rokoš},
  doi          = {10.1016/j.cma.2025.117867},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117867},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Similarity equivariant graph neural networks for homogenization of metamaterials},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Three-dimensional varying-order NURBS discretization method
for enhanced IGA of large deformation frictional contact problems.
<em>CMAME</em>, <em>439</em>, 117853. (<a
href="https://doi.org/10.1016/j.cma.2025.117853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this contribution, we introduce a varying-order (VO) NURBS discretization method to enhance the performance of the isogeometric analysis (IGA) technique for solving three-dimensional (3D) large deformation frictional contact problems involving two deformable bodies. Building on the promising results obtained from the previous work on the 2D isogeometric contact analysis (Agrawal and Gautam, 2020), this work extends the method’s capability for tri-variate NURBS-based discretization. The proposed method allows for independent, user-defined application of higher-order NURBS functions to discretize the contact surface while employing the minimum order NURBS for the remaining volume of the elastic solid. This flexible strategy enables the possibility to refine a NURBS-constructed solid at a fixed mesh with the controllable order elevation-based approach while preserving the original volume parametrization. The advantages of the method are twofold. First, employing higher-order NURBS for contact integral evaluations considerably enhances the accuracy of the contact responses at a fixed mesh, fully exploiting the advantage of higher-order NURBS specifically for contact computations. Second, the minimum order NURBS for the computations in the remaining bulk volume substantially reduces the computational cost inherently associated with the standard uniform order NURBS-based isogeometric contact analyses. The capabilities of the proposed method are demonstrated using various contact problems between elastic solids with or without considering friction. The results with the standard uniform order of tri-variate NURBS-based discretizations are also included to provide a comprehensive comparative assessment. We show that to attain results of similar accuracy, the varying-order NURBS discretization uses a much coarser mesh resolution than the standard uniform-order NURBS-based discretization, hence leading to a major gain in computational efficiency for isogeometric contact analysis. The convergence study demonstrates the consistent performance of the method for efficient IGA of 3D frictional contact problems. Furthermore, the simplicity of the method facilitates its direct integration into the existing 3D NURBS-based IGA framework with only a few minor modifications.},
  archive      = {J_CMAME},
  author       = {Vishal Agrawal},
  doi          = {10.1016/j.cma.2025.117853},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117853},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Three-dimensional varying-order NURBS discretization method for enhanced IGA of large deformation frictional contact problems},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assessing the capriccio method via one-dimensional systems
for coupled continuum-particle simulations in various uniaxial load
cases using a novel interdimensional comparison approach.
<em>CMAME</em>, <em>439</em>, 117817. (<a
href="https://doi.org/10.1016/j.cma.2025.117817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This contribution investigates sources of insufficiencies observed with the Capriccio method for concurrent continuum-particle coupling using a novel comparison technique. This approach maps the deformation states of three-dimensional (3D) coupled domains into a concise one-dimensional (1D) representation, which allows for a separate evaluation of the domain strains in a unified representation, enabling facile comparisons of the domain states during deformation. For the investigation, we employ both a 1D coupled system resembling the most relevant features of the full 3D Capriccio method as well as a corresponding 3D setup. Our analysis explores interactions between different material models in finite element (FE) and molecular dynamics (MD) domains. Based on various load cases studied in the 1D setup, we identify a resistance of the coupling region to spatial movement as the fundamental cause of strain convergence problems when applying the staggered solution scheme. Using the developed mapping approach, examination of the corresponding 3D setup reveals that these strain inconsistencies are even exacerbated by adverse relaxation effects in viscous MD models, particularly when coupled to a corresponding viscoelastic–viscoplastic FE model, leading to divergence from optimal strain. Our findings confirm that smaller strain increments in combination with larger load step numbers significantly improve strain convergence in all domains. Overall, this indicates the need for detailed sensitivity analysis of coupling parameter influences to reduce the identified motion resistance of the coupling region. Based on promising results in 1D, we further recommend exploring monolithic solving schemes for 3D systems to achieve optimal strain convergence for all types of Capriccio-based coupled particle and continuum material models. Moreover, our systematic approach of system definition and interdimensional comparison may serve as a model to assess other domain-decomposition coupling techniques.},
  archive      = {J_CMAME},
  author       = {Lukas Laubert and Felix Weber and Sebastian Pfaller},
  doi          = {10.1016/j.cma.2025.117817},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117817},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Assessing the capriccio method via one-dimensional systems for coupled continuum-particle simulations in various uniaxial load cases using a novel interdimensional comparison approach},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic particle packing to generate complex geometries.
<em>CMAME</em>, <em>439</em>, 117802. (<a
href="https://doi.org/10.1016/j.cma.2025.117802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the discrete nature of solid structures is crucial, particularly in situations where system behavior relies on material discontinuities, such as fracture and wear, along with their subsequent effects. It is not only essential to investigate when failure or discontinuity occurs within a material, but also how it unfolds and impacts its surroundings. While numerical methods serve as effective tools for analyzing structural behavior, continuum-based approaches may not provide a comprehensive view when dealing with discontinuities in a material. Discrete models provide the capability to simulate these discontinuities by bonding discrete elements (particles) together, thereby also simulating continuum behavior. However, the challenge lies in packing these particles within a complex-shaped structure. The dynamic packing approach excels in generating a tightly packed, randomly arranged bonded-particle structure with consistent mechanical behavior. However, it struggles when it comes to generating complex geometries. Conversely, the geometric approach is proficient at generating complex structures but lacks the reliability needed to simulate engineering materials. The method outlined in this paper represents the first attempt to dynamically pack particles within a complex geometry while maintaining all the necessary mechanical properties to accurately model isotropic engineering materials. Such precision in structure and methodology is vital for calibrating the bonds, ensuring that the bonded-particle structure behaves similarly to real materials. As an example, several bonded-particle structures are generated and tested to demonstrate the complexity of their shapes and their realistic mechanical behavior.},
  archive      = {J_CMAME},
  author       = {Muhammad Sameer and C. Fred Higgs III},
  doi          = {10.1016/j.cma.2025.117802},
  journal      = {Computer Methods in Applied Mechanics and Engineering},
  month        = {5},
  pages        = {117802},
  shortjournal = {Comput. Meth. Appl. Mech. Eng.},
  title        = {Dynamic particle packing to generate complex geometries},
  volume       = {439},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="comcom---21">COMCOM - 21</h2>
<ul>
<li><details>
<summary>
(2025). Research on intelligent ship resilient network architecture
based on SDN. <em>COMCOM</em>, <em>236</em>, 108151. (<a
href="https://doi.org/10.1016/j.comcom.2025.108151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the extensive adoption of information and communication technology (ICT) in the maritime field, intelligent ships are increasingly dependent on system integration, control, and data collection from devices. Real-time data transmission is essential for ensuring stable ship system operations. However, communication link failures frequently become key factors impacting data transmission. To this end, we propose an SDN-based intelligent ship network architecture, SDN-Intelligent Ship Network Architecture (SDISN), to simplify network management and enable centralized control of intelligent ships. On this basis, we design a link failure recovery model tailored for different maritime communication services to address the issue of sudden communication link failures. The model begins by collecting the status of the intelligent ship network and pre-defining backup flow rules for different maritime communication service flows. Considering the service flow characteristics, the optimization aims to minimize transmission delay and maximize switch TCAM utilization for life-safety communication flows and ship operational communication flows, respectively. For life-safety communication flows, we introduce a heuristic algorithm that progressively relaxes constraints. Meanwhile, we preload backup flow rules into switches. For ship operational communication flows, we apply a two-stage optimization algorithm, storing the relevant backup flow rules in the controller. Additionally, we propose a backup storage strategy for commercial communication flows based on dynamically adjusting the memory load of switches. Compared to existing approaches, the SDISN satisfies the need for real-time data transmission in intelligent ships while balancing resource consumption and fault response time in its link failure recovery mechanism. Lastly, experiments conduct on a testbed in a real network environment further validate the model&#39;s efficacy and efficiency.},
  archive      = {J_COMCOM},
  author       = {Qing Hu and Jiabing Liu and Zhengfei Wang and Haoyu Si and Sinian Jin and Ying Zhang and Jinhai Li},
  doi          = {10.1016/j.comcom.2025.108151},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108151},
  shortjournal = {Comput. Commun.},
  title        = {Research on intelligent ship resilient network architecture based on SDN},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LBMDTE: Multi-domain traffic engineering in distributed
software-defined networks. <em>COMCOM</em>, <em>236</em>, 108147. (<a
href="https://doi.org/10.1016/j.comcom.2025.108147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale Software-Defined Networks (SDN) applications rely on a distributed control architecture to manage network resources collaboratively among multiple subdomains. This requires multi-domain traffic engineering (TE) for reliable, comprehensive, and efficient traffic scheduling. However, the impact of control message traffic on link load has been ignored in previous multi-domain TE studies. Here, we explore a multi-objective load balancing scheme to address the traffic scheduling imbalance problem for the flat distributed architecture. First, we introduce four types of control message traffic and rules for intra-domain and inter-domain communication. Second, we develop a traffic optimization model to balance the controller load and minimize the maximum link utilization. Third, we propose a hierarchical routing algorithm to compute inter-domain routing, and then propose a heuristic Load Balancing Based Multi-Domain Traffic Engineering (LBMDTE) algorithm to address the optimization objective. Experiments conducted on three real networks and one synthetic network demonstrate that the control link traffic accounts for up to 11.32% of the total link traffic. Our proposed LBMDTE is able to jointly balance the controller load and the link load in comparison with other TE mechanisms.},
  archive      = {J_COMCOM},
  author       = {Kun Wang and Guanghong Lv},
  doi          = {10.1016/j.comcom.2025.108147},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108147},
  shortjournal = {Comput. Commun.},
  title        = {LBMDTE: Multi-domain traffic engineering in distributed software-defined networks},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive survey of network digital twin architecture,
capabilities, challenges, and requirements for edge–cloud continuum.
<em>COMCOM</em>, <em>236</em>, 108144. (<a
href="https://doi.org/10.1016/j.comcom.2025.108144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Digital Twin (NDT) collects data from physical, virtual, and software components and supports real-time network performance analysis, emulation, and intelligent physical network control. This paper surveys the current state of NDT specifications and explores NDT benefits for Network Operators (NOs) and its possible roles in future network management. It discusses the NDT key components, architecture, and integration of Machine Learning and Artificial Intelligence models in the NDT. Further, it covers virtualization technology management, suitability of Software-Defined Networking capabilities, and simulation tools to empower NDT. Two perspectives make the position of this survey different from existing studies; first, it highlights NDT limitations regarding Edge–Cloud Continuum (ECC) contextualization. ECC is a purposeful trending integration of Edge and Cloud Computing, involving multiple stakeholders like Service Providers, Customers, and Platform or Infrastructure Providers. However, current NDT specifications have not mentioned the ways to benefit stakeholders other than NOs. We also discuss notable computing and communication technologies transformations necessary to consider during NDT modeling, the existing data models, and reusable vocabularies that can be extended to achieve a detailed ECC representation for all stakeholders, essentially for Service Providers and Customers. Secondly, a data model is proposed that covers descriptive and prescriptive features and aims to provide a granular representation of ECC components to meet stakeholders’ requirements and render particular user information views. Different explored NDT perspectives, and proposed data model reduces the impact of existing NDT limitations in ECC representation.},
  archive      = {J_COMCOM},
  author       = {Syed Mohsan Raza and Roberto Minerva and Noel Crespi and Maira Alvi and Manoj Herath and Hrishikesh Dutta},
  doi          = {10.1016/j.comcom.2025.108144},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108144},
  shortjournal = {Comput. Commun.},
  title        = {A comprehensive survey of network digital twin architecture, capabilities, challenges, and requirements for Edge–Cloud continuum},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). INT-LLPP: Lightweight in-band network-wide telemetry with
low-latency and low-overhead path planning. <em>COMCOM</em>,
<em>236</em>, 108142. (<a
href="https://doi.org/10.1016/j.comcom.2025.108142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of networks, network telemetry becomes a critical part of network management. However, existing network telemetry systems still suffer from excessive control overhead, forwarding overhead, and latency. In this paper, we propose INT-LLPP, a novel in-band network-wide telemetry system with low-latency and low-overhead path planning. The network telemetry architecture of INT-LLPP is unique in that it only requires a set of probes to collect telemetry items for multiple service flows. Moreover, the proposed Probe Path Generation (PPG) algorithm optimizes the probe paths to reduce the forwarding overhead and achieve full network coverage. To balance the telemetry latency and control overhead, we propose an efficient algorithm called the Simulated Annealing Maximum Latency Setting (SAMLS) algorithm, which controls the length of the probe paths. Simulation results show that INT-LLPP can reduce network telemetry control overhead by over 50% and reduce forwarding overhead by 5% to 10%. Moreover, INT-LLPP can lower telemetry latency by 30% to 40%.},
  archive      = {J_COMCOM},
  author       = {Penghui Zhang and Hua Zhang and Yuqi Dai and Cheng Zeng and Jingyu Wang and Jianxin Liao},
  doi          = {10.1016/j.comcom.2025.108142},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108142},
  shortjournal = {Comput. Commun.},
  title        = {INT-LLPP: Lightweight in-band network-wide telemetry with low-latency and low-overhead path planning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient paths determining strategies in mobile
crowd-sensing networks with AI-based sensors forwarding data.
<em>COMCOM</em>, <em>236</em>, 108138. (<a
href="https://doi.org/10.1016/j.comcom.2025.108138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting a sufficient number of mobile users to collect and upload collected data to the server is a critical issue in the Mobile Crowd-sensing Networks (MCN). Previous studies have assumed that mobile users upload collected data over cellular networks, which could cause heavily burden to users. This work focus on how to forward collected data by pre-deployed wireless sensors which can fuse collected data and operate as edge nodes. Specifically, given the reward paid to each mobile user depends on the time he spends on data collection and uploading, this work investigates the problem how to select Points of Interest (PoIs) and edge nodes for participants who already have schedules with the objective of minimizing the total reward paid to all participants. We boil down this problem to the problem of determining path for each participant which connects participant’s initial location to PoI, then to an edge node and finally to participant’s destination. We formulate it as Paths determination with Cost Minimization problem. We can prove that this problem is an NP-Complete problem. Considering that the sensors acted as edge nodes which may be rechargeable or have limited energy, we design three heuristic algorithms: Minimum Cost Algorithm (MCA), Minimum Cost with Energy Consideration Algorithm (MCECA), and Energy Balance Algorithm (EBA) to address this problem. Finally, we conduct extensive simulations to validate the efficiency of the proposed algorithms. The results demonstrate that MCA finds paths for users with lower cost, while EBA effectively balances the energy consumption of edge nodes.},
  archive      = {J_COMCOM},
  author       = {Jiaoyan Chen and Jin Liu and Zhehao Cheng and Laurence Tianruo Yang and Xianjun Deng and Yihong Chen},
  doi          = {10.1016/j.comcom.2025.108138},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108138},
  shortjournal = {Comput. Commun.},
  title        = {Efficient paths determining strategies in mobile crowd-sensing networks with AI-based sensors forwarding data},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDSLS: An approximation SINR-based shortest link scheduling
algorithm with power control. <em>COMCOM</em>, <em>236</em>, 108137. (<a
href="https://doi.org/10.1016/j.comcom.2025.108137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine the Shortest Link Scheduling (SLS) issue in wireless networks within the context of the Signal-to-Interference-plus-Noise-Ratio ( SINR ) interference model with oblivious power control, and propose an approximation Diamond-based SLS with Power control (PDSLS) algorithm. Given that numerous nodes within wireless networks operate on battery power, minimizing the transmission power not only reduces interference but also conserves energy. We adopt a novel link classification approach, reducing nodes’ transmission power without generating “black and gray” links. We schedule links belonging to each class by dividing the link deployment plane into diamonds. The validity and efficacy of our algorithm are demonstrated through theoretical analysis and simulation outcomes. Numerical analysis shows that our approximation ratio is tighter than the best known ones in state-of-the-art algorithms. Simulation results demonstrate that the proposed algorithm effectively reduces the transmission power and the number of required time slots compared to the state-of-the-art algorithms.},
  archive      = {J_COMCOM},
  author       = {Neda Mohammadi and Bahram Sadeghi Bigham and Mehdi Kadivar},
  doi          = {10.1016/j.comcom.2025.108137},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108137},
  shortjournal = {Comput. Commun.},
  title        = {PDSLS: An approximation SINR-based shortest link scheduling algorithm with power control},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-powered resilience: A dual-approach for outage management
in dense cellular networks. <em>COMCOM</em>, <em>236</em>, 108129. (<a
href="https://doi.org/10.1016/j.comcom.2025.108129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As 5G evolves to 6G, network management faces growing challenges with increasing base station density, leading to more frequent outages. To address this, we introduce a robust, automated two-tier framework for outage management. The first tier involves an artificial intelligence-based outage detection scheme using an enhanced XGBoost model (Impv-XGBoost), which incorporates autoencoder outputs for hyperparameter tuning. The analysis shows Impv-XGBoost’s superior performance in high shadowing conditions and with sparse data, outperforming existing methods. The second tier adopts an actor–critic reinforcement learning strategy for outage compensation by adjusting the tilt of the neighboring base station and power. To prevent service declines to connected user equipment, our compensation scheme accounts for both outage-affected users and those connected to compensating base stations. We design a reward scheme that combines Jain’s fairness index and the geometric mean of the reference signal received power to ensure fairness and enhance convergence. Performance evaluations for single and multiple base station failures show coverage improvements for outage-affected users without compromising the coverage of the users in compensating base stations.},
  archive      = {J_COMCOM},
  author       = {Waseem Raza and Muhammad Umar Bin Farooq and Aneeqa Ijaz and Marvin Manalastas and Ali Imran},
  doi          = {10.1016/j.comcom.2025.108129},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108129},
  shortjournal = {Comput. Commun.},
  title        = {AI-powered resilience: A dual-approach for outage management in dense cellular networks},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SQID: A deep learning and network design synergy for
next-generation IoT resource allocation management. <em>COMCOM</em>,
<em>236</em>, 108128. (<a
href="https://doi.org/10.1016/j.comcom.2025.108128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exponential growth of mobile broadband and Internet of Things (IoT) devices has pushed traditional IoT models to their operational limits, necessitating more efficient data management strategies. This research introduces the SQID framework, a solution that integrates advanced techniques, including Sierpinski triangle design (STD) for network optimization, quantum density peak clustering (QDPC) for intelligent device clustering, and improved deep deterministic policy gradient (IDDPG) for deep learning-driven traffic prediction. By utilizing STD to optimize device communication, the framework applies the QDPC algorithm to efficiently cluster devices, ensuring balanced packet distribution and minimizing latency. Additionally, IDDPG enhances network performance by enabling accurate traffic prediction and resource allocation, optimizing data transmission. Extensive simulations reveal that SQID outperforms existing methods in critical metrics such as time efficiency, latency reduction, throughput maximization, and packet loss. These results indicate that SQID has the potential to significantly improve data management in IoT networks, paving the way for next-generation IoT advancements.},
  archive      = {J_COMCOM},
  author       = {Ali. M.A. Ibrahim and Zhigang Chen and Yijie Wang and Hala A. Eljailany},
  doi          = {10.1016/j.comcom.2025.108128},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108128},
  shortjournal = {Comput. Commun.},
  title        = {SQID: A deep learning and network design synergy for next-generation IoT resource allocation management},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Target wake time in IEEE 802.11 WLANs: Survey, challenges,
and opportunities. <em>COMCOM</em>, <em>236</em>, 108127. (<a
href="https://doi.org/10.1016/j.comcom.2025.108127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wi-Fi has become the most widely used Wireless Local Area Network (WLAN) technology, but as the density of WLAN deployments and the number of devices per network increase, congestion has become a significant issue. Scheduling features in Wi-Fi have the potential to alleviate these issues by managing medium access more efficiently. While there have been other scheduling features in Wi-Fi in the past, none were widely adopted and were limited in functionality. Target Wake Time (TWT) introduces powerful scheduling capabilities to Wi-Fi as part of Wi-Fi 6, representing a fundamental shift in how Wi-Fi Access Points (APs) manage channel access for Stations (STAs) while improving energy efficiency. TWT is extremely versatile and is poised to play a crucial role in reducing contention and enhancing performance, especially in dense network environments. The potential benefits are particularly valuable for Internet of Things (IoT) scenarios, where low power consumption and efficient medium access are essential due to the large number of connected devices. This paper presents an in-depth survey of the research on TWT, categorizing and analyzing existing literature while identifying practical challenges often overlooked due to idealized assumptions. We introduce comprehensive models of infrastructure-mode APs and STAs to facilitate discussions of current and future work. We provide a detailed analysis of the challenges and issues that must be addressed to fully realize the performance gains promised by TWT. Furthermore, we explore the potential future applications of TWT, particularly in conjunction with upcoming features in IEEE 802.11 such as multi-link operation (MLO) and multi-AP coordination, offering insights into novel uses of TWT for enhancing Wi-Fi performance.},
  archive      = {J_COMCOM},
  author       = {Shyam Krishnan Venkateswaran and Ching-Lun Tai and Atif Ahmed and Raghupathy Sivakumar},
  doi          = {10.1016/j.comcom.2025.108127},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108127},
  shortjournal = {Comput. Commun.},
  title        = {Target wake time in IEEE 802.11 WLANs: Survey, challenges, and opportunities},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards green networking: Efficient dynamic radio resource
management in open-RAN slicing using deep reinforcement learning and
transfer learning. <em>COMCOM</em>, <em>236</em>, 108126. (<a
href="https://doi.org/10.1016/j.comcom.2025.108126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next Generation Wireless Networks (NGWNs) are characterized by agility and flexibility. It introduces new technologies such as network slicing (NS) and Open Radio Access Network (O-RAN). NS supports multiple services with different requirements whereas O-RAN supports different network suppliers and provides Mobile Network Operators (MNOs) more intelligent control. Deep Reinforcement Learning (DRL) techniques have been presented to address resource management and other problems in NGWNs in recent years. However, instability and lateness in convergence are the main obstacles against their adoption in live networks. Moreover, deep learning models consume lots of energy and emit significant amounts of carbon dioxide which badly impacts climate. This paper addresses solving the dynamic radio resource management (RRM) problem in O-RAN slicing with DRL and Transfer Learning (TL), focusing on proposing a green model that minimizes power and energy consumption, decreasing the carbon footprint. A new latency-and-reliability-based reward function is designed. Then, a variable threshold action filtration mechanism is proposed, and a policy TL approach is proposed to accelerate the performance in commercial networks. Compared with the state-of-the-art, this work significantly improved exploration stability, convergence speed, Quality of Service (QoS) satisfaction, power and energy consumption, and emitted carbon footprint.},
  archive      = {J_COMCOM},
  author       = {Heba Sherif and Eman Ahmed and Amira M. Kotb},
  doi          = {10.1016/j.comcom.2025.108126},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108126},
  shortjournal = {Comput. Commun.},
  title        = {Towards green networking: Efficient dynamic radio resource management in open-RAN slicing using deep reinforcement learning and transfer learning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IoT edge network interoperability. <em>COMCOM</em>,
<em>236</em>, 108125. (<a
href="https://doi.org/10.1016/j.comcom.2025.108125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network interoperability is crucial for achieving seamless communication across Internet of Things (IoT) environments. IoT comprises heterogeneous devices and systems supporting diverse technologies, protocols, and manufacturers. Enabling devices to communicate and exchange data effectively, regardless of underlying protocols, is key to building cohesive and integrated IoT networks. IoT has transformed multiple sectors ranging from home automation to healthcare—by harnessing a vast array of sensors and actuators that communicate through cloud, fog, and edge layers. However, the variety in device manufacturing and communication standards demands interoperable interfaces, and most current solutions depend on cloud-based centralised architectures. These architectures introduce latency and scalability challenges, particularly for resource-constrained IoT devices that often struggle to communicate with the cloud due to limited resources. This paper addresses network interoperability at the IoT edge level, focusing on resource-efficient communication by integrating Wi-Fi and Bluetooth, two commonly used protocols in IoT ecosystems. We have implemented a network edge interoperability solution that supports effective data exchange between devices operating on these distinct protocols, enhancing the overall efficiency, flexibility, and scalability of IoT systems. Our approach allows devices interoperate by addressing network latency and bandwidth limitations, incorporating an integrated controller to facilitate broader applications and enhance performance across IoT networks. Our findings illustrate how bridging protocol differences can foster more resilient and adaptable IoT solutions, advancing the deployment of IoT applications across various domains and use cases.},
  archive      = {J_COMCOM},
  author       = {Tanzima Azad and M.A. Hakim Newton and Jarrod Trevathan and Abdul Sattar},
  doi          = {10.1016/j.comcom.2025.108125},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108125},
  shortjournal = {Comput. Commun.},
  title        = {IoT edge network interoperability},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A stochastic analysis of the gasper protocol.
<em>COMCOM</em>, <em>236</em>, 108123. (<a
href="https://doi.org/10.1016/j.comcom.2025.108123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ethereum has recently switched to a Proof of Stake consensus protocol called Gasper. We analyze Gasper using PRISM+ , an extension of the probabilistic model checker PRISM with primitives for modeling blockchain data types. PRISM+ is therefore used to rapidly and automatically analyze the robustness of Gasper when tuning, up or down, several basic parameters of the protocol, such as network latencies and number of validators. We also study the effectiveness of Gasper in updating stakes and its resilience to three attacks: the balance, bouncing and time attacks.},
  archive      = {J_COMCOM},
  author       = {Cosimo Laneve and Adele Veschetti},
  doi          = {10.1016/j.comcom.2025.108123},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108123},
  shortjournal = {Comput. Commun.},
  title        = {A stochastic analysis of the gasper protocol},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy efficient LEO satellite communications: Traffic-aware
payload switch-off techniques. <em>COMCOM</em>, <em>236</em>, 108122.
(<a href="https://doi.org/10.1016/j.comcom.2025.108122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low Earth orbit (LEO) satellite constellations have a pivotal role in shaping the future of communication networks by providing extensive global coverage. However, ensuring the long-term viability of LEO constellations relies on addressing significant challenges, particularly in the domains of energy efficiency and maximizing the lifespan of satellites. This paper introduces a novel approach that considers user traffic demands to optimize power consumption. By implementing a traffic-aware strategy, redundant satellites can be intelligently switched-off, resulting in significant power savings within the LEO constellation. To accomplish this objective, we formulate the problem of joint satellite beam assignment and beam power allocation as a mixed binary integer optimization problem while carefully considering the constraints imposed by satellite-user visibility and the need to fulfill the data traffic requirements of all ground users. To tackle the formulated problem, we employ a framework called the Difference of Convex Programming and Multiplier Penalty (DCMP) based convexification approach, which ensures convergence to a local optimum. The reformulated convex problem is solved using the low-complexity iterative algorithm, Successive Convex Approximation (SCA). Additionally, we propose a heuristic algorithm based on slant distance, which offers a simplified and efficient solution to the joint problem. To corroborate the effectiveness and validity of the proposed techniques, we assess and compare their performance via simulations, considering practical constellation patterns and realistic user traffic distribution. It has been shown that approximately 43% of the satellite nodes can be switched-off for energy saving, and thus, extending the constellation lifetime and reducing the aggregated interference from multi-beam satellites.},
  archive      = {J_COMCOM},
  author       = {Vaibhav Kumar Gupta and Hayder Al-Hraishawi and Eva Lagunas and Symeon Chatzinotas},
  doi          = {10.1016/j.comcom.2025.108122},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108122},
  shortjournal = {Comput. Commun.},
  title        = {Energy efficient LEO satellite communications: Traffic-aware payload switch-off techniques},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A defense mechanism for federated learning in AIoT through
critical gradient dimension extraction. <em>COMCOM</em>, <em>236</em>,
108114. (<a href="https://doi.org/10.1016/j.comcom.2025.108114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging the distributed nature of the Internet of Things (IoT), Federated Learning (FL) facilitates knowledge transfer among heterogeneous IoT devices, enhancing the capabilities of Artificial Intelligence of Things (AIoT) while preserving data privacy. However, FL is susceptible to poisoning attacks such as label flipping, Gaussian, and backdoor attacks. Most existing defense strategies rely on robust aggregation algorithms that use the statistical properties of gradient vectors to counteract poisoning attacks, however, they often overlook the non-independent and identically distributed (non-iid) nature of client data, limiting their effectiveness in the IoT. We propose a method that combines cross-node Top-k gradient vector compression and Principal Component Analysis (PCA) dimensionality reduction to extract critical gradient dimensions. By clustering these essential dimensions and performing filtering, our approach effectively distinguishes malicious from benign clients in non-iid data scenarios. Additionally, we introduce a client trust-score assessment mechanism that continuously monitors client behavior and applies secondary filtering, further improving the identification of malicious clients. Experimental results on the CIFAR-10, MNIST, DomainNet, and Flowers102 datasets demonstrate that our method achieves higher model accuracy and robustness in non-iid data settings compared to existing defense strategies.},
  archive      = {J_COMCOM},
  author       = {Jian Xu and Bing Guo and Fei Chen and Yan Shen and Shengxin Dai and Cheng Dai and Yuchuan Hu},
  doi          = {10.1016/j.comcom.2025.108114},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108114},
  shortjournal = {Comput. Commun.},
  title        = {A defense mechanism for federated learning in AIoT through critical gradient dimension extraction},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing UAV delivery for pervasive systems through
blockchain integration and adversarial machine learning.
<em>COMCOM</em>, <em>236</em>, 108113. (<a
href="https://doi.org/10.1016/j.comcom.2025.108113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned Aerial Vehicles (UAVs), play a significant role in the advancement of pervasive systems by providing efficient, scalable, and innovative solutions in various sectors, such as smart cities or location-based services. However, the current UAV delivery scenario presents various challenges for recipients, including lengthy identity verification processes, privacy concerns, and risks of fraud and theft. In response to these issues, this paper proposes an innovative system that leverages Blockchain technology and Adversarial Machine Learning (AML) to tackle these problems effectively. The proposed system streamlines the verification process, enhances privacy safeguards, and reduces fraud risks. The integration of AML is crucial as it enables users to have greater control over their personal data, boosting privacy and security. AML also plays a critical role in this system by creating test scenarios that reinforce the machine learning model against adversarial threats, ensuring its precision and dependability in the face of malicious manipulations. The paper also provides details on the practical implementation and evaluation of this system in real-life adversarial situations. The evaluation results demonstrate superior performance on selected metrics, highlighting the potential of this system as an effective solution for verifying recipients in UAV delivery.},
  archive      = {J_COMCOM},
  author       = {Chengzu Dong and Shantanu Pal and Aiting Yao and Frank Jiang and Shiping Chen and Xiao Liu},
  doi          = {10.1016/j.comcom.2025.108113},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108113},
  shortjournal = {Comput. Commun.},
  title        = {Optimizing UAV delivery for pervasive systems through blockchain integration and adversarial machine learning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decentralized coordination for resilient federated learning:
A blockchain-based approach with smart contracts and decentralized
storage. <em>COMCOM</em>, <em>236</em>, 108112. (<a
href="https://doi.org/10.1016/j.comcom.2025.108112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning (ML) in distributed environments increasingly deals with sensitive data (like healthcare or financial records) that cannot be centrally stored or processed due to privacy concerns. Federated Learning (FL) addresses this by enabling model training across decentralized devices, but faces significant challenges including system reliability, node failures, and trust issues among participants. Traditional FL approaches often rely on centralized coordinators, creating single points of failure and potential security vulnerabilities. This paper presents a novel approach to FL that leverages smart contracts, blockchain, and decentralized storage to enhance the traceability and reliability of the learning process. Our proposed system architecture is fully decentralized, eliminating single points of failure and promoting cooperation through a rewarding mechanism. Unlike previous approaches that neglect node fault tolerance, we introduce a smart contract based scheme for managing node failures and electing the aggregator node. The presence of the smart contract, executed on a decentralized permissioned blockchain, provides reliability guarantees and eliminates the need for costly distributed algorithms in terms of message exchange. An experimental study is conducted to evaluate various aspects of the FL system. We present results related to the accuracy and effectiveness of the FL system on ML models. We also examine the performance related to the distribution of the weights of the ML model based on the use of IPFS. Furthermore, we analyze the performance of the smart contract in terms of gas consumption. Lastly, we investigate the impact of failures combined with incentive policies and aggregator election algorithms on the FL system. Our findings demonstrate the viability of the proposed approach, paving the way for more robust, reliable, and efficient FL systems.},
  archive      = {J_COMCOM},
  author       = {Stefano Ferretti and Lorenzo Cassano and Gabriele Cialone and Jacopo D’Abramo and Filippo Imboccioli},
  doi          = {10.1016/j.comcom.2025.108112},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108112},
  shortjournal = {Comput. Commun.},
  title        = {Decentralized coordination for resilient federated learning: A blockchain-based approach with smart contracts and decentralized storage},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resiliency focused proactive lifecycle management for
stateful microservices in multi-cluster containerized environments.
<em>COMCOM</em>, <em>236</em>, 108111. (<a
href="https://doi.org/10.1016/j.comcom.2025.108111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Containerization has become fundamental to deploying cloud-native applications, allowing for the packaging and independent execution of applications. This approach speeds up deployment processes and facilitates the creation of various environments for feature testing. However, the ephemeral nature of containers poses a significant challenge to data persistence, especially during container restarts or migrations across different hosts. This paper proposes a proactive zero-touch management solution for stateful microservices applications, ensuring seamless application lifecycle management. Our solution integrates seamlessly with container platforms such as Kubernetes and supports multi-cluster environments, enhancing fault tolerance and data persistence in stateful applications. The solution has been thoroughly tested on different hardware configurations in the public cloud and with our on-premises servers.},
  archive      = {J_COMCOM},
  author       = {Abd Elghani Meliani and Mohamed Mekki and Adlen Ksentini},
  doi          = {10.1016/j.comcom.2025.108111},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108111},
  shortjournal = {Comput. Commun.},
  title        = {Resiliency focused proactive lifecycle management for stateful microservices in multi-cluster containerized environments},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Authenticated data visualization for hybrid blockchain-based
digital product passports. <em>COMCOM</em>, <em>236</em>, 108110. (<a
href="https://doi.org/10.1016/j.comcom.2025.108110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Digital Product Passport (DPP), introduced by the European Green Deal in 2022, is a key innovation designed to improve product sustainability and circularity by enabling secure and transparent communication among stakeholders. Despite its potential, existing blockchain-based implementations of the DPP face significant limitations, such as scalability challenges and usability issues, which hinder widespread adoption. To address these shortcomings, this paper proposes a hybrid blockchain-based implementation of the DPP that enhances data transparency, integrity, and accessibility while minimizing common drawbacks. The proposed solution utilizes a hybrid blockchain architecture, where data is collected and managed within a private blockchain network and notarized on a public blockchain. Additionally, the central problem of authenticated blockchain data visualization is addressed by proposing a new solution that not only ensures the provenance, integrity, and history consistency of DPP data, but also preserves these properties throughout data processing and visualization. Our experiments demonstrates the effectiveness of our approach, achieving low time consumption and storage overhead. To further promote transparency and collaboration, a selection of the implementation has been made available as open-source projects. We show that hybrid blockchains offer a promising path for realizing the full potential of the Digital Product Passport.},
  archive      = {J_COMCOM},
  author       = {Domenico Tortola and Claudio Felicioli and Andrea Canciani and Fabio Severino},
  doi          = {10.1016/j.comcom.2025.108110},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108110},
  shortjournal = {Comput. Commun.},
  title        = {Authenticated data visualization for hybrid blockchain-based digital product passports},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active queue management in 5G and beyond cellular networks
using machine learning. <em>COMCOM</em>, <em>236</em>, 108108. (<a
href="https://doi.org/10.1016/j.comcom.2025.108108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a state-of-the-art framework for adapting Active Queue Management (AQM) in 5G and beyond cellular networks with disaggregated Radio Access Network (RAN) deployments. While existing AQM algorithms effectively mitigate bufferbloat in monolithic RAN deployments, their potential in disaggregated ones remains largely unexplored. This gap particularly relates to AQM algorithms relying on communication between layers distributed across distinct network entities to operate. Our research explores the current literature on AQM, identifies the gaps regarding disaggregated deployments, and introduces a comprehensive framework that employs Artificial Intelligence (AI) and Machine Learning (ML) within the RAN Intelligent Controller (RIC) for adapting AQM in such deployments. We evaluate our novel solution on a previously proposed AQM algorithm which requires cross-layer communication, using OpenAirInterface5G (OAI5G) to deploy a disaggregated RAN and a connected User Equipment (UE) that experiences realistic network conditions, including noise and mobility. Finally, we assess its accuracy through the Quality of Service (QoS) achieved for our disaggregated deployment on the NITOS testbed.},
  archive      = {J_COMCOM},
  author       = {Alexandros Stoltidis and Kostas Choumas and Thanasis Korakis},
  doi          = {10.1016/j.comcom.2025.108108},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108108},
  shortjournal = {Comput. Commun.},
  title        = {Active queue management in 5G and beyond cellular networks using machine learning},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-time conditional handover for B5G/6G. <em>COMCOM</em>,
<em>236</em>, 108107. (<a
href="https://doi.org/10.1016/j.comcom.2025.108107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conditional Handover (CHO) by the 3rd Generation Partnership Project (3GPP) enables efficient user mobility between Base Stations (BSs) by preselecting and preparing Target BSs (T-BSs). However, CHO relies on signal strength for T-BS selection, leading to resource blocking on multiple T-BSs due to signal fluctuations. Existing state-of-the-art methods use deep learning to narrow the list of T-BSs but still lack an effective method for resource reservation timing. This paper presents in-time CHO (iCHO) which exploits historical mobility data to estimate user dwell time at the current BS to reduce resource reservation duration. The proposed iCHO employs a Multivariate Multi-output Single-step Prediction (MMSP) model that leverages a multi-task learning approach to simultaneously predict the minimal list of required T-BSs together with the user dwell time. The model demonstrates remarkable performance across two mobility datasets of different scales, achieving T-BS prediction accuracies of 98% and 95%. It also ensures a 100% handover success rate with a minimum of three and four predicted T-BSs for both datasets, respectively, significantly limiting the list of T-BSs. Moreover, the MMSP model achieves a Mean Absolute Error (MAE) of 19 s and 45 s when predicting the user’s dwell time at the current BS. By utilizing these predictions, iCHO reserves resources at the minimum number of T-BSs immediately before handover. Thus, iCHO can save up to 99% of resources from blockage as compared to the CHO, enabling operators to increase revenue by serving up to eighteen more users with the saved resources.},
  archive      = {J_COMCOM},
  author       = {Sardar Jaffar Ali and Syed M. Raza and Huigyu Yang and Duc Tai Le and Rajesh Challa and Moonseong Kim and Hyunseung Choo},
  doi          = {10.1016/j.comcom.2025.108107},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108107},
  shortjournal = {Comput. Commun.},
  title        = {In-time conditional handover for B5G/6G},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the ACME protocol to automate the management of
all x.509 web certificates (extended version). <em>COMCOM</em>,
<em>236</em>, 108106. (<a
href="https://doi.org/10.1016/j.comcom.2025.108106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {X.509 Public Key Infrastructures (PKIs) are widely used for managing X.509 Public Key Certificates (PKCs) to allow for secure communications and authentication on the Internet. PKCs are issued by a trusted third-party Certification Authority (CA), which is responsible for verifying the certificate requester’s information. Recent developments in web PKI show a high proliferation of Domain Validated (DV) certificates but a decline in Extended Validated (EV) certificates, indicating poor authentication of the entities behind web services. The ACME protocol facilitates the deployment of Web Certificates by automating their management. However, it is only limited to DV certificates. This paper proposes an enhancement to the ACME protocol for automating all types of Web X.509 PKCs by using W3C Verifiable Credentials (VCs) to assert a requester’s claims. We argue that any CA’s requirements for issuing a PKC can be expressed as a set of VCs returned in a Verifiable Presentation (VP) that could facilitate the issuance of high-profile certificates such as EV certificates. We also propose a generic communication workflow to request and present VPs, which interact with our ACME enhancement. In this regard, we present proof of our approach by using the OpenID for Verifiable Presentation protocol (OID4VP) to request and present VPs. To assess the feasibility of our solution, we conduct a complexity analysis, evaluating both computational and communication overhead compared to the standard ACME protocol. Finally, we present an implementation of our solution as proof-of-concept.},
  archive      = {J_COMCOM},
  author       = {David A. Cordova Morales and Ahmad Samer Wazan and David W. Chadwick and Romain Laborde and April Rains Reyes Maramara},
  doi          = {10.1016/j.comcom.2025.108106},
  journal      = {Computer Communications},
  month        = {4},
  pages        = {108106},
  shortjournal = {Comput. Commun.},
  title        = {Enhancing the ACME protocol to automate the management of all x.509 web certificates (Extended version)},
  volume       = {236},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cor---16">COR - 16</h2>
<ul>
<li><details>
<summary>
(2025). Logic-based benders decomposition methods for the
distributed permutation flow shop scheduling problem with production and
transportation cost. <em>COR</em>, <em>179</em>, 107044. (<a
href="https://doi.org/10.1016/j.cor.2025.107044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed manufacturing mode can significantly enhance production flexibility and efficiency. Considering that factories and customers in distributed manufacturing environments may be geographically dispersed, we address a distributed permutation flow shop scheduling problem (DPFSP) with direct transportation under different cost of production and transportation while the goal is to minimize of weighted sum cost and makespan (DPFSP-PTM). First, we formulate two mixed-integer linear programming (MILP) models and one constraint programming (CP) model to optimize the objective simultaneously. Then, by decomposing DPFSP-PTM into an order assignment master problem (AMP) and a series of scheduling subproblems (SSPs), we develop two exact methods based on logic-based Benders decomposition (LBBD) and Branch-and-Check (BCH). To accelerate convergence, we propose three strong SSP relaxations based on the single-machine bottleneck to enhance the MILP models and AMP. Additionally, we introduce an initial solution generated by the iterated greedy (IG) algorithm to warm-start the LBBD. Finally, we demonstrate the effectiveness of the proposed methods in achieving competitive average optimality gaps and lower bounds across both small-scale and large-scale instances.},
  archive      = {J_COR},
  author       = {Fuli Xiong and Jiangbo Shi and Lin Jing and An Ping},
  doi          = {10.1016/j.cor.2025.107044},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107044},
  shortjournal = {Comput. Oper. Res.},
  title        = {Logic-based benders decomposition methods for the distributed permutation flow shop scheduling problem with production and transportation cost},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling moldable tasks on homogeneous multi-cluster
platforms with GPUs. <em>COR</em>, <em>179</em>, 107041. (<a
href="https://doi.org/10.1016/j.cor.2025.107041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines task scheduling in homogeneous multi-cluster platforms, equipped with Graphics Processing Units (GPUs), with the aim of minimizing the makespan. We assume that tasks can be parallelized across these platforms under the moldable model. Recognizing the NP-hard nature of the problem, our goal is to develop algorithms that provide approximation ratios. While existing research has established algorithms for single-cluster GPU environments, scaling these to multi-cluster platforms introduces new challenges, especially due to the restriction that tasks cannot use processors from different clusters. We propose an integer programming-based algorithm that achieves an approximation ratio of 3 2 + ϵ , trading off runtime for an improved approximation ratio. Additionally, leveraging recent theoretical advancements, we have created a polynomial-time algorithm with an approximation ratio of 2 + ϵ . Empirical computational experiments show that our algorithms surpass their counterparts in empirical approximation ratios.},
  archive      = {J_COR},
  author       = {Fangfang Wu and Run Zhang and Xiandong Zhang},
  doi          = {10.1016/j.cor.2025.107041},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107041},
  shortjournal = {Comput. Oper. Res.},
  title        = {Scheduling moldable tasks on homogeneous multi-cluster platforms with GPUs},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-armed bandit for the cyclic minimum sitting
arrangement problem. <em>COR</em>, <em>179</em>, 107034. (<a
href="https://doi.org/10.1016/j.cor.2025.107034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graphs are commonly used to represent related elements and relationships among them. Signed graphs are a special type of graphs that can represent more complex structures, such as positive or negative connections in a social network. In this work, we address a combinatorial optimization problem, known as the Cyclic Minimum Sitting Arrangement, that consists of embedding a signed input graph into a cycle host graph, trying to locate in the embedding positive connected vertices closer than negative ones. This problem is a variant of the well-known Minimum Sitting Arrangement where the host graph has the structure of a path graph. To tackle the problem, we propose an algorithm based on the Multi-Armed Bandit method that combines three greedy-randomized constructive procedures with a Variable Neighborhood Descent local search algorithm. To assess the merit of our proposal, we compare it with the state-of-the-art method. Our experiments show that our algorithm outperforms the best-known method in the literature to date, and the results are statistically significant, establishing itself as the new state of the art for the problem.},
  archive      = {J_COR},
  author       = {Marcos Robles and Sergio Cavero and Eduardo G. Pardo and Oscar Cordón},
  doi          = {10.1016/j.cor.2025.107034},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107034},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-armed bandit for the cyclic minimum sitting arrangement problem},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient iterated local search for the minimum
quasi-clique partitioning problem. <em>COR</em>, <em>179</em>, 107033.
(<a href="https://doi.org/10.1016/j.cor.2025.107033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a simple undirected graph G and a real constant γ ∈ ( 0 , 1 ] , a γ -quasi-clique is defined as a subset of vertices that induces a subgraph with an edge density of at least γ . The minimum quasi-clique partitioning problem (MQCPP) seeks to identify the minimum cardinality of γ -quasi-clique partitions in G . This work presents an efficient iterated local search (ILS) method to address MQCPP by using a two-phase local search procedure for local improvement, and a greedy-based perturbation procedure for diversifying the search process. An evaluation function that records the number of intra edges of each quasi-clique is used for neighboring solution evaluation, and a fast incremental evaluation technique is employed to speed up the evaluation. Numerical results on three sets of 321 benchmark instances demonstrate the superior performance of the proposed algorithm compared with state-of-the-art approaches. Specifically, ILS reports 153 (47.7%) new upper bounds and fails to reach the best known solution for only 2 instances. Additional analysis experiments are conducted to evaluate the effects of the key components of ILS, including the two-phase local search procedure, the greedy-based perturbation procedure, and the fast incremental evaluation technique.},
  archive      = {J_COR},
  author       = {Qing Zhou and Tongtong Zhu and Qinghua Wu and Zhong-Zhong Jiang and Wenjie Wang},
  doi          = {10.1016/j.cor.2025.107033},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107033},
  shortjournal = {Comput. Oper. Res.},
  title        = {An efficient iterated local search for the minimum quasi-clique partitioning problem},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autonomous delivery vehicle routing problem with drones
based on multiple delivery modes. <em>COR</em>, <em>179</em>, 107032.
(<a href="https://doi.org/10.1016/j.cor.2025.107032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous delivery vehicles (ADVs) and drones have gained widespread attention in the last-mile delivery due to their efficiency, environmental sustainability, and convenience. Moreover, the cooperative delivery between ADVs and drones is very complex, and most of the existing studies are focused on the cooperative delivery between trucks and drones in a single delivery mode. In contrast, this paper introduces a new vehicle routing problem for an unmanned delivery system consisting of ADVs and heterogeneous drones based on multiple delivery modes. A mixed integer programming (MIP) model is constructed for the autonomous delivery vehicle routing problem with drones based on multiple delivery modes (ADVRPD-MDM) with the objective of minimizing cost. We design a randomized variable neighborhood search (RVNS) algorithm that incorporates 12 specific neighborhood structures, a random variable neighborhood descent (RVND) mechanism and a random shaking strategy to solve the model. We evaluate the application effects of each operator and verify the effectiveness of the RVNS algorithm by the improved Solomon instances. Furthermore, when compared to the large neighborhood search (LNS) algorithm in 56 instances, the RVNS algorithm demonstrates an average improvement of 3.86% in its lowest solution, thereby confirming its superior performance. Through a series of experiments, it has been observed that the integration of collaborative drones and parallel drones within the unmanned delivery system can effectively reduce the cost. The results of the sensitivity analysis demonstrate that factors such as the multi-visit capability, the utilization of multiple drones, the high payload capacity, the long endurance, and the rapid charging rate are critical in reducing the cost. Finally, we verify through a case study that the unmanned delivery system with the ADV as carrier offers cost advantages compared to those employing trucks.},
  archive      = {J_COR},
  author       = {Jili Kong and Hao Wang and Minhui Xie},
  doi          = {10.1016/j.cor.2025.107032},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107032},
  shortjournal = {Comput. Oper. Res.},
  title        = {Autonomous delivery vehicle routing problem with drones based on multiple delivery modes},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards more efficient local search for weighted graph
coloring problem in massive graphs. <em>COR</em>, <em>179</em>, 107031.
(<a href="https://doi.org/10.1016/j.cor.2025.107031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The weighted graph coloring problem (WGCP) is a well-known NP-hard combinatorial optimization problem with various practical applications. Due to its theoretical significance and practical relevance, numerous algorithms have been developed to address the WGCP. In the past, both exact and heuristic algorithms have primarily focused on solving classic benchmarks, with relatively few efforts dedicated to tackling the challenges posed by massive WGCP real-world applications. In our work, we propose an effective local search algorithm for the WGCP based on three main ideas. First, we introduce a new variant of configuration checking to escape from local optima. Second, we devise a novel method for selecting vertex movements that guides the search towards more favorable directions. Third, we propose a novel deep optimization strategy to perturb the solution. Extensive experiments demonstrate that our proposed algorithm outperforms several state-of-the-art algorithms on both classic and massive benchmarks. This indicates the effectiveness and superiority of our approach in solving the WGCP.},
  archive      = {J_COR},
  author       = {Shiwei Pan and Yujiao Zhao and Jiangnan Li and Yiyuan Wang and Ye Zhang and Wenbo Zhou and Minghao Yin},
  doi          = {10.1016/j.cor.2025.107031},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107031},
  shortjournal = {Comput. Oper. Res.},
  title        = {Towards more efficient local search for weighted graph coloring problem in massive graphs},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feasible and infeasible region search for the maximally
diverse grouping problem. <em>COR</em>, <em>179</em>, 107030. (<a
href="https://doi.org/10.1016/j.cor.2025.107030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The maximally diverse grouping problem (MDGP) involves assigning elements into disjoint groups, and its objective is to maximize the total diversity of the groups where each pair of elements in a group has a certain diversity. MDGP has broad application and is known to be an NP-hard problem. In this paper, we integrate infeasible region search, exploration, and exploitation into a new algorithm called the feasible and infeasible region (FIFR) algorithm. The FIFR algorithm is significantly better than three state-of-the-art algorithms on 500 instances widely used in the literature.},
  archive      = {J_COR},
  author       = {Xiaofan Wu and Jiejian Feng and Jinglei Yang and Yang Zhang},
  doi          = {10.1016/j.cor.2025.107030},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107030},
  shortjournal = {Comput. Oper. Res.},
  title        = {Feasible and infeasible region search for the maximally diverse grouping problem},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using machine learning to identify hidden constraints in
vehicle routing problems. <em>COR</em>, <em>179</em>, 107029. (<a
href="https://doi.org/10.1016/j.cor.2025.107029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Last-mile delivery involves a series of complex tasks in an unpredictable environment. Decision support tools based on optimization algorithms construct efficient routes for drivers, optimizing the cost of making deliveries. However, drivers often deviate from these routes due to factors not considered in the decision-making process. This discrepancy raises the question of how to identify routes that are useable in real-world scenarios. Our research proposes using modern machine learning techniques to classify routes based on their practical usability. In a controlled environment, we demonstrate that machine learning can learn hidden factors influencing route viability by focusing on variants of the vehicle routing problem with additional constraints like time window, capacity and precedence. For each underlying constraint, we show that a machine learning model can be trained to classify routes based on whether or not they violate the constraint. Using datasets generated from well-known benchmark instances, we present computational experiments to evaluate model performance. We discuss which types of constraints are more challenging to recognize and how large a dataset must be to allow for accurate classification. This research has the potential to improve existing decision tools, enabling them to generate routes that better account for real-world complexities.},
  archive      = {J_COR},
  author       = {Anna Konovalenko and Lars Magnus Hvattum and Mohamed Kais Msakni},
  doi          = {10.1016/j.cor.2025.107029},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107029},
  shortjournal = {Comput. Oper. Res.},
  title        = {Using machine learning to identify hidden constraints in vehicle routing problems},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online order acceptance and scheduling in a single machine
environment. <em>COR</em>, <em>179</em>, 107028. (<a
href="https://doi.org/10.1016/j.cor.2025.107028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the online order acceptance and scheduling (OAS) problem, a widely studied problem in its offline counterpart, where orders arrive online sequentially with associated rewards, arrival times, and due dates in a finite planning horizon. The objective is to make real-time order acceptance and scheduling decisions so as to maximize the total profit. To tackle this problem, we derive an upper bound on the competitive ratio of any online algorithm for the online OAS problem and introduce three algorithms (online greedy, online learning, and delay). For the online greedy algorithm, we provide a performance guarantee under the mild conditions via theoretical analysis. Furthermore, through computational studies we highlight that both the urgency of due dates of the orders and the workload level of the system can significantly influence the performance of the online algorithms. Since each proposed algorithm has its advantages and disadvantages, we categorize different scenarios for using the suitable algorithm, aiming at offering managerial insights for firms to make informed decisions.},
  archive      = {J_COR},
  author       = {Chunyan Zheng and Jin Yu and Guohua Wan},
  doi          = {10.1016/j.cor.2025.107028},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107028},
  shortjournal = {Comput. Oper. Res.},
  title        = {Online order acceptance and scheduling in a single machine environment},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective flexible job shop scheduling based on
feature information optimization algorithm. <em>COR</em>, <em>179</em>,
107027. (<a href="https://doi.org/10.1016/j.cor.2025.107027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective optimization methods are increasingly used in job shop scheduling optimization strategies. However, in the design process of multi-objective optimization strategies, a neighborhood search is performed on all solutions in the optimization algorithm, resulting in a time-consuming search. In the algorithm selection process, feature information carried by individuals is often ignored, leading to a lack of targeted guidance ability in the algorithm. To address the limitations of the existing methods, a multi-objective flexible job shop scheduling method based on a feature information optimization algorithm (FIOA) was proposed. First, a framework of multiple group optimization algorithms was applied to construct diverse groups. Subsequently, a representative individual selection strategy was applied to mine individual offspring information and accelerate population convergence. To balance the exploration ability and computational resources of the FIOA, multiple neighborhood search rules were used to improve the utilization rate of individual offspring. In this study, the parameter configuration of the proposed algorithm was calibrated using the Taguchi method. To evaluate the effectiveness and superiority of the FIOA, each improvement of the FIOA algorithm was evaluated. In addition, it was compared with state-of-the-art algorithms in benchmark tests, and the results showed that the FIOA outperformed the other algorithms in solving flexible job shop scheduling.},
  archive      = {J_COR},
  author       = {Zeyin Guo and Lixin Wei and Jinlu Zhang and Ziyu Hu and Hao Sun and Xin Li},
  doi          = {10.1016/j.cor.2025.107027},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107027},
  shortjournal = {Comput. Oper. Res.},
  title        = {Multi-objective flexible job shop scheduling based on feature information optimization algorithm},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidding in day-ahead electricity markets: A dynamic
programming framework. <em>COR</em>, <em>179</em>, 107024. (<a
href="https://doi.org/10.1016/j.cor.2025.107024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic bidding problems have gained a lot of attention with the introduction of deregulated electricity markets where producers and retailers trade electricity in a day-ahead market run by a Market Operator (MO). All actors propose bids composed of a unit production price and a quantity of electricity to the MO. Based on these bids, the MO selects the most interesting ones and defines the spot price of electricity at which all actors are paid. As the bids of all actors determine the price of electricity, a bidding Generation Company (GC) faces a high risk regarding its profit when placing bids as the bids of competitors are not known in advance. This paper proposes a novel dynamic programming framework for a GC’s Stochastic Bidding Problem (SBP) in the day-ahead market considering uncertainty over the competitor bids. We prove this problem is NP-hard and study two variants of this problem solved with the dynamic programming framework. Firstly, a relaxation provides an upper bound solved in polynomial time (SBP-R). Secondly, we consider a bidding problem using fixed bidding quantities (SBP-Q) that has previously been solved through heuristic methods. We prove that SBP-Q is NP-hard and solve it to optimality in pseudo-polynomial time. SBP-Q is solved on much larger instances than in previous studies. We show on realistic instances that its optimal value is typically under 1% of the optimal value of SBP by using the upper bound provided by SBP-R.},
  archive      = {J_COR},
  author       = {Jérôme De Boeck and Bernard Fortz and Martine Labbé and Étienne Marcotte and Patrice Marcotte and Gilles Savard},
  doi          = {10.1016/j.cor.2025.107024},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107024},
  shortjournal = {Comput. Oper. Res.},
  title        = {Bidding in day-ahead electricity markets: A dynamic programming framework},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The two-echelon vehicle routing problem with pickups,
deliveries, and deadlines. <em>COR</em>, <em>179</em>, 107016. (<a
href="https://doi.org/10.1016/j.cor.2025.107016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Two-Echelon Vehicle Routing Problem with Pickups, Deliveries, and Deadlines (2E-VRP-PDD), an emerging routing variant addressing the operations of logistics companies connecting consumers and suppliers in metropolitan areas. Logistics companies typically organize their logistics in such metropolitan areas via multiple geographically dispersed two-echelon distribution systems. The 2E-VRP-PDD is the practical problem that needs to be solved within each of such a single two-echelon distribution system, thereby merging first and last-mile logistics operations. Specifically, it integrates the distribution of last-mile parcels from the hub via satellites to the consumers with the collection of first-mile parcels from the suppliers via satellites that return to the hub. Moreover, it considers deadlines before first-mile parcels arrive at the hub, which must be transported further in the network. We solve the 2E-VRP-PDD with a newly developed Adaptive Large Neighborhood Search (ALNS) combined with a post-process integer programming model. Our ALNS provides high-quality solutions on established benchmark instances from the literature. On a new benchmark set for the 2E-VRP-PDD, we find that modifying time restrictions, such as parcel delivery deadlines at the city hub, can lead to an 8.27% cost increase, highlighting the overhead associated with same-day delivery compared to next-day delivery operations. Finally, by analyzing real-life instances containing up to 2150 customers obtained from our industry collaborator in Jakarta, Indonesia, we show that our ALNS can reduce the cost of operations by up to 17.54% compared to current practice.},
  archive      = {J_COR},
  author       = {M. Arya Zamal and Albert H. Schrotenboer and Tom Van Woensel},
  doi          = {10.1016/j.cor.2025.107016},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107016},
  shortjournal = {Comput. Oper. Res.},
  title        = {The two-echelon vehicle routing problem with pickups, deliveries, and deadlines},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive stochastic programming model for transfer
synchronization in transit networks. <em>COR</em>, <em>179</em>, 107015.
(<a href="https://doi.org/10.1016/j.cor.2025.107015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the stochastic transfer synchronization problem, which seeks to synchronize the timetables of different routes in a transit network to reduce transfer waiting times, delay times, and unnecessary in-vehicle times. We present a sophisticated two-stage stochastic mixed-integer programming model that takes into account variability in passenger walking times between bus stops, bus running times, dwell times, and demand uncertainty. Our model incorporates new features related to dwell time determination by considering passenger arrival patterns at bus stops which have been neglected in the literature on transfer synchronization and timetabling. We solve a sample average approximation of our model using a problem-based scenario reduction approach, and the progressive hedging algorithm. As a proof of concept, our computational experiments on instances using transfer nodes in the City of Toronto, with a mixture of low- and high-frequency routes, demonstrate the potential advantages of the proposed model. Our findings highlight the necessity and value of incorporating stochasticity in transfer-based timetabling models.},
  archive      = {J_COR},
  author       = {Zahra Ansarilari and Merve Bodur and Amer Shalaby},
  doi          = {10.1016/j.cor.2025.107015},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107015},
  shortjournal = {Comput. Oper. Res.},
  title        = {A comprehensive stochastic programming model for transfer synchronization in transit networks},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). General polyhedral approximation of two-stage robust linear
programming for budgeted uncertainty. <em>COR</em>, <em>179</em>,
107014. (<a href="https://doi.org/10.1016/j.cor.2025.107014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider two-stage robust linear programs with uncertain righthand side. We develop a General Polyhedral Approximation (GPA), in which the uncertainty set U is substituted by a finite set of polytopes derived from the vertex set of an arbitrary polytope that dominates U . The union of the polytopes need not contain U . We analyze and computationally test the performance of GPA for the frequently used budgeted uncertainty set U (with m rows). For budgeted uncertainty affine policies are known to be best possible approximations (if coefficients in the constraints are nonnegative for the second-stage decision). In practice calculating affine policies typically requires inhibitive running times. Therefore an approximation of U by a single simplex has been proposed in the literature. GPA maintains the low practical running times of the simplex based approach while improving the quality of approximation by a constant factor. The generality of our method allows to use any polytope dominating U (including the simplex). We provide a family of polytopes that allows for a trade-off between running time and approximation factor. The previous simplex based approach reaches a threshold at Γ &gt; m after which it is not better than a quasi nominal solution. Before this threshold, GPA significantly improves the approximation factor. After the threshold, it is the first fast method to outperform the quasi nominal solution. We exemplify the superiority of our method by a fundamental logistics problem, namely, the Transportation Location Problem, for which we also specifically adapt the method and show stronger results.},
  archive      = {J_COR},
  author       = {Lukas Grunau and Tim Niemann and Sebastian Stiller},
  doi          = {10.1016/j.cor.2025.107014},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107014},
  shortjournal = {Comput. Oper. Res.},
  title        = {General polyhedral approximation of two-stage robust linear programming for budgeted uncertainty},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hyper-heuristic based on surrogate genetic
programming for the three-dimensional spatial resource-constrained
project scheduling problem under uncertain environments. <em>COR</em>,
<em>179</em>, 107013. (<a
href="https://doi.org/10.1016/j.cor.2025.107013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a class of large and complex engineering projects with limited construction sites, three-dimensional (3D) spatial resources usually become a bottleneck that hinders their smooth implementation. A project schedule is easily disturbed by space conflicts and uncertain environments if these factors are not considered in advance. Firstly, we extend the traditional resource-constrained project scheduling problem (RCPSP) by considering 3D spatial resource constraints under uncertain environments, and propose a new three-dimensional spatial resource-constrained project scheduling problem with stochastic activity durations (3D-sRCPSPSAD). The activity schedule and the space allocation need to be decided simultaneously, so we design the first-fit and the best-fit strategies, and integrate them into the traditional resource-based policy to schedule activities and allocate 3D space. Secondly, a novel hyper-heuristic based on surrogate genetic programming (HH-SGP) is designed to evolve rules automatically for the 3D-sRCPSPSAD. The main goal of the surrogate model in HH-SGP is to construct an approximate model of the fitness function based on the random forest technique. Therefore, it can be used as an efficient alternative to the more expensive fitness function in the evolutionary process. More importantly, the weak elitism mechanism and other modified techniques are designed to improve the performance of HH-SGP. Thirdly, we configure the parameters of 3D spatial resources and generate numerical instances. Finally, from the aspects of solution quality and stability, we verify the efficiency, quality and convergence rate of HH-SGP under different uncertain environments. The effectiveness of the surrogate model, and the performance of the first-fit and the best-fit strategies are also analyzed through extensive numerical experiments. The results indicate that our designed HH-SGP algorithm performs better than traditional heuristics for the 3D-sRCPSPSAD, and the performance of the fitness function surrogate model in HH-SGP is generally better than without it. This study can also help project practitioners schedule activities and allocate spatial resources more effectively under various uncertain scenarios.},
  archive      = {J_COR},
  author       = {Lubo Li and Jingwen Zhang and Haohua Zhang and Roel Leus},
  doi          = {10.1016/j.cor.2025.107013},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107013},
  shortjournal = {Comput. Oper. Res.},
  title        = {A novel hyper-heuristic based on surrogate genetic programming for the three-dimensional spatial resource-constrained project scheduling problem under uncertain environments},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ship emission monitoring with a joint mode of motherships
and unmanned aerial vehicles. <em>COR</em>, <em>179</em>, 107012. (<a
href="https://doi.org/10.1016/j.cor.2025.107012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ship emission monitoring is crucial for improving compliance with emission control area (ECA) policies. To address the limitations of traditional base station-based monitoring methods, we propose a highly maneuverable mothership-based unmanned aerial vehicle (UAV) monitoring mode. We develop a mixed integer non-linear programming model to maximize the total profit (i.e., the revenues of ship emission monitoring minus the fixed costs of motherships and UAVs, the fuel cost of motherships, and the electricity cost of UAVs). Three types of integer variables are relaxed to continuous variables based on the model properties. We then design a tailored Benders decomposition algorithm to solve the model. Moreover, to improve the performance of the algorithm, we also present a variety of acceleration strategies, including lower bound limit inequalities and knapsack inequalities. Finally, we verify the effectiveness of the proposed algorithm using experimental instances based on the North American ECA. We also find a relationship between the width of emission inspection area and the total monitoring cost.},
  archive      = {J_COR},
  author       = {Dan Zhuge and Jianhui Du and Lu Zhen and Shuaian Wang and Peng Wu},
  doi          = {10.1016/j.cor.2025.107012},
  journal      = {Computers &amp; Operations Research},
  month        = {7},
  pages        = {107012},
  shortjournal = {Comput. Oper. Res.},
  title        = {Ship emission monitoring with a joint mode of motherships and unmanned aerial vehicles},
  volume       = {179},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="csda---5">CSDA - 5</h2>
<ul>
<li><details>
<summary>
(2025). Regression analysis of elliptically symmetric directional
data. <em>CSDA</em>, <em>208</em>, 108167. (<a
href="https://doi.org/10.1016/j.csda.2025.108167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A comprehensive toolkit is developed for regression analysis of directional data based on a flexible class of angular Gaussian distributions. Informative testing procedures to assess rotational symmetry around the mean direction, and the dependence of model parameters on covariates are proposed. Bootstrap-based algorithms are provided to assess the significance of the proposed test statistics. Moreover, a prediction region that achieves the smallest volume in a class of ellipsoidal prediction regions of the same coverage probability is constructed. The efficacy of these inference procedures is demonstrated in simulation experiments. Finally, this new toolkit is used to analyze directional data originating from a hydrology study and a bioinformatics application.},
  archive      = {J_CSDA},
  author       = {Zehao Yu and Xianzheng Huang},
  doi          = {10.1016/j.csda.2025.108167},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108167},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Regression analysis of elliptically symmetric directional data},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exact designs for order-of-addition experiments under a
transition-effect model. <em>CSDA</em>, <em>208</em>, 108162. (<a
href="https://doi.org/10.1016/j.csda.2025.108162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the chemical, pharmaceutical, and food industries, sometimes the order of adding a set of components has an impact on the final product. These are instances of the Order-of-Addition (OofA) problem, which aims to find the optimal sequence of the components. Extensive research on this topic has been conducted, but almost all designs are found by optimizing the D −optimality criterion. However, when prediction of the response is important, there is still a need for I −optimal designs. Furthermore, designs are needed for experiments where some orders are infeasible due to constraints. A new model for OofA experiments is presented that uses transition effects to model the effect of order on the response. Three algorithms are proposed to find D − and I −efficient exact designs under this new model: Simulated Annealing, a metaheuristic algorithm, Bubble Sorting, a greedy local optimization algorithm, and the Greedy Randomized Adaptive Search Procedure (GRASP), another metaheuristic algorithm. These three algorithms are generalized to handle block constraints, where components are grouped into blocks with a fixed order. Finally, two examples are shown to illustrate the effectiveness of the proposed designs and models, even under block constraints.},
  archive      = {J_CSDA},
  author       = {Jiayi Zheng and Nicholas Rios},
  doi          = {10.1016/j.csda.2025.108162},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108162},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Exact designs for order-of-addition experiments under a transition-effect model},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An accurate computational approach for partial likelihood
using poisson-binomial distributions. <em>CSDA</em>, <em>208</em>,
108161. (<a href="https://doi.org/10.1016/j.csda.2025.108161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Cox model, the partial likelihood, as the product of a series of conditional probabilities, is used to estimate the regression coefficients. In practice, those conditional probabilities are approximated by risk score ratios based on a continuous time model, and thus result in parameter estimates from only an approximate partial likelihood. Through a revisit to the original partial likelihood idea, an accurate partial likelihood computing method for the Cox model is proposed, which calculates the exact conditional probability using the Poisson-binomial distribution. New estimating and inference procedures are developed, and theoretical results are established for the proposed computational procedure. Although ties are common in real studies, current theories for the Cox model mostly do not consider cases for tied data. In contrast, the new approach includes the theory for grouped data, which allows ties, and also includes the theory for continuous data without ties, providing a unified framework for computing partial likelihood for data with or without ties. Numerical results show that the proposed method outperforms current methods in reducing bias and mean squared error, while achieving improved confidence interval coverage rates, especially when there are many ties or when the variability in risk scores is large. Comparisons between methods in real applications have been made.},
  archive      = {J_CSDA},
  author       = {Youngjin Cho and Yili Hong and Pang Du},
  doi          = {10.1016/j.csda.2025.108161},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108161},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {An accurate computational approach for partial likelihood using poisson-binomial distributions},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication-efficient estimation and inference for
high-dimensional longitudinal data. <em>CSDA</em>, <em>208</em>, 108154.
(<a href="https://doi.org/10.1016/j.csda.2025.108154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth in modern science and technology, distributed longitudinal data have drawn attention in a wide range of aspects. Realizing that not all effects of covariates are our parameters of interest, we focus on the distributed estimation and statistical inference of a pre-conceived low-dimensional parameter in the high-dimensional longitudinal GLMs with canonical links. To mitigate the impact of high-dimensional nuisance parameters and incorporate the within-subject correlation simultaneously, a decorrelated quadratic inference function is proposed for enhancing the estimation efficiency. Two communication-efficient surrogate decorrelated score estimators based on multi-round iterative algorithms are proposed. The error bounds and limiting distribution of the proposed estimators are established and extensive numerical experiments demonstrate the effectiveness of our method. An application to the National Longitudinal Survey of Youth Dataset is also presented.},
  archive      = {J_CSDA},
  author       = {Xing Li and Yanjing Peng and Lei Wang},
  doi          = {10.1016/j.csda.2025.108154},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108154},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Communication-efficient estimation and inference for high-dimensional longitudinal data},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Testing the constancy of the variance for time series with a
trend. <em>CSDA</em>, <em>208</em>, 108147. (<a
href="https://doi.org/10.1016/j.csda.2025.108147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assumption of constant variance is fundamental in numerous statistical procedures for time series analysis. Nonlinear time series may exhibit time-varying local conditional variance, even when they are globally homoscedastic. Two novel tests are proposed to assess the constancy of variance in time series with a possible time-varying mean trend. Unlike previous approaches, the new tests rely on Walsh transformations of squared processes after recentering the time series data. It is shown that the corresponding Walsh coefficients have desirable properties, such as asymptotic independence. Both a max-type statistic and an order selection statistic are developed, along with their asymptotic null distributions. Furthermore, the consistency of the proposed statistics under a sequence of local alternatives is established. An extensive simulation study is conducted to examine the finite-sample performance of the procedures in comparison with existing methodologies. The empirical results show that the proposed methods are more powerful in many situations while maintaining reasonable Type I error rates, especially for nonlinear time series. The proposed methods are applied to test the global homoscedasticity of a financial time series, a well log time series with a non-constant mean structure, and a vibration time series.},
  archive      = {J_CSDA},
  author       = {Lei Jin and Li Cai and Suojin Wang},
  doi          = {10.1016/j.csda.2025.108147},
  journal      = {Computational Statistics &amp; Data Analysis},
  month        = {8},
  pages        = {108147},
  shortjournal = {Comput. Stat. Data Anal.},
  title        = {Testing the constancy of the variance for time series with a trend},
  volume       = {208},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="cviu---5">CVIU - 5</h2>
<ul>
<li><details>
<summary>
(2025). Adversarial style mixup and improved temporal alignment for
cross-domain few-shot action recognition. <em>CVIU</em>, <em>255</em>,
104341. (<a href="https://doi.org/10.1016/j.cviu.2025.104341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-Domain Few-Shot Action Recognition (CDFSAR) aims at transferring knowledge from base classes to novel ones with limited labeled data, under distribution shift between base (source domain) and novel (target domain) classes. This paper addresses the issues of insufficient style coverage for the target domain and potential temporal misalignment with chronological order in existing methods. To mitigate distribution shifts across domains, we propose an Adversarial Style Mixup (ASM) module, which enriches the diversity of style distributions covering the target domain. ASM mixes up source and target domain styles through statistical means and variances, with the adversarially learned mixup ratio and style noise. On the other hand, we design an Improved Temporal Alignment (ITA) module to address the issue of temporal misalignment between videos. In the proposed ITA, keyframes are extracted as priors for better temporal alignment with a temporal mixer to reduce the misalignment noise. Extensive experiments on video action recognition datasets demonstrates the superiority of our method compared with the state of the arts for the challenging problem of CDFSAR. Ablation study validates that both the proposed ASM and ITA modules contribute to performance improvement by style distribution expansion and keyframe-based temporal alignment.},
  archive      = {J_CVIU},
  author       = {Kaiyan Cao and Jiawen Peng and Jiaxin Chen and Xinyuan Hou and Andy J. Ma},
  doi          = {10.1016/j.cviu.2025.104341},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104341},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Adversarial style mixup and improved temporal alignment for cross-domain few-shot action recognition},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Syntactically and semantically enhanced captioning network
via hybrid attention and POS tagging prompt. <em>CVIU</em>,
<em>255</em>, 104340. (<a
href="https://doi.org/10.1016/j.cviu.2025.104340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video captioning has become a thriving research area, with current methods relying on static visuals or motion information. However, videos contain a complex interplay between multiple objects with unique temporal patterns. Traditional techniques struggle to capture this intricate connection, leading to inaccurate captions due to the gap between video features and generated text. Analyzing these temporal variations and identifying relevant objects remains a challenge. This paper proposes SySCapNet, a novel deep-learning architecture for video captioning, designed to address this limitation. SySCapNet effectively captures objects involved in motions and extracts spatio-temporal action features. This information, along with visual features and motion data, guides the caption generation process. We introduce a groundbreaking hybrid attention module that leverages both visual saliency and spatio-temporal dynamics to extract highly detailed and semantically meaningful features. Furthermore, we incorporate part-of-speech tagging to guide the network in disambiguating words and understanding their grammatical roles. Extensive evaluations on benchmark datasets demonstrate that SySCapNet achieves superior performance compared to existing methods. The generated captions are not only informative but also grammatically correct and rich in context, surpassing the limitations of basic AI descriptions.},
  archive      = {J_CVIU},
  author       = {Deepali Verma and Tanima Dutta},
  doi          = {10.1016/j.cviu.2025.104340},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104340},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Syntactically and semantically enhanced captioning network via hybrid attention and POS tagging prompt},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FrTrGAN: Single image dehazing using the frequency component
of transmission maps in the generative adversarial network.
<em>CVIU</em>, <em>255</em>, 104336. (<a
href="https://doi.org/10.1016/j.cviu.2025.104336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hazy images, particularly in outdoor scenes, have reduced visibility due to atmospheric particles, making image dehazing a critical task for enhancing visual clarity. The main challenges in image dehazing involve accurately detecting and removing haze while preserving fine details and maintaining overall image quality. Many existing dehazing methods struggle with varying haze conditions, often compromising the structural and perceptual integrity of the restored images. In this paper, we introduce FrTrGAN, a framework for single-image dehazing that leverages the frequency components of transmission maps. This novel framework addresses these challenges by integrating the Fourier Transform within an enhanced CycleGAN architecture. Unlike traditional spatial-domain dehazing methods, FrTrGAN operates in the frequency domain, where it isolates low-frequency haze components – responsible for blurring fine details – and removes them more precisely. The Inverse Fourier Transform is then applied to map the refined data back to the spatial domain, ensuring that the resulting images maintain clarity, sharpness, and structural integrity. We evaluate our method on multiple datasets, including HSTS, SOTS Outdoor, O-Haze, I-Haze, D-Hazy, BeDDE and Dense-Haze using PSNR and SSIM for quantitative performance assessment. Additionally, we include results based on non-referential metrics such as FADE, SSEQ, BRISQUE and NIQE to further evaluate the perceptual quality of the dehazed images. The results demonstrate that FrTrGAN significantly outperforms existing methods while effectively restoring both frequency components and perceptual image quality. This comprehensive evaluation highlights the robustness of FrTrGAN in diverse haze conditions and underscores the effectiveness of a frequency-domain approach to image dehazing, laying the groundwork for future advancements in the field.},
  archive      = {J_CVIU},
  author       = {Pulkit Dwivedi and Soumendu Chakraborty},
  doi          = {10.1016/j.cviu.2025.104336},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104336},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {FrTrGAN: Single image dehazing using the frequency component of transmission maps in the generative adversarial network},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hexagonal mesh-based neural rendering for real-time
rendering and fast reconstruction. <em>CVIU</em>, <em>255</em>, 104335.
(<a href="https://doi.org/10.1016/j.cviu.2025.104335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although recent neural rendering-based methods can achieve high-quality geometry and realistic rendering results in multi-view reconstruction, they incur a heavy computational burden on rendering and training, which limits their application scenarios. To address these challenges, we propose an effective mesh-based neural rendering approach which leverages the characteristic of meshes being able to achieve real-time rendering. Besides, a coarse-to-fine scheme is introduced to efficiently extract the initial mesh so as to significantly reduce the reconstruction time. More importantly, we suggest a hexagonal mesh model to preserve surface regularity by constraining the second-order derivatives of its vertices, where only low level of positional encoding is engaged for neural rendering. Experiments show that our approach significantly reduces the rendering time from several tens of seconds to 0.05s compared to methods based on implicit representation. And it can quickly achieve state-of-the-art results in novel view synthesis and reconstruction. Our full implementation will be made publicly available at https://github.com/FuchengSu/FastMesh .},
  archive      = {J_CVIU},
  author       = {Yisu Zhang and Jianke Zhu and Lixiang Lin},
  doi          = {10.1016/j.cviu.2025.104335},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104335},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Hexagonal mesh-based neural rendering for real-time rendering and fast reconstruction},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic anchor: Density map guided small object detector for
tiny persons. <em>CVIU</em>, <em>255</em>, 104325. (<a
href="https://doi.org/10.1016/j.cviu.2025.104325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the application of aerial and space-based equipments, such as drones in the search and rescue process, there is an increasing demand on the detection of small and even tiny human targets. However, most existing detectors rely on generating smaller and denser anchors for small target detection, which introduces a high number of redundant negative anchor samples. To alleviate this issue, we propose a novel density map-guided tiny person detector with dynamic anchor. Specifically, we elaborately design an Anchor Proposals Mask (APM) module to effectively eliminate negative anchor samples and adaptively adjust anchor distribution with the guidance of density maps produced by Density Map Generator (DMG). To promote the quality of the density map, we develop a Multi-Scale Feature Distillation (MSFD) module and incorporate the Focal Inverse Distance Transform (FIDT) map to conduct knowledge distillation for DMG with the assistance of the crowd counting network. Extensive experiments on the TinyPerson and VisDrone datasets demonstrate that our method significantly enhances the performance of two-stage detectors in terms of average precision (AP) and average recall (AR) while effectively reducing the impact of negative anchor boxes.},
  archive      = {J_CVIU},
  author       = {Xingzhou Xu and Zhaoyong Mao and Xin Wang and Qinhao Tu and Junge Shen},
  doi          = {10.1016/j.cviu.2025.104325},
  journal      = {Computer Vision and Image Understanding},
  month        = {4},
  pages        = {104325},
  shortjournal = {Comput. Vis. Image Understanding},
  title        = {Dynamic anchor: Density map guided small object detector for tiny persons},
  volume       = {255},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="dke---10">DKE - 10</h2>
<ul>
<li><details>
<summary>
(2025). An MDA approach for robotic-based real-time business
intelligence applications. <em>DKE</em>, <em>157</em>, 102418. (<a
href="https://doi.org/10.1016/j.datak.2025.102418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industry 4.0, the fourth industrial revolution, has emerged from the convergence of robotics, automation, and the Internet of Things (IoT), transforming industrial processes with intelligent systems and digital integration. This revolution also brings with it Business Intelligence (BI) systems that enable the analysis of IoT and robotic data. The data architectures employed for BI in Industry 4.0 contexts are often intricate, typically comprising robots software, DBMSs, message brokers, and data stream management systems. Consequently, designing BI data-centric applications for Industry 4.0 presents a significant challenge. Inspired by the absence of modeling approaches for this type of application and by the well-established advantages of Model-Driven Architecture (MDA), this paper introduces a novel UML profile for real-time robotic data-driven BI applications. Our profile enables the representation of robotic and transactional data within a unified and consistent framework, enabling continuous queries over these streams. Additionally, we propose an automated method to implement UML class diagrams onto a technological stack featuring ROS, Apache Kafka, PostgreSQL, and Apache Flink. An experimental evaluation in the agricultural application domain confirms the merits of our approach.},
  archive      = {J_DKE},
  author       = {Houssam Bazza and Sandro Bimonte and Zakaria Gourti and Stefano Rizzi and Hassan Badir},
  doi          = {10.1016/j.datak.2025.102418},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102418},
  shortjournal = {Data Knowl. Eng.},
  title        = {An MDA approach for robotic-based real-time business intelligence applications},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-level recommendation fused with review and rating
representations. <em>DKE</em>, <em>157</em>, 102417. (<a
href="https://doi.org/10.1016/j.datak.2025.102417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Review contains user opinions about different aspects of an item, which is essential data for aspect-level recommendation. Most existing aspect-level recommendation algorithms are concerned with the degree to which user and item aspects match. However, even if an item is extremely popular due to its high quality, it may only partially match the aspects of a user. A tolerant user may like the item, whereas a strict user may dislike it. This implies that these works disregard the personalized behavior patterns of the user. In this paper, we propose a new A spect-level R ecommendation model fused with R eview and R ating, namely ARRR , to address the recommendation bias. First, we introduce rating to explore user behavior patterns and item quality. Then, we present a personalized attention mechanism that generates a set of aspect-level user or item representations from reviews. Finally, we obtain comprehensive user or item representations by combining rating- and review-based representations. In the experiments, the proposed model is compared with seven state-of-the-art recommendation algorithms on seven datasets. The results show that our model outperforms on seven metrics. The source code of ARRR is available at https://github.com/alinn00/ARRR .},
  archive      = {J_DKE},
  author       = {Heng-Ru Zhang and Ling Lin and Fan Min},
  doi          = {10.1016/j.datak.2025.102417},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102417},
  shortjournal = {Data Knowl. Eng.},
  title        = {Aspect-level recommendation fused with review and rating representations},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). How well can a large language model explain business
processes as perceived by users? <em>DKE</em>, <em>157</em>, 102416. (<a
href="https://doi.org/10.1016/j.datak.2025.102416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs) are trained on a vast amount of text to interpret and generate human-like textual content. They are becoming a vital vehicle in realizing the vision of the autonomous enterprise, with organizations today actively adopting LLMs to automate many aspects of their operations. LLMs are likely to play a prominent role in future AI-augmented business process management systems (ABPMSs) catering functionalities across all system lifecycle stages. One such system’s functionality is Situation-Aware eXplainability (SAX), which relates to generating causally sound and yet human-interpretable explanations that take into account the process context in which the explained condition occurred. In this paper, we present the SAX4BPM framework developed to generate SAX explanations. The SAX4BPM suite consists of a set of services and a central knowledge repository. The functionality of these services is to elicit the various knowledge ingredients that underlie SAX explanations. A key innovative component among these ingredients is the causal process execution view. In this work, we integrate the framework with an LLM to leverage its power to synthesize the various input ingredients for the sake of improved SAX explanations. Since the use of LLMs for SAX is also accompanied by a certain degree of doubt related to its capacity to adequately fulfill SAX along with its tendency for hallucination and lack of inherent capacity to reason, we pursued a methodological evaluation of the perceived quality of the generated explanations. To this aim, we developed a designated scale and conducted a rigorous user study. Our findings show that the input presented to the LLMs aided with the guard-railing of its performance, yielding SAX explanations having better-perceived fidelity. This improvement is moderated by the perception of trust and curiosity. More so, this improvement comes at the cost of the perceived interpretability of the explanation.},
  archive      = {J_DKE},
  author       = {Dirk Fahland and Fabiana Fournier and Lior Limonad and Inna Skarbovsky and Ava J.E. Swevels},
  doi          = {10.1016/j.datak.2025.102416},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102416},
  shortjournal = {Data Knowl. Eng.},
  title        = {How well can a large language model explain business processes as perceived by users?},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modelling and solving industrial production tasks as
planning-scheduling tasks. <em>DKE</em>, <em>157</em>, 102415. (<a
href="https://doi.org/10.1016/j.datak.2025.102415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial production planning or manufacturing concerns the selection of activities that can produce a desired product and scheduling them on resources that perform these activities. To deal with such problems techniques in the fields of Automated Planning and Scheduling might be leveraged, which are usually pursued separately even though they are (very) complementary. In manufacturing, the activities represent elementary steps in the production and each activity requires a specific input in order to produce a desired output. From that perspective, activities resemble actions in planning as they can capture such a requirement. Selecting proper activities including their (partial) ordering can be understood as a planning task while allocating the activities to the resources can be understood as a scheduling task. This paper formalises the concept of “combined” planning and scheduling tasks by defining planning-scheduling tasks that are suitable for problems concerning industrial production or manufacturing. In particular, we define two types of activities – production and maintenance activities – where the former describes elementary production tasks while the latter modifies attributes of the resources (e.g. changing the configuration of reconfigurable machines). We introduce an extension of Planning Domain Definition Language (PDDL), a well-known language for describing planning tasks, to support modelling of planning-scheduling tasks. To tackle planning-scheduling tasks we propose two compilation schemes, one into temporal planning (in PDDL 2.1) and one into classical planning. We evaluated our approaches in three use cases of industrial production planning — Reconfigurable Machines, Woodworking, and Tube Factory domains. The results showed that solving planning-scheduling tasks by compiling them into planning tasks in order to use off-the-shelf planning engines is suitable as it scales reasonably well with the size of the actual tasks (although the resulting solutions are suboptimal).},
  archive      = {J_DKE},
  author       = {Andrii Nyporko and Lukáš Chrpa},
  doi          = {10.1016/j.datak.2025.102415},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102415},
  shortjournal = {Data Knowl. Eng.},
  title        = {Modelling and solving industrial production tasks as planning-scheduling tasks},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating diabetes dataset for knowledge graph embedding
based link prediction. <em>DKE</em>, <em>157</em>, 102414. (<a
href="https://doi.org/10.1016/j.datak.2025.102414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For doing any accurate analysis or prediction on data, a complete and well-populated dataset is required. Medical based data for any disease like diabetes is highly coupled and heterogeneous in nature, with numerous interconnections. This inherently complex data cannot be analysed by simple relational databases making knowledge graphs an ideal tool for its representation which can efficiently handle intricate relationships. Thus, knowledge graphs can be leveraged to analyse diabetes data, enhancing both the accuracy and efficiency of data-driven decision-making processes. Although substantial data exists on diabetes in various formats, the availability of organized and complete datasets is limited, highlighting the critical need for creation of a well-populated knowledge graph. Moreover while developing the knowledge graph, an inevitable problem of incompleteness is present due to missing links or relationships, necessitating the use of knowledge graph completion tasks to fill in this absent information which involves predicting missing data with various Link Prediction (LP) techniques. Among various link prediction methods, approaches based on knowledge graph embeddings have demonstrated superior performance and effectiveness. These knowledge graphs can support in-depth analysis and enhance the prediction of diabetes-associated risks in this field. This paper introduces a dataset specifically designed for performing link prediction on a diabetes knowledge graph, so that it can be used to fill the information gaps further contributing in the domain of risk analysis in diabetes. The accuracy of the dataset is assessed through validation with state-of-the-art embedding-based link prediction methods.},
  archive      = {J_DKE},
  author       = {Sushmita Singh and Manvi Siwach},
  doi          = {10.1016/j.datak.2025.102414},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102414},
  shortjournal = {Data Knowl. Eng.},
  title        = {Evaluating diabetes dataset for knowledge graph embedding based link prediction},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Static and dynamic techniques for iterative test-driven
modelling of dynamic condition response graphs. <em>DKE</em>,
<em>157</em>, 102413. (<a
href="https://doi.org/10.1016/j.datak.2025.102413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Test-driven declarative process modelling combines process models with test traces and has been introduced as a means to achieve both the flexibility provided by the declarative approach and the comprehensibility of the imperative approach. Open test-driven modelling adds a notion of context to tests, specifying the activities of concern in the model, and has been introduced as a means to support both iterative test-driven modelling, where the model can be extended without having to change all tests, and unit testing, where tests can define desired properties of parts of the process without needing to reason about the details of the whole process. The openness however makes checking a test more demanding, since actions outside the context are allowed at any point in the test execution and therefore many different traces may validate or invalidate an open test. In this paper we combine previously developed static techniques for effective open test-driven modelling for Dynamic Condition Response Graphs with a novel efficient implementation of dynamic checking of open tests based on alignment checking. We illustrate the static techniques on an example based on a real-life cross-organizational case management system and benchmark the dynamic checking on models and tests of varying size.},
  archive      = {J_DKE},
  author       = {Axel K.F. Christfort and Vlad Paul Cosma and Søren Debois and Thomas T. Hildebrandt and Tijs Slaats},
  doi          = {10.1016/j.datak.2025.102413},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102413},
  shortjournal = {Data Knowl. Eng.},
  title        = {Static and dynamic techniques for iterative test-driven modelling of dynamic condition response graphs},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning for optimizing responses in care
processes. <em>DKE</em>, <em>157</em>, 102412. (<a
href="https://doi.org/10.1016/j.datak.2025.102412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prescriptive process monitoring aims to derive recommendations for optimizing complex processes. While previous studies have successfully used reinforcement learning techniques to derive actionable policies in business processes, care processes present unique challenges due to their dynamic and multifaceted nature. For example, at any stage of a care process, a multitude of actions is possible. In this study, we follow the Reinforcement Learning (RL) approach and present a general approach that uses event data to build and train Markov decision processes. We proposed three algorithms including one that takes the elapsed time into account when transforming an event log into a semi-Markov decision process. We evaluated the RL approach using an aggression incident data set. Specifically, the goal is to optimize staff member actions when clients are displaying different types of aggressive behavior. The Q-learning and SARSA are used to find optimal policies. Our results showed that the derived policies align closely with current practices while offering alternative options in specific situations. By employing RL in the context of care processes, we contribute to the ongoing efforts to enhance decision-making and efficiency in dynamic and complex environments.},
  archive      = {J_DKE},
  author       = {Olusanmi A. Hundogan and Bart J. Verhoef and Patrick Theeven and Hajo A. Reijers and Xixi Lu},
  doi          = {10.1016/j.datak.2025.102412},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102412},
  shortjournal = {Data Knowl. Eng.},
  title        = {Reinforcement learning for optimizing responses in care processes},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symmetric non negative matrices factorization applied to the
detection of communities in graphs and forensic image analysis.
<em>DKE</em>, <em>157</em>, 102411. (<a
href="https://doi.org/10.1016/j.datak.2025.102411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the proliferation of data, particularly on social networks, the accuracy of the information becomes uncertain. In this context, a major challenge lies in detecting image manipulations, where alterations are made to deceive observers. Aligning with the anomaly detection issue, recent methods approach the detection of image transformations as a community detection problem within graphs associated with the images. In this study, we propose using a community clustering method based on non-negative symmetric matrix factorization. By examining several experiments detecting alterations in manipulated images, we assess the method’s robustness and discuss potential enhancements. We also present a process for automatically generating visually and semantically coherent forged images. Additionally, we provide a web application to demonstrate this process.},
  archive      = {J_DKE},
  author       = {Gaël Marec and Nédra Mellouli},
  doi          = {10.1016/j.datak.2025.102411},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102411},
  shortjournal = {Data Knowl. Eng.},
  title        = {Symmetric non negative matrices factorization applied to the detection of communities in graphs and forensic image analysis},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REDIRE: Extreme REduction DImension for extRactivE
summarization. <em>DKE</em>, <em>157</em>, 102407. (<a
href="https://doi.org/10.1016/j.datak.2025.102407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an automatic unsupervised summarization model capable of extracting the most important sentences from a corpus. The unsupervised aspect makes it possible to do away with large corpora, made up of documents and their reference summaries, and to directly process documents potentially made up of several thousand words. To extract sentences in a summary, we use pre-entrained word embeddings to represent the documents. From this thick cloud of word vectors, we apply an extreme dimension reduction to identify important words, which we group by proximity. Sentences are extracted using linear constraint solving to maximize the information present in the summary. We evaluate the approach on large documents and present very encouraging initial results.},
  archive      = {J_DKE},
  author       = {Christophe Rodrigues and Marius Ortega and Aurélien Bossard and Nédra Mellouli},
  doi          = {10.1016/j.datak.2025.102407},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102407},
  shortjournal = {Data Knowl. Eng.},
  title        = {REDIRE: Extreme REduction DImension for extRactivE summarization},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Logic-infused knowledge graph QA: Enhancing large language
models for specialized domains through prolog integration. <em>DKE</em>,
<em>157</em>, 102406. (<a
href="https://doi.org/10.1016/j.datak.2025.102406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficiently answering questions over complex, domain-specific knowledge graphs remain a substantial challenge, as large language models (LLMs) often lack the logical reasoning abilities and particular knowledge required for such tasks. This paper presents a novel framework integrating LLMs with logical programming languages like Prolog for Logic-Infused Knowledge Graph Question Answering (KGQA) in specialized domains. The proposed methodology uses a transformer-based encoder–decoder architecture. An encoder reads the question, and a named entity recognition (NER) module connects entities to the knowledge graph. The extracted entities are fed into a grammar-guided decoder, producing a logical form (Prolog query) that captures the semantic constraints and relationships. The Prolog query is executed over the knowledge graph to perform symbolic reasoning and retrieve relevant answer entities. Comprehensive experiments on the MetaQA benchmark dataset demonstrate the superior performance of this logic-infused method in accurately identifying correct answer entities from the knowledge graph. Even when trained on a limited subset of annotated data, it outperforms state-of-the-art baselines, achieving 89.60 % and F1-scores of up to 89.61 %, showcasing its effectiveness in enhancing large language models with symbolic reasoning capabilities for specialized question-answering tasks. The seamless integration of LLMs and logical programming enables the proposed framework to reason effectively over complex, domain-specific knowledge graphs, overcoming a key limitation of existing KGQA systems. In specialized domains, the interpretability provided by representing questions such as Prologue queries is a valuable asset.},
  archive      = {J_DKE},
  author       = {Aneesa Bashir and Rong Peng and Yongchang Ding},
  doi          = {10.1016/j.datak.2025.102406},
  journal      = {Data &amp; Knowledge Engineering},
  month        = {5},
  pages        = {102406},
  shortjournal = {Data Knowl. Eng.},
  title        = {Logic-infused knowledge graph QA: Enhancing large language models for specialized domains through prolog integration},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="dss---14">DSS - 14</h2>
<ul>
<li><details>
<summary>
(2025). Are helpful reviews indeed helpful? Analyzing the
information and economic value of contextual cues in user-generated
images. <em>DSS</em>, <em>191</em>, 114426. (<a
href="https://doi.org/10.1016/j.dss.2025.114426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When shopping online, customers may find user-generated images (UGIs) where existing buyers share their product experiences in an actual setting. Drawing on the constructivist theory of visual perception, we propose a cognitive inference process in which shoppers utilize the background objects in UGIs that contextualize a product (e.g., a snow-covered mountain implying cold weather) to infer its features (e.g., the warmth of a jacket). As a result, the contextual cues in UGIs play a critical role in facilitating future buyers&#39; purchase decision-making. Our empirical probes using data from an online outdoor gear and clothing retailer confirm this conjecture by demonstrating that product contextualization in UGIs increases a review&#39;s perceived helpfulness and improves sales. By contrast, the contextual cues in the review text only assist buyers&#39; purchase decision process when they contextualize product functionality (e.g., the windproof of a coat). Yet, they do not work for aesthetic attributes (e.g., the color of a coat). We leverage an experiment to explore the relevant mechanism. In the sales analysis, we reveal that not all image content considered helpful would positively affect sales. For example, after we account for the contextual cues in the UGI, the mere presence of an image in product reviews does not affect sales. On the other hand, although illustrating product malfunction in a UGI does not increase its helpfulness, such content hurts sales. We offer managerial implications based on the empirical findings for review platforms that aim to assist online shoppers in making informed purchases.},
  archive      = {J_DSS},
  author       = {Youngeui Kim and Yang Wang},
  doi          = {10.1016/j.dss.2025.114426},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114426},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Are helpful reviews indeed helpful? analyzing the information and economic value of contextual cues in user-generated images},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing the costs and benefits of resilience-based
decision making. <em>DSS</em>, <em>191</em>, 114425. (<a
href="https://doi.org/10.1016/j.dss.2025.114425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most decision models of system resilience use static, deterministic optimization techniques while focusing on resilience assessment. At present, we lack appropriate decision support methodologies and computational tools that can offer dynamic control of resilience and balance the costs of resilience assurance. This paper presents a stochastic dynamic optimization model, based on an infinite horizon Continuous-Time Markov Decision Process, to balance the intervention costs and reduce the total recovery time ensuing a disruption of a social-physical system. We aim to offer a model that can facilitate its application to different disruption scenarios. Our state-space formulation of the recovery process uses discrete performance intervals, whereby actions and resulting rewards/costs are related to investment resources, which govern state transitions. We illustrate the model via a case study based on the 2010 Northern Colombia Dique Canal breach. Our results show that the optimal policy reduced the recovery time and restoration investment by approximately 40% and 10%, respectively, when compared to the efficiency of the government interventions. The proposed model features dynamic control of recovery resources and considers the costs of resilience assurance. The model can inform policymakers of ways to improve system resilience using balanced disruption recovery strategies.},
  archive      = {J_DSS},
  author       = {Weimar Ardila-Rueda and Alex Savachkin and Daniel Romero-Rodriguez and Jose Navarro},
  doi          = {10.1016/j.dss.2025.114425},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114425},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Balancing the costs and benefits of resilience-based decision making},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is ambiguity always adverse? Empirical evidence from the
wireless emergency alerts during the pandemic. <em>DSS</em>,
<em>191</em>, 114424. (<a
href="https://doi.org/10.1016/j.dss.2025.114424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless emergency alerts (WEAs) have become a crucial information system to notify residents of potential hazards in their vicinity. Using a large transaction dataset, we investigate (1) how WEAs influence offline and online transactions as a proxy to public mobility, and (2) how different types of information in WEAs affect transactions. Our results indicate that WEAs that only notify the occurrence of confirmed cases can significantly reduce public mobility compared to those that provide information on the exact movement of the patient. Further analysis suggests that the treatment effects of such WEAs are more pronounced in high-income areas.},
  archive      = {J_DSS},
  author       = {Jaeho Myeong and Yongjin Park and Jae-Hyeon Ahn},
  doi          = {10.1016/j.dss.2025.114424},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114424},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Is ambiguity always adverse? empirical evidence from the wireless emergency alerts during the pandemic},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metaverse technology in sustainable supply chain management:
Experimental findings. <em>DSS</em>, <em>191</em>, 114423. (<a
href="https://doi.org/10.1016/j.dss.2025.114423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The metaverse is a transformative force in supply chain information systems, particularly in the context of decision-making processes focusing on sustainable development goals. Thus, this study examines: How does the metaverse among stakeholders contribute to the supply chain decision-making processes regarding sustainable development goals ? This study is among the first to provide empirical data examining the impact of the metaverse on stakeholders&#39; sustainability assessment. Additionally, we examine how the metaverse influences supply chain collaboration and logistics decisions efficiency, particularly concerning their significant environmental implications. Through the lens of the practice-based theory, we test the proposed relationships using empirical data collected through a scenario-based survey. Furthermore, we analyzed tweets containing the keywords “metaverse” and “supply chain” to identify related topics and sentiments regarding the metaverse. The text mining analysis revealed three primary topics: logistics, digitalization, and sustainability. Results from the sentiment analysis indicated a predominantly positive attitude towards the metaverse within supply chains.},
  archive      = {J_DSS},
  author       = {Kiarash Sadeghi R. and Divesh Ojha and Puneet Kaur and Raj V. Mahto and Amandeep Dhir},
  doi          = {10.1016/j.dss.2025.114423},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114423},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Metaverse technology in sustainable supply chain management: Experimental findings},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the impact of free live-streamed medical
consultation on patient engagement and patient satisfaction in the
multistage online consultation process: A quasi-experimental design.
<em>DSS</em>, <em>191</em>, 114422. (<a
href="https://doi.org/10.1016/j.dss.2025.114422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many online healthcare communities (OHCs) in China introduced the feature of free live-streamed medical consultations (FLSMC), which allows patients to communicate with physicians and have an interactive consultation for free through live streaming. Despite the rapid growth of FLSMC, little is known about whether FLSMC can bring benefits to patients when they have online consultation needs in the future. Drawing on signaling theory, this study examines the impact of FLSMC on patient engagement and patient satisfaction in the multistage online consultation process. We further explore the moderating effects of physician&#39;s owned and earned signals in the pre-consultation stage by integrating social capital theory with signaling theory. We collect a panel data set of 16,151 physicians from a leading OHC in China. Based on the DID method, a quasi-experimental design, and the instrumental variable method, we demonstrate that FLSMC has a positive effect on patient choice, patient messaging, and patient satisfaction. In addition, we find that the physician&#39;s title and online rating can positively moderate the effects of FLSMC on patient choice. This study not only sheds light on the literature on online healthcare by identifying the role of signals in the context of FLSMC, but also provides decision support for patients, physicians, and OHC managers.},
  archive      = {J_DSS},
  author       = {Haochen Song and Xitong Guo and Tianshi Wu},
  doi          = {10.1016/j.dss.2025.114422},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114422},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Exploring the impact of free live-streamed medical consultation on patient engagement and patient satisfaction in the multistage online consultation process: A quasi-experimental design},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DECEN: A deep learning model enhanced by depressive emotions
for depression detection from social media content. <em>DSS</em>,
<em>191</em>, 114421. (<a
href="https://doi.org/10.1016/j.dss.2025.114421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depression is a serious and recurrent mental illness that significantly affects an individual&#39;s life and the society as a whole. Automatic detection of depression is crucial for early intervention and minimizing negative consequences. Existing studies on building deep learning models for automated depression detection have mainly used post-level emotion polarity (i.e., positive and negative emotions) and word embeddings as predictive features. Few have considered depressive emotions (e.g., anhedonia) expressed in those posts, despite that depressive emotions are essential to clinical depression diagnosis. Moreover, existing approaches for depression detection often ignore the relationship between emotions and their context. This study proposes a Depressive Emotion-Context Enhanced Network (DECEN) that consists of a pre-trained depressive emotion recognition module and an emotion-context enhanced representation module to address those limitations. DECEN first integrates semantic and syntactic structure representations of textual content of social media posts to identify depressive emotions conveyed through terms either explicitly or implicitly, rather than general emotion words. Furthermore, we propose an emotion-context enhanced representation method to enhance the role of the context of depressive emotions in depression detection. The evaluation using real social media data demonstrates that DECEN outperforms the state-of-the-art models in depression detection. The results of an ablation experiment also reveal that the proposed depressive emotion recognition and emotion-context enhanced representation modules, the two novel design artifacts, improve model performance. This study contributes to depression diagnostic decisions by introducing a novel method and providing new technical and practical insights for detecting depression from social media content.},
  archive      = {J_DSS},
  author       = {Zhijun Yan and Fei Peng and Dongsong Zhang},
  doi          = {10.1016/j.dss.2025.114421},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114421},
  shortjournal = {Decis. Supp. Syst.},
  title        = {DECEN: A deep learning model enhanced by depressive emotions for depression detection from social media content},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding physicians’ noncompliance use of AI-aided
diagnosis—a mixed-methods approach. <em>DSS</em>, <em>191</em>, 114420.
(<a href="https://doi.org/10.1016/j.dss.2025.114420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the pervasiveness of artificial intelligence (AI) technologies in the healthcare industry, physicians are reluctant to follow the recommendations suggested by AI-aided diagnostic systems. We conceptualize physicians&#39; noncompliance use of AI-aided diagnostic systems and draw on the technology threat avoidance theory (TTAT) to investigate the phenomenon of interest. Specifically, we leverage a mixed-methods approach to develop and test a comprehensive research model of physicians&#39; noncompliance use of AI under the overarching theory of TTAT. With an exploratory qualitative study by interviewing ten physicians with experience in using AI-aided diagnostic systems, we observe that (1) physicians experience two distinct types of threats imposed by AI, namely AI threats to diagnostic process and outcome, (2) physicians&#39; resistance to AI-aided diagnostic systems is the underlying psychological mechanism that turns their AI threat perceptions into noncompliance usage behavior, and (3) physicians&#39; professional capital serves as an essential boundary condition in understanding the impacts of AI threats on resistance. In a confirmatory quantitative survey with 160 physicians, we find that (1) both AI threats to diagnostic process and outcome arouse physicians&#39; psychological resistance, (2) such resistance to AI-aided diagnosis leads to noncompliance usage behavior, (3) noncompliance use of AI-aided diagnosis decreases physicians&#39; diagnostic performance enhanced by AI, and (4) physicians&#39; professional capital weakens the positive impact of AI threat to diagnostic process on resistance, but strengthens the positive impact of AI threat to diagnostic outcome on resistance. Our research advances the understanding of post-adoption noncompliance use of AI technology and enriches TTAT in health AI use. Our empirical findings offer practical suggestions for implementing and managing AI technology in the healthcare industry.},
  archive      = {J_DSS},
  author       = {Jiaoyang Li and Xixi Li and Cheng Zhang},
  doi          = {10.1016/j.dss.2025.114420},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114420},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Understanding physicians&#39; noncompliance use of AI-aided diagnosis—A mixed-methods approach},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Is seeing the same as doing? An evaluation of vicarious
experiences in the metaverse. <em>DSS</em>, <em>191</em>, 114419. (<a
href="https://doi.org/10.1016/j.dss.2025.114419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent explosion of vicarious experiences in the metaverse (e.g. twitch, YouTube gaming, Facebook gaming, etc.), understanding the underlying mechanism of this phenomenon is key for researchers and practitioners. This research examines the rising phenomenon of vicarious experiences within the metaverse. Using a three-study experimental approach, results show that subjects attain equal levels of embodied social presence (ESP) whether passively viewing or actively engaging with the metaverse. Since embodied social presence is a combination of activity theory and social presence, theory would suggest it cannot occur in purely vicarious experiences that do not involve direct engagement; however, our findings contradict both theory and previous research. Given these findings, we suggest users seek vicarious experiences not just to experience content they enjoy, but to have perceptually similar experiences as those actively participating in the metaverse.},
  archive      = {J_DSS},
  author       = {Caleb Krieger and Andy Luse and Ghazal Abdolhossein Khani and Rathindra Sarathy},
  doi          = {10.1016/j.dss.2025.114419},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114419},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Is seeing the same as doing? an evaluation of vicarious experiences in the metaverse},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning–based method to predict the length of stay
for patients with traumatic fall injuries in support of physicians’
clinical decisions and patient management. <em>DSS</em>, <em>191</em>,
114411. (<a href="https://doi.org/10.1016/j.dss.2025.114411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimates of the length of stay (LOS) for patients who suffer traumatic fall injuries are crucial to inform physicians&#39; clinical decisions and patient management. They also have important implications for resource utilization efficiency and cost containment efforts by healthcare organizations. Effective predictions should consider essential relationships across different variables pertaining to patient demographics, clinical history, injury severity, and physiology. A proposed deep learning–based method incorporates these relationships and can predict LOS more accurately, as demonstrated by a comparative evaluation involving 3722 patients who suffered traumatic fall injuries between 2011 and 2017. The results show the superior performance of the proposed method, relative to eleven prevalent methods that represent different analytics approaches. Our method demonstrates superior predictive performance, as manifested by the highest F-measure values and area under the curve. It is particularly efficacious for patients likely in need of longer LOS, which is relatively more important to physicians and healthcare organizations. This study underscores the value of incorporating important relationships and interactions among distinct patient variables to estimate LOS, with a particular emphasis on the inter-disease relationships, physiology-severity interactions, and patient information in clinical notes. The proposed method can be implemented as a decision support system to enhance physicians&#39; clinical decisions and patient management, and improve healthcare organizations&#39; resource planning and utilization efficiency, with nontrivial cost containment implications.},
  archive      = {J_DSS},
  author       = {Jiaxuan Peng and Da Xu and Paul Jen-Hwa Hu and Jessica Qiuhua Sheng and Ting-Shuo Huang},
  doi          = {10.1016/j.dss.2025.114411},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114411},
  shortjournal = {Decis. Supp. Syst.},
  title        = {A deep learning–based method to predict the length of stay for patients with traumatic fall injuries in support of physicians&#39; clinical decisions and patient management},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contending with coronaries: May HIT be with you.
<em>DSS</em>, <em>191</em>, 114410. (<a
href="https://doi.org/10.1016/j.dss.2025.114410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Health Information Technology (HIT) is revolutionizing healthcare by serving as the backbone for various decision support activities across the healthcare continuum, particularly within hospital settings. While existing literature highlights its positive impact on patient satisfaction, costs, and quality, its role in complementing other crucial hospital inputs to influence clinical healthcare outcomes has been relatively understudied. In this study, we explore the complementary effects of a specific type of HIT, Clinical Decision Support Systems (CDSS) on cardiac mortality rates (CMR) in hospitals. Though hospital personnel and cardiac medical services (CMS) are pivotal in reducing CMR, CDSS plays a complementary role by providing information and decision support throughout the cardiac care delivery process. Leveraging panel data spanning from 2016 to 2020, our analysis reveals that CDSS complements CMS and hospital personnel in mitigating CMR. These findings provide theoretical insights into the benefits facilitated by CDSS in cardiac care and hold managerial implications for the effective deployment of this technology within hospital settings. Through our analysis, we aim to elucidate the synergistic effects of CDSS, cardiac medical services, and healthcare personnel in improving clinical healthcare outcomes, particularly in the management of cardiac disease.},
  archive      = {J_DSS},
  author       = {Nirup Menon and Amitava Dutta and Sidhartha Das},
  doi          = {10.1016/j.dss.2025.114410},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114410},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Contending with coronaries: May HIT be with you},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Should a better-informed manufacturer hold pricing power for
the direct channel: The role of consumer reviews. <em>DSS</em>,
<em>191</em>, 114408. (<a
href="https://doi.org/10.1016/j.dss.2025.114408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Manufacturers can effectively obtain precise demand information through the utilization of data analysis technologies. These better-informed manufacturers commonly distribute their products not only through traditional offline retailers but also via direct sales channels. In this context, distinct pricing strategies for online channels, namely holding pricing power and giving up pricing power, can be observed in practice. Furthermore, these online channels also enable consumers to post consumer reviews, which significantly impacts consumers’ purchasing decisions. By applying a signaling game, our study examines the interaction between pricing strategy of a direct sales channel and consumer reviews. Our findings indicate that consumer reviews significantly influence the determination of the optimal pricing strategy of direct channel for a better-informed manufacturer. Holding pricing power is always the optimal strategy when the direct channel functions as an authentic distribution channel. However, giving up pricing power can be optimal when the direct channel personates a competitive threat, conditional on the travel cost of traditional channel and the information disclosed through consumer reviews. Contrary to expectations, manufacturer’s retention of pricing power for the direct channel can benefit the retailer when the travel cost to the traditional channel is moderate and the information disclosed in consumer reviews does not exhibit extreme negativity or positivity. Additionally, our findings indicate that the chain members can acquire an agreement on the direct channel’s pricing strategy, which results in a win-win outcome, thereby improving supply chain efficiency.},
  archive      = {J_DSS},
  author       = {Musen Xue and Jiahui Guo and Lin Feng},
  doi          = {10.1016/j.dss.2025.114408},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114408},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Should a better-informed manufacturer hold pricing power for the direct channel: The role of consumer reviews},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal review helpfulness prediction with a multi-level
cognitive reasoning mechanism: A theory-driven graph learning model.
<em>DSS</em>, <em>191</em>, 114406. (<a
href="https://doi.org/10.1016/j.dss.2025.114406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customers&#39; perception of review helpfulness entails a cognitive reasoning process influenced by the contextual information of reviews including product descriptions and review neighbors. Current studies on helpfulness prediction primarily focus on static features of individual reviews, neglecting the dynamic interaction among products, reviews and their contextual neighbors. To address this gap, we propose a theory-driven deep learning model for multimodal review helpfulness prediction (DeepMRHP-MCR). The model can collectively simulate human cognitive processes when voting on whether a review is helpful. Specifically, this study presents a multi-level cognitive reasoning mechanism that reconciles the inconsistencies among product descriptions, reviews and their neighbors from the modality, individual and contextual level, respectively. A case study is conducted on the real-world datasets collected from Amazon.com . Empirical results show that the proposed model can improve the quality and interpretability of review prediction process, and present a deep comprehension of consumer&#39;s cognitive decision-making process when evaluating reviews.},
  archive      = {J_DSS},
  author       = {Hai Wei and Ying Yang and Yu-Wang Chen},
  doi          = {10.1016/j.dss.2025.114406},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114406},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Multimodal review helpfulness prediction with a multi-level cognitive reasoning mechanism: A theory-driven graph learning model},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Does the most popular answer lead to the best answer: The
moderating roles of tenure, social closeness, and cultural tightness.
<em>DSS</em>, <em>191</em>, 114405. (<a
href="https://doi.org/10.1016/j.dss.2025.114405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online question and answer (Q&amp;A) communities rely on the general audience or the question asker to determine the best answer. However, limited attention has been directed toward understanding the influence of the general audience-favored answer (i.e., most popular answer) on the question asker-selected best answer (i.e., best answer). This study examines whether and how the general audience-favored answer influences the question asker-selected best answer. Drawing upon uncertainty reduction theory (URT), this paper investigates how three uncertainty reduction strategies (i.e. question askers&#39; tenure, social closeness between the question asker and question answerer, and cultural tightness of the question asker&#39;s region) moderate the relationship between the general audience-favored answer and the question asker-selected best answer. To test the theoretical model, we used a dataset from an online Q&amp;A community comprising 161,695 observations. Our results reveal that the general audience-favored answer more likely leads to the question asker-selected best answer. Furthermore, we find that the question asker&#39;s tenure and the social closeness between the question asker and question answerer negatively moderate the above relationship, while the cultural tightness of question asker&#39;s region positively moderates the above relationship. This research offers a new perspective on the mechanisms through which the general audience-favored answer leads to question asker-selected best answer. By identifying the critical roles of uncertainty reduction strategies during the best answer selection process, our research provides valuable insights for online Q&amp;A community managers to optimize user engagement and satisfaction.},
  archive      = {J_DSS},
  author       = {Yuxin Cai and Xiayu Chen and Shaobo Wei},
  doi          = {10.1016/j.dss.2025.114405},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114405},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Does the most popular answer lead to the best answer: The moderating roles of tenure, social closeness, and cultural tightness},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tell me a story! Narrative-driven XAI with large language
models. <em>DSS</em>, <em>191</em>, 114402. (<a
href="https://doi.org/10.1016/j.dss.2025.114402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing Explainable AI (XAI) approaches, such as the widely used SHAP values or counterfactual (CF) explanations, are arguably often too technical for users to understand and act upon. To enhance comprehension of explanations of AI decisions and the overall user experience, we introduce XAIstories, which leverage Large Language Models (LLMs) to provide narratives about how AI predictions are made: SHAPstories based on SHAP and CFstories on CF explanations. We study the impact of our approach on users’ experience and understanding of AI predictions. Our results are striking: over 90% of the surveyed general audience finds the narratives generated by SHAPstories convincing, and over 78% for CFstories, in a tabular data experiment. More than 75% of the respondents in an image experiment find CFstories more or equally convincing as their own crafted stories. We also find that the generated stories help users to more accurately summarize and understand AI decisions than they do when only SHAP values are provided. The results indicate that combining LLM generated stories with current XAI methods is a promising and impactful research direction.},
  archive      = {J_DSS},
  author       = {David Martens and James Hinns and Camille Dams and Mark Vergouwen and Theodoros Evgeniou},
  doi          = {10.1016/j.dss.2025.114402},
  journal      = {Decision Support Systems},
  month        = {4},
  pages        = {114402},
  shortjournal = {Decis. Supp. Syst.},
  title        = {Tell me a story! narrative-driven XAI with large language models},
  volume       = {191},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="eaai---69">EAAI - 69</h2>
<ul>
<li><details>
<summary>
(2025). Multimodal data imputation and fusion for trustworthy fault
diagnosis of mechanical systems. <em>EAAI</em>, <em>150</em>, 110663.
(<a href="https://doi.org/10.1016/j.engappai.2025.110663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of missing values in the collected data due to sensor failure, communication interruption, or environmental interference can greatly diminishes the trustworthiness of fault diagnosis for mechanical systems. Therefore, this study proposes and evaluates a novel multimodal data imputation and fusion method to perform the trustworthy fault diagnosis of mechanical systems. First, a generative adversarial imputation network, termed as the L2 regularization temporal–spatial generative adversarial imputation network (L2-TSGAIN), is developed. This L2-TSGAIN network, based on a temporal–spatial feature extraction module and L2 regularization loss function, can comprehensively extract data features from both temporal and spatial perspectives, thus achieving high-quality imputation of anomalous sensor data. Subsequently, a multi-input single-output autoencoder (MISO-AE) is designed to extract a universal representation of the imputed data from different modalities and recover features in the fusion data. Finally, the fusion data from different health states of mechanical systems are input into a convolutional neural network classifier to perform fault diagnosis. Experiment validations, considering the presence of missing values in sensor data, have been carried out on the planetary transmission system and gearbox test bench. Compared with several mainstream data imputation methods for fault diagnosis, the optimal diagnostic accuracy of 99.68 % and 100 % on these two datasets can be obtained using the proposed method, respectively, confirming its superior performance and reliability. Thus, the proposed method can provide a trustworthy fault diagnosis tool for mechanical systems in industrial scenarios considering anomalous sensor data.},
  archive      = {J_EAAI},
  author       = {Jie Zhang and Yun Kong and Qinkai Han and Tianyang Wang and Mingming Dong and Hui Liu and Fulei Chu},
  doi          = {10.1016/j.engappai.2025.110663},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110663},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multimodal data imputation and fusion for trustworthy fault diagnosis of mechanical systems},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Atrous spatial pyramid pooling with swin transformer model
for classification of gastrointestinal tract diseases from videos with
enhanced explainability. <em>EAAI</em>, <em>150</em>, 110656. (<a
href="https://doi.org/10.1016/j.engappai.2025.110656">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and early identification of gastrointestinal (GI) lesions is crucial for treating and preventing GI diseases, including cancer. Automated computer-aided diagnosis methods can assist physicians in early and accurate detection. Video classification of GI endoscopic videos is challenging due to the complexity and variability of visual data. This research proposes a novel method for classifying GI diseases using endoscopic videos. Leveraging the public HyperKvasir dataset, we applied preprocessing algorithms to enhance GI frames by removing noise and artifacts with morphological opening and closing techniques, ensuring high-quality visuals. We addressed dataset imbalance by proposing a novel algorithm. Our hybrid model, Atrous Spatial Pyramid Pooling with Swin Transformer (ASPPST), combines advanced Convolutional Neural Networks and the Swin Transformer to classify GI videos into 30 distinct classes. We incorporated Gradient-Class Activation Mapping (Grad-CAM) in ASPPST&#39;s final layer to improve model explainability. The proposed model achieved 97.49 % accuracy in classifying 30 GI diseases, outperforming other transfer learning models and transformers by 8.04 % and 3.99 %, respectively. It also demonstrated a precision of 97.80 %, recall of 97.77 %, and an F1 score of 97.75 %, showcasing robustness across metrics. The high accuracy of ASPPST makes it suitable for real-world use, delivering fewer errors and more precise results in GI endoscopy video classification. Our approach advances artificial intelligence (AI) in computer vision and deep learning for biomedical engineering applications. Grad-CAM integration enhances transparency, boosting clinician trust and adoption of AI tools in diagnostic workflows.},
  archive      = {J_EAAI},
  author       = {Arefin Ittesafun Abian and Mohaimenul Azam Khan Raiaan and Mirjam Jonkman and Sheikh Mohammed Shariful Islam and Sami Azam},
  doi          = {10.1016/j.engappai.2025.110656},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110656},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Atrous spatial pyramid pooling with swin transformer model for classification of gastrointestinal tract diseases from videos with enhanced explainability},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solution and application of two-dimensional seismic
wavefield evolution based on physics-informed neural networks.
<em>EAAI</em>, <em>150</em>, 110652. (<a
href="https://doi.org/10.1016/j.engappai.2025.110652">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics-Informed Neural Networks (PINN) integrate partial differential equations, initial conditions, and boundary conditions into the loss function to predict the solutions of partial differential equations, and have already demonstrated their value in solving two-dimensional (2D) seismic wavefields. However, when dealing with wave problems involving boundary conditions, the added complexity of boundary conditions can lead to imbalanced convergence rates among different loss terms, which may affect both the efficiency and accuracy of the computations. Moreover, the need to retrain the model for different problems limits the flexibility of its application. Therefore, this paper introduces an adaptive weight balancing method and presents a 2D wave simulation based on Self-Adaptive PINN (SA-PINN). This method automatically adjusts the weights in the loss function, improving the solving performance. Additionally, to improve the computational efficiency of PINN in solving similar wave problems, a transfer learning strategy is adopted. By leveraging the similarities between the PINN models of related wave problems, this strategy enhances the generalization ability of PINN when dealing with variations in source location and medium wave speed. Numerical examples in semi-infinite domains and V-shaped valleys demonstrate that this method effectively achieves intelligent and efficient simulation of 2D seismic wavefields, providing a more efficient and intelligent solution for complex seismic wave problems.},
  archive      = {J_EAAI},
  author       = {Zhihui Zhu and Zong Wang and Yang Feng and Weiqi Zheng},
  doi          = {10.1016/j.engappai.2025.110652},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110652},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solution and application of two-dimensional seismic wavefield evolution based on physics-informed neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive human in the loop system for identifying
non-optimal states in natural product manufacturing process.
<em>EAAI</em>, <em>150</em>, 110650. (<a
href="https://doi.org/10.1016/j.engappai.2025.110650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the extraction of natural products, the identification of non-optimal production states is pivotal for ensuring consistent product quality. Currently, there is a deficiency in online, automated detection methods. This study introduces an online machine vision strategy in a real industrial setting to maintain optimal production state. Specifically, the strategy incorporates an adaptive human in the loop deep learning approach to select high-value samples. This method achieves over 90 % accuracy with fewer training samples, effectively addressing the challenges posed by the low-value density characteristic of industrial data. Additionally, a convolutional neural networks-transformer framework is employed as a classifier for video data to meet the demands of time-series data. To enhance the efficiency of processing multiple video streams, we have implemented a knowledge distillation technique to lighten the model. Finally, this model has been deployed in an actual industrial environment for online monitoring of three extraction devices. The system encapsulates the expertise of engineers to standardize the criteria for assessing production states. This integration of innovative technologies ensures a more reliable and efficient extraction process, meeting the industry&#39;s need for consistent product quality.},
  archive      = {J_EAAI},
  author       = {Qilong Xue and Yang Yu and Shixin Cen and Yequan Yan and Jiping Pang and Ping Li and Yehan Hou and Lei Wang and Zheng Li},
  doi          = {10.1016/j.engappai.2025.110650},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110650},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive human in the loop system for identifying non-optimal states in natural product manufacturing process},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A chinese medical named entity recognition method
considering length diversity of entities. <em>EAAI</em>, <em>150</em>,
110649. (<a
href="https://doi.org/10.1016/j.engappai.2025.110649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting clinical entity concepts from professional medical materials is crucial for medical information analysis and knowledge extraction. Whereas, the Chinese medical named entity recognition (CMNER) task faces challenges due to the knowledge specialization and the diversity in entity lengths. To address these challenges, a novel method by considering length diversity of entities for CMNER is proposed, focusing on the integration of local information based on the predominance of large language models (LLMs). The method pre-trains a bidirectional encoder representation from transformers (BERT) based on open Chinese medical texts and designs a multi-dimensional convolutional residual module to enhance the semantic information for characters. This module effectively mines local information across various ranges and employs a local channel self-attention block to integrate this information, establishing a link between local information and entity length. Meanwhile, an adaptive optimization strategy for a learning rate is designed to improve the method&#39;s ability to search for the optimal solution. Experimental results reveal that, compared with state-of-the-art models, our approach achieves the optimal Recall and F1 , especially Recalls achieve 94.50 % (p &lt; 0.05) and 93.51 % (p &lt; 0.05) with effective performance in current task. The ablation results suggest that incorporating local information within 1–7 characters effectively addresses the challenges mentioned, highlighting the potential of our method to advance CMNER task.},
  archive      = {J_EAAI},
  author       = {Hongyu Zhang and Long Lyu and Weifu Chang and Yuexin Zhao and Xiaoqing Peng},
  doi          = {10.1016/j.engappai.2025.110649},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110649},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A chinese medical named entity recognition method considering length diversity of entities},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving weak magnetic detection of ferromagnetic material
defects diagnostics via transfer learning-enhanced residual networks.
<em>EAAI</em>, <em>150</em>, 110647. (<a
href="https://doi.org/10.1016/j.engappai.2025.110647">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of weak magnetic detection technology to identify defect sizes in ferromagnetic materials poses significant challenges due to the large volume of data and the relatively low prediction accuracy of conventional methods. Therefore, this paper proposes an improved Residual Networks (ResNet18) model that integrates transfer learning and channel attention mechanisms. Compared to traditional methods, the following improvements have been made: First, transfer learning has significantly reduced the data volume and time cost required for training from scratch, enhancing the model&#39;s generalization capability. Second, we have added a channel attention mechanism to the ResNet18 model, which involves calculating the importance of each channel through adaptive average pooling and fully connected layers, and generating channel weights using a Sigmoid function. This improvement allows the model to more accurately focus on features with higher relevance to defect sizes. Experimental results demonstrate that for grayscale images with defect lengths of 50 mm, depths of 2 mm, and widths of 1, 2, 3, 4, and 5 mm, the prediction accuracies reached 100 %, 100 %, 98.84 %, 99.58 %, and 100 %, respectively. For grayscale images with defect lengths of 50 mm, widths of 2 mm, and depths of 1, 2, 3, 4, and 5 mm, the prediction accuracies were 99.68 %, 100 %, 99.63 %, 100 %, and 99.60 %, respectively. Compared to the traditional ResNet18 model, the improved model not only enhances the accuracy of defect size prediction but also exhibits greater robustness, providing a new and effective method for defect classification in weak magnetic detection of ferromagnetic materials.},
  archive      = {J_EAAI},
  author       = {Yu Chen and Liangliang Li and Zhengxiang Ma and Xinling Wen and Jiabao Pang and Weitao Yuan},
  doi          = {10.1016/j.engappai.2025.110647},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110647},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving weak magnetic detection of ferromagnetic material defects diagnostics via transfer learning-enhanced residual networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-adaptive production scheduling for discrete
manufacturing workshop using multi-agent cyber physical system.
<em>EAAI</em>, <em>150</em>, 110638. (<a
href="https://doi.org/10.1016/j.engappai.2025.110638">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, the production control process of a discrete manufacturing workshop is characterized by high concurrency, mixed production lines and difficulty in prediction, which lead to uncertainty caused by dynamic disturbances and challenges in production control. Traditional system architectures struggle to handle these uncertainties flexibly and adaptively. To address these issues, an adaptive production scheduling system for the workshop is proposed, utilizing the Multi-agent Cyber Physical System (CPS-MAS) framework. This system integrates self-organization mechanisms and self-adaptive decision-making mechanisms to achieve cooperative optimal control of manufacturing resources. Using multi-agent technology, the resource model in the information space is encapsulated into an intelligent Cyber Physical System (CPS)-Agent model with cognitive interaction and autonomous decision-making capabilities. The improved contract network protocol (CNP) is utilized to the constructed agent, enabling their collaboration and competition to support the self-organization, negotiation, and assignment of manufacturing tasks. Based on multi-agent real-time perception and interactive negotiation, an adaptive control model of the manufacturing process is constructed based on Proportion Integration Differentiation (PID) control principle. This model is trained with the multi-layer perceptron that integrates an attention mechanism. The production strategy and parameters of the agent cooperative network are dynamically adjusted to enable dynamic decision-making optimization under disturbances. The proposed method is verified by experiments in scenarios involving machine failure, emergency order insertion and due date changes, proving its effectiveness.},
  archive      = {J_EAAI},
  author       = {Jie Chen and Zequn Zhang and Liping Wang and Dunbing Tang and Qixiang Cai and Kai Chen},
  doi          = {10.1016/j.engappai.2025.110638},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110638},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-adaptive production scheduling for discrete manufacturing workshop using multi-agent cyber physical system},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A pencil lead break-triggered, adversarial autoencoder-based
approach for rapid and robust rail damage detection. <em>EAAI</em>,
<em>150</em>, 110637. (<a
href="https://doi.org/10.1016/j.engappai.2025.110637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting early-stage damage is essential for railway maintenance, ruling out potential risks that could undermine railway ride comfort and safety. Ultrasonic testing methods, featuring high precision and non-destructive characteristics, have gained widespread use for on-site inspections in modern railway systems. However, current ultrasonic testing remains a highly complex technique that requires expensive ultrasonic devices and trained professionals for operation. This study presents a novel approach for rail damage detection utilizing a disposable mechanical pencil. By intentionally breaking the pencil lead on rail surface, the accumulated potential energy is released in the form of ultrasonic bursts which are acquired by sensors mounted on the rail. The rail damage diagnosis is empowered by an adversarial autoencoder (AAE) which learns representations of ultrasonic signals induced by pencil lead break (PLB). A damage-sensitive indicator is developed based on the Jensen-Shannon Divergence (JSD) between the AAE model output distributions of the baseline and an unknown signal, facilitating rapid and accurate damage diagnosis. Both laboratory experiments and on-site verifications were conducted to validate the proposed approach. The results demonstrate the effectiveness of the damage detection framework in identifying rail damage, exhibiting excellent robustness and reliability. Comparative studies are also conducted to demonstrate the adaptability and effectiveness of the proposed method against field testing environments. The research outcomes of this study will significantly contribute to the development of more efficient on-site inspection techniques for railway maintenance and sustainability.},
  archive      = {J_EAAI},
  author       = {Da-Zhi Dang and Bo-Yang Su and You-Wu Wang and Wai Kei Ao and Yi-Qing Ni},
  doi          = {10.1016/j.engappai.2025.110637},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110637},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A pencil lead break-triggered, adversarial autoencoder-based approach for rapid and robust rail damage detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional temperature field prediction with in-situ
data in metal additive manufacturing using physics-informed neural
networks. <em>EAAI</em>, <em>150</em>, 110636. (<a
href="https://doi.org/10.1016/j.engappai.2025.110636">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately predicting the temperature field in metal additive manufacturing (AM) processes is critical for preventing overheating, adjusting process parameters, and ensuring process stability. While physics-based computational models offer precision, they are often time-consuming and unsuitable for real-time predictions. Machine learning models, on the other hand, rely heavily on high-quality datasets, which can be costly and difficult to obtain in the metal AM domain. Existing studies on physics-informed neural networks (PINNs) have made progress in integrating physics with machine learning but often lack in-situ data integration, which is essential for capturing real-time thermal dynamics. Additionally, their methodologies are typically heavily dependent on specific process characteristics, limiting their flexibility. Our work addresses these gaps by introducing a PINN-based framework specifically designed for temperature field prediction in metal AM. The framework incorporates in-situ temperature data gathered during the manufacturing process, combining it with physics-informed inputs and a custom loss function. The approach is demonstrated through two case studies. In the first case, using a small set of experimental data, the model achieves an error below 3 % with a mean absolute error (MAE) of 11 °C. In the second case, using simulation data, the model achieves an error below 1 % with an MAE of 7 °C. In addition, the framework shows promising adaptability for different metal AM scenarios with different geometries, deposition patterns, and process parameters.},
  archive      = {J_EAAI},
  author       = {Pouyan Sajadi and Mostafa Rahmani Dehaghani and Yifan Tang and G. Gary Wang},
  doi          = {10.1016/j.engappai.2025.110636},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110636},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-dimensional temperature field prediction with in-situ data in metal additive manufacturing using physics-informed neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time onboard compressor stall warning method based on
attention multiple sensors fusion and lightweight network.
<em>EAAI</em>, <em>150</em>, 110635. (<a
href="https://doi.org/10.1016/j.engappai.2025.110635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressor stall is one of the critical faults in aero-engines. An effective stall warning model can assist operators and aviation power systems in taking timely measures to avoid or minimize the impact of compressor stall on flight. Real-time onboard stall warning systems for compressors demand models that possess sufficient accuracy, high reliability, and fast execution speed. Therefore, this paper proposes a novel lightweight network based on attention mechanism for multiple sensors feature fusion, named attention feature fusion lightweight network (AFF-LWNet). Specifically, the network first accomplishes multi-sensor feature fusion through an attention feature fusion block. It then learns input features through a lightweight network with two lightweight feature extraction units and finally employs a multi-layer perceptron (MLP) to output stall warning signals. To verify the feasibility of this approach, the proposed method is evaluated on the aero-engine compressor stall dataset. The results demonstrate that the proposed method achieves an average testing accuracy of 99.453 % and an actual average lead time of 241.87ms on the stall dataset, which surpasses the other five competing methods. Therefore, we believe that the proposed method can effectively achieve real-time onboard stall warning for aero-engine compressors with outstanding performance.},
  archive      = {J_EAAI},
  author       = {Huijie Jin and Yong-Ping Zhao and Zhiqiang Wang},
  doi          = {10.1016/j.engappai.2025.110635},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110635},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time onboard compressor stall warning method based on attention multiple sensors fusion and lightweight network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable graph convolutional network based on catastrophe
theory and its application to group activity recognition. <em>EAAI</em>,
<em>150</em>, 110634. (<a
href="https://doi.org/10.1016/j.engappai.2025.110634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (graph models for short) are crucial for understanding model decisions through mathematical white-box interpretation, which can radically improve the performance and credibility of downstream artificial intelligence applications. To address the limitations of existing interpretability of over-smoothing and over-squashing, we propose an explainable graph model based on nonlinear catastrophe theory and apply it to group activity recognition to validate the usefulness of interpretability. (1) We introduce catastrophe mathematical theory to explore the internal processes of graph models and construct the explainable dynamical equations of the graph convolutional network; (2) When graph node features lose uniqueness, leading to over-smoothing, which reduces the discriminative power of the graph model, we propose a mathematical method to predict over-smoothing; (3) In response to the over-squashing of the node feature values that is excessively compressed, we design a channel expansion unit to extend the transmission paths of graph nodes and alleviate the over-squashing in the graph structure. Finally, we apply our model to group activity recognition tasks to capture complex interactions within groups. We obtain the competitive results on five publicly available graph structure datasets (Actor, Chameleon, Texas, Cornell, Cora) and our self-built group activity dataset. Our model can effectively capture node and graph-level features with stronger generalization capabilities. For complex and diverse real-world group activity data, our model offers intuitive graph-level explanations for group activity analysis. Through the analysis of over-smoothing and over-squashing, our method extends new theoretical approaches in explainable artificial intelligence.},
  archive      = {J_EAAI},
  author       = {Junpeng Kang and Jing Zhang and Lin Chen and Hui Zhang and Li Zhuo},
  doi          = {10.1016/j.engappai.2025.110634},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110634},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Explainable graph convolutional network based on catastrophe theory and its application to group activity recognition},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A knowledge graph for the vulnerability of construction
safety system in megaprojects based on accident inversion.
<em>EAAI</em>, <em>150</em>, 110630. (<a
href="https://doi.org/10.1016/j.engappai.2025.110630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing vulnerability of construction safety systems in megaprojects (CSSMs) poses significant challenges to their safety management and control. To address this obstacle, this study retrodicts the accidents based on text mining using the Bidirectional Encoder Repre-sentations from Transformers Topic (BER-Topic) model to uncover topic and topic words related to the vulnerabilities of CSSMs. The vulnerability indicator system (VIS) is established by considering the exposure, sensitivity, and adaptability of the vulnerability of CSSMs. Subsequently, an improved Decision-making Trial and Evaluation Laboratory (DEMATEL) method based on association rules is proposed to reduce the subjectivity in assigning weights to vulnerability indicators, and a topological network based on complex network is constructed to identify the characteristics of VIS. Based on this, a knowledge graph of vulnerabilities in CSSMs is developed. Finally, taking into account the occurrence probability and the actual losses incurred of vulnerability indicators, a vulnerability assessment model for CSSMs is proposed. The research findings are: 1) Based on the BER-Topic model, 32 topics and topic words related to the vulnerability of CSSMs are mined. 2) A VIS for CSSMs is constructed, including 42 indicators across three dimensions of exposure (19), sensitivity (14), and adaptability (9), involving four aspects: humans, machines, environment, and management. 3) The key points for vulnerability management and control in CSSMs are Inaccurate implementation of geological remediation plans, Rusting of connecting components, and Unlicensed personnel operating, among others, which have strong intermediary roles.},
  archive      = {J_EAAI},
  author       = {Yingliu Yang and Pengcheng Xiang},
  doi          = {10.1016/j.engappai.2025.110630},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110630},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A knowledge graph for the vulnerability of construction safety system in megaprojects based on accident inversion},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust sparse discriminative least squares regression for
image classification. <em>EAAI</em>, <em>150</em>, 110626. (<a
href="https://doi.org/10.1016/j.engappai.2025.110626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discriminative Least Squares Regression (DLSR) is a method used for multi-class classification tasks that expands the distance between different classes through an ε -dragging technique. However, it also amplifies the differences in intra-class regression targets. Moreover, the samples contain a significant amount of noise, which negatively affect the classification performance. To mitigate these problems, we propose Robust Sparse Discriminative Least Squares Regression (RSDLSR) approach to enhance the model&#39;s discriminative power. Firstly, we maintain the original data structure by matrix decomposition in the label space. Secondly, the noise is fitted using sparse constrained noise matrix to enhance the model&#39;s denoising ability. Furthermore, we select important features from label space using a linear discriminant analysis criterion to minimize the influence of redundant features. Finally, l 2 , 1 norm constraint is imposed on the relaxation matrix to improve the sparsity and robustness of the model. Comparative evaluations demonstrate that our proposed method exhibits significant advantages over various existing methods across different classification tasks.},
  archive      = {J_EAAI},
  author       = {Zhangjing Yang and Dingan Wang and Pu Huang and Minghua Wan and Fanlong Zhang},
  doi          = {10.1016/j.engappai.2025.110626},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110626},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust sparse discriminative least squares regression for image classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A physics informed convolution neural network for
spatiotemporal temperature analysis of concrete dams. <em>EAAI</em>,
<em>150</em>, 110624. (<a
href="https://doi.org/10.1016/j.engappai.2025.110624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring is indispensable throughout the life cycle of dams, and the loading conditions determines the reliability of the assessment. Among them, temperature plays an important role on the behavior of arch dams, which are sparsely monitored in practice. How to use these sparsely measured data to obtain the accurate spatiotemporal temperature field becomes a critical problem. This study proposes a physics informed convolutional neural network for spatiotemporal temperature field of arch dams. A dual thread convolutional neural network considers the effects of spatiotemporal and temporal variables distinctively. The proposed model is validated using measured data from an existing arch dam. Compared with applied convolutional neural network, the proposed model improves the accuracy of temperature field reconstruction by 18 % and reduces reliance on measured data. Benefit of consideration of the continuity and heat transfer, the spatial distribution of the temperature field is more reasonable in continuity, and can retain accuracy even with limited monitoring data. The proposed model can provide the actual spatiotemporal non-uniform temperature field of the arch dam, providing basic data for the analysis and safety evaluation of arch dams throughout their life-cycle.},
  archive      = {J_EAAI},
  author       = {Jiaqi Yang and Jinting Wang and Feng Jin and Jianwen Pan},
  doi          = {10.1016/j.engappai.2025.110624},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110624},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A physics informed convolution neural network for spatiotemporal temperature analysis of concrete dams},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A decision modeling approach for the development of
sustainable transportation oil companies. <em>EAAI</em>, <em>150</em>,
110623. (<a
href="https://doi.org/10.1016/j.engappai.2025.110623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constructing sustainable transportation infrastructure to address climate change by reducing carbon dioxide and greenhouse gas emissions is unfeasible without the involvement of international oil companies (IOCs). Identifying the most sustainable IOC can significantly enhance legitimacy, corporate image, brand value, transparency, and reputation. The environmental impact of oil transportation is crucial to the sector&#39;s long-term growth, and modeling IOCs can guide decision-making that aligns with regulatory, environmental, and societal expectations, ensuring successful project implementation. Modeling IOCs presents multiple-attribute decision-analysis (MADA) challenges. Previous research proposed a decision matrix that crossed IOC alternatives with attributes, sub-attributes, and measurement items, utilizing assessments from 483 experts across 11 IOCs based on 2 attributes, 9 sub-attributes, and 47 measurements. Despite the literature review, challenges such as score deviations in the ranking method, as well as informational vagueness, ambiguity, and uncertainty in both weighting and ranking processes, remain unsolved, and early MADA methods exhibit theoretical flaws. This study aims to formulate and develop a decision modeling approach using multi-attribute ideal-real comparative analysis (MAIRCA) and fuzzy weighted zero inconsistency (FWZIC) within a homogeneous interval-valued intuitionistic fuzzy rough set (IIFRS) environment. This solution addresses the limitations in the literature and effectively handles the complexity of the decision matrix. The findings reveal that cost leadership under a hybrid competitive strategy (HCS-CL) emerged as the most sensitive attribute, holding the highest weight, highlighting the importance of cost efficiency and competitive pricing. IOC11 ranked highest, followed by IOC3 and IOC10, providing benchmarks for other companies. Lesser-ordered companies, such as IOC4, preserve employ these comprehensions to recognize intentional gaps and embrace best attempts from extraordinary-ordered participants. Sensitivity-analysis, Spearman&#39;s-correlation, and comparative-analysis proven the robustness of the proposed approach. The study highlights the require for oil and gas administrators to spotlight cost leadership advantages, raise-efficiency, lower-production costs, and influence economies of ratio to maintain a reasonable edge and enhance-market-positioning.},
  archive      = {J_EAAI},
  author       = {Hassan A. Alsattar and Sarah Qahtan and Nahia Mourad and A.A. Zaidan and Muhammet Deveci and Dragan Pamucar and Jurgita Antucheviciene and Weiping Ding},
  doi          = {10.1016/j.engappai.2025.110623},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110623},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A decision modeling approach for the development of sustainable transportation oil companies},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving model calibration in bone marrow cell
classification through mixup and center loss fusion. <em>EAAI</em>,
<em>150</em>, 110620. (<a
href="https://doi.org/10.1016/j.engappai.2025.110620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of bone marrow cell morphology is essential for the accurate diagnosis of hematological disorders. Traditional manual classification methods are time-consuming and labor-intensive. Although current automatic deep learning techniques mitigate these issues, they may still present significant risks in critical medical diagnostics due to overconfidence in predictions. To tackle these challenges, this paper proposes a novel calibration method called MixCL (Mix-Center Loss). MixCL combines the simple and effective data augmentation method Mixup with deep metric learning Center Loss, achieved through the design of a new loss function. By utilizing Mixup to generate mixing centers that enrich the feature sampling in the feature space, and leveraging the clustering effect of Center Loss to enhance the grouping of similar samples, MixCL combines the strengths of both methods. The effectiveness of MixCL is validated using three real bone marrow cell image datasets, demonstrating significant reductions in Expected Calibration Error (ECE) and Overconfidence Error (OE) for in-distribution samples. For example, in Shifted Windows Transformer model, ECE and OE metrics decreased across all datasets, with reductions averaging 1.72% in ECE and 2.10% in OE. The confidence Kernel Density Estimation (KDE) plot reveals that models using MixCL more effectively manage uncertainty in out-of-distribution samples, ensuring better differentiation between in-distribution and out-of-distribution samples. Thus, the proposed method effectively improves the calibration performance of the model while exhibiting better generalization performance, significantly improved when compared with current advanced bone marrow cell classification methods. Moreover, it has potential applications in various image classification fields, providing reliable confidence estimates.},
  archive      = {J_EAAI},
  author       = {Shuming Cheng and Qinghang Lu and Qianhang Guo and Yunqi Lin and Mingxin Li and Xingyu Zhao and Liang Guo and Jiaming Li and Jie Li and Qingmao Zhang and Qiongxiong Ma},
  doi          = {10.1016/j.engappai.2025.110620},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110620},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving model calibration in bone marrow cell classification through mixup and center loss fusion},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise step counting algorithm for pedestrians using
ultra-low-cost foot-mounted accelerometer. <em>EAAI</em>, <em>150</em>,
110619. (<a
href="https://doi.org/10.1016/j.engappai.2025.110619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-velocity update (ZUPT) is one of the most widely used step counting methods in pedestrian inertial navigation. Existing accelerometer-based methods encounter issues with misjudgments of zero velocity and step counting errors in various activities. To tackle these challenges, we present a precise step counting algorithm leveraging ultra-low-cost foot-mounted accelerometer for pedestrians with extremely low complexity. This algorithm mainly contains two key points: adaptive acceleration threshold selection and state vector update, implemented by twice zero-velocity detections (ZVD, generating state vectors to depict pedestrian&#39;s status) and length comparisons. Accelerations undergo gravity correction, magnitude calculation, data smoothing, and parameters initialization. Subsequently, the zero-acceleration threshold is adaptively selected through ZVD, and the length of state intervals (LSI) is compared with the first length threshold. Then, the state vector is updated by ZVD, and the LSI is compared with the second length threshold. Finally, the number of state intervals is interpreted as step counts. Step counting experiments were conducted utilizing three diverse datasets, which comprised a self-constructed ultra-low-cost accelerometer-based dataset and two public datasets. These datasets covered various activities, such as normal walking, fast walking, running, multiple turns in a corridor, stationary stepping, and upstairs/downstairs. The proposed algorithm could achieve an accuracy of 100 % under the above situations. Compared to long short term memory (LSTM) and other algorithms, it exhibited an accuracy improvement of at least 13.05 %, with a processing time only 0.07 % of that required by LSTM. The proposed algorithm enables accurate step counting across a range of activities performed by different pedestrians with high precision, low complexity, and robust applicability.},
  archive      = {J_EAAI},
  author       = {Jingxue Bi and Jianhui Wang and Baoguo Yu and Guobiao Yao and Yunjia Wang and Hongji Cao and Lu Huang and Huaqiao Xing},
  doi          = {10.1016/j.engappai.2025.110619},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110619},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Precise step counting algorithm for pedestrians using ultra-low-cost foot-mounted accelerometer},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-stream structure-oriented neighbor enhancement network
for dental model segmentation. <em>EAAI</em>, <em>150</em>, 110618. (<a
href="https://doi.org/10.1016/j.engappai.2025.110618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The primary objective of digital orthodontic treatment is to achieve accurate tooth segmentation of the three-dimensional (3D) dental mesh model obtained from oral scanning equipment. However, current advanced deep learning-based methods often consolidate all features into a single vector during the feature learning process, thus overlooking the distinct information among features and subsequently weakening their complementary roles. To address this issue, we propose a two-stream structure-oriented neighbor enhancement network (TSNEN) to improve the complementary effect among different features. Specifically, TSNEN develops an input-specific two-stream structure and feature enhancement modules to emphasize the geometric disparities among various meshes and achieve the complementary enhancement of different features, respectively. Furthermore, the self-attention module is modified to fully integrate the local features derived from the branches of the two streams, which effectively balances the data differences among different features to mitigate feature confusion, and ultimately achieves accurate segmentation of the dental model. The real dental model dataset is analyzed to verify the effectiveness and capability of the proposed method which reached an overall accuracy (OA) at 96.83 % and mean over union (mIoU) at 92.06 %. Finally, the comparative analysis is implemented and the results further show that the proposed method has better performance both in prediction accuracy and robustness.},
  archive      = {J_EAAI},
  author       = {Zhihua Liu and Hao Tang and Jiutao Xue and Yuhe Liao},
  doi          = {10.1016/j.engappai.2025.110618},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110618},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two-stream structure-oriented neighbor enhancement network for dental model segmentation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time prediction of axial force in concrete-filled steel
tubular columns under fire conditions using modular artificial
intelligence techniques. <em>EAAI</em>, <em>150</em>, 110617. (<a
href="https://doi.org/10.1016/j.engappai.2025.110617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The axial force plays a critical role in assessing the functional integrity of columns within a building in fire. However, it cannot be measured directly and is influenced by factors such as temperature, load ratio, and axial restraint. This study proposes a real-time methodology to predict the axial force of restrained concrete-filled steel tubular (CFST) columns exposed to real fires, utilizing modular artificial intelligence. A module is developed that combines a convolutional neural network (CNN) and long short-term memory (LSTM) networks to predict the temperature field of CFST columns caused by fire in real time. This module estimates the current temperature field using past data and the current surface temperature, which is continuously monitored with inherent noise. It effectively mitigates noise interference, achieving an R 2 of 0.97 on the test dataset, which ensures accurate estimations. Additionally, a separate LSTM module with a skip connection is employed to predict the axial force ratio, integrating temperature predictions and real-time measurements of axial deformation. Finally, the accuracy of this modular model demonstrates better performance in predicting real-time axial force compared to the conventional integrated deep learning model, achieving an R 2 of 0.99. The proposed approach enables accurate prediction of axial force in restrained CFST columns across various fire scenarios and structural conditions, aiming at increasing the scientificity of fire rescue decisions.},
  archive      = {J_EAAI},
  author       = {Hong-Hui Qi and Guo-Qiang Li and Shaojun Zhu},
  doi          = {10.1016/j.engappai.2025.110617},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110617},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Real-time prediction of axial force in concrete-filled steel tubular columns under fire conditions using modular artificial intelligence techniques},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A real-time prediction model for instantaneous dam-break
flood evolution of concrete gravity dams based on attention mechanism
and spatiotemporal multiple features. <em>EAAI</em>, <em>150</em>,
110616. (<a
href="https://doi.org/10.1016/j.engappai.2025.110616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simulating the flood evolution following the sudden breach of concrete gravity dams is crucial for enabling prompt emergency flood control decisions. The real-time performance and reliability of these flood propagation simulations are essential for improving the accuracy and speed of emergency responses. This study introduces a deep learning model that integrates an attention mechanism to predict flood evolution parameters in real time. Initially, parameters such as water depth and flow rate were measured under 32 distinct dam-break scenarios using a hydrodynamic model. By combining terrain data with time-series flood discharge data, we compiled a dataset containing 1984 entries, enhanced through reduced-order methods. A novel deep learning model, the Flood-Swin-Transformer, was then developed to predict the spatiotemporal evolution of dam-break floods. This model was benchmarked against 11 baseline models and four state-of-the-art deep learning models. The results indicate: (1) Baseline models accurately predict water depth but are less effective at predicting flow rate parameters; (2) Deep learning models outperform baseline models in both accuracy and classification capabilities for water depth and flow rate parameters, showing robust performance; (3) Extensive analyses, including error, classification accuracy, effectiveness, robustness, and flood parameter error mapping, demonstrate the superior performance of the proposed model; (4) The proposed model predicts flood evolution up to 43.75 times faster than traditional hydrodynamic models, facilitating real-time prediction capabilities.},
  archive      = {J_EAAI},
  author       = {Chao Wang and Yaofei Zhang and Sherong Zhang and Xiaohua Wang and Xingbo Zhou and Yishu Lai},
  doi          = {10.1016/j.engappai.2025.110616},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110616},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real-time prediction model for instantaneous dam-break flood evolution of concrete gravity dams based on attention mechanism and spatiotemporal multiple features},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dialogue response coherency evaluation with feature
sensitive negative sample using multi list-wise ranking loss.
<em>EAAI</em>, <em>150</em>, 110609. (<a
href="https://doi.org/10.1016/j.engappai.2025.110609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic evaluation of dialogue coherency is crucial for developing high-quality dialogue systems. However, traditional evaluation metrics such as Bilingual Evaluation Understudy (BLEU) and Recall-Oriented Understudy for Gisting Evaluation (ROUGE) have limitations when it comes to assessing diverse and creative responses because they heavily rely on reference responses. For learnable metrics which utilize contrastive learning, challenges are encountered due to the use of randomly selected negative samples that do not reflect conversational features (i.e. topic, emotion, intention) and the lack of granularity in assessing response appropriateness. To address these limitations, we propose the Feature sensitive Multi-Listwise Ranking (FMListR) response coherency evaluation model. This model aims to evaluate dialogue coherency in degrees while considering conversational sensitive features. This approach involves sampling feature-sensitive responses that share conversational features with ground truth responses and utilizing them as hard negative samples. The model is trained using Multi-Listwise Ranking (MListR) loss, which is designed to learn the ranking between negative samples and identify response features. The experimental results demonstrate that Feature sensitive Multi-Listwise Ranking exhibits stronger correlations with human judgment compared to other response coherency evaluation metrics. By considering conversational features and training the model using a specialized loss function, FMListR provides a more robust and accurate evaluation of dialogue coherency.},
  archive      = {J_EAAI},
  author       = {YeongJun Hwang and Dongjun Kang and JinYeong Bak},
  doi          = {10.1016/j.engappai.2025.110609},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110609},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dialogue response coherency evaluation with feature sensitive negative sample using multi list-wise ranking loss},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive assessment of failure mode and shear capacity
of reinforced concrete circular columns based on data-driven machine
learning methods. <em>EAAI</em>, <em>150</em>, 110603. (<a
href="https://doi.org/10.1016/j.engappai.2025.110603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforced concrete (RC) columns are critical elements in frame structures. A common challenge in structural engineering is estimating the seismic capacity of circular RC columns, as existing methods typically require transforming circular columns into equivalent square sections due to the absence of direct formulas. To address this, this study introduces data-driven machine learning (ML) methods to directly assess both failure modes and seismic shear capacity of circular RC columns. With the help of automated machine learning (AutoML), seven ML algorithms were selected and fine-tuned, resulting in 40 distinct models that were analyzed and compared in detail. The results indicate that the Multilayer Perceptron (MLP) model outperforms others in predicting seismic failure modes, achieving a high accuracy of 88 %. For seismic shear capacity predictions, the Weighted Ensemble (WE) model achieved the best performance with Root Mean Squared Error of 53.49, Mean Absolute Error of 39.23, Coefficient of Determination of 0.88 and Mean Squared Error of 2861.18 among all the ML models. Furthermore, the results (the predicted maximum lateral force/the experimental results) of the WE model, with a mean value of 0.98, a standard deviation of 0.11, and a coefficient of variation (mean/standard deviation) of 12.8 %, surpass those of traditional theoretical and empirical models. Besides, the ML models offer fast, accurate seismic performance evaluations for circular RC columns, eliminating the need for complex and time-consuming calculations. Furthermore, SHapley Additive exPlanations (SHAP) analysis provided visual insights into parameter contributions, enhancing model transparency and trust for engineering applications.},
  archive      = {J_EAAI},
  author       = {Yue Wen and Shiqiao Zhou and Gaochuang Cai and Zhili He and Amir Si Larbi},
  doi          = {10.1016/j.engappai.2025.110603},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110603},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comprehensive assessment of failure mode and shear capacity of reinforced concrete circular columns based on data-driven machine learning methods},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging large language models to examine the interaction
between investor sentiment and stock performance. <em>EAAI</em>,
<em>150</em>, 110602. (<a
href="https://doi.org/10.1016/j.engappai.2025.110602">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the relationship between investor sentiment and stock performance is crucial in dynamic financial markets. Existing researches often focus on financial news and stock prices, while studies on investor sentiment typically rely on traditional machine learning models that require extensive data labeling. Additionally, most researches focus on single stock indices, overlooking the impact of brand popularity. To address these gaps, this study proposes a novel framework to analyze the interaction between investor sentiment and stock performance, using Chinese Baijiu industry stocks as a case example. It further explores how brand popularity influences this relationship, offering insights for informed investment decisions through artificial intelligence technology. In this study, we leverage Generative Pre-trained Transformer 4 (GPT-4), a state-of-the-art black-box large language model, to process vast volumes of unstructured text data from stock forums. By employing in-context learning with human-labeled examples, GPT-4 generates weak labels that are subsequently used to fine-tune Large Language Model Meta AI (LLaMA), a smaller and more efficient open-source LLM from Meta AI, thereby enabling sentiment-driven decision-making in real-world scenarios. To construct a comprehensive sentiment indicator, we integrate both direct and indirect factors influencing sentiment and use principal component analysis to combine them effectively. To examine interaction between sentiment and stock yield, we apply the Granger causality test and vector autoregression models across stocks with different brand popularity levels. The results show that our framework achieves state-of-the-art performance investor sentiment analysis. Moreover, with brand popularity significantly amplifying the interaction between investor sentiment and stock yield, it leads to bidirectional Granger causality in highly popular brands.},
  archive      = {J_EAAI},
  author       = {Yong Zhuang and Feilong Wang and Dickson K.W. Chiu and Kevin K.W. Ho},
  doi          = {10.1016/j.engappai.2025.110602},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110602},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leveraging large language models to examine the interaction between investor sentiment and stock performance},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lane change trajectory planning based on improved model
predictive control with artificial potential field for autonomous
vehicles in medium-high speed scenarios. <em>EAAI</em>, <em>150</em>,
110601. (<a
href="https://doi.org/10.1016/j.engappai.2025.110601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design of a lane change control system for autonomous vehicles (AVs) in medium-high speed scenarios. A lane change trajectory planning method based on the combination of artificial potential field (APF) and model predictive control (MPC), referred to as APF-MPC, is proposed. To ensure a smooth transition at the beginning and end of the lane change, a reference trajectory based on a sinusoidal curve is designed. The obstacle potential field, constructed using a two-dimensional joint probability density function, is combined with the road potential field to enhance lane change safety. The potential field function is integrated into the MPC optimal control problem, which is constructed based on the point-mass model. This problem is then solved to obtain the planned trajectory within the predicted time domain. The lateral and longitudinal tracking controllers, designed using linear MPC, are employed to track the planned trajectory in real-time, thereby demonstrating the real-time performance of this method. The feasibility of the APF-MPC method is verified through a co-simulation platform. The simulation results indicate that the trajectories planned by the APF-MPC method meet the requirements of safety, occupant comfort, and lane change efficiency. In different scenarios, the front wheel angle of the AV during the lane change ranges from -2 to 2 degrees. Compared with non-adaptive APF and traditional MPC methods, the maximum lateral acceleration, maximum lateral velocity, and maximum front wheel steering angle of the AV during lane changing are reduced by more than 40%.},
  archive      = {J_EAAI},
  author       = {Zhaojun Zhang and Jiale Qin and Simeng Tan and Hongjie Luo},
  doi          = {10.1016/j.engappai.2025.110601},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110601},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Lane change trajectory planning based on improved model predictive control with artificial potential field for autonomous vehicles in medium-high speed scenarios},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Input parameterized physics informed neural networks for de
noising, super-resolution, and imaging artifact mitigation in time
resolved three dimensional phase-contrast magnetic resonance imaging.
<em>EAAI</em>, <em>150</em>, 110600. (<a
href="https://doi.org/10.1016/j.engappai.2025.110600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivation: Hemodynamic analysis is crucial for diagnosing and predicting cardiovascular diseases. However, methods relying on fluid flow simulations or blood flow imaging are complex, time-consuming, and require specialized expertise, limiting their clinical use. Goal: This research aims to automate the enhancement of blood flow images, providing clinicians with a fast, accurate tool for hemodynamic analysis without requiring advanced expertise. Objectives: A software tool based on physics-constrained neural networks was developed to enable clinicians to easily select and process regions of interest (ROIs) in time-resolved three-dimensional phase contrast magnetic resonance imaging (4D-Flow MRI) blood flow images for quick, accurate analysis. Methods: The Input Parameterized Physics-Informed Neural Network (IP-PINN) was introduced to improve the spatio-temporal resolution of 4D-Flow MRI. IP-PINN mitigates noise, velocity aliasing, and phase errors. A convolutional neural network processes ROI data into latent vectors, which are then used to predict velocity, pressure, and spin density via a multi-layer perceptron. The method is trained with synthetic blood flow data using an innovative loss function that addresses noise and artifacts. Results: IP-PINN successfully enhanced image resolution, reducing noise and artifacts when tested on synthetic 4D-Flow MRI data derived from blood flow simulations of intracranial aneurysms. For data with 20 decibels (dB) signal-to-noise ratio, results closely matched the ground truth with less than 5.5% relative error. Processing took under two minutes. The method also has the potential to reduce data acquisition time by 25%. Conclusions: IP-PINN could significantly enhance the clinical use of 4D-Flow MRI for personalized hemodynamic analysis in cardiovascular diseases.},
  archive      = {J_EAAI},
  author       = {Amin Pashaei Kalajahi and Hunor Csala and Zayeed Bin Mamun and Sangeeta Yadav and Omid Amili and Amirhossein Arzani and Roshan M. D’Souza},
  doi          = {10.1016/j.engappai.2025.110600},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110600},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Input parameterized physics informed neural networks for de noising, super-resolution, and imaging artifact mitigation in time resolved three dimensional phase-contrast magnetic resonance imaging},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing machine learning algorithms for fault
classification in rolling bearings: A bayesian optimization approach.
<em>EAAI</em>, <em>150</em>, 110597. (<a
href="https://doi.org/10.1016/j.engappai.2025.110597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern power machinery is inherently complex and operates under dynamic operating conditions, so they demand advanced solutions based on deep learning to diagnose bearing faults inside rotating equipment that cause unplanned downtime and safety issues, leading to operational challenges. However, most deep learning approaches aim to improve performance by incorporating hybrid neural networks that rely on multiple convolutional and temporal units, often overlooking optimizing the large number of hyperparameters that define the structure and performance of hybrid models along with the associated computational constraints. To address this gap, this study presents an innovative approach for the detection and classification of bearing faults by integrating an optimized sparse deep autoencoder (DAE) with a Bidirectional Long Short-Term Memory model (Bi-LSTM). The optimal network structure and hyperparameters are determined through Bayesian optimization (BO) with parallel settings, which automatically searches for network configurations that improve the feature extraction ability of the DAE and the generalization ability of the Bi-LSTM for more efficient fault classification in rolling bearings. Parallel optimization accelerates network structure and hyperparameter tuning by evaluating multiple configurations at once. It leverages the full potential of available multi-core Central Processing Units (CPUs)/Graphics Processing Units (GPUs) in conjunction with a lightweight BO surrogate model. This autonomous and user-friendly framework generates inputs from principal component analysis for linear and BO-DAE for non-linear feature extraction and selection, which are then used to train a BO-enhanced Bi-LSTM. This three-stage optimized method effectively captures spatial and temporal dependencies in vibrational signals, achieving superior efficiency, accuracy, and reliability compared to shallow and deep learning models. Evaluation metrics, including macro precision (99.50 %), recall (99.60 %), F1-Score (99.57 %), and Cohen&#39;s Kappa metric (Cκ = 99.53 %), demonstrate the efficacy of our approach for bearing fault classification in industrial applications.},
  archive      = {J_EAAI},
  author       = {Muhammad Zain Yousaf and Josep M. Guerrero and Muhammad Tariq Sadiq},
  doi          = {10.1016/j.engappai.2025.110597},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110597},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing machine learning algorithms for fault classification in rolling bearings: A bayesian optimization approach},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic scheduling in flexible and hybrid disassembly
systems with manual and automated workstations using reward-shaping
enhanced reinforcement learning. <em>EAAI</em>, <em>150</em>, 110588.
(<a href="https://doi.org/10.1016/j.engappai.2025.110588">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As e-waste grows at an alarming rate, efficient disassembly systems have become crucial for sustainable production practices. Existing disassembly systems rely heavily on fixed automation and limited manual intervention, making it challenging to adapt to dynamic issues such as workstation failures and system bottlenecks, leading to inefficiencies and suboptimal resource allocation. To address these issues, a hybrid disassembly system is developed that integrates manual and automated workstations, allowing for the flexible variation of manual resources as needed to optimize the disassembly process, with a focus on reducing time and maximizing profit. Through the proposal of a Proximal Policy Optimization (PPO) algorithm enhanced with Reward-Shaping, the research effectively tackles key challenges of uncertainty and dynamic conditions in disassembly systems, including workstation failures and system bottlenecks. These issues are explored through a refrigerator disassembly simulation model. The results demonstrate that the PPO algorithm significantly outperforms traditional rule-based methods and two other reinforcement learning techniques in managing complex dynamic scheduling and resource allocation tasks, offering greater efficiency and flexibility. These findings contribute to the advancement of automated disassembly processes and their integration into modern industrial systems.},
  archive      = {J_EAAI},
  author       = {Jinlong Wang and Qihuiyang Liang and Min Li and Zelin Qu and Yuanyuan Zhang},
  doi          = {10.1016/j.engappai.2025.110588},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110588},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic scheduling in flexible and hybrid disassembly systems with manual and automated workstations using reward-shaping enhanced reinforcement learning},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Soft actor-critic enhanced nonsingular terminal synergetic
control for serial manipulators with quantized input and state.
<em>EAAI</em>, <em>150</em>, 110587. (<a
href="https://doi.org/10.1016/j.engappai.2025.110587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synergetic control is vulnerable to model uncertainty, which affects control performances and stability. In addition, quantized sensor measurements and control signals compound these challenges. Equally important, a unique problem in serial manipulator robots is the varying control response across joints, which affects the end effector’s pose when moving to the desired position. The mentioned challenges motivate this study to propose soft actor-critic reinforcement learning as a novel adaptive approach for nonsingular terminal synergetic control on a 4-degree-of-freedom serial manipulator robot. The control law is designed based on the nonsingular terminal synergetic control evolution constraint, manifold, and macrovariable. Subsequently, the soft actor-critic reinforcement learning dynamically adjusts the evolution constraint parameters, adapting to the changing state of the environment. The Lyapunov stability theorem proves the control law stability. This study also introduces a novel reinforcement learning reward function that encourages state convergence using the Cauchy probability density function and macrovariable. The agent training environment accounts for state and input quantization, enabling a seamless sim-to-real transition. The simulations and physical experiments validate the effectiveness of the proposed controller in improving transient response, tracking response, and uniform performance across joints. Additionally, online training validates the safe exploration property of the proposed adaptive control.},
  archive      = {J_EAAI},
  author       = {Muhammad Auzan and Yong-Lin Kuo},
  doi          = {10.1016/j.engappai.2025.110587},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110587},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Soft actor-critic enhanced nonsingular terminal synergetic control for serial manipulators with quantized input and state},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial neural networks for finger vein recognition: A
survey. <em>EAAI</em>, <em>150</em>, 110586. (<a
href="https://doi.org/10.1016/j.engappai.2025.110586">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finger vein recognition is an emerging biometric recognition technology. Different from the other biometric features on the body surface, the venous vascular tissue of the fingers is buried deep inside the skin. Due to this advantage, finger vein recognition is highly stable and private. Finger veins are virtually impossible to steal and difficult to interfere with by external conditions. Unlike the finger vein recognition methods based on traditional machine learning, the artificial neural network technique, especially deep learning, does not rely on feature engineering and has superior performance. To summarize the development of finger vein recognition based on artificial neural networks,this paper collects 174 related papers. First, we introduce the background of finger vein recognition and the motivation for this survey. Then, the development history of artificial neural networks and the representative networks on finger vein recognition tasks are introduced. The public datasets widely used in finger vein recognition are then described. After that, we summarize the related finger vein recognition tasks based on classical neural networks and deep neural networks, respectively. Finally, the challenges and potential development directions in finger vein recognition are discussed. This paper provides a comprehensive and novel summary of the application of artificial neural networks in the finger vein recognition field.},
  archive      = {J_EAAI},
  author       = {Yimin Yin and Renye Zhang and Pengfei Liu and Wanxia Deng and Dayu Hu and Siliang He and Chen Li and Jinghua Zhang},
  doi          = {10.1016/j.engappai.2025.110586},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110586},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Artificial neural networks for finger vein recognition: A survey},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-module cooperative control method for on-ramp area in
heterogeneous traffic flow using reinforcement learning. <em>EAAI</em>,
<em>150</em>, 110584. (<a
href="https://doi.org/10.1016/j.engappai.2025.110584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the on-ramp area, vehicle conflicts significantly reduce traffic efficiency and increase collision risks. This study introduces a novel dual-module cooperative control approach designed for on-ramps that accommodate heterogeneous traffic flows, including connected and automated vehicles (CAVs) and human driving vehicles (HDVs). By utilizing reinforcement learning techniques, the approach aims to enhance both traffic efficiency and safety. The approach comprises two key modules: the merging control module and the lane-changing control module. The merging control module facilitates cooperation between mainline and ramp vehicles, while the lane-changing control module assists mainline CAVs in making informed lane-change decisions. Agents within these modules are trained using the proximal policy optimization algorithm, known for its strong convergence properties. After 100 to 200 training episodes, the agents achieve stable peak average rewards. Simulation results demonstrate significant improvements in traffic efficiency and safety with the dual-module control method in on-ramp areas, especially in scenarios involving CAV-HDV heterogeneous traffic flows. With a CAV penetration rate of just 0.2, average vehicle delay is reduced by 26 %. Furthermore, from a safety perspective, when the CAV penetration rate reaches or exceeds 0.3, the time-exposed time-to-collision decreases by approximately 45 %. Transferability analysis indicates that integrating reinforcement learning agents into the control strategy produces positive results across varying maximum speeds and flow rates. In heterogeneous traffic environments, it is advisable to train agents at high CAV penetration rates. Comparative studies further show that the proposed method significantly enhances traffic efficiency and safety, maintaining robust performance even at lower CAV penetration rates.},
  archive      = {J_EAAI},
  author       = {Wenzhang Yang and Changyin Dong and Ziqian Zhang and Xu Chen and Hao Wang},
  doi          = {10.1016/j.engappai.2025.110584},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110584},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dual-module cooperative control method for on-ramp area in heterogeneous traffic flow using reinforcement learning},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class imbalance-aware domain specific transfer learning
approach for medical image classification: Application on COVID-19
detection. <em>EAAI</em>, <em>150</em>, 110583. (<a
href="https://doi.org/10.1016/j.engappai.2025.110583">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) show promise in medical image classification; however, their effectiveness is often constrained by the availability of large, annotated datasets, which are not always accessible. Additionally, the lack of medically relevant transfer models limits the potential of Transfer Learning (TL) in addressing this challenge. Existing TL methods typically employ conventional approaches that result in suboptimal performance and exhibit issues related to network bias, especially in imbalanced datasets. To overcome these limitations, we introduce a novel class imbalance-aware, domain-specific transfer learning framework (CIDSTL-Net) designed specifically for medical imaging tasks. CIDSTL-Net adopts a two-stage training approach: initially developing domain-specific models followed by fine-tuning on targeted medical datasets. This method incorporates an innovative class weighting strategy in its loss calculation to address dataset bias and enhances the transfer head network with a novel combination of fully connected, batch normalization, and dropout layers. Additionally, CIDSTL-Net employs cyclically scheduled learning rates to optimize parameter exploration and exploitation during training. We have rigorously evaluated CIDSTL-Net on four publicly available COVID-related datasets, covering chest X-ray and Computed Tomography (CT) images for the classification of COVID, Non-COVID, Normal, Pneumonia, and Lung Opacity conditions. The results demonstrate state-of-the-art performance with 5-fold cross-validation mean accuracies of 96.87 %, 96.50 %, 99.70 %, and 99.55 % for the respective datasets, marking significant improvements over existing methods. Among various CNN architectures tested, DenseNet-121 proved to be the most effective, offering superior accuracy with fewer parameters. Given the pressing global challenge posed by the COVID-19 pandemic, CIDSTL-Net holds significant potential to aid medical practitioners in the rapid and accurate classification of COVID-19 cases.},
  archive      = {J_EAAI},
  author       = {Marut Jindal and Birmohan Singh},
  doi          = {10.1016/j.engappai.2025.110583},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110583},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Class imbalance-aware domain specific transfer learning approach for medical image classification: Application on COVID-19 detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent evaluation of pavement friction at high speeds
with artificial intelligence powered three-dimensional laser imaging
technology. <em>EAAI</em>, <em>150</em>, 110580. (<a
href="https://doi.org/10.1016/j.engappai.2025.110580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate non-contact pavement friction evaluation at high speeds faces many challenges when using low-resolution (LR) three-dimensional (3D) texture images or other deficient texture data. With artificial intelligence (AI) powered 0.1-mm (0.1-mm) 3D laser imaging technology, this paper proposed a two-step deep learning (DL) network, named Friction-8KNet, for accurate and intelligent non-contact pavement friction evaluation at high speeds. Particularly, a 3D laser imagining device was employed to collect LR texture images at a speed of 30 mph, which were processed via a DL-based super-resolution (SR) algorithm to obtain 0.1 mm high-resolution (HR) images with a size of 8192 × 4096 (8K) pixels. The Friction-8KNet comprises a network backbone for texture feature extraction in Step 1 and a triple attention network for friction evaluation in Step 2. The network backbone is developed to precisely extract features of an HR image without requiring large graphics processing unit (GPU) memory. The triple attention net is designed with three function-specific attention modules to utterly mine the extracted features for accurate friction prediction. Experimental results show that Friction-8KNet can achieve 99.19 % prediction accuracy and transcends models using other texture data, including small HR 3D images, LR 3D images, and two-dimensional (2D) texture profiles. This research promotes an accurate and efficient measurement of pavement friction for production level in a non-contact manner in the future.},
  archive      = {J_EAAI},
  author       = {Guolong Wang and Kelvin C.P. Wang and Guangwei Yang},
  doi          = {10.1016/j.engappai.2025.110580},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110580},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Intelligent evaluation of pavement friction at high speeds with artificial intelligence powered three-dimensional laser imaging technology},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “understanding the disparities in mathematics
performance: An interpretability-based examination” [eng. Appl. Artif.
Intell. 133 part b (2024) 108109]. <em>EAAI</em>, <em>150</em>, 110579.
(<a href="https://doi.org/10.1016/j.engappai.2025.110579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Ismael Gómez-Talal and Luis Bote-Curiel and José Luis Rojo-Álvarez},
  doi          = {10.1016/j.engappai.2025.110579},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110579},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Corrigendum to “Understanding the disparities in mathematics performance: An interpretability-based examination” [Eng. appl. artif. intell. 133 part b (2024) 108109]},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Standalone and hybrid machine learning approaches to predict
sediment load in an alluvial channel. <em>EAAI</em>, <em>150</em>,
110578. (<a
href="https://doi.org/10.1016/j.engappai.2025.110578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant amount of sediment transported in an alluvial river can alter the morphology and shape of the river. Accurate prediction of sediment load is essential in studying the change in geomorphology and dynamics of rivers and also to evaluate its impact on aquatic ecosystems, infrastructure, and human activities dependent on water resources. The present study demonstrates framework for predicting sediment load in alluvial channels using both standalone and hybrid machine learning (ML) models. Multiple datasets collected from various river surveys and flume studies were used to evaluate the significance of key variables such as friction slope ( Sf ), channel discharge ( Q ), and bed shear stress ( τ b ) affecting the sediment transport employing ML models (Bagging (BA), Random Committee (RC)) and the standalone ML models (Multi-Layer Perceptron Regression (MLPR) and Reduced Error Pruning Tree (REPT). The hybrid Bagging-REPT (BA-REPT) model outperformed other models with a Nash-Sutcliffe Efficiency (NSE) of 0.915, followed by RC-REPT (NSE = 0.906). Among the various variables, friction slope ( S f ) was identified as the most influential variable affecting sediment transport behavior. It was also observed that Hybrid models can predict sediment transport behavior more accurately as compared to standalone models and empirical equations. The findings of the study thus demonstrate the importance of hybrid learning in addressing the nonlinear complexity of sediment transport processes.},
  archive      = {J_EAAI},
  author       = {Sanjit Kumar and Vishal Deshpande and Mayank Agarwal},
  doi          = {10.1016/j.engappai.2025.110578},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110578},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Standalone and hybrid machine learning approaches to predict sediment load in an alluvial channel},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight vision transformer with embedded hybrid
attention for quick response code defect classification. <em>EAAI</em>,
<em>150</em>, 110575. (<a
href="https://doi.org/10.1016/j.engappai.2025.110575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quick Response (QR) code label printing quality is crucial to product control. Due to the limited number of defect samples, unclear features, and the need to detect a large number of labels in real time, automated visual inspection faces challenges. For efficient and accurate automated visual defect recognition of printed QR code production, we propose a lightweight Vision Transformer network, Vision Transformer with Embedded Hybrid Attention (ViT-EHA). First, the Mixed Depthwise Convolution Block (MDConvBlock) is introduced to capture QR code defect details and feature information. This method additionally reduces the number of model parameters and computational costs. Furthermore, the LeAttention-Local Convolution-Multilayer Perceptron (LeALCM) module is proposed to enhance the ability to capture global information of the model and improve the effect of minor defect recognition. Ultimately, a hybrid attention (HA) module has been integrated to enhance the processing of low-level image features and to strengthen the interplay between shallow and deep features. To verify the validity and generalization of the model, the experimental results show that the proposed ViT-EHA method achieved an accuracy of 99.00% and a parameter count of 4.198 million (M) on the self-constructed dataset Code-10 (QR Code Dataset with 10 Classes), and the accuracy reached 98.33% and 97.73% on the public datasets NEU-CLS (Northeastern University Classification Dataset) and NEU-CLS-64 (Northeastern University Classification Dataset with 64 × 64 images), respectively.},
  archive      = {J_EAAI},
  author       = {Dianlu Hu and Lun Zhao and Yu Ren and Sen Wang and Xuanlin Ye and Haohan Zhang and Changqing Peng},
  doi          = {10.1016/j.engappai.2025.110575},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110575},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A lightweight vision transformer with embedded hybrid attention for quick response code defect classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating pre-trained convolutional neural networks and
foundation models as feature extractors for content-based medical image
retrieval. <em>EAAI</em>, <em>150</em>, 110571. (<a
href="https://doi.org/10.1016/j.engappai.2025.110571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image retrieval refers to the task of finding similar images for given query images in a database, with applications such as diagnosis support. While traditional medical image retrieval relied on clinical metadata, content-based medical image retrieval (CBMIR) depends on image features, which can be extracted automatically or semi-automatically. Many approaches have been proposed for CBMIR, and among them, using pre-trained convolutional neural networks (CNNs) is a widely utilized approach. However, considering the recent advances in the development of foundation models for various computer vision tasks, their application for CBMIR can also be investigated. In this study, we used several pre-trained feature extractors from well-known pre-trained CNNs and pre-trained foundation models and investigated the CBMIR performance on eight types of two-dimensional (2D) and three-dimensional (3D) medical images. Furthermore, we investigated the effect of image size on the CBMIR performance. Our results show that, overall, for the 2D datasets, foundation models deliver superior performance by a large margin compared to CNNs, with the general-purpose self-supervised model for computational pathology (UNI) providing the best overall performance across all datasets and image sizes. For 3D datasets, CNNs and foundation models deliver more competitive performance, with contrastive learning from captions for histopathology model (CONCH) achieving the best overall performance. Moreover, our findings confirm that while using larger image sizes (especially for 2D datasets) yields slightly better performance, competitive CBMIR performance can still be achieved even with smaller image sizes. Our codes to reproduce the results are available at: https://github.com/masih4/MedImageRetrieval .},
  archive      = {J_EAAI},
  author       = {Amirreza Mahbod and Nematollah Saeidi and Sepideh Hatamikia and Ramona Woitek},
  doi          = {10.1016/j.engappai.2025.110571},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110571},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Evaluating pre-trained convolutional neural networks and foundation models as feature extractors for content-based medical image retrieval},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal image-guided complementary masking with multiscale
fusion for multi-spectral image semantic segmentation. <em>EAAI</em>,
<em>150</em>, 110569. (<a
href="https://doi.org/10.1016/j.engappai.2025.110569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of visible and thermal image is a kind of significant method for harsh environments. Most existing works focus on designing a multi-modal feature fusion module. However, these works may result in over-dependence on a specific modality and a lack of consideration for local and global context-aware information. Motivated by these issues, (1) a thermal image-guided complementary masking strategy is proposed to encourage the network to focus on regions with abundant semantic information; (2) a multi-modal fusion module is developed to integrate both local and global information and ensure consistency for semantic segmentation; (3) a self-distillation loss between unmasked and masked input modalities is introduced to enhance the robustness and consistency of the network. Particularly, the proposed masking strategy can force the network to concentrate on the meaningful area in all modalities, and thus the network can enhance the ability to connect context information. Experimental results on three public datasets demonstrate the superiority of our model.},
  archive      = {J_EAAI},
  author       = {Zeyang Chen and Mingnan Hu and Bo Chen},
  doi          = {10.1016/j.engappai.2025.110569},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110569},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal image-guided complementary masking with multiscale fusion for multi-spectral image semantic segmentation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An electric vehicle sales hybrid forecasting method based on
improved sentiment analysis model and secondary decomposition.
<em>EAAI</em>, <em>150</em>, 110561. (<a
href="https://doi.org/10.1016/j.engappai.2025.110561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The swift proliferation of electric vehicles has triggered profound shifts in consumer behavior, emphasizing the critical role of precise sales forecasts as the cornerstone for data-driven policy and production planning by both governments and electric vehicle manufacturers. However, extant forecasting models face challenges in accurately capturing consumer sentiment conveyed by online reviews and effectively extracting multiscale features of high-frequency sequences. Therefore, an electric vehicle sales hybrid forecasting method based on BERT-Bi-LSTM (Bidirectional Encoder Representations from Transformers-Bidirectional long short-term memory) sentiment analysis and secondary decomposition is proposed. First, the BERT-Bi-LSTM model is developed to perform sentiment analysis on online reviews. The model can better capture the relationship between each word and its surrounding words in text information. Second, a secondary decomposition model is constructed to decompose multisource data series, it can extract the seasonal components of the series and high-frequency complex data features, also solve potential issues of incomplete decomposition that may arise from a single decomposition. Finally, machine learning methods are utilized for hybrid forecasting. To verify the effectiveness of the proposed model, multiple sets of comparative experiments are conducted. The empirical results indicate the proposed model has higher prediction accuracy and robustness.},
  archive      = {J_EAAI},
  author       = {Jinpei Liu and Hui Pan and Rui Luo and Huayou Chen and Zhifu Tao and Zhijing Wu},
  doi          = {10.1016/j.engappai.2025.110561},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110561},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An electric vehicle sales hybrid forecasting method based on improved sentiment analysis model and secondary decomposition},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Causal explanation of nitrogen oxide emission predictions
for fluid catalytic cracking unit based on convergent cross mapping:
Predict the future and explain how. <em>EAAI</em>, <em>150</em>, 110560.
(<a href="https://doi.org/10.1016/j.engappai.2025.110560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial chemical processes are inherently intricate, characterized by prolonged operational sequences and correlations among features. Solely utilizing temporal information limits the prediction precision of deep learning methods. Moreover, causative features identified based on data may not align with the principles of chemical process. To solve these problems, this study proposes a spatial–temporal information based deep learning method, attention-based temporal graph convolutional network and convergent cross mapping (ATGCN-CCM). The devices are abstracted as nodes in a computational graph (CG) to represent the process, enabling the incorporation of spatial information into the predictive model. Attention mechanism is conducted within each node to dynamically weight the features. The CG is also used to select input features for causal analysis, ensuring that the identified causative features are not only consistent with the characteristics of the data, but also with the prior knowledge of the process. ATGCN-CCM is applied to datasets from industrial fluid catalytic cracking (FCC) units for nitrogen oxides (NOx) concentration prediction and causative feature identification. The prediction results demonstrate superior precision of ATGCN-CCM compared to some state-of-the-art spatial feature based, temporal feature based and hybrid methods. The identified features exhibit strong alignment with the principles of the chemical processes and the field experiences, thereby significantly enhancing model interpretability. The proposed ATGCN-CCM method illustrate its advanced capabilities in both precision and robustness, compared with attention-based methods and other causal analysis methods.},
  archive      = {J_EAAI},
  author       = {Han Jiang and Shucai Zhang and Jingru Liu and Xin Peng and Weimin Zhong},
  doi          = {10.1016/j.engappai.2025.110560},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110560},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Causal explanation of nitrogen oxide emission predictions for fluid catalytic cracking unit based on convergent cross mapping: Predict the future and explain how},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Keypoint-guided feature enhancement and alignment for
cross-resolution vehicle re-identification. <em>EAAI</em>, <em>150</em>,
110557. (<a
href="https://doi.org/10.1016/j.engappai.2025.110557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resolution mismatch between low-resolution query images and high-resolution gallery images in vehicle re-identification is rarely studied but ubiquitous in real-world applications. An intuitive approach to solving cross-resolution vehicle re-identification is to utilize super-resolution algorithms to recover detailed information from low-resolution query images. However, vehicle super-resolution algorithms not only recover the detailed information of the vehicle but also enhance the background noise, which would degrade the re-identification performance. In addition, the view mismatch problem also significantly limits the performance of vehicle re-identification. To handle these problems, we propose a novel Keypoint Guiding Network, which simultaneously addresses the problems of resolution mismatch and view mismatch from the perspective of keypoints in an end-to-end learning framework, for cross-resolution vehicle re-identification. In particular, we first generate a set of vehicle keypoints via an effective Gaussian localization method, and then adaptively construct two keypoint-based guidances using attention models. We integrate these two guidances into vehicle super-resolution and view alignment to handle the problems of resolution mismatch and view mismatch respectively. Moreover, to alleviate the heterogeneity between super-resolution query images and high-resolution gallery ones, we design a dual-path teacher–student distillation scheme to narrow their feature distributions. Comprehensive experiments on two down-sampled benchmark datasets demonstrate the effectiveness of our Keypoint Guiding Network against the state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Aihua Zheng and Longfei Zhang and Weijun Zhang and Zi Wang and Chenglong Li and Xiaofei Sheng},
  doi          = {10.1016/j.engappai.2025.110557},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110557},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Keypoint-guided feature enhancement and alignment for cross-resolution vehicle re-identification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Runner system geometry prediction using variational
autoencoder deep learning model. <em>EAAI</em>, <em>150</em>, 110555.
(<a href="https://doi.org/10.1016/j.engappai.2025.110555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The novelty of this article is the choice of the architecture of neural networks for fluid channel topology optimization and its application in the design of multi-cavity injection molds. A generative deep learning model was developed to extract characteristics representing the inverse field of the permeability of a fluid in a porous medium, which in turn represents the runner system geometry of a thermoplastic injection mold. The model comprises a variational autoencoder network and multilayer perceptron. The characteristics extracted from the variational autoencoder are used as a set of multilayer perceptron output vectors, whereas the input data are determined by the positions of the input and outputs of the injection channels. The field of the inverse permeability in each case was obtained by topology optimization using a heuristic algorithm. The trained model displayed statistical metrics indicating good performance and task generalizability. The mean absolute error was 0.0106 for the entire dataset. Speed up compared to traditional computational fluid dynamics software was 625 times faster in one case. For 150 cases, it was 76907 times faster⁠. The purpose of generating a deep learning model in this area is to reduce the design time of injection molds and the computational requirements. The developed neural network reduces the runner system volume by 16% or its hydraulic resistance by 25%.},
  archive      = {J_EAAI},
  author       = {Evgenii Kurkin and Jose Gabriel Quijada Pioquinto and Vladislava Chertykovtseva and Evgenii Minaev},
  doi          = {10.1016/j.engappai.2025.110555},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110555},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Runner system geometry prediction using variational autoencoder deep learning model},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection considering synergy between features based
on soft neighborhood rough sets. <em>EAAI</em>, <em>150</em>, 110553.
(<a href="https://doi.org/10.1016/j.engappai.2025.110553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighborhood entropy-based measures provide a powerful framework for feature selection to select features that are more useful for classification. However, most of these feature selection methods do not pay attention to the complementarities and synergies between features, as well as the interactions between them. In addition, most existing neighborhood rough sets are subjective in the determination of neighborhood radius when dealing with classification problems, which may lead to the omission of useful information. To solve these problems, a soft neighborhood rough set model-based feature selection method (SNCMI) is proposed. Firstly, the method dynamically adjusts the neighborhood radius, significantly minimizing its influence on the uncertainty measurement. Secondly, it comprehensively considers the correlation, redundancy, complementarity, and synergy between features through soft neighborhood uncertainty measures. Thirdly, an innovative objective evaluation function is introduced to evaluate the interactions between features. Finally, we compare the proposed SNCMI algorithm with several well-known feature selection algorithms on twenty public datasets and demonstrate the effectiveness of SNCMI.},
  archive      = {J_EAAI},
  author       = {Lubin Chen and Jinkun Chen and Yaojin Lin},
  doi          = {10.1016/j.engappai.2025.110553},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110553},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature selection considering synergy between features based on soft neighborhood rough sets},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forecasting train travel times of china–europe railway
express through a hybrid deep learning model optimized with a
bandit-based approach. <em>EAAI</em>, <em>150</em>, 110552. (<a
href="https://doi.org/10.1016/j.engappai.2025.110552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the globalization of economic trade, the China–Europe Railway Express (CRE) has emerged as a crucial means of international freight transportation. However, since the travel process of CRE trains is subject to various factors (e.g., customs clearance efficiency, weather changes, etc.), existing models struggle to handle the complex nonlinear characteristics of the travel time data, failing to achieve accurate train travel time predictions. This significantly affects the scheduling and utilization of capacity resources along the CRE routes. To address this issue, this study proposes a novel hybrid deep learning model, i.e., Discrete Wavelet Transform (DWT)-Convolutional Neural Networks (CNN)-Bidirectional Gated Recurrent Unit (BiGRU) (DWT-CNN-BiGRU). Specifically, the DWT technique is first used to preprocess historical train travel time data to reduce noise interference and improve data quality. Then, the CNN module focuses on extracting local spatial features from the data, whereas the BiGRU module emphasizes its long-term temporal dependencies. Furthermore, a bandit-based approach is applied to hyperparameter optimization to further exploit model potentials. By testing on a real-life CRE dataset, the DWT-CNN-BiGRU model demonstrates superior prediction accuracy with root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) values respectively equal to 10.7347 h, 7.5482 h, and 2.2034%, and it outperforms the other ten popular baseline models. In conclusion, the proposed DWT-CNN-BiGRU model features a lightweight structure and strong robustness, offering reliable technical support to alleviate capacity resource shortages and improve the service quality of CRE.},
  archive      = {J_EAAI},
  author       = {Yongxiang Zhang and Liting Gu and Jingwei Guo and Xu Yan and Xin Hu and Zhen-Song Chen},
  doi          = {10.1016/j.engappai.2025.110552},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110552},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting train travel times of China–Europe railway express through a hybrid deep learning model optimized with a bandit-based approach},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid architecture of sparse convolutional neural
network-transformer for enhanced spatial-geometric feature learning in
surface reconstruction. <em>EAAI</em>, <em>150</em>, 110550. (<a
href="https://doi.org/10.1016/j.engappai.2025.110550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based methods have garnered significant attention in indoor scene reconstruction tasks. However, researchers have often overlooked the crucial role of the surface prediction stage. Our study specifically focuses on this phase. According to our experiments and analysis, this phase primarily addresses spatial voxel occupancy and geometric structure maintenance. Simple structural designs are insufficient to effectively solve these problems. To address these challenges, we propose a hybrid model, which combines the strengths of Convolution Neural Networks and Transformer architectures for fine reconstruction. Additionally, we introduce several new techniques, including the Sparse Positional Attention mechanism, Sparse Channel Decoding Block, and Mixed Feature Fusion mechanism. These techniques, leveraging the characteristics of sparse computation, enhance feature utilization in both spatial and channel dimensions. With limited training and testing resources, our network achieves optimal results on the ScanNet dataset, improving precision and F-score by 2.1% and 1.6%, respectively, and reducing the Chamfer distance to 0.055 m. To our knowledge, our model is the first use of hybrid structures in the surface prediction phase of an indoor scene reconstruction task. Moreover, we hope that our design and analysis can provide a new paradigm for task network design in this phase.},
  archive      = {J_EAAI},
  author       = {Mingyang Li and Wei Zhang and Yanyan Liu and Xiang Feng and Changsong Liu and Yimeng Fan and Lixue Xu},
  doi          = {10.1016/j.engappai.2025.110550},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110550},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid architecture of sparse convolutional neural network-transformer for enhanced spatial-geometric feature learning in surface reconstruction},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing pose estimation for mobile robots: A comparative
analysis of deep reinforcement learning algorithms for adaptive extended
kalman filter-based estimation. <em>EAAI</em>, <em>150</em>, 110548. (<a
href="https://doi.org/10.1016/j.engappai.2025.110548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Extended Kalman Filter (EKF) is a widely used algorithm for state estimation in control systems. However, its lack of adaptability limits its performance in dynamic and uncertain environments. To address this limitation, we used an approach that leverages Deep Reinforcement Learning (DRL) to achieve adaptive state estimation in the EKF. By integrating DRL techniques, we enable the state estimator to autonomously learn and update the values of the system dynamics and measurement noise covariance matrices, Q and R, based on observed data, which encode environmental changes or system failures. In this research, we compare the performance of four DRL algorithms, namely Deep Deterministic Policy Gradient (DDPG), Twin Delayed Deep Deterministic Policy Gradient (TD3), Soft Actor-Critic (SAC), and Proximal Policy Optimization (PPO), in optimizing the EKF’s adaptability. The experiments are conducted in both simulated and real-world settings using the Gazebo simulation environment and the Robot Operating System (ROS). The results demonstrate that the DRL-based adaptive state estimator outperforms traditional methods in terms of estimation accuracy and robustness. The comparative analysis provides insights into the strengths and limitations of different DRL agents, showing that the TD3 and the DDPG are the most effective algorithms, with TD3 achieving superior performance, resulting in a 91% improvement over the classic EKF, due to its delayed update mechanism that reduces training noise. This research highlights the potential of DRL to advance state estimation algorithms, offering valuable insights for future work in adaptive estimation techniques.},
  archive      = {J_EAAI},
  author       = {Islem Kobbi and Abdelhak Benamirouche and Mohamed Tadjine},
  doi          = {10.1016/j.engappai.2025.110548},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110548},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Enhancing pose estimation for mobile robots: A comparative analysis of deep reinforcement learning algorithms for adaptive extended kalman filter-based estimation},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks with scattering transform for network
anomaly detection. <em>EAAI</em>, <em>150</em>, 110546. (<a
href="https://doi.org/10.1016/j.engappai.2025.110546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As cyber-attacks become increasingly sophisticated and frequent, the demand for advanced and proactive Network Intrusion Detection Systems (NIDS) has become more urgent than ever. To address critical shortcomings in existing NIDS approaches, such as high false-positive rates that trigger unnecessary alerts, inability to capture complex relationships between network nodes, and oversimplified node representation initialization that fails to reflect real-world network behaviors, we introduce a novel solution called Scattering Transform Edge Graph (STEG). STEG harnesses the wavelet scattering transform to extract edge feature information and employs a graph-based representation to effectively capture the topological relationships between network nodes. Additionally, we enhance STEG by incorporating node embedding techniques like DeepWalk for initializing node representations, moving beyond conventional uniform initialization methods. Comprehensive evaluations on benchmark NIDS datasets reveal that STEG outperforms current state-of-the-art methods. Moreover, the integration of Node2Vec-based initialization further boosts performance, marking a significant advancement in the effectiveness of network intrusion detection systems.},
  archive      = {J_EAAI},
  author       = {Abdeljalil Zoubir and Badr Missaoui},
  doi          = {10.1016/j.engappai.2025.110546},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110546},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph neural networks with scattering transform for network anomaly detection},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparative analysis and evaluation of ageing forecasting
methods for semiconductor devices in online health monitoring.
<em>EAAI</em>, <em>150</em>, 110545. (<a
href="https://doi.org/10.1016/j.engappai.2025.110545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semiconductor devices, especially MOSFETs (Metal–oxide–semiconductor field-effect transistor), are crucial in power electronics, but their reliability is affected by ageing processes influenced by cycling and temperature. The primary ageing mechanism in discrete semiconductors and power modules is the bond wire lift-off, caused by crack growth due to thermal fatigue. The process is empirically characterized by exponential growth and an abrupt end of life, making long-term ageing forecasts challenging. This research presents a comprehensive comparative assessment of different forecasting methods for MOSFET failure forecasting applications. Classical tracking, statistical forecasting and Neural Network (NN) based forecasting models are implemented along with novel Temporal Fusion Transformers (TFTs). A comprehensive comparison is performed assessing their MOSFET ageing forecasting ability for different forecasting horizons. For short-term predictions, all algorithms result in acceptable results, with the best results produced by classical NN forecasting models at the expense of higher computations. For long-term forecasting, only the TFT is able to produce valid outcomes owing to the ability to integrate covariates from the expected future conditions. Additionally, TFT attention points identify key ageing turning points, which indicate new failure modes or accelerated ageing phases.},
  archive      = {J_EAAI},
  author       = {Adrian Villalobos and Iban Barrutia and Rafael Peña-Alzola and Tomislav Dragicevic and Jose I. Aizpurua},
  doi          = {10.1016/j.engappai.2025.110545},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110545},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Comparative analysis and evaluation of ageing forecasting methods for semiconductor devices in online health monitoring},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of the flexural strength and elastic modulus of
cementitious materials reinforced with carbon nanotubes: An approach
with artificial intelligence. <em>EAAI</em>, <em>150</em>, 110544. (<a
href="https://doi.org/10.1016/j.engappai.2025.110544">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, researchers investigated incorporating carbon nanotubes (CNTs) to improve the mechanical properties of cementitious materials. Recently, few studies developed Machine Learning (ML)-based predictive models to maximize insights from limited experimental data. However, these models often fail to identify key parameters and their complex correlations with mechanical properties. This study aims to improve the prediction of the mechanical properties of CNT-reinforced cementitious materials, specifically, elastic modulus and flexural strength, by leveraging multiple predictive Artificial Intelligence (AI)-based models. Deep Neural Networks (DNN), ensemble-bagging, and Support Vector Regression (SVR) were proposed and rigorously tested to predict the flexural strength and elastic modulus of the composite material. The feature selection was performed based on the domain knowledge and the informative metrics including the permutation importance analyses and Pearson&#39;s correlation analyses. The research identified several parameters that have traditionally been overlooked but proved to be critical. With a total of nineteen input parameters analyzed, the findings indicate that the mechanical properties of the composite material are primarily influenced by surfactant-to-CNT mass ratio, CNT content and physical properties, as well as ultrasonication process. Conversely, sand type and CNT purity are found to have minimal importance to the change in mechanical properties. In addition, the proposed DNN models outperform other ML models in predicting both flexural strength and elastic modulus, achieving R-squared values of 0.93 and 0.86 with mean absolute percentage errors of 8.16% and 7.22%, respectively.},
  archive      = {J_EAAI},
  author       = {Mahyar Ramezani and Do-Eun Choe and Abdur Rasheed},
  doi          = {10.1016/j.engappai.2025.110544},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110544},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of the flexural strength and elastic modulus of cementitious materials reinforced with carbon nanotubes: An approach with artificial intelligence},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reparameterization convolutional neural networks for
handling imbalanced datasets in solar panel fault classification.
<em>EAAI</em>, <em>150</em>, 110541. (<a
href="https://doi.org/10.1016/j.engappai.2025.110541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solar photovoltaic technology has grown significantly as a renewable energy, with unmanned aerial vehicles equipped with thermal infrared cameras effectively inspecting solar panels. However, long-distance capture and low-resolution infrared cameras make the targets small, complicating feature extraction. Additionally, the large number of normal photovoltaic modules results in a significant imbalance in the dataset. Furthermore, limited computing resources on unmanned aerial vehicles further challenge real-time fault classification. These factors limit the performance of current fault classification systems for solar panels. The multi-scale and multi-branch Reparameterization of convolutional neural networks can improve model performance while reducing computational demands at the deployment stage, making them suitable for practical applications. This study proposes an efficient framework based on reparameterization for infrared solar panel fault classification. We propose a Proportional Balanced Weight asymmetric loss function to address the class imbalance and employ multi-branch, multi-scale convolutional kernels for extracting tiny features from low-resolution images. The designed models were trained with Exponential Moving Average for better performance and reparameterized for efficient deployment. We evaluated the designed models using the Infrared Solar Module dataset. The proposed framework achieved an accuracy of 83.8% for the 12-Class classification task and 74.0% for the 11-Class task, both without data augmentation to enhance generalization. The accuracy improvements of up to 16.4% and F1-Score gains of up to 18.7%. Additionally, we achieved an inference speed that is 3.4 times faster than the training speed, while maintaining high fault classification performance.},
  archive      = {J_EAAI},
  author       = {Jielong Guo and Chak Fong Chong and Pedro Henriques Abreu and Chao Mao and Jiaxuan Li and Chan-Tong Lam and Benjamin K. Ng},
  doi          = {10.1016/j.engappai.2025.110541},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110541},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reparameterization convolutional neural networks for handling imbalanced datasets in solar panel fault classification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain data with ransomware detection based on deep feed
forward maxout network. <em>EAAI</em>, <em>150</em>, 110538. (<a
href="https://doi.org/10.1016/j.engappai.2025.110538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of the internet and technology has become more common and essential in daily life. The main risk to the network is malware, and ransomware is considered a destructive kind of malware. The ransomware resulted in massive data losses and produced huge financial losses. In order to overcome this issue, the Deep Feed Forward Maxout Network (DFFMN) is developed to detect ransomware using blockchain data in this study. To accomplish this, initially, the input data from the blockchain is given to feature extraction to extract features. Then, data normalization is performed and the extracted features are fused together using a Deep Belief Network (DBN) with Lorentzian similarity. Lastly, ransomware detection is executed by utilizing the DFFMN technique, which is created by the integration of Deep Maxout Network and Deep Feedforward Neural Network. The experimental results exemplify that the proposed DFFMN acquired accuracy value of 91.57 %, sensitivity value of 91.04 %, precision value of 89.35 %, False Negative Rate (FNR) of 0.086, False Positive Rate (FPR) of 0.090 and F-Measure of 89.44 %.},
  archive      = {J_EAAI},
  author       = {Vemireddi Srinadh and Buddi Padmaja and Dhanunjaya Rao Chigurukota and Mallikharjuna Rao Karreddula and Balajee Maram and Smritilekha Das},
  doi          = {10.1016/j.engappai.2025.110538},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110538},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Blockchain data with ransomware detection based on deep feed forward maxout network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-branch crack segmentation network with multi-shape
kernel based on convolutional neural network and mamba. <em>EAAI</em>,
<em>150</em>, 110536. (<a
href="https://doi.org/10.1016/j.engappai.2025.110536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cracks are one of the most common pavement diseases. If not promptly repaired, they will hasten the deterioration of the road. Semantic segmentation is the most convenient pavement crack detection method to assess the damage level. Convolutional neural networks (CNN) excel at extracting local spatial information, but they have limitations in capturing global contextual information. Therefore, a dual-branch crack segmentation network (DBCNet) with Mamba and multi-shape convolutional kernels is proposed. First, a dual-branch encoder is employed to extract both spatial and contextual information, consisting of the spatial branch and the context branch. The cross-like block (CrossBlock) that excels in extracting spatial information horizontally and vertically from cracks is proposed. Multiple CrossBlocks are stacked to construct a lightweight network as a spatial branch. The improved Visual State Space Model (VMamba) serves as a context branch for modeling long-range dependencies for more accurate pixel-by-pixel segmentation. Second, the Feature Fusion Module (FFM), based on squeeze-and-excitation attention, is constructed to dynamically fuse the features from the two branches layer by layer. Third, a Cross-aware Mamba Module (CMM) with the hybrid CNN-Mamba architecture is proposed to compose the decoder. Fourth, comprehensive evaluations were conducted on three public datasets. Performs on multiple metrics achieved considerable progress, outperforming the seven state-of-the-art models. The mean intersection over union (mIoU) on Deepcrack, CrackTree 260, and CFD reached 87.87%, 85.34%, and 81.35%, respectively. Code and data will be available at https://github.com/name191/DBCNet .},
  archive      = {J_EAAI},
  author       = {Jianming Zhang and Dianwen Li and Zhigao Zeng and Rui Zhang and Jin Wang},
  doi          = {10.1016/j.engappai.2025.110536},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110536},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dual-branch crack segmentation network with multi-shape kernel based on convolutional neural network and mamba},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FA-SconvAE-LSTM: Feature-aligned stacked convolutional
autoencoder with long short-term memory network for soft sensor
modeling. <em>EAAI</em>, <em>150</em>, 110535. (<a
href="https://doi.org/10.1016/j.engappai.2025.110535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of soft sensor technology has enabled the real-time estimation of critical parameters in complex industrial processes, where direct measurement through hardware sensors is often infeasible. Industrial process data typically exhibit both spatial correlations and temporal dependencies, necessitating sophisticated modeling approaches to capture these characteristics effectively. In this study, a spatio-temporal model, termed the feature-aligned stacked convolutional autoencoder with long short-term memory, is proposed to develop soft sensors for nonlinear dynamic industrial processes. The proposed model begins with the systematic training of a stacked convolutional autoencoder using a layer-by-layer pre-training technique. This approach facilitates the extraction of high-level spatial feature representations from the process variables. To address the issue of feature misalignment in the spatial features extracted by the stacked convolutional autoencoder, a feature alignment strategy is implemented, ensuring that the extracted spatial features are properly aligned. Subsequently, the aligned spatial features are fed into a long short-term memory network to capture temporal dependencies, with quality variables serving as the output for soft sensor development. The effectiveness and superiority of the proposed method are demonstrated through experiments conducted on two industrial processes: the sulfur recovery unit and the multiphase flow process. Comparative analyses with other state-of-the-art methods reveal that the proposed model achieves the highest performance, with R 2 values of 0.86222 for the sulfur recovery unit and 0.94307 for the multiphase flow process, outperforming all compared methods.},
  archive      = {J_EAAI},
  author       = {Ping Wu and Zengdi Miao and Ke Wang and Jinfeng Gao and Xujie Zhang and Siwei Lou and Chunjie Yang},
  doi          = {10.1016/j.engappai.2025.110535},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110535},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {FA-SconvAE-LSTM: Feature-aligned stacked convolutional autoencoder with long short-term memory network for soft sensor modeling},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted motion planning and layout design of
robotic cellular manufacturing systems. <em>EAAI</em>, <em>150</em>,
110530. (<a
href="https://doi.org/10.1016/j.engappai.2025.110530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A surrogate-assisted multi-objective evolutionary algorithm is proposed for simultaneous optimization of robot motion planning and layout design in robotic cellular manufacturing systems. A sequence-pair is used to represent the layout of components in a robotic cell to avoid overlapping in the evolutionary computation. The robot motion planning with Rapidly exploring Random Trees Star (RRT*) is applied to compute the total operation time of a robot arm for each layout. Non-dominated Sorting Genetic Algorithm II (NSGA-II) is used to minimize the total required layout area and the operation time for a robot arm. The proposed surrogate model can estimate the robot’s operation time with 98% of accuracy without explicit computations of the motion planning algorithm. The experimental results with a physical 6 Degree of Freedom (DOF) manipulator show that the total computation time is approximately 1/400, significantly shorter than the conventional methods.},
  archive      = {J_EAAI},
  author       = {Tomoya Kawabe and Tatsushi Nishi and Ziang Liu and Tomofumi Fujiwara},
  doi          = {10.1016/j.engappai.2025.110530},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110530},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Surrogate-assisted motion planning and layout design of robotic cellular manufacturing systems},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-labeled framework with semi-supervised ball k-means
clustering-based synthetic example generation for semi-supervised
classification in industrial applications. <em>EAAI</em>, <em>150</em>,
110528. (<a
href="https://doi.org/10.1016/j.engappai.2025.110528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While self-labeled methods can exploit labeled and unlabeled instances to train classifiers, they are severely restricted by the labeled instance number and distribution. One category of the existing solutions tends to combine oversampling techniques, with the goal of creating labeled synthetic instances to improve the labeled instance number and distribution. The synthetic example generation-based framework for semi-supervised classification (SEG-SSC) is the only state-of-the-art instance of the above category. Nevertheless, it still suffers from the following issues: a) relying on 7 hyper-parameters, b) ineffectively improving the labeled instance number and distribution in sparser regions with fewer labeled instances, and c) having a relatively high time complexity of O ( nlogn + G×n ). To this end, a self-labeled framework with semi-supervised ball k -means clustering-based synthetic example generation (SEGBallKmeans-SSC), having only one hyper-parameter and the time complexity of O ( n ), is proposed for semi-supervised classification. The main uniqueness is that: a) firstly, a semi-supervised ball k -means clustering (SSBallKmeans) with a compact-cluster assumption is proposed to divide semi-supervised data into compact ball clusters, intending to reveal regions with different labeled instance numbers; b) secondly, an SSBallKmeans-based oversampling method (OMSSBallKmean) is proposed to create more labeled synthetic instances on compact ball clusters with fewer labeled instances, intending to improve the labeled instance number and distribution, especially on sparser regions with fewer labeled instances. After that, any self-labeled method are executed on improved labeled instances and unlabeled instances to train more accurate classifiers. Experiments have proven that SEGBallKmeans-SSC outperforms 7 state-of-the-art self-labeled frameworks on extensive benchmark datasets from various industrial applications.},
  archive      = {J_EAAI},
  author       = {Junnan Li and Lufeng Wang and Shun Fu ( Revision ) and Wei Fu and Xin Pan},
  doi          = {10.1016/j.engappai.2025.110528},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110528},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-labeled framework with semi-supervised ball K-means clustering-based synthetic example generation for semi-supervised classification in industrial applications},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning-based sentiment flow analysis model for
predicting financial risk of listed companies. <em>EAAI</em>,
<em>150</em>, 110522. (<a
href="https://doi.org/10.1016/j.engappai.2025.110522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of natural language processing technology, more studies are applying deep learning models to extract features from unstructured data and predict corporate financial risk through horizontal comparisons. This paper proposes the Sentiment Flow Analysis (SFA) model designed to capture the nuanced emotional dynamics present in corporate annual reports and analyst reports from a longitudinal perspective. By leveraging advanced contextual embeddings from a Transformer architecture and employing a sophisticated recurrent neural network, the model effectively processes sequential data, allowing for a comprehensive understanding of sentiment trends over a five-year period. The effectiveness of our model was validated through experiments predicting the removal of special treatment (ST) status for 344 listed companies under special treatment in 2022 and 2023, achieving a prediction accuracy of up to 82.27%. Compared to state-of-the-art models in the same field, our model demonstrates improvements in prediction accuracy and recall, showcasing the application of Artificial Intelligence (AI) in financial risk assessment.},
  archive      = {J_EAAI},
  author       = {Feifei Tao and Wenya Wang and Rongke Lu},
  doi          = {10.1016/j.engappai.2025.110522},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110522},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep learning-based sentiment flow analysis model for predicting financial risk of listed companies},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient self-learning disturbance-resistant control for
high-speed flight vehicle based on dual heuristic dynamic programming.
<em>EAAI</em>, <em>150</em>, 110521. (<a
href="https://doi.org/10.1016/j.engappai.2025.110521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in high-speed flight vehicles (HSFVs) have sparked significant interest due to their strategic importance and emerging civilian applications. These vehicles exhibit strong nonlinearities and multi-axis interactions and are usually influenced by uncertainties such as modeling errors, parameter perturbations, and external disturbances. Neglecting these challenges in attitude controller design can lead to trajectory tracking deviations and potential mission failure due to instability. Motivated by this issue, an efficient disturbance-resistant control method with online self-learning capability is proposed. Firstly, a feedback linearization baseline controller combined with finite-time extended state observers (FESOs) is designed to ensure stability. Next, a dual heuristic dynamic programming (DHP) controller with critic-only structure is developed for online performance optimization. Update laws of the critic neural network (NN) are derived based on policy iteration, and zero-sum game (ZSG) theory is incorporated to enhance the system’s adaptive capacity to uncertainties. Lyapunov theory is subsequently employed to validate the convergence of network weights and the system stability. The proposed method, compared to common adaptive dynamic programming (ADP) approaches for attitude control, demonstrates superior learning efficiency and guarantees the convergence of online learning without the necessity for pre-training. Simulation results indicate that the method equips the HSFV with robust dynamic performance throughout a broad flight envelope, with attitude tracking errors constrained to less than 0.5°. Future research will focus on developing fault-tolerant and prescribed performance control frameworks with online learning ability, representing an advancement in the current technique.},
  archive      = {J_EAAI},
  author       = {Xu Huang and Jiarun Liu and Yue Peng and Yuan Zhang and Zhaolei Wang and Weimin Bao},
  doi          = {10.1016/j.engappai.2025.110521},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110521},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient self-learning disturbance-resistant control for high-speed flight vehicle based on dual heuristic dynamic programming},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Remote sensing scene classification with relation-aware
dynamic graph neural networks. <em>EAAI</em>, <em>150</em>, 110513. (<a
href="https://doi.org/10.1016/j.engappai.2025.110513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing scene classification (RSSC) is challenging due to the complexity and diversity of scenes. Existing methods need help to capture long-range and structural relationships among image regions, limiting their performance. This paper proposes a novel graph-based model that learns relation-aware dynamic graph representations for remote sensing scene classification tasks. The proposed model consists of three main components: Multi-Scale Feature Extraction (MSFE), Relation-Aware Graph Processing (RAGP), and Scene Classification with Weighted Pooling (SCWP). MSFE uses a multi-scale feature extraction strategy to generate low-level feature nodes from remote sensing images. RAGP applies several cascaded graph processing blocks to dynamically learn the relations between nodes in high-level semantic spaces using relation-aware graph convolutional and node feature update operators. SCWP performs weighted pooling on the learned node features from RAGP to obtain global representations of remote sensing images and makes scene decisions using a fully feed-forward network-based classifier. We evaluate our model on three benchmark datasets and compare it with state-of-the-art RSSC methods. Our experimental results show that our model outperforms existing methods on all three datasets, demonstrating the effectiveness of a graph-based model with the proposed techniques for RSSC tasks.},
  archive      = {J_EAAI},
  author       = {Qionghao Huang and Fan Jiang and Changqin Huang},
  doi          = {10.1016/j.engappai.2025.110513},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110513},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Remote sensing scene classification with relation-aware dynamic graph neural networks},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning adaptive distractor-aware-suppression appearance
model for visual tracking. <em>EAAI</em>, <em>150</em>, 110511. (<a
href="https://doi.org/10.1016/j.engappai.2025.110511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some algorithms based on Siamese networks aim to improve the representation of target by combining background and target information, but they seldom consider adjusting the influence of background distractors on appearance modeling. In this paper, we propose an adaptive distractor suppression appearance model for robust visual tracking. Firstly, to fully utilize the valuable clues provided by the background, a new distractor model is specially designed to determine the weight of each distractor based on the similarity between the distractor and the target. This model adaptively fuses the distractors according to their weights, thereby focusing on distractors that are highly similar to the target. Secondly, a distractor model transformation strategy is constructed to rank the influence of the distractor model on appearance modeling, which mines the similarity relationship between the background distractor and target using regularized linear regression, effectively controlling the influence of the distractor model. Finally, we unify them into a learning adaptive distractor-aware-suppression appearance model for improving the discriminant ability of the appearance model, which selectively introduces the distractor model to suppress distractors according to the intensity of the distractor, achieving robust tracking in the presence of background interference. Experimental results on six benchmarks demonstrate that the proposed tracker achieves excellent performance in various challenging tracking tasks, particularly when facing background interference, where the tracking precision and success rate of our algorithm reach state-of-the-art levels.},
  archive      = {J_EAAI},
  author       = {Huanlong Zhang and Linwei Zhu and Yanchun Zhao and Fusheng Li and Deshuang Huang},
  doi          = {10.1016/j.engappai.2025.110511},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110511},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning adaptive distractor-aware-suppression appearance model for visual tracking},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiagent architecture for industrial internet of things
safety applications. <em>EAAI</em>, <em>150</em>, 110495. (<a
href="https://doi.org/10.1016/j.engappai.2025.110495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial Internet of Things (IIoT) is a key technological pillar of the Fourth Industrial Revolution, also known as Industry 4.0. In this context, an area of considerable interest is human safety technology. Solutions rely on multiple sensors connected to a central monitoring system and supported with software to autonomously or semi-autonomously identify safety hazards. To this end, Computer vision systems are leveraged. However, streaming continuous video from numerous sensors can strain network resources, risking timely hazard response in large industrial setups. This work proposes a reference IIoT architecture based on Multi-Agent Systems to manage safety risks. It allows for scalable sensor integration and dynamically assesses sensor input based on risk levels. To prevent network overload, the architecture uses sensor-level intelligence at the edge layer to assess situational risks and decide whether to forward video signals to a centralized local cloud agent. The central cloud agent, using strategies like ensemble learning, selectively requests additional data from distributed edge agents based on the diagnosed risk. This approach was tested in monitoring safety during aircraft assembly, showing that edge processing reduces network load by limiting unnecessary data transmission without compromising accuracy. This architecture effectively distributes processing to the edge, maintaining detection accuracy while minimizing network traffic compared to continuous centralized video transmission.},
  archive      = {J_EAAI},
  author       = {Gibson Barbosa and Djamel F.H. Sadok and Judith Kelner and Luis Ribeiro},
  doi          = {10.1016/j.engappai.2025.110495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multiagent architecture for industrial internet of things safety applications},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A systematic review of end-to-end framework for contactless
fingerprint recognition: Techniques, challenges, and future directions.
<em>EAAI</em>, <em>150</em>, 110493. (<a
href="https://doi.org/10.1016/j.engappai.2025.110493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contactless fingerprint biometrics have seen rapid advancements in the recent years due to its intrinsic advantages such as resilience against latent fingerprints, and enhanced hygiene due to the absence of physical contact between a finger and the sensor. These advantages boosted the development of novel techniques for contactless fingerprint recognition. An exponentially increasing number of publications related to these developments are becoming part of the literature. However, no systematic review that consolidates these developments has been presented to date, thereby leaving a significant void. Hence, there is a need to fill this void by presenting a comprehensive review of contactless fingerprint biometric technology. A review of this kind will be highly beneficial for individuals keen on pursuing research in this domain. This study presents a systematic review of the methods used in an end-to-end framework for contactless fingerprint recognition, including acquisition, segmentation, enhancement, feature extraction, and matching, using both traditional and deep learning techniques. As per the review protocol and inclusion-exclusion criteria, 112 papers have been finally included in this review. The primary focus of the review is to present the underlying methods, their reported performance outcomes, and their strengths and weaknesses. The review evaluates the recent research findings, highlights the research issues that have been effectively addressed, presents the biases in the studies, identifies ongoing challenges that remain in the field, and provides the future research directions.},
  archive      = {J_EAAI},
  author       = {Pooja Kaplesh and Aastha Gupta and Divya Bansal and Sanjeev Sofat and Ajay Mittal},
  doi          = {10.1016/j.engappai.2025.110493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A systematic review of end-to-end framework for contactless fingerprint recognition: Techniques, challenges, and future directions},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thoughtful and cautious reasoning: A fine-tuned knowledge
graph-based multi-hop question answering framework. <em>EAAI</em>,
<em>150</em>, 110479. (<a
href="https://doi.org/10.1016/j.engappai.2025.110479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of Knowledge Graph Question Answering (KGQA) is to find the answer entity by utilizing the Knowledge Graph (KG). Despite remarkable successes in recent years, the existing multi-hop KGQA research still faces numerous challenges. First, a multi-hop question often contains multiple entities and their relationships, and the semantic information is complex. The current methods extract the semantics of the question through an encoder that cannot completely extract the complex and rich semantic information in the multi-hop questions. Second, current question answering models use the coarse information filtering mechanism in the process of reasoning, which lead to the loss of effective information and introduce additional noise. To address these issues, we propose a Thoughtful and Cautious Reasoning framework for Knowledge Graph Question Answering (TCR-KGQA). We design a new question encoder that can extract and fully fuse the local semantic information of the question at different levels, focusing on the unique local features of the multi-hop question text. Based on the advantages of Gated Recurrent Unit (GRU) for information filtering, we propose a loop instruction update framework based on residual-GRU to effectively capture key information in the reasoning process. Extensive experiments on three broad benchmark datasets demonstrate the effectiveness of our model on KGQA tasks, and it also yields excellent results in the case of incomplete knowledge graphs with missing question–answer pairs.},
  archive      = {J_EAAI},
  author       = {Yinghao Zheng and Ling Lu and Yang Hu and Yinong Chen and Aijuan Wang},
  doi          = {10.1016/j.engappai.2025.110479},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110479},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thoughtful and cautious reasoning: A fine-tuned knowledge graph-based multi-hop question answering framework},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surrogate-assist quasi-affine transformation evolutionary
for multi-objective optimization of empty train deployment on heavy-haul
railways. <em>EAAI</em>, <em>150</em>, 110475. (<a
href="https://doi.org/10.1016/j.engappai.2025.110475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms have become increasingly popular for solving expensive and time-consuming single-objective and multi-objective problems. However, in multi-objective optimization, the Pareto non-dominated solution set space can quickly become computationally intractable, making it challenging to select which samples to evaluate using the expensive fitness function. In this paper, we propose a Surrogate-Assist Quasi-Affine Transformation Evolutionary algorithm (SA-QUATRE/MO) for solving multi-objective optimization problems. The SA-QUATRE/MO algorithm uses a radial basis function network as a surrogate model to improve the speed of the algorithm operation by replacing the expensive fitness evaluation with the surrogate model. To ensure the excellence and diversity of the selected samples while keeping the archived sample space fixed, we propose a technique called Vector Space Sampling, which samples objective points in the current set of non-dominated solutions by dividing several sub-vector spaces. Additionally, we propose an uncertain sample infilling strategy to select samples for real fitness evaluation using a designed uncertainty function. We compare the SA-QUATRE/MO algorithm with three state-of-the-art algorithms for multi-objective problems in three test function suites. Finally, we applied the SA-QUATRE/MO algorithm to optimize empty train deployment in a heavy-haul railway at the loading end and build a model based on the S12 section of a specific railway. The final experimental results demonstrate the practicality and effectiveness of our proposed method.},
  archive      = {J_EAAI},
  author       = {Zhi-Gang Du and Jeng-Shyang Pan and He-Ying Xu and Shu-Chuan Chu and Shao-Quan Ni},
  doi          = {10.1016/j.engappai.2025.110475},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110475},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A surrogate-assist quasi-affine transformation evolutionary for multi-objective optimization of empty train deployment on heavy-haul railways},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigating beyond the training set: A deep learning
framework for inverse design of architected composite materials.
<em>EAAI</em>, <em>150</em>, 110473. (<a
href="https://doi.org/10.1016/j.engappai.2025.110473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a deep learning (DL)-based inverse design framework for two-phase composite materials. The artificial intelligence (AI) contribution lies in the integration of Deep Convolutional Generative Adversarial Networks (DCGAN) and Convolutional Neural Networks (CNN) into a framework that enhances material discovery and design, particularly for out-of-distribution (OOD) targets. The major contribution is the development of a strategy that balances latent space exploration and optimization, achieving low design errors – below 10% – for targeted properties located in near- and extreme-OOD regions of the material property space (MPS). The engineering application focuses on designing composites with tailored linear elastic properties, accelerating inverse design and reducing reliance on traditional simulation-based approaches. An image dataset of 12,000 Representative Unit Cells (RUCs) was assembled using a parametric Voronoi diagram generator, with elastic responses computed through finite element (FE) simulations. The DCGAN generated synthetic samples with novel features not present in the original dataset, demonstrating interpolation and extrapolation capabilities. A single round of Active Learning (AL) and Transfer Learning (TL) enhanced the CNN’s predictive accuracy on synthetic data. The framework offers significant computational efficiency, with optimization complexity O ( m ⋅ n 2 ) , where m is the number of iterations and n the latent vector dimensionality. This complexity is considerably lower than that of direct FE-based topology optimization, which ranges from O ( m ⋅ N 4 ) to O ( m ⋅ N 6 ) , where N × N represents the RUC grid size. These findings demonstrate the scalability and adaptability of the framework for advanced material design and engineering applications.},
  archive      = {J_EAAI},
  author       = {José Pablo Quesada-Molina and Hossein Mofatteh and Abdolhamid Akbarzadeh and Stefano Mariani},
  doi          = {10.1016/j.engappai.2025.110473},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110473},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Navigating beyond the training set: A deep learning framework for inverse design of architected composite materials},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Thermal buckling of graphene platelets reinforced
microplates with piezoelectric layers using artificial neural network.
<em>EAAI</em>, <em>150</em>, 110469. (<a
href="https://doi.org/10.1016/j.engappai.2025.110469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functionally graded microplates are extensively employed in advanced engineering applications, including aerospace, micro-electromechanical systems, and smart structures, due to their exceptional mechanical performance, thermal resistance, and adaptability to multifunctional environments. This study examines the thermal buckling behavior of functionally graded graphene platelet-reinforced composite microplates integrated with piezoelectric layers under externally applied voltage. The modified couple stress theory is utilized to account for micro-scale effects, and the material properties of the composite layers are determined using the Halpin-Tsai micromechanical model. The governing equations based on first shear deformation theory are solved using the Ritz method to generate training data for an artificial neural network (ANN). To address computational challenges inherent in conventional methods, an ANN-based framework, leveraging the Levenberg-Marquardt algorithm, is developed to predict the critical buckling temperature with high precision and significantly reduced computational effort. The nanofiller dimensions, weight fraction, and piezoelectric layer thickness serve as inputs, while the thermal buckling load is the output. The obtained results show that the ANN offers a significant reduction in computational time, achieving speed improvements of over 85% across all cases. Also, the ANN reliably predicts the critical buckling temperatures, achieving a maximum discrepancy of only 0.26% when compared with the Ritz method. The novelty of this work lies in combining modified couple stress theory with ANN-assisted prediction models for efficient thermal buckling analysis. This methodology offers a practical solution for the rapid and reliable design of graphene platelet-reinforced composite microplates integrated with piezoelectric layers in applications demanding high precision and performance under thermal loading.},
  archive      = {J_EAAI},
  author       = {Hongxia Liu and Qiyu Wang and Zilin Zhang},
  doi          = {10.1016/j.engappai.2025.110469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thermal buckling of graphene platelets reinforced microplates with piezoelectric layers using artificial neural network},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimization strategy for batch-stochastic configuration
network models and their application in component content prediction.
<em>EAAI</em>, <em>150</em>, 110461. (<a
href="https://doi.org/10.1016/j.engappai.2025.110461">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the challenges of inefficiency and uncertain quality in incrementally adding hidden layer nodes to a stochastic configuration network (SCN). An optimized approach for batch-wise stochastic configuration network (BSCN) using an enhanced differential evolution (DE)algorithm is introduced. Initially, the inequality constraints of SCN is studied to analyze and establish the correlation between objective parameters and network residuals. Subsequently, to speed the network’s training velocity, a BSCN is utilized for developing the regression model. Combining the DE algorithm with regional contraction and greedy selection strategies. Specifically it leverages the robust global search prowess of the standard DE while mitigating its limitations in local search and ensuring global convergence. The formulation of this enhanced DE, termed regional contraction and greedy selection differential evolution (SGDE), is elaborated in detail, and an analysis and validation of its global convergence are conducted. Comparative experiments with the conventional DE underscore the superior optimization efficacy of SGDE. The applicability of SGDE enhanced BSCN (SGDE-BSCN) is corroborated through six real-world regression tasks. These tasks demonstrate that SGDE-BSCN not only excels in configuring hidden layer nodes but also exhibits enhanced error minimization and superior generalization capabilities with an equivalent number of hidden layer nodes. Additionally, a practical case study focused on predicting component content in rare earth extraction processes validates the effectiveness of the proposed method. The empirical results show that the application of SGDE-BSCN to artificial intelligence (AI) and artificial intelligence in the field of rare earth extraction shows high prediction accuracy and fast processing speed.},
  archive      = {J_EAAI},
  author       = {RongXiu Lu and XingRong Hu and Cong Pei and Hui Yang and WenHao Dai and JianYong Zhu},
  doi          = {10.1016/j.engappai.2025.110461},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110461},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization strategy for batch-stochastic configuration network models and their application in component content prediction},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning for behavior-based driver identification.
<em>EAAI</em>, <em>150</em>, 110459. (<a
href="https://doi.org/10.1016/j.engappai.2025.110459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Behavior-based Driver Identification is an emerging technology that recognizes drivers based on their unique driving behaviors, offering important applications such as vehicle theft prevention and personalized driving experiences. However, most studies fail to account for the real-world challenges of deploying Deep Learning models within vehicles. These challenges include operating under limited computational resources, adapting to new drivers, and changes in driving behavior over time. The objective of this study is to evaluate if Continual Learning (CL) is well-suited to address these challenges, as it enables models to retain previously learned knowledge while continually adapting with minimal computational overhead and resource requirements. We tested several CL techniques across three scenarios of increasing complexity based on a well-known dataset for the Driver Identification problem. This work provides an important step forward in scalable driver identification solutions, demonstrating that CL approaches, such as Dark Experience Replay (DER), can obtain strong performance with only an 11% reduction in accuracy compared to the static scenario. Furthermore, to enhance the performance, we propose two new methods, Smooth Experience Replay (SmooER) and Smooth Dark Experience Replay (SmooDER), that leverage the temporal continuity of driver identity over time to enhance classification accuracy. Our novel method, SmooDER, achieves optimal results with only a 2% accuracy reduction compared to the 11% of the DER approach. In conclusion, this study proves the feasibility of CL approaches to address the challenges of Driver Identification in dynamic environments, making them suitable for deployment on cloud infrastructure or directly within vehicles.},
  archive      = {J_EAAI},
  author       = {Mattia Fanan and Davide Dalle Pezze and Emad Efatinasab and Ruggero Carli and Mirco Rampazzo and Gian Antonio Susto},
  doi          = {10.1016/j.engappai.2025.110459},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110459},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Continual learning for behavior-based driver identification},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised contrastive representation learning for
classifying internet of things malware. <em>EAAI</em>, <em>150</em>,
110299. (<a
href="https://doi.org/10.1016/j.engappai.2025.110299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid increase in malware prevalence poses a substantial security threat to Internet of Things (IoT) devices. Classifying IoT malware has emerged as a crucial area, essential for identifying attack patterns and developing effective defense strategies. Many methods for classifying malware utilize supervised learning. However, supervised learning in malware classification requires a considerable amount of labeled samples, which poses challenges and costs in acquiring and labeling malware samples. Furthermore, Some malware classification models struggle to fully extract features. This article proposes a self-supervised contrastive learning framework. Initially, the malware is converted to greyscale. The encoder is then pre-trained by self-supervised contrastive learning. The encoder with the new structure is able to extract features more comprehensively, while the projection header with attention is enabled to project features into the low-dimensional space more efficiently. Finally, the pre-trained encoder and classifier are fine-tuned to form a classification model using labeled samples. Experiments have shown that the proposed method has better accuracy regardless of the number of labeled samples. Experiments conducted using the publicly benchmarked datasets, Malware Image (Malimg) and the Microsoft Malware Classification Challenge (BIG2015), demonstrate that our framework outperforms state-of-the-art deep learning models and traditional methods in terms of accuracy, with achieved rates of 99.46% and 99.22%, respectively. Using only 5% of the labels from BIG2015, the proposed framework produces an impressive accuracy of 94.76%. Furthermore, it also outperforms baseline methods in identifying evolving malware, as indicated by its accuracy of 79% in a benchmarked dataset for trustworthy malware family classification (BenchMFC-G1P1P2).},
  archive      = {J_EAAI},
  author       = {Fangwei Wang and Yinhe Chen and Hongfeng Gao and Qingru Li and Changguang Wang},
  doi          = {10.1016/j.engappai.2025.110299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {110299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Self-supervised contrastive representation learning for classifying internet of things malware},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid rough aggregation approach for the selection of
artificial intelligence-based industrial cleaning robots used in public
spaces from the perspective of urban waste management. <em>EAAI</em>,
<em>150</em>, 109566. (<a
href="https://doi.org/10.1016/j.engappai.2024.109566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Waste management is becoming increasingly complex and challenging, especially in megacities with large populations. Unlike the past, when urban waste was simply collected and disposed of, modern waste management requires careful planning and execution of collection, separation, recycling, and reuse processes. Effective management of this complex system now needs more than just human effort. Integrating artificial intelligence (AI)-based systems into waste management can enhance waste reduction, reuse, and recycling effectiveness and efficiency. Selecting suitable AI-based cleaning robots (AI-ICR) for crowded public spaces, such as stations, train stations, and airports, poses complex decision-making challenges. The primary challenge is the novelty of the technology, which leads to uncertainties in selecting AI-ICRs. To address this challenge, we have developed a decision-making approach based on rough Archimedean-Dombi partitioned aggregation. This approach, termed “rough Archimedean-Dombi partitioned aggregation,” combines the flexibility of Archimedean operators, the smoothness of Dombi operators, and the structured decomposition of Partitioned operators. This model is mainly chosen for its ability to handle the uncertainty and complexity inherent in multiple criteria decision-making (MCDM) processes. Leveraging rough numbers provides a robust framework for evaluating AI-ICRs under uncertain conditions. The main advantage of this model is its robustness, consistency, stability, and ability to handle complex uncertainties. We applied the proposed model to assess four AI-ICR alternatives identified through extensive research. We evaluated these alternatives using eighteen criteria established through comprehensive field studies. Based on the results, “Recycling cost (B12)” emerged as the most crucial criterion for selecting AI-ICRs. Additionally, the research identifies the SD45 manufactured by Peppermint Robotics Co. as the optimal AI-ICR candidate. Finally, the sensitivity and benchmark analyses to validate the proposed model confirm its robustness, consistency, and reliability.},
  archive      = {J_EAAI},
  author       = {Ömer Faruk Görçün and Abhijit Saha and Pydimarri Venkata Ravi Kumar and Bijoy Krishna Debnath},
  doi          = {10.1016/j.engappai.2024.109566},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {109566},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid rough aggregation approach for the selection of artificial intelligence-based industrial cleaning robots used in public spaces from the perspective of urban waste management},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A study on sustainable system for managing municipal solid
waste through a multi-criteria group decision-making technique.
<em>EAAI</em>, <em>150</em>, 109393. (<a
href="https://doi.org/10.1016/j.engappai.2024.109393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Municipal solid waste management, a unique aspect of sustainable development, is a crucial social-ecological system that intersects with the economy, society, and environment. The introduction of volume-based waste fees in some developed countries has been a step towards promoting recycling and waste reduction. However, the sustainability of high recycling targets and the impact of public satisfaction on waste management efficiency are areas that demand further exploration. A review of the literature on municipal solid waste management and technology selection from various countries reveals that many studies need more precise justification and a resolution to the ambiguity in decision-making. Meanwhile, some researchers have developed the fuzzy multi-criteria decision-making technique in the context of waste management. However, significant performance criteria for ’5R’s (refuse, reduce, reuse, repurpose, recycle)’ waste management technology selection and cause-and-effect group criteria still need to be identified. This study strongly emphasizes the potential of the ’5R’s’ waste management system to revolutionize waste management practices. The ’5R’s’ waste management system uses a multi-criteria group decision-making technique using fuzzy-based artificial intelligence methods, employing the novel fuzzy technique for order of preference by similarity to the ideal solution. This study also proposes a new way to rank generalized interval type-2 trapezoidal fuzzy numbers and defuzzifies them to address the uncertainties that arise when using fuzzy linguistic terms to make decisions. Finally, a numerical example of the ’5R’s’ waste management problem is discussed with new ranking methods and compared with existing methods, underscoring the significant potential of the ’5R’s’ waste management system.},
  archive      = {J_EAAI},
  author       = {Marimuthu Dharmalingam and Daekook Kang},
  doi          = {10.1016/j.engappai.2024.109393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {109393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A study on sustainable system for managing municipal solid waste through a multi-criteria group decision-making technique},
  volume       = {150},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ejor---21">EJOR - 21</h2>
<ul>
<li><details>
<summary>
(2025). Milk adulteration testing and impact of farmers efficiency
heterogeneity: A strategic analysis. <em>EJOR</em>, <em>323</em>(2),
686–700. (<a href="https://doi.org/10.1016/j.ejor.2024.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by economic motives, dairy farmers adulterate milk to increase its perceived quality, posing a serious risk to consumer health. We analyse a milk supply chain in which smallholder dairy farmers can adulterate milk and explore the feasibility of selling it to end consumers through an aggregator. Using a non-cooperative sequential game between the aggregator and farmers, we examine the impact of two testing strategies offered by the aggregator to curb adulteration - (i) individual (testing milk procured from each farmer individually) and (ii) composite (testing the milk after aggregating the portions procured from all the farmers). Our analyses reveal that the aggregator can control milk adulteration by judiciously using testing and penalty mechanisms. We find that a higher market price (aggregation effect) , fetched by the aggregator because of its bargaining power owing to the consolidation of milk supplies, is essential for its operation. It leads to higher revenue for the aggregator and expands the zone in which it is profitable for the aggregator to operate. However, our results show that the efficiency heterogeneity among farmers, which leads to the less efficient farmers free-riding on the more efficient ones, has a detrimental effect on the aggregator operation. We also explore the impact of external uncertainties on the supply chain and observe that the composite testing strategy becomes more profitable for the aggregator when external uncertainties increase. Our results provide important policy recommendations for aggregators adopting optimal testing strategies.},
  archive      = {J_EJOR},
  author       = {Samir Biswas and Preetam Basu and Balram Avittathur},
  doi          = {10.1016/j.ejor.2024.12.001},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {686-700},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Milk adulteration testing and impact of farmers efficiency heterogeneity: A strategic analysis},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from the aggregated optimum: Managing port wine
inventory in the face of climate risks. <em>EJOR</em>, <em>323</em>(2),
671–685. (<a href="https://doi.org/10.1016/j.ejor.2024.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Port wine stocks ameliorate during storage, facilitating product differentiation according to age. This induces a trade-off between immediate revenues and further maturation. Varying climate conditions in the limited supply region lead to stochastic purchase prices for wine grapes. Decision makers must integrate recurring purchasing, production, and issuance decisions. Because stocks from different age classes can be blended to create final products, the solution space increases exponentially in the number of age classes. We model the problem of managing port wine inventory as a Markov decision process, considering decay as an additional source of uncertainty. For small problems, we derive general management strategies from the long-run behavior of the optimal policy. Our solution approach for otherwise intractable large problems, therefore, first aggregates age classes to create a tractable problem representation. We then use machine learning to train tree-based decision rules that reproduce the optimal aggregated policy and the enclosed management strategies. The derived rules are scaled back to solve the original problem. Learning from the aggregated optimum outperforms benchmark rules by 21.4% in annual profits (while leaving a 2.8%-gap to an upper bound). For an industry case, we obtain a 17.4%-improvement over current practices. Our research provides distinct strategies for how producers can mitigate climate risks. The purchasing policy dynamically adapts to climate-dependent price fluctuations. Uncertainties are met with lower production of younger products, whereas strategic surpluses of older stocks ensure high production of older products. Moreover, a wide spread in the age classes used for blending reduces decay risk exposure.},
  archive      = {J_EJOR},
  author       = {Alexander Pahr and Martin Grunow and Pedro Amorim},
  doi          = {10.1016/j.ejor.2024.11.046},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {671-685},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Learning from the aggregated optimum: Managing port wine inventory in the face of climate risks},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Flexible enhanced indexation models through stochastic
dominance and ordered weighted average optimization. <em>EJOR</em>,
<em>323</em>(2), 657–670. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss portfolio selection strategies for Enhanced Indexation (EI), which are based on stochastic dominance relations. The goal is to select portfolios that stochastically dominate a given benchmark but that, at the same time, must generate some excess return with respect to a benchmark index. To achieve this goal, we propose a new methodology that selects portfolios using the ordered weighted average (OWA) operator, which generalizes previous approaches based on minimax selection rules and still leads to solving linear programming models. We also introduce a new type of approximate stochastic dominance rule and show that it implies the almost Second-order Stochastic Dominance (SSD) criterion proposed by Lizyayev and Ruszczyński (2012). We prove that our EI model based on OWA selects portfolios that dominate a given benchmark through this new form of stochastic dominance criterion. We test the performance of the obtained portfolios in an extensive empirical analysis based on real-world datasets. The computational results show that our proposed approach outperforms several SSD-based strategies widely used in the literature, as well as the global minimum variance portfolio.},
  archive      = {J_EJOR},
  author       = {Francesco Cesarone and Justo Puerto},
  doi          = {10.1016/j.ejor.2024.11.050},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {657-670},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Flexible enhanced indexation models through stochastic dominance and ordered weighted average optimization},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal fulfillment and replenishment for omnichannel
retailers with standard shipping contracts. <em>EJOR</em>,
<em>323</em>(2), 642–656. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-commerce sales rise exponentially and represent an increasing proportion of global retail. To benefit from this, traditional brick-and-mortar stores enter the e-commerce market and become omnichannel retailers. However, the profitability of omnichannel retailers remains questionable due to high shipment and fulfillment costs. This paper addresses this challenge, focusing on using standard shipping contracts as a potential solution. Such contracts promise delivery within a given number of periods. Once a customer orders, the retailer should set a delivery period. In this way, retailers are flexible in setting exact delivery days, providing an opportunity for jointly optimizing product replenishment and customer fulfillment. We provide a generic model for the use of standard shipping contracts and formulate it as a Markov decision process. We provide optimal solutions using a modified policy iteration algorithm. Our results show that using standard shipping contracts creates a win-win situation: It increases profits and customer service. The observed profit increase is directly linked to maintaining less on-hand inventory. This effect is more pronounced for higher valued products and longer replenishment lead times. Additionally, we propose a heuristic policy that performs within 4% of the optimal policy.},
  archive      = {J_EJOR},
  author       = {Bartu Arslan and Albert H. Schrotenboer and Zümbül Atan},
  doi          = {10.1016/j.ejor.2024.11.051},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {642-656},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal fulfillment and replenishment for omnichannel retailers with standard shipping contracts},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-rank matrix estimation via nonconvex spectral
regularized methods in errors-in-variables matrix regression.
<em>EJOR</em>, <em>323</em>(2), 626–641. (<a
href="https://doi.org/10.1016/j.ejor.2025.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional matrix regression has been studied in various aspects, such as statistical properties, computational efficiency and application to specific instances including multivariate regression, system identification and matrix compressed sensing. Current studies mainly consider the idealized case that the covariate matrix is obtained without noise, while the more realistic scenario that the covariates may always be corrupted with noise or missing data has received little attention. We consider the general errors-in-variables matrix regression model and proposed a unified framework for low-rank estimation based on nonconvex spectral regularization. Then from the statistical aspect, recovery bounds for any stationary points are provided to achieve statistical consistency. From the computational aspect, the proximal gradient method is applied to solve the nonconvex optimization problem and is proved to converge to a small neighborhood of the global solution in polynomial time. Consequences for concrete models such as matrix compressed sensing models with additive noise and missing data are obtained via verifying corresponding regularity conditions. Finally, the performance of the proposed nonconvex estimation method is illustrated by numerical experiments on both synthetic and real neuroimaging data.},
  archive      = {J_EJOR},
  author       = {Xin Li and Dongya Wu},
  doi          = {10.1016/j.ejor.2025.02.005},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {626-641},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Low-rank matrix estimation via nonconvex spectral regularized methods in errors-in-variables matrix regression},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). From collaborative filtering to deep learning: Advancing
recommender systems with longitudinal data in the financial services
industry. <em>EJOR</em>, <em>323</em>(2), 609–625. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RS) are highly relevant for multiple domains, allowing to construct personalized suggestions for consumers. Previous studies have strongly focused on collaborative filtering approaches, but the inclusion of longitudinal data (LD) has received limited attention. To address this gap, we investigate the impact of incorporating LD for recommendations, comparing traditional collaborative filtering approaches, multi-label classifier (MLC) algorithms, and a deep learning model (DL) in the form of gated recurrent units (GRU). Additional analysis for the best performing model is provided through SHapley Additive exPlanations (SHAP), to uncover relations between the different recommended products and features. Thus, this article contributes to operational research literature by (1) comparing several MLC techniques and RS, including state-of-the-art DL models in a real-life scenario, (2) the comparison of various featurization techniques to assess the impact of incorporating LD on MLC performance, (3) the evaluation of LD as sequential input through the use of DL models, (4) offering interpretable model insights to improve the understanding of RS with LD. The results uncover that DL models are capable of extracting information from longitudinal features for overall higher and statistically significant performance. Further, SHAP values reveal that LD has the higher impact on model output and managerial relevant temporal patterns emerge across product categories.},
  archive      = {J_EJOR},
  author       = {Stephanie Beyer Díaz and Kristof Coussement and Arno De Caigny},
  doi          = {10.1016/j.ejor.2025.01.022},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {609-625},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {From collaborative filtering to deep learning: Advancing recommender systems with longitudinal data in the financial services industry},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On enhancing the explainability and fairness of tree
ensembles. <em>EJOR</em>, <em>323</em>(2), 599–608. (<a
href="https://doi.org/10.1016/j.ejor.2025.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree ensembles are one of the most powerful methodologies in Machine Learning. In this paper, we investigate how to make tree ensembles more flexible to incorporate explainability and fairness in the training process, possibly at the expense of a decrease in accuracy. While explainability helps the user understand the key features that play a role in the classification task, with fairness we ensure that the ensemble does not discriminate against a group of observations that share a sensitive attribute. We propose a Mixed Integer Linear Optimization formulation to train an ensemble of trees that, apart from minimizing the misclassification cost, controls for sparsity as well as the accuracy in the sensitive group. Our formulation is scalable in the number of observations since its number of binary decision variables is independent of the number of observations. In our numerical results, we show that for standard datasets used in the fairness literature, we can dramatically enhance the fairness of the benchmark, namely the popular Random Forest, while using only a few features, all without damaging the misclassification cost.},
  archive      = {J_EJOR},
  author       = {Emilio Carrizosa and Kseniia Kurishchenko and Dolores Romero Morales},
  doi          = {10.1016/j.ejor.2025.01.008},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {599-608},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {On enhancing the explainability and fairness of tree ensembles},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The manufacturer’s resale strategy for trade-ins.
<em>EJOR</em>, <em>323</em>(2), 583–598. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To cope with the ever-increasing number of used cars, many automobile manufacturers now offer trade-in programs whereby they resell used cars to generate revenue. Consumers have the alternative of selling their used cars via an online peer-to-peer (P2P) resale platform, which charges a commission on each transaction. This paper studies a manufacturer’s traded-in resale strategy and assess how the manufacturer’s resale strategy and profits are affected by the presence of online P2P platforms. We find that in the absence of P2P platforms, the manufacturer may opt against implementing a resale program, whereas it will always do so in the presence of P2P platforms. This suggests a notable shift in manufacturers’ optimal choice of trade-in resale strategies due to the emergence of P2P platforms. Furthermore, the study reveals that the introduction of P2P platforms may diminishes the profits of manufacturers who have implemented a resale program. Importantly, the study underscores that manufacturers are not necessarily obliged to adopt a planned obsolescence strategy. When P2P platforms are absent, implementing a resale program allows manufacturers to increase profits by producing products that are either less or more durable. However, in the face of competition from P2P platforms, profitability can only be enhanced by making products more durable. This suggests that a platform’s emergence can alter how the depreciation rate affects a manufacturer’s profit and hence its optimal product design strategies. Understanding these dynamics is crucial for effectively navigating the growing used car market.},
  archive      = {J_EJOR},
  author       = {Shu Hu and Stuart X. Zhu and Ke Fu},
  doi          = {10.1016/j.ejor.2024.12.017},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {583-598},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {The manufacturer’s resale strategy for trade-ins},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Connections between multiple-objective programming and
weight restricted data envelopment analysis: The role of the ordering
cone. <em>EJOR</em>, <em>323</em>(2), 571–582. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores some new, important and interesting connections between Multiple-Objective Programming (MOP) and Data Envelopment Analysis (DEA). We show that imposing weight restrictions in DEA corresponds to changing the ordering cone in MOP in a specific way. The new ordering cone is constructed and its properties are proved, providing useful insights about the connections between MOP and DEA. After providing several theoretical results, we illustrate them on a real-world data set. In addition to their theoretical appeal, our results hold significant practical importance for several reasons which are addressed in the paper.},
  archive      = {J_EJOR},
  author       = {Pekka Korhonen and Majid Soleimani-damaneh and Jyrki Wallenius},
  doi          = {10.1016/j.ejor.2024.12.002},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {571-582},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Connections between multiple-objective programming and weight restricted data envelopment analysis: The role of the ordering cone},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An incremental preference elicitation-based approach to
learning potentially non-monotonic preferences in multi-criteria
sorting. <em>EJOR</em>, <em>323</em>(2), 553–570. (<a
href="https://doi.org/10.1016/j.ejor.2024.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leveraging assignment example preference information, to determine the shape of marginal utility functions and category thresholds of the threshold-based multi-criteria sorting (MCS) model, has emerged as a focal point of current research within the realm of MCS. Most studies assume decision makers can provide all assignment example preference information in batch and that their preferences over criteria are monotonic, which may not align with practical MCS problems. This paper introduces a novel incremental preference elicitation-based approach to learning potentially non-monotonic preferences in MCS problems, enabling decision makers to progressively provide assignment example preference information. Specifically, we first construct a max-margin optimization-based model to model potentially non-monotonic preferences and inconsistent assignment example preference information in each iteration of the incremental preference elicitation process. Using the optimal objective function value of the max-margin optimization-based model, we devise information amount measurement methods and question selection strategies to pinpoint the most informative alternative in each iteration within the framework of uncertainty sampling in active learning. Once the termination criterion is satisfied, the sorting result for non-reference alternatives can be determined through the use of two optimization models, i.e., the max-margin optimization-based model and the complexity controlling optimization model. Subsequently, two incremental preference elicitation-based algorithms are developed to learn potentially non-monotonic preferences, considering different termination criteria. Ultimately, we apply the proposed approach to a firm financial state rating problem to elucidate the detailed implementation steps, and perform computational experiments on both artificial and real-world data sets to compare the proposed question selection strategies with several benchmark strategies.},
  archive      = {J_EJOR},
  author       = {Zhuolin Li and Zhen Zhang and Witold Pedrycz},
  doi          = {10.1016/j.ejor.2024.11.047},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {553-570},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An incremental preference elicitation-based approach to learning potentially non-monotonic preferences in multi-criteria sorting},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A coevolutionary algorithm for exploiting a large fuzzy
outranking relation. <em>EJOR</em>, <em>323</em>(2), 540–552. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outranking approach in Multiple Criteria Decision Analysis (MCDA) uses ranking procedures to exploit a fuzzy outranking relation, which captures the decision maker&#39;s notion of a ranking. However, as decision problems become more complex and computer performance improves, new ranking procedures are needed to rank complex data sets that decision-makers may not interpret. This paper discusses recent efforts and potential directions for developing ranking procedures that use multiobjective evolutionary algorithms (MOEAs) to exploit a fuzzy outranking relation. After that, based on the cooperative coevolutionary algorithms (CCEA) approach, we suggest some fundamental modifications to extend the RP 2 -NSGA-II+H algorithm that improve the scalability of this MOEA to exploit large-sized fuzzy outranking relations. Empirical results indicate that adjustments improve the RP 2 -NSGA-II+H algorithm for the addressed problem. The proposed ranking procedure outperforms RP 2 -NSGA-II+H in terms of ranking error rates based on the experiments conducted. Our experimental results also demonstrate that the proposed approach can be scaled for instances of the ranking problem of up to one thousand alternatives.},
  archive      = {J_EJOR},
  author       = {Jesús Jaime Solano Noriega and Juan Carlos Leyva López and Carlos Andrés Oñate Ochoa and José Rui Figueira},
  doi          = {10.1016/j.ejor.2024.12.012},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {540-552},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A coevolutionary algorithm for exploiting a large fuzzy outranking relation},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain adoption and coordination strategies for green
supply chains considering consumer privacy concern. <em>EJOR</em>,
<em>323</em>(2), 525–539. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consumers’ uncertainty about the value of green products will reduce their willingness to pay, thereby obstructing green product promotion. Blockchain can eliminate this uncertainty but bring privacy concerns. We develop a game theoretical model to study a green supply chain composed of one manufacturer and one retailer, aiming to explore the implications of partial or full blockchain adoption on green product manufacturing. Subsequently, we consider the use of revenue-sharing and cost-sharing contracts as mechanisms to coordinate the supply chain that adopts blockchain technologies. We show that adopting blockchain for some products benefits the manufacturer and the retailer, and consumers’ privacy concerns make it impossible for blockchain to be adopted for all products. Interestingly, partial or full blockchain adoption does not affect the green investment level. Furthermore, we find that revenue-sharing and cost-sharing contracts are always beneficial for the manufacturer. However, it can be beneficial for the retailer only when the revenue-sharing or cost-sharing ratio is small. Surprisingly, the effectiveness of the coordinating contract is not affected by consumers’ privacy concerns. Finally, when comparing the wholesale price contract with two coordination mechanisms, we find that the manufacturer and the retailer can agree on adopting a cost-sharing contract when both revenue- and cost-sharing ratios are low. When the revenue-sharing ratio is moderate and the cost-sharing ratio is low, a revenue-sharing contract is adopted. In all other cases, trading is conducted according to the wholesale price contract. These insights can contribute to optimize the application of blockchain in green supply chains.},
  archive      = {J_EJOR},
  author       = {Changhua Liao and Qihui Lu and Salar Ghamat and Helen Huifen Cai},
  doi          = {10.1016/j.ejor.2024.12.022},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {525-539},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Blockchain adoption and coordination strategies for green supply chains considering consumer privacy concern},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An operation-agnostic stochastic user equilibrium model for
mobility-on-demand networks with congestible capacities. <em>EJOR</em>,
<em>323</em>(2), 504–524. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating the impact of privately-owned Mobility-on-Demand (MoD) services is important from a regulatory perspective. There is a need to model multimodal equilibria with MoD to support policymaking. While there exists a large body of literature on MoD services focusing on service design under equilibrium modeling, these studies commonly adopt assumptions of MoD operational policies. However, such policies might not be shared with regulatory agencies due to commercial privacy concerns of private operators. We model multimodal equilibrium with MoD systems in an operation-agnostic manner based on empirical observations of flow and capacity. This is done with a Flow-Capacity Interaction (FC) matrix that captures systematic effect of congestible capacities, a phenomenon in MoD systems where capacities are affected by flows. The FC matrix encapsulates the operation and demand patterns by capturing the empirical equilibrium relationship between flows and capacities. An operation-agnostic logit-based stochastic user equilibrium (SUE) formulation is proposed and proof of equivalence of the SUE formulation is derived. The proof shows that, unlike static capacities, path delays are not just the sum of the Lagrange multipliers of the links on the paths, but dependent on the whole network. We name this phenomenon as “non-separable link delays”. A solution algorithm that finds SUE with a bounded path set is proposed, with a custom Frank-Wolfe algorithm to solve the non-linear SUE formulation. Since the FC matrix cannot be directly observed, an inverse optimization problem is introduced to estimate it with observed flow and capacity data. Two numerical examples are provided with sensitivity tests. An empirical example with yellow taxi data of downtown Manhattan, NY is provided to demonstrate effectiveness of estimating the FC matrix from real data, and for determining the equilibrium that captures the underlying flow-capacity dynamics.},
  archive      = {J_EJOR},
  author       = {Bingqing Liu and David Watling and Joseph Y.J. Chow},
  doi          = {10.1016/j.ejor.2024.12.038},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {504-524},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {An operation-agnostic stochastic user equilibrium model for mobility-on-demand networks with congestible capacities},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Product line extensions and distribution channels in
pharmaceutical supply chain. <em>EJOR</em>, <em>323</em>(2), 490–503.
(<a href="https://doi.org/10.1016/j.ejor.2024.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to aggressive generic competition after the original drug’s patent expires, various original firms extend their product lines by introducing an authorized generic drug with both lower quality and cost, either via internal distribution or third-party distribution. In this paper, we develop a game-theoretic model to investigate the product line extension and distribution channel decisions for an original firm that has already sold an original drug and considers introducing an authorized generic drug to compete against the generic firm. We show that product line extension enables the original firm to leverage the value of drug differentiation by price discriminating the patients with heterogeneous preferences for quality, but it also leads to original drug’s profit loss caused by the internal cannibalization. Given an internal distribution channel, when the cost gap is not small for the internal cannibalization to be less aggressive, the original firm will extend the product line, which could surprisingly benefit the generic firm but harm the patients. In contrast, under a third-party distribution channel, the original firm always prefers to extend the product line by setting a low wholesale price, which always reduces the generic firm’s profit but increases the patient surplus. Finally, contrary to the conventional wisdom that a decentralized channel always harms the original firm compared with a centralized one due to the double marginalization, our results suggest that when the original drug has a small cost gap or a large quality gap relative to the generic drug, the original firm is better off with using the third-party distribution to introduce the authorized generic drug than the internal distribution, as it permits higher original drug’s profit due to alleviated internal cannibalization, although at the expense of lower authorized generic drug’s profit.},
  archive      = {J_EJOR},
  author       = {Ran Tao and Yanfei Lan and Ruiqing Zhao and Rong Gao},
  doi          = {10.1016/j.ejor.2024.12.013},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {490-503},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Product line extensions and distribution channels in pharmaceutical supply chain},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated differentiated time slot pricing and order
dispatching with uncertain customer demand in on-demand food delivery.
<em>EJOR</em>, <em>323</em>(2), 471–489. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentiated time slot pricing (DTSP) is a promising approach to enhance the efficiency and cost-effectiveness of food delivery platforms by influencing customers’ choices regarding delivery time slots. In this paper, we investigate the integrated problem of DTSP at the tactical level and order dispatching at the operational level, formulating it as a two-stage stochastic programming model. The first-stage model determines the delivery price for each time slot to maximize the system’s expected profit. The second-stage model generates the optimal order dispatching plan to minimize the generalized system cost under each stochastic scenario. To efficiently estimate the order dispatching cost for each scenario, we develop an order consolidation dispatching algorithm (OCDA) to solve the second-stage order dispatching subproblem under each demand scenario. Building on OCDA, we propose a hybrid adaptive large neighborhood search (HALNS) heuristic to solve the integrated problem. Extensive case studies based on real-world data verify the effectiveness of the proposed approach and demonstrate the benefits of DTSP strategy. Our numerical analysis provides important managerial insights for operating food delivery platforms.},
  archive      = {J_EJOR},
  author       = {Bo Zhang and Elkafi Hassini and Yun Zhou and Meng Zhao and Xiangpei Hu},
  doi          = {10.1016/j.ejor.2024.12.011},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {471-489},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Integrated differentiated time slot pricing and order dispatching with uncertain customer demand in on-demand food delivery},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal forecast reconciliation with time series selection.
<em>EJOR</em>, <em>323</em>(2), 455–470. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecast reconciliation ensures forecasts of time series in a hierarchy adhere to aggregation constraints, enabling aligned decision making. While forecast reconciliation can enhance overall accuracy in a hierarchical or grouped structure, it can lead to worse forecasts for certain series, with the greatest gains typically seen in series that originally have poorly performing base forecasts. In practical applications, some series in a structure often produce poor base forecasts due to model misspecification or low forecastability. To mitigate their negative impact, we propose two categories of forecast reconciliation methods that incorporate automatic time series selection based on out-of-sample and in-sample information, respectively. These methods keep “poor” base forecasts unused in forming reconciled forecasts, while adjusting the weights assigned to the remaining series accordingly when generating bottom-level reconciled forecasts. Additionally, our methods ameliorate disparities stemming from varied estimators of the base forecast error covariance matrix, alleviating challenges associated with estimator selection. Empirical evaluations through two simulation studies and applications using Australian labour force and domestic tourism data demonstrate the potential of the proposed methods to exclude series with high scaled forecast errors and show promising results.},
  archive      = {J_EJOR},
  author       = {Xiaoqian Wang and Rob J. Hyndman and Shanika L. Wickramasuriya},
  doi          = {10.1016/j.ejor.2024.12.004},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {455-470},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Optimal forecast reconciliation with time series selection},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring the discrete and continuous edge improvement
problems: Models and algorithms. <em>EJOR</em>, <em>323</em>(2),
441–454. (<a href="https://doi.org/10.1016/j.ejor.2024.12.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the edge improvement problem where the fixed edge traversal time assumption of the traditional network flow problems is relaxed. We consider two variants of the problem: one where improvement decisions are restricted to a discrete set (discrete edge improvement problem), and the other where they can take any value within a specified range (continuous edge improvement problem). We first analyze both problem variants on a tree-shaped network and discuss their computational complexities. For the general case, where the underlying network has no special structure, we provide mixed-integer programming (MIP) formulations for both versions of the problem. To the best of our knowledge, this study is the first to propose and compare different formulations for the discrete edge improvement problem and to present a formulation for the continuous edge improvement problem. Since the developed models do not perform well for medium and large problem instances, we introduce a Benders decomposition algorithm to solve the discrete edge improvement problem. Additionally, we employ it heuristically to find high-quality solution for the continuous edge improvement problem within reasonable times. We also devise an MIP formulation to find lower bounds for the continuous edge improvement problem, leveraging the McCormick envelopes and optimal solution properties. Our experiments demonstrate that the Benders decomposition algorithm outperforms the other formulations for the discrete edge improvement problem, while the heuristic method proposed for the continuous edge improvement problem provides quite well results even for large problem instances.},
  archive      = {J_EJOR},
  author       = {Esra Koca and A. Burak Paç},
  doi          = {10.1016/j.ejor.2024.12.051},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {441-454},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Exploring the discrete and continuous edge improvement problems: Models and algorithms},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fast and effective breakpoints heuristic algorithm for the
quadratic knapsack problem. <em>EJOR</em>, <em>323</em>(2), 425–440. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Quadratic Knapsack Problem (QKP) involves selecting a subset of elements that maximizes the sum of pairwise and singleton utilities without exceeding a given budget. The pairwise utilities are nonnegative, the singleton utilities may be positive, negative, or zero, and the node costs are nonnegative. We introduce a Breakpoints Algorithm for QKP, named QKBP, which is based on a technique proposed in Hochbaum (2009) for efficiently generating the concave envelope of the solutions to the relaxation of the problem for all values of the budget. Our approach utilizes the fact that breakpoints in the concave envelopes are optimal solutions for their respective budgets. For budgets between breakpoints, a fast greedy heuristic derives high-quality solutions from the optimal solutions of adjacent breakpoints. The QKBP algorithm is a heuristic which is highly scalable due to an efficient parametric cut procedure used to generate the concave envelope. This efficiency is further improved by a newly developed compact problem formulation. Our extensive computational study on both existing and new benchmark instances, with up to 10,000 elements, shows that while some leading algorithms perform well on a few instances, QKBP consistently delivers high-quality solutions regardless of instance size, density, or budget. Moreover, QKBP achieves these results in significantly faster running times than all leading algorithms. The source code of the QKBP algorithm, the benchmark instances, and the detailed results are publicly available on GitHub.},
  archive      = {J_EJOR},
  author       = {D.S. Hochbaum and P. Baumann and O. Goldschmidt and Y. Zhang},
  doi          = {10.1016/j.ejor.2024.12.019},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {425-440},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {A fast and effective breakpoints heuristic algorithm for the quadratic knapsack problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving the multiobjective quasi-clique problem.
<em>EJOR</em>, <em>323</em>(2), 409–424. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a simple undirected graph G , a quasi-clique is a subgraph of G whose density is at least γ ( 0 &lt; γ ≤ 1 ) . Finding a maximum quasi-clique has been addressed from two different perspectives: ( i ) maximizing vertex cardinality for a given edge density; and ( i i ) maximizing edge density for a given vertex cardinality. However, when no a priori preference information about cardinality and density is available, a more natural approach is to consider the problem from a multiobjective perspective. We introduce the Multiobjective Quasi-clique (MOQC) problem, which aims to find a quasi-clique by simultaneously maximizing both vertex cardinality and edge density. To efficiently address this problem, we explore the relationship among MOQC, its single-objective counterpart problems, and a bi-objective optimization problem, along with several properties of the MOQC problem and quasi-cliques. We propose a baseline approach using ɛ -constraint scalarization and introduce a Two-phase strategy, which applies a dichotomic search based on weighted sum scalarization in the first phase and an ɛ -constraint methodology in the second phase. Additionally, we present a Three-phase strategy that combines the dichotomic search used in Two-phase with a vertex-degree-based local search employing novel sufficient conditions to assess quasi-clique efficiency, followed by an ɛ -constraint in a final stage. Experimental results on synthetic and real-world sparse graphs indicate that the integrated use of dichotomic search and local search, together with mechanisms to assess quasi-clique efficiency, makes the Three-phase strategy an effective approach for solving the MOQC problem in sparse graphs in terms of running time and ability to produce new efficient quasi-cliques.},
  archive      = {J_EJOR},
  author       = {Daniela Scherer dos Santos and Kathrin Klamroth and Pedro Martins and Luís Paquete},
  doi          = {10.1016/j.ejor.2024.12.018},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {409-424},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Solving the multiobjective quasi-clique problem},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discrete optimization: A quantum revolution? <em>EJOR</em>,
<em>323</em>(2), 378–408. (<a
href="https://doi.org/10.1016/j.ejor.2024.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We develop several quantum procedures and investigate their potential to solve discrete optimization problems. First, we introduce a binary search procedure and illustrate how it can be used to effectively solve the binary knapsack problem. Next, we introduce two other procedures: a hybrid branch-and-bound procedure that allows to exploit the structure of the problem and a random-ascent procedure that can be used to solve problems that have no clear structure and/or are difficult to solve using traditional methods. We explain how to assess the performance of these procedures and perform an elaborate computational experiment. Our results show that we can match the worst-case performance of the best classical algorithms when solving the binary knapsack problem. After improving and generalizing our procedures, we show that they can be used to solve any discrete optimization problem. To illustrate, we show how to solve the quadratic binary knapsack problem. For this problem, our procedures outperform the best classical algorithms. In addition, we demonstrate that our procedures can be used as heuristics to find (near-) optimal solutions in limited time Not only does our work provide the tools required to explore a myriad of future research directions, it also shows that quantum computing has the potential to revolutionize the field of discrete optimization.},
  archive      = {J_EJOR},
  author       = {Stefan Creemers and Luis Fernando Pérez Armas},
  doi          = {10.1016/j.ejor.2024.12.016},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {378-408},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Discrete optimization: A quantum revolution?},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fifty years of multiple criteria decision analysis: From
classical methods to robust ordinal regression. <em>EJOR</em>,
<em>323</em>(2), 351–377. (<a
href="https://doi.org/10.1016/j.ejor.2024.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple Criteria Decision Analysis (MCDA) is a subfield of Operational Research that aims to support Decision-Makers (DMs) in the decision-making process through mathematical models and computational procedures. In this perspective, MCDA employs structured and traceable protocols to identify potential actions and the criteria for evaluating them. MCDA procedures aim to define recommendations consistent with the preferences of DMs for the specific decision problem at hand. These problems are generally formulated in terms of either choosing the best action, classifying actions into pre-defined and ordered decision classes, or ranking actions from best to worst. As the evaluation criteria are generally conflicting, the main challenge is to aggregate them into a mathematical preference model representing the DM value system. We review the development of MCDA over the past fifty years and describe its evolution with examples of distinctive methods. They are distinguished by the type of preference information elicited by DMs, the type of the preference model (criteria aggregation), and the way of converting the preference relation induced by the preference model in the set of potential actions into a decision recommendation. We focus on MCDA methods with a finite set of actions. References to specific application areas will be given. In the conclusion section, some prospective avenues of research will be outlined.},
  archive      = {J_EJOR},
  author       = {Salvatore Greco and Roman Słowiński and Jyrki Wallenius},
  doi          = {10.1016/j.ejor.2024.07.038},
  journal      = {European Journal of Operational Research},
  month        = {6},
  number       = {2},
  pages        = {351-377},
  shortjournal = {Eur. J. Oper. Res.},
  title        = {Fifty years of multiple criteria decision analysis: From classical methods to robust ordinal regression},
  volume       = {323},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="iandc---16">IANDC - 16</h2>
<ul>
<li><details>
<summary>
(2025). On the computational power of energy-constrained mobile
robots. <em>IANDC</em>, <em>303</em>, 105280. (<a
href="https://doi.org/10.1016/j.ic.2025.105280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider distributed systems of autonomous robots operating in the plane under synchronous Look - Compute - Move ( LCM ) cycles. Prior research on four distinct models assumes robots have unlimited energy. We remove this assumption and investigate systems where robots have limited but renewable energy, requiring inactivity for energy restoration. We analyze the computational impact of this constraint, fully characterizing the relationship between energy-restricted and unrestricted robots. Surprisingly, we show that energy constraints can enhance computational power. Additionally, we study how memory persistence and communication capabilities influence computation under energy constraints. By comparing the four models in this setting, we establish a complete characterization of their computational relationships. A key insight is that energy-limited robots can be modeled as unlimited-energy robots controlled by an adversarial activation scheduler. This provides a novel equivalence framework for analyzing energy-constrained distributed systems.},
  archive      = {J_IANDC},
  author       = {Kevin Buchin and Paola Flocchini and Irina Kostitsyna and Tom Peters and Nicola Santoro and Koichi Wada},
  doi          = {10.1016/j.ic.2025.105280},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105280},
  shortjournal = {Inf. Comput.},
  title        = {On the computational power of energy-constrained mobile robots},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistent query answering in multi-relation databases.
<em>IANDC</em>, <em>303</em>, 105279. (<a
href="https://doi.org/10.1016/j.ic.2025.105279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditionally, to verify the consistency of a multi-relation database with respect to a set of functional dependencies, one applies the well-known Chase algorithm, which derives new tuples as long as no conflict with some dependency arises. Therefore, the Chase algorithm uses dependencies both as inference rules and as tools to check consistency. If no conflicts occur, the database is declared consistent else inconsistent. If the database is consistent then query answering proceeds as usual, otherwise extracting consistent information from the inconsistent database is an issue, known as consistent query answering. To address this issue, we consider the set T of all tuples built from constants occurring in the database, and we use set theoretic semantics to characterize tuples in T in two orthogonal ways: true/false and conflicting/non-conflicting. Calling ‘consistent’ a tuple which is true and non-conflicting, a ‘repair’ is defined to be a maximal subset of true tuples that satisfies the dependencies and in which as many consitent tuples as possible are true. A query Q is of the form select X where C o n d i t i o n , and a tuple x of T is in the consistent answer of Q if x is in the answer of Q in every repair. Our main contributions are: (a) a novel approach to consistent query answering in multi-relation databases; (b) a modified Chase algorithm to compute true/false and conflicting/non-conflicting tuples; (c) for acyclic functional dependencies, a polynomial-time algorithm computing the exact or approximate consistent answers; (d) a detailed discussion comparing our approach with other related approaches.},
  archive      = {J_IANDC},
  author       = {Dominique Laurent and Nicolas Spyratos},
  doi          = {10.1016/j.ic.2025.105279},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105279},
  shortjournal = {Inf. Comput.},
  title        = {Consistent query answering in multi-relation databases},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On regular trees defined from unfoldings and coverings.
<em>IANDC</em>, <em>303</em>, 105278. (<a
href="https://doi.org/10.1016/j.ic.2025.105278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the infinite trees that arise, first as complete unfoldings of finite weighted directed graphs, and second, as universal coverings of finite weighted undirected graphs. They are respectively the regular rooted trees and the strongly regular trees, a new notion. A rooted tree is regular if it has finitely many subtrees up to isomorphism. A tree (without root) is strongly regular if it has finitely many rooted trees, up to isomorphism, obtained by taking each of its nodes as a root. We prove the first-order definability of each regular or strongly regular tree with respect to the class of trees (that is not itself first-order definable). We characterize the strongly regular trees among the regular ones and we establish several decidability results.},
  archive      = {J_IANDC},
  author       = {Bruno Courcelle},
  doi          = {10.1016/j.ic.2025.105278},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105278},
  shortjournal = {Inf. Comput.},
  title        = {On regular trees defined from unfoldings and coverings},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The computational properties of p systems with mutative
membrane structures. <em>IANDC</em>, <em>303</em>, 105277. (<a
href="https://doi.org/10.1016/j.ic.2025.105277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Membrane computing is a subfield of nature-inspired computing studying computational models named P systems , where several rules (division rules, dissolving rules, merging rules, creation rules, separation rules, etc) for evolving the membrane structure were considered in many variants of P systems, and most of these variants employ at most two of these types of rules. In this article, we combine budding rules, fusion rules, dissolving rules, division rules (both for non-elementary membrane and elementary membranes), therefore a mutative type of P systems, termed cell-like P systems with mutative membrane structures (CMMS P systems) are defined. We discuss the computational properties of CMMS P systems. More specifically, CMMS P systems are shown to be Turing universal by integrating some types of rules. Moreover, we prove that CMMS P systems can also effectively solve the SAT problem.},
  archive      = {J_IANDC},
  author       = {Bosheng Song and Chuanlong Hu and David Orellana-Martín and Antonio Ramírez-de-Arellano and Mario J. Pérez-Jiménez and Xiangxiang Zeng},
  doi          = {10.1016/j.ic.2025.105277},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105277},
  shortjournal = {Inf. Comput.},
  title        = {The computational properties of p systems with mutative membrane structures},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metric quantifiers and counting in timed logics and
automata. <em>IANDC</em>, <em>303</em>, 105268. (<a
href="https://doi.org/10.1016/j.ic.2025.105268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the expressiveness of the pointwise interpretations (i.e. over timed words) of some predicate and temporal logics with metric and counting features. We show that counting in the unit interval ( 0 , 1 ) is strictly weaker than counting in ( 0 , b ) with arbitrary b ≥ 0 ; moreover, allowing the latter to be included in temporal logics leads to expressive completeness for the metric predicate logic Q2MLO , recovering the corresponding result for the continuous interpretations (i.e. over signals). Exploiting this connection, we show that in contrast to the continuous case, adding ‘punctual’ predicates into Q2MLO is still insufficient for the full expressive power of the Monadic First-Order Logic of Order and Metric ( FO[ &lt; , + 1 ] ); as a remedy, we propose a generalisation of the recently proposed Pnueli automata modalities and show that the resulting metric temporal logic is expressively complete for FO[ &lt; , + 1 ] . On the practical side, we propose a compositional construction from metric interval temporal logic with counting or similar extensions to timed automata, which is more amenable to implementation based on existing tools that support on-the-fly model checking.},
  archive      = {J_IANDC},
  author       = {Hsi-Ming Ho and Khushraj Madnani},
  doi          = {10.1016/j.ic.2025.105268},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105268},
  shortjournal = {Inf. Comput.},
  title        = {Metric quantifiers and counting in timed logics and automata},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Generalising the maximum independent set algorithm via
boolean networks. <em>IANDC</em>, <em>303</em>, 105266. (<a
href="https://doi.org/10.1016/j.ic.2025.105266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A simple greedy algorithm to find a maximal independent set (MIS) in a graph starts with the empty set and visits every vertex, adding it to the set if and only if none of its neighbours are already in the set. In this paper, we consider (the complexity of decision problems related to) the generalisation of this MIS algorithm wherein any starting set is allowed. Two main approaches are leveraged. Firstly, we view the MIS algorithm as a sequential update of a Boolean network according to a permutation of the vertex set. Secondly, we introduce the concept of a constituency of a graph: a set of vertices that is dominated by an independent set. Recognizing a constituency is NP -complete, a fact we leverage repeatedly in our investigation. Our contributions are multiple: we establish that deciding whether all maximal independent sets can be reached from some configuration is coNP -complete; that fixing words (which reach a MIS from any starting configuration) and fixing permutations (briefly, permises) are coNP -complete to recognize; and that permissible graphs (graphs with a permis) are coNP -hard to recognize. We also exhibit large classes of permissible and non-permissible graphs, notably near-comparability graphs which may be of independent interest. Lastly, we extend our study to digraphs, where we search for kernels. Since the natural generalisation of our approach may not necessarily find a kernel, we introduce two further Boolean networks for digraphs: one always finds an independent set, and the other always finds a dominating set.},
  archive      = {J_IANDC},
  author       = {Maximilien Gadouleau and David C. Kutner},
  doi          = {10.1016/j.ic.2025.105266},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105266},
  shortjournal = {Inf. Comput.},
  title        = {Generalising the maximum independent set algorithm via boolean networks},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient assignment of identities in anonymous populations.
<em>IANDC</em>, <em>303</em>, 105265. (<a
href="https://doi.org/10.1016/j.ic.2025.105265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the fundamental problem of assigning distinct labels to agents in the probabilistic model of population protocols. Our protocols operate under the assumption that the size n of the population is embedded in the transition function. W.h.p. (with high probability), they are silent, i.e., eventually each agent reaches its final state and remains in it forever, and they are safe, i.e., never change a label that has already been assigned to an agent. We provide efficient protocols for this problem complemented with tight lower bounds. Our fast labeling protocol uses only O ( ( n log ⁡ n ) / ε ) interactions w.h.p., ( 2 + ε ) n + O ( n a ) states, and the label range [ 1 , ( 1 + ε ) n ] , where 1 ≥ ε &gt; 0 and 0 &lt; a &lt; 1 , while our nearly state-optimal protocol uses only n + 5 n + O ( log ⁡ log ⁡ n ) states, the label range [ 1 , n ] , and w.h.p., O ( n 3 ) interactions.},
  archive      = {J_IANDC},
  author       = {Leszek Gąsieniec and Jesper Jansson and Christos Levcopoulos and Andrzej Lingas},
  doi          = {10.1016/j.ic.2025.105265},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105265},
  shortjournal = {Inf. Comput.},
  title        = {Efficient assignment of identities in anonymous populations},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate envy-freeness in indivisible resource allocation
with budget constraints. <em>IANDC</em>, <em>303</em>, 105264. (<a
href="https://doi.org/10.1016/j.ic.2024.105264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the fair allocation of indivisible resources under knapsack constraints, where a set of items with varied costs and values are to be allocated among a group of agents. Each agent has a budget constraint on the total cost of items she can receive. The goal is to compute a budget-feasible allocation that is envy-free (EF), in which the agents do not envy each other for the items they receive, nor do they envy a charity, which is endowed with all the unallocated items. Since EF allocations barely exist (even without the budget constraints), we are interested in the relaxed notion of envy-freeness up to one item (EF1). Our results are twofold. Firstly, for the general setting where agents have heterogeneous valuations and budgets, we show that a budget-feasible allocation that maximizes the Nash social welfare (NSW) achieves a 1/4-approximation of EF1. This approximation ratio carries to the general case of arbitrary monotone subadditive valuations. The approximation ratio improves gracefully when the items have small cost compared with the agents&#39; budgets; it converges to 1/2 when the budget-cost ratio approaches infinity, and to 1 if the agents further have identical valuations. Secondly, when agents have identical valuations, we design a polynomial-time algorithm that computes a 1/2-approximate EF1 allocation for an arbitrary number of agents. For the case of identical agents and the case of two agents, we propose polynomial-time algorithms for computing EF1 allocations.},
  archive      = {J_IANDC},
  author       = {Xiaowei Wu and Bo Li and Jiarui Gan},
  doi          = {10.1016/j.ic.2024.105264},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105264},
  shortjournal = {Inf. Comput.},
  title        = {Approximate envy-freeness in indivisible resource allocation with budget constraints},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nondeterminism and the clique problem. <em>IANDC</em>,
<em>303</em>, 105260. (<a
href="https://doi.org/10.1016/j.ic.2024.105260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Clique problem is known to be NP-Complete and the question whether P=NP is unresolved. This paper examines the relative power of nondeterminism versus determinism in a restricted setting. Specifically, we consider solving the clique problem using non-deterministic and deterministic Turing machines. We impose a (reasonable) format in which a problem instance is encoded. We also impose constraints on the computation of both deterministic and non-deterministic Turing machines: both have two tapes, the input tape is read-only and one-way, and once a certain stop point in the input tape is reached, no additional writing on the work tape is allowed. We consider two cases for the position of the stop point: immediately after the number of graph nodes and the size of the clique are specified, or controlled by a parameter q that indicates what portion of the graph nodes&#39; edge specifications have been scanned. The parameter q may be arbitrarily close to 1, e.g., q = 0.99999 . We show, for both cases in our setting, that a non-deterministic Turing machine can solve the problem in O ( n 3 ) time whereas no deterministic Turing machine can solve the problem in polynomial time. However, we exhibit an exponential time deterministic single work tape, two-heads Turing machine that solves the clique problem in our setting.},
  archive      = {J_IANDC},
  author       = {Oded Shmueli},
  doi          = {10.1016/j.ic.2024.105260},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105260},
  shortjournal = {Inf. Comput.},
  title        = {Nondeterminism and the clique problem},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An algebraic attack on the key exchange protocol based upon
a modified tropical structure. <em>IANDC</em>, <em>303</em>, 105259. (<a
href="https://doi.org/10.1016/j.ic.2024.105259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we analyze the key exchange protocol based on an algebraic structure derived from a tropical semiring. The security of this key exchange scheme depends on an attacker&#39;s inability to solve a system of non-linear equations to obtain the private parameters. However, we propose an algebraic attack on this key exchange scheme using only the public parameters. We thoroughly evaluate the protocol&#39;s security against algebraic attacks through comprehensive cryptanalysis. We study the behavior of matrix sequences produced during key exchange, looking for any almost linear periodicity property that could affect the cryptanalysis. We provide the algorithm and an example to illustrate our attack, demonstrating that this key exchange protocol is not secure. Additionally, we examine how different parameter selections and matrix sizes impact the protocol&#39;s security. Ultimately, this cryptanalysis enhances tropical cryptography by expanding our understanding of the security implications of modified tropical semiring-based key exchange protocols.},
  archive      = {J_IANDC},
  author       = {J. Jackson and R. Perumal},
  doi          = {10.1016/j.ic.2024.105259},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105259},
  shortjournal = {Inf. Comput.},
  title        = {An algebraic attack on the key exchange protocol based upon a modified tropical structure},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extending CL-reducibility on array noncomputable degrees.
<em>IANDC</em>, <em>303</em>, 105258. (<a
href="https://doi.org/10.1016/j.ic.2024.105258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a function f , f -bounded-Turing ( f -bT-) reducibility is the Turing reducibility with use function bounded by f . In the special case where f = id + c (with id being the identity function and c a constant), this is referred to as cl-reducibility. In a work by Barmpalias, Fang, and Lewis-Pye, it was proven that there exist two left-c.e. reals such that no left-c.e. real ( id + g ) -bT-computes both of them whenever g is computable, nondecreasing, and satisfies ∑ n 2 − g ( n ) = ∞ . Moreover, such maximal pairs exist precisely within every array noncomputable degree. This result generalizes a prior result on cl-reducibility, which states that there exist two left-c.e. reals such that no left-c.e. real cl-computes both of them. An open question remained as to whether a similar extension could apply to another result on cl-reducibility, which asserts that there exists a left-c.e. real not cl-reducible to any random left-c.e. real. We answer this question affirmatively, providing a simpler proof compared to previous works. Additionally, we streamline the proof of the initial extension.},
  archive      = {J_IANDC},
  author       = {Nan Fang and Wolfgang Merkle},
  doi          = {10.1016/j.ic.2024.105258},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105258},
  shortjournal = {Inf. Comput.},
  title        = {Extending CL-reducibility on array noncomputable degrees},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reasoning about group responsibility for exceeding risk
threshold in one-shot games. <em>IANDC</em>, <em>303</em>, 105257. (<a
href="https://doi.org/10.1016/j.ic.2024.105257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tracing and analysing the responsibility for unsafe outcomes of actors&#39; decisions in multi-agent settings have been studied in recent years. These studies often focus on deterministic scenarios and assume that the unsafe outcomes for which actors can be held responsible are actually realized. This paper considers a broader notion of responsibility where unsafe outcomes are not necessarily realized, but their probabilities are unacceptably high. We present a logic combining strategic, probabilistic and temporal primitives designed to express concepts such as the risk of an undesirable outcome and being responsible for exceeding a risk threshold in one-shot games. We demonstrate that the proposed logic is (weakly) complete, decidable and has an efficient model-checking procedure. Finally, we define a probabilistic notion of responsibility and study its formal properties in the proposed logic setting.},
  archive      = {J_IANDC},
  author       = {Maksim Gladyshev and Natasha Alechina and Mehdi Dastani and Dragan Doder},
  doi          = {10.1016/j.ic.2024.105257},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105257},
  shortjournal = {Inf. Comput.},
  title        = {Reasoning about group responsibility for exceeding risk threshold in one-shot games},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic judgment aggregation with conditional
independence constraints. <em>IANDC</em>, <em>303</em>, 105256. (<a
href="https://doi.org/10.1016/j.ic.2024.105256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic judgment aggregation is concerned with aggregating judgments about probabilities of logically related issues. It takes as input imprecise probabilistic judgments over the issues given by a group of agents and defines rules of aggregating the individual judgments into a collective opinion representative for the group. The process of aggregation can be subject to constraints, i.e., aggregation rules can be required to satisfy certain properties. We explore how probabilistic independence constraints can be represented and incorporated into the aggregation process.},
  archive      = {J_IANDC},
  author       = {Magdalena Ivanovska and Marija Slavkovik},
  doi          = {10.1016/j.ic.2024.105256},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105256},
  shortjournal = {Inf. Comput.},
  title        = {Probabilistic judgment aggregation with conditional independence constraints},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ltlf synthesis under environment specifications for
reachability and safety properties. <em>IANDC</em>, <em>303</em>,
105255. (<a href="https://doi.org/10.1016/j.ic.2024.105255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study ltl f synthesis under environment specifications for arbitrary reachability and safety properties. We consider both kinds of properties for both agent tasks and environment specifications, providing a complete landscape of synthesis algorithms. For each case, we devise a specific algorithm (optimal wrt complexity of the problem) and prove its correctness. The algorithms combine common building blocks in different ways. While some cases are already studied in literature others are studied here for the first time.},
  archive      = {J_IANDC},
  author       = {Benjamin Aminof and Giuseppe De Giacomo and Antonio Di Stasio and Hugo Francon and Sasha Rubin and Shufang Zhu},
  doi          = {10.1016/j.ic.2024.105255},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105255},
  shortjournal = {Inf. Comput.},
  title        = {Ltlf synthesis under environment specifications for reachability and safety properties},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed fractional local ratio and independent set
approximation. <em>IANDC</em>, <em>303</em>, 105238. (<a
href="https://doi.org/10.1016/j.ic.2024.105238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Maximum Weight Independent Set problem, with a focus on obtaining good approximations for graphs of small maximum degree Δ. We give deterministic local algorithms running in time poly ( Δ , log ⁡ n ) that come close to matching the best centralized results known and improve the previous distributed approximations by a factor of about 2. More precisely, we obtain approximations below Δ + 1 / 2 2 , and a further improvement to 8 / 5 + ε when Δ = 3 . Technically, this is achieved by leveraging the fractional local ratio technique, for a first application in a distributed setting.},
  archive      = {J_IANDC},
  author       = {Magnús M. Halldórsson and Dror Rawitz},
  doi          = {10.1016/j.ic.2024.105238},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105238},
  shortjournal = {Inf. Comput.},
  title        = {Distributed fractional local ratio and independent set approximation},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A parallel algorithm for counting parse trees.
<em>IANDC</em>, <em>303</em>, 105237. (<a
href="https://doi.org/10.1016/j.ic.2024.105237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A parallel algorithm for computing the number of parse trees of a given string according to a fixed context-free grammar is defined. More generally, the algorithm applies to computing the weight of a string in a weighted grammar over any semiring. The algorithm is first implemented on an arithmetic circuit of depth at most 6 ( log 2 ⁡ n ) 2 + O ( log ⁡ n ) and with O ( n 6 ) elements, where the constant factors in the big-O notation depend on the grammar. Then, the circuit is improved using fast matrix multiplication to use only O ( n 5.38 ) elements, while preserving depth O ( ( log ⁡ n ) 2 ) .},
  archive      = {J_IANDC},
  author       = {Margarita Mikhelson and Alexander Okhotin},
  doi          = {10.1016/j.ic.2024.105237},
  journal      = {Information and Computation},
  month        = {3},
  pages        = {105237},
  shortjournal = {Inf. Comput.},
  title        = {A parallel algorithm for counting parse trees},
  volume       = {303},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="icv---16">ICV - 16</h2>
<ul>
<li><details>
<summary>
(2025). Spatio-temporal information mining and fusion feature-guided
modal alignment for video-based visible-infrared person
re-identification. <em>ICV</em>, <em>157</em>, 105518. (<a
href="https://doi.org/10.1016/j.imavis.2025.105518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The video-based visible-infrared person re-identification (Re-ID) aims to recognize the same person across modalities through video sequences. The core challenges of this task lie in narrowing the modal differences and deeply mining the rich spatio-temporal information contained in video to enhance model performance. However, existing research primarily focuses on addressing the modality gap, with insufficient utilization of the spatio-temporal information in video sequences. To address this, this paper proposes a novel spatio-temporal information mining and fusion feature-guided modal alignment framework for video-based visible-infrared person Re-ID. Specifically, we propose a spatio-temporal information mining method. This method employs the proposed feature correlation mechanism to enhance the discriminative features of person across different frames, while utilizing a temporal Transformer to mine person motion features. The advantage of this method lies in its ability to alleviate issues such as occlusion and frame misalignment, improving the discriminability of person features. Additionally, we introduce a fusion modality-guided modal alignment strategy, which reduces modality differences between infrared and visible video frames by aligning single-modality features with fusion features. The advantage of this strategy is that each modality not only learns its specific features but also absorbs person information from the other modality, thereby alleviating modality differences and further enhancing the discriminability of person features. Extensive comparative and ablation experiments conducted on the HITSZ-VCM and BUPTCampus datasets confirm the effectiveness and superiority of the proposed framework. The source code is available at https://github.com/lhf12278/SIMFGA .},
  archive      = {J_ICV},
  author       = {Zhigang Zuo and Huafeng Li and Yafei Zhang and Minghong Xie},
  doi          = {10.1016/j.imavis.2025.105518},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105518},
  shortjournal = {Image Vis. Comput.},
  title        = {Spatio-temporal information mining and fusion feature-guided modal alignment for video-based visible-infrared person re-identification},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stealth sight: A multi perspective approach for camouflaged
object detection. <em>ICV</em>, <em>157</em>, 105517. (<a
href="https://doi.org/10.1016/j.imavis.2025.105517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged object detection (COD) is a challenging task due to the inherent similarity between objects and their surroundings. This paper introduces Stealth Sight , a novel framework integrating multi-view feature fusion and depth-based refinement to enhance segmentation accuracy. Our approach incorporates a pretrained multi-view CLIP encoder and a depth extraction network, facilitating robust feature representation. Additionally, we introduce a cross-attention transformer decoder and a post-training pruning mechanism to improve efficiency. Extensive evaluations on benchmark datasets demonstrate that Stealth Sight outperforms state-of-the-art methods in camouflaged object segmentation. Our method significantly enhances detection in complex environments, making it applicable to medical imaging, security, and wildlife monitoring.},
  archive      = {J_ICV},
  author       = {Domnic S. and Jayanthan K.S.},
  doi          = {10.1016/j.imavis.2025.105517},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105517},
  shortjournal = {Image Vis. Comput.},
  title        = {Stealth sight: A multi perspective approach for camouflaged object detection},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MFKD: Multi-dimensional feature alignment for knowledge
distillation. <em>ICV</em>, <em>157</em>, 105514. (<a
href="https://doi.org/10.1016/j.imavis.2025.105514">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation is a popular technique for compressing and transferring models in the field of deep learning. However, existing distillation methods often focus on optimizing a single dimension and overlook the importance of aligning and transforming knowledge across multiple dimensions, leading to suboptimal results. In this article, we introduce a novel approach called multi-dimensional feature alignment for knowledge distillation (MFKD) to address this limitation. The MFKD framework is built on the observation that knowledge from different dimensions can complement each other effectively. We extract knowledge from features in the spatcial, sample and channel dimensions separately. Our spatial-level part separates the foreground and background information, guiding the student to focus on crucial image regions by mimicking the teacher’s spatial and channel attention maps. Our sample-level part distills knowledge encoded in semantic correlations between sample activations by aligning the student’s activations to emulate the teacher’s clustering patterns using the Spearman correlation coefficient. Furthermore, our channel-level part encourages the student to learn standardized feature representations aligned with the teacher’s channel-wise interdependencies. Finally, we dynamically balance the loss factors of the different dimensions to optimize the overall performance of the distillation process. To validate the effectiveness of our methodology, we conduct experiments on benchmark datasets such as CIFAR-100, ImageNet and COCO. The experimental results demonstrate substantial performance improvements compared to baseline and recent state-of-the-art methods, confirming the efficacy of our MFKD framework. Furthermore, we provide a comprehensive analysis of the experimental results, offering deeper insight into the benefits and effectiveness of our approach. Through this analysis, we reinforce the significance of aligning and leveraging knowledge across multiple dimensions in knowledge distillation.},
  archive      = {J_ICV},
  author       = {Zhen Guo and Pengzhou Zhang and Peng Liang},
  doi          = {10.1016/j.imavis.2025.105514},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105514},
  shortjournal = {Image Vis. Comput.},
  title        = {MFKD: Multi-dimensional feature alignment for knowledge distillation},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fusing grid and adaptive region features for image
captioning. <em>ICV</em>, <em>157</em>, 105513. (<a
href="https://doi.org/10.1016/j.imavis.2025.105513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image captioning aims to automatically generate grammatically correct and reasonable description sentences for given images. Improving feature optimization and processing is crucial for enhancing performance in this task. A common approach is to leverage the complementary advantages of grid features and region features. However, incorporating region features in most current methods may lead to incorrect guidance during training, along with high acquisition costs and the requirement of pre-caching. These factors impact the effectiveness and practical application of image captioning. To address these limitations, this paper proposes a method called fusing grid and adaptive region features for image captioning (FGAR). FGAR dynamically explores pseudo-region information within a given image based on the extracted grid features. Subsequently, it utilizes a combination of computational layers with varying permissions to fuse features, enabling comprehensive interaction between information from different modalities while preserving the unique characteristics of each modality. The resulting enhanced visual features provide improved support to the decoder for autoregressively generating sentences describing the content of a given image. All processes are integrated within a fully end-to-end framework, facilitating both training and inference processes while achieving satisfactory performance. Extensive experiments validate the effectiveness of the proposed FGAR method.},
  archive      = {J_ICV},
  author       = {Jiahui Wei and Zhixin Li and Canlong Zhang and Huifang Ma},
  doi          = {10.1016/j.imavis.2025.105513},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105513},
  shortjournal = {Image Vis. Comput.},
  title        = {Fusing grid and adaptive region features for image captioning},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention head purification: A new perspective to harness
CLIP for domain generalization. <em>ICV</em>, <em>157</em>, 105511. (<a
href="https://doi.org/10.1016/j.imavis.2025.105511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain Generalization (DG) aims to learn a model from multiple source domains to achieve satisfactory performance on unseen target domains. Recent works introduce CLIP to DG tasks due to its superior image-text alignment and zeros-shot performance. Previous methods either utilize full fine-tuning or prompt-learning paradigms to harness CLIP for DG tasks. Those works focus on avoiding catastrophic forgetting of the original knowledge encoded in CLIP but ignore that the knowledge encoded in CLIP in nature may contain domain-specific cues that constrain its domain generalization performance. In this paper, we propose a new perspective to harness CLIP for DG, i.e., attention head purification. We observe that different attention heads may encode different properties of an image and selecting heads appropriately may yield remarkable performance improvement across domains. Based on such observations, we purify the attention heads of CLIP from two levels, including task-level purification and domain-level purification . For task-level purification, we design head-aware LoRA to make each head more adapted to the task we considered. For domain-level purification, we perform head selection via a simple gating strategy. We utilize MMD loss to encourage masked head features to be more domain-invariant to emphasize more generalizable properties/heads. During training, we jointly perform task-level purification and domain-level purification. We conduct experiments on various representative DG benchmarks. Though simple, extensive experiments demonstrate that our method performs favorably against previous state-of-the-arts.},
  archive      = {J_ICV},
  author       = {Yingfan Wang and Guoliang Kang},
  doi          = {10.1016/j.imavis.2025.105511},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105511},
  shortjournal = {Image Vis. Comput.},
  title        = {Attention head purification: A new perspective to harness CLIP for domain generalization},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DDMCB: Open-world object detection empowered by denoising
diffusion models and calibration balance. <em>ICV</em>, <em>157</em>,
105508. (<a href="https://doi.org/10.1016/j.imavis.2025.105508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-world object detection (OWOD) differs from traditional object detection by being more suited to real-world, dynamic scenarios. It aims to recognize unseen objects and have the skill to learn incrementally based on newly introduced knowledge. However, the current OWOD usually relies on supervising of known objects in identifying unknown objects, using high objectness scores as critical indicators of potential unknown objects. While these methods can detect unknown objects with features similar to known objects, they also classify regions dissimilar to known objects as background, leading to label bias issues. To address this problem, we leverage the knowledge from large visual models to provide auxiliary supervision for unknown objects. Additionally, we apply the Denoising Diffusion Probabilistic Model (DDPM) in OWOD scenarios. We propose an unsupervised modeling approach based on DDPM, which significantly improves the accuracy of unknown object detection. Despite this, the classifier trained during the model training process only encounters known classes, resulting in higher confidence for known classes during inference; thus, bias issues again occur. Therefore, we propose a probability calibration technique for post-processing predictions during inference. The calibration aims to reduce the probabilities of known objects and increase the probabilities of unknown objects, thereby balancing the final probability predictions. Our experiments demonstrate that the proposed method achieves significant improvements on OWOD benchmarks, with an unknown objects detection recall rate of 54.7 U-Recall , surpassing the current state-of-the-art (SOTA) methods by 44.3% . In terms of real-time performance, Our model uses a few parameters, and pure convolutional neural networks instead of intensive attention mechanisms, achieving an inference speed of 35.04 FPS , exceeding the SOTA OWOD methods based on Faster R-CNN and Deformable DETR by 2.79 and 10.95 FPS , respectively.},
  archive      = {J_ICV},
  author       = {Yangyang Huang and Xing Xi and Ronghua Luo},
  doi          = {10.1016/j.imavis.2025.105508},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105508},
  shortjournal = {Image Vis. Comput.},
  title        = {DDMCB: Open-world object detection empowered by denoising diffusion models and calibration balance},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised monocular depth learning from unknown
cameras: Leveraging the power of raw data. <em>ICV</em>, <em>157</em>,
105505. (<a href="https://doi.org/10.1016/j.imavis.2025.105505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised monocular depth estimation from wild videos with unknown camera intrinsics is a practical and challenging task in computer vision. Most of the existing methods in literature employed a camera decoder and a pose decoder to estimate camera intrinsics and poses respectively, however, their performances would be degraded significantly in many complex scenarios with severe noise and large camera rotations. To address this problem, we propose a novel self-supervised monocular depth estimation method, which could be trained from wild videos with a joint optimization strategy for simultaneously estimating camera intrinsics and poses. In the proposed method, a depth encoder is employed to learn scene depth features, and then by taking these features as inputs, a Neighborhood Influence Module (NIM) is designed for predicting each pixel’s depth by fusing the depths of its neighboring pixels, which could explicitly enforce the depth accuracy. In addition, a knowledge distillation mechanism is introduced to learn a lightweight depth encoder from a large-scale depth encoder, for achieving a balance between computational speed and accuracy. Experimental results on four public datasets demonstrate that the proposed method outperforms some state-of-the-art methods in most cases. Moreover, once the proposed method is trained with a mixed set of different datasets, its performance would be further boosted in comparison to the proposed method trained with each involved single dataset. Codes are available at: https://github.com/ZhuYongChaoUSST/IntrLessMonoDepth .},
  archive      = {J_ICV},
  author       = {Xiaofei Qin and Yongchao Zhu and Lin Wang and Xuedian Zhang and Changxiang He and Qiulei Dong},
  doi          = {10.1016/j.imavis.2025.105505},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105505},
  shortjournal = {Image Vis. Comput.},
  title        = {Self-supervised monocular depth learning from unknown cameras: Leveraging the power of raw data},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advanced deep learning and large language models:
Comprehensive insights for cancer detection. <em>ICV</em>, <em>157</em>,
105495. (<a href="https://doi.org/10.1016/j.imavis.2025.105495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the rapid advancement of machine learning (ML), particularly deep learning (DL), has revolutionized various fields, with healthcare being one of the most notable beneficiaries. DL has demonstrated exceptional capabilities in addressing complex medical challenges, including the early detection and diagnosis of cancer. Its superior performance, surpassing both traditional ML methods and human accuracy, has made it a critical tool in identifying and diagnosing diseases such as cancer. Despite the availability of numerous reviews on DL applications in healthcare, a comprehensive and detailed understanding of DL’s role in cancer detection remains lacking. Most existing studies focus on specific aspects of DL, leaving significant gaps in the broader knowledge base. This paper aims to bridge these gaps by offering a thorough review of advanced DL techniques, namely transfer learning (TL), reinforcement learning (RL), federated learning (FL), Transformers, and large language models (LLMs). These cutting-edge approaches are pushing the boundaries of cancer detection by enhancing model accuracy, addressing data scarcity, and enabling decentralized learning across institutions while maintaining data privacy. TL enables the adaptation of pre-trained models to new cancer datasets, significantly improving performance with limited labeled data. RL is emerging as a promising method for optimizing diagnostic pathways and treatment strategies, while FL ensures collaborative model development without sharing sensitive patient data. Furthermore, Transformers and LLMs, traditionally utilized in natural language processing (NLP), are now being applied to medical data for enhanced interpretability and context-based predictions. In addition, this review explores the efficiency of the aforementioned techniques in cancer diagnosis, it addresses key challenges such as data imbalance, and proposes potential solutions. It aims to be a valuable resource for researchers and practitioners, offering insights into current trends and guiding future research in the application of advanced DL techniques for cancer detection.},
  archive      = {J_ICV},
  author       = {Yassine Habchi and Hamza Kheddar and Yassine Himeur and Adel Belouchrani and Erchin Serpedin and Fouad Khelifi and Muhammad E.H. Chowdhury},
  doi          = {10.1016/j.imavis.2025.105495},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105495},
  shortjournal = {Image Vis. Comput.},
  title        = {Advanced deep learning and large language models: Comprehensive insights for cancer detection},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rif-diff: Improving image fusion based on diffusion model
via residual prediction. <em>ICV</em>, <em>157</em>, 105494. (<a
href="https://doi.org/10.1016/j.imavis.2025.105494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an image fusion framework Rif-Diff, which adopts several strategies and approaches to improve current fusion methods based on diffusion model. Rif-Diff employs residual images as the generation target of the diffusion model to optimize the model’s convergence process and enhance the fusion performance. For fusion tasks lacking ground truth, image fusion prior is utilized to facilitate the production of residual images. Simultaneously, to overcome the limitations of the model’s learning capacity imposed by training with image fusion prior, Rif-Diff introduces the idea of image restoration to enable the initial fused images to incorporate more expected information. Additionally, a dual-step decision module is designed to address the blurriness issue of fused images in existing multi-focus image fusion methods that do not rely on decision maps. Extensive experiments demonstrate the effectiveness of Rif-Diff across multiple fusion tasks including multi-focus image fusion, multi-exposure image fusion, and infrared-visible image fusion. The code is available at: https://github.com/peixuanWu/Rif-Diff .},
  archive      = {J_ICV},
  author       = {Peixuan Wu and Shen Yang and Jin Wu and Qian Li},
  doi          = {10.1016/j.imavis.2025.105494},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105494},
  shortjournal = {Image Vis. Comput.},
  title        = {Rif-diff: Improving image fusion based on diffusion model via residual prediction},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strengthening incomplete multi-view clustering: An attention
contrastive learning method. <em>ICV</em>, <em>157</em>, 105493. (<a
href="https://doi.org/10.1016/j.imavis.2025.105493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multi-view clustering presents greater challenges than traditional multi-view clustering. In recent years, significant progress has been made in this field, multi-view clustering relies on the consistency and integrity of views to ensure the accurate transmission of data information. However, during the process of data collection and transmission, data loss is inevitable, leading to partial view loss and increasing the difficulty of joint learning on incomplete multi-view data. To address this issue, we propose a multi-view contrastive learning framework based on the attention mechanism. Previous contrastive learning mainly focused on the relationships between isolated sample pairs, which limited the robustness of the method. Our method selects positive samples from both global and local perspectives by utilizing the nearest neighbor graph to maximize the correlation between local features and latent features of each view. Additionally, we use a cross-view encoder network with self-attention structure to fuse the low dimensional representations of each view into a joint representation, and guide the learning of the joint representation through a high confidence structure. Furthermore, we introduce graph constraint learning to explore potential neighbor relationships among instances to facilitate data reconstruction. The experimental results on six multi-view datasets demonstrate that our method exhibits significant effectiveness and superiority compared to existing methods.},
  archive      = {J_ICV},
  author       = {Shudong Hou and Lanlan Guo and Xu Wei},
  doi          = {10.1016/j.imavis.2025.105493},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105493},
  shortjournal = {Image Vis. Comput.},
  title        = {Strengthening incomplete multi-view clustering: An attention contrastive learning method},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early progression detection from MCI to AD using multi-view
MRI for enhanced assisted living. <em>ICV</em>, <em>157</em>, 105491.
(<a href="https://doi.org/10.1016/j.imavis.2025.105491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer&#39;s disease (AD) is a progressive neurodegenerative disorder. Early detection is crucial for timely intervention and treatment to improve assisted living. Although magnetic resonance imaging (MRI) is a widely used neuroimaging modality for the diagnosis of AD, most studies focus on a single MRI plane, missing comprehensive spatial information. In this study, we proposed a novel approach that leverages multiple MRI planes (axial, coronal, and sagittal) from 3D MRI volumes to predict progression from stable mild cognitive impairment (sMCI) to progressive MCI (pMCI) and AD. We employed a list of convolutional neural networks, including EfficientNet-B7, ConvNext, and DenseNet-121, to extract deep features from each MRI plane, followed by a feature enhancement step through an attention module. The optimized feature set was then passed through a Bayesian-optimized pool of classification heads (i.e., multilayer perceptron (MLP), long short-term memory (LSTM), and multi-head attention (MHA)) to obtain the most effective model for each MRI plane. The optimal model for each MRI plane was then integrated into homogeneous and heterogeneous ensembles to further enhance the performance of the model. Using the ADNI dataset, the proposed model achieved 91% accuracy, 87% sensitivity, 88% specificity, and 92% AUC. To enhance the interpretability of the model, we used the Grad-CAM explainability technique to generate attention maps for each MRI plane, which identified critical brain regions affected by disease progression. These attention maps revealed consistent patterns of tissue damage across the MRI scans. The results demonstrate the effectiveness of combining multiplane MRI data with ensemble learning and attention mechanisms to improve the early detection and tracking of AD progression in patients with MCI, offering a more comprehensive diagnostic tool and enhanced clinical decision-making. The datasets, results, and code used to conduct the comprehensive analysis are made available to the research community through the following link: https://github.com/nasir3843/Early_Progression_detection_MCI-to_AD},
  archive      = {J_ICV},
  author       = {Nasir Rahim and Naveed Ahmad and Waseem Ullah and Jatin Bedi and Younhyun Jung},
  doi          = {10.1016/j.imavis.2025.105491},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105491},
  shortjournal = {Image Vis. Comput.},
  title        = {Early progression detection from MCI to AD using multi-view MRI for enhanced assisted living},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-modal few-shot image recognition with enhanced
semantic and visual integration. <em>ICV</em>, <em>157</em>, 105490. (<a
href="https://doi.org/10.1016/j.imavis.2025.105490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Learning (FSL) enables models to recognize new classes with only a few examples by leveraging knowledge from known classes. Although some methods incorporate class names as prior knowledge, effectively integrating visual and semantic information remains challenging. Additionally, conventional similarity measurement techniques often result in information loss, obscure distinctions between samples, and fail to capture intra-sample diversity. To address these issues, this paper presents a Multi-modal Few-shot Image Recognition (MFSIR) approach. We first introduce the Multi-Scale Interaction Module (MSIM), which facilitates multi-scale interactions between semantic and visual features, significantly enhancing the representation of visual features. We also propose the Hybrid Similarity Measurement Module (HSMM), which integrates information from multiple dimensions to evaluate the similarity between samples by dynamically adjusting the weights of various similarity measurement methods, thereby improving the accuracy and robustness of similarity assessments. Experimental results demonstrate that our approach significantly outperforms existing methods on four FSL benchmarks, with marked improvements in FSL accuracy under 1-shot and 5-shot scenarios.},
  archive      = {J_ICV},
  author       = {Chunru Dong and Lizhen Wang and Feng Zhang and Qiang Hua},
  doi          = {10.1016/j.imavis.2025.105490},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105490},
  shortjournal = {Image Vis. Comput.},
  title        = {Multi-modal few-shot image recognition with enhanced semantic and visual integration},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Object tracking based on temporal and spatial context
information. <em>ICV</em>, <em>157</em>, 105488. (<a
href="https://doi.org/10.1016/j.imavis.2025.105488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, numerous advanced trackers improve stability by optimizing the target visual appearance models or by improving interactions between templates and search areas. Despite these advancements, appearance-based trackers still primarily depend on the visual information of targets without adequately integrating spatio-temporal context information, thus limiting their effectiveness in handling similar objects around the target. To address this challenge, a novel object tracking method, TSCTrack, which leverages spatio-temporal context information, has been introduced. TSCTrack overcomes the shortcomings of traditional center-cropping preprocessing techniques by introducing Global Spatial Position Embedding, effectively preserving spatial information and capturing motion data of targets. Additionally, TSCTrack incorporates a Spatial Relationship Aggregation module and a Temporal Relationship Aggregation module—the former captures static spatial context information per frame, while the latter integrates dynamic temporal context information. This sophisticated integration allows the Dynamic Tracking Prediction module to generate precise target coordinates effectively, greatly reducing the impact of target deformations and scale changes on tracking performance. Demonstrated across multiple public tracking datasets including LaSOT, TrackingNet, UAV123, GOT-10k, and OTB, TSCTrack showcases superior performance and validates its exceptional tracking capabilities in diverse scenarios.},
  archive      = {J_ICV},
  author       = {Yan Chen and Tao Lin and Jixiang Du and Hongbo Zhang},
  doi          = {10.1016/j.imavis.2025.105488},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105488},
  shortjournal = {Image Vis. Comput.},
  title        = {Object tracking based on temporal and spatial context information},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An edge-aware high-resolution framework for camouflaged
object detection. <em>ICV</em>, <em>157</em>, 105487. (<a
href="https://doi.org/10.1016/j.imavis.2025.105487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Camouflaged objects are often seamlessly assimilated into their surroundings and exhibit indistinct boundaries. The complex environmental conditions and the high intrinsic similarity between camouflaged targets and their backgrounds present significant challenges in accurately locating and fully segmenting these objects. Although existing methods have achieved remarkable performance across various real-world scenarios, they still struggle with challenging cases such as small targets, thin structures, and blurred boundaries. To address these issues, we propose a novel edge-aware high-resolution network. Specifically, we design a High-Resolution Feature Enhancement Module to exploit multi-scale features while preserving local details. Furthermore, we introduce an Edge Prediction Module to generate high-quality edge prediction maps. Subsequently, we develop an Attention-Guided Fusion Module to effectively leverage the edge prediction maps. With these key modules, the proposed model achieves real-time performance at 58 FPS and surpasses 21 state-of-the-art algorithms across six standard evaluation metrics. Source code will be publicly available at https://github.com/clelouch/EHNet .},
  archive      = {J_ICV},
  author       = {Jingyuan Ma and Tianyou Chen and Jin Xiao and Xiaoguang Hu and Yingxun Wang},
  doi          = {10.1016/j.imavis.2025.105487},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105487},
  shortjournal = {Image Vis. Comput.},
  title        = {An edge-aware high-resolution framework for camouflaged object detection},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive scale matching for remote sensing object detection
based on aerial images. <em>ICV</em>, <em>157</em>, 105482. (<a
href="https://doi.org/10.1016/j.imavis.2025.105482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing object detection based on aerial images presents challenges due to their complex backgrounds, and the utilization of specific a contextual information can enhance detection accuracy. Inadequate long-range background information may lead to erroneous detection of small remotely sensed objects, with variations in background complexity observed across different object types. In this paper, we propose a new YOLO -based real-time object detector. The detector aims to S cale- M atch the proportions of various objects in remote sensing images using the model named YOLO-SM . Specifically, this paper proposes a straightforward yet highly efficient building block that dynamically adjusts the necessary receptive field for each object, minimizing the loss of feature information caused by consecutive convolutions. Additionally, a supplementary bottom-up pathway is incorporated to improve the representation of smaller objects. Empirical evaluations conducted on DOTA-v1.0, DOTA-v1.5, DIOR-R, and HRSC2016 datasets confirm the efficacy of the proposed methodology. On DOTA-v1.0, compared to RTMDet-R-L, YOLO-SM-S achieved competitive accuracy while significantly reducing parameters by 74.8% and FLOPs by 78.5%. Compared to LSKNet on HRSC2016, YOLO-SM-Tiny dramatically reduces 76% of parameters and 90% of FLOPs and improves FPS by about three times while maintaining stable accuracy.},
  archive      = {J_ICV},
  author       = {Lu Han and Nan Li and Zeyuan Zhong and Dong Niu and Bingbing Gao},
  doi          = {10.1016/j.imavis.2025.105482},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105482},
  shortjournal = {Image Vis. Comput.},
  title        = {Adaptive scale matching for remote sensing object detection based on aerial images},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Video wire inpainting via hierarchical feature mixture.
<em>ICV</em>, <em>157</em>, 105460. (<a
href="https://doi.org/10.1016/j.imavis.2025.105460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video wire inpainting aims at automatically eliminating visible wires from film footage, significantly streamlining post-production workflows. Previous models address redundancy in wire removal by eliminating redundant blocks to enhance focus on crucial wire details for more accurate reconstruction. However, once redundancy is removed, the disorganized non-redundant blocks disrupt temporal and spatial coherence, making seamless inpainting challenging. The absence of multi-scale feature fusion further limits the model’s ability to handle different wire scales and blend inpainted regions with complex backgrounds. To address these challenges, we propose a Hierarchical Feature Mixture Network (HFM-Net) that integrates two novel modules: a Hierarchical Transformer Module (HTM) and a Spatio-temporal Feature Mixture Module (SFM). Specifically, the HTM employs redundancy-aware attention modules and lightweight transformers to reorganize and fuse key high- and low-dimensional patches. The lightweight transformers are sufficient due to the reduced number of non-redundant blocks processing. By aggregating similar features, these transformers guide the alignment of non-redundant blocks and achieve effective spatio-temporal synchronization. Building on this, the SFM incorporates gated convolutions and GRU to enhance spatial and temporal integration further. Gated convolutions fuse low- and high-dimensional features, while the GRU captures temporal dependencies, enabling seamless inpainting of dynamic wire patterns. Additionally, we introduce a lightweight 3D separable convolution discriminator to improve video quality during the inpainting process while reducing computational costs. Experimental results demonstrate that HFM-Net achieves state-of-the-art performance on the video wire removal task.},
  archive      = {J_ICV},
  author       = {Zhong Ji and Yimu Su and Yan Zhang and Shuangming Yang and Yanwei Pang},
  doi          = {10.1016/j.imavis.2025.105460},
  journal      = {Image and Vision Computing},
  month        = {5},
  pages        = {105460},
  shortjournal = {Image Vis. Comput.},
  title        = {Video wire inpainting via hierarchical feature mixture},
  volume       = {157},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ijar---10">IJAR - 10</h2>
<ul>
<li><details>
<summary>
(2025). Improved evidential three-way decisions in incomplete
multi-scale information systems. <em>IJAR</em>, <em>181</em>, 109417.
(<a href="https://doi.org/10.1016/j.ijar.2025.109417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Granular computing, by simulating human thought processes, provides a paradigm for solving complex decision-making problems. The three-way decision is a key component of granular computing. Compared to traditional decision-making methodologies, it introduces “deferred decision-making”, allowing for multi-granularity exploration of alternatives. This process gradually refines the granularity of alternatives, leading to a transition between acceptance and rejection. Moreover, data structures in the real world are typically multi-granular, multi-level, and incomplete. Compared to single-scale information systems, incomplete multi-scale information systems provide richer decision foundations by mapping information to different levels. Additionally, they allow for more precise and flexible decision-making by integrating attribute information from different levels at a specific granularity, depending on requirements. Therefore, this paper seeks to present a three-way multi-scale decision-making methodology under incomplete environments. First, an integration methodology under incomplete multi-scale information systems by using the best-worst method is built, which comprehensively considers the importance of each scale of attributes. Second, the grey relation analysis calculation is integrated into the technique for order preference by similarity to ideal solution methodology to obtain the score of alternatives, serving as the conditional probability of three-way decisions, which compensates for the problem of Euclidean distance failures due to the correlation among indicators. Third, according to the evidence theory and the enhanced belief Jensen-Sharma-Mittal divergence, the thresholds of three-way decisions are fused, improving the classification efficiency of three-way decisions for alternatives. Finally, the effectiveness of the methodology established in this paper is validated using the campus environment evaluation data set collected through the Questionnaire Star from Shanxi University, China.},
  archive      = {J_IJAR},
  author       = {Rui Li and Chao Zhang and Deyu Li and Wentao Li and Jianming Zhan},
  doi          = {10.1016/j.ijar.2025.109417},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109417},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Improved evidential three-way decisions in incomplete multi-scale information systems},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel axiomatic approach to l-valued rough sets within an
l-universe via inner product and outer product of l-subsets.
<em>IJAR</em>, <em>181</em>, 109416. (<a
href="https://doi.org/10.1016/j.ijar.2025.109416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy rough approximation operator serves as the cornerstone of fuzzy rough set theory and its practical applications. Axiomatization is a crucial approach in the exploration of fuzzy rough sets, aiming to offer a clear and direct characterization of fuzzy rough approximation operators. Among the fundamental tools employed in this process, the inner product and outer product of fuzzy sets stand out as essential components in the axiomatization of fuzzy rough sets. In this paper, we will develop the axiomatization of a comprehensive fuzzy rough set theory, that is, the so-called L -valued rough sets with an L -set serving as the foundational universe (referred to as the L -universe) for defining L -valued rough approximation operators, where L typically denotes a GL-quantale. Firstly, we give the notions of inner product and outer product of two L -subsets within an L -universe and examine their basic properties. It is shown that these notions are extensions of the corresponding notion of fuzzy sets within a classical universe. Secondly, leveraging the inner product and outer product of L -subsets, we respectively characterize L -valued upper and lower rough approximation operators generated by general, reflexive, transitive, symmetric, Euclidean, and median L -value relations on L -universe as well as their compositions. Finally, utilizing the provided axiomatic characterizations, we present the precise examples for the least and largest equivalent L -valued upper and lower rough approximation operators. Notably, many existing axiom characterizations of fuzzy rough sets within classical universe can be viewed as direct consequences of our findings.},
  archive      = {J_IJAR},
  author       = {Lingqiang Li and Qiu Jin},
  doi          = {10.1016/j.ijar.2025.109416},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109416},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {A novel axiomatic approach to L-valued rough sets within an L-universe via inner product and outer product of L-subsets},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Matrix-based local multigranulation reduction for covering
decision information systems. <em>IJAR</em>, <em>181</em>, 109415. (<a
href="https://doi.org/10.1016/j.ijar.2025.109415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction has become an essential step in pattern recognition and machine learning tasks. As an extension of the classical rough set, the covering rough set has garnered considerable attention in both theory and application. A matrix-based method for computing local covering optimistic approximation sets and local optimistic multigranulation reductions based on covering rough set in covering decision information systems (CDISs) is proposed in this paper. Firstly, we introduce a matrix representation along with its associated operations to compute the local covering optimistic approximation sets and the local positive regions of the CDISs. Subsequently, local optimistic discernibility matrices and local optimistic discernibility functions are constructed for the CDISs. By performing disjunction and conjunction operations on these local optimistic discernibility matrices, all local optimistic multigranulation reductions of the CDISs can be accurately obtained. In addition, an algorithm is developed using the local optimistic discernibility matrix to compute a suboptimal minimal local optimistic multigranulation reduction. Finally, to verify the effectiveness and feasibility of the proposed method, numerical experiments are conducted on 6 UCI datasets.},
  archive      = {J_IJAR},
  author       = {Tao Jiang and Yan-Lan Zhang},
  doi          = {10.1016/j.ijar.2025.109415},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109415},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Matrix-based local multigranulation reduction for covering decision information systems},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizations for union and intersection on non-normal
membership functions of type-2 fuzzy sets. <em>IJAR</em>, <em>181</em>,
109414. (<a href="https://doi.org/10.1016/j.ijar.2025.109414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we mainly investigate set operations for type-2 fuzzy sets. To be more exact, we present several algorithms under the left continuous t-norms that compute the join and meet operations of the non-normal convex secondary membership functions of type-2 fuzzy sets, and give some properties of operations that would enhance the application of fuzzy logic connectives. We anticipate that these algorithms can be applied to type-2 fuzzy logic systems as well as several fields of soft computing that tackle logical operations in type-2 fuzzy sets.},
  archive      = {J_IJAR},
  author       = {Zhi-qiang Liu and Jingxin Liu},
  doi          = {10.1016/j.ijar.2025.109414},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109414},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Characterizations for union and intersection on non-normal membership functions of type-2 fuzzy sets},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised hierarchical multi-label classifier based on
local information. <em>IJAR</em>, <em>181</em>, 109411. (<a
href="https://doi.org/10.1016/j.ijar.2025.109411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scarcity of labeled data is a common problem in supervised classification, since hand-labeling can be time consuming, expensive or hard to label; on the other hand, large amounts of unlabeled information can be found. The problem of scarcity of labeled data is even more notorious in hierarchical classification, because the data of a node is split among its children, which results in few instances associated to the deepest nodes of the hierarchy. In this work it is proposed the semi-supervised hierarchical multi-label classifier based on local information (SSHMC-BLI) which can be trained with labeled and unlabeled data to perform hierarchical classification tasks. The method can be applied to any type of hierarchical problem, here we focus on the most difficult case: hierarchies of DAG type, where the instances can be associated to multiple paths of labels which can finish in an internal node. SSHMC-BLI builds pseudo-labels for each unlabeled instance from the paths of labels of its labeled neighbors, while it considers whether the unlabeled instance is similar to its neighbors. Experiments on 12 challenging datasets from functional genomics show that making use of unlabeled along with labeled data can help to improve the performance of a supervised hierarchical classifier trained only on labeled data, even with statistical significance.},
  archive      = {J_IJAR},
  author       = {Jonathan Serrano-Pérez and L. Enrique Sucar},
  doi          = {10.1016/j.ijar.2025.109411},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109411},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Semi-supervised hierarchical multi-label classifier based on local information},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspace approach to relation-based neighborhood
operators. <em>IJAR</em>, <em>181</em>, 109404. (<a
href="https://doi.org/10.1016/j.ijar.2025.109404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, new, subsequent versions of neighborhoods have been defined based on the concept of relation-based neighborhoods introduced by Y.Y. Yao. This article proposes a unified concept for investigations of such neighborhoods. This work presents the notion of hyper-neighborhood, which enables the investigation of the neighborhoods from the universe&#39;s perspective. As a result, we drive multiple equivalent characterizations of the types of neighborhoods that enable us to compare them and indicate the new, missing kinds of neighborhoods. Moreover, many kinds of neighborhoods defined in the literature on the issue proved to be identical. In particular, none of the types of recently defined so-called subset neighborhoods is new.},
  archive      = {J_IJAR},
  author       = {Marian Przemski},
  doi          = {10.1016/j.ijar.2025.109404},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109404},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Hyperspace approach to relation-based neighborhood operators},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evidential time-to-event prediction with calibrated
uncertainty quantification. <em>IJAR</em>, <em>181</em>, 109403. (<a
href="https://doi.org/10.1016/j.ijar.2025.109403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-to-event analysis provides insights into clinical prognosis and treatment recommendations. However, this task is more challenging than standard regression problems due to the presence of censored observations. Additionally, the lack of confidence assessment, model robustness, and prediction calibration raises concerns about the reliability of predictions. To address these challenges, we propose an evidential regression model specifically designed for time-to-event prediction. Our approach computes a degree of belief for the event time occurring within a time interval, without any strict distribution assumption. Meanwhile, the proposed model quantifies both epistemic and aleatory uncertainties using Gaussian Random Fuzzy Numbers and belief functions, providing clinicians with uncertainty-aware survival time predictions. Experimental evaluations using simulated and real-world survival datasets highlight the potential of our approach for enhancing clinical decision-making in survival analysis.},
  archive      = {J_IJAR},
  author       = {Ling Huang and Yucheng Xing and Swapnil Mishra and Thierry Denœux and Mengling Feng},
  doi          = {10.1016/j.ijar.2025.109403},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109403},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Evidential time-to-event prediction with calibrated uncertainty quantification},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view outlier detection based on multi-granularity
fusion of fuzzy rough granules. <em>IJAR</em>, <em>181</em>, 109402. (<a
href="https://doi.org/10.1016/j.ijar.2025.109402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-view data has seen widespread application across various fields, presenting both opportunities and challenges due to its complex distribution across different views. Detecting outliers in such heterogeneous data has become a significant research problem. Existing multi-view outlier detection methods often rely on clustering assumptions, pairwise constraints between views, and a focus on learning consensus information, which overlook the inherent differences across views. To address the aforementioned issues, this paper proposes an outlier detection method based on the fusion of multi-granularity fuzzy rough information (MGFMOD). The method calculates a multi-granularity similarity matrix using fuzzy similarity relationships, combines similarity matrices from different granularities to form an upper approximation matrix, and constructs fused upper approximation granules to detect attribute anomalies. Neighbor domain probabilistic mapping is then employed to unify neighborhood relationships across views, allowing the analysis of both consistency and distribution differences to capture class outliers. Additionally, this paper employs a novel coarse-to-fine approximation method to construct the upper approximation matrix, further improving the accuracy of attribute outlier detection. Experimental results on multiple public datasets demonstrate that the proposed method generally outperforms existing multi-view outlier detection methods in terms of detection accuracy and robustness.},
  archive      = {J_IJAR},
  author       = {Siyi Qiu and Yuefei Wang and Zixu Wang and Jinyan Cao and Xi Yu},
  doi          = {10.1016/j.ijar.2025.109402},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109402},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multi-view outlier detection based on multi-granularity fusion of fuzzy rough granules},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiindistinguishability operators. <em>IJAR</em>,
<em>181</em>, 109401. (<a
href="https://doi.org/10.1016/j.ijar.2025.109401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper (binary) equivalence relations and their fuzzification, indistinguishability operators, are generalized to n -equivalence relations and n -multiindistinguishability operators respectively. Some of the properties of these two last objects are stated as well as their relation with binary ones.},
  archive      = {J_IJAR},
  author       = {D. Boixader and J. Recasens},
  doi          = {10.1016/j.ijar.2025.109401},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109401},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {Multiindistinguishability operators},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DEEM: A novel approach to semi-supervised and unsupervised
image clustering under uncertainty using belief functions and
convolutional neural networks. <em>IJAR</em>, <em>181</em>, 109400. (<a
href="https://doi.org/10.1016/j.ijar.2025.109400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DEEM (Deep Evidential Encoding of iMages) is a clustering algorithm that combines belief functions with convolutional neural networks in a Siamese-like framework for unsupervised and semi-supervised image clustering. In DEEM, images are mapped to Dempster–Shafer mass functions to quantify uncertainty in cluster membership. Various forms of prior information, including must-link and cannot-link constraints, supervised dissimilarities, and Distance Metric Learning, are incorporated to guide training and improve generalisation. By processing image pairs through shared network weights, DEEM aligns pairwise dissimilarities with the conflict between mass functions, thereby mitigating errors in noisy or incomplete distance matrices. Experiments on MNIST demonstrate that DEEM generalises effectively to unseen data while managing different types of prior knowledge, making it a promising approach for clustering and semi-supervised learning from image data under uncertainty.},
  archive      = {J_IJAR},
  author       = {Loïc Guiziou and Emmanuel Ramasso and Sébastien Thibaud and Sébastien Denneulin},
  doi          = {10.1016/j.ijar.2025.109400},
  journal      = {International Journal of Approximate Reasoning},
  month        = {6},
  pages        = {109400},
  shortjournal = {Int. J. Approx. Reasoning},
  title        = {DEEM: A novel approach to semi-supervised and unsupervised image clustering under uncertainty using belief functions and convolutional neural networks},
  volume       = {181},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ipl---14">IPL - 14</h2>
<ul>
<li><details>
<summary>
(2025). On the tractability landscape of the conditional minisum
approval voting rule. <em>IPL</em>, <em>189</em>, 106561. (<a
href="https://doi.org/10.1016/j.ipl.2025.106561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work examines the Conditional Approval Framework for elections involving multiple interdependent issues, specifically focusing on the Conditional Minisum Approval Voting Rule. We first conduct a detailed analysis of the computational complexity of this rule, demonstrating that no approach can significantly outperform the brute-force algorithm under common computational complexity assumptions and various natural input restrictions. In response, we propose two practical restrictions (the first in the literature) that make the problem computationally tractable and show that these restrictions are essentially tight. Overall, this work provides a clear picture of the tractability landscape of the problem, contributing to a comprehensive understanding of the complications introduced by conditional ballots and indicating that conditional approval voting can be applied in practice, albeit under specific conditions.},
  archive      = {J_IPL},
  author       = {Georgios Amanatidis and Michael Lampis and Evangelos Markakis and Georgios Papasotiropoulos},
  doi          = {10.1016/j.ipl.2025.106561},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106561},
  shortjournal = {Inf. Process. Lett.},
  title        = {On the tractability landscape of the conditional minisum approval voting rule},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Total variation distance for product distributions is
#p-complete. <em>IPL</em>, <em>189</em>, 106560. (<a
href="https://doi.org/10.1016/j.ipl.2025.106560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that computing the total variation distance between two product distributions is # P -complete. This is in stark contrast with other distance measures such as Kullback–Leibler, Chi-square, and Hellinger, which tensorize over the marginals leading to efficient algorithms.},
  archive      = {J_IPL},
  author       = {Arnab Bhattacharyya and Sutanu Gayen and Kuldeep S. Meel and Dimitrios Myrisiotis and A. Pavan and N.V. Vinodchandran},
  doi          = {10.1016/j.ipl.2025.106560},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106560},
  shortjournal = {Inf. Process. Lett.},
  title        = {Total variation distance for product distributions is #P-complete},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metric distortion of obnoxious distributed voting.
<em>IPL</em>, <em>189</em>, 106559. (<a
href="https://doi.org/10.1016/j.ipl.2025.106559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a distributed voting problem with a set of agents that are partitioned into disjoint groups and a set of obnoxious alternatives. Agents and alternatives are represented by points in a metric space. The goal is to compute the alternative that maximizes the total distance from all agents using a two-step mechanism which, given some information about the distances between agents and alternatives, first chooses a representative alternative for each group of agents, and then declares one of them as the overall winner. Due to the restricted nature of the mechanism and the potentially limited information it has to make its decision, it might not be always possible to choose the optimal alternative. We show tight bounds on the distortion of different mechanisms depending on the amount of the information they have access to; in particular, we study full-information and ordinal mechanisms.},
  archive      = {J_IPL},
  author       = {Alexandros A. Voudouris},
  doi          = {10.1016/j.ipl.2025.106559},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106559},
  shortjournal = {Inf. Process. Lett.},
  title        = {Metric distortion of obnoxious distributed voting},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lower bound for the quickhull convex hull algorithm that
disproves the quickhull precision conjecture. <em>IPL</em>,
<em>189</em>, 106558. (<a
href="https://doi.org/10.1016/j.ipl.2025.106558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Quickhull algorithm is a simple algorithm for constructing the convex hull of a set of n points. Quickhull is usually described for points in the plane, in which case it is defined as a divide-and-conquer algorithm, where one has a pair of points ( p , r ) such that p and r are on the convex hull, and one then finds the point, q , farthest from the line p r ‾ , which must also be on the convex hull, and then uses the triangle ( p , q , r ) to divide the remaining points and recursively solve the resulting subproblems. It is well-known that Quickhull has a worst-case running time of Θ ( n 2 ) , but it runs much faster than this for some input distributions. In a highly cited paper, Barber, Dobkin, and Huhdanpaa conjecture that the Quickhull algorithm runs in worst-case O ( n log ⁡ h ) time, where h is the size of the convex hull, when the input points have precision O ( log ⁡ n ) . In this paper, we give an explicit lower-bound construction that shows that, in general, the worst-case running time of the Quickhull algorithm is Θ ( n h ) . Our lower bound proof also provides a counter-example to the Quickhull precision conjecture of Barber et al., in that we give an explicit construction of a set, S , of n points with precision O ( log ⁡ n ) such that h is O ( log ⁡ n ) but the worst-case running time of Quickhull on S is Θ ( n h ) , not O ( n log ⁡ h ) .},
  archive      = {J_IPL},
  author       = {Michael T. Goodrich},
  doi          = {10.1016/j.ipl.2025.106558},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106558},
  shortjournal = {Inf. Process. Lett.},
  title        = {A lower bound for the quickhull convex hull algorithm that disproves the quickhull precision conjecture},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). String searching with mismatches using AVX2 and AVX-512
instructions. <em>IPL</em>, <em>189</em>, 106557. (<a
href="https://doi.org/10.1016/j.ipl.2025.106557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present new algorithms for the k mismatches version of approximate string matching. Our algorithms utilize the SIMD (Single Instruction Multiple Data) instruction set extensions, particularly AVX2 and AVX-512 instructions. Our approach is an extension of an earlier algorithm for exact string matching with SSE2 and AVX2. In addition, we modify this exact string matching algorithm to work with AVX-512. We demonstrate the competitiveness of our solutions by practical experiments. Our algorithms outperform earlier algorithms for both exact and approximate string matching on various benchmark data sets.},
  archive      = {J_IPL},
  author       = {Tamanna Chhabra and Sukhpal Singh Ghuman and Jorma Tarhio},
  doi          = {10.1016/j.ipl.2025.106557},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106557},
  shortjournal = {Inf. Process. Lett.},
  title        = {String searching with mismatches using AVX2 and AVX-512 instructions},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On approximate reconfigurability of label cover.
<em>IPL</em>, <em>189</em>, 106556. (<a
href="https://doi.org/10.1016/j.ipl.2024.106556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a two-prover game G and its two satisfying labelings ψ ini and ψ tar , the Label Cover Reconfiguration problem asks whether ψ ini can be transformed into ψ tar by repeatedly changing the label of a single vertex while preserving any intermediate labeling satisfying G . We consider its optimization version by relaxing the feasibility of labelings, referred to as Maxmin Label Cover Reconfiguration : We are allowed to pass through any non-satisfying labelings, but required to maximize the “soundness error,” which is defined as the minimum fraction of satisfied edges during transformation from ψ ini to ψ tar . Since the parallel repetition theorem of Raz (1998) [32] , which implies -hardness of approximating Label Cover within any constant factor, gives strong inapproximability results for many -hard problems, one may think of using Maxmin Label Cover Reconfiguration to derive inapproximability results for reconfiguration problems. We prove the following results on Maxmin Label Cover Reconfiguration , which display different trends from those of Label Cover and the parallel repetition theorem: • Maxmin Label Cover Reconfiguration can be approximated within a factor of 1 4 − o ( 1 ) for some restricted graph classes, including biregular graphs, balanced bipartite graphs with no isolated vertices, and superconstant average degree graphs. • A “naive” parallel repetition of Maxmin Label Cover Reconfiguration does not decrease the soundness error for every two-prover game. • Label Cover Reconfiguration on projection games can be decided in polynomial time. Our results suggest that a reconfiguration analogue of the parallel repetition theorem is unlikely.},
  archive      = {J_IPL},
  author       = {Naoto Ohsaka},
  doi          = {10.1016/j.ipl.2024.106556},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106556},
  shortjournal = {Inf. Process. Lett.},
  title        = {On approximate reconfigurability of label cover},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New bounds for the number of lightest cycles in undirected
graphs. <em>IPL</em>, <em>189</em>, 106555. (<a
href="https://doi.org/10.1016/j.ipl.2024.106555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consider an undirected graph G = ( V , E ) with positive integer edge weights. Subramanian [11] established an upper bound of | V | 4 / 6 on the number of minimum weight cycles. We present a new algorithm to enumerate all minimum weight cycles with a complexity of O ( | V | 3 ( | E | + | V | log ⁡ | V | ) ) . Using this algorithm, we derive the following upper bounds for the number of minimum weight cycles: if the minimum weight is even, the bound is | V | 4 / 4 , and if it is odd, the bound is | V | 3 / 2 . Notably, we improve Subramanian&#39;s bound by an order of magnitude when the minimum weight of a cycle is odd. Additionally, we demonstrate that these bounds are asymptotically tight.},
  archive      = {J_IPL},
  author       = {Hassene Aissi and Mourad Baiou and Francisco Barahona},
  doi          = {10.1016/j.ipl.2024.106555},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106555},
  shortjournal = {Inf. Process. Lett.},
  title        = {New bounds for the number of lightest cycles in undirected graphs},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Connected equitable cake division via sperner’s lemma.
<em>IPL</em>, <em>189</em>, 106554. (<a
href="https://doi.org/10.1016/j.ipl.2024.106554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of fair cake-cutting where each agent receives a connected piece of the cake. A division of the cake is deemed fair if it is equitable , which means that all agents derive the same value from their assigned piece. Prior work has established the existence of a connected equitable division for agents with nonnegative valuations using various techniques. We provide a simple proof of this result using Sperner&#39;s lemma. Our proof extends known existence results for connected equitable divisions to significantly more general classes of valuations, including nonnegative valuations with externalities, as well as several interesting subclasses of general (possibly negative) valuations.},
  archive      = {J_IPL},
  author       = {Umang Bhaskar and A.R. Sricharan and Rohit Vaish},
  doi          = {10.1016/j.ipl.2024.106554},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106554},
  shortjournal = {Inf. Process. Lett.},
  title        = {Connected equitable cake division via sperner&#39;s lemma},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Satisfying the restricted isometry property with the optimal
number of rows and slightly less randomness. <em>IPL</em>, <em>189</em>,
106553. (<a href="https://doi.org/10.1016/j.ipl.2024.106553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A matrix Φ ∈ R Q × N satisfies the restricted isometry property if ‖ Φ x ‖ 2 2 is approximately equal to ‖ x ‖ 2 2 for all k -sparse vectors x . We give a construction of RIP matrices with the optimal Q = O ( k log ⁡ ( N / k ) ) rows using O ( k log ⁡ ( N / k ) log ⁡ ( k ) ) bits of randomness. The main technical ingredient is an extension of the Hanson-Wright inequality to ε -biased distributions.},
  archive      = {J_IPL},
  author       = {Shravas Rao},
  doi          = {10.1016/j.ipl.2024.106553},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106553},
  shortjournal = {Inf. Process. Lett.},
  title        = {Satisfying the restricted isometry property with the optimal number of rows and slightly less randomness},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved hardness of approximation for geometric bin
packing. <em>IPL</em>, <em>189</em>, 106552. (<a
href="https://doi.org/10.1016/j.ipl.2024.106552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Geometric Bin Packing (GBP) problem is a generalization of Bin Packing where the input is a set of d -dimensional rectangles, and the goal is to pack them into d -dimensional unit cubes efficiently. It is NP-hard to obtain a PTAS for the problem, even when d = 2 . For general d , the best-known approximation algorithm has an approximation guarantee that is exponential in d . In contrast, the best hardness of approximation is still a small constant inapproximability from the case when d = 2 . In this paper, we show that the problem cannot be approximated within a d 1 − ϵ factor unless NP = P . Recently, d -dimensional Vector Bin Packing, a problem closely related to the GBP, was shown to be hard to approximate within a Ω ( log ⁡ d ) factor when d is a fixed constant, using a notion of Packing Dimension of set families. In this paper, we introduce a geometric analog of it, the Geometric Packing Dimension of set families. While we fall short of obtaining similar inapproximability results for the Geometric Bin Packing problem when d is fixed, we prove a couple of key properties of the Geometric Packing Dimension which highlight fundamental differences between Geometric Bin Packing and Vector Bin Packing.},
  archive      = {J_IPL},
  author       = {Arka Ray and Sai Sandeep},
  doi          = {10.1016/j.ipl.2024.106552},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106552},
  shortjournal = {Inf. Process. Lett.},
  title        = {Improved hardness of approximation for geometric bin packing},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient algorithm for identifying rainbow ortho-convex
4-sets in k-colored point sets. <em>IPL</em>, <em>189</em>, 106551. (<a
href="https://doi.org/10.1016/j.ipl.2024.106551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let P be a k -colored set of n points in the plane, 4 ≤ k ≤ n . We study the problem of deciding if P contains a subset of four points of different colors such that its Rectilinear Convex Hull has positive area. We show this problem to be equivalent to deciding if there exists a point c in the plane such that each of the open quadrants defined by c contains a point of P , each of them having a different color. We provide an O ( n log ⁡ n ) -time algorithm for this problem, where the hidden constant does not depend on k ; then, we prove that this problem has time complexity Ω ( n log ⁡ n ) in the algebraic computation tree model. No general position assumptions for P are required.},
  archive      = {J_IPL},
  author       = {David Flores-Peñaloza and Mario A. Lopez and Nestaly Marín and David Orden},
  doi          = {10.1016/j.ipl.2024.106551},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106551},
  shortjournal = {Inf. Process. Lett.},
  title        = {An efficient algorithm for identifying rainbow ortho-convex 4-sets in k-colored point sets},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple division-free algorithm for computing pfaffians.
<em>IPL</em>, <em>189</em>, 106550. (<a
href="https://doi.org/10.1016/j.ipl.2024.106550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a very simple algorithm for computing Pfaffians which uses no division operations. Essentially, it amounts to iterating matrix multiplication and truncation. Its complexity, for a 2 n × 2 n matrix, is O ( n M ( n ) ) , where M ( n ) is the cost of matrix multiplication. In case of a sparse matrix, M ( n ) is the cost of the dense-sparse matrix multiplication. The algorithm is an adaptation of the Bird algorithm for determinants. We show how to extract, with practically no additional work, the characteristic polynomial and the Pfaffian characteristic polynomial from these algorithms.},
  archive      = {J_IPL},
  author       = {Adam J. Przeździecki},
  doi          = {10.1016/j.ipl.2024.106550},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106550},
  shortjournal = {Inf. Process. Lett.},
  title        = {A simple division-free algorithm for computing pfaffians},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modifying an instance of the super-stable matching problem.
<em>IPL</em>, <em>189</em>, 106549. (<a
href="https://doi.org/10.1016/j.ipl.2024.106549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The topic of this paper is the stable matching problem in a bipartite graph. Super-stability is one of the stability concepts in the stable matching problem with ties. It is known that there may not exist a super-stable matching, and the existence of a super-stable matching can be checked in polynomial time. In this paper, we consider the problem of modifying an instance of the stable matching problem with ties by deleting some bounded number of agents in such a way that there exists a super-stable matching in the modified instance. First, we consider the setting where we are allowed to delete agents on only one side. We prove that, in this setting, our problem can be solved in polynomial time. Interestingly, this result is obtained by carefully observing the existing algorithm for checking the existence of a super-stable matching. Next, we consider the setting where we are given an upper bound on the number of deleted agents for each side, and we are allowed to delete agents on both sides. We prove that, in this setting, our problem is NP-complete.},
  archive      = {J_IPL},
  author       = {Naoyuki Kamiyama},
  doi          = {10.1016/j.ipl.2024.106549},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106549},
  shortjournal = {Inf. Process. Lett.},
  title        = {Modifying an instance of the super-stable matching problem},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instability results for cosine-dissimilarity-based nearest
neighbor search on high dimensional gaussian data. <em>IPL</em>,
<em>189</em>, 106542. (<a
href="https://doi.org/10.1016/j.ipl.2024.106542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because many dissimilarity functions behave differently in low versus high-dimensional spaces, the behavior of high-dimensional nearest neighbor search has been studied extensively. One line of research involves the characterization of nearest neighbor queries as unstable if their query points have nearly identical dissimilarity with most points in the dataset. This research has shown that, for various data distributions and dissimilarity functions, the probability of query instability approaches one. Previous work in Information Processing Letters by C. Giannella in 2021 explicated this phenomenon for centered Gaussian data and Euclidean distance. This paper addresses the problem of characterizing query instability behavior over centered Gaussian data and a fundamentally different dissimilarity function, cosine dissimilarity. Conditions are provided on the covariance matrices and dataset size function guaranteeing that the probability of query instability goes to one. Furthermore, conditions are provided under which the instability probability is bounded away from one.},
  archive      = {J_IPL},
  author       = {Chris R. Giannella},
  doi          = {10.1016/j.ipl.2024.106542},
  journal      = {Information Processing Letters},
  month        = {3},
  pages        = {106542},
  shortjournal = {Inf. Process. Lett.},
  title        = {Instability results for cosine-dissimilarity-based nearest neighbor search on high dimensional gaussian data},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="isci---12">ISCI - 12</h2>
<ul>
<li><details>
<summary>
(2025). Herbal ingredient-target interaction prediction via
multi-modal learning. <em>ISCI</em>, <em>711</em>, 122115. (<a
href="https://doi.org/10.1016/j.ins.2025.122115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computational prediction of herbal ingredient-target interactions (ITIs) is essential for understanding the mechanisms of action (MoA) of herbal medicine. However, many existing computational methods have yet to fully utilize the multi-modal knowledge of herbs, and the potential noise in literature-mined ITI data has been overlooked. To address these challenges, we propose Multi-ITI, a multi-modal learning framework to learn molecular biological and network topological features for ingredients and targets from multi-modal herbal data, including ingredient SMILES sequences, target protein sequences, ingredient SMILES sequence similarity, target protein sequence similarity, and ingredient-target interactions. Multi-ITI consists of a biological feature learning module and a heterogeneous graph learning module. The biological feature learning module integrates pre-trained models to build deep feature representations for ingredients and targets, while the heterogeneous graph learning module leverages a heterogeneous graph neural network with dynamic attention mechanisms to capture ingredient-target network interactions and mitigate the impact of noisy connections. Experimental results on three public datasets demonstrate that Multi-ITI outperforms six state-of-the-art methods. Additionally, we validate the effectiveness of Multi-ITI through molecular docking simulations and comparisons with recent studies, further highlighting its superior predictive performance and practical applicability.},
  archive      = {J_ISCI},
  author       = {Xudong Liang and Guichuan Lai and Jintong Yu and Tao Lin and Chaochao Wang and Wei Wang},
  doi          = {10.1016/j.ins.2025.122115},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122115},
  shortjournal = {Inf. Sci.},
  title        = {Herbal ingredient-target interaction prediction via multi-modal learning},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive stochastic configuration network based on online
active learning for evolving data streams. <em>ISCI</em>, <em>711</em>,
122113. (<a href="https://doi.org/10.1016/j.ins.2025.122113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic Configuration Networks (SCNs) have exhibited significant potential in data mining, owing to their advantages in fast incremental construction and universal approximation capabilities. However, less researches were done on SCNs-based classification models for concept-drifting data streams. The so-called drifts refer to data distributions changing over time that may degrade the classification performance of SCNs trained on historical data. The previous drift adaptation approach is to discard all the hidden nodes of SCNs, and then learn a new model with new instances, in which the valuable historical information cannot be fully utilized. In addition, labeling all newly-arrived instances is time-consuming and impractical. To address these issues, an adaptive stochastic configuration network embedding online active learning is proposed. Crucially, a query strategy is developed to select representative instances for labeling based on the change degree of instances density and their uncertainty. An online update mechanism is employed to incrementally update the network&#39;s output parameters instance by instance. To rationally forget the outdated information and learn new concepts, a dynamic adjustment mechanism adaptively adds or prunes nodes in the SCN model. Experimental results for nine datasets confirm that our algorithm outperforms six popular ones on classification accuracy.},
  archive      = {J_ISCI},
  author       = {Yinan Guo and Jiayang Pu and Jiale He and Botao Jiao and Jianjiao Ji and Shengxiang Yang},
  doi          = {10.1016/j.ins.2025.122113},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122113},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive stochastic configuration network based on online active learning for evolving data streams},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised manifold regularized multi-task learning
with privileged information. <em>ISCI</em>, <em>711</em>, 122112. (<a
href="https://doi.org/10.1016/j.ins.2025.122112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) represents an advanced learning paradigm that improves the generalization ability and learning efficiency of a model by learning multiple related tasks simultaneously. The fundamental principle of multi-task learning is the transfer of information between tasks. Nevertheless where data is limited in quantity, effectively modeling inter-task correlations is a significant challenge. We propose a novel method, semi-supervised manifold regularized multi-task learning with privileged information (MSMTL-PI), that effectively leverages the intrinsic geometric structure of data by enforcing manifold regularization and subspace learning techniques. Specifically, a similarity graph is constructed over both labeled and unlabeled samples, ensuring the preservation of local geometric relationships between data points, and manifold regularization is applied as a constraint. Concurrently, information sharing on low-dimensional subspace makes the relationship modeling between tasks more reasonable. Furthermore, a significant amount of privileged information is incorporated into the training phase, thereby optimizing the decision boundary and reducing the impact of insufficient labeled samples on the model. There is substantial experimental evidence that MSMTL-PI markedly enhances the performance of image and text classification tasks, achieving superior classification accuracy with minimal labeled data. Across 15 benchmark datasets, MSMTL-PI consistently outperforms existing methods, achieving an average F1-scores improvement of 1.92% compared to the best baseline, with a maximum gain of 4.17%.},
  archive      = {J_ISCI},
  author       = {Bo Liu and Baoqing Li and Yanshan Xiao and Zhitong Wang and Boxu Zhou and Shengxin He and Chenlong Ye and Fan Cao},
  doi          = {10.1016/j.ins.2025.122112},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122112},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised manifold regularized multi-task learning with privileged information},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-fragile fuzzy control of input-saturated systems with
global prescribed performance via an error-triggered mechanism.
<em>ISCI</em>, <em>711</em>, 122111. (<a
href="https://doi.org/10.1016/j.ins.2025.122111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An error-triggered mechanism-based non-fragile prescribed performance control (PPC) scheme is proposed for input-saturated systems in this paper. Unlike existing non-fragile PPC schemes, the proposed scheme only acts on the single prescribed performance boundary (PPB) and automatically relaxes only when the tracking error is about to contact the PPB. Moreover, through the redesign of the PPC, the scheme eliminates the initial feasibility condition and concurrently addresses settling time specifications, asymmetric regulation, and steady-state error correction. Additionally, the scheme incorporates a fuzzy logic system to approximate unknown smooth functions. The effectiveness and superiority of the proposed scheme are substantiated through simulation results.},
  archive      = {J_ISCI},
  author       = {Yu Xia and Jun He and Hak-Keung Lam and Leszek Rutkowski and Radu-Emil Precup},
  doi          = {10.1016/j.ins.2025.122111},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122111},
  shortjournal = {Inf. Sci.},
  title        = {Non-fragile fuzzy control of input-saturated systems with global prescribed performance via an error-triggered mechanism},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Batch active learning for time-series classification with
multi-mode exploration. <em>ISCI</em>, <em>711</em>, 122109. (<a
href="https://doi.org/10.1016/j.ins.2025.122109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collecting a sufficient amount of labeled data is challenging in practice. To deal with this challenge, active learning, which selects informative instances for annotation, has been studied. However, for time series, the dataset quality is often quite poor, and its multi-modality makes it unsuited to conventional active learning methods. Existing time series active learning methods have limitations, such as redundancy among selected instances, unrealistic assumptions on datasets, and inefficient calculations. We propose a batch active learning method for time series (BALT), which efficiently selects a batch of informative samples. BALT performs efficient clustering and picks one instance with the maximum informativeness score from each cluster. Using this score, we consider in-batch diversity explicitly so as to effectively handle multi-modality by exploring unknown regions, even under an extreme lack of labeled data. We also apply an adaptive weighting strategy to emphasize exploration in the early stage of the algorithm but shift to exploitation as the algorithm proceeds. Through experiments on several time-series datasets under various scenarios, we demonstrate the efficacy of BALT in achieving superior classification performance with less computation time under a predetermined budget, compared to existing time-series active learning methods.},
  archive      = {J_ISCI},
  author       = {Sangho Lee and Chihyeon Choi and Hyungrok Do and Youngdoo Son},
  doi          = {10.1016/j.ins.2025.122109},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122109},
  shortjournal = {Inf. Sci.},
  title        = {Batch active learning for time-series classification with multi-mode exploration},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Traffic forecasting using spatio-temporal dynamics and
attention with graph attention PDEs. <em>ISCI</em>, <em>711</em>,
122108. (<a href="https://doi.org/10.1016/j.ins.2025.122108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic forecasting is vital for optimizing intelligent transportation systems (ITS), yet existing models often struggle to capture the complex spatio-temporal patterns of urban traffic. We present GAPDE (Graph Attention Partial Differential Equation), a novel framework that integrates Partial Differential Equations (PDEs), Graph Convolutional Networks (GCNs), and advanced attention mechanisms. GAPDE enables continuous-time spatio-temporal modeling and dynamically prioritizes critical features through attention-driven traffic forecasting. Experiments on benchmark datasets, including PEMS-BAY, METR-LA, and various PeMS collections (PeMS03, PeMS04, PeMS07, PeMS08, PeMSD7M, and PeMSD7L), demonstrate GAPDE&#39;s superior performance over state-of-the-art models such as RGDAN, SGODE-RNN, and STD-MAE. GAPDE achieves up to 9.2 percent lower RMSE and 10.4 percent lower MAE, outperforming baselines in both short- and long-term prediction tasks. It demonstrates strong robustness to missing data, high scalability for large-scale networks, and enhanced interpretability through spatial and temporal attention visualizations. Comprehensive comparative evaluations and an in-depth ablation study further validate the effectiveness of GAPDE&#39;s components, including the GPDE block and spatio-temporal attention mechanisms. By combining PDEs, GCNs, and attention mechanisms in a scalable and efficient design, GAPDE offers a robust solution for real-time traffic forecasting in complex urban environments.},
  archive      = {J_ISCI},
  author       = {Ghadah Almousa and Yugyung Lee},
  doi          = {10.1016/j.ins.2025.122108},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122108},
  shortjournal = {Inf. Sci.},
  title        = {Traffic forecasting using spatio-temporal dynamics and attention with graph attention PDEs},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using AIE-d algorithm to recognize the node importance of
weighted urban rail transit network considering passenger flow.
<em>ISCI</em>, <em>711</em>, 122106. (<a
href="https://doi.org/10.1016/j.ins.2025.122106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The AIE-D algorithm (Adjacent Information Entropy-D algorithm) is proposed to recognize the importance of nodes in the urban rail transit network (URTN) weighted by passenger flow, which considers passenger flow, topological characteristics of nodes in the URTN, and the influence of neighboring nodes. The travel impedance is determined by using travel time, the D algorithm is used to search the k-short paths, and the weight value of each edge is the passenger flow cross-section of the corresponding line. Then, the detail AIE calculation steps are introduced. Next, a numerical study and comparison study are conducted by using the weighted topology of network. Compared with other commonly used algorithms, AIE-D has lower time complexity with faster calculation speed, and higher recognition accuracy. Finally, a real-world case study is conducted by using URTN of Chengdu Metro Network as the background. Weighted by passenger flow has greater impact on the operation of urban rail transit. The nodes are categorized into three classes according to the ranking of node importance, which includes Classification VI, Classification I and Classification GI. We conduct random attacks and deliberate attacks on the network, and analyze the network efficiency and maximum connectivity subgraph rate after the attacks.},
  archive      = {J_ISCI},
  author       = {Wencheng Huang and Xingyu Chen and Hongbing Pu and Yanhui Yin},
  doi          = {10.1016/j.ins.2025.122106},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122106},
  shortjournal = {Inf. Sci.},
  title        = {Using AIE-D algorithm to recognize the node importance of weighted urban rail transit network considering passenger flow},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A forward k-means algorithm for regression clustering.
<em>ISCI</em>, <em>711</em>, 122105. (<a
href="https://doi.org/10.1016/j.ins.2025.122105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel forward k -means algorithm for regression clustering, where the “forward” strategy progressively partitions samples from a single cluster into multiple ones, using the current optimal clustering solutions as initialization for subsequent iterations, thereby ensuring a deterministic result without any initialization requirements. We employ the mean squared error from the fitted clustering results as a criterion to guide partition optimization, which not only ensures rapid convergence of the algorithm to a stable solution but also yields desirable theoretical results. Meanwhile, we also suggest a difference-based threshold ridge ratio criterion to consistently determine the number of clusters. Comprehensive numerical studies are further conducted to demonstrate the algorithm&#39;s efficacy.},
  archive      = {J_ISCI},
  author       = {Jun Lu and Tingjin Luo and Kai Li},
  doi          = {10.1016/j.ins.2025.122105},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122105},
  shortjournal = {Inf. Sci.},
  title        = {A forward k-means algorithm for regression clustering},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refined kolmogorov complexity of analog, evolving and
stochastic recurrent neural networks. <em>ISCI</em>, <em>711</em>,
122104. (<a href="https://doi.org/10.1016/j.ins.2025.122104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kolmogorov complexity measures the compressibility of real numbers. We provide a refined characterization of the hypercomputational power of analog, evolving, and stochastic neural networks based on the Kolmogorov complexity of their real weights, evolving weights, and real probabilities, respectively. First, we retrieve the infinite hierarchy of complexity classes of analog networks, defined in terms of the Kolmogorov complexity of their real weights. This hierarchy lies between the complexity classes P and P / poly . Next, using a natural identification between real numbers and infinite sequences of bits, we generalize this result to evolving networks, obtaining a similar hierarchy of complexity classes within the same bounds. Finally, we extend these results to stochastic networks that employ real probabilities as randomness, deriving a new infinite hierarchy of complexity classes situated between BPP and BPP / lo g ⁎ . Beyond providing examples of such hierarchies, we describe a generic method for constructing them based on classes of functions of increasing complexity. As a practical application, we show that the predictive capabilities of recurrent neural networks are strongly impacted by the quantization applied to their weights. Overall, these results highlight the relationship between the computational power of neural networks and the intrinsic information contained by their parameters.},
  archive      = {J_ISCI},
  author       = {Jérémie Cabessa and Yann Strozecki},
  doi          = {10.1016/j.ins.2025.122104},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122104},
  shortjournal = {Inf. Sci.},
  title        = {Refined kolmogorov complexity of analog, evolving and stochastic recurrent neural networks},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The incremental SMOTE: A new approach based on the
incremental k-means algorithm for solving imbalanced data set problem.
<em>ISCI</em>, <em>711</em>, 122103. (<a
href="https://doi.org/10.1016/j.ins.2025.122103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is one of the very important areas in data mining. In real-life problems, developed methods for modeling with the classification problem generally perform well on datasets where the class distribution is balanced. On the other hand, the data sets are often imbalanced and it is important to develop algorithms to solve the classification problem on imbalanced data sets. Imbalanced datasets are more difficult to classify than balanced datasets because learning a class with underrepresentation is difficult. Most real life problems are imbalanced. The class with the least number of data usually corresponds to rare cases and is more important. Learning these classes is critical accordingly. One of the most commonly used solution methods to solve this problem is to oversample the minor class. When oversampling, too many repetitions in the dataset can cause overfitting. For this reason, it is very important to ensure data diversity when oversampling. Therefore, this paper proposes a new oversampling methods (the incremental SMOTE) combining the incremental k-means algorithm and Synthetic minority oversampling technique (SMOTE). The original dataset is clustered with the incremental k-means algorithm and the clusters are filtered to determine the safe clusters. The number of points to be produced from the safe clusters is determined, and then new instances are produced with the improved SMOTE algorithm. In the incremental SMOTE, diversity in the dataset is achieved by generating with incremental rate. In order to evaluate the performance of the incremental SMOTE algorithm, classification was performed on imbalanced datasets, balanced datasets obtained by the random oversampling, SMOTE, Borderline-SMOTE and SVM SMOTE methods. Comparisons for 10 datasets showed that the performance of the proposed method improves as the imbalance ratio of the dataset increases.},
  archive      = {J_ISCI},
  author       = {Duygu Selin Turan and Burak Ordin},
  doi          = {10.1016/j.ins.2025.122103},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122103},
  shortjournal = {Inf. Sci.},
  title        = {The incremental SMOTE: A new approach based on the incremental k-means algorithm for solving imbalanced data set problem},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel modelling method for rolling force prediction based
on deep stochastic configuration networks fused with physical knowledge.
<em>ISCI</em>, <em>711</em>, 122097. (<a
href="https://doi.org/10.1016/j.ins.2025.122097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the production of hot-rolled strip steal, the use of physical models frequently leads to inaccurate predictions of rolling force because some parameters are determined empirically. Further, purely data-driven models may not necessarily conform to the rolling principles, significantly restricting the applicability of machine learning in practical scenarios. Consequently, this study proposes an innovative modelling approach for predicting rolling force, utilizing a deep stochastic configuration network (DeepSCN) integrated with physical knowledge. Considering the many empirical parameters in existing physical models, an improved dung beetle optimizer (IDBO) is developed to optimize these parameters, thereby enhancing the accuracy of the physical models and acquiring more reasonable physical features. Subsequently, those physical features are utilized as deep inputs for the DeepSCN model to achieve the fusion of physical knowledge and data-driven approaches. The results suggest that the proposed model outperforms both physical and pure data-driven models. This work is able to demonstrate that the proposed fusion model conforms to the existing rolling theories and is suitable for various working conditions.},
  archive      = {J_ISCI},
  author       = {LingMing Meng and JingGuo Ding and ZiShuo Dong and Chuang Zhang and Wen Peng and DianHua Zhang},
  doi          = {10.1016/j.ins.2025.122097},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {122097},
  shortjournal = {Inf. Sci.},
  title        = {A novel modelling method for rolling force prediction based on deep stochastic configuration networks fused with physical knowledge},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An innovative recommendation-driven friendship path
selection strategy utilizing multi-agent collaborative edge caching for
social IoT networks. <em>ISCI</em>, <em>711</em>, 121914. (<a
href="https://doi.org/10.1016/j.ins.2025.121914">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing complexity of the Social Internet of Things (SIoT) networks necessitates more efficient and intelligent methods for managing social interactions and service recommendations. This paper introduces a novel approach to improving the process of selecting SIoT friendship paths based on real-time recommendations leveraging a collaborative caching Multi-Agent Federated Deep Reinforcement Learning (MAFDRL) framework. This process involves using recommendation algorithms to predict and select optimal friendship connections, enhancing navigability and interaction efficiency within SIoT environments. The proposed model incorporates both the social relationships and resource-sharing dynamics of Internet of Things (IoT) devices to optimize recommendation accuracy and network performance. By combining Federated Learning (FL) principles with Deep Reinforcement Learning (DRL), the MAFDRL framework allows multiple agents to collaboratively train models without compromising privacy, ensuring scalability across distributed networks. Additionally, the integration of cache-driven techniques enhances computational efficiency, reducing latency and cost in friendship path discovery and improving real-time decision-making. Our experiments, conducted with the Waze and MovieLens-1 M datasets, reveal that the introduced framework achieves an average 30 % reduction in system and delay expenses. It also improves cache hit efficiency, with expenses reduced by approximately 25 % and around a 35 % increase in the accuracy of personalized recommendations.},
  archive      = {J_ISCI},
  author       = {Babak Farhadi and Parvaneh Asghari and Azadeh Zamanifar and Hamid Haj Seyyed Javadi},
  doi          = {10.1016/j.ins.2025.121914},
  journal      = {Information Sciences},
  month        = {9},
  pages        = {121914},
  shortjournal = {Inf. Sci.},
  title        = {An innovative recommendation-driven friendship path selection strategy utilizing multi-agent collaborative edge caching for social IoT networks},
  volume       = {711},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jat---5">JAT - 5</h2>
<ul>
<li><details>
<summary>
(2025). Asymptotics of bergman polynomials for domains with
reflection-invariant corners. <em>JAT</em>, <em>309</em>, 106172. (<a
href="https://doi.org/10.1016/j.jat.2025.106172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the asymptotic behavior of the Bergman orthogonal polynomials ( p n ) n = 0 ∞ for a class of bounded simply connected domains D . The class is defined by the requirement that conformal maps φ of D onto the unit disk extend analytically across the boundary L of D , and that φ ′ has a finite number of zeros z 1 , … , z q on L . The boundary L is then piecewise analytic with corners at the zeros of φ ′ . A result of Stylianopoulos implies that a Carleman-type strong asymptotic formula for p n holds on the exterior domain ℂ ∖ D ¯ . We prove that the same formula remains valid across L ∖ { z 1 , … , z q } and on a maximal open subset of D . As a consequence, the only boundary points that attract zeros of p n are the corners. This is in stark contrast to the case when φ fails to admit an analytic extension past L , since when this happens the zero counting measure of p n is known to approach the equilibrium measure for L along suitable subsequences.},
  archive      = {J_JAT},
  author       = {Erwin Miña-Díaz and Aron Wennman},
  doi          = {10.1016/j.jat.2025.106172},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106172},
  shortjournal = {J. Approx. Theory},
  title        = {Asymptotics of bergman polynomials for domains with reflection-invariant corners},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A note on diffusion limits for stochastic gradient descent.
<em>JAT</em>, <em>309</em>, 106160. (<a
href="https://doi.org/10.1016/j.jat.2025.106160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the machine learning literature stochastic gradient descent has recently been widely discussed for its purported implicit regularization properties. Much of the theory, that attempts to clarify the role of noise in stochastic gradient algorithms, has approximated stochastic gradient descent by a stochastic differential equation with Gaussian noise. We provide a rigorous theoretical justification for this practice that showcases how the Gaussianity of the noise arises naturally.},
  archive      = {J_JAT},
  author       = {Alberto Lanconelli and Christopher S.A. Lauria},
  doi          = {10.1016/j.jat.2025.106160},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106160},
  shortjournal = {J. Approx. Theory},
  title        = {A note on diffusion limits for stochastic gradient descent},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pseudo s-numbers of embeddings of gaussian weighted sobolev
spaces. <em>JAT</em>, <em>309</em>, 106159. (<a
href="https://doi.org/10.1016/j.jat.2025.106159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the approximation problem for functions in the Gaussian-weighted Sobolev space W p α ( R d , γ ) of mixed smoothness α ∈ N with error measured in the Gaussian-weighted space L q ( R d , γ ) . We obtain the exact asymptotic order of some pseudo s -numbers for the cases 1 ≤ q &lt; p &lt; ∞ and p = q = 2 . Additionally, we also obtain an upper bound and a lower bound for some pseudo s -numbers of the embedding of W 2 α ( R d , γ ) into L ∞ g ( R d ) . Our result is an extension of that obtained in Dinh Dũng and Van Kien Nguyen (IMA Journal of Numerical Analysis, 2023) for approximation and Kolmogorov numbers.},
  archive      = {J_JAT},
  author       = {Van Kien Nguyen},
  doi          = {10.1016/j.jat.2025.106159},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106159},
  shortjournal = {J. Approx. Theory},
  title        = {Pseudo s-numbers of embeddings of gaussian weighted sobolev spaces},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relative asymptotics of multiple orthogonal polynomials for
nikishin systems of two measures. <em>JAT</em>, <em>309</em>, 106158.
(<a href="https://doi.org/10.1016/j.jat.2025.106158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the relative asymptotics of two sequences of multiple orthogonal polynomials corresponding to two Nikishin systems of measures on the real line, the second one of which is obtained from the first one perturbing the generating measures with non-negative integrable functions. Each Nikishin system consists of two measures.},
  archive      = {J_JAT},
  author       = {A. López García and G. López Lagomasino},
  doi          = {10.1016/j.jat.2025.106158},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106158},
  shortjournal = {J. Approx. Theory},
  title        = {Relative asymptotics of multiple orthogonal polynomials for nikishin systems of two measures},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The pearcey integral in the highly oscillatory region II.
<em>JAT</em>, <em>309</em>, 106150. (<a
href="https://doi.org/10.1016/j.jat.2025.106150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the Pearcey integral P ( x , y ) for large values of | x | and bounded values of | y | . The standard saddle point analysis is difficult to apply because the Pearcey integral is highly oscillating in this region. To overcome this problem we use the modified saddle point method introduced in López et al. (2009). A complete asymptotic analysis is possible with this method, and we derive a complete asymptotic expansion of P ( x , y ) for large | x | , accompanied by the exact location of the Stokes lines. There are two Stokes lines that divide the complex x − plane in two different sectors in which P ( x , y ) behaves differently when | x | is large. The asymptotic approximation is the sum of two asymptotic series whose terms are elementary functions of x and y . Both of them are of Poincaré type; one of them is given in terms of inverse powers of x ; the other one in terms of inverse powers of x 1 / 2 , and it is multiplied by an exponential factor that behaves differently in the two mentioned sectors. Some numerical experiments illustrate the accuracy of the approximation.},
  archive      = {J_JAT},
  author       = {Chelo Ferreira and José L. López and Ester Pérez Sinusía},
  doi          = {10.1016/j.jat.2025.106150},
  journal      = {Journal of Approximation Theory},
  month        = {8},
  pages        = {106150},
  shortjournal = {J. Approx. Theory},
  title        = {The pearcey integral in the highly oscillatory region II},
  volume       = {309},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jde---10">JDE - 10</h2>
<ul>
<li><details>
<summary>
(2025). Local well-posedness of the minimum energy estimator for a
defocusing cubic wave equation. <em>JDE</em>, <em>435</em>, 113258. (<a
href="https://doi.org/10.1016/j.jde.2025.113258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is concerned with the minimum energy estimator for a nonlinear hyperbolic partial differential equation. The Mortensen observer – originally introduced for the energy-optimal reconstruction of the state of nonlinear finite-dimensional systems – is formulated for a disturbed cubic wave equation and the associated observer equation is derived. An in depth study of the associated optimal control problem and sensitivity analysis of the corresponding value function reveals that the energy optimal state estimator is well-defined. Deploying a classical fixed point argument we proceed to show that the observer equation is locally well-posed.},
  archive      = {J_JDE},
  author       = {Jesper Schröder},
  doi          = {10.1016/j.jde.2025.113258},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113258},
  shortjournal = {J. Diff. Equ.},
  title        = {Local well-posedness of the minimum energy estimator for a defocusing cubic wave equation},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics and integrability of polynomial vector fields on
the n-dimensional sphere. <em>JDE</em>, <em>435</em>, 113253. (<a
href="https://doi.org/10.1016/j.jde.2025.113253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we characterize arbitrary polynomial vector fields on S n . We establish a necessary and sufficient condition for a degree one vector field on the odd-dimensional sphere S 2 n − 1 to be Hamiltonian. Additionally, we classify polynomial vector fields on S n up to degree two that possess an invariant great ( n − 1 ) -sphere. We present a class of completely integrable vector fields on S n . We found a sharp bound for the number of invariant meridian hyperplanes for a polynomial vector field on S 2 . Furthermore, we compute the sharp bound for the number of invariant parallel hyperplanes for any polynomial vector field on S n . Finally, we study homogeneous polynomial vector fields on S n , providing a characterization of their invariant ( n − 1 ) -spheres.},
  archive      = {J_JDE},
  author       = {Supriyo Jana and Soumen Sarkar},
  doi          = {10.1016/j.jde.2025.113253},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113253},
  shortjournal = {J. Diff. Equ.},
  title        = {Dynamics and integrability of polynomial vector fields on the n-dimensional sphere},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamics of a periodic predator-prey reaction-diffusion
system in heterogeneous environments. <em>JDE</em>, <em>435</em>,
113252. (<a href="https://doi.org/10.1016/j.jde.2025.113252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is dedicated to investigating a predator-prey reaction-diffusion model with time-periodic, where all coefficient functions are both spatially and temporally heterogeneous. We rigorously characterize the properties of the principal eigenvalue and establish a precise relationship between the coefficient functions and the dynamics. Our results indicate that slow predator movement and short frequency of environmental periodic variations promote successful predator invasion. Conversely, reducing the predator mortality rate facilitates long-term coexistence of both populations. Additionally, we explore the asymptotic behaviors of positive periodic solutions when the diffusion coefficients are large or small, revealing the effects of diffusion on the invasion dynamics.},
  archive      = {J_JDE},
  author       = {Zhenrui Zhang and Jinfeng Wang},
  doi          = {10.1016/j.jde.2025.113252},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113252},
  shortjournal = {J. Diff. Equ.},
  title        = {Dynamics of a periodic predator-prey reaction-diffusion system in heterogeneous environments},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Second order regularity for solutions to anisotropic
degenerate elliptic equations. <em>JDE</em>, <em>435</em>, 113250. (<a
href="https://doi.org/10.1016/j.jde.2025.113250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider solutions to degenerate anisotropic elliptic equations in order to study their regularity. In particular we establish second-order estimates and enclose regularity results for the stress field. All our results are new even in the euclidean case.},
  archive      = {J_JDE},
  author       = {Daniel Baratta and Luigi Muglia and Domenico Vuono},
  doi          = {10.1016/j.jde.2025.113250},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113250},
  shortjournal = {J. Diff. Equ.},
  title        = {Second order regularity for solutions to anisotropic degenerate elliptic equations},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On li-lin’s open problem. <em>JDE</em>, <em>435</em>,
113244. (<a href="https://doi.org/10.1016/j.jde.2025.113244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we give a first negative answer to a question proposed by Li and Lin (2012) [5] . Meanwhile, we also give a second positive answer to the Li-Lin&#39;s open problem. The first positive answer was given by G. Cerami, X. Zhong and W. Zou (2015) [2] .},
  archive      = {J_JDE},
  author       = {Zhi-Yun Tang and Xianhua Tang},
  doi          = {10.1016/j.jde.2025.113244},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113244},
  shortjournal = {J. Diff. Equ.},
  title        = {On li-lin&#39;s open problem},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A simple way to well-posedness in h1 of a delay differential
equation from cell biology. <em>JDE</em>, <em>435</em>, 113241. (<a
href="https://doi.org/10.1016/j.jde.2025.113241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an application of recent well-posedness results in the theory of delay differential equations for ordinary differential equations [10] to a generalized population model for stem cell maturation. The weak approach using Sobolev-spaces we take allows for a larger class of initial prehistories and makes checking the requirements for well-posedness of such a model considerably easier compared to previous approaches. In fact the present approach is a possible means to guarantee that the solution manifold is not empty, which is a necessary requirement for a C 1 -approach to work.},
  archive      = {J_JDE},
  author       = {Bernhard Aigner and Marcus Waurick},
  doi          = {10.1016/j.jde.2025.113241},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113241},
  shortjournal = {J. Diff. Equ.},
  title        = {A simple way to well-posedness in h1 of a delay differential equation from cell biology},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Backward stochastic volterra integral equations with jumps
and some related problems. <em>JDE</em>, <em>435</em>, 113240. (<a
href="https://doi.org/10.1016/j.jde.2025.113240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we deal with backward stochastic Volterra integral equations with jumps. Firstly, we present the well-posedness of backward stochastic Volterra integral equations with jumps in the sense of adapted M-solution. Secondly, we give some properties of backward stochastic Volterra integral equations with jumps, which contain the duality principle, comparison theorem and the regularity of adapted M-solution. Thirdly, dynamic risk measure by means of backward stochastic Volterra integral equations with jumps is established. Fourthly, a maximum principle of Pontryagin type is obtained for an optimal control problem of stochastic Volterra integral equations with jumps. Finally, we investigate the well-posedness of linear fractional backward stochastic Volterra integral equations.},
  archive      = {J_JDE},
  author       = {Zongkui Fu and Shasha Shen and Jinbiao Wu},
  doi          = {10.1016/j.jde.2025.113240},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113240},
  shortjournal = {J. Diff. Equ.},
  title        = {Backward stochastic volterra integral equations with jumps and some related problems},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-time-scale stochastic functional differential equations:
Inclusion of infinite delay and coupled segment processes. <em>JDE</em>,
<em>435</em>, 113238. (<a
href="https://doi.org/10.1016/j.jde.2025.113238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on two-time-scale stochastic functional differential equations (SFDEs). It features in inclusion of infinite delay and coupling of slow and fast components. The coupling is through the segment processes of the slow and fast processes. The main difficulties include infinite delay and the coupling of segment processes involving fast and slow motions. Concentrating on weak convergence, the tightness of the segment process is established on a space of continuous functions. In addition, the Hölder continuity and boundedness for the segment process of the slow component, uniform boundedness for the segment process of a fixed- x SFDE, exponential ergodicity, and continuous dependence on parameters are obtained to carry out the desired asymptotic analysis, and also as byproducts, which are interesting in their own right. Then using the martingale problem formulation, an average principle is established by a direct averaging, which involves detailed computations and subtle estimates. Finally, two classes of special SFDEs, stochastic integro-differential equations and stochastic delay differential equations with two-time scales are investigated.},
  archive      = {J_JDE},
  author       = {Fuke Wu and George Yin},
  doi          = {10.1016/j.jde.2025.113238},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113238},
  shortjournal = {J. Diff. Equ.},
  title        = {Two-time-scale stochastic functional differential equations: Inclusion of infinite delay and coupled segment processes},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local controllability of the korteweg-de vries equation with
the right dirichlet control. <em>JDE</em>, <em>435</em>, 113235. (<a
href="https://doi.org/10.1016/j.jde.2025.113235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Korteweg-de Vries (KdV) equation with the right Dirichlet control is small time, locally, exactly controllable for all non-critical lengths and its linearized system is not controllable for all critical lengths. In this paper, we give a definitive picture of the local controllability properties of this control problem for all critical lengths. In particular, we show that the unreachable space of the linearized system is always of dimension 1 and the KdV system with the right Dirichlet control is not locally null controllable in small time for any critical length. We also give a criterion to determine whether the system is locally exactly controllable in finite time or not locally null controllable in any positive time for all critical lengths. Consequently, we show that there exist critical lengths such that the system is not locally null controllable in small time but is locally exactly controllable in finite time.},
  archive      = {J_JDE},
  author       = {Hoai-Minh Nguyen},
  doi          = {10.1016/j.jde.2025.113235},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113235},
  shortjournal = {J. Diff. Equ.},
  title        = {Local controllability of the korteweg-de vries equation with the right dirichlet control},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global boundedness of solutions to a class of partial
differential equations with time delay. <em>JDE</em>, <em>435</em>,
113232. (<a href="https://doi.org/10.1016/j.jde.2025.113232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of diffusive partial differential equations with strongly coupled time delays and diffusion is considered. The global boundedness of weak solutions of the equation is proved by an entropy method that was initially proposed for studying the global boundedness of reaction-diffusion equations with cross-diffusion. The presence of the time delays in the equation prevents the entropy method to be directly applied, and here we extend the entropy method to this class of diffusive partial differential equations with time delays by proving some key entropy inequalities, which further allows us to obtain the estimates of gradient of the solutions. The results can be used to show the global boundedness of solutions of population models with memory effect, which were recently proposed for describing the movement of highly-developed animal species. In addition, we show that the results are also applicable for the classic partial functional differential equations, where the time delays only appear in the reaction terms.},
  archive      = {J_JDE},
  author       = {Xuanyu Liu and Junping Shi and Chuncheng Wang and Dejun Fan},
  doi          = {10.1016/j.jde.2025.113232},
  journal      = {Journal of Differential Equations},
  month        = {8},
  pages        = {113232},
  shortjournal = {J. Diff. Equ.},
  title        = {Global boundedness of solutions to a class of partial differential equations with time delay},
  volume       = {435},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jmaa---19">JMAA - 19</h2>
<ul>
<li><details>
<summary>
(2025). Composition of locally solid convergences. <em>JMAA</em>,
<em>549</em>(2), 129511. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We carry on a more detailed investigation of the composition of locally solid convergences as introduced in [6] , as well as the corresponding notion of idempotency considered in [4] . In particular, we study the interactions between these two concepts and various operations with convergences. We prove associativity of the composition and show that the adherence of an ideal with respect to an idempotent convergence is equal to its closure. Some results from [12] about unbounded modification of locally solid topologies are generalized to the level of locally solid idempotent convergences. A simple application of the composition allows us to answer a question from [6] about minimal Hausdorff locally solid convergences. We also show that the weakest Hausdorff locally solid convergence exists on an Archimedean vector lattice if and only if it is atomic.},
  archive      = {J_JMAA},
  author       = {Eugene Bilokopytov},
  doi          = {10.1016/j.jmaa.2025.129511},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129511},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Composition of locally solid convergences},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two-dimensional schrödinger operators with non-local
singular potentials. <em>JMAA</em>, <em>549</em>(2), 129498. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce and study a family of self-adjoint realizations of the Laplacian in L 2 ( R 2 ) with a new type of transmission conditions along a closed bi-Lipschitz curve Σ. These conditions incorporate jumps in the Dirichlet traces both of the functions in the operator domains and of their Wirtinger derivatives and are non-local. Constructing a convenient generalized boundary triple, they may be parametrized by all compact self-adjoint operators in L 2 ( Σ ; C 2 ) . Whereas for all choices of parameters the essential spectrum is stable and equal to [ 0 , + ∞ ) , the discrete spectrum exhibits diverse behavior. While in many cases it is finite, we will describe also a class of parameters for which the discrete spectrum is infinite and accumulates at −∞. The latter class contains a non-local version of the oblique transmission conditions. Finally, we will connect the current model to its relativistic counterpart studied recently in [33] .},
  archive      = {J_JMAA},
  author       = {Lukáš Heriban and Markus Holzmann and Christian Stelzer-Landauer and Georg Stenzel and Matěj Tušek},
  doi          = {10.1016/j.jmaa.2025.129498},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129498},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Two-dimensional schrödinger operators with non-local singular potentials},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dirac structure for linear dynamical systems on sobolev
spaces. <em>JMAA</em>, <em>549</em>(2), 129493. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The port-Hamiltonian structure of linear dynamical systems is defined by a Dirac structure. In this paper we prove existence and well-posedness of a Dirac structure for linear dynamical systems on Sobolev spaces of differential forms on a bounded, connected and oriented manifold with Lipschitz continuous boundary. This result extends the proof of a Dirac structure for linear dynamical systems originally defined on smooth differential forms to a much larger class of function spaces, which is of theoretical importance and provides a solid basis for the numerical discretization of many linear port-Hamiltonian dynamical systems.},
  archive      = {J_JMAA},
  author       = {N. Kumar and H.J. Zwart and J.J.W. van der Vegt},
  doi          = {10.1016/j.jmaa.2025.129493},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129493},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Dirac structure for linear dynamical systems on sobolev spaces},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An alternate proof for the global mean speed of bistable
transition fronts. <em>JMAA</em>, <em>549</em>(2), 129492. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an alternate proof to show the existence and uniqueness of the global mean speed of bistable transition fronts under a general framework.},
  archive      = {J_JMAA},
  author       = {Linlin Li and Hong Xu and Zhi-Cheng Wang},
  doi          = {10.1016/j.jmaa.2025.129492},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129492},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {An alternate proof for the global mean speed of bistable transition fronts},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). (P,q)-sobolev inequality and nash inequality on compact
finsler metric measure manifolds. <em>JMAA</em>, <em>549</em>(2),
129491. (<a href="https://doi.org/10.1016/j.jmaa.2025.129491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we carry out in-depth research centering around the ( p , q ) -Sobolev inequality and Nash inequality on compact Finsler metric measure manifolds under the condition that Ric ∞ ≥ − K for some K ≥ 0 . We first obtain a global p -Poincaré inequality on complete Finsler manifolds. Based on this, we can derive a ( p , q ) -Sobolev inequality. Furthermore, we establish a global optimal ( p , q ) -Sobolev inequality. Finally, as an application of the p -Poincaré inequality, we prove a Nash inequality.},
  archive      = {J_JMAA},
  author       = {Xinyue Cheng and Qihui Ni},
  doi          = {10.1016/j.jmaa.2025.129491},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129491},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {(p,q)-sobolev inequality and nash inequality on compact finsler metric measure manifolds},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Null controllability for cascade systems of coupled backward
stochastic parabolic equations with one distributed control.
<em>JMAA</em>, <em>549</em>(2), 129489. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove the null controllability of a cascade system of n coupled backward stochastic parabolic equations, which involve both reaction and convection terms, as well as general second-order parabolic operators, with n ≥ 2 . To achieve this, we apply a single distributed control to the first equation, while the other equations are controlled through the coupling. To obtain our results, we develop a new global Carleman estimate for the forward stochastic parabolic adjoint system, with some terms in the H − 1 -space. Subsequently, we derive the corresponding observability inequality, and using the classical duality argument, we establish our null controllability result. Additionally, we provide an accurate estimate for the null control cost in terms of the final time T and the potentials of the system.},
  archive      = {J_JMAA},
  author       = {Said Boulite and Abdellatif Elgrou and Lahcen Maniar},
  doi          = {10.1016/j.jmaa.2025.129489},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129489},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Null controllability for cascade systems of coupled backward stochastic parabolic equations with one distributed control},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spherically symmetric strong solution of compressible flow
with large data and density-dependent viscosities. <em>JMAA</em>,
<em>549</em>(2), 129488. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the isentropic compressible Navier-Stokes equations with density-dependent viscosities μ ( ρ ) = ρ α , λ ( ρ ) = ( α − 1 ) ρ α in N -dimensional ( N = 2 , 3 ) bounded domain when the initial data are spherically symmetric. Based on the exploitation of the one-dimensional and non-swirl feature of symmetric solution, together with the BD-entropy estimates, the global well-posedness of strong solution with the symmetry center is proved for non-vacuum and large initial data as N = 2 , 4 5 ≤ α &lt; 1 , 1 &lt; γ or N = 3 , 7 8 ≤ α &lt; 1 , 1 &lt; γ &lt; 9 α − 6 . In particular, it is shown that the solution will not develop the vacuum states in any finite time provided that no vacuum states are present initially.},
  archive      = {J_JMAA},
  author       = {Xueyao Zhang},
  doi          = {10.1016/j.jmaa.2025.129488},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129488},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Spherically symmetric strong solution of compressible flow with large data and density-dependent viscosities},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Upper bounds for the blow-up time of the 2-d
parabolic-elliptic patlak-keller-segel model of chemotaxis.
<em>JMAA</em>, <em>549</em>(2), 129487. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we obtain upper bounds for the critical time T ⁎ of the blow-up for the parabolic-elliptic Patlak-Keller-Segel system on the 2D-Euclidean space. No moment condition or/and entropy condition are required on the initial data; only the usual assumptions of non-negativity and finiteness of the total mass is assumed. The result is expressed not only in terms of supercritical mass M &gt; 8 π , but also in terms of the shape of the initial data.},
  archive      = {J_JMAA},
  author       = {Patrick Maheux},
  doi          = {10.1016/j.jmaa.2025.129487},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129487},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Upper bounds for the blow-up time of the 2-d parabolic-elliptic patlak-keller-segel model of chemotaxis},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polynomial growth and functional calculus in algebras of
integrable cross-sections. <em>JMAA</em>, <em>549</em>(2), 129486. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let G be a locally compact group with polynomial growth of order d , a polynomial weight ν on G and a Fell bundle C → q G . We study the Banach ⁎ -algebras L 1 ( G | C ) and L 1 , ν ( G | C ) , consisting of integrable cross-sections with respect to d x and ν ( x ) d x , respectively. By exploring new relations between the L p -norms and the norm of the Hilbert C ⁎ -module L e 2 ( G | C ) , we are able to show that the growth of the self-adjoint, compactly supported, continuous cross-sections is polynomial. More precisely, they satisfy ‖ e i t Φ ‖ = O ( | t | n ) , as | t | → ∞ , for values of n that only depend on d and the weight ν . We use this fact to develop a smooth functional calculus for such elements. We also give some sufficient conditions for these algebras to be symmetric. As consequences, we show that these algebras are locally regular, ⁎ -regular and have the Wiener property (when symmetric), among other results. Our results are already new for convolution algebras associated with C ⁎ -dynamical systems.},
  archive      = {J_JMAA},
  author       = {Felipe I. Flores},
  doi          = {10.1016/j.jmaa.2025.129486},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129486},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Polynomial growth and functional calculus in algebras of integrable cross-sections},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the existence of eigenvalues of a one-dimensional dirac
operator. <em>JMAA</em>, <em>549</em>(2), 129485. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to study the existence of eigenvalues in the gap of the essential spectrum of the one-dimensional Dirac operator in the presence of a bounded potential. We employ a generalized variational principle to prove existence of such eigenvalues, estimate how many eigenvalues there are, and give upper and lower bounds for them.},
  archive      = {J_JMAA},
  author       = {Daniel Sánchez-Mendoza and Monika Winklmeier},
  doi          = {10.1016/j.jmaa.2025.129485},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129485},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On the existence of eigenvalues of a one-dimensional dirac operator},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On elliptic equations with unbounded or decaying potentials
involving stein-weiss convolution parts and critical exponential growth.
<em>JMAA</em>, <em>549</em>(2), 129483. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a class of nonlinear Schrödinger equations with Stein-Weiss convolution parts − Δ u + V ( x ) u = ( ∫ R 2 F ( u ) | x − y | μ | | y | β d y ) f ( u ) | x | β , x ∈ R 2 , where V is an unbounded or decaying potential, β &gt; 0 , μ &gt; 0 with 0 &lt; 2 β + μ &lt; 2 , and F denotes the primitive of f that fulfills the critical exponential growth in the Trudinger-Moser sense at infinity. Via establishing a new version of the Trudinger-Moser inequality, we shall exploit the general minimax principle to demonstrate the existence of nontrivial solutions using variational method.},
  archive      = {J_JMAA},
  author       = {Claudianor Oliveira Alves and Manassés de Souza and Liejun Shen},
  doi          = {10.1016/j.jmaa.2025.129483},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129483},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {On elliptic equations with unbounded or decaying potentials involving stein-weiss convolution parts and critical exponential growth},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A (μ,ν)-dichotomy spectrum. <em>JMAA</em>, <em>549</em>(2),
129482. (<a href="https://doi.org/10.1016/j.jmaa.2025.129482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce three notions of dichotomy spectrum based on general growth rates and describe their structure. Our results are applicable to nonautonomous linear systems acting on general Banach spaces having negative μ -index of compactness, a condition which is satisfied, for instance, by any sequence of compact operators. Moreover, for any possible form of the spectra, we present an explicit example exhibiting such spectrum. Furthermore, as an application, we obtain normal forms of certain nonautonomous systems. We emphasize that the classical Sacker-Sell spectrum can be obtained as a very particular case of our setting.},
  archive      = {J_JMAA},
  author       = {Lucas Backes},
  doi          = {10.1016/j.jmaa.2025.129482},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129482},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {A (μ,ν)-dichotomy spectrum},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The fueter mittag-leffler bargmann transform. <em>JMAA</em>,
<em>549</em>(2), 129480. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we continue exploring the Mittag-Leffler Bargmann (MLB) transform, which maps the Hilbert space L 2 ( R ) onto the Mittag-Leffler-Fock (MLF) space. The MLF space is a reproducing kernel Hilbert space that extends the classic Fock space and its reproducing kernel is given by the Mittag-Leffler function. We study the MLB transform and its main properties in the quaternionic setting. In this noncommutative setting there are two function theories that are prominent: the slice hyperholomorphic theory and the Fueter regular theory. The connection between the slice hyperholomorphic functions and the Fueter regular functions is given by the Fueter mapping theorem. The Mittag-Leffler Bargmann transform investigated in this paper maps the quaternionic-valued L 2 ( R , H ) space onto a counterpart of the MLF space in the Fueter regular setting. Finally the creation, annihilation, backward-shift and integration operators are studied in the case of the Fueter-MLF space.},
  archive      = {J_JMAA},
  author       = {Natanael Alpay and Antonino De Martino and Kamal Diki},
  doi          = {10.1016/j.jmaa.2025.129480},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129480},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {The fueter mittag-leffler bargmann transform},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence at infinity for solutions of nonhomogeneous
degenerate and singular elliptic equations in exterior domains.
<em>JMAA</em>, <em>549</em>(2), 129476. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the existence of the limit at infinity of weak solutions of the nonhomogeneous equation − div ( | ∇ u | p − 2 A ( | ∇ u | ) ∇ u ) = f in the exterior domain R n ﹨ K , where K ⊂ R n is a compact set. Indeed, for any p ∈ ( 1 , + ∞ ) and n ≥ 2 , we prove that the solutions converge at infinity if A satisfies some growth conditions and f ∈ L ∞ ( R n ) has some decay property. Moreover, for p &gt; n we can show that the solutions converge at some rate and, for p &lt; n , the convergence holds even for some unbounded f . In addition, for p &gt; n , we show that for any continuous function ϕ defined on ∂ K , the problem { − div ( | ∇ u | p − 2 A ( | ∇ u | ) ∇ u ) = f in R n ﹨ K u = ϕ , on ∂ K has a bounded weak solution in C ( R n ﹨ K ‾ ) ∩ C 1 ( R n ﹨ K ) , provided A and f are suitable. Furthermore, if ϕ ∈ C α ( K ) , then this solution is in C α ( R n ) .}},
  archive      = {J_JMAA},
  author       = {Leonardo P. Bonorino and Lucas P. Dutra and Filipe J. dos Santos},
  doi          = {10.1016/j.jmaa.2025.129476},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129476},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Convergence at infinity for solutions of nonhomogeneous degenerate and singular elliptic equations in exterior domains},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local and global properties of spaces of minimal usco maps.
<em>JMAA</em>, <em>549</em>(2), 129472. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study an interplay between local and global properties of spaces of minimal usco maps equipped with the topology of uniform convergence on compact sets. In particular, for each locally compact space X and metric space Y , we characterize the space of minimal usco maps from X to Y , satisfying one of the following properties: (i) compact, (ii) locally compact, (iii) σ -compact, (iv) locally σ -compact, (v) metrizable, (vi) ccc, (vii) locally ccc, where in the last two items we additionally assumed that Y is separable and non-discrete. Some of the aforementioned results complement ones of Ľubica Holá and Dušan Holý. Also, we obtain analogous characterizations for spaces of minimal cusco maps.},
  archive      = {J_JMAA},
  author       = {Serhii Bardyla and Branislav Novotný and Jaroslav Šupina},
  doi          = {10.1016/j.jmaa.2025.129472},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129472},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Local and global properties of spaces of minimal usco maps},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local existence and uniqueness of classical solutions for a
compressible oldroyd-b model with vacuum. <em>JMAA</em>,
<em>549</em>(2), 129450. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider compressible Oldroyd-B equations in a bounded or unbounded domain Ω of R 3 . Assuming that the initial data satisfy a natural compatibility condition, we show the local existence and uniqueness of the classical solutions for Oldroyd-B equations through some high-order estimations with respect to time weighting. To obtain the result, the initial density does not need to differ from zero and may vanish in an open subset (vacuum) of Ω or decay at infinity when Ω is unbounded.},
  archive      = {J_JMAA},
  author       = {Yubi Yin and Xingyang Zhang},
  doi          = {10.1016/j.jmaa.2025.129450},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129450},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Local existence and uniqueness of classical solutions for a compressible oldroyd-B model with vacuum},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotics for k-crank of k-colored partitions.
<em>JMAA</em>, <em>549</em>(2), 129447. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we obtain asymptotic formulas for the k -crank of k -colored partitions. Let M k ( a , c ; n ) denote the number of k -colored partitions of n with a k -crank congruent to a mod c . For the cases k = 2 , 3 , 4 , Fu and Tang derived several inequality relations for M k ( a , c ; n ) using generating functions. We employ the Hardy-Ramanujan Circle Method to extend the results of Fu and Tang. Furthermore, strict log-subadditivity for M k ( a , c ; n ) is established.},
  archive      = {J_JMAA},
  author       = {Helen W.J. Zhang and Ying Zhong},
  doi          = {10.1016/j.jmaa.2025.129447},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129447},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Asymptotics for k-crank of k-colored partitions},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Admissibility and generalized nonuniform dichotomies for
nonautonomous random dynamical systems. <em>JMAA</em>, <em>549</em>(2),
129441. (<a href="https://doi.org/10.1016/j.jmaa.2025.129441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce generalized dichotomies for nonautonomous random linear dynamical systems acting on arbitrary Banach spaces, and obtain their complete characterization in terms of an appropriate admissibility property. These generalized dichotomies are associated to growth rates satisfying mild conditions and they include the standard exponential behavior as a very particular case. As a nontrivial application, we establish the robustness property of such dichotomies under small (linear) perturbations.},
  archive      = {J_JMAA},
  author       = {Davor Dragičević and César M. Silva and Helder Vilarinho},
  doi          = {10.1016/j.jmaa.2025.129441},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129441},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {Admissibility and generalized nonuniform dichotomies for nonautonomous random dynamical systems},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). About solutions for gradient-type cooperative systems beyond
extremal parameter. <em>JMAA</em>, <em>549</em>(2), 129436. (<a
href="https://doi.org/10.1016/j.jmaa.2025.129436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the existence and non-existence of solutions for cooperative elliptic gradient-type systems, depending on the real parameters λ and μ . Our approach, based on a refined analysis of the Nehari manifold associated with the problem, allows us to establish the existence and multiplicity of solutions by minimizing the associated energy functional over components of the Nehari set for parameters beyond the extremal parameter λ ⁎ ( μ ) .},
  archive      = {J_JMAA},
  author       = {Steffânio Moreno},
  doi          = {10.1016/j.jmaa.2025.129436},
  journal      = {Journal of Mathematical Analysis and Applications},
  month        = {9},
  number       = {2},
  pages        = {129436},
  shortjournal = {J. Math. Anal. Appl.},
  title        = {About solutions for gradient-type cooperative systems beyond extremal parameter},
  volume       = {549},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jocs---4">JOCS - 4</h2>
<ul>
<li><details>
<summary>
(2025). A cluster-based opposition differential evolution algorithm
boosted by a local search for ECG signal classification. <em>JOCS</em>,
<em>86</em>, 102541. (<a
href="https://doi.org/10.1016/j.jocs.2025.102541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiogram (ECG) signals, which capturethe heart&#39;s electrical activity, are used to diagnose and monitor cardiac problems. The accurate classification of ECG signals, particularly for distinguishing among various types of arrhythmias and myocardial infarctions, is crucial for the early detection and treatment of heart-related diseases. This paper proposes a novel approach based on an improved differential evolution (DE) algorithm for ECG signal classification for enhancing the performance. In the initial stages of our approach, the preprocessing step is followed by the extraction of several significant features from the ECG signals. These extracted features are then provided as inputs to an enhanced multi-layer perceptron (MLP). While MLPs are still widely used for ECG signal classification, using gradient-based training methods, the most widely used algorithm for the training process, has significant disadvantages, such as the possibility of being stuck in local optimums. This paper employs an enhanced differential evolution (DE) algorithm for the training process as one of the most effective population-based algorithms. To this end, we improved DE based on a clustering-based strategy, opposition-based learning, and a local search. Clustering-based strategies can act as crossover operators, while the goal of the opposition operator is to improve the exploration of the DE algorithm. The weights and biases found by the improved DE algorithm are then fed into six gradient-based local search algorithms. In other words, the weights found by the DE are employed as an initialization point. Therefore, we introduced six different algorithms for the training process (in terms of different local search algorithms). In an extensive set of experiments, we showed that our proposed training algorithm could provide better results than the conventional training algorithms.},
  archive      = {J_JOCS},
  author       = {Mehran Pourvahab and Seyed Jalaleddin Mousavirad and Virginie Felizardo and Nuno Pombo and Henriques Zacarias and Hamzeh Mohammadigheymasi and Sebastião Pais and Seyed Nooreddin Jafari and Nuno M. Garcia},
  doi          = {10.1016/j.jocs.2025.102541},
  journal      = {Journal of Computational Science},
  month        = {4},
  pages        = {102541},
  shortjournal = {J. Comput. Sci.},
  title        = {A cluster-based opposition differential evolution algorithm boosted by a local search for ECG signal classification},
  volume       = {86},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Community-based voting approach to enhance the spreading
dynamics by identifying a group of influential spreaders in complex
networks. <em>JOCS</em>, <em>86</em>, 102540. (<a
href="https://doi.org/10.1016/j.jocs.2025.102540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploring a group of influential spreaders to acquire maximum influence has become an emerging area of research in complex network analysis. The main challenge of this research is to identify the group of important nodes that are scattered broadly, such that the propagation ability of information is maximum to a network. Researchers proposed many centrality-based approaches with certain limitations to identify the influential nodes (spreaders) considering different properties of the networks. To find a group of spreaders, the VoteRank (a voting mechanism) based method produces effective results with low time complexity, where in each iteration, the node votes for its neighbors by its voting capability, and the node obtaining the maximum vote score is identified as an influential spreader. The major loophole of existing VoteRank methods is measuring the voting capability based on the degree, k-shell index, or contribution of neighbors methods, which does not efficiently identify the spreaders from the diverse regions based on their spreading ability. In this paper, we propose a novel Community-based VoteRank method (CVoteRank) to identify a group of influential spreaders from diverse network regions by which the diffusion process is enhanced. Firstly, we measure every node’s spreading ability based on intra- and inter-connectivity structure in a community, which signifies the local and global importance of the node. To identify the seed nodes, we assign the spreading ability to that node’s voting capability and iteratively calculate the voting score of a node based on its neighboring voting capability and its spreading ability. Then, the node acquiring the maximum voting score is identified as the influential spreader in each iteration. Finally, to solve the problem of influence overlapping, CVoteRank reduces the voting capability of the neighboring nodes of the identified spreader. The efficiency of CVoteRank is evaluated and compared with the different state-of-the-art methods on twelve real networks. Utilizing the stochastic susceptible–infected–recovered epidemic method, we calculate the infected scale, final infected scale, and the average shortest path length among the identified spreaders. The experimental results show that CVoteRank identifies the most efficient spreaders with the highest spreading ability within a short period and the maximum reachability, and the identified spreaders are situated at diverse portions of the networks.},
  archive      = {J_JOCS},
  author       = {Suman Nandi and Mariana Curado Malta and Giridhar Maji and Animesh Dutta},
  doi          = {10.1016/j.jocs.2025.102540},
  journal      = {Journal of Computational Science},
  month        = {4},
  pages        = {102540},
  shortjournal = {J. Comput. Sci.},
  title        = {Community-based voting approach to enhance the spreading dynamics by identifying a group of influential spreaders in complex networks},
  volume       = {86},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep dive into generative models through feature interpoint
distances. <em>JOCS</em>, <em>86</em>, 102539. (<a
href="https://doi.org/10.1016/j.jocs.2025.102539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Interpoint Inception Distance (IID) as a new approach for evaluating deep generative models. It is based on reducing the measurement of discrepancy between multidimensional feature distributions to one-dimensional interpoint comparisons. Our method provides a general tool for deriving a wide range of evaluation measures. The Cramér Interpoint Inception Distance (CIID) is notable for its theoretical properties, including a Gaussian-free structure of feature distribution and a strongly consistent estimator. Our experiments, conducted on both synthetic and large-scale real or generated data, suggest that CIID is a promising competitor to the Fréchet Inception Distance (FID), which is currently the primary metric for evaluating deep generative models. This article is an extended version of the ICCS 2024 conference paper (Jajeśniak et al., 2024) [1] .},
  archive      = {J_JOCS},
  author       = {Dariusz Jajeśniak and Piotr Kościelniak and Arkadiusz Zajdel and Marcin Mazur},
  doi          = {10.1016/j.jocs.2025.102539},
  journal      = {Journal of Computational Science},
  month        = {4},
  pages        = {102539},
  shortjournal = {J. Comput. Sci.},
  title        = {Deep dive into generative models through feature interpoint distances},
  volume       = {86},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised continual learning by cross-level,
instance-group and pseudo-group discrimination with hard attention.
<em>JOCS</em>, <em>86</em>, 102535. (<a
href="https://doi.org/10.1016/j.jocs.2025.102535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extensive work has been done in supervised continual learning (SCL) , wherein models adapt to changing distributions with labeled data while mitigating catastrophic forgetting. However, this approach diverges from real-world scenarios where labeled data is scarce or non-existent. Unsupervised continual learning (UCL) emerges to bridge this disparity. Previous research has explored methods for unsupervised continuous feature learning by incorporating rehearsal to alleviate the problem of catastrophic forgetting. Although these techniques are effective, they may not be feasible for scenarios where storing training data is impractical. Moreover, rehearsal techniques may confront challenges pertaining to representation drifts and overfitting, particularly under limited buffer size conditions. To address these drawbacks, we employ parameter isolation as a strategy to mitigate forgetting. Specifically, we use task-specific hard attention to prevent updates to parameters important for previous tasks. In contrastive learning, loss is prone to be negatively affected by a reduction in the diversity of negative samples. Therefore, we incorporate instance-to-instance similarity into contrastive learning through both direct instance grouping and discrimination at the cross-level with local instance groups, as well as with local pseudo-instance groups. The masked model learns the features using cross-level discrimination, which naturally clusters similar data in the representation space. Extensive experimentation demonstrates that our proposed approach outperforms current state-of-the-art (SOTA) baselines by significant margins, all while exhibiting minimal or nearly zero forgetting, and without the need for any rehearsal buffer. Additionally, the model learns distinct task boundaries. It achieves an overall-average task and class incremental learning (TIL &amp; CIL) accuracy of 76.79% and 62.96% respectively with nearly zero forgetting, across standard datasets for varying task sequences ranging from 5 to 100. This surpasses SOTA baselines, which only reach 74.28% and 60.68% respectively in the UCL setting, where they experience substantial forgetting of almost over 4%. Moreover, our approach achieves performance nearly comparable to the SCL baseline and even surpasses it on some standard datasets, with a notable reduction in forgetting from almost 14.51% to nearly zero.},
  archive      = {J_JOCS},
  author       = {Ankit Malviya and Sayak Dhole and Chandresh Kumar Maurya},
  doi          = {10.1016/j.jocs.2025.102535},
  journal      = {Journal of Computational Science},
  month        = {4},
  pages        = {102535},
  shortjournal = {J. Comput. Sci.},
  title        = {Unsupervised continual learning by cross-level, instance-group and pseudo-group discrimination with hard attention},
  volume       = {86},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="joe---19">JOE - 19</h2>
<ul>
<li><details>
<summary>
(2025). Reprint of: Finite underidentification. <em>JOE</em>,
<em>248</em>, 105947. (<a
href="https://doi.org/10.1016/j.jeconom.2025.105947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I adapt the Generalised Method of Moments to deal with nonlinear models in which a finite number of isolated parameter values satisfy the moment conditions. I also study the closely related class of first-order underidentified models, whose expected Jacobian is rank deficient but not necessarily zero. In both cases, my proposed procedures exploit the underidentification structure to yield parameter estimators and underidentification tests within a standard asymptotically normal GMM framework. I study nonlinear models with and without separation of data and parameters. I also illustrate my proposed inference procedures with applications to production function estimation and dynamic panel data models.},
  archive      = {J_JOE},
  author       = {Enrique Sentana},
  doi          = {10.1016/j.jeconom.2025.105947},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105947},
  shortjournal = {J. Econ.},
  title        = {Reprint of: Finite underidentification},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identifying the volatility risk price through the leverage
effect. <em>JOE</em>, <em>248</em>, 105943. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In asset pricing models with stochastic volatility, uncertainty about volatility affects risk premia through two channels: aversion to decreasing returns and aversion to increasing volatility. We analyze the identification of and robust inference for structural parameters measuring investors’ aversions to these risks: the return risk price and the volatility risk price. In the presence of a leverage effect (instantaneous causality between the asset return and its volatility), we study the identification of both structural parameters with the price data only, without relying on additional option pricing models or option data. We analyze this identification challenge in a nonparametric discrete-time exponentially affine model, complementing the continuous-time approach of Bandi and Renò (2016). We then specialize to a parametric model and derive the implied minimum distance criterion relating the risk prices to the asset return and volatility’s joint distribution. This criterion is almost flat when the leverage effect is small, and we introduce identification-robust confidence sets for both risk prices regardless of the magnitude of the leverage effect.},
  archive      = {J_JOE},
  author       = {Xu Cheng and Eric Renault and Paul Sangrey},
  doi          = {10.1016/j.jeconom.2024.105943},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105943},
  shortjournal = {J. Econ.},
  title        = {Identifying the volatility risk price through the leverage effect},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification, inference and risk. <em>JOE</em>,
<em>248</em>, 105938. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOE},
  author       = {Bertille Antoine and Patrick Gagliardini and René Garcia and Enrique Sentana},
  doi          = {10.1016/j.jeconom.2024.105938},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105938},
  shortjournal = {J. Econ.},
  title        = {Identification, inference and risk},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional ecological inference. <em>JOE</em>, <em>248</em>,
105918. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of ecological inference when one observes the conditional distributions of Y | W and Z | W from aggregate data and attempts to infer the conditional distribution of Y | Z without observing Y and Z in the same sample. First, we show that this problem can be transformed into a linear equation involving operators for which, under suitable regularity assumptions, least squares solutions are available. We then propose the use of the least squares solution with the minimum Hilbert–Schmidt norm, which, in our context, can be structurally interpreted as the solution with minimum dependence between Y and Z . Interestingly, in the case where the conditioning variable W is discrete and belongs to a finite set, such as the labels of units/groups/cities, the solution of this minimal dependence has a closed form. In the more general case, we use a regularization scheme and show the convergence of our proposed estimator. A numerical evaluation of our procedure is proposed.},
  archive      = {J_JOE},
  author       = {Christian Bontemps and Jean-Pierre Florens and Nour Meddahi},
  doi          = {10.1016/j.jeconom.2024.105918},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105918},
  shortjournal = {J. Econ.},
  title        = {Functional ecological inference},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification-robust and simultaneous inference in
multifactor asset pricing models. <em>JOE</em>, <em>248</em>, 105915.
(<a href="https://doi.org/10.1016/j.jeconom.2024.105915">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes exact identification-robust confidence sets for the zero-beta rate and ex-post factor prices in asset pricing models. Exploiting the information from the cross-sectional intercept allows us to impose or formally test model-consistent restrictions, including those resulting from traded factors in excess of the zero beta-rate or from return spreads. Analytical projection-based solutions for confidence set outcomes are developed. The proposed procedures are extended to the case of missing factors. Empirical and simulation results with traded and non-traded factors show that model-consistent restrictions and elusive factors can materially affect model fit, identification, inference and temporal constancy of pricing influence.},
  archive      = {J_JOE},
  author       = {Marie-Claude Beaulieu and Jean-Marie Dufour and Lynda Khalaf},
  doi          = {10.1016/j.jeconom.2024.105915},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105915},
  shortjournal = {J. Econ.},
  title        = {Identification-robust and simultaneous inference in multifactor asset pricing models},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-run risk in stationary vector autoregressive models.
<em>JOE</em>, <em>248</em>, 105905. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a local-to-unity/small sigma model for stationary processes with long-range persistence and non-negligible long-run prediction and estimation risks. The model represents a process containing unobserved short and long-run components measured on different time scales. The short-run component is defined in calendar time, while the long-run component evolves in rescaled time with ultra-long units. We develop estimation and long-run prediction methods for time series with multivariate Vector Autoregressive (VAR) short-run components and reveal the impossibility of estimating consistently some of the long-run parameters, which causes significant estimation and prediction risks in the long run. A simulation study and an application to macroeconomic data illustrate the approach.},
  archive      = {J_JOE},
  author       = {Christian Gourieroux and Joann Jasiak},
  doi          = {10.1016/j.jeconom.2024.105905},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105905},
  shortjournal = {J. Econ.},
  title        = {Long-run risk in stationary vector autoregressive models},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncovering asset market participation from household
consumption and income. <em>JOE</em>, <em>248</em>, 105867. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an asset pricing model featuring time-varying limited participation in both bond and stock markets and household heterogeneity. Households participate in financial markets with a certain probability that depends on their individual income and on asset market conditions. We use indirect inference to uncover individual asset market participation from individual consumption data and asset prices. Our model very accurately reproduces the proportions of stockholders in the Survey of Consumer Finances over three-year intervals, provides a reasonable estimate of stock market participation costs, and is able to price characteristic-based stock portfolios with the top decile of households identified as stockholders.},
  archive      = {J_JOE},
  author       = {Veronika Czellar and René Garcia and François Le Grand},
  doi          = {10.1016/j.jeconom.2024.105867},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105867},
  shortjournal = {J. Econ.},
  title        = {Uncovering asset market participation from household consumption and income},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Weak identification in discrete choice models. <em>JOE</em>,
<em>248</em>, 105866. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the impact of weak identification in discrete choice models, and provide insights into the determinants of identification strength in these models. Using these insights, we propose a novel test that can consistently detect weak identification in commonly applied discrete choice models, such as probit, logit, and many of their extensions. Furthermore, we demonstrate that when the null hypothesis of weak identification is rejected, Wald-based inference can be carried out using standard formulas and critical values. A Monte Carlo study compares our proposed testing approach against commonly applied weak identification tests. The results simultaneously demonstrate the good performance of our approach and the fundamental failure of using conventional weak identification tests for linear models in the discrete choice model context. Lastly, we apply our approach in two empirical examples: married women labor force participation, and US food aid and civil conflicts.},
  archive      = {J_JOE},
  author       = {David T. Frazier and Eric Renault and Lina Zhang and Xueyan Zhao},
  doi          = {10.1016/j.jeconom.2024.105866},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105866},
  shortjournal = {J. Econ.},
  title        = {Weak identification in discrete choice models},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conditional spectral methods. <em>JOE</em>, <em>248</em>,
105863. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We model predictive scale-specific cycles. By employing suitable matrix representations, we express the forecast errors of covariance-stationary multivariate time series in terms of conditionally orthonormal scale-specific bases. The representations yield conditionally orthogonal decompositions of these forecast errors. They also provide decompositions of their variances and betas in terms of scale-specific variances and betas capturing predictive variability and co-variability over cycles of alternative lengths without spillovers across cycles. Making use of the proposed representations within the classical family of time-varying conditional volatility models, we document the role of time-varying volatility forecasts in generating orthogonal predictive scale-specific cycles in returns. We conclude by providing suggestive evidence that the conditional variances of the predictive return cycles ( i ) may be priced over short-to-medium horizons and ( i i ) may offer economically-relevant trading signals over these same horizons.},
  archive      = {J_JOE},
  author       = {Federico M. Bandi and Yinan Su},
  doi          = {10.1016/j.jeconom.2024.105863},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105863},
  shortjournal = {J. Econ.},
  title        = {Conditional spectral methods},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exogeneity tests and weak identification in IV regressions:
Asymptotic theory and point estimation. <em>JOE</em>, <em>248</em>,
105821. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides new insights on exogeneity tests in linear IV models and their use for estimation, when identification fails or may not be strong. We make two main contributions. First , we show that Durbin–Wu–Hausman (DWH) and Revankar–Hartley (RH) exogeneity tests have correct level asymptotically, even when the first-stage coefficient matrix (which controls identification) is rank-deficient. We provide necessary and sufficient conditions under which these tests are consistent. In particular, we show that test consistency can hold even when identification fails, provided at least one component of the structural parameter vector is identifiable. Second , we study point estimation after estimator (or model) selection, when the outcome of a DWH/RH test determines whether OLS or an IV method is employed in the second-stage. For this purpose, we use ( non-local ) concepts of asymptotic bias , asymptotic mean squared error (AMSE), and asymptotic relative efficiency (ARE), which remain applicable even when the estimators considered do not have moments (as can happen for 2SLS) or may be inconsistent. We study the asymptotic properties of OLS, 2SLS, and pretest estimators which select OLS or 2SLS based on the outcome of a DWH/RH test. We show that: (i) OLS typically dominates 2SLS estimator asymptotically for MSE across a broad spectrum of cases, including weak identification and moderate endogeneity; (ii) exogeneity-pretest estimators exhibit consistently good performance and asymptotically dominate both OLS and 2SLS. The proposed theoretical findings are documented by Monte Carlo simulations.},
  archive      = {J_JOE},
  author       = {Firmin Doko Tchatoka and Jean-Marie Dufour},
  doi          = {10.1016/j.jeconom.2024.105821},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105821},
  shortjournal = {J. Econ.},
  title        = {Exogeneity tests and weak identification in IV regressions: Asymptotic theory and point estimation},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Simulation-based estimation with many auxiliary statistics
applied to long-run dynamic analysis. <em>JOE</em>, <em>248</em>,
105814. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing asymptotic theory for estimators obtained by simulated minimum distance does not cover situations in which the number of components of the auxiliary statistics (or number of matched “moments”) is large — typically larger than the sample size. We establish the consistency of the simulated minimum distance estimator in this situation and derive its asymptotic distribution. Our estimator is easy to implement and allows us to exploit all the informational content of a large number of auxiliary statistics without having to, (i) know these functions explicitly, or (ii) choose a priori which functions are the most informative. As a result, we are able to exploit, among other things, long-run information. We illustrate the implementation of the proposed method through Monte-Carlo simulation experiments based on small- and medium-scale New Keynesian models. These examples highlight how to conveniently exploit valuable information from matching a large number of impulse responses including at long-run horizons.},
  archive      = {J_JOE},
  author       = {Bertille Antoine and Wenqian Sun},
  doi          = {10.1016/j.jeconom.2024.105814},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105814},
  shortjournal = {J. Econ.},
  title        = {Simulation-based estimation with many auxiliary statistics applied to long-run dynamic analysis},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The chained difference-in-differences. <em>JOE</em>,
<em>248</em>, 105783. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the identification, estimation, and inference of long-term (binary) treatment effect parameters when balanced panel data is not available, or consists of only a subset of the available data. We develop a new estimator: the chained difference-in-differences, which leverages the overlapping structure of many unbalanced panel data sets. This approach consists in aggregating a collection of short-term treatment effects estimated on multiple incomplete panels. Our estimator accommodates (1) multiple time periods, (2) variation in treatment timing, (3) treatment effect heterogeneity, (4) general missing data patterns, and (5) sample selection on observables. We establish the asymptotic properties of the proposed estimator and discuss identification and efficiency gains in comparison to existing methods. Finally, we illustrate its relevance through (i) numerical simulations, and (ii) an application about the effects of an innovation policy in France.},
  archive      = {J_JOE},
  author       = {Christophe Bellégo and David Benatia and Vincent Dortet-Bernadet},
  doi          = {10.1016/j.jeconom.2024.105783},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105783},
  shortjournal = {J. Econ.},
  title        = {The chained difference-in-differences},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Regularizing stock return covariance matrices via multiple
testing of correlations. <em>JOE</em>, <em>248</em>, 105753. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105753">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a large-scale inference approach for the regularization of stock return covariance matrices. The framework allows for the presence of heavy tails and multivariate GARCH-type effects of unknown form among the stock returns. The approach involves simultaneous testing of all pairwise correlations, followed by setting non-statistically significant elements to zero. This adaptive thresholding is achieved through sign-based Monte Carlo resampling within multiple testing procedures, controlling either the traditional familywise error rate, a generalized familywise error rate, or the false discovery proportion. Subsequent shrinkage ensures that the final covariance matrix estimate is positive definite and well-conditioned while preserving the achieved sparsity. Compared to alternative estimators, this new regularization method demonstrates strong performance in simulation experiments and real portfolio optimization.},
  archive      = {J_JOE},
  author       = {Richard Luger},
  doi          = {10.1016/j.jeconom.2024.105753},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105753},
  shortjournal = {J. Econ.},
  title        = {Regularizing stock return covariance matrices via multiple testing of correlations},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spanning latent and observable factors. <em>JOE</em>,
<em>248</em>, 105743. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Factor analysis is a widely used tool to summarize high dimensional panel data via a small dimensional set of latent factors. Many applications in finance and macroeconomics, are often focused on observable factors with an economic interpretation. The objective of this paper is to provide a test to answer a question which naturally comes up in discussions regarding latent versus observable factors: do latent and observable factors span the same space? We derive asymptotic properties of a formal test and propose a bootstrap version with improved small sample properties. We find empirical evidence for a small number of factors common between a small number of traditional Fama–French risk factors – or returns on a few stocks (i.e. “magnificent” 5 or 7) – and large panels of US, North American and international portfolio returns.},
  archive      = {J_JOE},
  author       = {E. Andreou and P. Gagliardini and E. Ghysels and M. Rubin},
  doi          = {10.1016/j.jeconom.2024.105743},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105743},
  shortjournal = {J. Econ.},
  title        = {Spanning latent and observable factors},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Identification robust inference for the risk premium in term
structure models. <em>JOE</em>, <em>248</em>, 105728. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105728">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose identification robust statistics for testing hypotheses on the risk premia in dynamic affine term structure models. We do so using the moment equation specification proposed in Adrian et al. (2013) . Statistical inference based on their three-stage estimator requires knowledge of the risk factors’ quality and can be misleading when the β ’s are weak, which results when sampling errors are of comparable order of magnitude as the risk factor loadings. We extend the subset (factor) Anderson–Rubin test from Guggenberger et al. (2012) to models with multiple dynamic factors and time-varying risk prices. It provides a computationally tractable manner to conduct identification robust tests on a few risk premia when a larger number is present. We use it to analyze potential identification issues arising in the data from Adrian et al. (2013) for which we show that some factors, though potentially weak, may drive the time variation of risk prices, and weak identification issues are more prominent in multi-factor models.},
  archive      = {J_JOE},
  author       = {Frank Kleibergen and Lingwei Kong},
  doi          = {10.1016/j.jeconom.2024.105728},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105728},
  shortjournal = {J. Econ.},
  title        = {Identification robust inference for the risk premium in term structure models},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiency bounds for moment condition models with mixed
identification strength. <em>JOE</em>, <em>248</em>, 105723. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moment condition models with mixed identification strength are models that are point identified but with estimating moment functions that are allowed to drift to 0 uniformly over the parameter space. Even though identification fails in the limit, depending on how slow the moment functions vanish, consistent estimation is possible. Existing estimators such as the generalized method of moment (GMM) estimator exhibit a pattern of nonstandard or even heterogeneous rate of convergence that materializes by some parameter directions being estimated at a slower rate than others. This paper derives asymptotic semiparametric efficiency bounds for regular estimators of parameters of these models. We show that GMM estimators are regular and that the so-called two-step GMM estimator – using the inverse of estimating function’s variance as weighting matrix – is semiparametrically efficient as it reaches the minimum variance attainable by regular estimators. This estimator is also asymptotically minimax efficient with respect to a large family of loss functions. Monte Carlo simulations are provided that confirm these results.},
  archive      = {J_JOE},
  author       = {Prosper Dovonon and Yves F. Atchadé and Firmin Doko Tchatoka},
  doi          = {10.1016/j.jeconom.2024.105723},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105723},
  shortjournal = {J. Econ.},
  title        = {Efficiency bounds for moment condition models with mixed identification strength},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Score-type tests for normal mixtures. <em>JOE</em>,
<em>248</em>, 105717. (<a
href="https://doi.org/10.1016/j.jeconom.2024.105717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing normality against discrete normal mixtures is complex because some parameters turn increasingly underidentified along alternative ways of approaching the null, others are inequality constrained, and several higher-order derivatives become identically 0. These problems make the maximum of the alternative model log-likelihood function numerically unreliable. We propose score-type tests asymptotically equivalent to the likelihood ratio as the largest of two simple intuitive statistics that only require estimation under the null. One novelty of our approach is that we treat symmetrically both ways of writing the null hypothesis without excluding any region of the parameter space. We derive the asymptotic distribution of our tests under the null and sequences of local alternatives. We also show that their asymptotic distribution is the same whether applied to observations or standardized residuals from heteroskedastic regression models. Finally, we study their power in simulations and apply them to the residuals of Mincer earnings functions.},
  archive      = {J_JOE},
  author       = {Dante Amengual and Xinyue Bei and Marine Carrasco and Enrique Sentana},
  doi          = {10.1016/j.jeconom.2024.105717},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105717},
  shortjournal = {J. Econ.},
  title        = {Score-type tests for normal mixtures},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). When uncertainty and volatility are disconnected:
Implications for asset pricing and portfolio performance. <em>JOE</em>,
<em>248</em>, 105654. (<a
href="https://doi.org/10.1016/j.jeconom.2023.105654">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyze an environment where the uncertainty in the equity market return and its volatility are both stochastic and may be potentially disconnected. We solve a representative investor’s optimal asset allocation and derive the resulting conditional equity premium and risk-free rate in equilibrium. Our empirical analysis shows that the equity premium appears to be earned for facing uncertainty, especially high uncertainty that is disconnected from lower volatility, rather than for facing volatility as traditionally assumed. Incorporating the possibility of a disconnect between volatility and uncertainty significantly improves portfolio performance, over and above the performance obtained by conditioning on volatility only.},
  archive      = {J_JOE},
  author       = {Yacine Aït-Sahalia and Felix Matthys and Emilio Osambela and Ronnie Sircar},
  doi          = {10.1016/j.jeconom.2023.105654},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105654},
  shortjournal = {J. Econ.},
  title        = {When uncertainty and volatility are disconnected: Implications for asset pricing and portfolio performance},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The term structure of macroeconomic risks at the effective
lower bound. <em>JOE</em>, <em>248</em>, 105383. (<a
href="https://doi.org/10.1016/j.jeconom.2023.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new macro-finance model that solves the tension between tractability, flexibility in macroeconomic dynamics, and consistency of the term structures of treasury yields with the effective lower bound (ELB). I use the term structures of U.S. nominal and real treasury yields from 1990 to explore the interdependence between inflation expectations, volatility, and monetary policy at the ELB. The estimation reveals that real yields stay elevated during the ELB due to large premia and deflation fears, produced by a persistent shift in inflation dynamics, with low average inflation and heightened inflation volatility.},
  archive      = {J_JOE},
  author       = {Guillaume Roussellet},
  doi          = {10.1016/j.jeconom.2023.01.005},
  journal      = {Journal of Econometrics},
  month        = {3},
  pages        = {105383},
  shortjournal = {J. Econ.},
  title        = {The term structure of macroeconomic risks at the effective lower bound},
  volume       = {248},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="joma---15">JOMA - 15</h2>
<ul>
<li><details>
<summary>
(2025). Graph-constrained analysis for multivariate functional data.
<em>JOMA</em>, <em>207</em>, 105428. (<a
href="https://doi.org/10.1016/j.jmva.2025.105428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The manuscript considers multivariate functional data analysis with a known graphical model among the functional variables representing their conditional relationships (e.g., brain region-level fMRI data with a prespecified connectivity graph among brain regions). Functional Gaussian graphical models (GGM) used for analyzing multivariate functional data customarily estimate an unknown graphical model, and cannot preserve knowledge of a given graph. We propose a method for multivariate functional analysis that exactly conforms to a given inter-variable graph. We first show the equivalence between partially separable functional GGM and graphical Gaussian processes (GP), proposed recently for constructing optimal multivariate covariance functions that retain a given graphical model. The theoretical connection helps to design a new algorithm that leverages Dempster’s covariance selection for obtaining the maximum likelihood estimate of the covariance function for multivariate functional data under graphical constraints. We also show that the finite term truncation of functional GGM basis expansion used in practice is equivalent to a low-rank graphical GP, which is known to oversmooth marginal distributions. To remedy this, we extend our algorithm to better preserve marginal distributions while respecting the graph and retaining computational scalability. The benefits of the proposed algorithms are illustrated using empirical experiments and a neuroimaging application.},
  archive      = {J_JOMA},
  author       = {Debangan Dey and Sudipto Banerjee and Martin A. Lindquist and Abhirup Datta},
  doi          = {10.1016/j.jmva.2025.105428},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105428},
  shortjournal = {J. Multi. Anal.},
  title        = {Graph-constrained analysis for multivariate functional data},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A review of multivariate permutation tests: Findings and
trends. <em>JOMA</em>, <em>207</em>, 105421. (<a
href="https://doi.org/10.1016/j.jmva.2025.105421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The permutation test is a widely recognized and frequently used nonparametric hypothesis test, notable for its minimal reliance on assumptions compared to parametric tests. It has found applications in many fields, particularly in multivariate analysis. Since its introduction in the 1930s, permutation tests have been extensively examined both theoretically and empirically. This article provides the results of a comprehensive and systematic review of the literature, focusing on different aspects of multivariate permutation tests. Key articles published in international journals from 2010 onwards have been analyzed, classifying them into four main research strands: data, model, test and issues. These strands were further subdivided into more specific categories. The state of the art and significant developments in this field are summarized, followed by a discussion on future research challenges and trends, offering guidance for the design and development on new approaches.},
  archive      = {J_JOMA},
  author       = {Rosa Arboretti and Elena Barzizza and Nicoló Biasetton and Marta Disegna},
  doi          = {10.1016/j.jmva.2025.105421},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105421},
  shortjournal = {J. Multi. Anal.},
  title        = {A review of multivariate permutation tests: Findings and trends},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Consistency of empirical distributions of sequences of graph
statistics in networks with dependent edges. <em>JOMA</em>,
<em>207</em>, 105420. (<a
href="https://doi.org/10.1016/j.jmva.2025.105420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the first steps in applications of statistical network analysis is frequently to produce summary charts of important features of the network. Many of these features take the form of sequences of graph statistics counting the number of realized events in the network, examples of which are degree distributions, edgewise shared partner distributions, and more. We provide conditions under which the empirical distributions of sequences of graph statistics are consistent in the ℓ ∞ -norm in settings where edges in the network are dependent. We accomplish this task by deriving concentration inequalities that bound probabilities of deviations of graph statistics from the expected value under weak dependence conditions. We apply our concentration inequalities to empirical distributions of sequences of graph statistics and derive non-asymptotic bounds on the ℓ ∞ -error which hold with high probability. Our non-asymptotic results are then extended to demonstrate uniform convergence almost surely in selected examples. We illustrate theoretical results through examples, simulation studies, and an application.},
  archive      = {J_JOMA},
  author       = {Jonathan R. Stewart},
  doi          = {10.1016/j.jmva.2025.105420},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105420},
  shortjournal = {J. Multi. Anal.},
  title        = {Consistency of empirical distributions of sequences of graph statistics in networks with dependent edges},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semiparametric density estimation with localized bregman
divergence. <em>JOMA</em>, <em>207</em>, 105419. (<a
href="https://doi.org/10.1016/j.jmva.2025.105419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines semiparametric density estimation by combining a parametric crude guess and its nonparametric adjustment. The nonparametric adjustment is implemented via minimization of the localized Bregman divergence, which yields a broad class of semiparametric density estimators. Asymptotic theories of the density estimators in this general class are developed. Specific concrete forms of density estimators under a certain divergence and parametric guess are calculated. Simulations for several target densities and application to a real data set reveal that the proposed density estimators offer competitive or, in some cases, better performance compared to fully nonparametric kernel density estimator.},
  archive      = {J_JOMA},
  author       = {Daisuke Matsuno and Kanta Naito},
  doi          = {10.1016/j.jmva.2025.105419},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105419},
  shortjournal = {J. Multi. Anal.},
  title        = {Semiparametric density estimation with localized bregman divergence},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tree-structured markov random fields with poisson marginal
distributions. <em>JOMA</em>, <em>207</em>, 105418. (<a
href="https://doi.org/10.1016/j.jmva.2025.105418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new family of tree-structured Markov random fields for a vector of discrete counting random variables is introduced. According to the characteristics of the family, the marginal distributions of the Markov random fields are all Poisson with the same mean, and are untied from the strength or structure of their built-in dependence. This key feature is uncommon for Markov random fields and most convenient for applications purposes. The specific properties of this new family confer a straightforward sampling procedure and analytic expressions for the joint probability mass function and the joint probability generating function of the vector of counting random variables, thus granting computational methods that scale well to vectors of high dimension. We study the distribution of the sum of random variables constituting a Markov random field from the proposed family, analyze a random variable’s individual contribution to that sum through expected allocations, and establish stochastic orderings to assess a wide understanding of their behavior.},
  archive      = {J_JOMA},
  author       = {Benjamin Côté and Hélène Cossette and Etienne Marceau},
  doi          = {10.1016/j.jmva.2025.105418},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105418},
  shortjournal = {J. Multi. Anal.},
  title        = {Tree-structured markov random fields with poisson marginal distributions},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Classification using global and local mahalanobis distances.
<em>JOMA</em>, <em>207</em>, 105417. (<a
href="https://doi.org/10.1016/j.jmva.2025.105417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel semiparametric classifier based on Mahalanobis distances of an observation from the competing classes. Our tool is a generalized additive model with the logistic link function that uses these distances as features to estimate the posterior probabilities of different classes. While popular parametric classifiers like linear and quadratic discriminant analyses are mainly motivated by the normality of the underlying distributions, the proposed classifier is more flexible and free from such parametric modeling assumptions. Since the densities of elliptic distributions are functions of Mahalanobis distances, this classifier works well when the competing classes are (nearly) elliptic. In such cases, it often outperforms popular nonparametric classifiers, especially when the sample size is small compared to the dimension of the data. To cope with non-elliptic and possibly multimodal distributions, we propose a local version of the Mahalanobis distance. Subsequently, we propose another classifier based on a generalized additive model that uses the local Mahalanobis distances as features. This nonparametric classifier usually performs like the Mahalanobis distance based semiparametric classifier when the underlying distributions are elliptic, but outperforms it for several non-elliptic and multimodal distributions. We also investigate the behavior of these two classifiers in high dimension, low sample size situations. A thorough numerical study involving several simulated and real datasets demonstrate the usefulness of the proposed classifiers in comparison to many state-of-the-art methods.},
  archive      = {J_JOMA},
  author       = {Annesha Ghosh and Anil K. Ghosh and Rita SahaRay and Soham Sarkar},
  doi          = {10.1016/j.jmva.2025.105417},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105417},
  shortjournal = {J. Multi. Anal.},
  title        = {Classification using global and local mahalanobis distances},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model averaging for global fréchet regression.
<em>JOMA</em>, <em>207</em>, 105416. (<a
href="https://doi.org/10.1016/j.jmva.2025.105416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-Euclidean complex data analysis becomes increasingly popular in various fields of data science. In a seminal paper, Petersen and Müller (2019) generalized the notion of regression analysis to non-Euclidean response objects. Meanwhile, in the conventional regression analysis, model averaging has a long history and is widely applied in statistics literature. This paper studies the problem of optimal prediction for non-Euclidean objects by extending the method of model averaging. In particular, we generalize the notion of model averaging for global Fréchet regressions and establish an optimal property of the cross-validation to select the averaging weights in terms of the final prediction error. A simulation study illustrates excellent out-of-sample predictions of the proposed method.},
  archive      = {J_JOMA},
  author       = {Daisuke Kurisu and Taisuke Otsu},
  doi          = {10.1016/j.jmva.2025.105416},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105416},
  shortjournal = {J. Multi. Anal.},
  title        = {Model averaging for global fréchet regression},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An exponential inequality for hilbert-valued u-statistics of
i.i.d. data. <em>JOMA</em>, <em>207</em>, 105406. (<a
href="https://doi.org/10.1016/j.jmva.2025.105406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we establish an exponential inequality for U -statistics of i.i.d. data, varying kernel and taking values in a separable Hilbert space. The bound is expressed as a sum of an exponential term plus an other one involving the tail of a sum of squared norms. We start by the degenerate case. Then we provide applications to U -statistics of not necessarily degenerate fixed kernel, incomplete U -statistics and weighted U -statistics.},
  archive      = {J_JOMA},
  author       = {Davide Giraudo},
  doi          = {10.1016/j.jmva.2025.105406},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105406},
  shortjournal = {J. Multi. Anal.},
  title        = {An exponential inequality for hilbert-valued U-statistics of i.i.d. data},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFQRA: Scaled factor-augmented quantile regression with
aggregation in conditional mean forecasting. <em>JOMA</em>,
<em>207</em>, 105405. (<a
href="https://doi.org/10.1016/j.jmva.2024.105405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving robust forecasts for a single time series with many covariates and possible nonlinear effects is a problem worth investigating. In this paper, a scaled factor-augmented quantile regression with aggregation (SFQRA) method is proposed for an effective prediction. It first estimates different conditional quantiles by introducing scaled covariates to the factor-augmented quantile regression, which not only combats the curse of dimensionality but also includes the target information in the estimation. Then the different conditional quantiles are aggregated appropriately to a robust forecast. Moreover, combining SFQRA with feature screening via an aggregated quantile correlation allows it to be extended to handle cases when only a portion of covariates is informative. The effectiveness of the proposed methods is justified theoretically, under the framework of large cross-sections and large time dimensions while no restriction is imposed on the relation between them. Various simulation studies and real data analyses demonstrate the superiority of the newly proposed method in forecasting.},
  archive      = {J_JOMA},
  author       = {Lei Shu and Yifan Hao and Yu Chen and Qing Yang},
  doi          = {10.1016/j.jmva.2024.105405},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105405},
  shortjournal = {J. Multi. Anal.},
  title        = {SFQRA: Scaled factor-augmented quantile regression with aggregation in conditional mean forecasting},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fisher’s legacy of directional statistics, and beyond to
statistics on manifolds. <em>JOMA</em>, <em>207</em>, 105404. (<a
href="https://doi.org/10.1016/j.jmva.2024.105404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is not an exaggeration to say that R.A. Fisher is the Albert Einstein of Statistics. He pioneered almost all the main branches of statistics, but it is not as well known that he opened the area of Directional Statistics with his 1953 paper introducing a distribution on the sphere which is now known as the Fisher distribution. He stressed that for spherical data one should take into account that the data is on a manifold. We will describe this Fisher distribution and reanalyze his geological data. We also comment on the two goals he set himself in that paper, and on how he reinvented the von Mises distribution on the circle. Since then, many extensions of this distribution have appeared bearing Fisher’s name such as the von Mises–Fisher distribution and the matrix Fisher distribution. In fact, the subject of Directional Statistics has grown tremendously in the last two decades with new applications emerging in life sciences, image analysis, machine learning and so on. We give a recent new method of constructing the Fisher type distributions on manifolds which has been motivated by some problems in machine learning. The number of directional distributions has increased since then, including the bivariate von Mises distribution and we describe its connection to work resulting in the 2024 Nobel-winning AlphaFold (in Chemistry). Further, the subject has evolved as Statistics on Manifolds which also includes the new field of Shape Analysis, and finally, we end with a historical note pointing out some correspondence between D’Arcy Thompson and R.A. Fisher related to Shape Analysis.},
  archive      = {J_JOMA},
  author       = {Kanti V. Mardia},
  doi          = {10.1016/j.jmva.2024.105404},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105404},
  shortjournal = {J. Multi. Anal.},
  title        = {Fisher’s legacy of directional statistics, and beyond to statistics on manifolds},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequential estimation of high-dimensional signal plus noise
models under general elliptical frameworks. <em>JOMA</em>, <em>207</em>,
105403. (<a href="https://doi.org/10.1016/j.jmva.2024.105403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High dimensional data analysis has attracted considerable interest and is facing new challenges, one of which is the increasingly available data with noise corrupted and in a streaming manner, such as signals and stocks. In this paper, we develop a sequential method to dynamically update the estimates of signal and noise strength in signal plus noise models. The proposed sequential method is easy to compute based on the stored statistics and the current data point. The consistency and, more importantly, the asymptotic normality of the estimators of signal strength and noise level are demonstrated for high dimensional settings under mild conditions. Simulations and real data examples are further provided to illustrate the practical utility of our proposal.},
  archive      = {J_JOMA},
  author       = {Li Yanpeng and Xie Jiahui and Zhou Guoliang and Zhou Wang},
  doi          = {10.1016/j.jmva.2024.105403},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105403},
  shortjournal = {J. Multi. Anal.},
  title        = {Sequential estimation of high-dimensional signal plus noise models under general elliptical frameworks},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-functional varying coefficient mode-based regression.
<em>JOMA</em>, <em>207</em>, 105402. (<a
href="https://doi.org/10.1016/j.jmva.2024.105402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose estimating semi-functional varying coefficient regression based on the mode value through a kernel objective function, where the bandwidth included is treated as a tuning parameter to achieve efficiency and robustness. For estimation, functional principal component basis functions are utilized to approximate the slope function and functional predictor variable, while B-spline functions are employed to approximate the varying coefficient component. Under mild regularity conditions, the convergence rates of the resulting estimators for the unknown slope function and varying coefficient are established under various cases. To numerically estimate the proposed model, we recommend employing a computationally efficient mode expectation–maximization algorithm with the aid of a Gaussian kernel. The tuning parameters are selected using the mode-based Bayesian information criterion and cross-validation procedures. Built upon the generalized likelihood technique, we further develop a goodness-of-fit test to assess the constancy of varying coefficient functions and put forward a wild bootstrap procedure for estimating the corresponding critical values. The finite sample performance of the developed estimators is illustrated through Monte Carlo simulations and real data analysis related to the Tecator data. The results produced by the propounded method are compared favorably with those obtained from alternative estimation techniques.},
  archive      = {J_JOMA},
  author       = {Tao Wang},
  doi          = {10.1016/j.jmva.2024.105402},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105402},
  shortjournal = {J. Multi. Anal.},
  title        = {Semi-functional varying coefficient mode-based regression},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-dimensional projection-based ANOVA test. <em>JOMA</em>,
<em>207</em>, 105401. (<a
href="https://doi.org/10.1016/j.jmva.2024.105401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In bioinformation and medicine, an enormous amount of high-dimensional multi-population data is collected. For the inference of several-samples mean problem, traditional tests do not perform well and many new theories mainly focus on normal distribution and low correlation assumptions. Motivated by the weighted sign test, we propose two projection-based tests which are robust against the choice of correlation matrix. One test utilizes Scheffe’s transformation to generate a group of new samples and derives the optimal projection direction. The other test is adaptive to projection direction and is generalized to the assumption of the whole elliptical distribution and independent component model. Further the theoretical properties are deduced and numerical experiments are carried out to examine the finite sample performance. They show that our tests outperform others under certain circumstances.},
  archive      = {J_JOMA},
  author       = {Weihao Yu and Qi Zhang and Weiyu Li},
  doi          = {10.1016/j.jmva.2024.105401},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105401},
  shortjournal = {J. Multi. Anal.},
  title        = {High-dimensional projection-based ANOVA test},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quadratic inference with dense functional responses.
<em>JOMA</em>, <em>207</em>, 105400. (<a
href="https://doi.org/10.1016/j.jmva.2024.105400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the challenge of estimation in the context of constant linear effect models with dense functional responses. In this framework, the conditional expectation of the response curve is represented by a linear combination of functional covariates with constant regression parameters. In this paper, we present an alternative solution by employing the quadratic inference approach, a well-established method for analyzing correlated data, to estimate the regression coefficients. Our approach leverages non-parametrically estimated basis functions, eliminating the need for choosing working correlation structures. Furthermore, we demonstrate that our method achieves a parametric n -convergence rate, contingent on an appropriate choice of bandwidth. This convergence is observed when the number of repeated measurements per trajectory exceeds a certain threshold, specifically, when it surpasses n a 0 , with n representing the number of trajectories. Additionally, we establish the asymptotic normality of the resulting estimator. The performance of the proposed method is compared with that of existing methods through extensive simulation studies, where our proposed method outperforms. Real data analysis is also conducted to demonstrate the proposed method.},
  archive      = {J_JOMA},
  author       = {Pratim Guha Niyogi and Ping-Shou Zhong},
  doi          = {10.1016/j.jmva.2024.105400},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105400},
  shortjournal = {J. Multi. Anal.},
  title        = {Quadratic inference with dense functional responses},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the consistency of the jackknife estimator of the
asymptotic variance of spatial median. <em>JOMA</em>, <em>207</em>,
105399. (<a href="https://doi.org/10.1016/j.jmva.2024.105399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is shown that the usual delete-1 jackknife variance estimator of the asymptotic variance of spatial median is consistent. This is proved under the assumptions that the dimension of the data d ≥ 3 , the sampled distribution possesses a density with respect to the Lebesgue measure and this density is bounded on every bounded subset of R d .},
  archive      = {J_JOMA},
  author       = {František Rublík},
  doi          = {10.1016/j.jmva.2024.105399},
  journal      = {Journal of Multivariate Analysis},
  month        = {5},
  pages        = {105399},
  shortjournal = {J. Multi. Anal.},
  title        = {On the consistency of the jackknife estimator of the asymptotic variance of spatial median},
  volume       = {207},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jomp---7">JOMP - 7</h2>
<ul>
<li><details>
<summary>
(2025). Conjugate bayesian analysis of the wald model: On an exact
drift-rate posterior. <em>JOMP</em>, <em>124</em>, 102904. (<a
href="https://doi.org/10.1016/j.jmp.2025.102904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cognitive psychology, simple response times are often modeled as the time required by a one-dimensional Wiener process with drift to first reach a given threshold. This stochastic process’s first-passage time follows a Wald distribution, which is a specific parameterization of the inverse-Gaussian distribution. It can be shown that the Gaussian-Gamma distribution is a conjugate prior with respect to an inverse-Gaussian likelihood, albeit under a parameterization different from that of the Wald distribution. This leads to a posterior distribution that does not directly correspond to the core parameters of the Wiener process; that is, the drift-rate and the threshold parameter. While the marginal threshold posterior under a Gaussian-Gamma prior is relatively easy to derive and turns out to be a known distribution, this is not the case for the marginal drift-rate posterior. The present work addresses this issue by providing the exact marginal posterior distributions of the drift-rate parameter under a Gaussian-Gamma prior—something that has not yet been done in the literature. Unfortunately, the probability density function of this distribution cannot be expressed in terms of elementary functions. Thus, different methods of approximation are discussed as an expedient for time-critical applications.},
  archive      = {J_JOMP},
  author       = {Constantin G. Meyer-Grant},
  doi          = {10.1016/j.jmp.2025.102904},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102904},
  shortjournal = {J. Math. Psychol.},
  title        = {Conjugate bayesian analysis of the wald model: On an exact drift-rate posterior},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic models of delay discounting: “Fixed-endpoint”
psychometric curves improve plausibility and performance. <em>JOMP</em>,
<em>124</em>, 102902. (<a
href="https://doi.org/10.1016/j.jmp.2025.102902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic models of delay discounting allow the estimation of discount functions without prescribing unrealistically sharp boundaries in decision making. However, existing probabilistic models have two implausible implications: first, that no reward is sometimes preferred over some reward (e.g., $0 now over $100 in 1 year), and second, that the same reward is sometimes preferred later rather than sooner (e.g., $100 in a year over $100 now). We introduce a class of “fixed-endpoint” models that assign these edge cases a probability of 0. We find that these outperform conventional models across a range of discount functions using nonlinear regression. We also introduce a series of generalized linear models that implicitly parameterize various discount functions, and demonstrate the same result for these.},
  archive      = {J_JOMP},
  author       = {Isaac Kinley and Joseph Oluwasola and Suzanna Becker},
  doi          = {10.1016/j.jmp.2025.102902},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102902},
  shortjournal = {J. Math. Psychol.},
  title        = {Probabilistic models of delay discounting: “Fixed-endpoint” psychometric curves improve plausibility and performance},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Choosing is losing: How opportunity cost influences
valuations and choice. <em>JOMP</em>, <em>124</em>, 102901. (<a
href="https://doi.org/10.1016/j.jmp.2025.102901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a model of choice that accounts for opportunity costs actually suffered, as a result of renouncing the alternative not chosen. The valuation of each option is relative: The decision maker subtracts from the standard utility of any given option the psychological cost of giving up the alternative. In the presence of a default option, the final inclination of a person is the net effect of a ‘conservative’ disposition to keep the default and an ‘adventurous’ disposition toward choosing an alternative. This trait-like inclination is captured by the difference in sensitivity to giving up the default option or its alternative(s). When the options have elements in common, the conservative and adventurous dispositions operate only on their distinguishing elements. Unlike previous conceptualizations of anticipated regret, our decision maker suffers most when the foregone option is of comparable value to the chosen one. Our model can explain the empirical regularity that faced with the same choice, some people tend to favor the default option (a form of endowment effect), while others tend to favor its alternative (a form of fear of missing out). In the presence of several alternatives, the decision maker compares the default option with the best option among the alternatives.},
  archive      = {J_JOMP},
  author       = {Tomás Lejarraga and József Sákovics},
  doi          = {10.1016/j.jmp.2025.102901},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102901},
  shortjournal = {J. Math. Psychol.},
  title        = {Choosing is losing: How opportunity cost influences valuations and choice},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A class of random utility models yielding the exploded
logit. <em>JOMP</em>, <em>124</em>, 102900. (<a
href="https://doi.org/10.1016/j.jmp.2025.102900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We reexamine a family of distributions introduced within the framework of random utility models by David Strauss. This family generates ranking probabilities of the exploded logit model and, de facto, the choice probabilities of the multinomial logit model. We explore the necessary and sufficient conditions for its validity within the copula theory. By specifying the minimal assumptions required for the support of the marginal utility distributions, we clarify and reinforce the fundamental structure of the model, proving that it relies on strict archimedean copulas. Additionally, we provide a new mathematical proof by induction on the number of alternatives confirming that these utility distributions indeed generate the exploded logit model.},
  archive      = {J_JOMP},
  author       = {Karim Kilani},
  doi          = {10.1016/j.jmp.2025.102900},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102900},
  shortjournal = {J. Math. Psychol.},
  title        = {A class of random utility models yielding the exploded logit},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysing the bias introduced by adaptive designs to
estimates of psychometric functions. <em>JOMP</em>, <em>124</em>,
102899. (<a href="https://doi.org/10.1016/j.jmp.2025.102899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive design adjusts dynamically as information is accrued. In psychometrics and psychophysics, a class of studies investigates a subject’s ability to perform tasks as a function of the stimulus intensity, ie the amount or clarity of information supplied for the task. The relationship between performance and intensity is represented by a psychometric function. Such experiments routinely apply adaptive designs using both previous intensities and performance to assign stimulus intensities, the strategy being to sample intensities where information about the psychometric function is maximised. We investigate the influence of adaptation on statistical inference about the psychometric function focusing on estimation, considering parametric and non-parametric estimation under both fixed and adaptive designs and under within-subject independence as well as dependence. We study the scenarios analytically and numerically through a simulation study. We show that while asymptotic properties of estimators are preserved under adaptation, the adaptive nature of the design introduces small-sample bias, in particular in the slope parameter of the psychometric function. We supply an explanation of this phenomenon that formalises and supplements the one found in the literature. We argue that this poses a dilemma for studies applying an adaptive design in the form of a trade-off between more efficient sampling and the need to increase the number of samples to ameliorate small-sample bias.},
  archive      = {J_JOMP},
  author       = {Simon Bang Kristensen and Katrine Bødkergaard and Bo Martin Bibby},
  doi          = {10.1016/j.jmp.2025.102899},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102899},
  shortjournal = {J. Math. Psychol.},
  title        = {Analysing the bias introduced by adaptive designs to estimates of psychometric functions},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dimensions of knowledge structures. <em>JOMP</em>,
<em>124</em>, 102898. (<a
href="https://doi.org/10.1016/j.jmp.2024.102898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A knowledge structure is inherently one-dimensional when its collection of states forms a chain. But how to define the dimension of a knowledge structure in general? We investigate four options: (i) the ordinal dimension , which is the dimension of the poset consisting of all states ordered by inclusion; (ii) for a knowledge space, the spatial dimension which is the least number of one-dimensional knowledge spaces which generate the space (a notion extending from learning spaces to knowledge spaces the dual of the convex dimension of an antimatroid); (iii) the bidimension , which is the bidimension of the membership relation from items to states, in either the intersection or the union version of the bidimension. Our results establish or disprove inequalities among the four dimension parameters for knowledge structures, for knowledge spaces, for terse knowledge structures, for terse knowledge spaces, and finally for learning spaces. We finally list some problems for future research.},
  archive      = {J_JOMP},
  author       = {Jean-Paul Doignon and Luca Stefanutti},
  doi          = {10.1016/j.jmp.2024.102898},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102898},
  shortjournal = {J. Math. Psychol.},
  title        = {Dimensions of knowledge structures},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Characterizing master fringes in competence-based knowledge
space theory for personalized learning applications. <em>JOMP</em>,
<em>124</em>, 102897. (<a
href="https://doi.org/10.1016/j.jmp.2024.102897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a general method to directly compute the outer (inner) master fringe of the knowledge state based on the top or bottom of the equivalence class of competence state, and a general method for personalized learning guidance (reinforcement learning recommendation) based on competences and the master fringe. Two characterization theorems are mainly given: one characterizes the top (bottom) of competence states using skill functions; the other characterizes the outer (inner) master fringe of knowledge states using problem functions. As applications of two characterization theorems, the first is to provide a new method to directly obtain the corresponding competence state’s top or bottom from the knowledge state. The second application is to integrate skills into the competence-based master fringe, which takes into account the influence of students’ latent competences, resulting in more precise values.},
  archive      = {J_JOMP},
  author       = {Gongxun Wang and Jinjin Li and Bo Wang and Chenyi Tao},
  doi          = {10.1016/j.jmp.2024.102897},
  journal      = {Journal of Mathematical Psychology},
  month        = {3},
  pages        = {102897},
  shortjournal = {J. Math. Psychol.},
  title        = {Characterizing master fringes in competence-based knowledge space theory for personalized learning applications},
  volume       = {124},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jpdc---9">JPDC - 9</h2>
<ul>
<li><details>
<summary>
(2025). Front matter 1 - full title page (regular issues)/special
issue title page (special issues). <em>JPDC</em>, <em>199</em>, 105060.
(<a href="https://doi.org/10.1016/S0743-7315(25)00027-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JPDC},
  doi          = {10.1016/S0743-7315(25)00027-9},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105060},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Front matter 1 - full title page (regular issues)/Special issue title page (special issues)},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DePoL: Assuring training integrity in collaborative learning
via decentralized verification. <em>JPDC</em>, <em>199</em>, 105056. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative learning enables multiple participants to jointly train complex models but is vulnerable to attacks like model poisoning or backdoor attacks. Ensuring training integrity can prevent these threats by blocking any tampered contributions from affecting the model. However, traditional approaches often suffer from single points of bottleneck or failure in decentralized environments. To address these issues, we propose DePoL , a secure, scalable, and efficient decentralized verification framework based on duplicated execution. DePoL leverages blockchain to distribute the verification tasks across multiple participant-formed groups, eliminating single-point bottlenecks. Within each group, redundant verification and a majority-based arbitration prevent single points of failure. To further enhance security, DePoL introduces a two-stage plagiarism-free commitment scheme to prevent untrusted verifiers from exploiting public on-chain data. Additionally, a hybrid verification method employs fuzzy matching to handle unpredictable reproduction errors, while a “slow path” ensures zero false positives for honest trainers. Our theoretical analysis demonstrates DePoL &#39;s security and termination properties. Extensive evaluations show that DePoL has overhead similar to common distributed machine learning algorithms, while outperforming centralized verification schemes in scalability, reducing training latency by up to 46%. Additionally, DePoL effectively handles reproduction errors with 0 false positives.},
  archive      = {J_JPDC},
  author       = {Zhicheng Xu and Xiaoli Zhang and Xuanyu Yin and Hongbing Cheng},
  doi          = {10.1016/j.jpdc.2025.105056},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105056},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {DePoL: Assuring training integrity in collaborative learning via decentralized verification},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Massive parallel simulation of gas turbine combustion using
a fully implicit unstructured solver on the heterogeneous sunway
taihulight supercomputer. <em>JPDC</em>, <em>199</em>, 105055. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive parallel simulations of a full annular aeroengine combustor chamber have been achieved on the on-chip heterogeneous Sunway Taihulight supercomputer. A billion-size unstructured mesh is generated through grid replication and rotation, accompanied by the development of an efficient geometric matching algorithm to address the conformal interface issue. We developed graph-based and tree-based loop fusion approaches for implicit solving procedure of the momentum equation, it is found that the strategic utilization of data reuse and separation of vector computation significantly enhances the performance on many-core processor. For linear system, a finer-grained parallelization based on sparse matrix-vector multiplication and vector computation is validated. Massive parallel tests utilizing 16 K processes with 1 M cores are successfully conducted to simulate the turbulent non-premixed combustion in an aeroengine combustor with nearly one billion cells. Compared to the pre-optimization version, this fully accelerated code achieves an impressive 5.48 times speedup in overall performance, with a parallel efficiency of up to 59 %.},
  archive      = {J_JPDC},
  author       = {Fei Gao and Hu Ren and Zhuyin Ren and Ming Liu and Chengpeng Zhao and Guangwen Yang},
  doi          = {10.1016/j.jpdc.2025.105055},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105055},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Massive parallel simulation of gas turbine combustion using a fully implicit unstructured solver on the heterogeneous sunway taihulight supercomputer},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient GPU-accelerated parallel cross-correlation.
<em>JPDC</em>, <em>199</em>, 105054. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-correlation is a data analysis method widely employed in various signal processing and similarity-search applications. Our objective is to design a highly optimized GPU-accelerated implementation that will speed up the applications and also improve energy efficiency since GPUs are more efficient than CPUs in data-parallel tasks. There are two rudimentary ways to compute cross-correlation — a definition-based algorithm that tries all possible overlaps and an algorithm based on the Fourier transform, which is much more complex but has better asymptotical time complexity. We have focused mainly on the definition-based approach which is better suited for smaller input data and we have implemented multiple CUDA-enabled algorithms with multiple optimization options. The algorithms were evaluated on various scenarios, including the most typical types of multi-signal correlations, and we provide empirically verified optimal solutions for each of the studied scenarios.},
  archive      = {J_JPDC},
  author       = {Karel Maděra and Adam Šmelko and Martin Kruliš},
  doi          = {10.1016/j.jpdc.2025.105054},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105054},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Efficient GPU-accelerated parallel cross-correlation},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GPU memory usage optimization for backward propagation in
deep network training. <em>JPDC</em>, <em>199</em>, 105053. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern Deep Learning, it has been a trend to design larger Deep Neural Networks (DNNs) for the execution of more complex tasks and better accuracy. On the other hand, Convolutional Neural Networks (CNNs) have become the standard method for most of computer vision tasks. However, the memory allocation for the intermediate data in convolution layers can cause severe memory pressure during model training. Many solutions have been proposed to resolve the problem. Besides hardware-dependent solutions, a general methodology rematerialization can reduce GPU memory usage by trading computation for memory efficiently. The idea is to select a set of intermediate results during the forward phase as checkpoints , and only save them in memory to reduce memory usage. The backward phase recomputes the intermediate data from the closest checkpoints in memory as needed. This recomputation increases execution time but saves memory by not storing all intermediate results in memory during the forward phase. In this paper, we will focus on efficiently finding the optimal checkpoint subset to achieve the least peak memory usage during the model training. We first describe the theoretical background of the training of a neural network using mathematical equations. We use these equations to identify all essential data required during both forward and backward phases to compute the gradient of weights of the model. We first identify the checkpoint selection problem and propose a dynamic programming algorithm with time complexity O ( n 3 ) to solve the problem of finding the optimal checkpoint subset. With extensive experiments, we formulate a more accurate description of the problem using our theoretical analysis and revise the objective function based on the tracing, and propose an O ( n ) -time algorithm for finding the optimal checkpoint subset.},
  archive      = {J_JPDC},
  author       = {Ding-Yong Hong and Tzu-Hsien Tsai and Ning Wang and Pangfeng Liu and Jan-Jan Wu},
  doi          = {10.1016/j.jpdc.2025.105053},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105053},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {GPU memory usage optimization for backward propagation in deep network training},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An introductory-level undergraduate CS course that
introduces parallel computing. <em>JPDC</em>, <em>199</em>, 105044. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the curricular design, pedagogy, and goals of an introductory-level course on computer systems that introduces parallel and distributed computing (PDC) to students who have only a CS1 background. With the ubiquity of multicore processors, cloud computing, and hardware accelerators, PDC topics have become fundamental knowledge areas in the undergraduate CS curriculum. As a result, it is increasingly important for students to learn a common core of introductory parallel and distributed computing topics and to develop parallel thinking skills early in their CS studies. Our introductory-level course focuses on three main curricular goals: 1) understanding how a computer runs a program, 2) evaluating system costs associated with running a program, and 3) taking advantage of the power of parallel computing. We elaborate on the goals and details of our course&#39;s key modules, and we discuss our pedagogical approach that includes active-learning techniques. We also include an evaluation of our course and a discussion of our experiences teaching it since Fall 2012. We find that the PDC foundation gained through early exposure in our course helps students gain confidence in their ability to expand and apply their understanding of PDC concepts throughout their CS education.},
  archive      = {J_JPDC},
  author       = {Tia Newhall and Kevin C. Webb and Vasanta Chaganti and Andrew Danner},
  doi          = {10.1016/j.jpdc.2025.105044},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105044},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {An introductory-level undergraduate CS course that introduces parallel computing},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRViT: A dynamic redundancy-aware vision transformer
accelerator via algorithm and architecture co-design on FPGA.
<em>JPDC</em>, <em>199</em>, 105042. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-modal artificial intelligence (MAI) has attracted significant interest due to its capability to process and integrate data from multiple modalities, including images, text, and audio. Addressing MAI tasks in distributed systems necessitate robust and efficient architectures. The Transformer architecture has emerged as a primary network in this context. The integration of Vision Transformers (ViTs) within multimodal frameworks is crucial for enhancing the processing and comprehension of image data across diverse modalities. However, the complex architecture of ViTs and the extensive resources required for processing large-scale image data pose high computational and storage demands. These demands are particularly challenging for deploying ViTs on edge devices within distributed frameworks. To address this issue, we propose a novel dynamic redundancy-aware ViT accelerator based on parallel computing, termed DRViT. DRViT is supported by an algorithm and architecture co-design. We first propose a hardware-friendly lightweight algorithm featuring token merging, token pruning, and an INT8 quantization scheme. Then, we design a specialized architecture to support this algorithm, transforming the lightweight algorithm into significant latency and energy-efficiency improvements. Our design is implemented on the Xilinx Alveo U250, achieving an overall inference latency of 0.86 ms and 1.17 ms per image for ViT-tiny at 140 MHz and 100 MHz, respectively. The throughput can reach 1,380 GOP/s at peak, demonstrating superior performance compared to state-of-the-art accelerators, even at lower frequencies.},
  archive      = {J_JPDC},
  author       = {Xiangfeng Sun and Yuanting Zhang and Qinyu Wang and Xiaofeng Zou and Yujia Liu and Ziqian Zeng and Huiping Zhuang},
  doi          = {10.1016/j.jpdc.2025.105042},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105042},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {DRViT: A dynamic redundancy-aware vision transformer accelerator via algorithm and architecture co-design on FPGA},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latency-aware placement of stream processing operators in
modern-day stream processing frameworks. <em>JPDC</em>, <em>199</em>,
105041. (<a href="https://doi.org/10.1016/j.jpdc.2025.105041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of the Internet of Things has substantially increased the number of interconnected devices at the edge of the network. As a result, a large number of computations are now distributed in the compute continuum, spanning from the edge to the cloud, generating vast amounts of data. Stream processing is typically employed to process this data in near real-time due to its efficiency in handling continuous streams of information in a scalable manner. However, many stream processing approaches do not consider the underlying network devices of the compute continuum as candidate resources for processing data. Moreover, many existing works do not consider the incurred network latency of performing computations on multiple devices in a distributed way. To avoid this, we formulate an optimization problem for utilizing the complete compute continuum resources and design heuristics to solve this problem efficiently. Furthermore, we integrate our heuristics into Apache Storm and perform experiments that show latency- and throughput-related benefits compared to alternatives.},
  archive      = {J_JPDC},
  author       = {Raphael Ecker and Vasileios Karagiannis and Michael Sober and Stefan Schulte},
  doi          = {10.1016/j.jpdc.2025.105041},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105041},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Latency-aware placement of stream processing operators in modern-day stream processing frameworks},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skyward secure: Advancing drone data-sharing in 6G with
decentralized dataspace and supported technologies. <em>JPDC</em>,
<em>199</em>, 105040. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacity of Dataspace enables the distribution of heterogeneous data from several sources and domains and has attracted attention for resolving data integration challenges. Drone data sharing faces challenges such as protecting privacy and security, building trust and dependability, controlling latency and scalability, facilitating real-time data processing, and preserving the caliber of shared models. Therefore, sixth-generation (6G) networks provide high throughput and low latency to improve drone operations; security issues are exacerbated by the sensitive nature of shared data and the lack of centralized monitoring. To address the challenges, this paper presents a conceptual framework for a Dataspace in the Sky to enable secure and efficient drone data-sharing within 6G networks in the transition from Industry 4.0 to Industry 5.0. The Dataspace in the Sky integrates Federated Learning (FL), a decentralized Machine Learning (ML) approach that enhances security and privacy by sharing models instead of raw data, facilitating effective drone collaboration. However, the quality of shared local models often suffers due to inconsistent data contributions and unreliable recording mechanisms, which can undermine the performance of FL. To tackle the challenges, the framework employs blockchain (BC) to decentralize and secure the Dataspace, ensuring the integrity of contribution records and improving the reliability of shared models. Dataspace in the Sky empowered decentralized data sharing which addresses latency issues by decentralizing decision-making and enhances trust and reliability by leveraging immutable and transparent BC mechanisms. The robustness of Dataspace in the Sky solution is not only secures drone-sharing operations in 6G environments but enables the development of citizen-friendly mobility services, expanding opportunities across smart environments.},
  archive      = {J_JPDC},
  author       = {Saeed Hamood Alsamhi and Sumit Srivastava and Mamoon Rashid and Amnnah Alhabeeb and Santosh Kumar and Navin Singh Rajput and Ammar Hawbani and Liang Zhao and Mohammed A.A. Al-qaness and Edward Curry},
  doi          = {10.1016/j.jpdc.2025.105040},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105040},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Skyward secure: Advancing drone data-sharing in 6G with decentralized dataspace and supported technologies},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="jtb---13">JTB - 13</h2>
<ul>
<li><details>
<summary>
(2025). The short comment on the individual response to ionizing
radiation. <em>JTB</em>, <em>604</em>, 112092. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JTB},
  author       = {Krzysztof Wojciech Fornalski},
  doi          = {10.1016/j.jtbi.2025.112092},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112092},
  shortjournal = {J. Theor. Biol},
  title        = {The short comment on the individual response to ionizing radiation},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The effects of trade-off shape and dimensionality on
eco-evolutionary dynamics in resource competition. <em>JTB</em>,
<em>604</em>, 112087. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Organisms invariably experience trade-offs in their capacities for interacting with their environments. In resource competition, this often means that an organism’s ability to acquire one resource can only come at the cost of less ability with others. If the traits governing resource acquisition are under selection and heritable, this will induce eco-evolutionary dynamics along the trade-off. For Lotka–Volterra models derived from MacArthur resource competition models and for explicit resource models with two resources, the shape and dimensionality of trade-offs has seen substantial study. However, how the joint effects of trade-off shapes and the number of resources under competition affect eco-evolutionary outcomes has seen relatively little. For example, is diversification through evolutionary branching more or less likely when the number of resources increases? Here, we will present techniques complementary to existing ones for recasting trade-offs in an implicit form. Combining adaptive dynamics and resource-competition theory, we derive expressions for directional and stabilizing/disruptive selection. We apply our techniques to two models of resource competition and investigate how the number of resources and trade-off shapes affect the stability characteristics of the generalist strategy, and how diverse a community of consumers can be assembled through successive evolutionary branching. We find that even for these simple and highly symmetric models, outcomes are surprisingly complex and idiosyncratic. Taken together, our results deepen our understanding of the eco-evolutionary dynamics of resource competition for multiple resources.},
  archive      = {J_JTB},
  author       = {Jonas Wickman and Christopher A. Klausmeier},
  doi          = {10.1016/j.jtbi.2025.112087},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112087},
  shortjournal = {J. Theor. Biol},
  title        = {The effects of trade-off shape and dimensionality on eco-evolutionary dynamics in resource competition},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Absorbing markov chain model of PrEP drug adherence to
estimate adherence decay rate and probability distribution in clinical
trials. <em>JTB</em>, <em>604</em>, 112086. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-exposure prophylaxis (PrEP) is increasingly used to prevent the transmission of H.I.V. in at-risk populations. However, PrEP users may discontinue use of the medicine due to side effects, lower perceived risk, or other reasons. The usage metrics of 594 individuals was tracked over 350 days using the Wisepill electronic monitoring system. We model the PrEP drug adherence level using an absorbing Markov chain with a unique absorbing state. The transition matrix T obtained from the Wisepill data will have a trivial eigenvector (eigendistribution) associated with the first (i.e., largest) eigenvalue 1. The 2nd eigenvalue(s) then become important in determining the asymptotic behavior of the Markov chain, dictating how fast the Markov chain decays to the absorbing state. Under a fairly general assumption, we prove that the second positive eigenvalue is unique and the corresponding eigenvector will have nonnegative entries with exceptions at absorbing states. In addition, we define the asymptotic half life of the absorbing Markov chain directly from the 2nd eigenvalue. We then determine the 2nd eigenvalue of T and the asymptotic half life of the Markov chain, which turns out to be very close to the real half life of the Markov chain. Finally, we interpret the 2nd eigenvector as the relative probability distribution of X ∞ with respect to the decay rate of the 2nd eigenvalue. By applying these methods to the Wisepill data, we estimate the half-life of population adherence to be 46 weeks. The bi-weekly decay rate observed in these data from 90 to 100 % adherence is 3 %. This work produces an estimate at which adherence falls over time, given no external intervention is applied. These results suggest an eigenvector-based approach to estimate adherence trends, as well as the timing of interventions to improve adherence.},
  archive      = {J_JTB},
  author       = {Renee Dale and Hongyu He and Yingqing Chen},
  doi          = {10.1016/j.jtbi.2025.112086},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112086},
  shortjournal = {J. Theor. Biol},
  title        = {Absorbing markov chain model of PrEP drug adherence to estimate adherence decay rate and probability distribution in clinical trials},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometrically balanced model of cell growth. <em>JTB</em>,
<em>604</em>, 112085. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proteome balance constraint in metabolic flux balance analysis asserts that the proteome is constructed by ribosomes, which themselves contain many proteins. This leads to a fundamental question of optimal allocation of limited proteome among different pools of enzymes, which include ribosomes themselves. However, recent work points to additional constraints imposed by the cell geometry. In this paper we deduce the proteogeometric constraint π ¯ A = π A + θ π L / π P , where π A , π P and π L are the proteomic fractions allocated to the cell surface area, protein synthesis and cell membrane phospholipids synthesis and π ¯ A and θ are constants imposed by geometry of the cell. We illustrate the relevance of this constraint using a reduced model of cell metabolism, illuminating the interplay between cell metabolism and cell geometry.},
  archive      = {J_JTB},
  author       = {Alexei Vazquez and Tomáš Gedeon},
  doi          = {10.1016/j.jtbi.2025.112085},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112085},
  shortjournal = {J. Theor. Biol},
  title        = {Geometrically balanced model of cell growth},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Incorporating adult age into mosquito population models:
Implications for predicting abundances in changing climates.
<em>JTB</em>, <em>604</em>, 112084. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mosquito-borne diseases (MBDs) pose increasing threats under future climate change scenarios and an understanding of mosquito population dynamics is pivotal to predicting future risk of MBDs. Most models that describe mosquito population dynamics often assume that adult life-history is independent of adult age and yet mosquito senescence is known to affect mosquito mortality, fecundity and other key biological traits. Despite this, little is known about the effects of adult age at the level of the mosquito population, especially under varying temperature scenarios. We develop a stage-structured delayed differential equations (DDEs) model incorporating the effects of the abiotic environment and adult age to shed light on the complex interactions between age, temperature, and mosquito population dynamics. Taking Culex pipiens , a major vector of West Nile Virus, as our study species our results show that failing to consider mosquito senescence can lead to underestimates of future mosquito abundances predicted under climate change scenarios. We also find that the age-dependent mechanisms combined with the effects of density-dependent mortality on the immature stages can result in mosquito abundances decreasing at extreme temperatures. With our work, we underscore the need for more studies to consider the effects of mosquito age. Not accounting for senescence can compromise the accuracy of abundance estimates and has implications for predicting the risk of future MBD outbreaks.},
  archive      = {J_JTB},
  author       = {Renato Andrade and Steven M. White and Christina A. Cobbold},
  doi          = {10.1016/j.jtbi.2025.112084},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112084},
  shortjournal = {J. Theor. Biol},
  title        = {Incorporating adult age into mosquito population models: Implications for predicting abundances in changing climates},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding the regulation of chronic wounds by tissue
inhibitors of matrix metalloproteinases through mathematical modelling.
<em>JTB</em>, <em>604</em>, 112083. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the biochemistry and pharmacodynamics of chronic wounds is of key importance, due to the millions of people in the UK affected and the significant cost to the NHS. Chronic wounds are characterised by elevated concentrations of matrix metalloproteinases (MMPs) that destroy the surrounding extracellular matrix (ECM). However, fibroblasts can produce tissue inhibitors of MMPs (TIMPs) in order to regulate wound healing. Therefore, the role of TIMPs in both acute and chronic wounds needs to be properly understood in order to develop therapeutic treatments. In this work, we propose a reaction-diffusion system of four partial differential equations that describe the interaction of the ECM, fibroblasts, MMPs, and TIMPs in a wound. We observe that, subject to parameter sets corresponding to both acute and chronic wound healing, this mathematical model gives rise to travelling wave solutions. Using bifurcation analysis, we demonstrate that excessive degradation of the ECM results in the emergence of chronic wounds, and the reversal of these chronic wounds is prohibited for lower TIMP production values. These results are replicated within a simplified model obtained via a parameter sensitivity analysis. This model is further extended to more realistic spatial domains where we demonstrate the effectiveness of a therapeutic hydrogel containing TIMPs as a treatment for chronic wounds.},
  archive      = {J_JTB},
  author       = {Sonia Dari and Reuben D. O’dea and Nabil T. Fadai},
  doi          = {10.1016/j.jtbi.2025.112083},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112083},
  shortjournal = {J. Theor. Biol},
  title        = {Understanding the regulation of chronic wounds by tissue inhibitors of matrix metalloproteinases through mathematical modelling},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Kir4.1 channel and voltage-gated calcium channel of
astrocyte account for the transition dynamics of seizures. <em>JTB</em>,
<em>604</em>, 112082. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Astrocytes have an important role in the indirect regulation of neuronal excitability. The abnormalities of their ion channels cause neurons to discharge abnormally, which may induce seizures. The inwardly rectifying potassium channel 4.1 (Kir4.1 channel) and the voltage-gated calcium channel (VGCC) of an astrocyte play important roles in maintaining the homeostasis of these potassium and calcium ions, and have been found to be associated with seizures. However, the underlying mechanisms by which they induce seizures remain unclear. This paper established a neuron-astrocyte network model, which is a model consisting of a neuron and an astrocyte, to explore some mechanisms of epileptic seizures. Through a series of simulations based on this model, the results showed that low conductance of Kir4.1 channel can induce spontaneous periodic epileptic activity (SPEA) whereas higher conductance results in spontaneous periodic bursting event (SPBE) and high-frequency tonic discharges (HFTD). The abnormalities of VGCC also lead to the generation of SPEA and SPBE. As the changes of potassium concentration in the largest nearby reservoir which is analogous to a bath solution that contains a specific concentration of potassium, SPEA can undergo a process from appearance to disappearance. Thus, the research findings showed that the transitions of seizure-like discharges provide further theoretical analyses to clarify the complex mechanism of seizures.},
  archive      = {J_JTB},
  author       = {Yu Rui and Shu Liu and Suyu Liu},
  doi          = {10.1016/j.jtbi.2025.112082},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112082},
  shortjournal = {J. Theor. Biol},
  title        = {Kir4.1 channel and voltage-gated calcium channel of astrocyte account for the transition dynamics of seizures},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PD-based ADRC using time-varying gains: An application to
microalgal-based bioprocess. <em>JTB</em>, <em>604</em>, 112074. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microalgae cultivation has gained significant attention in recent years due to its potential applications in various fields. However, achieving high productivity in these bioprocesses requires efficient process control. The dynamics of growth models typically comprise both known and unknown components due to mismatches between the nonlinear dynamics and their mathematical representations. Additionally, microalgal culture is subject to external disturbances. To address these issues, a classical proportional-derivative (PD) providing the feedback error, assisted by a time-varying gain extended state observer (ESO), maintaining the structure of an Active Disturbance Rejection Control (ADRC), was implemented. The formulation is aided by a time-varying gain extended state observer to avoid high-peaking estimation values. The optimal operating conditions were identified using the GEKKO Python package. The proposed controller was applied to the growth model of the microalga Isochrysis galbana , and numerical results demonstrated the effectiveness of the control strategy in eliminating steady-state error and ensuring asymptotic convergence to the optimal equilibrium despite unknown disturbances. A detailed analysis of the photobioreactor model, including stability under steady-state conditions, was also conducted. The results indicated that the model exhibits one, two, or no stable steady-state solutions when the dilution rate ( D ( t ) ) is manipulated.},
  archive      = {J_JTB},
  author       = {Viyils Sangregorio-Soto and Edgar Yesid Mayorga Lancheros and Gianfranco Mazzanti and Claudia L. Garzón-Castro},
  doi          = {10.1016/j.jtbi.2025.112074},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112074},
  shortjournal = {J. Theor. Biol},
  title        = {PD-based ADRC using time-varying gains: An application to microalgal-based bioprocess},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Co-evolution of pathogen–host interactions with vertical
transmission can produce bistable outcomes. <em>JTB</em>, <em>604</em>,
112073. (<a href="https://doi.org/10.1016/j.jtbi.2025.112073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vertical transmission is widely predicted to select for reduced virulence of pathogens. Recent theory cast doubt on this prediction by showing that the evolutionary response of the host to vertical transmission can lead to severe disease outcomes. That theory, however, takes a simplified view of host population dynamics by assuming pathogen-induced mortality alone inhibits host population growth. The assumption limits our ability to uncover benign co-evolutionary outcomes characterized by low levels of pathogen-induced mortality. Here, we revisit the role of vertical transmission using a model that assumes host population growth is self-regulated. Our model tracks the co-evolution of pathogen-induced mortality and host recovery until both have reached an evolutionarily stable level. For any given set of model conditions, we could identify as many as two distinct pairs of stable mortality-recovery traits. Mortality and recovery were higher for one of the pairs (the ‘escalated’ one) and lower for the other of the pairs (the ‘de-escalated’ one). As the rate of vertical transmission rose, stable expression of the pathogen-induced mortality trait always decreased, while stable expression of the host-recovery trait increased for ‘escalated’ pairs and decreased for ‘de-escalated’ ones. In addition, (i) increasing the intrinsic rate of host population growth, (ii) increasing the cost of host recovery, and (iii) decreasing the efficiency of horizontal disease transmission all led to lower levels of stable trait expression for both pathogen and host. Factors (i)-(iii) also led to lower virulence, more frequent occurrence of the de-escalated (almost commensal) stable outcome, and greater disease prevalence. We conclude that (i)-(iii) promote the co-evolution of more benign interactions in keeping with previous findings. However, our new insight is that the benign nature of the host-pathogen interaction can now be understood as the more frequent occurrence of the de-escalated outcome. We discuss our findings in light of previous theory and experimental work.},
  archive      = {J_JTB},
  author       = {Samantha Brotman and Geoff Wild},
  doi          = {10.1016/j.jtbi.2025.112073},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112073},
  shortjournal = {J. Theor. Biol},
  title        = {Co-evolution of pathogen–host interactions with vertical transmission can produce bistable outcomes},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal social distancing in pandemic preparedness and
lessons from COVID-19: Intervention intensity and infective travelers.
<em>JTB</em>, <em>604</em>, 112072. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our analysis seeks best social distancing strategies optimally balancing the direct costs of a threatening outbreak with its societal-level costs by investigating the effects of different levels of restrictions’ intensity and of the continued importation of infective travellers, while controlling for the key dimensions of the response, such as early action, adherence and the relative weight of societal costs. We identify two primary degrees of freedom in epidemic control, namely the maximum intensity of control measures and their duration. In the absence of travellers, a lower (higher) maximum intensity requires a longer (shorter) duration to achieve similar control outcomes. However, uncontrollable external factors, like the importation of undetected infectives, significantly constrain these degrees of freedom so that the optimal strategy results to be one with low/moderate intensity but prolonged in time. These findings underscore the necessity for resilient health systems and coordinated global responses in preparedness plans.},
  archive      = {J_JTB},
  author       = {Alberto Landi and Giulio Pisaneschi and Marco Laurino and Piero Manfredi},
  doi          = {10.1016/j.jtbi.2025.112072},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112072},
  shortjournal = {J. Theor. Biol},
  title        = {Optimal social distancing in pandemic preparedness and lessons from COVID-19: Intervention intensity and infective travelers},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An in-depth study of the dynamics of thornley’s mathematical
model in plant biology with a view to an improved model. <em>JTB</em>,
<em>604</em>, 112071. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Plants are essential for life on Earth, serving as a major source of food supply and contributing to the planet’s carbon balance. Mathematical modelling is an important mechanism for predicting and optimising plant growth in agriculture, and Thornley’s mathematical model (Thornley, 1997) is one of the most widely used models describing carbon and nitrogen allocation in plants. However, a formal mathematical analysis of the model’s behaviour has not been performed. Our analysis of the model provides new insights into how and why the model can be inappropriate. By varying the values of some model parameters, we identify non-physical and even quite chaotic behaviour. In response, we modify Thornley’s model by including additional litter terms, resulting in the elimination of these non-physical behaviours.},
  archive      = {J_JTB},
  author       = {Ati Rostami and Brodie A.J. Lawson and Kevin Burrage},
  doi          = {10.1016/j.jtbi.2025.112071},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112071},
  shortjournal = {J. Theor. Biol},
  title        = {An in-depth study of the dynamics of thornley’s mathematical model in plant biology with a view to an improved model},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cell position-based evaluation of mechanical features of
cells in multicellular systems. <em>JTB</em>, <em>604</em>, 112070. (<a
href="https://doi.org/10.1016/j.jtbi.2025.112070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measurement of mechanical forces of cell–cell interactions is important for studying the emergence of diverse three-dimensional morphologies of multicellular organisms. We previously reported an image-based statistical method for inferring effective pairwise forces of cell–cell interactions (i.e., attractive/repulsive forces), where a cell particle model was fitted to cell tracking data acquired by live imaging. However, because the particle model is a coarse-grained model, it remains unclear how the pairwise forces relates to sub-cellular mechanical components including cell–cell adhesive forces. Here we applied our inference method to cell tracking data generated by vertex models that assumed sub-cellular components. Through this approach, we investigated the relationship between the effective pairwise forces and various sub-cellular components: cell–cell adhesion forces, cell surface tensions, cell–extracellular matrix (ECM) adhesion, traction forces between cells and ECM, cell growth, etc. We found that the cell–cell adhesion forces were attractive, and both the cell surface tensions and cell–ECM adhesive forces were repulsive, etc. These results indicate that sub-cellular mechanical components can contribute to the effective attractive/repulsive forces of cell–cell interactions. This comprehensive analysis provides theoretical bases for linking the pairwise forces to the sub-cellular mechanical components: this showcase is useful for speculating the sub-cellular mechanical components from the information of cell positions, and for interpreting simulation results based on particle models.},
  archive      = {J_JTB},
  author       = {Hiroshi Koyama and Atsushi M. Ito and Hisashi Okumura and Tetsuhisa Otani and Kazuyuki Nakamura and Toshihiko Fujimori},
  doi          = {10.1016/j.jtbi.2025.112070},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112070},
  shortjournal = {J. Theor. Biol},
  title        = {Cell position-based evaluation of mechanical features of cells in multicellular systems},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tradeoffs in the energetic value of neuromodulation in a
closed-loop neuromechanical system. <em>JTB</em>, <em>604</em>, 112050.
(<a href="https://doi.org/10.1016/j.jtbi.2025.112050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rhythmic motor behaviors controlled by neuromechanical systems, consisting of central neural circuitry, biomechanics, and sensory feedback, show efficiency in energy expenditure. The biomechanical elements (e.g., muscles) are modulated by peripheral neuromodulation which may improve their strength and speed properties. However, there are relatively few studies on neuromodulatory control of muscle function and metabolic mechanical efficiency in neuromechanical systems. To investigate the role of neuromodulation on the system’s mechanical efficiency, we consider a neuromuscular model of motor patterns for feeding in the marine mollusk Aplysia californica . By incorporating muscle energetics and neuromodulatory effects into the model, we demonstrate tradeoffs in the energy efficiency of Aplysia ’s rhythmic swallowing behavior as a function of the level of neuromodulation. A robust efficiency optimum arises from an intermediate level of neuromodulation, and excessive neuromodulation may be inefficient and disadvantageous to an animal’s metabolism. This optimum emerges from physiological constraints imposed upon serotonergic modulation trajectories on the energy efficiency landscape. Our results may lead to experimentally testable hypotheses of the role of neuromodulation in rhythmic motor control.},
  archive      = {J_JTB},
  author       = {Zhuojun Yu and Yangyang Wang and Peter J. Thomas and Hillel J. Chiel},
  doi          = {10.1016/j.jtbi.2025.112050},
  journal      = {Journal of Theoretical Biology},
  month        = {5},
  pages        = {112050},
  shortjournal = {J. Theor. Biol},
  title        = {Tradeoffs in the energetic value of neuromodulation in a closed-loop neuromechanical system},
  volume       = {604},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="matdes---100">MATDES - 100</h2>
<ul>
<li><details>
<summary>
(2025). Cover_252. <em>MATDES</em>, <em>252</em>, 113847. (<a
href="https://doi.org/10.1016/S0264-1275(25)00267-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  doi          = {10.1016/S0264-1275(25)00267-9},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113847},
  shortjournal = {Mater. Des.},
  title        = {Cover_252},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Direct evidence and kinetics of cu precipitation in the
austenite phase of a maraging stainless steel. <em>MATDES</em>,
<em>252</em>, 113835. (<a
href="https://doi.org/10.1016/j.matdes.2025.113835">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate the precipitation kinetics of Cu in 15–5 PH maraging stainless steel during high-temperature thermal treatments in the fully austenitic state. This provides direct evidence that Cu precipitation can occur in the austenite phase of martensitic or ferritic steels. The kinetics of Cu precipitation in austenite are examined at 700 and 800 °C using in situ synchrotron small-angle and wide-angle X-ray scattering, complemented by atom probe tomography investigations to analyze the precipitates, particularly their chemistry, following heat treatment. The resulting experimental data, which include the evolution of size, volume fraction, number density and chemical composition, are used to inform precipitation kinetics modelling using the Langer-Schwartz-Kampmann-Wagner (LSKW) approach coupled with CALPHAD thermodynamic and kinetic databases. The simulations accurately capture the experimental data by adjusting the interfacial energy in an inverse modelling approach. The insight that Cu precipitation occurs in austenite and subsequently in martensite paves the way for design of hierarchical structures with a bi-modal particle size distribution of Cu precipitates with varying crystal structures and compositions. Additionally, the validated LSKW modelling approach establishes a foundation for designing Cu-alloyed high-performance steels, taking into account various manufacturing routes.},
  archive      = {J_MATDES},
  author       = {Tao Zhou and Gabriel Spartacus and Xiaoqing Li and Sonia Guehairia and Tim Fischer and Malte Blankenburg and Peter Hedström},
  doi          = {10.1016/j.matdes.2025.113835},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113835},
  shortjournal = {Mater. Des.},
  title        = {Direct evidence and kinetics of cu precipitation in the austenite phase of a maraging stainless steel},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Molecular dynamics and machine learning study of tensile
behavior in single-crystal tungsten containing he bubbles.
<em>MATDES</em>, <em>252</em>, 113831. (<a
href="https://doi.org/10.1016/j.matdes.2025.113831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tungsten is commonly used in nuclear fusion plants, where irradiation defects (e.g., He bubbles) are frequently generated. This study investigates the impact of He bubbles on the tensile behavior of single-crystal tungsten through molecular dynamics (MD) simulations. The analysis considers varying He bubble sizes, He/V ratios (the number of helium atoms with respect to the number of vacancies in helium bubble), temperatures, and strain rates. The findings indicate that He bubbles significantly affect the material’s mechanical properties, with larger bubble sizes reducing tensile strength. Dislocation emission initiates from the void surface during tensile deformation. While the He/V ratio slightly influences peak stress values, it does not alter the overall stress–strain curve. Elevated temperatures lower peak stress, whereas higher strain rates increase it. Additionally, machine learning models predict the combined effects of bubble size, He/V ratio, strain rate, and temperature on the peak stress of tungsten, utilizing MD simulation data. This work offers important insights into tungsten’s behavior under irradiation conditions.},
  archive      = {J_MATDES},
  author       = {Pan-dong Lin and Yan Lin and Hong-guang Li and Shu-gang Cui and Jun-feng Nie and Bai-wen Zhong and Yu-peng Lu},
  doi          = {10.1016/j.matdes.2025.113831},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113831},
  shortjournal = {Mater. Des.},
  title        = {Molecular dynamics and machine learning study of tensile behavior in single-crystal tungsten containing he bubbles},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microstructure and composition evolution of SPPs in the
oxide film of zr-1.0Sn-0.25Nb-0.2Fe-0.1Cr during corrosion.
<em>MATDES</em>, <em>252</em>, 113830. (<a
href="https://doi.org/10.1016/j.matdes.2025.113830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The microstructure and composition evolution of SPPs in the oxide film of Zr-1.0Sn-0.25Nb-0.2Fe-0.1Cr alloy during aqueous corrosion at 360 °C is investigated by HRTEM. The results show that SPPs with their distances to the O-M interface less than 500 nm remain metallic and exhibit similar structure and composition as those in Zr matrix. However, the SPPs with their distances to the O-M interface more than 1 μm exhibit obvious oxidation, characterized by the high O content and the appearance of the oxides of Fe, Cr and Zr inside the SPPs. The cracks connected to the SPPs could provide a good O supply and enhance the oxidation of the SPPs. Such cracks also promote the outwards diffusion of Fe and Cr from the SPPs during oxidation. In the oxidized Zr(FeCrNb) 2 particles, Fe has a faster outwards diffusion rate than Cr, while Nb seems to be almost immobile. Under certain conditions, small oxidized SPPs will leave porous regions within the oxide film locally. Tetragonal ZrO 2 is observed occasionally nearby the oxidized SPPs, which is thought to be caused by the doping effect of Fe depleted from the dissolved SPPs.},
  archive      = {J_MATDES},
  author       = {Tianguo Wei and Xun Dai and Yi Zhao and Dong Wang and Yufeng Du and JiYun Zheng and Chongsheng Long and Chao Sun},
  doi          = {10.1016/j.matdes.2025.113830},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113830},
  shortjournal = {Mater. Des.},
  title        = {Microstructure and composition evolution of SPPs in the oxide film of zr-1.0Sn-0.25Nb-0.2Fe-0.1Cr during corrosion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Geometric design and mechanical performance of isotropic
bone scaffolds. <em>MATDES</em>, <em>252</em>, 113829. (<a
href="https://doi.org/10.1016/j.matdes.2025.113829">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bone tissue engineering scaffolds with reduced elastic anisotropy, enhanced mechanical performance, and high ratio of surface to volume are continuous pursuits. In this work, a mechanical metamaterial design strategy for isotropic bone scaffolds is proposed. The design of isotropic bone scaffolds is realized by interactive clipping of the lattice structure without nesting and complex adjustments. Employing homogenization, elastic stiffness tensors were estimated to evaluate the anisotropic measure, according to Zener ratio and elastic modulus. The designed scaffolds have a Zener ratio of nearly 1.0 and an increase of 20 % in stiffness over the pristine lattice. Quasi-static compression experiments were performed to investigate the Ti4Al6V scaffolds fabricated by selective laser melting, and the results showed that the isotropic scaffolds had compressive strengths of 100.59–198.53 MPa and stiffnesses of 1.86–4.88 GPa, which met the requirements for bone implants. Finite element simulations further revealed the structure’s mechanical response mechanism. Computational fluid dynamics results demonstrated that the structure’s permeability of 8.56 × 10 −9 -1.29 × 10 −8 m 2 , matches well with the requirements of human trabecular bone. Its large surface area facilitates osteogenic differentiation and enhances osseointegration. This study has important contribution in overcoming the constraints in the clinical applications of bone tissue engineering scaffolds.},
  archive      = {J_MATDES},
  author       = {Rongwei Xu and Zhou Zhang and Zhen Peng and Fuyuan Deng and Zhong Li and Xu Liu and Liang He},
  doi          = {10.1016/j.matdes.2025.113829},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113829},
  shortjournal = {Mater. Des.},
  title        = {Geometric design and mechanical performance of isotropic bone scaffolds},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanisms of in-situ polymerization for enhancing washout
resistance of cement paste. <em>MATDES</em>, <em>252</em>, 113825. (<a
href="https://doi.org/10.1016/j.matdes.2025.113825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional concrete is generally unsuitable for underwater construction, typically requiring the addition of anti-washout admixtures (AWAs) to improve its washout resistance. Herein, we demonstrate the enhancement of cement paste washout resistance through the in-situ polymerization of acrylamide (AM) and sodium acrylate (SA) and elucidate the underlying mechanisms. Macroscopic experiments reveal a significant improvement, with washout loss reduced to 12 % and 2 % of that observed in REF at 60 min for cement pastes modified by the in-situ polymerization of AM and SA, respectively. This enhancement is attributed to the formation of a more flocculated microstructure, where smaller flocs agglomerate into larger ones due to increased floc strength induced by the bridging effect of the resultant polymers. Consequently, flocs in cement pastes with in-situ polymerized SA exhibit higher strength and a denser structure, with a fractal dimension ( D f ) exceeding 2.00, shifting the floc break mode from surface erosion to large-scale fragmentation and thereby improving washout resistance. Nevertheless, the in-situ polymerization of both AM and SA retards cement hydration, albeit through distinct mechanisms: the non-adsorbing PAM molecules primarily hinder the nucleation and formation of hydration products, whereas the adsorbed PAAS molecules predominantly inhibit the dissolution of aqueous species.},
  archive      = {J_MATDES},
  author       = {Zhaoyang Sun and Ming Sun and Dongshuai Hou and Binmeng Chen},
  doi          = {10.1016/j.matdes.2025.113825},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113825},
  shortjournal = {Mater. Des.},
  title        = {Mechanisms of in-situ polymerization for enhancing washout resistance of cement paste},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-situ alloying of nonequiatomic TiNbMoTaW refractory
bio-high entropy alloy via laser powder bed fusion: Achieving suppressed
microsegregation and texture formation. <em>MATDES</em>, <em>252</em>,
113824. (<a href="https://doi.org/10.1016/j.matdes.2025.113824">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-entropy alloys (HEAs) have attracted considerable attention owing to their excellent properties. However, the severe segregation of the constituent elements remains a common challenge in refractory HEAs. Recently, an approach to suppress segregation was proposed using laser powder bed fusion (LPBF) owing to the ultra-high cooling rates during solidification. Despite the advantages of LPBF, the persistent microsegregation between the dendritic and interdendritic regions of refractory HEAs and costly gas atomization process hinder the further development. To address these challenges, a novel nonequiatomic TiNbMoTaW refractory HEA was designed to minimize the difference between the liquidus and solidus temperatures to prevent segregation and phase separation for a better biological performance. In-situ alloying was implemented instead of costly and time-consuming gas atomization process. The segregation of constituent elements was suppressed by remelting, resulted in epitaxial growth and development of crystallographic texture, consequently reducing residual stress. The mechanical properties were improved due to the increase of solid solution strengthening and densification. It showed superior mechanical strength and equivalent biocompatibility compared to conventional biomaterials, indicating its superiority as a biomaterial. This study represents the first successful control of crystallographic texture through in-situ alloying of BioHEAs for next-generation biomaterials.},
  archive      = {J_MATDES},
  author       = {Yong Seong Kim and Ozkan Gokcekaya and Kazuhisa Sato and Ryosuke Ozasa and Aira Matsugaki and Takayoshi Nakano},
  doi          = {10.1016/j.matdes.2025.113824},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113824},
  shortjournal = {Mater. Des.},
  title        = {In-situ alloying of nonequiatomic TiNbMoTaW refractory bio-high entropy alloy via laser powder bed fusion: Achieving suppressed microsegregation and texture formation},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel concept for self-healing metallic structural
materials: Internal soldering of damage using low melting eutectics.
<em>MATDES</em>, <em>252</em>, 113821. (<a
href="https://doi.org/10.1016/j.matdes.2025.113821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel self-healing concept for metallic structural materials based on internal soldering using low-melting constituents is presented. The proof-of-principle study is based on a binary Al–4.28 wt%-Sn alloy, where a Sn-rich eutectic with a liquidus temperature of 228 °C acts as a self-assembling healing agent, and validated by a two-pronged approach: (i) A bulk sample with artificial damage is exploited to evaluate the healing effect on large cracks open to the sample surface and to gauge its mechanical effectiveness, whereas (ii) a 3.5 µm-thick Al 2 O 3 -Al-Sn-Al thin film multilayer architecture was used as a model system to study the healing mechanisms of small-scale internal damage induced by bending of the brittle Al 2 O 3 layer. A crack length of ∼1.6 mm could be successfully re-filled by the low-melting eutectic with a simple annealing treatment at 400 °C for 30 min, which increased the bulk tensile ductility to more than 120 % compared to a similarly damaged pure Al sample. Furthermore, it is shown that the dispersion of the Sn-rich eutectic can be effectively controlled by utilising the polymorphy of Sn during material production. Alloy design perspectives for translating these findings towards industrial materials and applications are outlined and discussed.},
  archive      = {J_MATDES},
  author       = {L. Tanure and L. Patterer and S. Balakumar and M. Fekete and S. Mráz and S. Karimi Aghda and M. Hans and J.M. Schneider and H. Springer},
  doi          = {10.1016/j.matdes.2025.113821},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113821},
  shortjournal = {Mater. Des.},
  title        = {A novel concept for self-healing metallic structural materials: Internal soldering of damage using low melting eutectics},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the efficiency of luminescent solar concentrators
via soft colloidal lithography negative templating. <em>MATDES</em>,
<em>252</em>, 113817. (<a
href="https://doi.org/10.1016/j.matdes.2025.113817">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building-integrated photovoltaics (BIPV) offers a sustainable pathway by seamlessly incorporating PV cells into architectural elements like façades and windows. In this study, we investigate the potential of luminescent down-shifting solar concentrators in combination with a nanophotonic light-trapping scheme to improve the optical-guiding capabilities and thereby enhance the energy conversion efficiency. We propose a novel cost-effective method to fabricate the photonic structures via soft colloidal lithography negative templating of thin films of TiO 2 nanoparticles, successfully scaling the production to 11x11 cm 2 glass windows. Through simulations and optical-electrical characterization, we demonstrate substantial improvements in energy harvesting for different angles of solar irradiation. We found increases in power output ranging from 57% for angles of incidence below 45° to above 100% for 60° thanks to the nanostructured TiO 2 nanoparticles coatings added to a bottom down-shifting layer. This shows that such integrated approach can enhance both the efficiency and aesthetic appeal of solar solutions in urban environments, advancing the design of energy-efficient, sustainable buildings. Our methodology ensures consistent solar energy capture all year-round, for the relevant range of sunlight incidence angles, while preserving the transparency and multifunctionality of building elements.},
  archive      = {J_MATDES},
  author       = {J.G. Guerrero-Felix and S.F.H. Correia and M. Alexandre and C.D. Gonzalez-Gomez and V. Sencadas and L. Fu and E. Ruiz-Reina and P.S. André and C.L. Moraila-Martinez and M.J. Mendes and R.A.S. Ferreira and M.A. Fernandez-Rodriguez},
  doi          = {10.1016/j.matdes.2025.113817},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113817},
  shortjournal = {Mater. Des.},
  title        = {Enhancing the efficiency of luminescent solar concentrators via soft colloidal lithography negative templating},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergistic strengthening and toughening in β titanium alloy
via enhanced micron-sized primary α with the fiber-like β grains.
<em>MATDES</em>, <em>252</em>, 113816. (<a
href="https://doi.org/10.1016/j.matdes.2025.113816">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The trade-offs between strength and toughness and strength and ductility restrict the broader use of high-strength titanium alloys. To optimize the coordination of strength, ductility and toughness, a fiber-like structure in a metastable β titanium alloy was architected through a simple thermomechanical process and aging treatment. During the thermomechanical process, the microscale primary α phase (α p ) hindered the migration of β grain boundaries and coordinated the deformation, forming fiber-like β grains. The fiber-like β grains effectively hinder and deflect crack propagation in Charpy impact tests, significantly enhancing the impact toughness. Meanwhile, plenty of kink bands activated in the α p after the thermomechanical process, refining the α grains and resulting in high yield strength and ductility. The impact toughness of the fiber-structured titanium alloy rises from 28.3 ± 2.5 J/cm 2 to 47.3 ± 2.8 J/cm 2 when compared to the sample with a bimodal structure, while the yield strength and elongation remain at the same level. The design of Fiber-structured titanium alloys synergistically enhances the strength, ductility and toughness of the Ti-Al-Mo-V-Cr-Nb titanium alloy, providing a novel way to coordinate the strength, ductility and toughness of high-strength titanium alloy.},
  archive      = {J_MATDES},
  author       = {Leliang Liu and Qiaoyan Sun and Jixiong Liu and Xiaoxiang Wang and Jun Sun},
  doi          = {10.1016/j.matdes.2025.113816},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113816},
  shortjournal = {Mater. Des.},
  title        = {Synergistic strengthening and toughening in β titanium alloy via enhanced micron-sized primary α with the fiber-like β grains},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale as-sb-s chalcogenide glasses with ultrahigh
gradient refractive index. <em>MATDES</em>, <em>252</em>, 113815. (<a
href="https://doi.org/10.1016/j.matdes.2025.113815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient refractive index (GRIN) infrared lens provided additional degrees of freedom for correcting chromatic and spherical aberrations in optical design by combining an internally customized refractive index distribution with the surface curvature of optical elements. However, high-performance GRIN infrared lenses are still faced with multiple bottlenecks including complex processing processes, limited fabrication size, unsatisfying refractive index difference and inferior interface quality, which restrict their wide applications. In this study, a group of novel infrared lens with high plasticity and large refractive index difference were developed based on the As 40- x Sb x S 60 system. Planar and spherical infrared GRIN lenses were successfully fabricated using precision molding technology, with a maximum refractive index difference (Δ n ) of 0.33 at a wavelength of 2 μm. In addition, a maximum diffusion depth of 6000 μm between two pieces of glass was achieved using a high-temperature melt diffusion process. The successful preparation of large-scale Δ n GRIN optical lens with controllable size and shape provides a new solution for realizing high performance and lightweight infrared optical systems.},
  archive      = {J_MATDES},
  author       = {Peikuan Fan and Chengwei Gao and Gangjie Zhou and Linling Tan and Shiliang Kang and Jinjin Chen and Shixun Dai and Changgui Lin},
  doi          = {10.1016/j.matdes.2025.113815},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113815},
  shortjournal = {Mater. Des.},
  title        = {Large-scale as-sb-S chalcogenide glasses with ultrahigh gradient refractive index},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Injectable PRP-enriched photosensitive hydrogel: Enhanced
prevention and infection control in anastomotic leaks. <em>MATDES</em>,
<em>252</em>, 113813. (<a
href="https://doi.org/10.1016/j.matdes.2025.113813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The occurrence of anastomotic leakage (AL) could lead to leakage of digestive fluid, which erodes surrounding organs, subsequently causing severe intra-abdominal infections, hemorrhaging, and even death. Preventing AL was crucial for significantly enhancing patient quality of life. Thus, we developed an injectable photosensitive hydrogel enriched with platelet-rich plasma (PRP) aimed at preventing AL. This study utilized the Schiff-base crosslinking reaction between photosensitive methacryloyl-substituted gelatin (GM) and oxidized dextran (OD), incorporating PRP to create a multifunctional, tri-crosslinked hydrogel (GM/OD@PRP) that effectively promotes AL healing. This GM/OD@PRP exhibited excellent mechanical properties, biocompatibility, and self-healing capabilities. The hydrogel was loaded with PRP, which was rich in various growth factors that stimulate fibroblast proliferation and angiogenesis, thereby increasing cell proliferation, vascular regeneration, and formation and ultimately promoting healing at the anastomotic site. Furthermore, the superior antimicrobial properties of GM/OD@PRP provide a relatively sterile environment at the healing site, reducing the possibility of abdominal infections. In a rat model of AL, the GM/OD@PRP notably enhanced anastomotic healing prevented the occurrence of fistulae, and demonstrated significant advantages in reducing abdominal adhesions. This GM/OD@PRP holds substantial potential for use in preventing AL and represents a promising new composite material for improving patient quality of life.},
  archive      = {J_MATDES},
  author       = {Huijie Wang and Dongjie Zhang and Yiheng Ju and Yihui Cheng and Lei Liu and Houxi Li and Lianghong Lv and Jing Zhang and Yun Lu},
  doi          = {10.1016/j.matdes.2025.113813},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113813},
  shortjournal = {Mater. Des.},
  title        = {Injectable PRP-enriched photosensitive hydrogel: Enhanced prevention and infection control in anastomotic leaks},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “shear strength parameters for porous asphalt
mixtures: From macro to meso” [mater. Design 238 (2024) 112670].
<em>MATDES</em>, <em>252</em>, 113812. (<a
href="https://doi.org/10.1016/j.matdes.2025.113812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  author       = {Shu Liu and Rui Huang and Juan Wang and Jing Bie and Alvaro Garcia Hernandez},
  doi          = {10.1016/j.matdes.2025.113812},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113812},
  shortjournal = {Mater. Des.},
  title        = {Corrigendum to “Shear strength parameters for porous asphalt mixtures: From macro to meso” [Mater. design 238 (2024) 112670]},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Liquid metal-graphene composite conductive nanofiber
flexible pressure sensor for dynamic health monitoring. <em>MATDES</em>,
<em>252</em>, 113811. (<a
href="https://doi.org/10.1016/j.matdes.2025.113811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible pressure sensors nanofibers-based have garnered significant attention due to their applications in smart wearable devices, healthcare monitoring, human–computer interaction, and artificial intelligence. However, developing flexible pressure sensors with excellent conductivity and stability for stable monitoring of small pressures remains a considerable challenge. This study presents a highly sensitive and rapid-response flexible pressure sensor using liquid metal-graphene composite conductive nanofibers. The sensor employs electrospinning and electrostatic spraying techniques to prepare a liquid metal-polyimide matrix material, with polyvinyl alcohol modification significantly enhancing its adhesion. Notably, an ultrasonic impregnation method was utilized to uniformly disperse conductive fillers onto the surfaces of the nanofibers and within the three-dimensional skeletal structure, creating a dual-conductive network that enhances the sensor’s conductivity. The sensor exhibits high sensitivity (3.02 kPa −1 ), rapid response/recovery times (80 ms/200 ms), and a broad detection range (0–90 kPa), along with excellent mechanical stability and durability (5000 loading–unloading cycles). These advantages enable the flexible pressure sensor to detect various signals from minor body movements to larger motions, such as throat swallowing and finger bending. This research provides an effective method for continuous health monitoring and the identification of subtle physiological changes, showcasing its tremendous potential in the fields of smart robotics and prosthetics.},
  archive      = {J_MATDES},
  author       = {Manfeng Gong and Chenglong Tu and Xitong Lin and Fang Wang and Haishan Lian and Zaifu Cui and Xiaojun Chen},
  doi          = {10.1016/j.matdes.2025.113811},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113811},
  shortjournal = {Mater. Des.},
  title        = {Liquid metal-graphene composite conductive nanofiber flexible pressure sensor for dynamic health monitoring},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Insights on enhancing the adhesion of inkjet-printed
europium-doped yttrium oxide by tailoring interfacial bonding
environments. <em>MATDES</em>, <em>252</em>, 113810. (<a
href="https://doi.org/10.1016/j.matdes.2025.113810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inkjet printing of metal nitrate precursors and subsequent annealing offers a facile and scalable route toward tailoring metal oxides in well-defined patterns. In the following work, an ink formulation comprised of yttrium nitrate hexahydrate, europium nitrate hexahydrate, and urea was printed onto borosilicate glass and stainless steel 304 substrates to study the surface reaction and interface evolution after annealing in an air or N 2 environment. A QR code was fabricated with luminescent europium-doped yttrium oxide droplets to demonstrate the user-defined patterning capability of the inkjet printing technique, in which an invisible pattern to the naked eye was achieved for the oxide deposited on stainless steel. X-ray photoelectron spectroscopy reveals the reaction evolution from the yttrium nitrate precursor to yttrium oxide and yields insight into the potential role of cation diffusion and thermal expansion mismatch in governing the adhesion properties of the oxide layer.},
  archive      = {J_MATDES},
  author       = {Yujuan He and Jeffrey A. Dhas and Kijoon Lee and Milad Ghayoor and V. Vinay K. Doddapaneni and Anton T. Escher and Somayeh Pasebani and Brian K. Paul and Chih-hung Chang},
  doi          = {10.1016/j.matdes.2025.113810},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113810},
  shortjournal = {Mater. Des.},
  title        = {Insights on enhancing the adhesion of inkjet-printed europium-doped yttrium oxide by tailoring interfacial bonding environments},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D multi-site hydrogen evolution reaction catalysts on
nanoimprinted surfaces, structured via multi-photon lithography derived
masks. <em>MATDES</em>, <em>252</em>, 113809. (<a
href="https://doi.org/10.1016/j.matdes.2025.113809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient water splitting is a major challenge in green hydrogen production and energy transition. Thus, considerable scientific efforts are devoted to optimize surface geometries for enhancing the performance of water-splitting catalysts. The current study aims to develop a reliable and facile 3-step (re-)production technique for manufacturing structured surfaces by combining multi-photon lithography (MPL) and nanoimprint lithography (NIL). MPL enables structuring of high-definition micrometer-scale surface geometries. A variation of these topologies was used as masks for replication by NIL. Thus, molds were derived to emboss the original nanostructured topologies repeatedly into a UV-curable resin. Subsequently, a Ni thin film metallization was deposited by physical vapor deposition onto the final imprinted polymeric structures, thereby realizing topologically structured conductive electrodes. To demonstrate the applicability of this elaborated technique, the catalytic activities towards the hydrogen evolution reaction were assessed for different surface geometries. An increase in catalytic performance was achieved through surface enlargement by structuring, whereby a direct contribution of the specific structure geometry was not evident. This elegant method is highly versatile and scalable for producing a wide range of structured functional surfaces on a lab scale, as demonstrated for the water splitting reaction, with results transferable to an industrial scale.},
  archive      = {J_MATDES},
  author       = {Alexander Jelinek and Daniela Neumüller and Christoph Gammer and Jürgen Eckert and Daniel Kiener},
  doi          = {10.1016/j.matdes.2025.113809},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113809},
  shortjournal = {Mater. Des.},
  title        = {3D multi-site hydrogen evolution reaction catalysts on nanoimprinted surfaces, structured via multi-photon lithography derived masks},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “machine learning in additive
manufacturing——NiTi alloy’s transformation behavior” [mater. Des. 247
(2024) 113443]. <em>MATDES</em>, <em>252</em>, 113808. (<a
href="https://doi.org/10.1016/j.matdes.2025.113808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  author       = {Lidong Gu and Kongyuan Yang and Hongchang Ding and Zezhou Xu and Chunling Mao and Panpan Li and Zhenglei Yu and Yunting Guo and Luquan Ren},
  doi          = {10.1016/j.matdes.2025.113808},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113808},
  shortjournal = {Mater. Des.},
  title        = {Corrigendum to “Machine learning in additive manufacturing——NiTi alloy’s transformation behavior” [Mater. des. 247 (2024) 113443]},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new journey of fluorescent carbon dots: A shining star in
the realm of nucleic acid dyes. <em>MATDES</em>, <em>252</em>, 113806.
(<a href="https://doi.org/10.1016/j.matdes.2025.113806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nucleic acid dyes play important roles in the quantification and detection of nucleic acids by binding to nucleic acids. However, traditional nucleic acid dyes pose great environmental and economic challenges due to their high price, high toxicity, long dyeing time, low sensitivity and insufficient stability. To overcome these problems, we developed a new nucleic acid dye based on carbon dots, which were generated through hydrothermal synthesis with liquorice components as precursors and a system containing ethylenediamine. This new type of carbon dot can effectively replace traditional dyes and can be used to efficiently visualize DNA, RNA and plasmids via agarose gel electrophoresis. Then, we studied the interaction mechanism between carbon dots and nucleic acids by UV–visible spectroscopy, Fourier transform infrared spectroscopy and circular dichroism spectroscopy. The interaction between the carbon dots and nucleic acids mainly occurred through groove binding and was accompanied by a slight electrostatic interaction. Carbon dots-based nucleic acid dyes, with their low cost, simple synthesis process and high stability, have opened a new path for the field of nucleic acid detection. Its research and development not only promote the frontier progress of biological science and medicine but also introduces innovative strategies and tools for scientific research and clinical practice.},
  archive      = {J_MATDES},
  author       = {Yu Ma and Bin Zhao and Guozhen Yan and Ting Zhou and Zhihua Xu and Zhihan Niu and Zhenghong Xu and Tongtong Zhang and Feng Shi},
  doi          = {10.1016/j.matdes.2025.113806},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113806},
  shortjournal = {Mater. Des.},
  title        = {A new journey of fluorescent carbon dots: A shining star in the realm of nucleic acid dyes},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Negative to zero poisson’s ratio adjustable UV-PDMS flexible
metamaterials fabricated by using 3D photolithography. <em>MATDES</em>,
<em>252</em>, 113805. (<a
href="https://doi.org/10.1016/j.matdes.2025.113805">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical metamaterials (MMs) exhibit mechanical characteristics that are challenging to achieve using existing isotropic materials. Due to their unique characteristics, MMs hold significant potential for applications in diverse fields such as space, architecture, and robotics. This study proposes a method for processing and tuning the mechanical characteristics of MMs composed of UV-curable silicone rubber (UV-PDMS) submillimeter-sized thorough holes, specifically for integration into flexible microdevices. We focused on the microfabrication of polymeric materials with elastic limits and MMs regions, which have traditionally been difficult to achieve. Using 3D photolithography, UV-PDMS was successfully processed to incorporate submillimeter-sized through-holes. Furthermore, MMs with different linewidths were fabricated using from an identical mask pattern by only adjusting the UV incidence angle and exposure dose using 3D photolithography. The resulting flexible MMs exhibited tunable Poisson’s ratios within the range of −0.16 to −0.06.},
  archive      = {J_MATDES},
  author       = {Riku Ito and Yuji Takata and Yuya Tanaka and Hiroshi Toshiyoshi and Takaaki Suzuki},
  doi          = {10.1016/j.matdes.2025.113805},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113805},
  shortjournal = {Mater. Des.},
  title        = {Negative to zero poisson’s ratio adjustable UV-PDMS flexible metamaterials fabricated by using 3D photolithography},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Infrared spectroscopic characterization by atomic force
microscopy of two model nano-samples of low-density polyethylene
designed by laser ablation and ultraviolet/ultrasound. <em>MATDES</em>,
<em>252</em>, 113804. (<a
href="https://doi.org/10.1016/j.matdes.2025.113804">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model plastic samples mimicking the behavior of environmental nanoparticles (NPs) are necessary for understanding their biological effects. This is because the particle size and surface chemistry of plastic particles can be parameters for biotoxicity testing. Therefore, different types of particles need to be produced or designed. In this study, the chemical and physical properties of two model nano-samples of Low-Density Polyethylene (LDPE) were investigated; one designed by nanosecond laser ablation (LASER-LDPE.NPs), and the other designed by a combination of Ultraviolet (UV) irradiation and Ultrasound (US) exposure (UV/US-LDPE.NPs). AFM-IR, for detecting and imaging the response of a sample by scanning an AFM cantilever while irradiating an IR laser, was used to analyze the local chemical properties of these particles. New peaks specific to oxidation and degradation reactions were observed. In addition, the LASER-LDPE.NPs tend to have greater oxidation behavior with increasing methyl groups and a greater degradation with increasing carbonyl index than UV/US-LDPE.NPs. It was found that each NP production process produces NPs with unique chemical and physical properties. These designed model plastic particles mimic NPs in the environment and a study of their respective oxidation and degradation properties is expected to provide new insights into the assessment of biological effects. (200 words)},
  archive      = {J_MATDES},
  author       = {Ikuna Kanehara and Naoto Washihira and Tatsuhiro Nagasaka and Hirofumi Seki and Sho Fujii and Tsuyoshi Kimura and Masaya Yamamoto and Tadao Tanabe},
  doi          = {10.1016/j.matdes.2025.113804},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113804},
  shortjournal = {Mater. Des.},
  title        = {Infrared spectroscopic characterization by atomic force microscopy of two model nano-samples of low-density polyethylene designed by laser ablation and Ultraviolet/Ultrasound},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure, chemistry, and mechanical properties of
non-reactively sputtered ti-al-n. <em>MATDES</em>, <em>252</em>, 113803.
(<a href="https://doi.org/10.1016/j.matdes.2025.113803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the influence of substrate temperature, sputtering conditions (DC and pulsed DC), and Al content on chemical composition, structure, growth morphology, mechanical properties and thermal stability of non-reactively sputtered Ti-Al-N coatings. The substrate temperature and the pulse frequency have a minor impact on the coating properties, which are more strongly influenced by the chemical composition of the target (Ti 0.5 Al 0.5 N, Ti 0.33 Al 0.67 N, or Ti 0.2 Al 0.8 N) and the duty cycle during pulsed DC sputtering. The highest deposition rate of 109 ± 2 nm/min was obtained from a single-phase cubic rock-salt-structured coating and the highest hardness of 38.2 ± 2.5 GPa from a two-phase-structure coating (cubic rock salt and minor hexagonal wurtzite structure), both prepared from the Ti 0.5 Al 0.5 N target. The maximum Al content (Ti 1-x Al x N) for single-phase cubic rock-salt-structured coatings is x = 0.64, and the minimum Al content for single-phase hexagonal wurtzite-structured coatings is x = 0.81. The findings demonstrate that non-reactive sputtering is a viable method for preparing Ti-Al-N coatings. Furthermore, even without additional substrate heating, this approach achieves a high hardness of 33.6 ± 1.5 GPa and an impressive deposition rate of 102 ± 1 nm/min, offering a pathway to further enhance the sustainable production of these hard protective coatings.},
  archive      = {J_MATDES},
  author       = {Sarah Christine Bermanschläger and Balint Istvan Hajas and Tomasz Wojcik and Eleni Ntemou and Daniel Primetzhofer and Szilard Kolozsvari and Friedrich Bleicher and Paul Heinz Mayrhofer},
  doi          = {10.1016/j.matdes.2025.113803},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113803},
  shortjournal = {Mater. Des.},
  title        = {Structure, chemistry, and mechanical properties of non-reactively sputtered ti-al-N},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High power impulse magnetron sputtering plasma nitriding of
biomedical grade CoCrMo alloy. <em>MATDES</em>, <em>252</em>, 113802.
(<a href="https://doi.org/10.1016/j.matdes.2025.113802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical implants are requested to meet stringent requirements to ensure their safety and efficacy over extended periods within the human body. The use of surface modification techniques, such as nitriding, is essential in advancing the performance and lifetime of implant materials. The innovative use of High Power Impulse Magnetron Sputtering (HiPIMS) discharge for nitriding represents a significant advancement in surface treatment technologies for medical implants. In this work, a CoCrMo alloy underwent a low-pressure plasma nitriding process by using four different target materials to sustain the plasma: Ti, Cr, Mo and Ta. Among them, the molybdenum target leads to the best overall performance, since it achieves the formation of the desired γ N phase without secondary phases or surface particles and provides enhanced mechanical properties and chemical stability. The hardness achieved after the nitriding process is significantly higher than that of untreated CoCrMo, reaching up to 18 GPa. All nitrided samples exhibit a positive shift in corrosion potential values in Ringer’s solution, indicating improved corrosion resistance and demonstrate reduced wear rates and smoother wear scars compared to pristine samples, especially the Mo-treated one offers improved tribocorrosion behaviour, balancing wear and corrosion resistance effectively.},
  archive      = {J_MATDES},
  author       = {Valentina Zin and Francesco Montagner and Silvia Maria Deambrosis and Enrico Miorin and Nicola Comisso and Marzio Rancan and Enrico Paradisi and Cecilia Mortalò},
  doi          = {10.1016/j.matdes.2025.113802},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113802},
  shortjournal = {Mater. Des.},
  title        = {High power impulse magnetron sputtering plasma nitriding of biomedical grade CoCrMo alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spring-based mechanical metamaterials with
deep-learning-accelerated design. <em>MATDES</em>, <em>252</em>, 113800.
(<a href="https://doi.org/10.1016/j.matdes.2025.113800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanical metamaterials exhibit unique properties that depend on their microstructure and surpass those of their constituent materials. Flexible mechanical metamaterials, in particular, hold significant potential for applications requiring substantial deformations, such as soft robotics and energy absorption. In this study, we proposed a collection of flexible mechanical metamaterials discretely assembled using structural spring elements. These spring elements enhance both flexibility and reversibility, allowing the materials to withstand large deformations. The geometric regularity of the metamaterials enables zero-shot learning, allowing deep learning frameworks to address property prediction and inverse design problems beyond the training dataset. Using a property-prediction model, the effective mechanical properties of these metamaterials can be accurately predicted based on specified design parameters. Furthermore, an inverse-design model enables the direct generation of mechanical metamaterials with desired target properties, even outside the training dataspace, in the range of Young&#39;s modulus E ∈ (0, 350) kPa and Poisson&#39;s ratio ν ∈ (-0.12, 0.12). The properties of these inversely designed metamaterials are analyzed through finite element method simulations and mechanical testing. The deep learning-accelerated design approach not only streamlines the development process but also provides a framework for advancing metamaterial design, encompassing property prediction and inverse design.},
  archive      = {J_MATDES},
  author       = {Xiaofeng Guo and Xiaoyang Zheng and Jiaxin Zhou and Takayuki Yamada and Yong Yi and Ikumu Watanabe},
  doi          = {10.1016/j.matdes.2025.113800},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113800},
  shortjournal = {Mater. Des.},
  title        = {Spring-based mechanical metamaterials with deep-learning-accelerated design},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Designing laves-phase RFe2-type alloy with excellent
magnetostrictive performance by physics-informed interpretable machine
learning. <em>MATDES</em>, <em>252</em>, 113799. (<a
href="https://doi.org/10.1016/j.matdes.2025.113799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laves-phase RFe 2 -type (R = rare earth) magnetostrictive materials have tremendous application potential in smart devices. However, efficiently unearthing novel RFe 2 -type compounds with huge magnetostriction in experiments remains challenge due to the vast compositional space. Herein, we employ a physics-informed interpretable machine learning-based strategy to facilitate the design of targeted alloys. A home-built dataset is obtained through constructing composition-physical parameters-magnetostriction relationship. By comparing different models, the XGBoost (XGB) regression model is selected to predict magnetostriction of quaternary Tb x Dy 1- x Fe y V 2- y alloys. The results demonstrate that the optimal performance occurs in the composition range of 0.23–0.38 for Tb content and 0.01–0.08 for V content. The predicted properties are then verified by the measured results of a series of synthesized samples. Additionally, a model interpretability based on SHapley Additive exPlanations (SHAP) values manifests that volume magnetic susceptibility and bulk modulus exert the greatest impact on magnetostriction. This work offers a recipe to swiftly designing RFe 2 -type materials with giant magnetostriction.},
  archive      = {J_MATDES},
  author       = {Pengqiang Hu and Chao Zhou and Ruisheng Zhang and Sidan Ding and Yuanjun Guo and Bo Wang and Dezhen Xue and Yizhe Ma and Zhiyong Dai and Yin Zhang and Fanghua Tian and Sen Yang},
  doi          = {10.1016/j.matdes.2025.113799},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113799},
  shortjournal = {Mater. Des.},
  title        = {Designing laves-phase RFe2-type alloy with excellent magnetostrictive performance by physics-informed interpretable machine learning},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design of auxetic metamaterial for enhanced low cycle
fatigue life and negative poisson’s ratio through multi-objective
bayesian optimization. <em>MATDES</em>, <em>252</em>, 113798. (<a
href="https://doi.org/10.1016/j.matdes.2025.113798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Auxetic metamaterials (AM) with negative Poisson’s ratio (NPR) offer promising mechanical properties but often suffer from significant stress concentrations, compromising durability and fatigue life. Conventional design approaches, including topology optimization and empirical geometry-based methods, struggle with exploring complex design spaces, while data-driven techniques demand extensive datasets, making fatigue life prediction computationally expensive. To address these challenges, we propose a novel framework that integrates Bézier curve-based geometric parameterization, multi-objective Bayesian optimization (MBO), and fatigue life prediction via elastoplastic homogenization and critical distance theory. This approach systematically explores the design space, simultaneously enhancing NPR and optimizing fatigue resistance while alleviating localized stress concentrations. MBO efficiently balances exploration and exploitation with limited data, making it particularly suitable for computationally intensive fatigue analysis. Optimized AM structures exhibited an 85.11% increase in NPR and a 12.07% improvement in low-cycle fatigue (LCF) life compared to initial designs. Experimental validation confirmed up to 30 times the LCF life and a 2.5-fold NPR increase over conventional AM structures. These findings establish a scalable methodology for AM design, advancing the development of durable, high-performance metamaterials for biomedical, aerospace, and energy-harvesting applications.},
  archive      = {J_MATDES},
  author       = {Sukheon Kang and Hyeonbin Moon and Seonho Shin and Mahmoud Mousavi and Hyokyung Sung and Seunghwa Ryu},
  doi          = {10.1016/j.matdes.2025.113798},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113798},
  shortjournal = {Mater. Des.},
  title        = {Design of auxetic metamaterial for enhanced low cycle fatigue life and negative poisson’s ratio through multi-objective bayesian optimization},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Friction and wear study for the new method of laser-induced
cavitation micro-texturing on 7050 aluminum alloy. <em>MATDES</em>,
<em>252</em>, 113796. (<a
href="https://doi.org/10.1016/j.matdes.2025.113796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new surface-texturing technique—laser-induced cavitation micro-texturing (LICMT) was proposed to improve the friction and lubrication properties of 7050 aluminum alloy. Reciprocating friction tests were used to analyze the tribological properties at different micro-texturing densities and depths under starved lubrication conditions. SEM was used to observe the morphology of the wear surface. The average friction coefficient and wear rate were lowest for a micro-texturing density of 19.63 %. The average friction coefficient decreased with increasing micro-texturing depth. Compared with LST, no craters formed on the surface. Because of the lower abrasive and adhesive wear, the LICMT samples exhibited good friction reduction and lubrication performance. Finally, the mechanism of LICMT explained friction reduction and lubrication under starved lubrication conditions.},
  archive      = {J_MATDES},
  author       = {Rui Zhou and Weidong Shi and Yupeng Cao and Yongfei Yang and Kangwen Li},
  doi          = {10.1016/j.matdes.2025.113796},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113796},
  shortjournal = {Mater. Des.},
  title        = {Friction and wear study for the new method of laser-induced cavitation micro-texturing on 7050 aluminum alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of various UHMWPE formulations from contemporary
total knee replacements before and after accelerated aging.
<em>MATDES</em>, <em>252</em>, 113795. (<a
href="https://doi.org/10.1016/j.matdes.2025.113795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have collected 21 different formulations of ultrahigh molecular weight polyethylene (UHMWPE), which have been employed as liners in contemporary total knee replacements (TKR). The UHMWPE liners were bought from the most important manufacturers on the orthopedic market in the Czech Republic as of 2020. The collected liners represented a broad range of both traditional and modern UHMWPE formulations, which differed by the level of crosslinking, type of thermal treatment, sterilization and/or stabilization. All obtained UHMWPE’s were characterized by multiple methods immediately after purchase and after the accelerated aging in H 2 O 2 . The experimental results (oxidative degradation, structure changes, and micromechanical properties) were correlated with manufacturer’s data (crosslinking, thermal treatment, sterilization, and stabilization). The investigated UHMWPE liners exhibited significant differences in their properties, namely in their resistance to long term oxidative degradation. The stiffness-related mechanical properties showed a strong correlation with the overall crystallinity. The crystallinity depended mostly on the oxidative degradation of the UHMWPE liners, while the thermal treatment played a minor role. The highest resistance to oxidation and wear, which promises the best in vivo performance, was found for the crosslinked UHMWPE formulations with biocompatible stabilizers (such as α-tocopherol, which is the key component of vitamin E).},
  archive      = {J_MATDES},
  author       = {Petr Fulin and Veronika Gajdosova and Ivana Sloufova and Jiri Hodan and David Pokorny and Miroslav Slouf},
  doi          = {10.1016/j.matdes.2025.113795},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113795},
  shortjournal = {Mater. Des.},
  title        = {Comparison of various UHMWPE formulations from contemporary total knee replacements before and after accelerated aging},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Melting mode-driven processing diagram for
nanoparticle-enhanced high-strength aluminum alloy processed by laser
powder bed fusion. <em>MATDES</em>, <em>252</em>, 113794. (<a
href="https://doi.org/10.1016/j.matdes.2025.113794">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AA7075 + ZrH 2 (7A76) is a nanoparticle-enhanced high-strength Al alloy, designed to substantially prevent solidification cracking during laser powder bed fusion (LPBF). Significant knowledge gaps persist in understanding the effects of melting modes, the functionality of nanoparticles, and compositional variations in this material system. This study systematically investigates the melting modes in LPBF of 7A76 to achieve defect-free samples. Processing diagrams were generated using dimensionless heat input ( E* ) and velocity ( v* ) terms, alongside a physics-based temperature prediction model used to predict melting mode thresholds. A wide operation window was discovered within the transition melting mode region, resulting in defect-free 7A76, reaching a relative density of 99.98 %, reported for the first time. Furthermore, the transition melting mode was effective in lowering the Mg and Zn evaporation. Microstructural characterizations revealed that although melting and solidification during the LPBF process resulted in the dissolution of Zr into the printed alloy, some Zr-rich particles remained unmelted. This work represents the first observation of grain nucleation on the partially melted Zr-rich particles in this modified alloy. Additionally, this work sheds light on the successful printing of nanoparticle-enhanced, crack-prone aluminum alloys using processing diagrams, while elucidating the role of nanoparticles in this process.},
  archive      = {J_MATDES},
  author       = {Ali Rezaei and Mohsen K. Keshavarz and John Barnes and Mihaela Vlasea},
  doi          = {10.1016/j.matdes.2025.113794},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113794},
  shortjournal = {Mater. Des.},
  title        = {Melting mode-driven processing diagram for nanoparticle-enhanced high-strength aluminum alloy processed by laser powder bed fusion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced two-dimensional superelasticity in a laser
micromachined auxetic NiTiNOL geometry. <em>MATDES</em>, <em>252</em>,
113793. (<a href="https://doi.org/10.1016/j.matdes.2025.113793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The superelastic effect in nitinol allows it to accommodate and recover large amounts of deformation. Despite possessing this incredible ability, their use in applications remains limited due to the difficulty in machining into novel geometries. Laser-micromachining is an attractive solution to this problem, with the ability to micromachine geometries not conventionally possible. Such geometries, like auxetics, could be used to enhance the simultaneous two-dimensional accommodation and recovery of superelastic strain. We showcase an example of this enhancement in a laser-micromachined auxetic geometry that has minimal material removal. The recoverable strain in the auxetic geometry represents an enhancement of 86% increase over the bulk failure strain in the loading direction, and an absolute increase of 70% over the bulk failure strain in the transverse direction. Such geometries with enhanced two-dimensional functionality could serve as functional backbones on elastomeric composite testbeds with potential applications in soft robotics, stretch-triggered drug delivery, stretchable electronics, adaptive filters and controlled adhesion.},
  archive      = {J_MATDES},
  author       = {Asheesh Lanba and Tymur Sabirov and Adrien Melanson and Kevin Voter and Benjamin Hall},
  doi          = {10.1016/j.matdes.2025.113793},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113793},
  shortjournal = {Mater. Des.},
  title        = {Enhanced two-dimensional superelasticity in a laser micromachined auxetic NiTiNOL geometry},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electrospinning-based bone tissue scaffold construction:
Progress and trends. <em>MATDES</em>, <em>252</em>, 113792. (<a
href="https://doi.org/10.1016/j.matdes.2025.113792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrospinning is a key technique for producing nanofibers used in bone tissue engineering. Electrospinning methods, materials, and parameters affect bone scaffold properties and efficacy. However, there is currently a lack of systematic reviews, and the influence of electrospinning forms, scaffold types, and their parameters on scaffold performance remains unclear, making it difficult for researchers to obtain effective references. Therefore, this paper reviews the applications of electrospun scaffolds in bone tissue engineering. Firstly, it summarizes various electrospun scaffold fabrication methods and their principles, including conventional, blend, melt, coaxial, emulsion, solution, free surface, and improved techniques. Based on differences in scaffold structure, this paper further classifies scaffolds into multilayer, grid, and tubular types, analyzing the advantages and limitations of electrospinning processes and scaffold types, and discussing related scaffolds. Future research should focus on material, structural, and solvent optimization to improve scaffold performance. Secondly, this paper discusses the material characterization and applications of electrospun scaffolds in bone tissue engineering, emphasizing the need for performance optimization for improving bone repair. Finally, it proposes future research directions to address current challenges. This paper aims to provide systematic guidance and technical support for the application of electrospinning technology in bone tissue engineering.},
  archive      = {J_MATDES},
  author       = {Yunqi Ma and Ruiyu Zhou and Min Yang and Jun Zhang and Wei Song and Xiao Ma and Mingzheng Liu and Xin Cui and Benkai Li and Yanbin Zhang and Yunze Long and Zhigang Zhou and Changhe Li},
  doi          = {10.1016/j.matdes.2025.113792},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113792},
  shortjournal = {Mater. Des.},
  title        = {Electrospinning-based bone tissue scaffold construction: Progress and trends},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Developing a multi-scale framework to predict and evaluate
cohesion and adhesion of rejuvenated bitumen: Insights from molecular
dynamics simulations and experiments. <em>MATDES</em>, <em>252</em>,
113791. (<a href="https://doi.org/10.1016/j.matdes.2025.113791">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rejuvenators are crucial for efficient asphalt pavement recycling, but their effectiveness varies widely based on factors like bitumen source, aging degree, and rejuvenator composition. This study aims to develop a multiscale evaluation methodology to assess the cohesive and adhesive performance of rejuvenated bitumen, integrating molecular dynamics (MD) simulations and experimental testing. Molecular models of rejuvenated bitumen are established to predict nanoscale cohesion energy and the linear amplitude sweep (LAS) tests for fatigue evaluation. Bitumen-aggregate interface models undergo MD simulations for adhesion assessment, validated by pull-off tension tests, while microstructural observations clarify debonding mechanisms. Results show that bio-oil is the most effective rejuvenator for restoring aged bitumen’s cohesion, followed by engine-oil, naphthenic-oil, and aromatic-oil. LAS tests confirm these rankings for both bitumen and mastic, with Filler Wigro outperforming Wigro60K in reducing cohesive cracking risk. While aging decreases adhesion property, rejuvenators restore both cohesive and adhesive performance, with bio-oil achieving 44.4 % restoration of adhesion when adding 10 % by weight of bitumen. Additionally, MD simulations reveal that the work of adhesion (W aa ) negatively correlates with fatigue parameter (G*sinδ) and positively with fatigue life (N f ), and both Waa and the work of bonding adhesion (W BA ) decrease linearly with the pull-off tension strength (POTS) index. Bitumen TB is the most effective for improving cohesion crack resistance, whereas binder FB results in lower fatigue life. Overall, bio-oil proves most effective in restoring cohesion and adhesion across bitumen types and fillers, improving rejuvenated asphalt performance.},
  archive      = {J_MATDES},
  author       = {Shisong Ren and Marco Poot and Xueyan Liu and Sandra Erkens},
  doi          = {10.1016/j.matdes.2025.113791},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113791},
  shortjournal = {Mater. Des.},
  title        = {Developing a multi-scale framework to predict and evaluate cohesion and adhesion of rejuvenated bitumen: Insights from molecular dynamics simulations and experiments},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Electrical resistivity and self-sensing properties of
low-cement limestone calcined clay cement (LC3) mortar. <em>MATDES</em>,
<em>252</em>, 113790. (<a
href="https://doi.org/10.1016/j.matdes.2025.113790">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigated the mechanical, electrical, and piezoresistive performances of mortars made with Ordinary Portland cement (OPC) and limestone calcined clay cement (LC 3 ), especially when reinforced with 0.1 wt% recycled carbon fibre (rCF) by weight of the binder. The results found that 0.1 wt% rCF failed to considerably enhance the electrical conductivity of OPC and LC 3 mortars during the curing period, but the enhancement became apparent when these composites were 1 day-dried. With the increasing cement replacement ratio and the introduction of rCF, the mechanical properties deteriorated because of the dilutive effects together with the fragility of rCF. The OPC and LC 3 mortars exhibited a certain degree of piezoresistivity under compression, which was amplified with added 0.1 wt% rCF. Additionally, the piezoresistive performance of the LC 3 mortar was better than that of the OPC mortar, regardless of the presence of rCFs. The sensing capacity of composites is greatly weakened in terms of flexural stress. In terms of the two-probe method, because of the contact resistance, the resistivity usually decreases under compression, which results in larger fractional changes in resistivity values. This study aims to develop a low conductivity self-sensing cement-based composite (SSCC) filled with a small dosage of rCF.},
  archive      = {J_MATDES},
  author       = {Wenkui Dong and Ameer Hamza Ahmed and Marco Liebscher and Huanyu Li and Yipu Guo and Bo Pang and Mostafa Adresi and Wengui Li and Viktor Mechtcherine},
  doi          = {10.1016/j.matdes.2025.113790},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113790},
  shortjournal = {Mater. Des.},
  title        = {Electrical resistivity and self-sensing properties of low-cement limestone calcined clay cement (LC3) mortar},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced intragranular precipitation strengthening in
sc-microalloyed ultrafine-grained SiCp/al-cu-mg composites via
retrogression and re-ageing heat treatment. <em>MATDES</em>,
<em>252</em>, 113789. (<a
href="https://doi.org/10.1016/j.matdes.2025.113789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrafine-grained Al matrix composites suffer from the insufficient dislocation accumulation capability and intragranular precipitation strengthening due to their length-scale dependent precipitation behaviors. In this work, a combination of Sc-microalloying and a retrogression and re-ageing (RRA) route was applied on the SiC p /Al-Cu-Mg composites to achieve well-balanced strength and ductility. Compared to the T6 treatment, RRA heat treatment exhibit a significant strengthening effect in Sc-microalloyed composites with only a slight loss in ductility. The yield strength and ultimate strength of the Sc-RRA samples reach up to 686.4 MPa and 734.5 MPa, respectively. The plastic deformation mechanism was analyzed by thermal activation analysis and TEM observation of deformed microstructure. The plastic deformation of UFG composites, both with and without Sc, is primarily governed by a dislocation-grain boundary interaction mechanism. As confirmed by the observed stacking faults, the Sc-microalloyed composite subjected to T6 treatment suffers from poor dislocation storge capacity and insufficient intragranular precipitation strengthening. In contrast, the RRA treatment promotes the formation of intragranular Al 3 Sc precipitates and GP zones, which improve the dislocation accumulation capability and precipitation strengthening of ultrafine-grained composites by pinning dislocations. This work provides an accessible pathway to exploit aluminum matrix composites with advanced strength-ductility balance.},
  archive      = {J_MATDES},
  author       = {Yunpeng Cai and Kan Liu and Yiwei Dong and Andong Hua and Yishi Su and Qiubao Ouyang and Di Zhang},
  doi          = {10.1016/j.matdes.2025.113789},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113789},
  shortjournal = {Mater. Des.},
  title        = {Enhanced intragranular precipitation strengthening in sc-microalloyed ultrafine-grained SiCp/Al-cu-mg composites via retrogression and re-ageing heat treatment},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Driving martensitic transformation through pre-cold
deformation: Unveiling the mechanism of microstructural evolution in
martensite bearing steel. <em>MATDES</em>, <em>252</em>, 113788. (<a
href="https://doi.org/10.1016/j.matdes.2025.113788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bearing steel is used to produce bearing components through preforming processes, such as cold heading and cold rolling, prior to heat treatment. Cold rolling is a key developmental direction for manufacturing high-performance bearing. This research comprehensively examines how pre-cold deformation affects the microstructural evolution and mechanical characteristics of martensitic bearing steel. The findings suggest that pre-cold deformation reduces the original austenite grain size decreases by half, and the cementite particles become more uniformly distributed. Simultaneously, pre-cold deformation treatment considerably increases the bearing steel hardness from 715HV to 768HV whilst maintaining its toughness. The homogenisation of cementite size and the increase in hardness enhance the wear resistance of the samples by 34%. Furthermore, we explores the microstructural evolution mechanisms during subsequent phase transformations: the bearing steel in the process of martensitic transformation, the pre-cold deformation treatment leads to a strong variant selection, which increases the intrinsic nucleation rate and reduces the autocatalytic nucleation rate of martensite. The change of nucleation positions causes the great differences in the crystallography of the samples. The martensite twins transforming into twinned variants that adhere to the Kurdjumov-Sachs orientation relationship. In this study, we have established a relationship linking crystallography, phase transitions, and mechanical properties.},
  archive      = {J_MATDES},
  author       = {Decheng Jia and Chunsheng Zhang and Runzhou Dong and Haida Zhang and Xinliang Gao and Xiaoyong Feng and Zhinan Yang and Fucheng Zhang},
  doi          = {10.1016/j.matdes.2025.113788},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113788},
  shortjournal = {Mater. Des.},
  title        = {Driving martensitic transformation through pre-cold deformation: Unveiling the mechanism of microstructural evolution in martensite bearing steel},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inhomogeneous α-al/Mg2Si two-phase microstructures with
chemical fluctuation produced by laser-beam powder bed fusion.
<em>MATDES</em>, <em>252</em>, 113787. (<a
href="https://doi.org/10.1016/j.matdes.2025.113787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigated the additive manufacturing of high-strength Al–Mg–Si ternary alloy with refined α-Al/Mg 2 Si two-phase microstructures by laser-beam powder bed fusion (PBF-LB). Although PBF-LB processing produced crack-free samples with high relative densities (&gt;99.5 %), the scanning laser irradiation caused significant Mg vaporization, reducing the Mg content of the sample from 11.3 to 7.6 %. Laser-induced vaporization caused micron-scale chemical fluctuations in the melt-pool structure, resulting in the development of inhomogeneous microstructures. Refined cellular microstructures with many columnar α-Al phases surrounded by numerous Mg 2 Si nano-particles were observed in most parts of the melt-pool structure, corresponding to hypo-eutectic compositions in the Al–Mg–Si ternary system. However, primary solidified Mg 2 Si phases were observed in some parts of the melt-pool boundaries with local Mg-rich compositions (hyper-eutectic compositions). The PBF-LB manufactured alloy specimens with a total composition of Al–7.6Mg–5.4Si (wt%) exhibited a high tensile strength, which reduced significantly with increasing testing temperature, and low ductility (529 MPa and &lt; 2 %, respectively) at room temperature. Moreover, the specimens underwent mechanical deterioration at elevated temperatures, owing to a significant coarsening of metastable microstructural factors (nanoscale Mg 2 Si precipitates or their related metastable phases and atomistic clusters) that contribute towards the high room-temperature strength.},
  archive      = {J_MATDES},
  author       = {Yuki Otani and Naoki Takata and Asuka Suzuki and Makoto Kobashi and Junji Umeda},
  doi          = {10.1016/j.matdes.2025.113787},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113787},
  shortjournal = {Mater. Des.},
  title        = {Inhomogeneous α-Al/Mg2Si two-phase microstructures with chemical fluctuation produced by laser-beam powder bed fusion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evading strength-ductility trade-off in a metastability
engineered layered metallic composite. <em>MATDES</em>, <em>252</em>,
113786. (<a href="https://doi.org/10.1016/j.matdes.2025.113786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This investigation demonstrates a unique layered metallic composite (LMC) design strategy which exploits the metastability tunability of the transformative complex concentrate alloys (CCAs). Metastability engineered LMC (ME-LMC) was prepared by sandwiching a relatively less metastable Fe 38.5 Mn 20 Co 20 Cr 15 Si 5 Cu 1.5 CCA (SFE = 12 mJ/m 2 ) between the two layers of the highly metastable Fe 40 Mn 20 Co 20 Cr 15 Si 5 CCA (SFE = 6 mJ/m 2 ). In ME-LMC, plastic instability of highly metastable alloy got delayed resulting in slight increase in the ultimate tensile strength (UTS) while maintaining comparable ductility compared to the monolithic CCAs. Superior properties of the ME-LMC are attributed to the enhanced activation of transformation and twin systems in the HCP phase due to the generation of biaxial state of stresses originating from the CCA interface affected zones. Enhanced transformation and twinning led to the greater dynamic refinement of the microstructure providing higher strain hardening enabling greater ductility while benefitting from the dynamic Hall-Petch strengthening. A dislocation density evolution based modelling framework is developed to elucidate the enhancement in mechanical properties.},
  archive      = {J_MATDES},
  author       = {Roopam Jain and Ravi Sankar Haridas and Prithvi Awasthi and Abhijeet Dhal and Rajiv S. Mishra},
  doi          = {10.1016/j.matdes.2025.113786},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113786},
  shortjournal = {Mater. Des.},
  title        = {Evading strength-ductility trade-off in a metastability engineered layered metallic composite},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modeling plastic deformation of TWIP steel using cohesive
zone and crystal plasticity finite element. <em>MATDES</em>,
<em>252</em>, 113785. (<a
href="https://doi.org/10.1016/j.matdes.2025.113785">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research, the cohesive zone model-crystal plasticity finite element (CZM-CPFE) method was applied to reveal the influence mechanism of grain boundaries (GBs) and grains on the mechanical properties of fine/ultrafine grained TWIP steels. The reliability and efficiency of this method were verified via corroborating with in-situ SEM tensile tests and EBSD/TEM characterisation. When the average grain size was refined from 8.49 to 0.70 μm, the yield stress increased from 181 to 317 MPa and the ultimate tensile strength from 868 to 1004 MPa with little loss of UE, which was successfully predicted by the CZM-CPFE method. Also, the neighbouring grain model revealed that stress concentrations are pronounced near GBs with high misorientation angle due to the dislocation motion and twin growth hindered by GBs. Furthermore, the simulation and experimental results indicated that the critical resolved shear stress (CRSS) for twinning increased to 202 MPa for average grain size reduction to 0.70 μm, which was much higher than the 138.5 MPa for slip, making twin activation more difficult. The application of this work in steels with moderate grain sizes can facilitate understanding of the evolution of the slip and twins and the strain hardening.},
  archive      = {J_MATDES},
  author       = {Wang Cai and Chaoyang Sun and Hongjia Zhang and Lingyun Qian and Linghui Meng and M.W. Fu},
  doi          = {10.1016/j.matdes.2025.113785},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113785},
  shortjournal = {Mater. Des.},
  title        = {Modeling plastic deformation of TWIP steel using cohesive zone and crystal plasticity finite element},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Free volume and nonlinear viscoelasticity in
supercrystalline nanocomposites: A nanoindentation driven modelling
analysis. <em>MATDES</em>, <em>252</em>, 113784. (<a
href="https://doi.org/10.1016/j.matdes.2025.113784">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supercrystalline nanocomposites (SCNCs) are a new class of hybrid materials consisting of organically functionalized nanoparticles that are arranged into periodic architectures, featuring multi-functional properties. While their mechanical behavior is starting to be assessed, the time-dependent aspects thereof, and especially creep, remain unexplored. This lack of understanding is an obstacle towards future implementation of SCNCs into devices. It is therefore imperative not only to capture experimentally the creep behavior of SCNCs, but also to develop models that accurately predict its evolution. Here, a model is proposed to capture the nanoindentation creep behavior of SCNCs, using both rheological models and free volume theory. The creep compliance derived from the rheological model shows a stress-dependent trend, indicating nonlinear viscoelasticity. The presence of free volume is experimentally detected in SCNCs via positron annihilation lifetime spectroscopy. It decreases in size with increasing degrees of crosslinking of the organic phase, a phenomenon attributed to the shrinkage of superlattices. The creep compliance is predicted by introducing a shift factor to account for the evolution of the relaxation time caused by the change in free volume. A free volume-based creep model is proposed to predict the creep behavior of SCNCs, and its applicability is validated through new nanoindentation creep tests at varying loads.},
  archive      = {J_MATDES},
  author       = {Cong Yan and Eric Hirschmann and Marc G.D. Geers and Diletta Giuntini},
  doi          = {10.1016/j.matdes.2025.113784},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113784},
  shortjournal = {Mater. Des.},
  title        = {Free volume and nonlinear viscoelasticity in supercrystalline nanocomposites: A nanoindentation driven modelling analysis},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Additive manufacturing of multi-material parts – effect of
heat treatment on thermal, electrical, and mechanical part properties of
316L/CuCrZr. <em>MATDES</em>, <em>252</em>, 113783. (<a
href="https://doi.org/10.1016/j.matdes.2025.113783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in multi-material powder bed fusion of metals using a laser beam (PBF-LB/M) facilitate manufacturing 3D parts with an arbitrary voxel-wise material distribution, using 316L and CuCrZr alloy in a single-step process. This combination leverages each material&#39;s distinct advantages for applications requiring high strength, corrosion resistance, and superior thermal and electrical conductivity. However, inherent anisotropy at the interface between these materials poses significant challenges, impacting the integrity of material interfaces and affecting the materials&#39; properties. This research investigates the influence of three different build orientations (CuCrZr on 316L, 316L on CuCrZr, and CuCrZr next to 316L) on interface quality and part performance. Techniques like microscopy imaging, laser flash analysis, and eddy current measurements, alongside Vickers hardness tests, were employed. Aging at 500 °C for 1.5 hours increased CuCrZr&#39;s conductivity by 250% and doubled its hardness. Samples with 316L built on CuCrZr showed reduced thermal contact resistance, suggesting this configuration is preferable for efficient heat transfer. Moreover, 316L contamination reduced the microhardness of CuCrZr, impacting its precipitation hardening potential. These findings underscore the importance of strategic material selection and arrangement within the PBF-LB/M process and highlight the benefits and challenges of heat treatment and contamination.},
  archive      = {J_MATDES},
  author       = {Ina Meyer and Cameron Owen Messmann and Tobias Ehlers and Roland Lachmayer},
  doi          = {10.1016/j.matdes.2025.113783},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113783},
  shortjournal = {Mater. Des.},
  title        = {Additive manufacturing of multi-material parts – effect of heat treatment on thermal, electrical, and mechanical part properties of 316L/CuCrZr},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving superior mechanical properties by regulating
nano-phases in cast al-li alloys: Experimental and simulation.
<em>MATDES</em>, <em>252</em>, 113782. (<a
href="https://doi.org/10.1016/j.matdes.2025.113782">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the outstanding advantages such as low density, high modulus, and high damage tolerance, cast Al-Li alloys are highly promising metallic materials for load-bearing applications in the coming decades. However, compared to their wrought counterparts, the mechanical properties of these alloys, particularly the ductility, are still unsatisfactory, which severely limits their further applications. Here, we report that the mechanical properties of cast Al-Li alloys can be significantly improved by regulating various nano-phases during aging. Results show that the introduction of 0.2 wt% Zr in the Al-2Li-2Cu-0.5 Mg alloy contributes to grain refinement by providing a large number of primary Al 3 Zr particles acting as ideal heterogeneous nucleation sites for the α-Al matrix. During subsequent aging, Al 3 Li tends to nucleate and grow on the Al 3 Zr surface to reduce the interfacial energy and form a nano-complex with a core–shell structure in 0.2Zr alloy. Then, the Al 3 Li shell can serve as an effective nucleation site for the T 1 and θʹ phases. Density functional theory (DFT) calculations indicate that nucleation of T 1 and θʹ on the Al 3 Li shell reduces the interfacial energy, which promotes their uniform precipitation. In this case, unique Al 3 (Zr, Li) particles and higher density of finer T 1 and θʹ phases provide a substantial Orowan strengthening effect, alleviating the stress concentration. In addition, grain refinement improves the coordination of plastic deformation in 0.2Zr alloys. As a result, the ductility of 0.2Zr alloy increases from 3.6 % to 7.1 % compared to the Base alloy, accompanied by a 66 MPa increase in ultimate tensile strength. This work is expected to offer a new engineering approach to designing high-performance cast Al-Li alloy components with broad application prospects.},
  archive      = {J_MATDES},
  author       = {Wengang Bu and Pengfei He and Jiamao Hao and Rong Wang and Zhenfeng Hu and Jinyong Mo and Xiubing Liang},
  doi          = {10.1016/j.matdes.2025.113782},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113782},
  shortjournal = {Mater. Des.},
  title        = {Achieving superior mechanical properties by regulating nano-phases in cast al-li alloys: Experimental and simulation},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Longitudinal wave propagation behavior and dimension effect
of origami-inspired metamaterials prepared by laser powder bed fusion.
<em>MATDES</em>, <em>252</em>, 113781. (<a
href="https://doi.org/10.1016/j.matdes.2025.113781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Origami principles have garnered significant attention in science and engineering due to their unique deformation behaviors and resultant mechanical properties. This study introduces an innovative elastic metamaterial inspired by Miura-origami tubes, fabricated using laser powder bed fusion (LPBF), a prevalent additive manufacturing technique. The metamaterial’s unit cell consists of a diamond-shaped frame and a pair of orthogonal springs, displaying quasi-zero stiffness through the interaction of lateral and longitudinal springs, which balances internal pressure and tension. The transmission and dispersion of longitudinal waves in these metamaterials, with varying structural parameters, were systematically investigated. The findings demonstrate that the Miura-origami inspired metamaterial can generate ultra-wide band gaps for low-frequency longitudinal waves (500 Hz to 2500 Hz). It effectively converts longitudinal waves into other energy forms via internal vibration mode transformations. Structural parameters critically impact the metamaterial’s mechanical performance and manufacturing quality. Optimal parameters for LPBF fabrication were identified through rigorous experiments and simulations. These origami-inspired elastic metamaterials show substantial promise for vibration mitigation in civil, medical, mechanical, and aerospace engineering applications.},
  archive      = {J_MATDES},
  author       = {Ke Chen and Haoran Wan and Hongyu Chen and Xiang Fang and Tiwen Lu and Yonggang Wang and Yang Liu and Konrad Kosiba},
  doi          = {10.1016/j.matdes.2025.113781},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113781},
  shortjournal = {Mater. Des.},
  title        = {Longitudinal wave propagation behavior and dimension effect of origami-inspired metamaterials prepared by laser powder bed fusion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Current-assisted low-temperature silver sinter bonding to
silicon carbide by utilizing ion migration. <em>MATDES</em>,
<em>252</em>, 113780. (<a
href="https://doi.org/10.1016/j.matdes.2025.113780">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sinter bonding using fine metal particles has attracted significant attention as a promising technology for next-generation power devices. However, achieving high-strength joints between semiconductor materials and metal substrates remains challenging due to the low interfacial bonding ratios, leading to interfacial fractures that weaken the joint. Herein, we demonstrate a current-assisted low-temperature Ag sinter bonding process for SiC, utilizing ion migration within the bonding layer. The process significantly improved the joint strength by enhancing the interfacial bonding properties via Ag precipitation on the SiC surface. The precipitation, facilitated by the current-driven migration of Ag ions derived from the decomposition of compounds, effectively increased the density and interfacial bonding ratio of the sintered Ag layer, thereby mitigating interfacial fracture. Based on these findings, we successfully achieved current-assisted sinter bonding, notably at room temperature. Furthermore, the current-driven migration of the generated Ag ions was sufficiently induced even with a minimal amount of Ag compounds. Accordingly, the joint properties were further enhanced by suppressing localized vulnerability in the sintered Ag layer through the optimization of the Ag 2 O mixture ratio in the bonding paste. This current-assisted process plays a crucial role in achieving reliable low-temperature sinter bonding, essential for advanced electronics packaging.},
  archive      = {J_MATDES},
  author       = {Tetsuhiro Matsuda and Tomoki Matsuda and Makoto Kambara and Akio Hirose},
  doi          = {10.1016/j.matdes.2025.113780},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113780},
  shortjournal = {Mater. Des.},
  title        = {Current-assisted low-temperature silver sinter bonding to silicon carbide by utilizing ion migration},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Programmable helix-tubular composites with bio-inspired
architecture. <em>MATDES</em>, <em>252</em>, 113779. (<a
href="https://doi.org/10.1016/j.matdes.2025.113779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The programmable materials have attracted attention for its groundbreaking functionalities across diverse applications, especially the curl-fiber reinforced composites inspired from collagen fibers. In this work, a novel helix-tubular composite (HTC) is developed through an integrated braiding-knitting fabrication approach. Experimental analyses demonstrate that the mechanical properties of HTC can be directionally optimized through parameterization of secondary conformational architecture and coupling states. Remarkably, HTC manifests triphasic nonlinear mechanical behavior analogous to native ligamentous tissues. This biomimetic response originates from synergistic interactions between the stiff helix conformation (the stiff conformation) and highly stretchable tubular conformation (the stretchable conformation). Furthermore, cyclic tensile evaluations reveal exceptional fatigue resistance exceeding thousands of cycles. This durability substantiates the composite’s potential for replicating the multifunctional mechanical behavior of biological tendons and ligaments. These findings establish a methodological framework for engineering advanced materials with spatially programmable mechanical properties through conformational coupling.},
  archive      = {J_MATDES},
  author       = {Tong Yang and Zhijia Dong and Chaoyu Chen and Jun Song and Pibo Ma},
  doi          = {10.1016/j.matdes.2025.113779},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113779},
  shortjournal = {Mater. Des.},
  title        = {Programmable helix-tubular composites with bio-inspired architecture},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable phononic metamaterials: Tunable bandgap design and
multi-scale experimental validation. <em>MATDES</em>, <em>252</em>,
113778. (<a href="https://doi.org/10.1016/j.matdes.2025.113778">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phononic metamaterials offer unprecedented control over wave propagation, making them essential for applications such as vibration isolation, waveguiding, and acoustic filtering. However, achieving scalable and precisely tunable bandgap properties across different length scales remains challenging. This study presents a user-friendly design framework for phononic metamaterials, enabling ultra-wide bandgap tunability ( B/ ω c ratios up to 172 %) across multiple frequency ranges and scales. Using finite element simulations of a Yablonovite-inspired unit cell, we establish a comprehensive parametric design space that illustrates how geometric parameters, such as sphere size and beam diameter, controls bandgap width and frequency. The scalability and robustness of the framework are validated through experimental testing on additively manufactured structures at both macro (10 mm) and micro (80 µm) scales, fabricated using Stereolithography and Two-Photon Polymerization. Transmission loss measurements, conducted with piezoelectric transducers and laser vibrometry, closely match simulations in the kHz and MHz frequency ranges, confirming the reliability and consistency of the bandgap behavior across scales. This work bridges theory and experiments at multiple scales, offering a practical methodology for the rapid design of phononic metamaterials and expanding their potential for diverse applications across a broad range of frequencies.},
  archive      = {J_MATDES},
  author       = {Timon Meier and Vasileios Korakis and Brian W. Blankenship and Haotian Lu and Eudokia Kyriakou and Savvas Papamakarios and Zacharias Vangelatos and M. Erden Yildizdag and Gordon Zyla and Xiaoxing Xia and Xiaoyu Zheng and Yoonsoo Rho and Maria Farsari and Costas P. Grigoropoulos},
  doi          = {10.1016/j.matdes.2025.113778},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113778},
  shortjournal = {Mater. Des.},
  title        = {Scalable phononic metamaterials: Tunable bandgap design and multi-scale experimental validation},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties of CoCrFeMnNi high entropy alloy
lattice structures formed by selective laser melting. <em>MATDES</em>,
<em>252</em>, 113777. (<a
href="https://doi.org/10.1016/j.matdes.2025.113777">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The special structure of the lattice structure makes it have many excellent properties. CoCrFeMnNi high-entropy alloys (HEAs) is widely used due to its good plasticity, low temperature strength and other advantages. To enhance the mechanical properties of the lattice structure, a unique decahedral internal diamond (DID) unit cell type was designed to construct the periodic lattice structure. The DID lattice structure was prepared by SLM using CoCrFeMnNi HEAs spherical powder as the material, and its surface morphology was observed under SEM. In comparison to conventional lattice structures, various lattice structures’ mechanical properties and deformation behaviors were analyzed using quasi-static compression tests and finite element analysis. Additionally, the effects of different rod diameter on the compressive performance and energy absorption characteristics of the DID lattice structure were also studied. The results show that the lattice structure prepared by SLM has good forming quality. In the tested samples, the DID structure has better bearing capacity and energy absorption performance, and the yield strength of the DID lattice structure with an overall size of 15 mm × 15 mm × 15 mm and a relative density of 25 % is 66 MPa, and the Young’s modulus is 3798 MPa. In addition, increasing the rod diameter can reduce the forming defects of the crossbar and further improve the compressive performance and energy absorption characteristics of the DID structure. This study provides a theoretical reference for the design and fabrication of load-absorber integrated structures, and confirms that the CoCrFeMnNi HEAs DID lattice structure can be used for lightweight support manufacturing applications.},
  archive      = {J_MATDES},
  author       = {Yangwei Du and Ketai He and Rong Guo and Zhipeng Zhou and Guoxuan Ming and Qi Liu and Hao Dong},
  doi          = {10.1016/j.matdes.2025.113777},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113777},
  shortjournal = {Mater. Des.},
  title        = {Mechanical properties of CoCrFeMnNi high entropy alloy lattice structures formed by selective laser melting},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards understanding the machining effect on the additively
manufactured stainless steel for various scanning directions: Texture
evolution and mechanical properties. <em>MATDES</em>, <em>252</em>,
113776. (<a href="https://doi.org/10.1016/j.matdes.2025.113776">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive manufacturing (AM) technology hybridized with subtractive manufacturing has been extensively applied as a solution for the fabrication of functional parts. However, the complicated morphologies and anisotropic properties of the resultant grain features lead to challenges in the metallurgical and mechanical analysis of the cutting process of AM-materials, affecting the understanding on mechanical strength alteration of the final surface. In this study, a crystallographic-texture-based analysis method is proposed to elucidate the cutting-induced microstructural alteration from the grain to the texture level, enabling a comprehensive understanding of the collective effect of the hybrid cutting process on the resultant surface. Orthogonal cutting on additively manufactured 17–4 PH stainless steel applying three scanning directions was conducted to produce cut surfaces. In-depth electron backscatter diffraction inspection was applied for quantitative texture analysis based on the calculation of the orientation distribution function and volume fractions of significant texture components. As a result, the textures of the machined surfaces showed an increased intensity of normal direction fiber component to that of building direction with respect to 0° and 90° owing to cutting-induced deformation. This work advances the understanding on the roles of textural evolution for achieving a better surface quality regulation via function-oriented hybrid manufacturing process.},
  archive      = {J_MATDES},
  author       = {Chao Wang and Zhenglong Fang and Toru Kizaki and Naohiko Sugita},
  doi          = {10.1016/j.matdes.2025.113776},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113776},
  shortjournal = {Mater. Des.},
  title        = {Towards understanding the machining effect on the additively manufactured stainless steel for various scanning directions: Texture evolution and mechanical properties},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tuning anionic components to control the phase stability and
mechanical properties of high-entropy carbonitrides. <em>MATDES</em>,
<em>252</em>, 113775. (<a
href="https://doi.org/10.1016/j.matdes.2025.113775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence of nitrogen on the synthesis and mechanical properties of high-entropy carbonitride are evaluated in (Ti, Zr, Nb, Mo, Ta)C x N 1-x solid solution (denoted as HECN) through experimental method, thermodynamic calculations and ab-intio modeling. HECN powders with varying nitrogen content are fabricated using an open dynamic carbothermal reduction nitriding method. Both the calculation and experiment results indicate that the higher nitrogen content alters the bonding behavior and charge distribution difference of HECN due to the highly distorted crystal lattice. Leading the increase of formation energy between the HECN and sub-system configurations, resulting in decreased phase stability. Due to the correlation between electronic structure and mechanical properties calculated by Density functional theory and integrated density of states, HEC 0.9 N 0.1 exhibits the highest mechanical properties, with a hardness of 20.1 ± 0.1 GPa at 49N and an indentation fracture resistance ( K IC ) of 5.54 ± 0.16 MPa∙m 1/2 . The weak bonding characteristic between Mo and N atoms contributes to the reduced phase stability and the random atomic occupation. This work reveals the nitridation characteristics critical for the design and preparation of high entropy systems and elucidates the correlation between nitrogen content and intrinsic properties, providing a feasible strategy for guiding the design and synthesis of HECN ceramics.},
  archive      = {J_MATDES},
  author       = {Yifan Li and Zhiyao Ouyang and Yongye Ding and Ying Liu and Na Jin and Jinwen Ye},
  doi          = {10.1016/j.matdes.2025.113775},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113775},
  shortjournal = {Mater. Des.},
  title        = {Tuning anionic components to control the phase stability and mechanical properties of high-entropy carbonitrides},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High efficient near-infrared sintering for
electrohydrodynamic printed frequency selective surface.
<em>MATDES</em>, <em>252</em>, 113774. (<a
href="https://doi.org/10.1016/j.matdes.2025.113774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficient and compatible nano-silver paste sintering technology is significant for printed electronics. However, the current sintering technology still has limitations in terms of sintering time, post-sintering resistivity, and applicable types of substrates. Here we propose a highly efficient near-infrared sintering method for electrohydrodynamic (EHD) printed nano-silver paste. This method is suitable for sintering of nano-silver ink for large curved circuits manufacturing, achieving excellent film conductivity along with enhancing its interfacial strength. This article focuses on exploring the effects of process parameters such as near-infrared sintering power, time and lap-substrate distance on efficiency and resistivity, and ultimately achieving a rapid sintering of nano-silver paste with a resistivity of 12.8 × 10 − 8 Ω ⋅ m . This method adopted near-infrared sintering to sinter nano-silver ink circuits created by EHD printing, followed by plasma treatment to enhance the interfacial strength up to 5B level. Finally, we have successfully fabricated both planar and curved frequency selective surface (FSS) by the above-mentioned methods. The planar FSS sample presented a shielding capability of 2̃5 dB at resonant frequencies of 6 GHz and 10 GHz, which is quite accordance to the simulation results. This method shows great potential for application in large-scale, high-efficiency printed electronics fabrication.},
  archive      = {J_MATDES},
  author       = {Long Bai and Ziru Wang and Dong Ye and Hanghang Wei and Zihan Peng and Jiaying Ge and Siwei Tan and Tianxiang Li and Hao Wu},
  doi          = {10.1016/j.matdes.2025.113774},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113774},
  shortjournal = {Mater. Des.},
  title        = {High efficient near-infrared sintering for electrohydrodynamic printed frequency selective surface},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Size-controlled synthesis of ultrafine silver powders for
electronic paste using a one-pot aqueous method. <em>MATDES</em>,
<em>252</em>, 113773. (<a
href="https://doi.org/10.1016/j.matdes.2025.113773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Silver nanoparticles possess unique electrical, thermal, and catalytic properties, making them valuable in various fields such as flexible electronics printing, electronic device interconnections, and solar energy applications. Controlling the size of silver nanoparticles is critical to its properties and determining the application. This study investigates the influence of reaction rates on the size of silver nanoparticles synthesized in aqueous solutions. The precursor of silver ammonia concentrations from 5 to 160 mM was explored, revealing a positive correlation between reactant concentration and particle size that challenges traditional theories. It results from aggregation growth facilitated by high concentrations, leading to significant increases of particle size, with a trigger of 10 mM. Furthermore, when fix the precursor concentration, the instantaneous and homogeneous concentrations of the reducing agent have completely opposite effects. Specifically, decreasing the instantaneous concentration while increasing the homogeneous concentration compress the reaction zone and refined particle size distributions. It successfully shrank the particle size from 510 to 140 nm for the condition of 20 mM precursor concentration. Additionally, lower temperatures bring a anisotropic self-assemble, while higher temperatures result in a random growth. At last, the size of silver particles exhibits distinct effects on the printing performance and conductivity of silver paste.},
  archive      = {J_MATDES},
  author       = {Zhe Huang and Jin Yang and Baishan Chen and Minggang Li and Siwei Tang and Yunzhu Ma and Wensheng Liu},
  doi          = {10.1016/j.matdes.2025.113773},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113773},
  shortjournal = {Mater. Des.},
  title        = {Size-controlled synthesis of ultrafine silver powders for electronic paste using a one-pot aqueous method},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active learning-based alloy design strategy for improving
the strength-ductility balance of al-mg-zn alloys. <em>MATDES</em>,
<em>252</em>, 113772. (<a
href="https://doi.org/10.1016/j.matdes.2025.113772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Al-Mg-Zn alloys, designed to combine the formability of 5xxx alloys with the high strength of 7xxx alloys, still face challenges in achieving an optimal strength-ductility balance. This study presents an active learning-based alloy design strategy to guide experiments aimed at enhancing the strength-ductility balance in Al-Mg-Zn alloys. Firstly, a sub-dataset comprising ultimate tensile strength (UTS) and elongation (EL) data with optimal generalization ability was identified from the small and disordered Al-Mg-Zn dataset using the bagging method. Subsequently, the bagging model of this sub-dataset was employed to construct a Pareto front based on the Upper Confidence Bound for UTS and EL, providing guidance for alloy composition design. Through experimental validation and iterative optimization, the strength-ductility balance of Al-Mg-Zn alloys was significantly improved, with the designed Al-5.27Mg-2.8Zn-0.44Cu-0.19Ag-0.15Sc-0.05Mn-0.01Zr alloy (wt.%) exhibiting superior mechanical properties with the measured UTS of 602 MPa and EL of 15.1 %. Microstructural analysis using SEM, EBSD and TEM revealed that the improved strength-ductility balance of the alloy is attributed to its optimized composition, which results in the minimal micron phases, numerous fine Al 3 Sc particles, low-recrystallization grains, and a high density of precipitates. This active learning-based design strategy offering a novel approach for material development in systems with limited data.},
  archive      = {J_MATDES},
  author       = {Wuwei Mo and Yao Xiao and Yushen Huang and Peng Sun and Ya Li and Xiaoyu Zheng and Qiang Lu and Bo Li and Yuling Liu and Yong Du},
  doi          = {10.1016/j.matdes.2025.113772},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113772},
  shortjournal = {Mater. Des.},
  title        = {Active learning-based alloy design strategy for improving the strength-ductility balance of al-mg-zn alloys},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design strategy for al-containing metallic glasses by
entropy engineering and covalent attribute. <em>MATDES</em>,
<em>252</em>, 113771. (<a
href="https://doi.org/10.1016/j.matdes.2025.113771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional approaches to the composition design of metallic glasses often disregard the distinct nature of metallic and covalent interactions, leading to challenges in accurately incorporating specific elements that are more covalent and understanding their interactions. This limitation complicates the quantitative design process and hinders the development of a comprehensive theoretical framework. To address this, we propose a novel design strategy based on entropy engineering to tune metallic bonds using melting entropy, while the covalent interactions is guided by mixing enthalpy. Applying this method, we successfully designed the metallic glasses La 60.6 Ni 22.9 Al 17.5 and La 62.2 Ni 11.8 Cu 12.7 Al 13.2 whose GFA is highly consistent with the reported components.},
  archive      = {J_MATDES},
  author       = {Bing-Tao Wang and Zi-Jing Li and Shi-Dong Feng and Li-Min Wang},
  doi          = {10.1016/j.matdes.2025.113771},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113771},
  shortjournal = {Mater. Des.},
  title        = {Design strategy for al-containing metallic glasses by entropy engineering and covalent attribute},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). First-principles study on the faulted interface of
dislocation-sheared t1 precipitates. <em>MATDES</em>, <em>252</em>,
113770. (<a href="https://doi.org/10.1016/j.matdes.2025.113770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The T 1 phase is a crucial shearable precipitate that enhances the strength of Al-Cu-Li alloys. Its strengthening effect is associated with the energy of the faulted interfaces generated upon dislocation-shearing of the precipitates. Due to the extremely small size of the T 1 phase, this energy cannot be directly measured, and the atomic arrangement around the faulted interface has never been characterized, leading to a knowledge gap regarding these interfaces. This work constructed large-scale supercells that encompassed both precipitate and matrix atoms for a first-principles examination of the faulted interfaces. Two opposite dislocation-shearing actions were incorporated to reserve the overall periodicity of the supercells, which is essential for compatibility with density functional theory calculations. Rigorous statistical analysis of the faulted interface energy was facilitated by modeling a variety of possible atomic arrangements of the faulted interfaces and investigating scenarios with T 1 phases of 1, 2, and 3 unit-cells in thickness. Following density functional theory relaxation of the supercells, the results demonstrated satisfactory convergence. The faulted interface energy was calculated as approximately 4 to 5 times the unstable stacking-fault energy of the matrix. The diverse thickening mechanisms of T 1 precipitates were found to significantly alter the overall FIE of the thickened precipitate.},
  archive      = {J_MATDES},
  author       = {Ruohan Shen and Xianchang Li and Panwang Zhou},
  doi          = {10.1016/j.matdes.2025.113770},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113770},
  shortjournal = {Mater. Des.},
  title        = {First-principles study on the faulted interface of dislocation-sheared t1 precipitates},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrosion behavior of steel parts repaired using additive
manufacturing: Overview and research perspective. <em>MATDES</em>,
<em>252</em>, 113769. (<a
href="https://doi.org/10.1016/j.matdes.2025.113769">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metal Additive Manufacturing (MAM) for the repair of steel components has attracted considerable interest due to its advantages over traditional repair methods. This paper presents a comprehensive overview of the corrosion aspects of steel parts repaired using MAM, emphasizing both the benefits and challenges associated with this innovative technology. A detailed comparison is made between various MAM repair techniques and conventional methods, focusing on their effects on corrosion resistance. Key factors related to MAM such as chemical composition, microstructure, galvanic couplings, defects, and post-processing techniques are examined concerning their influence on the corrosion performance of steel-repaired components. This review identifies critical knowledge gaps, particularly concerning the need for further comparative studies and the long-term performance of MAM-repaired steel components in diverse environmental conditions. The findings underscore the experimental validation and the use of theoretical simulations to fully understand the capabilities and limitations of MAM in steel repair applications.},
  archive      = {J_MATDES},
  author       = {Marina Furbino and Rubén Del Olmo and Reynier I. Revilla and Iris De Graeve},
  doi          = {10.1016/j.matdes.2025.113769},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113769},
  shortjournal = {Mater. Des.},
  title        = {Corrosion behavior of steel parts repaired using additive manufacturing: Overview and research perspective},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Near α titanium alloy ti60 with equiaxed β grain fabricated
by laser direct energy deposition assisted with ultrasound.
<em>MATDES</em>, <em>252</em>, 113768. (<a
href="https://doi.org/10.1016/j.matdes.2025.113768">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Laser direct energy deposition (LDED) offers unique advantages in the integrated forming of 3D complex-shape parts. However, the columnar grains that grow epitaxially along the building direction are prone to reduce the performance of the as-built parts. Herein, external ultrasonic field are introduced during the LDED of near-α titanium alloy Ti60 (Ti-5.7Al-4.0Sn-3.5Zr-0.4Mo-0.4Si-0.4Nb-1.0Ta-0.05C), resulting in equiaxed β grains with an average grain size of 62.82 μm. The single track morphology, molten pool, microstructure, and mechanical properties under different ultrasonic powers are characterized and investigated. The results indicate that the ultrasound can induce columnar to equiaxed transition (CET) of the prior-β grains and promote the precipitation of silicides, but the width of the α laths increases due to heating effect caused by ultrasound. Consequently, the sample prepared with the 6 μm ultrasonic vibration exhibits a increases of 67.18 % in elongation, and the mechanical properties reach the forge standard. Finally, the effects of prior-β grain and α lath on the final mechanical properties of the samples are discussed. This work provides a deep insight into the LDED process of near-α titanium alloy Ti60 assisted with ultrasound.},
  archive      = {J_MATDES},
  author       = {Yuxiang Ai and Jiasen Han and Yuanxi Huang and Kuitong Yang and Yang Zhou and Hui Chen and Xin Lin and Wentao Yan},
  doi          = {10.1016/j.matdes.2025.113768},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113768},
  shortjournal = {Mater. Des.},
  title        = {Near α titanium alloy ti60 with equiaxed β grain fabricated by laser direct energy deposition assisted with ultrasound},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physical twin of an industrial quad-laser powder bed fusion
machine for high-speed multi-modal sensing measurements.
<em>MATDES</em>, <em>252</em>, 113767. (<a
href="https://doi.org/10.1016/j.matdes.2025.113767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To faithfully capture the laser-material interaction and subsequent process dynamics during the industrial laser powder bed fusion process, we developed a Quad-laser in situ and operando process replicator (or the Quad-ISOPR) – a physical twin that mimics the Renishaw plc.’s RenAM 500Q multi-laser additive manufacturing system that can be used in laboratories and synchrotron radiation facilities. The Quad-ISOPR allows users to take synchrotron X-ray measurements while collecting correlative high-speed optical and photodiode imaging within a 10 ns delay, mounted in-line with the scanning lasers. We have selected case studies to demonstrate: (i) multi-modal data acquisition; (ii) signal processing using continuous wavelet transform; (iii) the study of laser drilling with ultra high-speed X-ray imaging; (iv) process mapping of melting and defect modes in Ti-6Al-4V; and lastly, (v) we showcase the interaction between multi-lasers on a Ti-6Al-4V alloy. Our experimental approach allows end-users to explore the process-structure–property relationship in multi-laser material processing and to use such the physical twin to design new materials and processes.},
  archive      = {J_MATDES},
  author       = {Samy Hocine and Sebastian Marussi and Andrew Farndell and Elena Ruckh and Rubén Lambert-Garcia and Anna C.M. Getley and Kwan Kim and Nick Jones and Maureen Fitzpatrick and Marta Majkut and Alexander Rack and Peter D. Lee and Chu Lun Alex Leung},
  doi          = {10.1016/j.matdes.2025.113767},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113767},
  shortjournal = {Mater. Des.},
  title        = {Physical twin of an industrial quad-laser powder bed fusion machine for high-speed multi-modal sensing measurements},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). In-situ immobilization technique for radioactive cesium
using laser technology for fukushima daiichi decommissioning.
<em>MATDES</em>, <em>252</em>, 113766. (<a
href="https://doi.org/10.1016/j.matdes.2025.113766">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decommissioning of the Fukushima Daiichi (1F) nuclear power plant remains a significant environmental concern. A crucial aspect of this process involves the effective immobilization of 137 Cs to reduce the volume of radioactive waste. This technique traps radioactive materials that adhere to the concrete surface by embedding in the glass, allowing only the glass to be removed during decommissioning. In this study, we first irradiated concrete mixed with 133 Cs, which had the same composition as the nuclear reactor building at 1F, using a high-brightness laser beam to immobilize Cs. We then investigated the characteristics of in-situ immobilization of Cs from the aspects of distribution, migration, and elution. X-ray diffraction (XRD) results indicate that the concrete underwent vitrification. Measurements from an electron probe microanalyzer (EPMA) show that Cs exhibits aggregate-dependent heterogeneity within the fused, glass-like concrete. The experimental migration rate of 99 % is more reliable compared to the 57 % achieved through conventional thermal plasma melting of simulated low-level radioactive waste. As far as elution is concerned, the normalized mass loss of the elements is 0.06 to 0.08 g/m 2 , which is below the 2 g/m 2 limit set by the American Society for Testing and Materials (ASTM) International. Consequently, laser-assisted in-situ immobilization of Cs has superior potential for supporting the decommissioning of 1F by effectively utilizing the hazardous materials on site.},
  archive      = {J_MATDES},
  author       = {Hitoshi Ozaki and Yosuke Kawahito and Michiko Mori and Masahito Shibata and Tsuyoshi Nakamura and Tatsuya Mase and Hiroyuki Yoshida and Hiroshi Kawakami and Muneo Hori},
  doi          = {10.1016/j.matdes.2025.113766},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113766},
  shortjournal = {Mater. Des.},
  title        = {In-situ immobilization technique for radioactive cesium using laser technology for fukushima daiichi decommissioning},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A skeletonization based image segmentation algorithm to
isolate slender regions in 3D microstructures. <em>MATDES</em>,
<em>252</em>, 113765. (<a
href="https://doi.org/10.1016/j.matdes.2025.113765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work proposes an image segmentation algorithm that isolates slender regions in three-dimensional microstructures. Characterizing slender regions in material microstructures is an extremely important aspect in material science because these regions govern the macroscopic behavior of materials for many applications like energy absorption, activation of metamaterials, stability of high temperature filters, etc. This work utilizes skeletonization method to calculate centerline of the microstructure geometry followed by a novel pruning strategy based on cross-sectional area to identify slender regions in the microstructure. 3D images of such microstructures obtained from micro-CT often suffer from low image resolution resulting in high surface noise. The skeleton of such an image has many spurious skeletal branches that do not represent the actual microstructure geometry. The proposed pruning method of cross-sectional area is insensitive to surface noise and hence is a reliable method of identifying skeletal branches that represent the slender regions in the microstructure. The proposed algorithm is implemented on a test case to showcase its effectiveness. Further it is implemented on a 3D microstructure of ceramic foam to identify the slender regions present in it. It is shown that the method can be used to segment slender regions of varying dimensions and to study their geometric properties.},
  archive      = {J_MATDES},
  author       = {Vinit Vijay Deshpande and Romana Piat},
  doi          = {10.1016/j.matdes.2025.113765},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113765},
  shortjournal = {Mater. Des.},
  title        = {A skeletonization based image segmentation algorithm to isolate slender regions in 3D microstructures},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Specific activation of cGAS-STING pathway by manganese-doped
bioactive glasses for boosting systemic tumor immunotherapy.
<em>MATDES</em>, <em>252</em>, 113764. (<a
href="https://doi.org/10.1016/j.matdes.2025.113764">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recurrence and metastasis of renal cell carcinoma present significant challenges in clinical settings, necessitating the urgent development of strategies to enhance the efficacy of kidney cancer treatments. In this study, we designed and developed a manganese-doped bioactive glass-based (Mn-MBG) core, creating a Mn-rich nanotherapeutic platform named MMPI. This platform was further modified by encapsulation with polydopamine (PDA) and successfully loaded with the photosensitizer indocyanine green (ICG) through π-π stacking interactions, enabling photothermal therapy (PTT) and photodynamic therapy (PDT). In vitro experiments demonstrated that under near-infrared (NIR) irradiation, MMPI could generate a moderate photothermal effect, causing damage to tumor cells. At the same time, the photothermal effect enhanced Mn 2+ and ICG release and increased reactive oxygen species (ROS) production, intensifying damage to heat-sensitive tumor cells and aiding tumor elimination. In vivo experiments showed that MMPI can counteract the tumor’s immunosuppressive environment by activating the cGAS-STING pathway, boosting local innate immune cell recruitment, dendritic cell maturation, and T cell-mediated adaptive antitumor responses. In conclusion, this study elucidates the concept of a manganese-based non-invasive tumor immunotherapy model, establishing a paradigm for immunotherapeutic approaches in renal cell carcinoma.},
  archive      = {J_MATDES},
  author       = {Zhaolin Yang and Jiale Zhou and Xinrui Wu and Sian Zhou and Wei Xue and Jiahua Pan and Yonghui Chen and Xiaorong Wu},
  doi          = {10.1016/j.matdes.2025.113764},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113764},
  shortjournal = {Mater. Des.},
  title        = {Specific activation of cGAS-STING pathway by manganese-doped bioactive glasses for boosting systemic tumor immunotherapy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spiral kinematics: A biomimetic approach to enhancing
demolding efficiency in 3D-printed polymeric formworks for customized
hollow concrete structures. <em>MATDES</em>, <em>252</em>, 113763. (<a
href="https://doi.org/10.1016/j.matdes.2025.113763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The customization of hollow concrete components has gained significant attention for enhancing multi-functional performance, including structural efficiency, thermal and acoustic properties; however, it also poses challenges in fabricating complex geometries. Conventional concrete formwork often faces demolding difficulties, which can damage both the formwork and the concrete and lead to increased costs and environmental impact. This study introduces a novel approach where polymeric formworks with biomimetic spiral designs are fabricated by 3D-priniting. Such customized 3D-printed formwork designs introduce a kinematic mechanism to enhance demolding efficiency while maintaining structural integrity. Polylactic acid (PLA) and thermoplastic polyurethane (TPU) were used to fabricate 3D-printed polymer bars with varying spiral gap lengths (0.2 mm and 0.6 mm), which were tested under monotonic pull-out conditions, mimicking formwork extraction from hollow concrete components. The spiral designs significantly reduce pull-out resistance, demolding difficulty, and associated damage. The kinematic benefits from spirals can be further amplified by adopting wider spiral gaps or by selecting TPU as the 3D printing filament, due to its greater toughness and flexibility, which resemble those of elastomeric materials. This work advances concrete demolding through innovative design optimization and offers practical solutions for greater customization and fabrication efficiency for intricate concrete structures.},
  archive      = {J_MATDES},
  author       = {Zhuyin Lu and Shawn Owyong and Xin Tian and Pei Xuan Tan and Yi Xuan Liau and Siti Nur Ain Abdul Aziz and Hanmo Wang and Alexander Lin},
  doi          = {10.1016/j.matdes.2025.113763},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113763},
  shortjournal = {Mater. Des.},
  title        = {Spiral kinematics: A biomimetic approach to enhancing demolding efficiency in 3D-printed polymeric formworks for customized hollow concrete structures},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D printing of curved continuous fibre filaments using fused
deposition modelling. <em>MATDES</em>, <em>252</em>, 113762. (<a
href="https://doi.org/10.1016/j.matdes.2025.113762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fused deposition modelling (FDM) is a 3D printing technique capable of fabricating intricately shaped composites through the deposition of continuous fibre filaments. This study investigates the limitations of 3D printing curved filaments using FDM. Polyamide matrix filaments containing continuous carbon, glass, or aramid fibres were 3D printed into curved profiles with different radii as low as 1 mm. A detailed microstructural and mechanical analysis was conducted to assess the damage incurred during curved printing. The deposition mechanism of the FDM process was found to lack high dimensional accuracy when 3D printing continuous fibre filaments in tight curvatures. Issues including filament peeling and twisting resulted in printing error of up to 60 % in the curvature radius, depending on the fibre types. The filaments experienced fibre damage, matrix tearing, and shape distortion during the curved printing process, which subsequently reduced the tensile properties of the printed composites. The average filament strengths were found to be only 30 %, 41 % and 64 % compared to that of the straight printed filament for carbon, glass, and aramid fibre filaments, respectively, when the radius was below 5 mm. These findings provide foundations for identifying optimal FDM printing conditions to produce defect-free composite with complex structures.},
  archive      = {J_MATDES},
  author       = {Yiwei Hu and Adrian P. Mouritz and Raj B. Ladani and Yazhi Li and Shaoyu Zhao and Huanxin Zhang},
  doi          = {10.1016/j.matdes.2025.113762},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113762},
  shortjournal = {Mater. Des.},
  title        = {3D printing of curved continuous fibre filaments using fused deposition modelling},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A static and high-cycle fatigue characterization framework
of metallic lattice structures additive manufactured via fused
deposition modeling based method. <em>MATDES</em>, <em>252</em>, 113761.
(<a href="https://doi.org/10.1016/j.matdes.2025.113761">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to conventional metal additive manufacturing techniques, metal fused deposition modeling (Metal FDM) reduces cost at the expense of deterioration in materials’ mechanical performance. To realize the full design potential that Metal FDM components can offer, effectively predicting the performance becomes imperative, especially for lattice structures that are widely used in aerospace under complex and cyclic loading. This work developed a framework for characterizing and predicting static and high-cycle fatigue behaviors of FDM-printed metal lattices. Constitutive model constants of FDM-printed 17-4PH steels were identified via experiments on dog bone samples at the same length scale of lattice microstructures. The material exhibits quasi-brittle behavior at microstructural size, with a tensile stiffness of 24 GPa. It is only 13 % of the expected stiffness for macroscopic level materials, showing a severe effect by length scale. Residual porosity leads to microcracks, which act as the primary failure mechanism under high-cycle fatigue, reducing the fatigue limit to 31 % of rolled steel. Assigning developed constitutive models, the asymptotic homogenization method was employed to obtain equivalent static properties of stretch- and bend-dominated lattices, which were in accord with testing results. Through the Brown-Miller-Morrow method, the framework numerically predicted lattice high-cycle fatigue life, which was validated against experiments.},
  archive      = {J_MATDES},
  author       = {Wei Zhang and Rujun Li and Yan Peng and Hang Xu},
  doi          = {10.1016/j.matdes.2025.113761},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113761},
  shortjournal = {Mater. Des.},
  title        = {A static and high-cycle fatigue characterization framework of metallic lattice structures additive manufactured via fused deposition modeling based method},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biology as inspiration for creative design of roadside
safety hardware: A perspective on the state of the art. <em>MATDES</em>,
<em>252</em>, 113760. (<a
href="https://doi.org/10.1016/j.matdes.2025.113760">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Roadside safety hardware, such as longitudinal barriers and crash cushions, is part of the highway infrastructure used to protect an errant vehicle from crashing into fixed roadside objects in a well-controlled manner. Despite constantly improved design and standardized full-scale impact testing of the roadside safety hardware, more than 3% of U.S. traffic fatalities are caused by the inefficiency of the roadside safety hardware. This perspective article highlights the need for innovative designs to enhance protection and mitigate impact severity. In nature, many plants and animals are optimized to adapt to various overload conditions and have demonstrated superior impact-resistant and energy-absorbing capabilities. Careful study of these biological structures may inspire the development of a new generation of soft, flexible, curvilinear roadside safety hardware.},
  archive      = {J_MATDES},
  author       = {Arman Moussavi and Cody Stolle and Congrui Jin},
  doi          = {10.1016/j.matdes.2025.113760},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113760},
  shortjournal = {Mater. Des.},
  title        = {Biology as inspiration for creative design of roadside safety hardware: A perspective on the state of the art},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Er microalloying significantly refines precipitates to
simultaneously promote the strength and ductility of mg-gd-y-zn-zr
alloy. <em>MATDES</em>, <em>252</em>, 113759. (<a
href="https://doi.org/10.1016/j.matdes.2025.113759">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The contradiction between the strength and ductility of magnesium (Mg) alloys has become a theoretical obstacle and technical bottleneck in their research. The preparation technology of ultrafine grains/nanocrystals relying on severe plastic deformation deviates from actual industrial production, therefore alloying is currently a more practical choice. This work simultaneously promoted the strength and ductility of Mg-Gd-Y-Zn-Zr alloy by adding a trace amount of Er element (0.5 wt%). Er microalloying has little effect on grain size, texture, morphology and content of long-period stacking ordered (LPSO) structure, but significantly promotes aging precipitation, thereby substantially increasing the number density of β’ and reducing its size. The significantly refined β’ makes calculations based on the Orowan bypass mechanism less accurate, and more consideration should be given to linking the synchronous improvement of strength and ductility with the dislocation-shearing mechanism.},
  archive      = {J_MATDES},
  author       = {Qian Zhang and Fulin Wang and Jian Zeng and Fenghua Wang and Shuai Dong and Li Jin and Jie Dong},
  doi          = {10.1016/j.matdes.2025.113759},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113759},
  shortjournal = {Mater. Des.},
  title        = {Er microalloying significantly refines precipitates to simultaneously promote the strength and ductility of mg-gd-Y-zn-zr alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing mechanical properties of CoCrNi via in-situ
alloying with Al2O3 through laser powder bed fusion. <em>MATDES</em>,
<em>252</em>, 113758. (<a
href="https://doi.org/10.1016/j.matdes.2025.113758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For advantages in integrating the intrinsic properties of the metal matrix and reinforcing phases, properly designed metal matrix composites (MMCs) are promising candidates for overcoming the trade-offs of properties such as corrosion, ductility, strength, and lightweight. However, MMCs often face challenges such as agglomeration and inhomogeneous distribution of the reinforcing phase, leading to significant degradation of mechanical properties. In this study, we propose a method to overcome these obstacles by in-situ alloying via laser powder bed fusion (LPBF), achieving a uniform distribution of the reinforcing nano-sized phase (α-Al 2 O 3 ) within a medium-entropy alloy matrix (CoCrNi). During the LPBF process, Al 2 O 3 is refined from the micrometer scale to the nanometer scale, simultaneously affecting the crystal orientation and leading to grain refinement of the CoCrNi matrix. The mechanical properties of CoCrNi were significantly enhanced by adding Al 2 O 3 , with an ultimate compressive strength of ∼1143 MPa, a fracture strain of ∼25%, and a hardness of ∼300 HV. The achieved strength and hardness levels are among the highest reported in the literature. The results from this study provide new design strategies for the in-situ formation of MMCs, offering a promising approach to developing MMCs with high strength and ductility.},
  archive      = {J_MATDES},
  author       = {Zairan Luo and Qian Liu and Dingding Zhu and Jiang Yi and Zhiqian Rao and Shuai Wang},
  doi          = {10.1016/j.matdes.2025.113758},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113758},
  shortjournal = {Mater. Des.},
  title        = {Enhancing mechanical properties of CoCrNi via in-situ alloying with Al2O3 through laser powder bed fusion},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Powder bed fusion on single lines of cu-doped hydroxyapatite
powder bed. <em>MATDES</em>, <em>252</em>, 113757. (<a
href="https://doi.org/10.1016/j.matdes.2025.113757">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to design ceramic scaffolds for precise bone reconstruction using Powder Bed Laser Sintering (PBLS) to create cohesive Cu-doped HAp ribbons from a single lasered line on a thin powder bed atop a silicate lime substrate. Depending on laser parameters, two ribbon types—delaminated (CDR) or anchored (CAR)—are produced, both exhibiting surface density gradients from the center to the edges. Microscale analysis reveals surface density gradients in both ribbon types, extending from center to edge. CDRs also show depth-wise density variations, resulting in mechanical stresses that cause detachment and curling. In CARs, intense local heating and thermal conductivity cause a temperature rise beyond the irradiated area. The substrate acts as a thermal barrier, concentrating heat at the film-substrate interface and ensuring ribbon adhesion. Cracks propagate perpendicular to isothermal lines, enabling controlled crack patterning.},
  archive      = {J_MATDES},
  author       = {François Rouzé l’Alzit and Benoit Glorieux and Thierry Cardinal and Manuel Gaudon},
  doi          = {10.1016/j.matdes.2025.113757},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113757},
  shortjournal = {Mater. Des.},
  title        = {Powder bed fusion on single lines of cu-doped hydroxyapatite powder bed},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). Corrigendum to “ballistic impact performance of
kevlar®/UHMWPE hybrid composite panels with a liquid thermoplastic
resin, elium®” [mater. Des. 252 (2025) 113706]. <em>MATDES</em>,
<em>252</em>, 113756. (<a
href="https://doi.org/10.1016/j.matdes.2025.113756">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  author       = {Aswani Kumar Bandaru and Dinesh Kumar Kothandan and Hemant Chouhan and Hong Ma and Ronan M. O’Higgins},
  doi          = {10.1016/j.matdes.2025.113756},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113756},
  shortjournal = {Mater. Des.},
  title        = {Corrigendum to “Ballistic impact performance of Kevlar®/UHMWPE hybrid composite panels with a liquid thermoplastic resin, elium®” [Mater. des. 252 (2025) 113706]},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tailor-made 3D printing TPU/PLA composites for damping and
energy absorption. <em>MATDES</em>, <em>252</em>, 113752. (<a
href="https://doi.org/10.1016/j.matdes.2025.113752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commercially available thermoplastic polyurethane (TPU) materials for 3D printing often exhibit inadequate damping properties, limiting their application in damping scenarios. However, 3D printing TPU filaments specifically engineered for enhanced damping performance frequently lack sufficient stiffness, causing printing continuity issues. To address these challenges, this study investigates the rational design of TPU composites by regulating TPU molecular structure and incorporating polylactic acid (PLA) to enhance both damping performance and stiffness. The results reveal that a prepolymer curing coefficient of 2.0, combined with a chain extender ratio of Dimethyl thio-toluene diamine (DMTDA) to 1,4-Butanediol (BDO) at 5:5, optimizes the damping and mechanical properties of the TPU material. Furthermore, by incorporating 30 wt% PLA particles into the TPU matrix, the obtained TPU7/PLA3 composite filament has excellent printability and admirable damping properties with a peak damping value of 0.60 around room temperature and an effective damping temperature range exceeding 100 °C. A lattice structure resembling Kelvin foam was successfully fabricated using the TPU/PLA filaments, demonstrating superior damping performance compared to commercial TPU filaments and underscoring its potential for energy absorption applications.},
  archive      = {J_MATDES},
  author       = {Ruichao Zu and Wenzheng Chen and Yicang Huang and Yujie Chen and Chengzhen Du and Qunfu Fan and Hua Li and Hezhou Liu},
  doi          = {10.1016/j.matdes.2025.113752},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113752},
  shortjournal = {Mater. Des.},
  title        = {Tailor-made 3D printing TPU/PLA composites for damping and energy absorption},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High temperature he bubble evolution and thermal stability
of the WTaCrV refractory concentrated solid solution alloy.
<em>MATDES</em>, <em>252</em>, 113751. (<a
href="https://doi.org/10.1016/j.matdes.2025.113751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigate the thermal stability and high-temperature evolution of He bubbles within the structure of the WTaCrV refractory concentrated solid solution alloy (RCSA), which is dedicated to nuclear fusion applications. The material was first irradiated with He + ions to form nanometric He bubbles within its structure. Subsequently, their high-temperature evolution was studied using an in-situ heating method in a transmission electron microscope over a temperature range of 700 °C to 1000 °C. We found that the bubbles are stable in size up to a temperature of 700 °C and show no agglomeration up to 800 °C. At higher temperatures, the coarsening of the bubbles occurs through the migration and coalescence mechanism; however, even at 1000 °C, the size of the bubbles only slightly exceeds 1 nm. For a more in-depth understanding of the phenomena occurring during high-temperature annealing, molecular dynamics simulations were applied. We demonstrate that the low diffusivity of V m He n clusters in the investigated WTaCrV alloy is responsible for the low tendency for high-temperature coarsening of the bubbles. The results of this study highlight the potential of the WTaCrV RCSA as a refractory, irradiation-resistant material for crucial components in future fusion reactors.},
  archive      = {J_MATDES},
  author       = {Damian Kalita and Amin Esfandiarpour and Iwona Jóźwik and Yanwen Zhang and Jesper Byggmästar and Mikko J. Alava and Łukasz Kurpaska and William J. Weber and Philip D. Rack and Jacek Jagielski},
  doi          = {10.1016/j.matdes.2025.113751},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113751},
  shortjournal = {Mater. Des.},
  title        = {High temperature he bubble evolution and thermal stability of the WTaCrV refractory concentrated solid solution alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Laser-based additive manufacturing of bulk metallic glasses:
A review on principle, microstructure and performance. <em>MATDES</em>,
<em>252</em>, 113750. (<a
href="https://doi.org/10.1016/j.matdes.2025.113750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bulk metallic glasses (BMGs) have gained significant attention in the engineering field due to their unique microstructure and excellent properties. However, the fabrication of large-sized and complex-shaped BMGs components remains a major challenge. Laser-based additive manufacturing (LAM) techniques offer a promising solution to conquer the limitations of traditional methods in manufacturing BMGs. Theoretically, LAM techniques can achieve extremely high cooling rates of over 10 4 K/s, resulting in the formation of metallic glass structures within the tiny molten pools. More significantly, the bottom-up concept of LAM enables the layer-by-layer construction of large-sized BMGs parts. Herein, this review extensively explores cutting-edge research on various aspects of utilizing LAM techniques in BMGs fabrication. It provides a comprehensive discussion of the forming mechanism of BMGs during LAM, focusing on factors such as heterogeneous microstructure, crystallization behavior and defect elimination. Additionally, the influence of composition and process parameters on the performance of LAM-produced BMGs, including mechanical properties, corrosion behavior, and biocompatibility, is systematically reviewed. An outlook on the LAM techniques for BMGs production is presented, aiming to provide some guiding principles for future research directions in this pioneering field.},
  archive      = {J_MATDES},
  author       = {Jiapeng Ren and Dongsheng Wang and Xuehua Wu and Youwen Yang},
  doi          = {10.1016/j.matdes.2025.113750},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113750},
  shortjournal = {Mater. Des.},
  title        = {Laser-based additive manufacturing of bulk metallic glasses: A review on principle, microstructure and performance},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Topological interface modes in 3D-printed triply periodic
minimal surface phononic crystals. <em>MATDES</em>, <em>252</em>,
113749. (<a href="https://doi.org/10.1016/j.matdes.2025.113749">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Triply periodic minimal surface (TPMS)-based continuous structures have recently attracted increased attention due to their remarkable mechanical properties, such as high strength-to-weight ratio, impact resistance, and energy absorption capabilities. In this study, we investigate topological interface modes in I-WP (Wrapped Package) TPMS geometry. Inspired by a one-dimensional (1D) Su–Schrieffer–Heeger (SSH) model, we design 1D elastic Phononic Crystals (PCs) made of sheet-based I-WP minimal surface geometry. By manipulating the geometry of the I-WP minimal surface, we open the degeneracies formed at the edges of the Brillouin zone to create band-folding-induced bandgaps. We then design a 1D dimerized chain of two topologically distinct unit cells of I-WP minimal surface to create an interface and introduce topological interface modes. Numerical simulations are performed to study the band structure and topological transition properties of the proposed 1D PC. In addition, we show that hybridizing alternative I-WP unit cells of different relative densities can also break the inversion symmetry of the periodic structure in contrast to manipulating the geometry. The 1D PC made of hybridized I-WP geometry is then used to realize topological interface modes. The proposed 1D PCs are additively manufactured to experimentally validate the existence of topological interface modes. Our work provides an efficient method for TPMS structures to produce multifunctional devices that can support superior load-bearing capabilities as well as robust topological phase properties.},
  archive      = {J_MATDES},
  author       = {Prabhakaran Manogharan and Alper Erturk},
  doi          = {10.1016/j.matdes.2025.113749},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113749},
  shortjournal = {Mater. Des.},
  title        = {Topological interface modes in 3D-printed triply periodic minimal surface phononic crystals},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Natural pigments as multifunctional additives in contact
lenses. <em>MATDES</em>, <em>252</em>, 113748. (<a
href="https://doi.org/10.1016/j.matdes.2025.113748">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous exposure to blue light emitting devices as part of modern life leads to melatonin suppression that results in poor sleep quality and overall health. Contact lenses capable of blue light filtering could be used to mitigate this issue. This can be facilitated by using natural dyes to filter certain wavelengths from contact lenses. In this research, Curcuma Aromatica and Rubia Cordifolia were used to stain commercial contact lenses. This improved the blue light filtering capability and antibacterial resistance against Staphylococcus aureus and Pseudomonas aeruginosa bacteria. The UV Vis transmission spectra showed great blue light reduction for both natural pigments, C. aromatica being the better choice. The lenses showed a reduction of around 95 % in the blue light region while maintaining high transparency. Use of PVA improved the shelf life for C. aromatica, by providing better stability in both deionized water and contact lens storage solution. The lenses showed comparable contact angle and water retention properties, indicating that the additives retained the commercial contact lens’ properties. The MTT assay and Trypan blue assay indicated very good cell viability implying good biocompatibility of the lenses. Additionally, the anti-inflammatory effect of C. aromatica and C. aromatica + PVA dipped lenses strengthens the possibility of implementing them in further applications. The R. cordifolia dipped lenses seem to have improved inflammatory responses upon the addition of PVA. These lenses show great promise for protection against blue light from displays and other sources, offering a remedy to prolonged exposure to blue light.},
  archive      = {J_MATDES},
  author       = {C. Muhammed Shebeeb and Sanjana Chandran and Liya Jacob and Abdulrahim Sajini and Haider Butt},
  doi          = {10.1016/j.matdes.2025.113748},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113748},
  shortjournal = {Mater. Des.},
  title        = {Natural pigments as multifunctional additives in contact lenses},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparison of hydrogen resilience of three different
corrosion-resistant martensitic steels. <em>MATDES</em>, <em>252</em>,
113747. (<a href="https://doi.org/10.1016/j.matdes.2025.113747">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hydrogen gas is a critical resource for future sustainable energy production, with stainless steels playing a substantial role in applications where components are exposed to hydrogen gas environments. In this work, the resistance to hydrogen embrittlement of three ultra-high strength martensitic stainless steels was investigated. The materials comprised of one high carbon, one nitrogen-alloyed and one dual precipitation hardened steel. The experiments involved a combined deuterium charge, followed by atom probe tomography, and hydrogen gas charge, followed by slow strain rate testing. This approach enabled the study of each steel’s resilience to hydrogen gas and allowed correlations between mechanical behaviors after hydrogen charging and their hydrogen trapping capabilities, as well as the presence of undissolved primary carbides or carbonitrides. Results showed that while the nitrogen-alloyed stainless steel demonstrated the highest hydrogen trapping capability, the presence of undissolved primary carbides or carbonitrides within it served as crack initiation sites during slow strain rate tests, reducing its hydrogen resistance. The dual precipitation-hardened steel, which lacked undissolved carbides, exhibited the least hydrogen embrittlement.},
  archive      = {J_MATDES},
  author       = {Severin Jakob and Mattias Thuvander and Steve W. Ooi},
  doi          = {10.1016/j.matdes.2025.113747},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113747},
  shortjournal = {Mater. Des.},
  title        = {Comparison of hydrogen resilience of three different corrosion-resistant martensitic steels},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of SiC on the antioxidant properties of al-containing
composites Ti3SiC2/SiC and its oxidation mechanism analysis.
<em>MATDES</em>, <em>252</em>, 113746. (<a
href="https://doi.org/10.1016/j.matdes.2025.113746">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims at improving the oxidation resistance of ceramics intended for high-temperature applications by examining the quantitative SiC-reinforced aluminum-containing composites Ti 3 SiC 2 /SiC that were synthesized through a powder metallurgy method. The high-temperature antioxidant properties of these composites were evaluated at temperatures between 900 °C and 1300 °C. The findings reveal that an increase in SiC content elevates the activation energy associated with oxidation, mitigates oxidation behavior, and decreases the weight gain attributable to oxidation of the material. Additionally, the formation of the oxide layer and atomic diffusion were investigated through the analysis of surface micro-morphology and the distribution of the oxide layer at the interface. It was found that the addition of SiC modifies the oxide layer structure of the material, which primarily consists of an outer mixed oxide layer of TiO 2 and Al 2 O 3 , an intermediate oxide layer of TiO 2 with a small amount of SiO 2 , and an inner homogeneous mixed oxide layer of TiO 2 and SiO 2 . Finally, the high-temperature oxidation mechanism of Ti 3 SiC 2 /SiC composites is systematically illustrated through experimental results.},
  archive      = {J_MATDES},
  author       = {Chengzhi Du and Bo Lei and Yajie Qi and Rui Zhang},
  doi          = {10.1016/j.matdes.2025.113746},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113746},
  shortjournal = {Mater. Des.},
  title        = {Effect of SiC on the antioxidant properties of al-containing composites Ti3SiC2/SiC and its oxidation mechanism analysis},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Femtosecond-laser-surface-nanostructured glass for
building-integrated photovoltaics. <em>MATDES</em>, <em>252</em>,
113745. (<a href="https://doi.org/10.1016/j.matdes.2025.113745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emerging luminescent solar concentrators (LSC) for building-integrated photovoltaics (BIPV) face challenges such as narrow conversion spectrum, material degradation, high costs, and safety concerns, while their reliance on complex fabrication processes further hinders their practical application in large-area systems. In this paper, we present a novel application of femtosecond-laser-nanostructured borosilicate glass for BIPV, offering a promising alternative to traditional LSC windows. Utilizing a scalable, one-step femtosecond laser direct writing process, we fabricate nanostructured borosilicate glass specifically designed to effectively scatter incident light toward solar cells positioned at the edges of the glass. To optimize the laser processing, we perform comprehensive characterizations using scanning electron microscopy, X-ray diffraction, Raman spectroscopy, photoluminescence spectroscopy, and spectrophotometry. The proof-of-concept system demonstrates that the glass processed at an optimized scan speed exhibits a 55-fold increase in photocurrent generation compared to unprocessed glass, highlighting its enhanced optical efficiency. Additionally, a hydrophobic coating is applied on the nanostructured glass to confer self-cleaning properties, achieving superhydrophobicity with advancing and receding contact angles of approximately 170°. This novel approach to utilizing nanostructured glass for solar concentration shows considerable promise for improving both the efficiency and practicality of building-integrated photovoltaics.},
  archive      = {J_MATDES},
  author       = {Lingju Meng and Mohammad Awashra and Sara Hamed and Dmytro Gnatyuk and Ville Vähänissi and Ville Jokinen and Hele Savin and Xiaolong Liu},
  doi          = {10.1016/j.matdes.2025.113745},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113745},
  shortjournal = {Mater. Des.},
  title        = {Femtosecond-laser-surface-nanostructured glass for building-integrated photovoltaics},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Light and pH-activated nanoplatform based on oxidative
stress-amplified for photodynamic and ferroptosis synergistic therapy of
breast cancer. <em>MATDES</em>, <em>252</em>, 113744. (<a
href="https://doi.org/10.1016/j.matdes.2025.113744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to traditional tumor chemotherapy, photodynamic therapy (PDT) can effectively reduce toxic side effects and prevent tumor resistance. However, the reactive oxygen species (ROS) generated by photosensitizers are limited, and the destructive effects on tumor cells are inadequate. In this study, nanomedicines loaded with the photosensitizers chlorin e6 (Ce6) and dihydroartemisinin (DHA) were constructed using human serum albumin (HSA) and transferrin (Tf), self-assembly for the programmed activation, and expansion of ROS in tumor cells. These nanomedicines, Ce6/DHA@HSA-SS-Tf nanoparticles (NPs), can target Tf receptors overexpressed on cancer cells to produce ROS through PDT with laser irradiation. Subsequently, the ROS-responsive vector is cleaved, and iron ions catalyze the released DHA to produce sufficient ROS and induce ferroptosis in tumor cells. The nanomedicine amplifies the ROS content in tumor cells through a dual response and programmed activation, which can effectively solve the problem of insufficient ROS production in tumor PDT. Consequently, the Ce6/DHA@HSA-SS-Tf NPs demonstrate excellent anti-tumor effects through the synergistic effects of PDT and ferroptosis. This treatment strategy provides a reliable basis for tumor-specific and efficient treatments.},
  archive      = {J_MATDES},
  author       = {Song Li and Zhenxin Guan and Yurong Liu and Xiaokang Zhang and Yunheng Liu and Shaojing Jiang and Wenjing Liu and Aoya Wang and Xiaolin Li and Xukai Che and Liyuan Shao and Li Zhang and Jinghui Hu and Jing Chen},
  doi          = {10.1016/j.matdes.2025.113744},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113744},
  shortjournal = {Mater. Des.},
  title        = {Light and pH-activated nanoplatform based on oxidative stress-amplified for photodynamic and ferroptosis synergistic therapy of breast cancer},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “superior hemostatic and wound-healing
properties of tetrastigma polysaccharide” [mater. Des. 241 (2024)
112967]. <em>MATDES</em>, <em>252</em>, 113743. (<a
href="https://doi.org/10.1016/j.matdes.2025.113743">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MATDES},
  author       = {Shengyu Li and Wenjun Xu and Weihan Zhu and Jinwei Wang and Jintao Shi and Jingyi Tang and Xia Liu and Wei Zhang and Huiying Fu and Qiyang Shou},
  doi          = {10.1016/j.matdes.2025.113743},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113743},
  shortjournal = {Mater. Des.},
  title        = {Corrigendum to “Superior hemostatic and wound-healing properties of tetrastigma polysaccharide” [Mater. des. 241 (2024) 112967]},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The interaction between local melting and helium bubble in
radiated aluminium under dynamic tension at high temperature and strain
rates. <em>MATDES</em>, <em>252</em>, 113741. (<a
href="https://doi.org/10.1016/j.matdes.2025.113741">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Materials exposed to extreme radiation environments (e.g., nuclear devices) accumulate substantial defects, such as helium (He) bubbles. These defects can alter material properties, including melting behavior, which has not been intensively explored. Here, the melting process and the He bubble evolution in aluminium under dynamic tension at high temperature and strain rates were investigated via molecular dynamic simulations. We found that the melting process contains slow premelting and sequential fast local melting at relatively lower strain rates (10 6 ∼ 10 8 /s). The rapid growth of the bubble promotes local melting, which in turn facilitates the migration and shrinkage of the bubble. The underlying microscopic mechanisms for the interplay between the bubble and local melting have also been uncovered. Such interaction becomes weak at high strain rates (10 9 ∼ 10 10 /s). Homogeneous melting occurs directly and spontaneously throughout the sample, and local melting around the bubble becomes inconspicuous. The evolution process of the bubble gets simple, characterized by continuous growth without shrinkage or migration. Furthermore, damage development is dominated by the growth of the He bubble, which occurs after the sample is nearly completely melted at lower strain rates while it happens concurrently with melting at high strain rates.},
  archive      = {J_MATDES},
  author       = {Tingting Zhou and Fuqi Zhao and Anmin He and Pei Wang},
  doi          = {10.1016/j.matdes.2025.113741},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113741},
  shortjournal = {Mater. Des.},
  title        = {The interaction between local melting and helium bubble in radiated aluminium under dynamic tension at high temperature and strain rates},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigation on fabricating ni/Ni3Al/NiAl thin-walled
cup-shaped component by combining superplastic forming of ni/Ni2Al3
composite sheet with subsequent in-situ reaction. <em>MATDES</em>,
<em>252</em>, 113740. (<a
href="https://doi.org/10.1016/j.matdes.2025.113740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present study, a novel approach is proposed to fabricating Ni/Ni 3 Al/NiAl thin-walled cup-shape component based on superplastic forming of Ni/Ni 2 Al 3 composite sheet with heterogeneous bimodal grains. Firstly, Ni/Ni 2 Al 3 composite sheet with heterogeneous bimodal grains is prepared by means of hot pressing reaction synthesis from Ni and Al for 2 h at 630 ℃ under the pressure of 20 MPa and it is characterized by superplasticity at 750℃ at the strain rate of 1 × 10 - 3 to 1 × 10 - 2 s −1 . Subsequently, Ni/Ni 2 Al 3 composite sheet can be readily used to be made into the thin-walled cup-shaped components by gas forming. The Ni/Ni 2 Al 3 thin-walled cup-shape component is subjected to second-order in-situ reaction for 4 h at 1000℃ under the pressure of 20 MPa, and consequently the involved Ni/Ni 3 Al/NiAl thin-walled cup-shaped component is fabricated, where Ni 3 Al and NiAl phases are dominant. In particular, Ni 3 Al phase contributes to enhancing high-temperature strength and NiAl phase is responsible for bolstering high-temperature plasticity. The present work provides a novel approach for fabricating Ni/Ni 3 Al/NiAl thin-walled cup-shaped component.},
  archive      = {J_MATDES},
  author       = {Peng Lin and Pengle Kong and Bingyao Yan and Hongliang Yin and Dong Sun and Hao Feng and Qihan Zhang and Shuyong Jiang},
  doi          = {10.1016/j.matdes.2025.113740},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113740},
  shortjournal = {Mater. Des.},
  title        = {Investigation on fabricating Ni/Ni3Al/NiAl thin-walled cup-shaped component by combining superplastic forming of Ni/Ni2Al3 composite sheet with subsequent in-situ reaction},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mechanical properties of polymer-infiltrated ZrO2 ceramic
network improved by incorporation of SiO2 component. <em>MATDES</em>,
<em>252</em>, 113739. (<a
href="https://doi.org/10.1016/j.matdes.2025.113739">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polymer-infiltrated ZrO 2 ceramic networks, due to their similar elastic moduli and hardness with natural enamel, have become a promising material for dental restoration. However, since the couple between ZrO 2 and resin is difficult, the poor interface bonding of ZrO 2 /resin degrades the mechanical characteristics of polymer-infiltrated ZrO 2 ceramic networks. This study introduced SiO 2 into ZrO 2 as a scaffold to improve the coupling via the reaction of SiO 2 and silane coupling agents. The impacts of the SiO 2 concentration on the microstructures, the fracture characteristics, and mechanical properties of the porous ceramics and composites were investigated. The microstructures showed that ceramics and resins were bonded more tightly in PICNs with ZrO 2 /SiO 2 scaffold than PICNs with pure ZrO 2 scaffold. The flexural strengths of the composites were significantly improved by the addition of SiO 2 , which was attributed to the increased coupling degree. The composites with 20 mol.% SiO 2 as the porous ceramic exhibited the optimal mechanical properties, with flexural strength, elastic modulus, hardness, and fracture toughness values of 249.8 ± 24.3 MPa, 28.8 ± 4.0 GPa, 2.0 ± 0.2 GPa, and 2.6 ± 0.5 MPa·m 1/2 , respectively. This study provides valuable information for the preparation of polymer-infiltrated ZrO 2 ceramic networks with excellent performance for dental restorations.},
  archive      = {J_MATDES},
  author       = {Xinkai Cui and Xiaoyu Zhang and Lin Hu and Zhe Zhao and Kai Tang and Zhenyu Yang and Fu Wang and Jihua Chen and Lina Niu},
  doi          = {10.1016/j.matdes.2025.113739},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113739},
  shortjournal = {Mater. Des.},
  title        = {Mechanical properties of polymer-infiltrated ZrO2 ceramic network improved by incorporation of SiO2 component},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Phase transformation and recrystallization of cold-rolled
AISI 304L austenitic stainless steel during annealing. <em>MATDES</em>,
<em>252</em>, 113738. (<a
href="https://doi.org/10.1016/j.matdes.2025.113738">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Refining the heat-affected zone (HAZ) microstructure of thermomechanically welded cold-worked AISI 304L austenitic stainless steels (ASSs) improves the weld quality. This study explored the annealing behavior of cold-rolled AISI 304L ASSs through heat treatments over temperatures ranging from 600 °C to 1200 °C and holding times ranging from 2 min to 480 min. The microstructure was analyzed using optical microscopy and EBSD, and the deformation-induced martensite (DIM) content was evaluated using the ferrite scope. Vickers hardness values were correlated with the microstructure evolution following the Hall-Patch relationship. The grain size distribution and the kinetics of grain coarsening were analyzed. Results show that during annealing, the reverse transformation of DIM occurred, followed by static recrystallization of the γ-austenite phase. After recrystallization, grains coarsen with an activation energy of 133.8 kJ/mol, and grain size distribution fits a log-normal function. Nanoscale grains (&lt; 180 nm) were achieved in cold-rolled samples (67 % thickness reduction) annealed at 700 °C for 4 h. The δ-ferrite, primarily located at γ-grain boundaries, retarding their movement during recrystallization and coarsening. Finally, the δ-ferrite partially transformed into austenite and globularized during annealing. These findings show that the processes of phase transformation and recrystallization in cold-worked dual-phase steels are coupled.},
  archive      = {J_MATDES},
  author       = {Peng Wang and Muhammad Farrukh Siddiqui and Maria Cecilia Poletti and Norbert Enzinger},
  doi          = {10.1016/j.matdes.2025.113738},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113738},
  shortjournal = {Mater. Des.},
  title        = {Phase transformation and recrystallization of cold-rolled AISI 304L austenitic stainless steel during annealing},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuro-symbolic artificial intelligence in accelerated design
for 4D printing: Status, challenges, and perspectives. <em>MATDES</em>,
<em>252</em>, 113737. (<a
href="https://doi.org/10.1016/j.matdes.2025.113737">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {4D printing enables the creation of adaptive and reconfigurable devices by combining additive manufacturing with smart materials. This integration introduces challenges in designing printable, responsive materials and structures. Current research focuses on improving the responsiveness and mechanical performance of smart materials, but incremental advances often lack sufficient feedback for achieving specific properties, shapes, and performance targets. Inverse design has emerged as a strategy for determining material compositions and structural configurations to meet desired outputs, but its application remains limited to simple structures. Accelerating material and structural discovery is crucial for advancing 4D printing. Artificial intelligence (AI), especially machine learning (ML), offers promising solutions to address the complexity of 4D printing design. However, conventional AI approaches often lack logical reasoning, explainability, and interpretability. This review paper highlights recent achievements and challenges in 4D printing design and introduces neuro-symbolic AI as a promising approach. By combining ML&#39;s learning capabilities with the logical reasoning and semantic understanding of symbolic AI, this approach can enhance the exploration of advanced active materials and structures. The insights provided aim to guide future research toward optimizing 4D printing for broader applications and enhanced performance.},
  archive      = {J_MATDES},
  author       = {Oualid Bougzime and Christophe Cruz and Jean-Claude André and Kun Zhou and H. Jerry Qi and Frédéric Demoly},
  doi          = {10.1016/j.matdes.2025.113737},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113737},
  shortjournal = {Mater. Des.},
  title        = {Neuro-symbolic artificial intelligence in accelerated design for 4D printing: Status, challenges, and perspectives},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning inverse design of high-strength
mid-temperature ag-based solders. <em>MATDES</em>, <em>252</em>, 113736.
(<a href="https://doi.org/10.1016/j.matdes.2025.113736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional trial-and-error experimentation and computational methods are often inefficient for designing solders with specific properties, revealing the need for more effective design strategies. This work presents a novel inverse design framework for accelerating the discovery of mid-temperature (400–600 °C) Ag-based solders. A Wasserstein Autoencoder (WAE) generates candidate compositions, targeting melting temperatures within the 400–600 °C range through a Gaussian Mixture Model and neural network classifier. Yield strength is predicted using a stacking ensemble learning model, combining Multilayer Perceptron and Gradient Boosted Decision Trees with a Decision Tree meta -learner, achieving high accuracy, which was confirmed by experimental validation of four selected alloys. This data-driven approach demonstrates significant potential for the efficient design of high-performance solder materials.},
  archive      = {J_MATDES},
  author       = {Chengchen Jin and Kai Xiong and Yingwu Wang and Shunmeng Zhang and Yunyang Ye and Hui Fang and Aimin Zhang and Hua Dai and Yong Mao},
  doi          = {10.1016/j.matdes.2025.113736},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113736},
  shortjournal = {Mater. Des.},
  title        = {Machine learning inverse design of high-strength mid-temperature ag-based solders},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An overview of methods to qualitatively and quantitatively
characterize the structure of polymer-coated cardboards: Advantages and
limitations. <em>MATDES</em>, <em>252</em>, 113735. (<a
href="https://doi.org/10.1016/j.matdes.2025.113735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polymer-coated cardboards are increasingly replacing conventional plastics for packaging applications. Understanding and quantifying the complex structure of these multilayered materials is essential for assessing the coating quality and predicting the performance; however, it remains challenging. This review aims to gather the existing knowledge and advances in experimental techniques and methods developed to characterize the structure of polymer-coated cardboards by systematically highlighting their advantages and limitations. The first part presents the evaluation of the surface coating quality (i.e., its homogeneity and the presence or absence of defects), starting from the detection of surface defects in the coating layer to their visualization and quantification with techniques such as SEM and X-ray tomography. The second part focuses on the evaluation of the thickness of each layer making up the material, which is necessary for predictive modeling and the production of just-necessary food packaging, ranging from visualization approaches to methods that rely on physical measurements. The third part reviews methods for characterizing the cardboard porosity, which is a key property for further modeling approaches as the impregnation of the polymer depends on it.},
  archive      = {J_MATDES},
  author       = {Allison Vercasson and Sébastien Gaucel and Valérie Guillard and Hélène Angellier-Coussy},
  doi          = {10.1016/j.matdes.2025.113735},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113735},
  shortjournal = {Mater. Des.},
  title        = {An overview of methods to qualitatively and quantitatively characterize the structure of polymer-coated cardboards: Advantages and limitations},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Understanding effects of deformation parameters on dynamic
recrystallization-dependent superplasticity in an al-cu-li alloy.
<em>MATDES</em>, <em>252</em>, 113734. (<a
href="https://doi.org/10.1016/j.matdes.2025.113734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aluminum alloys with initial unrecrystallized structures generally exhibit better superplasticity and are produced more efficiently and cost-effectively than fully recrystallized ones. However, the underlying recrystallization and deformation mechanisms of dynamic recrystallization (DRX)-dependent superplastic aluminium alloys under varying deformation parameters are not yet fully understood. This study investigates the effects of deformation parameters, Al 3 Zr dispersoids, and coarse secondary particles on DRX and superplasticity in an Al-Cu-Li alloy. The alloy achieves a maximum elongation of 780 % at 430 °C and 0.002 s −1 , primarily due to continuous dynamic recrystallization (CDRX) and grain boundary sliding (GBS). Under optimal conditions, deformed grains transform into equiaxed recrystallized grains through sub-grain rotation and coalescence, with GBS dominating subsequent deformation. Lower Zener-Hollomon parameter (lnZ) conditions promote dynamic recovery (DRV) and sub-grain growth, hindering grain refinement and superplastic deformation. Conversely, higher lnZ values inhibit recrystallization due to insufficient thermal driving force and lower DRV, resulting in retained banded grains and reduced elongation. Cu-rich secondary phases enhance CDRX but lose efficacy with their dissolution and coarsening at low lnZ conditions. This work provides insights into DRX-dependent superplastic mechanisms and offers guidance for optimizing deformation parameters to enhance the performance of aluminum alloys.},
  archive      = {J_MATDES},
  author       = {Guotong Zou and Ruiqiang Zhang and Wei Wang and Jun Li and Lingying Ye},
  doi          = {10.1016/j.matdes.2025.113734},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113734},
  shortjournal = {Mater. Des.},
  title        = {Understanding effects of deformation parameters on dynamic recrystallization-dependent superplasticity in an al-cu-li alloy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joining inconel 718 and GRCop42: A framework for developing
transition compositions to avoid cracking and brittle phase formation.
<em>MATDES</em>, <em>252</em>, 113733. (<a
href="https://doi.org/10.1016/j.matdes.2025.113733">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distinct regions of high temperature strength and high thermal conductivity are required for components such as combustion chambers. Inconel 718 and GRCop42 are commonly used for such components. However, the bimetallic joining of these alloys has been shown to result in a liquid miscibility gap at the interface, which at select compositions can lead to brittle phase formation and cracking. In this work, CALPHAD modeling is used to predict regions of brittle phase formation in the Inconel 718–Ni–GRCop42 and Ni–Cu GRCop42 multi-component ternary systems, with experimental validation of the modeling provided by arc melting. Through characterization of arc melted sample microstructure combined with CALPHAD modeling, the solidification paths throughout the system are elucidated and a brittle phase and crack free compositional region is identified. Based on these results, a compositionally graded path consisting of two transition compositions is identified. Powder Laser Directed Energy Deposition is used to fabricate the Inconel 718–GRCop42 joint with the identified transition compositions, and the joint is subject to characterization in terms of composition profile, defects, grain morphology, present phases and microhardness. Results confirm the transition compositions circumvent brittle phase formation found in bimetallic Inconel 718–GRCop42 joints, thus overcoming the thermodynamic barrier of bimetallic joining.},
  archive      = {J_MATDES},
  author       = {Jakub Preis and Stephanie B. Lawson and Nick Wannenmacher and Somayeh Pasebani},
  doi          = {10.1016/j.matdes.2025.113733},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113733},
  shortjournal = {Mater. Des.},
  title        = {Joining inconel 718 and GRCop42: A framework for developing transition compositions to avoid cracking and brittle phase formation},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploration of MAB phase formation in the fe-y-al-b system
using thin film materials libraries. <em>MATDES</em>, <em>252</em>,
113731. (<a href="https://doi.org/10.1016/j.matdes.2025.113731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the recent theoretical and experimental advancements in MAB phase materials design we investigate the Fe-Y-Al-B system in search for the theoretically predicted (Fe 2/3 Y 1/3 ) 2 AlB 2 in-plane ordered MAB phase. We use combinatorial co-sputtering of thin film materials libraries from elemental targets on 100 mm diameter sapphire substrates at 700 °C followed by high-throughput X-ray diffraction and energy dispersive X-ray spectroscopy measurements. Selected samples from the materials libraries are further characterized by transmission electron microscopy and atom probe tomography. The MAB phase Fe 2 AlB 2 is realized in thin film form as large, elongated grains imbedded in an Fe-Y-Al-B matrix. However, in contrast to the theoretical thermodynamic stability calculations, no incorporation of Y into Fe 2 AlB 2 was detected.},
  archive      = {J_MATDES},
  author       = {Aurelija Mockute and Aleksander Kostka and Lamya Abdellaoui and Yujiao Li and Alireza B. Parsa and Florian Lourens and Christina Scheu and Alfred Ludwig},
  doi          = {10.1016/j.matdes.2025.113731},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113731},
  shortjournal = {Mater. Des.},
  title        = {Exploration of MAB phase formation in the fe-Y-al-B system using thin film materials libraries},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mitigating core energy losses in fe-si alloys fabricated by
direct energy deposition through oxide inclusions and abnormal goss
grain growth. <em>MATDES</em>, <em>252</em>, 113730. (<a
href="https://doi.org/10.1016/j.matdes.2025.113730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In traditional electrical steel production oxide inclusions are conventionally perceived as deleterious elements for the functional and structural properties. The present work describes the fabrication of a high silicon content electrical steel alloy (Fe-6.5wt%Si) using directed energy deposition (DED), coupled with oxide inclusions to mitigate core energy losses. Abnormal Grain Growth (ABG) was observed after thermal post-processing at 1000 °C for 24 h (1000–24), together with the creation of oxide inclusions mainly around the grain boundaries. Magnetic properties were assessed through dynamic and quasi-static measurements for both as-printed (AP) and 1000–24 samples. The quasi-static analysis revealed hysteresis losses of 206.9 J/m 3 for the AP and 19.02 J/m 3 for the 1000–24, with maximum flux densities of 1.295 T and 1.031 T, at the magnetic field of 3000 A/m. Dynamic magnetic analysis demonstrated an improvement of 39.2% in the total core losses of the 1000–24 sample (2088.8 J/m 3 ), compared to the AP sample (3436.9 J/m 3 ). The microstructure of the 1000–24 sample revealed the formation of Goss texture via ABG, ultimately decreasing the static hysteresis loss. Furthermore, an improved electrical resistivity compare to conventional electrical steel alloys was demonstrated at 119 μΩcm for the 1000-24 sample, and 105 μΩcm for the AP sample. This work introduces a promising avenue to minimize core energy losses by incorporating oxide inclusions and ABG Goss texture in additively manufactured soft magneitc components after thermal post-processing.},
  archive      = {J_MATDES},
  author       = {Xiaojun Shen and Konstantinos A. Liogas and Verner Soh Qun Liang and Yung Zhen Lek and Fanbo Meng and Yiming Shen and John E. Huber and Roger C. Reed and Pei Wang and Alexander M. Korsunsky and Christopher H.T. Lee},
  doi          = {10.1016/j.matdes.2025.113730},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113730},
  shortjournal = {Mater. Des.},
  title        = {Mitigating core energy losses in fe-si alloys fabricated by direct energy deposition through oxide inclusions and abnormal goss grain growth},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biomimetic kagome-gyroid interpenetrating metamaterial for
tailoring lightweight and mechanical performance. <em>MATDES</em>,
<em>252</em>, 113729. (<a
href="https://doi.org/10.1016/j.matdes.2025.113729">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel interpenetrating Kagome-Gyroid (K-G) structure designed to optimize lightweight, high-strength materials. Inspired by natural biomimetic structures, such as the microstructure of butterfly wings and cancellous bone, which are known for their lightweight and strength properties, the K-G structure combines the shear resistance of the Kagome lattice with the high specific strength and stiffness of the Gyroid lattice. The optimized K-G structure demonstrates a 49.5 % increase in specific energy absorption and a 35.6 % improvement in energy absorption efficiency compared to conventional materials, highlighting its superior potential for high-impact applications. Experimental and simulation results reveal that geometric parameters significantly influence the failure and fracture behavior of the structure, particularly affecting its energy absorption characteristics. The study also investigates the distribution patterns of surface roughness and internal defects during the laser powder bed fusion (L-PBF) manufacturing process, highlighting their potential impact on the mechanical performance of the final structure. This novel design provides a promising foundation for the development of advanced materials with superior energy absorption capabilities, making it ideal for high-impact applications in aerospace, rail transportation, and automotive industries, where lightweight and enhanced mechanical performance are critical.},
  archive      = {J_MATDES},
  author       = {Chang Wang and Xin Lu and Xiaoyi Yang and Hanning Zuo and Mengnie Victor Li and Xin Zhao and Tao Peng and Xing Lu},
  doi          = {10.1016/j.matdes.2025.113729},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113729},
  shortjournal = {Mater. Des.},
  title        = {Biomimetic kagome-gyroid interpenetrating metamaterial for tailoring lightweight and mechanical performance},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combined x-ray microdiffraction and micromechanical testing
for direct measurement of thin film elastic constants. <em>MATDES</em>,
<em>252</em>, 113720. (<a
href="https://doi.org/10.1016/j.matdes.2025.113720">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direct measurement of elastic constants for thin films is still far from routine and poses significant technical and analytical challenges compared to bulk materials. Ab initio Density Functional Theory calculations offer theoretical input, however, discrepancies between model systems and real-world properties persist, primarily due to a lack of available experimental data for newly emerging material systems. Moreover, computationally affordable models are typically limited to defect-free single crystals, omitting microstructural effects that strongly influence the material’s behavior. This study addresses this gap by proposing a novel experimental approach to measure direction-dependent elastic constants, combining synchrotron microdiffraction and micropillar compression, testing a polycrystalline face-centered cubic TiN 0.8 B 0.2 thin film, where linear elastic failure prevails. We have established an advanced in-situ testing environment to continuously record the load–displacement of the indenter while simultaneously collecting the material’s deformation response to uniform uniaxial compression. This dynamic approach allows the evaluation of the orientation-dependent elastic strain components and the macroscopic uniaxial compressive stresses, each over time, enabling a differential analysis to assess the elastic and X-ray elastic constants. The excellent agreement between experimental and ab initio data solidifies the here-proposed robust method for direct elastic constant measurements, which is crucial for advancements in thin film material testing.},
  archive      = {J_MATDES},
  author       = {Rebecca Janknecht and Rainer Hahn and Nikola Koutná and Juraj Todt and Michael Meindlhumer and Anton Davydok and Helmut Riedl and Jozef Keckes and Paul H. Mayrhofer},
  doi          = {10.1016/j.matdes.2025.113720},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113720},
  shortjournal = {Mater. Des.},
  title        = {Combined X-ray microdiffraction and micromechanical testing for direct measurement of thin film elastic constants},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and additive manufacture of patient-specific head
phantom for radiotherapy. <em>MATDES</em>, <em>252</em>, 113719. (<a
href="https://doi.org/10.1016/j.matdes.2025.113719">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D printing has extensive potential in medical fields in creating prototypes for treatment planning and in this study, the materials and design of a modular head phantom for dosimetry quality assurance in radiotherapy of cancer treatment were described. Till now, the challenge in medical phantoms lies in their ability to accurately represent the anatomical and radiodensity heterogeneity of actual human tissues using representative synthetic materials and topology. Here, polylactic acid was employed for soft tissue representation, while a new custom material mix of Acrylonitrile Butadiene Styrene and bismuth was developed to replicate the higher Hounsfield Unit values characteristic of bone. Appropriate 3D printing infill densities derived from their respective linear regressions were implemented to achieve specific target radiodensities. To facilitate the efficient assembly, structural and anatomical fidelity, the head phantom was printed in 39 consecutive sections, post-processed and scanned using computed tomography (CT). Validation confirmed the success of the fabrication process, achieving both anatomical accuracy and radiodensity consistency, even in regions with complex geometries and high heterogeneity. This study marks a significant step in advancing the use of 3D printing and modularity design that can be patient-specific in developing cancer treatment processes and contributes to safer and more effective radiotherapy.},
  archive      = {J_MATDES},
  author       = {Brandon Zhan Hong Lin and Ee Teng Zhang and Huiyan Ng and Mervin Yen Leong Tan and Zheng Han Soh and Yun Ming Wong and Clifford Ghee Ann Chua and Kah Seng Lew and Eric Pei Ping Pang and Hong Qi Tan and Sung Yong Park and Bing Feng Ng and Wei Yang Calvin Koh},
  doi          = {10.1016/j.matdes.2025.113719},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113719},
  shortjournal = {Mater. Des.},
  title        = {Design and additive manufacture of patient-specific head phantom for radiotherapy},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New insights into structural and spectroscopic
characteristics of cu2+ doped β-Ca3(PO4)2: Correlation between cu2+
concentration and material properties. <em>MATDES</em>, <em>252</em>,
113718. (<a href="https://doi.org/10.1016/j.matdes.2025.113718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Doping β-tricalcium phosphate (β-TCP) with copper (Cu 2+ ) has great potential in various applications due to its rich chemistry. However, the doping characteristics are rarely studied in detail and are yet to be fully understood, creating a gap in the existing knowledge of these multifunctional materials. In this work, a series of Cu 2+ doped β-TCP (Cu x -TCPs) were prepared and comprehensively characterized to investigate the correlation between Cu 2+ doping and the material properties. Also, the synthesis of Cu x -TCPs was modeled using thermodynamic equilibrium calculations to investigate their formation pathways. The calculations predicted a possible inclusion of Cu 2+ in intermediate phosphate phases during the material synthesis, depending on the temperature. The structural analyses revealed lattice shrinkage due to the Cu 2+ doping and that Cu 2+ occupied Ca4 and Ca5 sites in the β-TCP crystal. The vibrational spectroscopy of the Cu x -TCPs showed noticeable deformation of ν 1 band of P O 4 3 - ligand. The ultraviolet–visible absorption analysis revealed a reduction in the band gap energy induced by Cu 2+ doping. Photoluminescence spectroscopy demonstrated an enhanced emission tunability of Cu x -TCPs in the blue and orange–red regions depending on Cu 2+ concentration. These findings are a step toward a deeper understanding of the structure–property relationships of Cu 2+ doped β-TCPs and can play a significant role in their multidisciplinary applications.},
  archive      = {J_MATDES},
  author       = {Sana Elbashir and Roushdey Salh and Britt M. Andersson},
  doi          = {10.1016/j.matdes.2025.113718},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113718},
  shortjournal = {Mater. Des.},
  title        = {New insights into structural and spectroscopic characteristics of cu2+ doped β-Ca3(PO4)2: Correlation between cu2+ concentration and material properties},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Material removal and deformation mechanism in multiple
nanoscratches of single crystal MgAl2O4. <em>MATDES</em>, <em>252</em>,
113717. (<a href="https://doi.org/10.1016/j.matdes.2025.113717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single crystal MgAl 2 O 4 requires ultra-precision machining to achieve dimensional accuracy and surface quality due to its high hardness and brittleness. To investigate the effect of multi-abrasive scratch sequences on the material removal and deformation mechanism of single crystal MgAl 2 O 4 in ultra-precision machining. Multiple nanoscratches experiments with different sequences were conducted to demonstrate the randomness of the scratch sequence occurrence at the abrasive tip in ultra-precision machining. The interactions between multiple nanoscratches with different sequences were analyzed for their effects on the material deformation characteristics and surface morphologies of single crystal MgAl 2 O 4 . Additionally, theoretical models for the penetration depth of multiple nanoscratches with different sequences were established. The results show that multiple nanoscratches with different sequences affect the material removal and deformation mechanism of single crystal MgAl 2 O 4 , and the predictions of the penetration depth theoretical model align closely with the experimental results. TEM analysis results show that the subsurface deformation mechanism in the ductile removal region during multiple nanoscratches is primarily characterized by the transformation of single crystals into poly-crystalline of nanocrystalline.},
  archive      = {J_MATDES},
  author       = {Jun Zhao and Yeshen Lan and Marian Wiercigroch and Wuqian Li and Shiwei Chen and Oltmann Riemer and Bernhard Karpuschewski},
  doi          = {10.1016/j.matdes.2025.113717},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113717},
  shortjournal = {Mater. Des.},
  title        = {Material removal and deformation mechanism in multiple nanoscratches of single crystal MgAl2O4},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polyetheretherketone biomaterials and their current
progress, modification-based biomedical applications and future
challenges. <em>MATDES</em>, <em>252</em>, 113716. (<a
href="https://doi.org/10.1016/j.matdes.2025.113716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polyetheretherketone (PEEK), a high-performance polymer biomaterial, has demonstrated significant potential for biomedical applications due to its excellent resistance to high temperature, friction, and corrosion. However, the scope of its biomedical applications is limited by its inherent biological inertness. To address this limitation and further enhance both the biocompatibility and mechanical properties of PEEK, various technical approaches-such as surface modification and the development of composite materials-have been extensively explored. These advancements aim to broaden the future applications of PEEK as a biomaterial. PEEK is expected to play a pivotal role in diverse fields, including cardiovascular disease treatment, ophthalmic implants, biosensing devices, and 3D printing. Besides, its use in orthopedic and dental clinics is expected to expand significantly. Despite these promising developments, there is currently a lack of comprehensive review articles that summarize the potential future biomedical applications of modified PEEK implants. To address this gap, we conducted this review to systematically examine the latest research findings on modified PEEK implants in the medical field over the past decade and their future prospects in biomedical applications.},
  archive      = {J_MATDES},
  author       = {Zuge Yang and Weiwei Guo and Wenhao Yang and Jianye Song and Wenhui Hu and Kun Wang},
  doi          = {10.1016/j.matdes.2025.113716},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113716},
  shortjournal = {Mater. Des.},
  title        = {Polyetheretherketone biomaterials and their current progress, modification-based biomedical applications and future challenges},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Microstructural analysis and design of electroplated-cu
micropillar under different process variables and pattern structures.
<em>MATDES</em>, <em>252</em>, 113715. (<a
href="https://doi.org/10.1016/j.matdes.2025.113715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cu micropillars, designed to meet the fine pitch demands of high-performance high-density semiconductor devices, offer superior thermal dissipation and electromigration resistance compared to conventional solder bumps. In microelectronic packaging, the Cu micropillar bump pitch and diameter are adjusted as needed; however, achieving a uniform height across all micropillars for reliable signal transmission remains a major challenge. In this study, the morphology of Cu micropillars electrodeposited in pores was patterned for various structures under different deposition conditions. The micropillar morphological characteristics were measured via scanning electron microscopy, revealing tendencies in micropillar height with respect to the deposition conditions and micropore structure. COMSOL-Multiphysics, a finite-element-analysis-based simulation software, was used to verify the ion concentrations and electrolyte distributions in the structure according to the deposition conditions and micropore structure. The methodology and findings of this study could be used to predict, control, and design the microstructural thickness deviations in processes requiring precise micro-plating structures.},
  archive      = {J_MATDES},
  author       = {Sangyeun Park and Byungkwon Chun and Sunbum Kim and Hak-Sung Kim and Hongyun So},
  doi          = {10.1016/j.matdes.2025.113715},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113715},
  shortjournal = {Mater. Des.},
  title        = {Microstructural analysis and design of electroplated-cu micropillar under different process variables and pattern structures},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Programmable control of soft magnetic helical microrobot
from microfluidics. <em>MATDES</em>, <em>252</em>, 113707. (<a
href="https://doi.org/10.1016/j.matdes.2025.113707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft magnetic helical microrobots (SMHMs) have received increasing attention due to their body compliance, high controllability, and rotation-based motion. Their accurate and programmable control is expected for complex environments facing practical applications. We fabricate the SMHM easily through microfluidics, and build a Helmholtz coil system with a user-friendly graphical user interface (GUI) to programmatically control them. By controlling the currents of three-dimensional Helmholtz coil, the rotation speed and direction of the uniform rotating magnetic field generated by the coil can be customized. Besides, SMHMs can rotate in the direction perpendicular to the rotation axis of the magnetic field, and their speeds increase with the magnetic rotation frequency. Thus, the accurate manipulation of the SMHMs’ speed and direction will be achieved just by regulating the coil current. Further, a GUI combined with path planning algorithm is developed to control SMHMs by programming the currents, planning the optimal path for SMHMs, and monitoring their real-time motions. Even non-specialists could easily manipulate SMHMS to move along the desired path and realize the controllable obstacle avoidance movement, which is programmable, user-friendly, and potential for complex scenarios. These characteristics may enable more accurate, effective, and safe work of SMHMs in various fields.},
  archive      = {J_MATDES},
  author       = {Yikai Wu and Can Wang and Wenhui Zhang and Jiahui Yang and Hainiu Zhu and Linlin Xia and Jie Wang},
  doi          = {10.1016/j.matdes.2025.113707},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113707},
  shortjournal = {Mater. Des.},
  title        = {Programmable control of soft magnetic helical microrobot from microfluidics},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). Ballistic impact performance of kevlar®/UHMWPE hybrid
composite panels with a liquid thermoplastic resin, elium®.
<em>MATDES</em>, <em>252</em>, 113706. (<a
href="https://doi.org/10.1016/j.matdes.2025.113706">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the ballistic impact performance of composite panels with novel liquid Methyl methacrylate (MMA) (Elium®) thermoplastic resin. The panels, which include Kevlar ® (Kevlar) and ultra-high molecular weight polyethylene (UHMWPE), and hybrids with their combination (Kevlar/UHMWPE and UHMWPE/Kevlar), were manufactured with different numbers of layers (16 and 24) using vacuum-assisted resin transfer. These panels were tested against 0.38 lead round nose (300 ± 15 m/s) and 0.357 semi-jacketed soft point flat (550 ± 15 m/s) projectiles. The study assesses the ballistic impact performance of single fibre reinforced and the influence of hybridisation through various parameters such as, damage patterns, back face deformation, energy absorption, and residual velocity. The results reveal that 16 and 24 layer panels effectively defeated 0.38 projectile with relatively lower back face deformation while showing perforations for 0.357 projectile with varying residual velocities for different panel configurations. The hybrid combination of Kevlar/UHMWPE with Kevlar on the front demonstrated higher energy absorption with low residual velocity, leveraging the superior energy absorption capability of Kevlar and better stretching from UHMWPE. This study not only underscores the potential of Elium® resin-based composite panels for ballistic protection but also emphasises the crucial role of reinforcement hybridisation in enhancing the ballistic performance.},
  archive      = {J_MATDES},
  author       = {Aswani Kumar Bandaru and Dinesh Kumar Kothandan and Hemant Chouhan and Hong Ma and Ronan M. O’Higgins},
  doi          = {10.1016/j.matdes.2025.113706},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113706},
  shortjournal = {Mater. Des.},
  title        = {Ballistic impact performance of Kevlar®/UHMWPE hybrid composite panels with a liquid thermoplastic resin, elium®},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unveiling processing–property relationships in laser powder
bed fusion: The synergy of machine learning and high-throughput
experiments. <em>MATDES</em>, <em>252</em>, 113705. (<a
href="https://doi.org/10.1016/j.matdes.2025.113705">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving desired mechanical properties in additive manufacturing requires many experiments and a well-defined design framework becomes crucial in reducing trials and conserving resources. Here, we propose a methodology embracing the synergy between high-throughput (HT) experimentation and hierarchical machine learning (ML) to unveil the complex relationships between a large set of process parameters in Laser Powder Bed Fusion (LPBF) and selected mechanical properties (tensile strength and ductility). The HT method envisions the fabrication of small samples for rapid automated hardness and porosity characterization, and a smaller set of tensile specimens for more labor-intensive direct measurement of yield strength and ductility. The ML approach is based on a sequential application of Gaussian processes (GPs) where the correlations between process parameters and hardness/porosity are first learnt and subsequently adopted by the GPs that relate strength and ductility to process parameters. Finally, an optimization scheme is devised that leverages these GPs to identify the process parameters that maximize combinations of strength and ductility. By founding the learning on larger “easy-to-collect” and smaller “labor-intensive” data, we reduce the reliance on expensive characterization and enable exploration of a large processing space. Our approach is material-agnostic and herein we demonstrate its application on 17-4PH stainless steel.},
  archive      = {J_MATDES},
  author       = {Mahsa Amiri and Zahra Zanjani Foumani and Penghui Cao and Lorenzo Valdevit and Ramin Bostanabad},
  doi          = {10.1016/j.matdes.2025.113705},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113705},
  shortjournal = {Mater. Des.},
  title        = {Unveiling processing–property relationships in laser powder bed fusion: The synergy of machine learning and high-throughput experiments},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Udimet 720Li as a potential alternative for optimised
aeroengine turbines: Thermophysical and thermomechanical
characterisation under wide-ranging testing conditions. <em>MATDES</em>,
<em>252</em>, 113700. (<a
href="https://doi.org/10.1016/j.matdes.2025.113700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The need to reduce fuel consumption and emissions is driving advances in aeroengine performance. Efficiency gains are limited by the capacity of the turbine material to withstand the high thermomechanical loads of the combustion process. Nickel-based alloy Udimet 720Li has emerged as a promising alternative to the most widely used Inconel 718 for critical aeroengine components. Nonetheless, its material properties under industry-relevant conditions remain understudied, hindering industrial implementation. Furthermore, discrepancies in the methodology for applying adiabatic heating correction in thermomechanical tests on nickel-based alloys prevent comparability of studies and alloys. This paper presents the thermophysical and thermomechanical properties of forged and heat-treated Udimet 720Li to enable advanced aeroengine design and manufacture. A novel adiabatic heating correction procedure is also proposed for thermomechanical tests. Thermophysical properties (specific heat, density, diffusivity, thermal expansion, and conductivity) were characterised for temperatures 20–1200 °C. Thermomechanical properties were obtained for temperatures 20–1100 °C and strain rates 0.01–100 s −1 with cylinder compression tests. The results show that Udimet 720Li exhibits higher thermomechanical properties than Inconel 718 at elevated temperatures and can withstand greater in-service temperatures (8–23 %) due to the higher γ ’ strengthening phase content which remains stable up to 760 °C.},
  archive      = {J_MATDES},
  author       = {Gorka Ortiz-de-Zarate and Idriss Tiba and Aitor Madariaga and Arantza Linaza and Ainhara Garay and Guénaël Germain and Pedro J. Arrazola},
  doi          = {10.1016/j.matdes.2025.113700},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113700},
  shortjournal = {Mater. Des.},
  title        = {Udimet 720Li as a potential alternative for optimised aeroengine turbines: Thermophysical and thermomechanical characterisation under wide-ranging testing conditions},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interfacial adhesion between dissimilar thermoplastics
fabricated via material extrusion-based multi-material additive
manufacturing. <em>MATDES</em>, <em>252</em>, 113688. (<a
href="https://doi.org/10.1016/j.matdes.2025.113688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-material additive manufacturing (MMAM) enables the design of materials with tunable mechanical performance by fabricating multiple dissimilar materials in a single print. MMAM has been utilized to fabricate components with unique mechanical properties for applications such as damage detection, medical devices, sensors, and soft robotics. However, the bonding strength between dissimilar polymeric materials strongly depends on the material combination and is typically lower than the material strength of the constituents. This study investigates the interfacial adhesion between two thermoplastics fabricated via material extrusion (ME)-based MMAM by quantifying the interface bonding strength using mechanical tests and polymer adhesion theory-based correlation analysis. Experimental results showed that the polylactic acid (PLA)-polyethylene terephthalate glycol (PETG), PETG-polycarbonate (PC) and PLA-PC material combinations exhibit bonding strengths that are close to or exceed their constituent’s material strength. Material combinations that include polypropylene (PP) and polyethylene (PE) exhibited bonding strengths of nearly two magnitudes lower than those of PLA-PETG, PETG-PC, and PLA-PC. The microstructural images of the samples showed that the most compatible combinations exhibited a smooth, gradient interface indicating the importance of nano-scale adhesion mechanisms. Based on Hansen solubility parameters and the coefficient of thermal expansion (CTE), we observed the correlation between wettability and physical adsorption, intermolecular diffusion, thermal stress, and the interface bonding strength. The wettability and physical adsorption feature extracted from the solubility parameters showed the highest correlation with the interface bonding strength. Furthermore, we observed that the smaller the difference in solubility parameters and CTE between two thermoplastics fabricated via ME, the more compatible the two thermoplastics are.},
  archive      = {J_MATDES},
  author       = {Felix Richter and Dazhong Wu},
  doi          = {10.1016/j.matdes.2025.113688},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113688},
  shortjournal = {Mater. Des.},
  title        = {Interfacial adhesion between dissimilar thermoplastics fabricated via material extrusion-based multi-material additive manufacturing},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Additive manufacturing of metal matrix composites.
<em>MATDES</em>, <em>252</em>, 113609. (<a
href="https://doi.org/10.1016/j.matdes.2025.113609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although Metal matrix composites (MMCs) are superior to most sought-after metallic alloys, their challenging fabricability has limited their widespread use in bulk-form applications. Among the many advanced fabrication techniques, Additive Manufacturing (AM), owing to its unique capabilities to produce near-net shapes, has drawn significant traction in the past two decades, especially for materials that are difficult to process using traditional methods. However, unlike pure metal/alloy systems, MMCs are highly sensitive to the processing conditions prevailing in AM techniques due to factors such as the high melting point of reinforcement particles and the potential for in-situ reactions. Therefore, it may be a while before metal matrix composites are commercially produced via AM. This review will discuss the current state-of-the-art design, fabricability, and performance of various additively manufactured Metal matrix composites (AMMCs). A particular focus will be on microstructural evolution and microstructure-property relationships. The most employed AM techniques, such as directed energy deposition, powder bed fusion, binder jetting, sheet lamination, and solid-state friction stir processing, are fundamentally different in terms of thermo-kinetics, forming the perspective for this review. A detailed comparison of microstructural evolution and process parameter optimization, including feedstock preparation methods and the role of machine learning and modeling among the different AM processes, is also presented. Finally, a critical evaluation of emerging AM technologies for MMCs is also provided, highlighting their potential advantages and challenges.},
  archive      = {J_MATDES},
  author       = {Mohan Sai Kiran Kumar Yadav Nartu and Priyanshi Agrawal},
  doi          = {10.1016/j.matdes.2025.113609},
  journal      = {Materials &amp; Design},
  month        = {4},
  pages        = {113609},
  shortjournal = {Mater. Des.},
  title        = {Additive manufacturing of metal matrix composites},
  volume       = {252},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="mla---22">MLA - 22</h2>
<ul>
<li><details>
<summary>
(2025). Predicting classification errors using NLP-based machine
learning algorithms and expert opinions. <em>MLA</em>, <em>19</em>,
100630. (<a href="https://doi.org/10.1016/j.mlwa.2025.100630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various intentional and unintentional biases of humans manifest in classification tasks, such as those related to risk management. In this paper we demonstrate the role of ML algorithms when accomplishing these tasks and highlight the role of expert know-how when training the staff as well as, and very importantly, when training and fine-tuning ML algorithms. In the process of doing so and when facing well-known inefficiencies of the traditional F1 score, especially when working with unbalanced datasets, we suggest a modification of the score by incorporating human-experience-trained algorithms, which include both expert-trained algorithms (i.e., with the involvement of expert experiences in classification tasks) and staff-trained algorithms (i.e., with the involvement of experiences of those staff who have been trained by experts). Our findings reveal that the modified F1 score diverges from the traditional staff F1 score when the staff labels exhibit weak correlation with expert labels, which indicates insufficient staff training. Furthermore, the Long Short-Term Memory (LSTM) model outperforms other classifiers in terms of the modified F1 score when applied to the classification of textual narratives in consumer complaints.},
  archive      = {J_MLA},
  author       = {Peiheng Gao and Chen Yang and Ning Sun and Ričardas Zitikis},
  doi          = {10.1016/j.mlwa.2025.100630},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100630},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predicting classification errors using NLP-based machine learning algorithms and expert opinions},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning framework for accurate COVID-19
classification in CT-scan images. <em>MLA</em>, <em>19</em>, 100628. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background In response to the global COVID-19 pandemic, we have introduced a binary classification model that employs convolutional layers to differentiate between normal cases and COVID-19-infected cases. Our primary aim was to address the urgent need for a highly efficient and accurate diagnostic tool to combat the widespread outbreak of COVID-19. Methods To achieve the background, we proposed a convolutional structure that comprises 10 layers in the encoder and 3 dense layers in the decoder. We conducted comprehensive experiments and evaluations using four distinct datasets. Results The outcomes of our study consistently demonstrated remarkable performance, with our proposed model achieving an accuracy of 89.00 %, a sensitivity of 0.95, a specificity of 0.88, and an impressive AUC of 0.92. Notably, Dataset 4 yielded the most promising results among all datasets, underscoring the effectiveness of our approach. Conclusion Our research substantiates the superiority of our model over previous methodologies and pre-trained models. Furthermore, it significantly contributes to global efforts in combating COVID-19 by providing an advanced diagnostic tool. This work also paves the way for future breakthroughs in the field of medical image analysis.},
  archive      = {J_MLA},
  author       = {Shirin Kordnoori and Maliheh Sabeti and Hamidreza Mostafaei and Saeed Seyed Agha Banihashemi},
  doi          = {10.1016/j.mlwa.2025.100628},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100628},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A deep learning framework for accurate COVID-19 classification in CT-scan images},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “machine learning for sports betting: Should
model selection be based on accuracy or calibration?” [Machine learning
with applications volume 16, june 2024, 100539]. <em>MLA</em>,
<em>19</em>, 100627. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MLA},
  author       = {Conor Walsh and Alok Joshi},
  doi          = {10.1016/j.mlwa.2025.100627},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100627},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Corrigendum to “Machine learning for sports betting: Should model selection be based on accuracy or calibration?” [Machine learning with applications volume 16, june 2024, 100539]},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noninvasive estimation of blood glucose and HbA1c using
quantum machine learning technique. <em>MLA</em>, <em>19</em>, 100626.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we developed models with quantum and classical machine learning algorithms to detect blood glucose and HbA1c noninvasively from ten-second fingertip video by deploying a smartphone and near-infrared spectroscopy. Using our developed framework, we collected 136 participants’ ten-second fingertip videos with their baseline blood glucose and HbA1c levels after getting approval from the Institutional Review Board (IRB). We extracted 45 PPG (photoplethysmography) features from the ten-second fingertip video by using the Beer–Lambert law and applied feature engineering to select the most important features. We applied two Quantum Machine Learning (QML) based algorithms and seven Classical Machine Learning (CML) based algorithms for estimating blood glucose and HbA1c levels. The application of QML for the noninvasive estimation of blood glucose and HbA1c is a new and unexplored research area. Among all developed models, the Quantum Support Vector Machine performs best for predicting both blood glucose and HbA1c. The Quantum Support Vector Machine provides an accuracy of 89.30% and an average k-fold cross-validation score of 92.50% for blood glucose prediction and an accuracy of 96.30% and an average k-fold cross-validation score of 92.50% for HbA1c prediction. Our study signifies the potential of QML algorithms in noninvasive health monitoring, especially in the less-explored area of blood glucose and HbA1c estimation. The high performance of the developed models paves the way for advancing noninvasive techniques for measuring blood constituents. These findings offer promising applications in personalized healthcare, including continuous monitoring, early disease diagnosis, and more convenient management of chronic conditions.},
  archive      = {J_MLA},
  author       = {Parama Sridevi and Masud Rabbani and Md Hasanul Aziz and Paramita Basak Upama and Sayed Mashroor Mamun and Rumi Ahmed Khan and Sheikh Iqbal Ahamed},
  doi          = {10.1016/j.mlwa.2025.100626},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100626},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Noninvasive estimation of blood glucose and HbA1c using quantum machine learning technique},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiobjective continuation method to compute the
regularization path of deep neural networks. <em>MLA</em>, <em>19</em>,
100625. (<a href="https://doi.org/10.1016/j.mlwa.2025.100625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability (due to the smaller number of relevant features), and robustness. For linear models, it is well known that there exists a regularization path connecting the sparsest solution in terms of the ℓ 1 norm, i.e., zero weights and the non-regularized solution. Recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ( ℓ 1 norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the ℓ 1 norm and the large number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto front for the above-mentioned objectives in a very efficient manner for high-dimensional DNNs with millions of parameters. We present numerical examples using both deterministic and stochastic gradients. We furthermore demonstrate that knowledge of the regularization path allows for a well-generalizing network parametrization.},
  archive      = {J_MLA},
  author       = {Augustina Chidinma Amakor and Konstantin Sonntag and Sebastian Peitz},
  doi          = {10.1016/j.mlwa.2025.100625},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100625},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A multiobjective continuation method to compute the regularization path of deep neural networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Apply a deep learning hybrid model optimized by an improved
chimp optimization algorithm in PM2.5 prediction. <em>MLA</em>,
<em>19</em>, 100624. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PM 2.5 pollution in the atmosphere not only contaminates the environment but also seriously affects human health. Therefore, studying how to accurately predict future PM 2.5 concentrations holds significant importance and practical value. This paper innovatively P M 2 . 5 proposes a high-accuracy prediction model: RF-ICHOA-CNN-LSTM-Attention. First, the Random Forest (RF) model is utilized to evaluate the importance of air pollution and meteorological features and select more suitable input features. Subsequently, a one-dimensional convolutional neural network (1DCNN) with efficient feature extraction capability is used to extract dynamic features from sequences. The extracted feature vector sequences are then fed into a Long Short-Term Memory Network (LSTM). After the LSTM, an Attention Mechanism is incorporated to assign different weights to the input features, emphasizing the role of the important features. Additionally, the Improved Chimp Optimization Algorithm (IChOA) is employed to optimize the number of neurons in the two hidden layers of LSTM, the learning rate, and the number of training epochs. The experimental results on 12 test functions demonstrate that the optimization performance of IChOA is better than that of ChOA and the representative swarm optimization algorithms used for comparison. In the case of PM 2.5 predictions in Yining and Beijing, experimental results show that the proposed model achieved the best performance in terms of RMSE, MAE, and R 2 This indicates its excellent prediction accuracy and generalization capability, Thus proving its effectiveness in predicting PM 2.5 concentration in the real world.},
  archive      = {J_MLA},
  author       = {Ming Wei and Xiaopeng Du},
  doi          = {10.1016/j.mlwa.2025.100624},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100624},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Apply a deep learning hybrid model optimized by an improved chimp optimization algorithm in PM2.5 prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning techniques and multi-objective programming
to select the best suppliers and determine the orders. <em>MLA</em>,
<em>19</em>, 100623. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selection of appropriate suppliers and allocation the orders among them have become the two key strategic decisions regarding purchasing. In this study, a two-phase integrated approach is proposed for solving supplier selection and order allocation problems. Phase 1 contains four techniques from statistics and Machine Learning (ML), including Auto-Regressive Integrated Moving Average, Random Forest, Gradient Boosting Regression, and Long Short-term Memory for forecasting the demands, using large amounts of real historical data. In Phase 2, suppliers’ qualitative weights are determined by a fuzzy logic model. Then, a new multi-objective programming model is designed, considering multiple periods and products. In this phase, the results of Phase 1 and the results of the fuzzy model are utilized as inputs for the multi-objective model. The weighted-sum method is applied for solving the multi-objective model. The results show Random Forest model leads to more accurate predictions than the other examined models in this study. In addition, based on the results, the selection of the forecasting techniques and different weights of suppliers affect both supplier selection and the related orders.},
  archive      = {J_MLA},
  author       = {Asma ul Husna and Saman Hassanzadeh Amin and Ahmad Ghasempoor},
  doi          = {10.1016/j.mlwa.2025.100623},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100623},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning techniques and multi-objective programming to select the best suppliers and determine the orders},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safety analysis in the era of large language models: A case
study of STPA using ChatGPT. <em>MLA</em>, <em>19</em>, 100622. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can safety analysis leverage Large Language Models (LLMs)? This study examines the application of Systems Theoretic Process Analysis (STPA) to Automatic Emergency Brake (AEB) and Electricity Demand Side Management (DSM) systems, utilising Chat Generative Pre-Trained Transformer (ChatGPT). We investigate the impact of collaboration schemes, input semantic complexity, and prompt engineering on STPA results. Comparative results indicate that using ChatGPT without human intervention may be inadequate due to reliability issues. However, with careful design, it has the potential to outperform human experts. No statistically significant differences were observed when varying the input semantic complexity or using domain-agnostic prompt guidelines. While STPA-specific prompt engineering produced statistically significant and more pertinent results, ChatGPT generally yielded more conservative and less comprehensive outcomes. We also identify future challenges, such as concerns regarding the trustworthiness of LLMs and the need for standardisation and regulation in this field. All experimental data are publicly accessible.},
  archive      = {J_MLA},
  author       = {Yi Qi and Xingyu Zhao and Siddartha Khastgir and Xiaowei Huang},
  doi          = {10.1016/j.mlwa.2025.100622},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100622},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Safety analysis in the era of large language models: A case study of STPA using ChatGPT},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensembles of deep one-class classifiers for multi-class
image classification. <em>MLA</em>, <em>19</em>, 100621. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for multi-class classification (MCC) involve using a monolithic feature extractor and classifier trained on data from all the classes simultaneously. These methods are dependent on the number and types of classes and are therefore rigid against changes to the class structure. For instance, if the number of classes needs to be modified or new training data becomes available, retraining would be required for optimum classification performance. Moreover, these classifiers can become biased toward classes with a large data imbalance. An alternative, more attractive framework is to consider an ensemble of one-class classifiers (EOCC) where each one-class classifier (OCC) is trained with data from a single class only, without using any information from the other classes. Although this framework has not yet systematically matched or surpassed the performance of traditional MCC approaches, it deserves further investigation for several reasons. First, it provides a more flexible framework for handling changes in class structure compared to the traditional MCC approach. Second, it is less biased toward classes with large data imbalances compared to the multi-class classification approach. Finally, each OCC can be separately optimized depending on the characteristics of the class it represents. In this paper, we have performed extensive experiments to evaluate EOCC for MCC using traditional OCCs based on Principal Component Analysis (PCA) and Auto-encoders (AE) as well as newly proposed OCCs based on Generative Adversarial Networks (GANs). Moreover, we have compared the performance of EOCC with traditional multi-class DL classifiers including VGG-19, Resnet and EfficientNet. Two different datasets were used in our experiments: (i) a subset from the Plant Village dataset plant disease dataset with high variance in the number of classes and amount of data in each class, and (ii) an Alzheimer’s disease dataset with low amounts of data and a large imbalance in data between classes. Our results show that the GAN-based EOCC outperform previous EOCC approaches and improve the performance gap with traditional MCC approaches.},
  archive      = {J_MLA},
  author       = {Alexander Novotny and George Bebis and Alireza Tavakkoli and Mircea Nicolescu},
  doi          = {10.1016/j.mlwa.2025.100621},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100621},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Ensembles of deep one-class classifiers for multi-class image classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent deep reinforcement learning with online and fair
optimal dispatch of EV aggregators. <em>MLA</em>, <em>19</em>, 100620.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing popularity of electric vehicles (EVs) and the unpredictable behavior of EV owners have attracted attention to real-time coordination of EVs charging management. This paper presents a hierarchical structure for charging management of EVs by integrating fairness and efficiency concepts within the operations of the distribution system operator (DSO) while utilizing a multi-agent deep reinforcement learning (MADRL) framework to tackle the complexities of energy purchasing and distribution among EV aggregators (EVAs). At the upper level, DSO calculates the maximum allowable power for each EVA based on power flow constraints to ensure grid safety. Then, it finds the optimal efficiency-Jain tradeoff (EJT) point, where it sells the highest energy amount while ensuring equitable energy distribution. At the lower level, initially, each EVA acts as an agent employing a double deep Q-network (DDQN) with adaptive learning rates and prioritized experience replay to determine optimal energy purchases from the DSO. Then, the real-time smart dispatch (RSD) controller prioritizes EVs for energy dispatch based on relevant EVs information. Findings indicate the proposed enhanced DDQN outperforms deep deterministic policy gradient (DDPG) and proximal policy optimization (PPO) in cumulative rewards and convergence speed. Finally, the framework’s performance is evaluated against uncontrolled charging and the first come first serve (FCFS) scenario using the 118-bus distribution system, demonstrating superior performance in maintaining safe operation of the grid while reducing charging costs for EVAs. Additionally, the framework’s integration with renewable energy sources (RESs), such as photovoltaic (PV), demonstrates its potential to enhance grid reliability.},
  archive      = {J_MLA},
  author       = {Arian Shah Kamrani and Anoosh Dini and Hanane Dagdougui and Keyhan Sheshyekani},
  doi          = {10.1016/j.mlwa.2025.100620},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100620},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Multi-agent deep reinforcement learning with online and fair optimal dispatch of EV aggregators},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving mango ripeness grading accuracy: A comprehensive
analysis of deep learning, traditional machine learning, and transfer
learning techniques. <em>MLA</em>, <em>19</em>, 100619. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bangladesh ranks among the top 10 countries globally in mango output. Mangoes can be classified based on their ripeness, with skin color being the most significant aspect. The current classification procedure is done manually, leading to mistakes and vulnerability to human error. Most research often focuses on using a single method to assess the ripeness of fruits. The study comprises a set of comprehensive tests showcasing different tactics for determining the most efficient methods through various models. One unique dataset was used for all five models: Gaussian Naive Bayes (GNB), Support Vector Machine (SVM), Gradient Boosting (GB), Random Forest (RF), and K-Nearest Neighbors (KNN). Utilizing convolutional neural networks (CNNs) and VGG16, a pre-trained CNN model, to extract features and train the dataset. Used these training datasets as input to calculate the average accuracy of the five models during testing. In addition to these experiments, these five models using standard techniques also evaluated. The study also included a comparative analysis that emphasized the best performance of each model in various scenarios. This analysis shows that the CNN model consistently performs better than the transfer learning model (VGG16) and classical machine learning methods. Except for the KNN and Naive Bayes scenarios, the VGG16 model achieved much higher accuracy compared to typical machine learning methods. In three other models, classical machine learning outperforms the VGG16 model. The Gradient Boosting model in deep learning (CNN) demonstrated the highest accuracy of 96.28 % compared to other models and techniques.},
  archive      = {J_MLA},
  author       = {Md․ Saon Sikder and Mohammad Shamsul Islam and Momenatul Islam and Md․ Suman Reza},
  doi          = {10.1016/j.mlwa.2025.100619},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100619},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Improving mango ripeness grading accuracy: A comprehensive analysis of deep learning, traditional machine learning, and transfer learning techniques},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting customer subscription in bank telemarketing
campaigns using ensemble learning models. <em>MLA</em>, <em>19</em>,
100618. (<a href="https://doi.org/10.1016/j.mlwa.2025.100618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the use of ensemble learning models bagging, boosting, and stacking to enhance the accuracy and reliability of predicting customer subscriptions in bank telemarketing campaigns. Recognizing the challenges posed by class imbalance and complex customer behaviors, we employ multiple ensemble techniques to build a robust predictive framework. Our analysis demonstrates that stacking models achieve the best overall performance, with an accuracy of 91.88% and an Receiver Operating Characteristic Area Under the Curve (ROC-AUC) score of 0.9491, indicating a strong capability to differentiate between subscribers and non-subscribers. Additionally, feature importance analysis reveals that contact duration, economic indicators like the Euro interbank offered (Euribor) rate, and customer age are the most influential factors in predicting subscription likelihood. These findings suggest that by focusing on customer engagement and economic trends, banks can improve telemarketing campaign effectiveness. We recommend the integration of advanced balancing techniques and real-time prediction systems to further enhance model performance and adaptability. Future work could explore deep learning models and interpretability techniques to gain deeper insights into customer behavior patterns. Overall, this study highlights the potential of ensemble models in predictive modeling for telemarketing, providing a data-driven foundation for more targeted and efficient customer acquisition strategies.},
  archive      = {J_MLA},
  author       = {Michael Peter and Hawa Mofi and Said Likoko and Julius Sabas and Ramadhani Mbura and Neema Mduma},
  doi          = {10.1016/j.mlwa.2025.100618},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100618},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predicting customer subscription in bank telemarketing campaigns using ensemble learning models},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S&amp;p-500 vs. Nasdaq-100 price movement prediction with
LSTM for different daily periods. <em>MLA</em>, <em>19</em>, 100617. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the efficiency of LSTM neural networks in predicting price movements for the two major U.S. stock indices: the S&amp;P-500 and the Nasdaq-100 index. We consider three distinct daily periods: “overnight” (Close-to-Open), “daytime” (Open-to-Close) and “24-hour” (Close-to-Close) trading sessions. Using historical pricing data for these indices since 2000, this study shows how well the standard LSTM model captures price movement patterns to improve short-term trading strategies. The findings reveal that, for the S&amp;P-500, a one-year training with 24-hour periods delivers a 14.5% more return over the Buy-and-Hold strategy. Moreover, combining “overnight” and “daytime” strategies delivers more than 40% return compared to passive index investing. By contrast, for the Nasdaq-100, a shorter training period of three months for “24-hour” periods delivers 90% more return than passive index investing. These results suggest that LSTM effectively learns the unique market dynamics associated with each index and different time periods, offering further insights into how deep learning can enhance financial forecasting and trading opportunities.},
  archive      = {J_MLA},
  author       = {Xiang Zhang and Eugene Pinsky},
  doi          = {10.1016/j.mlwa.2024.100617},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100617},
  shortjournal = {Mach. Learn. Appl.},
  title        = {S&amp;P-500 vs. nasdaq-100 price movement prediction with LSTM for different daily periods},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified wound diagnostic framework for wound segmentation
and classification. <em>MLA</em>, <em>19</em>, 100616. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic wounds affect millions worldwide, posing significant challenges for healthcare systems and a heavy economic burden globally. The segmentation and classification (S&amp;C) of chronic wounds are critical for wound care management and diagnosis, aiding clinicians in selecting appropriate treatments. Existing approaches have utilized either traditional machine learning or deep learning methods for S&amp;C. However, most focus on binary classification, with few addressing multi-class classification, often showing degraded performance for pressure and diabetic wounds. Wound segmentation has been largely limited to foot ulcer images, and there is no unified diagnostic tool for both S&amp;C tasks. To address these gaps, we developed a unified approach that performs S&amp;C simultaneously. For segmentation, we proposed Attention-Dense-UNet (Att- d -UNet), and for classification, we introduced a feature concatenation-based method. Our framework segments wound images using Att- d -UNet, followed by classification into one of the wound types using our proposed method. We evaluated our models on publicly available wound classification datasets (AZH and Medetec) and segmentation datasets (FUSeg and AZH). To test our unified approach, we extended wound classification datasets by generating segmentation masks for Medetec and AZH images. The proposed unified approach achieved 90% accuracy and an 86.55% dice score on the Medetec dataset and 81% accuracy and an 86.53% dice score on the AZH dataset These results demonstrate the effectiveness of our separate models and unified approach for wound S&amp;C.},
  archive      = {J_MLA},
  author       = {Mustafa Alhababi and Gregory Auner and Hafiz Malik and Muteb Aljasem and Zaid Aldoulah},
  doi          = {10.1016/j.mlwa.2024.100616},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100616},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Unified wound diagnostic framework for wound segmentation and classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combinations of distributional regression algorithms with
application in uncertainty estimation of corrected satellite
precipitation products. <em>MLA</em>, <em>19</em>, 100615. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To facilitate effective decision-making, precipitation datasets should include uncertainty estimates. Quantile regression with machine learning has been proposed for issuing such estimates. Distributional regression offers distinct advantages over quantile regression, including the ability to model intermittency as well as a stronger ability to extrapolate beyond the training data, which is critical for predicting extreme precipitation. Therefore, here, we introduce the concept of distributional regression in precipitation dataset creation, specifically for the spatial prediction task of correcting satellite precipitation products. Building upon this concept, we formulated new ensemble learning methods that can be valuable not only for spatial prediction but also for other prediction problems. These methods exploit conditional zero-adjusted probability distributions estimated with generalized additive models for location, scale and shape (GAMLSS), spline-based GAMLSS and distributional regression forests as well as their ensembles (stacking based on quantile regression and equal-weight averaging). To identify the most effective methods for our specific problem, we compared them to benchmarks using a large, multi-source precipitation dataset. Stacking was shown to be superior to individual methods at most quantile levels when evaluated with the quantile loss function. Moreover, while the relative ranking of the methods varied across different quantile levels, stacking methods, and to a lesser extent mean combiners, exhibited lower variance in their performance across different quantiles compared to individual methods that occasionally ranked extremely low. Overall, a task-specific combination of multiple distributional regression algorithms could yield significant benefits in terms of stability.},
  archive      = {J_MLA},
  author       = {Georgia Papacharalampous and Hristos Tyralis and Nikolaos Doulamis and Anastasios Doulamis},
  doi          = {10.1016/j.mlwa.2024.100615},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100615},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Combinations of distributional regression algorithms with application in uncertainty estimation of corrected satellite precipitation products},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The association between mindfulness, psychological
flexibility, and rumination in predicting mental health and well-being
among university students using machine learning and structural equation
modeling. <em>MLA</em>, <em>19</em>, 100614. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives This study explores the intricate relationships between mindfulness, psychological flexibility, rumination, and their combined impact on mental health and well-being. Methods Random forest regression on survey data from 524 undergraduate students was used to identify significant predictors from a comprehensive set of psychological variables. Neural networks were then trained on various combinations of these predictors to evaluate their performance in predicting mental health and well-being outcomes. Finally, structural equation modeling (SEM) was employed to validate a model based on the identified key predictors, focusing on pathways from mindfulness through psychological flexibility to rumination and well-being. Results The random forest analysis revealed that the mindfulness variables exerted their influence partially indirectly through psychological flexibility and rumination. The deep neural network analysis supported these findings and additionally showed that the mindfulness manifold model (consisting of self-awareness, self-regulation, and self-transcendence) was superior to the Five Facet Mindfulness Questionnaire variables in predicting mental health outcomes. The SEM analysis confirmed that psychological flexibility, particularly its avoidance and acceptance components, mediated the relationship between mindfulness and mental health. The hypothesized serial mediation pathway—mindfulness affecting psychological flexibility, which then influences rumination and subsequently mental health and well-being—was supported by the data. Self-transcendence was a particularly powerful predictor of mental health outcomes. Conclusions The findings underscore the critical role of psychological flexibility and rumination in mediating the effects of mindfulness on mental health and well-being, suggesting that enhancing mindfulness and psychological flexibility might significantly reduce rumination, thereby improving overall mental health and well-being.},
  archive      = {J_MLA},
  author       = {Ruohan Feng and Vaibhav Mishra and Xin Hao and Paul Verhaeghen},
  doi          = {10.1016/j.mlwa.2024.100614},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100614},
  shortjournal = {Mach. Learn. Appl.},
  title        = {The association between mindfulness, psychological flexibility, and rumination in predicting mental health and well-being among university students using machine learning and structural equation modeling},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stairway to heaven: An emotional journey in divina commedia
with threshold-based naïve bayes classifier. <em>MLA</em>, <em>19</em>,
100613. (<a href="https://doi.org/10.1016/j.mlwa.2024.100613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational literary uses data science and computer science techniques to study literature. In this framework, we investigate how an expert system can acquire knowledge from the specific content of a narrative text without any pre-existing information about it. We utilize the Threshold-based Naïve Bayes (Tb-NB) classifier to analyze the content of Dante Alighieri’s Divina Commedia poem. Tb-NB is a probabilistic data-driven model that predicts the polarity of a binary response based on the probability of an event occurring given certain features, and assigns a log-likelihood score to each word in a text. Our first task is understanding if and how the links between lexical forms and meanings characterize the three parts of the poem (Inferno, Purgatorio and Paradiso) in order to predict if a Canto belongs to Inferno or Paradiso based on its specific content, and to determine if a Canto of Purgatorio is more similar to those of Inferno or to those of Paradiso. We show Tb-NB outperform other similar approaches and achieves the same performance of Random Forest (F1-score = 0.985) but providing much more information to interpret the specific content and the lexical forms used by Dante Alighieri in its poem. The Tb-NB’s scores are the base of knowledge for the implementation of an expert system, like a search engine, that can help users to identify the most informative verses of a Canto or by better comprehend or discover the content of the poem from a word related to a particular feeling or emotion.},
  archive      = {J_MLA},
  author       = {Maurizio Romano and Claudio Conversano},
  doi          = {10.1016/j.mlwa.2024.100613},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100613},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Stairway to heaven: An emotional journey in divina commedia with threshold-based naïve bayes classifier},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive gate residual connection and multi-scale RCNN for
fake news detection. <em>MLA</em>, <em>19</em>, 100612. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of false news based on text classification technology has significant research significance and practical value in the current information age. However, existing methods overlook the problem of uneven sample distribution in the false news dataset and fail to consider the mutual influence between news articles. In light of this, this paper proposes a new method for false news detection. Firstly, news texts are embedded using Electra (Efficiently Learning an Encoder that Classifies Token Replacements Accurately) to obtain word embedding representations. Secondly, Multi-Scale Recurrent Convolutional Neural Network (RCNN) is employed to further extract contextual information from news texts. Self-attention is introduced to calculate attention scores between news articles, allowing for mutual influence between news features. The establishment of connections between modules is achieved through adaptive gated residual connections. Finally, the focal loss function is used to balance the relationship between few-sample and multi-sample data in the dataset. Experimental results on publicly available false news detection datasets demonstrate that the proposed method achieves higher prediction accuracy than the comparative methods. This method provides a new perspective for the field of false news detection, playing a positive role in promoting information authenticity and protecting public interests.},
  archive      = {J_MLA},
  author       = {QunHui Zhou and Tijian Cai},
  doi          = {10.1016/j.mlwa.2024.100612},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100612},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Adaptive gate residual connection and multi-scale RCNN for fake news detection},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical classification accuracy of sequential data using
neural networks. <em>MLA</em>, <em>19</em>, 100611. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing studies on neural network accuracy utilize datasets that may not always reflect real-world conditions. While it has been demonstrated that accuracy tends to decrease as the number of benign samples increases, this effect has not been quantitatively assessed within neural networks. Moreover, its relevance to security tasks beyond malware classification remains unexplored. In this research, we refined the metric to evaluate the degradation of accuracy with an increased number of benign samples in test data. Utilizing both standard and specific neural network models, we conducted experiments to adapt this metric to neural networks and various feature extraction techniques. Using the FFRI dataset, comprising 150,000 malware and 400,000 benign samples, along with the URL dataset, containing 3143 malicious and 106,545,781 benign samples, we increased benign samples in the test set while keeping the training set’s malicious and benign samples constant. Our findings indicate that neural networks can indeed overestimate their accuracy with a smaller count of benign samples. Importantly, our refined metric is not only applicable to neural networks but is also effective for other feature extraction methods and security tasks beyond malware detection.},
  archive      = {J_MLA},
  author       = {Mamoru Mimura},
  doi          = {10.1016/j.mlwa.2024.100611},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100611},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Practical classification accuracy of sequential data using neural networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demographic bias mitigation at test-time using uncertainty
estimation and human–machine partnership. <em>MLA</em>, <em>19</em>,
100610. (<a href="https://doi.org/10.1016/j.mlwa.2024.100610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial attribute classification algorithms frequently manifest demographic biases by obtaining differential performance across gender and racial groups. Existing bias mitigation techniques are mostly in-processing techniques, i.e., implemented during the classifier’s training stage, that often lack generalizability, require demographically annotated training sets, and exhibit a trade-off between fairness and classification accuracy. In this paper, we propose a technique to mitigate bias at the test time i.e., during the deployment stage, by harnessing prediction uncertainty and human–machine partnership. To this front, we propose to utilize those lowest percentages of test data samples identified as outliers with high prediction uncertainty. These identified uncertain samples at test-time are labeled by human analysts for decision rendering and for subsequently re-training the deep neural network in a continual learning framework. With minimal human involvement and through iterative refinement of the network with human guidance at test-time, we seek to enhance the accuracy as well as the fairness of the already deployed facial attribute classification algorithms. Extensive experiments are conducted on gender and smile attribute classification tasks using four publicly available datasets and with gender and race as the protected attributes. The obtained outcomes consistently demonstrate improved accuracy by up to 2% and 5% for the gender and smile attribute classification tasks, respectively, using our proposed approaches. Further, the demographic bias was significantly reduced, outperforming the State-of-the-Art (SOTA) bias mitigation and baseline techniques by up to 55% for both classification tasks. The demo shall be released on https://github.com/hashtaglensman/HumanintheLoop .},
  archive      = {J_MLA},
  author       = {Anoop Krishnan Upendran Nair and Ajita Rattani},
  doi          = {10.1016/j.mlwa.2024.100610},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100610},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Demographic bias mitigation at test-time using uncertainty estimation and human–machine partnership},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of convolutional neural networks and ensemble
methods in the fiber volume content analysis of natural fiber
composites. <em>MLA</em>, <em>19</em>, 100609. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incorporation of natural fibers into fiber-reinforced polymer composites (FRPC) has the potential to bolster their sustainability. A critical attribute of FRPC is the fiber volume content ( FVC ), a parameter that profoundly influences their thermo-mechanical characteristics. However, the determination of FVC in natural fiber composites (NFC) through manual analysis of light microscopy images is a labor-intensive process. In this work, it is demonstrated that the pixels from light microscopy images of NFC can be utilized to predict FVC using machine learning (ML) models. In this proof-of-concept investigation, it is shown that convolutional neural network-based models predict FVC with an accuracy required in polymer engineering applications, with a mean average error of 2.72 % and an R 2 coefficient of 0.85. Finally, it is shown that much simpler ML models, non-specialized in image recognition, besides being much easier and more efficient to optimize and train, can also deliver good accuracies required for FVC characterization, which not only contributes to the sustainability, but also facilitates the access of such models by researchers in regions with little computational resources. This study marks a substantial advancement in the area of automated characterization of NFC, and democratization of knowledge, offering a promising avenue for the enhancement of sustainable materials.},
  archive      = {J_MLA},
  author       = {Florian Rothenhäusler and Rodrigo Queiroz Albuquerque and Marcel Sticher and Christopher Kuenneth and Holger Ruckdaeschel},
  doi          = {10.1016/j.mlwa.2024.100609},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100609},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Application of convolutional neural networks and ensemble methods in the fiber volume content analysis of natural fiber composites},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of fraud in IoT based credit card collected
dataset using machine learning. <em>MLA</em>, <em>19</em>, 100603. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due in large part to the proliferation of electronic financial transactions, credit card fraud is a serious problem for customers, merchants, and banks. For this reason, a novel approach is offered to fraud detection that makes use of cutting-edge ML methods in an IoT setting. The method in this paper employs a carefully selected set of cutting-edge ML algorithms specifically designed to handle the complexities of fraud detection, in contrast to older approaches that have difficulty adapting to shifting fraud patterns. In order to address the many facets of the problem, the methodology employs a large collection of ML models. These models include deep neural networks, decision trees, support vector machines, random forests, and clustering methods. This paper provides a solution that is able to detect fraudulent activity in real time by efficiently analyzing massive amounts of transactional data thanks to the power of big data processing and cloud computing. The model is able to distinguish between valid and fraudulent transactions thanks to careful feature engineering and anomaly detection methods. Extensive experiments on a large and diverse collection of real and simulated credit card transactions, both legitimate and fraudulent, prove the success of this technique. The findings demonstrate state-of-the-art performance in fraud detection, with increased precision and recall rates compared to traditional methods. And because the presented ML models are easy to understand, they improve fraud risk management and prevention techniques. The findings of this study provide banking institutions, government agencies, and policymakers with vital information for combating the negative effects of credit card fraud on consumers, companies, and the economy as a whole. This study provides a solution to the problem of fraud in the Internet of Things (IoT) ecosystem and paves the way for future developments in this crucial area by proposing a unique ML-driven approach to the problem.},
  archive      = {J_MLA},
  author       = {Mohammed Naif Alatawi},
  doi          = {10.1016/j.mlwa.2024.100603},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100603},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Detection of fraud in IoT based credit card collected dataset using machine learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="neucom---57">NEUCOM - 57</h2>
<ul>
<li><details>
<summary>
(2025). Real-time stereo matching with enhanced geometric
comprehension through cross-attention integration. <em>NEUCOM</em>,
<em>636</em>, 130069. (<a
href="https://doi.org/10.1016/j.neucom.2025.130069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate disparity estimation through stereo matching remains a critical challenge, especially for real-time applications. This work introduces a novel and computationally efficient framework that achieves high accuracy and real-time performance in stereo-based disparity estimation. The proposed approach introduces three key innovations. This work proposes a context cross-attention (CCA) module, which enhances the cost volume aggregation process by leveraging localized cross-attention for improved geometric understanding. Guided concatenation volume (GCV) is also implemented, which optimizes feature matching by effectively combining correlation clues with contextual information, reducing computational redundancy while maintaining crucial spatial details. Also, this paper proposes an uncertainty-based refinement (UR) module, which improves accuracy in challenging scenarios by utilizing an uncertainty map, a context feature map, and a geometry feature map to correct errors in challenging areas such as textureless regions and occlusions. Comprehensive experiments on multiple benchmark datasets, including KITTI, Sceneflow, Middlebury, and ETH3D, demonstrate that the proposed model performs better than existing state-of-the-art real-time approaches in accuracy metrics while maintaining comparable computational efficiency. These results establish the framework as a viable solution for demanding real-world applications, particularly in autonomous driving and robotics systems where real-time performance is crucial. The source code is available at https://github.com/kayhan-hashemi/CCAStereo .},
  archive      = {J_NEUCOM},
  author       = {Hosein Hashemi and Yasser Baleghi and Mohamad Reza Hassanzadeh},
  doi          = {10.1016/j.neucom.2025.130069},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130069},
  shortjournal = {Neurocomputing},
  title        = {Real-time stereo matching with enhanced geometric comprehension through cross-attention integration},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Drop inherent biases: Multi-level attention calibration for
robust cross-domain few-shot classification. <em>NEUCOM</em>,
<em>636</em>, 130056. (<a
href="https://doi.org/10.1016/j.neucom.2025.130056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning (FSL) is a promising approach for addressing the challenge of classifying novel classes with only limited labeled data. Many few-shot studies have elaborated various task-shared inductive biases (meta-knowledge) to solve such tasks and have achieved impressive performance. However, when there is a domain shift between the training and testing tasks, the learned inductive biases fail to generalize across domains. In this paper, we attempt to suppress and correct inherent discriminative inductive biases from the source domain through source domain attention release and target domain attention reaggregation. We propose a few-shot learning framework, which systematically addresses the large domain shift between base and novel classes. Specifically, the framework consists of three parts: prototype-level attention calibration, feature-level attention calibration for attention release and reaggregation, and loss attention calibration. First, the prototype-level attention calibration module highlights key instances via prototype calibration, reducing the influence of noisy instances in few-shot settings. Second, the feature-level attention calibration module suppresses and corrects erroneous discriminative inductive biases from the source domain through base class attention release and novel class attention reaggregation, respectively. Finally, we incorporate the loss attention calibration module into the loss function to balance the discriminability and diversity of the classification matrix, mitigating the decline in generalization ability caused by erroneous discriminative features during domain shift. We conduct experiments on eight classic few-shot cross-domain datasets. The results demonstrate that, under varying domain shifts, our method improves performance, with average accuracy gains of 0.82% and 1.31% in the 5-way 1-shot and 5-way 5-shot settings, respectively, compared to the existing state-of-the-art (SOTA) method.},
  archive      = {J_NEUCOM},
  author       = {Minghui Li and Jing Jiang and Hongxun Yao},
  doi          = {10.1016/j.neucom.2025.130056},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130056},
  shortjournal = {Neurocomputing},
  title        = {Drop inherent biases: Multi-level attention calibration for robust cross-domain few-shot classification},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HDCPAA: A few-shot class-incremental learning model for
remote sensing image recognition. <em>NEUCOM</em>, <em>636</em>, 130043.
(<a href="https://doi.org/10.1016/j.neucom.2025.130043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the scene of remote sensing image (RSI) recognition, it is difficult to obtain a sufficient number of samples for training all categories at once. A more realistic situation is that the recognition task occurs in an open environment, with categories gradually increasing. Additionally, due to the difficulty of collecting certain data, there are only a few samples for each new category. This leads to the problem of few-shot class-incremental learning (FSCIL), where the model learns incrementally and the number of samples for incremental classes is very small, generally only a few, while the number of samples for base classes is relatively large. To address this, this paper proposes a model framework for FSCIL of RSIs, called HDCPAA. The model is mainly divided into three parts. The first part is the feature extraction network, which is pre-trained on the base classes and then its parameters are frozen in subsequent incremental learning to alleviate catastrophic forgetting of the base classes. The second part is a fully connected layer, which transforms the prototypes of each category into quasi-orthogonal prototypes to increase the distance between the prototypes. The third part is the prototype adaptation attention module, which adaptively updates prototypes and query vectors using attention mechanisms. The training process of this module is based on the meta-learning of pseudo-incremental classes. Experiments on two popular benchmark RSI datasets, MSTAR and NWPU-RESISC45, show that our model significantly outperforms the baseline models and sets new state-of-the-art results with remarkable advantages. Our code will be uploaded at: https://github.com/lipeng144/HDCPAA .},
  archive      = {J_NEUCOM},
  author       = {Peng Li and Cunqian Feng and Xiaowei Hu and Weike Feng},
  doi          = {10.1016/j.neucom.2025.130043},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130043},
  shortjournal = {Neurocomputing},
  title        = {HDCPAA: A few-shot class-incremental learning model for remote sensing image recognition},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unifying the syntax and semantics for math word problem
solving. <em>NEUCOM</em>, <em>636</em>, 130042. (<a
href="https://doi.org/10.1016/j.neucom.2025.130042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Math word problem solving is a complex task for natural language processing systems, requiring both comprehension of problem descriptions and deduction of accurate solutions. Existing studies have shown that graph-based approaches can achieve competitive results by applying multilayer graph neural networks to syntactic structure graphs. However, challenges such as incorrect parsing of syntactic dependency trees and insensitivity to numerical information may lead to misinterpretations in the representation. In this paper, we introduce a novel synthetic graph, the N umber- C entered S ynthetic S emantic G raph (NC-SSG), to address these challenges by reorganizing the dependency tree layout around numerical elements. We propose a double-channel graph transformer to enhance the connections between numbers and their contextual elements, thereby improving the understanding of problem descriptions. Additionally, we present a question-driven tree decoder to generate more accurate solutions, aiming to overcome shallow heuristics. Our approach mitigates the impact of parsing errors in syntactic dependency trees, yielding more precise representations and solutions. Experimental evaluations on two benchmark datasets demonstrate that our solver outperforms previous methods and achieves competitive performance compared to large language models.},
  archive      = {J_NEUCOM},
  author       = {Xingyu Tao and Yi Zhang and Zhiwen Xie and Zhuo Zhao and Guangyou Zhou and Yongchun Lu},
  doi          = {10.1016/j.neucom.2025.130042},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130042},
  shortjournal = {Neurocomputing},
  title        = {Unifying the syntax and semantics for math word problem solving},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CS4TE: A novel coded self-attention and semantic synergy
network for triple extraction. <em>NEUCOM</em>, <em>636</em>, 130034.
(<a href="https://doi.org/10.1016/j.neucom.2025.130034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The joint entity relation extraction approach holds great potential for extracting triples from unstructured text. However, in current research, two prevalent shortcomings significantly impact the efficacy of triple extraction task. Firstly, since entities constitute only a small proportion of sentences and token embedding contain a substantial amount of irrelevant information, these factors present significant challenges to the performance of classification models. Secondly, the typical process of predicting triples begins with identifying entities and then predicting triples solely based on the obtained entity representation, this process often overlooks the contextual semantic information associated with the entities. In this work, we propose CS4TE: A Novel Coded Self-Attention and Semantic Synergy Network for Triple Extraction. Specifically, we propose a novel Coded Self-Attention Mechanism designed to refine text representation by effectively masking irrelevant information and enhancing entity representation. Additionally, we propose a Semantic Synergy Network, which innovatively integrates semantic information with token pairs to predict triples, addressing the limitations of previous research that often overlooked semantic information. Finally, our model outperforms state-of-the-art baseline models on two public datasets in the joint entity-relation extraction task, and extensive experiments have been conducted to demonstrate the effectiveness of our method from multiple perspectives.},
  archive      = {J_NEUCOM},
  author       = {Huiyong Lv and Yurong Qian and Jiaying Chen and Shuxiang Hou and Hongyong Leng and Mengnan Ma},
  doi          = {10.1016/j.neucom.2025.130034},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130034},
  shortjournal = {Neurocomputing},
  title        = {CS4TE: A novel coded self-attention and semantic synergy network for triple extraction},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-morphing attack detection using few-shot learning and
triplet-loss. <em>NEUCOM</em>, <em>636</em>, 130033. (<a
href="https://doi.org/10.1016/j.neucom.2025.130033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face morphing attack detection is challenging and presents a concrete and severe threat to face verification systems. A reliable detection mechanism for such attacks, tested with a robust cross-dataset protocol and unknown morphing tools, is still a research challenge. This paper proposes a framework based on the Few-Shot-Learning approach that shares image information based on the Siamese network using triplet-semi-hard-loss to tackle the morphing attack detection and boost the learning classification process. This network compares a bona fide or potentially morphed image with triplets of morphing face images. Our results show that this new network clusters the morphed images and assigns them to the right classes to obtain a lower equal error rate in a cross-dataset scenario. Few-shot learning helps to boost the learning process by sharing only small image numbers from an unknown dataset. Experimental results using cross-datasets trained with FRGCv2 and tested with FERET datasets reduced the BPCER 10 from 43% to 4.91% using ResNet50. For the AMSL open-access dataset is reduced for MobileNetV2 from BPCER 10 of 31.50% to 2.02%. For the SDD open-access synthetic dataset, the BPCER 10 is reduced for MobileNetV2 from 21.37% to 1.96%.},
  archive      = {J_NEUCOM},
  author       = {Juan E. Tapia and Daniel Schulz and Christoph Busch},
  doi          = {10.1016/j.neucom.2025.130033},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130033},
  shortjournal = {Neurocomputing},
  title        = {Single-morphing attack detection using few-shot learning and triplet-loss},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Broad hashing for image retrieval. <em>NEUCOM</em>,
<em>636</em>, 130031. (<a
href="https://doi.org/10.1016/j.neucom.2025.130031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of deep learning, deep hashing methods have become mainstream of hashing methods which adopt deep networks to learn better feature representation of images and simultaneously generate compact binary hash codes. Deep hashing methods have a bottleneck in training efficiency due to the complex structure of deep networks. In this work, we propose a broad hashing (BH) method with high retrieval performance and very short learning time. In BH, uncorrelated and balanced binary codes are assigned to each category through a Hadamard matrix. Then, a broad hashing network is constructed to learn hash functions which maps images to binary hash codes with high efficiency. Our method yields higher retrieval precision while its training time is 200 to 700 times faster than that of deep hashing methods. At the same time, more compact hash codes are obtained compared with conventional supervised learning methods. In addition, three incremental algorithms for BH are developed for dynamic environments, which enable the hash network to be remodeled without retraining. Experiments on three benchmark datasets validate the effectiveness and efficiency of BH.},
  archive      = {J_NEUCOM},
  author       = {Wing W.Y. Ng and Xuyu Liu and Xing Tian and Ting Wang and Jianjun Zhang and C.L. Philip Chen},
  doi          = {10.1016/j.neucom.2025.130031},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130031},
  shortjournal = {Neurocomputing},
  title        = {Broad hashing for image retrieval},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial erasure network based on multi-instance learning
for weakly supervised video anomaly detection. <em>NEUCOM</em>,
<em>636</em>, 130030. (<a
href="https://doi.org/10.1016/j.neucom.2025.130030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised video anomaly detection (WSVAD) aims to precisely locate temporal windows of abnormal events in untrimmed videos using only video-level labels. By accurately locating anomalies, WSVAD has great application potential in the security domain and contributes to the progress of smart city development. However, the lack of frame-level annotations during training makes it highly challenging to infer the status of each frame. Multiple-Instance Learning (MIL) is the dominant method in WSVAD. Due to the limitation of video-level annotations, most MIL-based methods detect obvious abnormal segments to represent the overall anomaly level of the video while overlooking weak abnormal segments. To focus on the discrimination of weak anomalies, we propose a novel WSVAD framework named Adversarial Erasure Network (AE-Net). AE-Net consists of two key components: (1) a dual-branch architecture that highlights weak anomalies by erasing the most obvious abnormal features and combining the erased features with the original ones. (2) a novel triplet loss function that improves weak anomaly representation by separating abnormal and normal features in the erased feature space. Through the above design, AE-Net can reduce false negatives in real-world anomaly detection. Extensive experiments on three WSVAD benchmarks demonstrate that our method outperforms most existing state-of-the-art methods. Specifically, AE-Net achieves an AUC of 88.40% on the UCF-Crime dataset and 98.27% on the ShanghaiTech dataset, which demonstrates that AE-Net can effectively distinguish between normal and abnormal events. Moreover, AE-Net achieves an AP of 85.13% on the XD-Violence dataset, which highlights that AE-Net can accurately detect abnormal events.},
  archive      = {J_NEUCOM},
  author       = {Xin Song and Penghui Liu and Suyuan Li and Siyang Xu and Ke Wang},
  doi          = {10.1016/j.neucom.2025.130030},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130030},
  shortjournal = {Neurocomputing},
  title        = {Adversarial erasure network based on multi-instance learning for weakly supervised video anomaly detection},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attributed network community detection based on graph
contrastive learning and multi-objective evolutionary algorithm.
<em>NEUCOM</em>, <em>636</em>, 130029. (<a
href="https://doi.org/10.1016/j.neucom.2025.130029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attributed network community detection holds significant research value for network structure analysis and practical applications. However, existing methods still face significant challenges in addressing the conflicts between topological structure and attribute features, as well as balancing structural tightness and attribute similarity in community detection. In light of this, we propose a community detection method based on graph contrastive learning and multi-objective evolutionary algorithm (GCL-MOEA) for attributed networks. Specifically, GCL-MOEA contains two core parts: node embedding and community detection. Considering the conflict between topological structure and attribute features, the node embedding part constructs topology-augmented and attribute-augmented views, which are utilized in a cross-view graph contrastive learning model. This model comprehensively extracts node features to obtain node embedding vectors, effectively preserving the consistency and complementarity between the structure and attributes. The community detection part utilizes clustering results of node embeddings to construct high-quality initial populations. A multi-objective evolutionary algorithm is subsequently employed to obtain community structures where nodes are tightly connected and have similar attributes. The effectiveness of the proposed method is validated on five real-world networks. Experimental results demonstrate that GCL-MOEA outperforms baselines in terms of ACC, NMI, ARI, and F1, obtaining better community detection results.},
  archive      = {J_NEUCOM},
  author       = {Yao Liang and Jian Shu and Linlan Liu},
  doi          = {10.1016/j.neucom.2025.130029},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130029},
  shortjournal = {Neurocomputing},
  title        = {Attributed network community detection based on graph contrastive learning and multi-objective evolutionary algorithm},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained multi-modal prompt learning for vision–language
models. <em>NEUCOM</em>, <em>636</em>, 130028. (<a
href="https://doi.org/10.1016/j.neucom.2025.130028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently advanced pre-trained vision language models have demonstrated outstanding performance in many downstream tasks via prompt learning. Prompt learning provides task-specific prompt information to exploit beneficial knowledge stored in pre-trained models to promote generalization ability for downstream tasks. However, previous work mainly focused on single modal prompt tuning (with only one prompt per modality) and salient distinguished features, which unable to flexibly adjust the two representation spaces on downstream tasks dynamically, yet makes it hard to capture subtle discriminative knowledge, which resulting in suboptimal solutions. In this work, we propose a novel F ine- G rained M ulti-modal P rompt L earning framework, denoted as FGMPL , based on the contrastive language–image pre-trained model (CLIP). To facilitate the pre-trained CLIP model to learn and represent more effective features, we design a dual-grained visual prompt scheme to learn global discrepancies as well as specify the subtle discriminative details among visual classes, and transform random vectors with class names in class-aware text prompt into class-specific discrepancy representation. Moreover, in contrast to the previous prompt approaches, we use shared latent semantic space to generate visual and text prompts to encourage cross-modal interaction. Furthermore, a multimodal prompt tuning evaluator is proposed, which can make the vision and text prompts semantically aligned and enhance each other to promote cross-modal collaborative reasoning to further improve FGMPL. Comprehensive experiments on popular image recognition benchmarks show that our approach has superior generalization and few-shot capabilities.},
  archive      = {J_NEUCOM},
  author       = {Yunfei Liu and Yunziwei Deng and Anqi Liu and Yanan Liu and Shengyang Li},
  doi          = {10.1016/j.neucom.2025.130028},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130028},
  shortjournal = {Neurocomputing},
  title        = {Fine-grained multi-modal prompt learning for vision–language models},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event denoising for dynamic vision sensor using residual
graph neural network with density-based spatial clustering.
<em>NEUCOM</em>, <em>636</em>, 130026. (<a
href="https://doi.org/10.1016/j.neucom.2025.130026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bio-inspired emerging dynamic vision sensor (DVS), characterized by its exceptional high temporal resolution and immediate response, possesses an innate advantage in capturing rapidly changing scenes. Nevertheless, it is also susceptible to severe noise interference, especially in challenging conditions like low illumination and high exposure. Notably, the existing noise processing approaches tend to oversimplify data into 2-dimensional (2D) patterns, disregarding the sparse and irregular crucial event structure information that the DVS intrinsically provides via its asynchronous output. Aiming at these problems, we propose a residual graph neural network (RGNN) framework based on density spatial clustering for event denoising, called DBRGNN. Leveraging the temporal window rule, we extract non-overlapping event segments from the DVS event stream and adopt a density-based spatial clustering algorithm to obtain event groups with spatial correlations. To fully exploit the inherent sparsity and plentiful spatiotemporal information of the raw event stream, we transform each event group as compact graph representations via directed edges and feed them into a graph coding module composed of a series of graph convolutional and pooling layers to learn robust geometric features from event sequences. Importantly, our approach effectively reduces noise levels without compromising the spatial structure and temporal coherence of spike events. Compared with other baseline methods, our DBRGNN achieves competitive performance by quantitative and qualitative evaluations on publicly available datasets under varying lighting conditions and noise ratios.},
  archive      = {J_NEUCOM},
  author       = {Weibin Feng and Xiaoping Wang and Xin Zhan and Hongzhi Huang},
  doi          = {10.1016/j.neucom.2025.130026},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130026},
  shortjournal = {Neurocomputing},
  title        = {Event denoising for dynamic vision sensor using residual graph neural network with density-based spatial clustering},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SGCDiff: Sketch-guided cross-modal diffusion model for 3D
shape completion. <em>NEUCOM</em>, <em>636</em>, 130025. (<a
href="https://doi.org/10.1016/j.neucom.2025.130025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape completion aims to generate complete shapes based on partial observations. Most recent methods utilize existing information on 3D shapes for shape completion tasks, such as inputting a partial 3D shape into an encoder–decoder structure to obtain a complete 3D shape. Despite the recent rapid evolution of neural networks greatly improving the completion performance of 3D shapes, they usually generate deterministic results. However, the completed shape is inherently diverse, leading to the concept of multimodal shape completion, in which a single partial shape can correspond to multiple plausible complete shapes. Existing multimodal shape completion methods are typically unpredictable, which results in the generated complete shapes exhibiting randomness. To address the challenge of achieving a guided generation process for multimodal shape completion, we propose a novel sketch-based diffusion model. Our key designs encompass the following. We propose a novel diffusion-based framework that employs sketches as guidance to generate complete 3D shapes. Within the framework, we introduce a dual cross-modal attention module that ensures the generated results retain sufficient geometric detail. Experimental results indicate that our approach not only facilitates multimodal shape completion based on sketches but also achieves competitive performance in deterministic shape completion.},
  archive      = {J_NEUCOM},
  author       = {Zhenjiang Du and Yan Zhang and Zhitao Liu and Guan Wang and Zeyu Ma and Ning Xie and Yang Yang},
  doi          = {10.1016/j.neucom.2025.130025},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130025},
  shortjournal = {Neurocomputing},
  title        = {SGCDiff: Sketch-guided cross-modal diffusion model for 3D shape completion},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging diffusion and flow matching models for
demographic bias mitigation of facial attribute classifiers.
<em>NEUCOM</em>, <em>636</em>, 130024. (<a
href="https://doi.org/10.1016/j.neucom.2025.130024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Published research highlights the presence of demographic bias in automated facial attribute classification algorithms, notably impacting women and individuals with darker skin tones. Proposed bias mitigation techniques are not generalizable, need demographic annotations, are application-specific, and often obtain fairness by reducing overall classification accuracy. In response to these challenges, this paper proposes a novel bias mitigation technique that systematically integrates diffusion and flow-matching models with a base classifier with minimal additional computational overhead. These generative models are chosen for their extreme success in capturing diverse data distributions and their inherent stochasticity. Our proposed approach augments the base classifier’s accuracy across all demographic sub-groups with enhanced fairness. Further, the stochastic nature of these generative models is harnessed to quantify prediction uncertainty, allowing for test-time rejection, which further enhances fairness. Additionally, novel solvers are proposed to significantly reduce the computational overhead of generative model inference. An exhaustive evaluation carried out on facial attribute annotated datasets substantiates the efficacy of our approach in enhancing the accuracy and fairness of facial attribute classifiers by 0 . 5 % − 3 % and 0 . 5 % − 5 % across datasets over SOTA mitigation techniques. Thus, obtaining state-of-the-art performance. Further, our proposal does not need a demographically annotated training set and is generalizable to any downstream classification task.},
  archive      = {J_NEUCOM},
  author       = {Sreeraj Ramachandran and Ajita Rattani},
  doi          = {10.1016/j.neucom.2025.130024},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130024},
  shortjournal = {Neurocomputing},
  title        = {Leveraging diffusion and flow matching models for demographic bias mitigation of facial attribute classifiers},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level semantic-assisted prototype learning for
few-shot action recognition. <em>NEUCOM</em>, <em>636</em>, 130022. (<a
href="https://doi.org/10.1016/j.neucom.2025.130022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Few-Shot Action Recognition (FSAR) task involves recognizing new categories with limited labeled data. The conventional fine-tuning-based adaptation approach is often prone to overfitting and lacks temporal modeling for video data. Moreover, the discrepancy in distribution between meta-training and meta-test sets can also lead to suboptimal performance in few-shot scenarios. This paper introduces a simple yet effective multi-level semantic-assisted prototype learning framework to tackle these challenges. Initially, we leverage CLIP to achieve multimodal adaptation learning and present a multi-level semantic-assisted learning module to enhance the prototypes of different action classes based on semantic information. Additionally, we integrate the lightweight adapters into the CLIP visual encoder to support parameter-efficient transfer learning and improve temporal modeling in videos. Especially, a bias compensation block is employed for feature rectification to mitigate the distribution bias in FSAR stemming from data scarcity. Extensive experiments conducted on five standard benchmark datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Dan Liu and Qing Xia and Fanrong Meng and Mao Ye and Jianwei Zhang},
  doi          = {10.1016/j.neucom.2025.130022},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130022},
  shortjournal = {Neurocomputing},
  title        = {Multi-level semantic-assisted prototype learning for few-shot action recognition},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant and attack-tolerant cooperative
event-triggered sampled-data security control for synchronization of
RDNNs with stochastic actuator failures and random deception attacks.
<em>NEUCOM</em>, <em>636</em>, 130021. (<a
href="https://doi.org/10.1016/j.neucom.2025.130021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the fault-tolerant and attack-tolerant cooperative event-triggered sampled-data security (FACETSDS) synchronization problem of space-varying reaction–diffusion neural networks (SVRDNNs) under spatially point measurements (SPMs) with stochastic actuator failures and random deception attacks is investigated. First, to save more communication resources and adapt to the variation of system dynamics subject to stochastic actuator failures and random deception attacks, a FACETSDS control scheme is proposed under SPMs. Second, by constructing a Lyapunov functional and utilizing inequality techniques, some synchronization criteria based on spatial linear matrix inequalities (SLMIs) are derived for SVRDNNs. Then, to solve SLMIs, the FETSDS control for synchronization problem of SVRDNNs under SPMs with stochastic actuator failures and random deception attacks is formulated as an linear matrix inequality feasibility problem. Lastly, the designed FACETSDS synchronization strategy is verified by one numerical example.},
  archive      = {J_NEUCOM},
  author       = {Feng-Liang Zhao and Zi-Peng Wang and Junfei Qiao and Huai-Ning Wu and Tingwen Huang},
  doi          = {10.1016/j.neucom.2025.130021},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130021},
  shortjournal = {Neurocomputing},
  title        = {Fault-tolerant and attack-tolerant cooperative event-triggered sampled-data security control for synchronization of RDNNs with stochastic actuator failures and random deception attacks},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic facial expression recognition in the wild via
multi-snippet spatiotemporal learning. <em>NEUCOM</em>, <em>636</em>,
130020. (<a href="https://doi.org/10.1016/j.neucom.2025.130020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Facial Expression Recognition (DFER) in-the-wild poses a significant challenge in emotion recognition research. Many studies have focused on extracting finer facial features while overlooking the effect of noisy frames on the entire sequence. In addition, the imbalance between short- and long-term temporal relationships remains inadequately addressed. To tackle these issues, we propose the Multi-Snippet Spatiotemporal Learning (MSSL) framework that uses distinct temporal and spatial modeling for snippet feature extraction, enabling more accurate simulation of subtle facial expression changes while capturing finer details. We also introduced a dual-branch hierarchical module, BiTemporal Multi-Snippet Enhancement (BTMSE), which is designed to capture spatiotemporal dependencies and model subtle visual changes across snippets effectively. The Temporal-Transformer further enhances the learning of long-term dependencies, whereas learnable temporal position embeddings ensure consistency between snippet and fused features over time. By leveraging (2+1)D multi-snippet spatiotemporal modeling, BTMSE, and the Temporal-Transformer, MSSL hierarchically explores the complex interrelationships between temporal dynamics and facial expressions. Comparative experiments and ablation studies confirmed the effectiveness of our method on three large-scale in-the-wild datasets: DFEW, FERV39K, and MAFW.},
  archive      = {J_NEUCOM},
  author       = {Yang Lü and Fuchun Zhang and Zongnan Ma and Bo Zheng and Zhixiong Nan},
  doi          = {10.1016/j.neucom.2025.130020},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130020},
  shortjournal = {Neurocomputing},
  title        = {Dynamic facial expression recognition in the wild via multi-snippet spatiotemporal learning},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation for object detection with diffusion
model. <em>NEUCOM</em>, <em>636</em>, 130019. (<a
href="https://doi.org/10.1016/j.neucom.2025.130019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation is a method that transfers information from a larger network (i.e. the teacher) to a smaller network (i.e. the student), so that the student network can inherit the strong performance of the teacher network while maintaining its computational complexity within a relatively lower range. Currently, knowledge distillation has been widely applied to object detection field to mitigate the rapid expansion of the model size. In this paper, we propose an object detector based on knowledge distillation method. Meanwhile, directly mimicking the features of the teacher often fails to achieve the desired results due to the extra noise in the feature extracted by the student, which causes significant inconsistency and may even weaken the capability of the student. To address this issue, we utilize diffusion model to remove the noise so as to narrow the gap between the features extracted by the teacher and the student, improving the performance of the student. Furthermore, we develop a noise matching module that matches noise level in the student feature during the denoising process. Extensive experiments have been conducted on COCO and Pascal VOC to validate the effectiveness of the proposed method, in which our method achieves 40.0% mAP and 81.63% mAP respectively, while maintaining a frame rate of 27.3FPS, exhibiting the superiority of our model in both accuracy and speed.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Junzong Long and Chunrui Li},
  doi          = {10.1016/j.neucom.2025.130019},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130019},
  shortjournal = {Neurocomputing},
  title        = {Knowledge distillation for object detection with diffusion model},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal multitask similarity learning for vision language
model on radiological images and reports. <em>NEUCOM</em>, <em>636</em>,
130018. (<a href="https://doi.org/10.1016/j.neucom.2025.130018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, large-scale Vision-Language Models (VLM) have shown promise in learning general representations for various medical image analysis tasks. However, current medical VLM methods typically employ contrastive learning approaches that have limited ability to capture nuanced yet crucial medical knowledge, particularly within similar medical images, and do not explicitly consider the uneven and complementary semantic information contained in different modalities. To address these challenges, we propose a novel Multimodal Multitask Similarity Learning (M2SL) method that learns joint representations of image–text pairs and captures the relational similarity between different modalities via a coupling network. Our method also notably leverages the rich information in the text inputs to construct a knowledge-driven semantic similarity matrix as the supervision signal. We conduct extensive experiments for cross-modal retrieval and zero-shot classification tasks on radiological images and reports and demonstrate substantial performance gains over existing methods. Our method also accommodates low-resource settings with limited training data availability and has significant implications for enhancing VLM development.},
  archive      = {J_NEUCOM},
  author       = {Yang Yu and Jiahao Wang and Weide Liu and Ivan Ho Mien and Pavitra Krishnaswamy and Xulei Yang and Jun Cheng},
  doi          = {10.1016/j.neucom.2025.130018},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130018},
  shortjournal = {Neurocomputing},
  title        = {Multimodal multitask similarity learning for vision language model on radiological images and reports},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pinning synchronization of higher-order nonlinear networks
with time delays. <em>NEUCOM</em>, <em>636</em>, 130010. (<a
href="https://doi.org/10.1016/j.neucom.2025.130010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the pinning synchronization problem for a class of nonlinear higher-order time-delay networks. In contrast to previous works, the networks studied possess two distinguishing features: (i) the coupling functions governing the higher-order interactions are nonlinear, and (ii) the networks account for time delays, which include intra-node delays and higher-order interaction delays. The above two features are the key factors influencing the synchronization of the networks. By employing Lyapunov stability theory and algebraic graph theory, we derive sufficient conditions for achieving pinning synchronization in the nonlinear higher-order time-delay networks. Two key challenges in deriving the sufficient conditions arise from the two aforementioned features, which introduce: (i) complex tensor computations and (ii) difficulties in decoupling multi-node interactions. In order to address the challenges, we present a pivotal lemma. This lemma serves as a bridge to transform the complex higher-order problem into a first-order one, reducing the complexity of the derivations. Finally, the validity of the theoretical results is demonstrated through two application examples.},
  archive      = {J_NEUCOM},
  author       = {Weibin Li and Kaixin Lu and Zhichao Liang and Zhongye Xia and Bo Liu and Yanshan Xiao and Quanying Liu},
  doi          = {10.1016/j.neucom.2025.130010},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130010},
  shortjournal = {Neurocomputing},
  title        = {Pinning synchronization of higher-order nonlinear networks with time delays},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). M-MDD: A multi-task deep learning framework for major
depressive disorder diagnosis using EEG. <em>NEUCOM</em>, <em>636</em>,
130008. (<a href="https://doi.org/10.1016/j.neucom.2025.130008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Major depressive disorder (MDD) is a common and destructive psychiatric disorder worldwide. Traditional MDD diagnosis relies heavily on subjective observation and questionnaires. Recently, a non-invasive method of recording the brain’s spontaneous activity called Electroencephalogram (EEG) has been a useful tool of MDD diagnosis. However, there are still some challenges to be addressed: (1) The model’s robustness to common EEG noise has to be improved, (2) The temporal, spectral and spatial features of EEG need to be extracted and fused appropriately. Learning both robust and powerful features for MDD diagnosis can improve the overall performance, and multi-task learning is a powerful solution. In this paper, we propose M-MDD, a multi-task deep learning framework for MDD diagnosis using EEG. First, we design the Contrastive Noise Robustness Task to learn noise-independent features. Then, we design the Supervised Feature Extraction Task to extract temporal, spectral and spatial features of EEG respectively, and then effectively combine them together. Finally, the above two modules share the same feature space and are trained jointly with the Multi-task Learning Module, improving the overall performance. Validated on two public MDD diagnosis datasets with subject-independent cross-validation, our model achieves the state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Yilin Wang and Sha Zhao and Haiteng Jiang and Shijian Li and Tao Li and Gang Pan},
  doi          = {10.1016/j.neucom.2025.130008},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130008},
  shortjournal = {Neurocomputing},
  title        = {M-MDD: A multi-task deep learning framework for major depressive disorder diagnosis using EEG},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring interaction: Inner-outer spatial–temporal
transformer for skeleton-based mutual action recognition.
<em>NEUCOM</em>, <em>636</em>, 130007. (<a
href="https://doi.org/10.1016/j.neucom.2025.130007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based methods have achieved significant results in the field of skeleton-based action recognition. However, when dealing with two-person interaction, existing approaches normally embed the skeleton of each person separately and then introduce an additional module to learn their interactions. This risks losing the spatial and semantic connection information between the two entities, which is crucial for interaction identification. To address this issue, a unified interactive spatial–temporal transformer is proposed in this paper. First, a Two-Person Embedding (TPE) is performed to provide a holistic interactive relationship representation, which can effectively avoid the information gap caused by the division of interacting entities. Second, an innovative Inner-Outer Transformer (IOformer) combining with a new spatio-temporal partition strategy is proposed to simultaneously learn the interactions between intra-partition joints and inter-partition skeletal parts. By comprehensively capturing the key spatio-temporal interactive feature, the accuracy and robustness of interaction recognition can be significantly improved. Extensive experiments on three challenging benchmark datasets validate that our method achieves better performance in comprehensive evaluation methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaotian Wang and Xiang Jiang and Zhifu Zhao and Kexin Wang and Yifan Yang},
  doi          = {10.1016/j.neucom.2025.130007},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130007},
  shortjournal = {Neurocomputing},
  title        = {Exploring interaction: Inner-outer spatial–temporal transformer for skeleton-based mutual action recognition},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Texture dominated no-reference quality assessment for high
resolution image by multi-scale mechanism. <em>NEUCOM</em>,
<em>636</em>, 130003. (<a
href="https://doi.org/10.1016/j.neucom.2025.130003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of new media formats, various high-definition display devices are ubiquitous, and high-resolution (HR) images are essential for high-quality visual experiences. Quality assessment of HR images has become an urgent challenge. However, conventional image quality assessment (IQA) methods with good performance are designed for low-resolution (LR) images, which lacks the perceptual characteristics of HR images, resulting in difficult to achieve satisfactory subjective consistency. Moreover, huge computational costs would have to be consumed when applying those deep neural networks in LR-IQA directly to HR images. Inspired by the fact that regions with rich textures are more sensitive to distortion than others, texture dominated no-reference image quality assessment for HR images are proposed in this paper. Specifically, a dual branch network based on multi-scale technology was designed to extract texture and semantic features separately, and cross scale and dual dimensional attention were introduced to ensure the dominance of texture features. Then, multi-layer perception network is used to map the extracted quality perception feature vectors to the predicted quality score. Worthy of note is that local entropy has been calculated and representative blocks are cropped as inputs to the feature extraction network, greatly reducing computational complexity. Overall, the texture dominated high-resolution IQA network (TD-HRNet) proposed utilizes a reference free method, while could perform excellently on HR datasets of different sizes, image types, and distortion types, accurately predicting the quality of different types of HR images.},
  archive      = {J_NEUCOM},
  author       = {Ziqing Huang and Hao Liu and Zhihao Jia and Shuo Zhang and Yonghua Zhang and Shiguang Liu},
  doi          = {10.1016/j.neucom.2025.130003},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130003},
  shortjournal = {Neurocomputing},
  title        = {Texture dominated no-reference quality assessment for high resolution image by multi-scale mechanism},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time synchronization in p-th moment for stochastic
multi-layer neural networks: An adaptive graph-theoretic lyapunov
functional approach. <em>NEUCOM</em>, <em>636</em>, 130002. (<a
href="https://doi.org/10.1016/j.neucom.2025.130002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the p-th moment synchronization problem for a class of stochastic multi-layer neural networks with intra-layer and inter-layer connections is investigated. Due to the multiple connections with delays and stochastic noise, the typical methodologies that build a canonical linear or expanded matrix model to analyze its stability by constraining eigenvalues in the left-half plane, such as the Kronecker product method, linear matrix inequality and M -matrix approach are tough to tackle the problem. Consequently, a graph-theory-based Lyapunov functional is constructed by combining multiplicative principles and a graph-theoretic approach to help examine the effect of inter- and intra-layer connectivity on a unified framework. With the proposed adaptive fixed-time controller, sufficient conditions for the p-th moment synchronization in a fixed time are derived in terms of algebraic inequality. A corollary, together with a constant-gain fixed-time controller, is presented in case there is no delay. Finally, a confirmatory and two comparative simulations show the effectiveness and convenient implementation of the proposed control strategy.},
  archive      = {J_NEUCOM},
  author       = {Guan-Nan Yu and Xiao-Kang Liu and Yan Lei and Yan-Wu Wang},
  doi          = {10.1016/j.neucom.2025.130002},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130002},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time synchronization in p-th moment for stochastic multi-layer neural networks: An adaptive graph-theoretic lyapunov functional approach},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lag-bipartite consensus control of nonlinear multi-agent
systems with exogenous disturbances via dynamic event-triggered
strategy. <em>NEUCOM</em>, <em>636</em>, 130001. (<a
href="https://doi.org/10.1016/j.neucom.2025.130001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the lag-bipartite consensus issue for nonlinear multi-agent systems with external disturbances via event-triggered mechanisms. Firstly, a disturbance observer is devised to offset disturbances induced from ambient noise or parameter uncertainties. To save needless communication among neighbor agents and enhance the system’s anti-disturbance abilities, the centralized event-based approach and a distributed dynamic event-triggered control scheme with internal dynamic parameters are raised via combining the disturbance compensation strategy, respectively. Unlike existent static triggering approaches, this dynamic triggering scheme widens interval duration between two successive triggering instants. On the basis of both control schemes, a few sufficient conditions are provided to reach lag-bipartite consensus for nonlinear multi-agent systems, while Zeno behavior cannot arise via developed triggering rules. Finally, the validity of presented schemes is illustrated under numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Junsheng Yu and Huizhi Xu and Zhongjun Ma},
  doi          = {10.1016/j.neucom.2025.130001},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130001},
  shortjournal = {Neurocomputing},
  title        = {Lag-bipartite consensus control of nonlinear multi-agent systems with exogenous disturbances via dynamic event-triggered strategy},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed approximate aggregative optimization of multiple
euler–lagrange systems using only sampling measurements.
<em>NEUCOM</em>, <em>636</em>, 130000. (<a
href="https://doi.org/10.1016/j.neucom.2025.130000">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the distributed aggregative optimization for multiple Euler–Lagrange systems over directed networks. First, a new class of auxiliary aggregative variables is proposed that only utilize sampling measurements of adjacent outputs. Then, by selecting a smoothing function, we can gradually integrate the sampling information into new variables within the sampling period. Given the proposed variables, a key theorem is derived to transform the approximate aggregative optimization problem into a regulation problem, such that classical control methods can be utilized to regulate the aggregative variables for more complex dynamics. In addition, an adaptive fuzzy distributed control law is constructed based on aggregative variables, deadzone function and fuzzy system to solve the aggregative optimization for fully actuated Lagrangian agents with bounded disturbance. Finally, a numerical experiment is conducted to demonstrate the validity and effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Cong Li and Qingling Wang},
  doi          = {10.1016/j.neucom.2025.130000},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {130000},
  shortjournal = {Neurocomputing},
  title        = {Distributed approximate aggregative optimization of multiple Euler–Lagrange systems using only sampling measurements},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial–spectral morphological mamba for hyperspectral image
classification. <em>NEUCOM</em>, <em>636</em>, 129995. (<a
href="https://doi.org/10.1016/j.neucom.2025.129995">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in transformers, specifically self-attention mechanisms, have significantly improved hyperspectral image (HSI) classification. However, these models often have inefficiencies, as their computational complexity scales quadratically with sequence length. To address these challenges, we propose the morphological spatial mamba (SMM) and morphological spatial–spectral Mamba (SSMM) model (MorpMamba), which combines the strengths of morphological operations and the state space model framework, offering a more computationally efficient alternative to transformers. In MorpMamba, a novel token generation module first converts HSI patches into spatial–spectral tokens. These tokens are then processed through morphological operations such as erosion and dilation, utilizing depthwise separable convolutions to capture structural and shape information. A token enhancement module refines these features by dynamically adjusting the spatial and spectral tokens based on central HSI regions, ensuring effective feature fusion within each block. Subsequently, multi-head self-attention is applied to enrich the feature representations further, allowing the model to capture complex relationships and dependencies within the data. Finally, the enhanced tokens are fed into a state space module, which efficiently models the temporal evolution of the features for classification. Experimental results on widely used HSI datasets demonstrate that MorpMamba achieves superior parametric efficiency compared to traditional CNN and transformer models while maintaining high accuracy. The source code is available at https://github.com/mahmad000/MorpMamba .},
  archive      = {J_NEUCOM},
  author       = {Muhammad Ahmad and Muhammad Hassaan Farooq Butt and Adil Mehmood Khan and Manuel Mazzara and Salvatore Distefano and Muhammad Usama and Swalpa Kumar Roy and Jocelyn Chanussot and Danfeng Hong},
  doi          = {10.1016/j.neucom.2025.129995},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129995},
  shortjournal = {Neurocomputing},
  title        = {Spatial–spectral morphological mamba for hyperspectral image classification},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decoding motor imagery hand direction in brain computer
interface from direction-dependent modulation of parietal connectivity
using a new brain functional connectivity measure. <em>NEUCOM</em>,
<em>636</em>, 129994. (<a
href="https://doi.org/10.1016/j.neucom.2025.129994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The posterior Parietal Cortex (PPC) of human and nonhuman primates plays a vital role in motor planning. However, EEG functional connectivity correlates within PPC associated with motor intentions are less investigated in the literature. In this study, we investigate whether parietal EEG exhibits direction-dependent modulation of functional connectivity, during bidirectional hand movement imagination in right and left directions. Further, the utility of parietal connectivity modulation patterns, in decoding the directions of imagined hand movement is also evaluated. Imagined movement directions of the dominant hand are decoded using connectivity features derived from parietal EEG. A new brain functional connectivity measure called Cumulative Phase Lag is proposed to evaluate the functional connectivity within the right and left hemispheres of the posterior parietal cortex. Parietal connectivity features are derived from twenty-three EEG subbands from both hemispheres. Further, hemispherical asymmetry is exploited to identify the hemisphere with dominant directive discriminability. Connectivity features of the selected hemisphere are used to identify the most discriminative subband and selected features of the discriminative subband are used to classify the directions of imagined hand movement. The proposed algorithm employing subject-specific connectivity features yielded an average right vs left-hand motor imagery direction decoding accuracy of 79.67 % among 15 healthy subjects. The study results revealed that connectivity patterns in the posterior parietal cortex exhibited direction-dependent variability, suggesting a direction-dependent modulation of connectivity within the posterior parietal cortex. The results suggest the use of the posterior parietal cortex as a potential source of control signals for neuro-prosthetic applications.},
  archive      = {J_NEUCOM},
  author       = {K. Sagila Gangadharan and A.P. Vinod},
  doi          = {10.1016/j.neucom.2025.129994},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129994},
  shortjournal = {Neurocomputing},
  title        = {Decoding motor imagery hand direction in brain computer interface from direction-dependent modulation of parietal connectivity using a new brain functional connectivity measure},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-reference generative exposure correction and adaptive
fusion for low-light image enhancement. <em>NEUCOM</em>, <em>636</em>,
129992. (<a href="https://doi.org/10.1016/j.neucom.2025.129992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing low-light image enhancement methods have the problem of difficulty in enhancing dark areas while controlling overexposed areas in natural images. To address this issue, a Generative Exposure Correction method based on Retinex theory is proposed in this paper, in which the Pseudo-Exposure Residual map and illumination map are deeply coupled based on the proposed intensity compensation prior to constrain the generative network’s output in order to simultaneously deal with overexposure and underexposure. Furthermore, to enhance the effect and prevent over-correction, an exposure fusion technique is proposed, which adaptively selects the best exposure area from the two corrected images and achieves a globally balanced exposure by using an intensity correction compensation operator. More importantly, our proposed method does not require the collection of additional external datasets, which also overcomes the difficulty of data acquisition. Experimental comparisons of our method with the other seven state-of-the-art methods on five public datasets demonstrate that our method achieves the best performance in terms of detail enhancement and natural color preservation.},
  archive      = {J_NEUCOM},
  author       = {Qing Pan and Zirong Zhang and Nili Tian},
  doi          = {10.1016/j.neucom.2025.129992},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129992},
  shortjournal = {Neurocomputing},
  title        = {Zero-reference generative exposure correction and adaptive fusion for low-light image enhancement},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extending evolution-guided policy gradient learning into the
multi-objective domain. <em>NEUCOM</em>, <em>636</em>, 129991. (<a
href="https://doi.org/10.1016/j.neucom.2025.129991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Objective Reinforcement Learning (MORL) poses significant challenges, primarily due to the necessity of balancing conflicting objectives—a limitation that traditional single-objective approaches fail to address. This paper introduces Multi-Objective Evolutionary Reinforcement Learning (MO-ERL), the first adaptation of Evolutionary Reinforcement Learning (ERL) specifically designed to address the complexities of the multi-objective domain effectively. MO-ERL integrates policy gradient-based reinforcement learning (RL), which optimizes expected utility, with evolutionary algorithms (EAs) that maintain diversity across the Pareto front. This combination leverages RL’s strength in exploitation and EAs’ proficiency in exploration, enabling MO-ERL to effectively navigate the trade-offs inherent in multi-objective optimization problems. Evaluation on multi-objective continuous control tasks using the MuJoCo physics engine demonstrates that MO-ERL outperforms state-of-the-art baselines, achieving up to 62.71% higher hypervolume and 196.28% greater expected utility. These results validate MO-ERL’s ability to balance solution diversity and optimality, setting a new benchmark for solving MORL tasks.},
  archive      = {J_NEUCOM},
  author       = {Adam Callaghan and Karl Mason and Patrick Mannion},
  doi          = {10.1016/j.neucom.2025.129991},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129991},
  shortjournal = {Neurocomputing},
  title        = {Extending evolution-guided policy gradient learning into the multi-objective domain},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HSACT: A hierarchical semantic-aware CNN-transformer for
remote sensing image spectral super-resolution. <em>NEUCOM</em>,
<em>636</em>, 129990. (<a
href="https://doi.org/10.1016/j.neucom.2025.129990">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral remote sensing technology has demonstrated its spectral diagnosis advantages in numerous remote sensing observation fields. However, hyperspectral imaging is expensive and less portable compared to RGB imaging. To recover the corresponding hyperspectral image (HSI) from a remote sensing RGB image, this paper proposes a new hierarchical semantic-aware convolutional neural network (CNN)-Transformer (HSACT) for remote sensing image spectral super-resolution (SSR). Particularly, this work aims to reconstruct HSIs from RGB images within the same field of view using a lightweight semantic embedding architecture. Our HSACT consists of the following steps. First, an initial spectrum estimation module (from the RGB image to the HSI) is designed to progressively consider spectral estimation between RGB wavelength-inner and wavelength-outer information. Then, an attention-driven semantic-aware CNN-Transformer is developed to reconstruct the spatial and spectral details of HSI. Specifically, a trainable polymorphic superpixel convolution (PSConv) is proposed to capture features efficiently in the above module. Next, we introduce an information-lossless hierarchical network architecture to link the above modules and achieve end-to-end RGB image SSR through weight sharing. Experimental results on several datasets demonstrated that our HSACT outperforms traditional and advanced SSR methods. The codes of this paper are available from https://github.com/chengle-zhou/HSACT .},
  archive      = {J_NEUCOM},
  author       = {Chengle Zhou and Zhi He and Liwei Zou and Yunfei Li and Antonio Plaza},
  doi          = {10.1016/j.neucom.2025.129990},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129990},
  shortjournal = {Neurocomputing},
  title        = {HSACT: A hierarchical semantic-aware CNN-transformer for remote sensing image spectral super-resolution},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PCSViT: Efficient and hardware friendly pyramid vision
transformer with channel and spatial self-attentions. <em>NEUCOM</em>,
<em>636</em>, 129987. (<a
href="https://doi.org/10.1016/j.neucom.2025.129987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision Transformers (ViT) have been widely used in various visual tasks and have achieved great success due to their advantageous self-attention mechanism. However, most ViT models focus primarily on spatial self-attention, often overlooking the importance of channel attention. In this paper, we propose a channel self-attention module as a complementary addition to the standard self-attention module in ViTs. Then, we introduce an adaptive feed-forward network designed for different attention modules. Based on the proposed self-attention module and adaptive feed-forward network, we propose a flexible Vision Transformer with channel and spatial attentions (CSViT) and conduct a series of experiments to explore the optimal position of different attention modules. Additionally, we introduce PCSViT, which combines the strengths of CSViT and convolutional neural networks (CNNs). PCSViT features a pyramid architecture and incorporates local spatial attention, global spatial attention, and channel attention. We further explore hardware-friendly designs to efficiently implement and accelerate PCSViT on embedded devices. The performance of the proposed methods is evaluated on small datasets CIFAR and Fashion-MNIST, as well as the larger dataset ImageNet. Experimental results show that the proposed model reduces ViT’s reliance on large datasets and outperforms several lightweight state-of-the-art CNN and ViT models across a range of model sizes. The hardware-friendly designs achieve about 10% acceleration on a RISC-V CPU.},
  archive      = {J_NEUCOM},
  author       = {Xiaofeng Zou and Yuanxi Peng and Guoqing Li and Xinye Cao},
  doi          = {10.1016/j.neucom.2025.129987},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129987},
  shortjournal = {Neurocomputing},
  title        = {PCSViT: Efficient and hardware friendly pyramid vision transformer with channel and spatial self-attentions},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adjustable behavior-guided adaptive dynamic programming for
neural learning control. <em>NEUCOM</em>, <em>636</em>, 129986. (<a
href="https://doi.org/10.1016/j.neucom.2025.129986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an adjustable behavior-guided adaptive dynamic programming (BGADP) algorithm is designed to solve the optimal regulation problem for discrete-time systems. In conventional adaptive dynamic programming methods, gradient information of system dynamics is necessary for conducting policy improvement. However, these methods face challenges when gradient information cannot be computed or when the system dynamics is non-differentiable. To overcome these limitations, a human-behavior-inspired swarm intelligence approach is used to search for superior policies during the iterative process, eliminating the need for gradient information. Additionally, a relaxation factor is introduced into the value function update to accelerate the convergence speed of the algorithm. The monotonicity and convergence properties of the iterative value function are rigorously analyzed. Finally, the effectiveness and practicality of the adjustable BGADP algorithm are validated through two simulation studies, which are implemented using the actor–critic framework with neural networks.},
  archive      = {J_NEUCOM},
  author       = {Guohan Tang and Ding Wang and Ao Liu and Junfei Qiao},
  doi          = {10.1016/j.neucom.2025.129986},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129986},
  shortjournal = {Neurocomputing},
  title        = {Adjustable behavior-guided adaptive dynamic programming for neural learning control},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Grid mamba: Grid state space model for large-scale point
cloud analysis. <em>NEUCOM</em>, <em>636</em>, 129985. (<a
href="https://doi.org/10.1016/j.neucom.2025.129985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale point cloud semantic segmentation aims to classify scene point clouds at the pixel level, which is crucial for understanding 3D real-world scenes. Existing Transformer-based models for point cloud segmentation face the challenge of quadratic computational complexity, limiting their ability to handle high-resolution and large-scale point clouds. Inspired by the recently proposed Mamba model, known for its efficient long-sequence modeling capabilities, we propose Grid Mamba in this work, which is a specialized network tailored for large-scale point cloud learning, achieving global linear computational complexity. Grid Mamba’s highlights consist of three parts: Grid Multi-view Scanning, Grid Sparsity Pooling, and Grid Mamba Block. Grid Multi-view Scanning can reduce the loss of spatial proximity caused by serialization. Grid Sparsity Pooling addresses the issue of local information loss during the pooling stage of large-scale point clouds. Additionally, Grid Mamba Block overcomes the limitations of Mamba in scene point cloud feature interactions. Extensive experimental results demonstrate that Grid Mamba achieves outstanding performance across multiple indoor and outdoor scene datasets.},
  archive      = {J_NEUCOM},
  author       = {Yulong Yang and Tianzhou Xun and Kuangrong Hao and Bing Wei and Xue-song Tang},
  doi          = {10.1016/j.neucom.2025.129985},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129985},
  shortjournal = {Neurocomputing},
  title        = {Grid mamba: Grid state space model for large-scale point cloud analysis},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GCD-net: Global consciousness-driven open-vocabulary
semantic segmentation network. <em>NEUCOM</em>, <em>636</em>, 129982.
(<a href="https://doi.org/10.1016/j.neucom.2025.129982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Open-vocabulary semantic segmentation aims to achieve accurate classification of different categories of pixels, even if these categories are not explicitly labeled during training. The current research trend in this field emphasizes the utilization of pre-trained visual–language models to augment exploration capabilities. The core of these methods is to use image-level models to guide the segmentation process at the pixel level, thereby enhancing the model’s ability to recognize and segment unseen categories during training. However, many approaches overlook global information, which may lead to a lack of comprehensive scene understanding when processing images. Thereby, GCD-Net is introduced as an innovative open-vocabulary semantic segmentation framework, which integrates a novel decoder with a hierarchical encoder to form an encoder–decoder architecture. The hierarchical encoder leverages a hierarchical backbone network to generate a pixel-level image–text cost map, which preserves spatial information effectively at different levels. The proposed decoder, known as the Feature Fusion Decoder, comprises three pivotal modules: the Global Feature Extraction Module, the Visual Enhancement Module, and the Feature Aggregation Module. These modules cooperate to process hierarchical feature maps from different levels to capture global context information and effectively aggregate pixel blocks into semantic regions for high-quality open-vocabulary semantic segmentation. Experiments on multiple open-vocabulary semantic segmentation datasets demonstrate that GCD-Net achieves an mIoU score of 17.5% on PC-459 and 94.3% on PAS-20, verifying the effectiveness and superiority of the method.},
  archive      = {J_NEUCOM},
  author       = {Xing Wu and Zhenyao Xu and Quan Qian and Bin Huang},
  doi          = {10.1016/j.neucom.2025.129982},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129982},
  shortjournal = {Neurocomputing},
  title        = {GCD-net: Global consciousness-driven open-vocabulary semantic segmentation network},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimized inverse dead-zone formation control using
reinforcement learning for the nonlinear single-integrator dynamic
multi-agent system. <em>NEUCOM</em>, <em>636</em>, 129981. (<a
href="https://doi.org/10.1016/j.neucom.2025.129981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an optimized inverse dead-zone formation control using identifier–critic–actor reinforcement learning (RL) is studied for the nonlinear single-integral dynamic multi-agent system (MAS). Since MAS formation is often accompanied with a high energy expenditure, it is very necessary and essential to take optimization as a control design principle. In order to smoothly achieve the optimized MAS formation control, a simplified RL is developed by performing the gradient descent method to a simple positive function, which is equivalent to Hamilton–Jacobi–Bellman (HJB) equation. Furthermore, since the MAS formation cooperation is depended on the information exchange among agents, it is very possible to happen the control dead-zone phenomenon, which makes the actuator without control signal. For eliminating the effect of dead-zone, an adaptive inverse dead-zone method is developed and then is combined with RL for this optimized formation control. In comparison to the conventional inverse dead-zone approach, this design has the less adaptive parameters. Finally, the results of theoretical and simulation demonstrate viability of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Guoxing Wen and Wenxia Sun and Shuaihua Ma},
  doi          = {10.1016/j.neucom.2025.129981},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129981},
  shortjournal = {Neurocomputing},
  title        = {Optimized inverse dead-zone formation control using reinforcement learning for the nonlinear single-integrator dynamic multi-agent system},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shading- and geometry-aware lighting calibration network for
uncalibrated photometric stereo. <em>NEUCOM</em>, <em>636</em>, 129979.
(<a href="https://doi.org/10.1016/j.neucom.2025.129979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional measurement provides essential geometric information for fault diagnosis and product optimization in intelligent manufacturing applications. Photometric stereo is a non-destructive 3D measurement technique that estimates the surface normals of objects using shading cues from images under different lighting conditions. However, the generalized bas-relief (GBR) ambiguity caused by unknown or varying lighting will significantly decrease measurement accuracy. To address this issue, we propose a shading- and geometry-aware lighting calibration network (SGLC-Net) to mitigate the inherent ambiguity and enhance surface normal estimation in uncalibrated photometric stereo by generating accurate lighting information. The proposed method iteratively optimizes lighting direction and intensity by leveraging self-generated shading and normal prior features. To further improve the accuracy of the lighting estimation, we introduce collocated light into SGLC-Net to implicitly extract shading features of images to generate accurate rough lighting. Accurate rough lighting can generate accurate shading and normal prior features, which can be used to optimize rough lighting to generate fine lighting. Experimental results indicate that the proposed method significantly outperforms most uncalibrated photometric stereo methods in lighting estimation on multiple real-world datasets. Furthermore, our method can seamlessly integrate with most uncalibrated photometric stereo methods to effectively enhance the accuracy of the surface normal estimation under unknown illumination.},
  archive      = {J_NEUCOM},
  author       = {Yuze Yang and Jiahang Liu and Yangyu Fu and Yue Ni and Yan Xu},
  doi          = {10.1016/j.neucom.2025.129979},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129979},
  shortjournal = {Neurocomputing},
  title        = {Shading- and geometry-aware lighting calibration network for uncalibrated photometric stereo},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing offline reinforcement learning for wastewater
treatment via transition filter and prioritized approximation loss.
<em>NEUCOM</em>, <em>636</em>, 129977. (<a
href="https://doi.org/10.1016/j.neucom.2025.129977">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wastewater treatment plays a crucial role in urban society, requiring efficient control strategies to optimize its performance. In this paper, we propose an enhanced offline reinforcement learning (RL) approach for wastewater treatment. Our algorithm improves the learning process. It uses a transition filter to sort out low-performance transitions and employs prioritized approximation loss to achieve prioritized experience replay with uniformly sampled loss. Additionally, the variational autoencoder is introduced to address the problem of distribution shift in offline RL. The proposed approach is evaluated on a nonlinear system and wastewater treatment simulation platform, demonstrating its effectiveness in achieving optimal control. The contributions of this paper include the development of an improved offline RL algorithm for wastewater treatment and the integration of transition filtering and prioritized approximation loss. Evaluation results demonstrate that the proposed algorithm achieves lower tracking error and cost.},
  archive      = {J_NEUCOM},
  author       = {Ruyue Yang and Ding Wang and Menghua Li and Chengyu Cui and Junfei Qiao},
  doi          = {10.1016/j.neucom.2025.129977},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129977},
  shortjournal = {Neurocomputing},
  title        = {Enhancing offline reinforcement learning for wastewater treatment via transition filter and prioritized approximation loss},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VLSG-net: Vision-language scene graphs network for paragraph
video captioning. <em>NEUCOM</em>, <em>636</em>, 129976. (<a
href="https://doi.org/10.1016/j.neucom.2025.129976">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Paragraph Video captioning seeks to automatically describe multiple events in a video. Despite significant progress, most current approaches fail to fully leverage scene graph knowledge when performing cross-modal alignment between video and text representations. Consequently, such methods may not learn causal associations between entities, leading to a degradation in captioning performance. In this paper, we propose an end-to-end Vision-Language Scene Graphs Network (VLSG-net) to address this issue. We first introduce an encoder that integrates scene graph knowledge with global features and predicates to understand visual scenes. Specifically, scene graph knowledge detects entities and models their correlations and constraints, enabling the representation of relationships between various entities. We then introduce a Knowledge-Enhanced Encoder paired with a contrastive loss to leverage scene graph knowledge, thereby enhancing multimodal structured representations. Finally, we propose a transformer-in-transformer decoder to model the coherency of intra- and inter-event relationships within the video and generate captions. By incorporating relationship reasoning among entities through scene graphs and video-language alignment learning, VLSG-net generates more logical and detailed captions. Extensive experiments confirm that VLSG-net performs favorably against the state-of-the-art methods on two widely used benchmark datasets, ActivityNet Captions, and YouCookII.},
  archive      = {J_NEUCOM},
  author       = {Yufeng Hou and Qingguo Zhou and Hui Lv and Lan Guo and Yan Li and La Duo and Zhenyu He},
  doi          = {10.1016/j.neucom.2025.129976},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129976},
  shortjournal = {Neurocomputing},
  title        = {VLSG-net: Vision-language scene graphs network for paragraph video captioning},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving and byzantine-robust federated broad
learning with chain-loop structure. <em>NEUCOM</em>, <em>636</em>,
129975. (<a href="https://doi.org/10.1016/j.neucom.2025.129975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) can collaboratively train a model by aggregating local models instead of aggregating raw data, which can protect privacy by ensuring that data remains on the client. However, the traditional FL still faces some challenges such as privacy leakage and the presence of Byzantine clients. We propose a privacy-preserving and Byzantine-robust federated broad learning framework with chain-loop structure i.e., PBFBL-CL, and this algorithm can simultaneously achieve protection of clients’ privacy and robustness against Byzantine attacks. In this paper, we apply Byzantine step-by-step co-validation algorithm to address the existence of Byzantine clients. We pass the aggregated model through the chain, so each client’s privacy is well protected. Moreover, PBFBL-CL can reduce the communication overhead between clients and server. Finally, we evaluate the PBFBL-CL algorithm in MNIST, Fashion-MNIST and NORB datasets, and the results show that our algorithm is better than existing FL algorithms in terms of model accuracy and training speed. Experimental results demonstrate that under the extreme scenario where Byzantine client proportion reaches 90%, the model achieves an accuracy of 89.53%, only 4.17% lower than the 93.7% accuracy observed in the ideal scenario without Byzantine clients.},
  archive      = {J_NEUCOM},
  author       = {Nan Li and Chang-E Ren and Siyao Cheng},
  doi          = {10.1016/j.neucom.2025.129975},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129975},
  shortjournal = {Neurocomputing},
  title        = {Privacy-preserving and byzantine-robust federated broad learning with chain-loop structure},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectrum-guided spatial feature enhancement network for
event-based lip-reading. <em>NEUCOM</em>, <em>636</em>, 129974. (<a
href="https://doi.org/10.1016/j.neucom.2025.129974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Automatic Lip-reading task aims to recognize spoken words through visual cues from the speaker’s lip movements. This crucial task complements audio-based speech recognition systems and can substitute them when sound is unavailable. Event-based lip-reading methods have gained increasing attention due to the advantages of event cameras, such as high temporal resolution and low power consumption. However, existing methods often fail to fully utilize the spatial information in event data due to its sparsity and the presence of random activations. To address this, we propose a novel Spectral-guided Spatial Enhancement Network (SSE-Net). SSE-Net introduces two core innovations: the Spectrum-guided Spatial Feature Enhance Module (SSEM) and the Multi-Scale Spatial Interaction Module (MS-SIM). SSEM employs frequency domain enhancement and spatial feature enhancement strategies to augment spatial features crucial for event-based lipreading tasks. MS-SIM conducts the fusion and interaction of multi-level semantics, enriching the contextual information of lip representations. We conducted experiments on the event-based lip-reading dataset DVS-Lip with our proposed method and demonstrated its superiority over other state-of-the-art event-based lip-reading methods.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Xiuping Liu and Hongchen Tan and Xin Li},
  doi          = {10.1016/j.neucom.2025.129974},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129974},
  shortjournal = {Neurocomputing},
  title        = {Spectrum-guided spatial feature enhancement network for event-based lip-reading},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HRL-painter: Optimal planning painter based on hierarchical
reinforcement learning. <em>NEUCOM</em>, <em>636</em>, 129972. (<a
href="https://doi.org/10.1016/j.neucom.2025.129972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stroke-based rendering method has shown its superiority in generating stylized paintings from realistic photographs. However, the existing methods often divide the image into regular blocks for parallel painting or start painting by progressively narrowing down the painting region from the entire canvas. Not only does this lead to an irrational allocation of stroke resources, but also deviates from the painting approach employed by human artists. To address this, we propose a novel painting method based on hierarchical reinforcement learning, namely HRL-Painter, which consists of a high-level agent that strategically plans the sequence of painting regions and a low-level agent that carries out specific painting tasks in the corresponding regions. In the initial stage, we consider the entire canvas as the painting region and then use a small number of strokes for a rough depiction. Next, our high-level agent plans the optimal sequence of painting regions based on the content of the target image, taking into account the error between the current canvas and the target image. Finally, the low-level agent is dedicated to executing detailed painting tasks within the painting regions proposed by the high-level agent. Extensive experiments on standard datasets including CelebA , ImageNet , CUB-200 Birds and Stanford Cars-196 demonstrate that our proposed hierarchical painting agent not only produce high-quality canvases but also exhibit a painting process that closely resembles the human painting style, showcasing excellent interpretability.},
  archive      = {J_NEUCOM},
  author       = {Jiong Zhang and Guangxin Xu and Xiaoyan Zhang},
  doi          = {10.1016/j.neucom.2025.129972},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129972},
  shortjournal = {Neurocomputing},
  title        = {HRL-painter: Optimal planning painter based on hierarchical reinforcement learning},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed neural predictor enhanced coordinated control of
AUVs. <em>NEUCOM</em>, <em>636</em>, 129971. (<a
href="https://doi.org/10.1016/j.neucom.2025.129971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates an enhanced tunnel prescribed performance coordinated control problem of multiple autonomous underwater vehicles (AUVs) under initial constraints. To meet high performance requirements in complex underwater conditions, AUV control faces challenges. In order to address these, an enhanced tunnel prescribed performance (ETPP) method is proposed, which is composed of composite error scaling function (CESF) and tunnel prescribed performance (TPP). In particular, a CESF-based error transformation is performed to scale the tracking error within the TPP limits. In the guidance loop, an ETPP-based guidance law is devised to guarantee the transient and steady-state behavior of the tracking error. In the control loop, based on the distributed learning strategy with weighted average, a quantized input-based distributed neural predictor (QDNP) is proposed to estimate the unknown external disturbances. Using the antidisturbance technique, a QDNP-based quantized control law is designed to stabilize multi-AUV formations. The uniformly ultimately bounded (UUB) stability of the overall closed-loop system is established in the Lyapunov sense. Finally, simulation examples with four AUVs are provided to demonstrate the effectiveness of the proposed distributed tunnel performance-guaranteed coordinated control method.},
  archive      = {J_NEUCOM},
  author       = {Minjing Wang and Di Wu and Lei Qiao and Rui Gao and Wenlong Feng},
  doi          = {10.1016/j.neucom.2025.129971},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129971},
  shortjournal = {Neurocomputing},
  title        = {Distributed neural predictor enhanced coordinated control of AUVs},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rad-mark: Reliable adversarial zero-watermarking.
<em>NEUCOM</em>, <em>636</em>, 129970. (<a
href="https://doi.org/10.1016/j.neucom.2025.129970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-watermarking is a lossless protection technique, and thus it is widely used in medical images, artworks and other carriers that require lossless protection. However, the current zero-watermarking suffers from the problem of high similarity between the feature images of different host images, which results in a high false positive rate. To address this challenge, we propose Rad-Mark, a deep learning-based zero-watermarking framework that leverages adversarial feature optimization to enhance the robustness and accuracy of watermark detection significantly for the first time. The adversarial samples are employed to significantly improve the framework’s security, which can achieve the NC value of false positives close to 0.5. Both image perturbation and Gaussian noise are incorporated into the training process. Specifically, our Rad-Mark involves a feature fusion design, a mapping network based on the fusion of locally filtered and global handcrafted features. We conduct an in-depth analysis of key parameters, including Gaussian noise, watermark dimensions, and weighting factors, exploring their impact on the performance of our Rad-Mark. Extensive experimental results demonstrate that Rad-Mark outperforms existing zero-watermarking methods in terms of both security and robustness.},
  archive      = {J_NEUCOM},
  author       = {Kun Hu and Dakai Zhai and Heng Gao and Haoyu Xie and Xingjun Wang},
  doi          = {10.1016/j.neucom.2025.129970},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129970},
  shortjournal = {Neurocomputing},
  title        = {Rad-mark: Reliable adversarial zero-watermarking},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An event-triggered reliable cloud control scheme based on
ADP and integral sliding mode. <em>NEUCOM</em>, <em>636</em>, 129968.
(<a href="https://doi.org/10.1016/j.neucom.2025.129968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates event-triggered (ET) reliable control problems for cloud control systems under actuator faults and data injection attacks via the adaptive dynamic programming (ADP) and integral sliding mode (ISM). A mist-fog-regional cloud control architecture is first given, which can improve computing efficiency of the cloud platform. In this architecture, a fog-based fault parameter estimation method is proposed with the aid of neural networks. It is driven by the feedback of fault parameter estimation errors, so as to achieve more accurate estimations of fault parameters. A double ET reliable cloud control scheme is further presented. It is composed of an ISM-based and an ADP-based regional cloud controllers. As a result, it not only saves communication resources, but also eliminates the influence of the attacks and matched uncertainties, as well as ensures the stability of the equivalent sliding-mode dynamics with optimal performance. Finally, the effectiveness of the proposed method is verified by the simulation results.},
  archive      = {J_NEUCOM},
  author       = {Xin Huang and Sicheng Bi and Xinyu Han and Shuyi Xiao and Qingyu Su},
  doi          = {10.1016/j.neucom.2025.129968},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129968},
  shortjournal = {Neurocomputing},
  title        = {An event-triggered reliable cloud control scheme based on ADP and integral sliding mode},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A memory failure computational model in alzheimer-like
disease via continuous delayed hopfield network with lurie control
system based healing. <em>NEUCOM</em>, <em>636</em>, 129967. (<a
href="https://doi.org/10.1016/j.neucom.2025.129967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a degenerative neurological condition that impacts millions of individuals across the globe and remains without a healing. In the search for new possibilities of treatments for this terrible disease, this work presents the improved Alzheimer-like disease (IALD) model for memory failure and connects it to a new control technique that establishes a cure for the memory lost, either in biological or in artificial neural networks. For the IALD model, continuous Hopfield neural networks (HNN) with time delay are used. From the healing side, a robust control technique is used, which is based on new discoveries in Lurie control systems. In addition, this paper reviews the development of Alzheimer-like disease (ALD) model, as well as, the relationship of HNN with Lurie system. Simulations are executed to validate the model and to show the efficacy of applying a new theorem from Lurie problem. With the results presented, this work proposes a new conceptual paradigm that could potentially be applied in memory failure treatments in AD, as well as in hardware implemented HNN under adversarial attacks or adverse environmental conditions.},
  archive      = {J_NEUCOM},
  author       = {Rafael Fernandes Pinheiro and Diego Colón and Rui Fonseca-Pinto},
  doi          = {10.1016/j.neucom.2025.129967},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129967},
  shortjournal = {Neurocomputing},
  title        = {A memory failure computational model in alzheimer-like disease via continuous delayed hopfield network with lurie control system based healing},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-grained hierarchical singular value decomposition for
convolutional neural networks compression and acceleration.
<em>NEUCOM</em>, <em>636</em>, 129966. (<a
href="https://doi.org/10.1016/j.neucom.2025.129966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) still remain crucial in the field of computer vision, especially in industrial-embedded scenarios. Although modern artificial intelligence chips such as embedded graphics processing units (GPUs) and neural process units (NPUs) are equipped with sufficient computability, making CNNs more lightweight always has non-negligible significance. Until now, many researchers have made multiple corresponding achievements, in which a series of tensor decomposition methods have represented their unique advantages such as concision, flexibility, and low-rank approximation theory. However, balancing the compression, acceleration, and precision, is still an open issue, because the traditional tensor decompositions are hard to deal with the trade-off between approximation and compression ability, while the so-called fine-grained tensor decompositions such as Kronecker canonical polyadic (KCP) have not created a way to merge the factors for efficient inference. In this paper, we first review related works on convolutional neural network (CNN) compression and the necessary prior knowledge. We then propose a novel matrix decomposition method, termed hierarchical singular value (HSV) decomposition, and validate its effectiveness. Subsequently, we introduce a fast contraction strategy based on the merged factors of HSV and explain how our method addresses the inefficiencies in inference associated with traditional contraction processes. Additionally, we validate the advantages of HSV by comparing its complexity with that of other classical tensor decomposition methods. Thereafter, we apply HSV to CNN compression and acceleration by transforming convolution operations into matrix multiplication. We also propose a self-adaptive rank selection algorithm tailored to standard CNN architecture and conduct a theoretical analysis of the convergence of our method. Multiple experiments on CIFAR-10, ImageNet, COCO, and Cityscapes benchmark datasets show that the proposed HSV-Conv can simultaneously gain considerable compression ratio and acceleration ratio, while the precision loss is almost non-existent. We also make a comprehensive comparison with the other related works, and the superiority of our method is further validated. Besides, we give a deep discussion about the rank selection issue of HSV in the aspects of practice and theory, which explains the strategy of the proposed self-adaptive rank selection and the reason for choosing fine-tuning rather than training from scratch.},
  archive      = {J_NEUCOM},
  author       = {Mengmeng Qi and Dingheng Wang and Wei Yang and Baorong Liu and Fuyong Wang and Zengqiang Chen},
  doi          = {10.1016/j.neucom.2025.129966},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129966},
  shortjournal = {Neurocomputing},
  title        = {Fine-grained hierarchical singular value decomposition for convolutional neural networks compression and acceleration},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level feature splicing 3D network based on multi-task
joint learning for video anomaly detection. <em>NEUCOM</em>,
<em>636</em>, 129964. (<a
href="https://doi.org/10.1016/j.neucom.2025.129964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In video anomaly detection research, deep learning is dedicated to identifying anomalous events accurately and efficiently. However, due to the scarcity and diversity of anomaly samples, previous methods have not adequately taken into account important information about location and timing. In addition, the overpowered generalization ability of the models leads to the fact that anomalies can also be well reconstructed or predicted. To address the above challenges, we propose a 3D network based on multi-level feature splicing with joint multi-task learning. The network is improved by the autoencoder (AE) as a backbone network. Firstly, we design a normal sample training task and a Gaussian noise task from a spatial perspective to enhance the reconstruction of positive samples. The frame-skipping task and the inverse sequence task of the video are designed from the temporal perspective to suppress the reconstruction ability of negative samples. Secondly, we use multi-level feature splicing in the encoding and decoding process to equip the network with the ability to explore sufficient information from the full scale. At the same time, we use an attention gating module to filter redundant features. The results show that our network is competitive with state-of-the-art methods. In terms of AUC, UCSD Ped2 achieves 99.3%, CUHK Avenue achieves 88.4%, and ShanghaiTech Campus achieves 74.2%.},
  archive      = {J_NEUCOM},
  author       = {Yang Li and Guoxiang Tong},
  doi          = {10.1016/j.neucom.2025.129964},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129964},
  shortjournal = {Neurocomputing},
  title        = {Multi-level feature splicing 3D network based on multi-task joint learning for video anomaly detection},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). L2M-GCN: A new framework for learning robust GCN against
structural attacks. <em>NEUCOM</em>, <em>636</em>, 129962. (<a
href="https://doi.org/10.1016/j.neucom.2025.129962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Convolutional Networks (GCNs) have gained extensive attention due to their strong ability to learn from graphs. However, with the advent of stealthy attacks that cause significant differences in node embeddings, the vulnerability of GCNs to malicious attacks has been exposed. Although there are many studies on defense in the spatial or spectral domains, they neglect the complementary roles of the two. In this paper, we propose a new framework, Low frequency and 2-hop in Multi-channel GCN (L2M-GCN), which combines spatial and spectral defense. L2M-GCN has two GCN-based modules. In module one, a new structure reconstructed from learnable spectrum and low-frequency components replaces the adjacency matrix in GCN. In module two, purified 2-hop is introduced and the attention mechanism is used to learn the importance weights of node embeddings. The two modules are eventually assembled into L2M-GCN for joint learning in a parameter-sharing and end-to-end fashion. Extensive experiments demonstrate that L2M-GCN significantly improves the defense performance against structural attacks and outperforms the baselines and state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Haoran Chen and Xianchen Zhou and Jiwei Zhang and Hongxia Wang},
  doi          = {10.1016/j.neucom.2025.129962},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129962},
  shortjournal = {Neurocomputing},
  title        = {L2M-GCN: A new framework for learning robust GCN against structural attacks},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Channel pruning for convolutional neural networks using
l0-norm constraints. <em>NEUCOM</em>, <em>636</em>, 129925. (<a
href="https://doi.org/10.1016/j.neucom.2025.129925">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Channel pruning can effectively reduce the size and inference time of Convolutional Neural Networks (CNNs). However, existing channel pruning methods still face several issues, including high computational costs, extensive manual intervention, difficulty in hyperparameter tuning, and challenges in directly controlling the sparsity. To address these issues, this paper proposes two channel pruning methods based on l 0 -norm sparse optimization: the l 0 -norm Pruner and the Automated l 0 -norm Pruner. The l 0 -norm Pruner formulates the channel pruning problem as a sparse optimization problem involving the l 0 -norm and achieves a fast solution through a series of approximations and transformations. Inspired by this solution process, we devise the Zero-Norm (ZN) module, which can autonomously select output channels for each layer based on a predefined global pruning ratio. This approach incurs low computational cost and allows for precise control over the overall pruning ratio. Furthermore, to further enhance the performance of the pruned model, we have developed the Automated l 0 -norm Pruner. This method utilizes a Bee Colony Optimization algorithm to adjust the pruning ratio, mitigating the negative impact of manually preset pruning ratios on model performance. Our experiments demonstrate that the proposed pruning methods outperform several state-of-the-art techniques. The source code for our proposed methods is available at: https://github.com/TCCofWANG/l0_prune .},
  archive      = {J_NEUCOM},
  author       = {Enhao Chen and Hao Wang and Zhanglei Shi and Wei Zhang},
  doi          = {10.1016/j.neucom.2025.129925},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129925},
  shortjournal = {Neurocomputing},
  title        = {Channel pruning for convolutional neural networks using l0-norm constraints},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cascade-UDA: A cascade paradigm for unsupervised domain
adaptation. <em>NEUCOM</em>, <em>636</em>, 129924. (<a
href="https://doi.org/10.1016/j.neucom.2025.129924">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation (UDA) aims to enhance the performance of models on unlabeled target domains by utilizing labeled data from a related source domain. However, existing UDA methods often struggle with semantic confusion and distribution shifts. To address these issues, we propose a novel two-stage UDA framework called Cascade-UDA. In the first stage, we fine-tune CLIP-LoRA on the source domain to learn class-related, domain-invariant features while preserving semantic integrity. In the second stage, we freeze the fine-tuned CLIP-LoRA and introduce a textual prompt for target domain adaptation, refining pseudo-labels with knowledge from the source domain. Our proposed method effectively decouples semantic learning from domain-specific adaptation, enhancing performance on the target domain. Extensive experiments on public datasets demonstrate the superiority of our approach over existing methods.},
  archive      = {J_NEUCOM},
  author       = {Mengmeng Zhan and Zongqian Wu and Huafu Xu and Xiaofeng Zhu and Rongyao Hu},
  doi          = {10.1016/j.neucom.2025.129924},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129924},
  shortjournal = {Neurocomputing},
  title        = {Cascade-UDA: A cascade paradigm for unsupervised domain adaptation},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). YOLO-ELWNet: A lightweight object detection network.
<em>NEUCOM</em>, <em>636</em>, 129904. (<a
href="https://doi.org/10.1016/j.neucom.2025.129904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a YOLO-based efficient lightweight network (YOLO-ELWNet) for onboard object detection based on the YOLOv3. A channel split and shuffle with coordinate attention module is developed in the backbone block, which effectively reduces the size of model parameters and computational cost while maintaining the detection accuracy. A new feature fusion network is proposed in the neck block, where a cross-stage partial with efficient bottleneck module is put forward to improve the feature extraction ability and reduce the computational cost. The Scylla intersection over union-based loss function is utilized in the head block, which accelerates the convergence speed of the YOLO-ELWNet. The effectiveness of the proposed YOLO-ELWNet is validated on the open source KITTI vision benchmark. The performance of YOLO-ELWNet is superior to some mainstream lightweight object detection models in terms of detection accuracy and computational cost, which demonstrates its applicability for resource-constrained onboard object detection.},
  archive      = {J_NEUCOM},
  author       = {Baoye Song and Jianyu Chen and Weibo Liu and Jingzhong Fang and Yani Xue and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2025.129904},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129904},
  shortjournal = {Neurocomputing},
  title        = {YOLO-ELWNet: A lightweight object detection network},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCFT: Dependency-aware continual learning fine-tuning for
sparse LLMs. <em>NEUCOM</em>, <em>636</em>, 129897. (<a
href="https://doi.org/10.1016/j.neucom.2025.129897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the size of Large Language Models (LLMs) increasing, they exhibit enhanced capabilities in general intelligence but also present greater challenges in deployment. Consequently, compressing LLMs has become critically important. Among the various compression techniques, post-training pruning is highly favored by researchers due to its efficiency. However, this one-shot pruning approach often results in a significant deterioration of model performance. To mitigate this issue, we introduce Dependency-aware Continual learning Fine-Tuning (DCFT) for sparse LLMs. This method facilitates fine-tuning across sequential tasks without compromising the model’s sparsity. Initially, we revisit the inference process in LLMs from a novel perspective, treating two matrices that previously required independent optimization as a unified entity. This strategy involves introduces merely 0.011‰ additional parameters to achieve efficient fine-tuning. Furthermore, we re-evaluate the parameter fine-tuning process through the lens of matrix space mapping. By constraining the similarity of the mapping matrices, our approach enables the model to retain its performance on prior tasks while learning new ones. We tested our method on models from the LLaMA-V1/V2 families, with parameters ranging from 7B to 70B, and under various sparsity ratios and patterns (unstructured and N:M sparsity). The results consistently demonstrate outstanding performance.},
  archive      = {J_NEUCOM},
  author       = {Yanzhe Wang and Yizhen Wang and Baoqun Yin},
  doi          = {10.1016/j.neucom.2025.129897},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129897},
  shortjournal = {Neurocomputing},
  title        = {DCFT: Dependency-aware continual learning fine-tuning for sparse LLMs},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel spatiotemporal network to recognize
micro-expression. <em>NEUCOM</em>, <em>636</em>, 129891. (<a
href="https://doi.org/10.1016/j.neucom.2025.129891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expressions are fleeting spontaneous facial expressions that commonly occur in high-stakes scenarios and reflect humans’ mental states. Thus, it is one of the crucial clues for lie detection. Furthermore, due to the brief duration of micro-expression, temporal information is important for micro-expression recognition. The paper proposes a Parallel Spatiotemporal Network (PSN) to recognize micro-expression. The proposed PSN includes a spatial sub-network and a temporal sub-network. The spatial sub-network is a shallow network with subtle motion information as the input. And the temporal sub-network is a network with a novel temporal feature extraction unit that extracts sparse temporal features of micro-expressions. Finally, we propose an element-wise addition with 1 × 1 convolutional kernel fusion model to fuse the spatial and temporal features. The proposed PSN gets better measurement metrics (such as recognition rate, F1 score, true positive rate, and true negative rate) than the other state-of-the-art methods on the consisted databases consisting of CASME, CASME II, CAS(ME) 2 , and SAMM.},
  archive      = {J_NEUCOM},
  author       = {Jingting Li and Su-Jing Wang and Yong Wang and Haoliang Zhou and Xiaolan Fu},
  doi          = {10.1016/j.neucom.2025.129891},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129891},
  shortjournal = {Neurocomputing},
  title        = {Parallel spatiotemporal network to recognize micro-expression},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Farewell to CycleGAN: Single GAN with decoupled constraint
for unpaired image dehazing. <em>NEUCOM</em>, <em>636</em>, 129888. (<a
href="https://doi.org/10.1016/j.neucom.2025.129888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unpaired image dehazing has attracted more and more attention, since the pair-wise training data which is prerequisite for the supervised dehazing methods leads to high cost if they are really captured or performance degradation on the real-hazy scenes if they are synthesized. The existing methods for unpaired image dehazing are all based on the CycleGAN-like framework with pixel-to-pixel constraint, which leads to burdensome model complexity and unstable training. In this paper, we propose a novel single GAN model for unpaired image dehazing (SinGAN-Dehaze), which gets rid of the cycle-consistency constraint. To be specific, the cycle-consistency is decoupled to content-consistency and style-consistency, where the pixel-to-pixel mapping is replaced by the patch-to-patch semantic mapping. The content-consistency is ensured by capturing local distinctive representations and global contextual dependencies. The style-consistency is achieved by forcing the high-frequency information distribution of dehazing result close to that of the clear image with similar style. Extensive experiments demonstrate that our proposal can achieve superior performance for unpaired image dehazing in terms of the objective index and visual effect on both synthetic and real-hazy scenarios.},
  archive      = {J_NEUCOM},
  author       = {Xiaotong Luo and Wenjin Yang and Yuan Xie and Yanyun Qu},
  doi          = {10.1016/j.neucom.2025.129888},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129888},
  shortjournal = {Neurocomputing},
  title        = {Farewell to CycleGAN: Single GAN with decoupled constraint for unpaired image dehazing},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid approach combining sentiment analysis and deep
learning to mitigate data sparsity in recommender systems.
<em>NEUCOM</em>, <em>636</em>, 129886. (<a
href="https://doi.org/10.1016/j.neucom.2025.129886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of recommendation systems (RS) is crucial for delivering personalized product suggestions. Despite their successes, RS approaches often face challenges, such as data sparsity in the user–item matrix, which can undermine their performance. To address these challenges, integrating additional information sources, such as item/user profiles and textual reviews, is essential. These sources offer valuable insights into user preferences and item characteristics, helping in understanding the contextual details of both. This study focuses on developing an advanced RS architecture that combines Singular Value Decomposition (SVD) with BERT-CB methods and a Hybrid Model-based Sentiment Analysis. By integrating BERT with Multilayer Perceptron (MLP) methods, the system gains a deeper understanding of item profiles, improving the comprehension of user preferences and item characteristics. Additionally, a novel hybrid approach for sentiment analysis is proposed, using GloVe embeddings and CNN-BiGRU, improving the accuracy and robustness of sentiment detection in user reviews. This comprehensive understanding, combined with collaborative filtering models like SVD, enables the system to provide highly accurate recommendations. The proposed approach consists of four main phases: first, embedding review text using GloVe embeddings and developing a hybrid sentiment analysis approach with CNN and BiGRU architectures; second, creating a BERT language model for generating embeddings from item profile texts, followed by dimensionality reduction using Auto-Encoder; third, using these vectors to build a novel MLP model; fourth, developing a Collaborative Filtering method using SVD, and finally, combining these methods into a hybrid approach and conducting a comprehensive evaluation. Empirical results clearly show the effectiveness of our approach, particularly the combination of GloVe-CNN-BiGRU and BERT-CB with SVD methodology, demonstrating significant improvements across various performance metrics. This confirms the practical value of using contextualized data from BERT-CB and the sentiment analysis approach, enhancing the recommendation system’s effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Ikram Karabila and Nossayba Darraz and Anas El-Ansari and Nabil Alami and Mostafa El Mallahi},
  doi          = {10.1016/j.neucom.2025.129886},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129886},
  shortjournal = {Neurocomputing},
  title        = {A hybrid approach combining sentiment analysis and deep learning to mitigate data sparsity in recommender systems},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural learning rules from associative networks theory.
<em>NEUCOM</em>, <em>636</em>, 129865. (<a
href="https://doi.org/10.1016/j.neucom.2025.129865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Associative networks theory is increasingly providing tools to interpret update rules of artificial neural networks. At the same time, deriving neural learning rules from a solid theory remains a fundamental challenge. We make some steps in this direction by considering general energy-based associative networks of continuous neurons and synapses that evolve in multiple time scales. We use the separation of these timescales to recover a limit in which the activation of the neurons, the energy of the system and the neural dynamics can all be recovered from a generating function. By allowing the generating function to depend on memories, we recover the conventional Hebbian modeling choice for the interaction strength between neurons. Finally, we propose and discuss a dynamics of memories that enables us to include learning in this framework.},
  archive      = {J_NEUCOM},
  author       = {Daniele Lotito},
  doi          = {10.1016/j.neucom.2025.129865},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129865},
  shortjournal = {Neurocomputing},
  title        = {Neural learning rules from associative networks theory},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive temperature distillation method for mining hard
samples’ knowledge. <em>NEUCOM</em>, <em>636</em>, 129745. (<a
href="https://doi.org/10.1016/j.neucom.2025.129745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation can transfer knowledge from a complex teacher network into a simple student one through a high temperature factor, improving the latter’s performance. However, existing studies usually use fixed temperatures, making them ineffective in mining the rich knowledge contained in hard samples. Specifically, high temperature tends to over-smooth knowledge on hard samples, whereas low temperature makes knowledge almost equivalent to hard labels on easy samples. In this paper, we propose an Adaptive Temperature Distillation (ATD) method to effectively address these challenges. A well-trained teacher network’s information entropy is used to assess a sample’s relative difficulty. Then, low temperature is used in a hard sample, which allows the student network to learn its dark knowledge more effectively. And high temperature is employed in an easy sample to prevent the student network from becoming overconfident and ignoring the dark knowledge of negative classes. Furthermore, we propose a mixup variant to enable the student network to access more hard samples with rich dark knowledge. Instead of focusing on data augmentation as the existing mixup studies, ATD pays attention to increasing the richness of dark knowledge by mixing the output logits of easy and hard samples. The overall performance of ATD is verified in multiple benchmark datasets by comparing it with state-of-the-art knowledge distillation methods.},
  archive      = {J_NEUCOM},
  author       = {Shunzhi Yang and Xiong Yang and Jin Ren and Liuchi Xu and Jinfeng Yang and Zhenhua Huang and Zheng Gong and Wenguang Wang},
  doi          = {10.1016/j.neucom.2025.129745},
  journal      = {Neurocomputing},
  month        = {7},
  pages        = {129745},
  shortjournal = {Neurocomputing},
  title        = {Adaptive temperature distillation method for mining hard samples’ knowledge},
  volume       = {636},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="nn---93">NN - 93</h2>
<ul>
<li><details>
<summary>
(2025). A novel self-supervised graph clustering method with
reliable semi-supervision. <em>NN</em>, <em>187</em>, 107418. (<a
href="https://doi.org/10.1016/j.neunet.2025.107418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cluster analysis, as a core technique in unsupervised learning, has widespread applications. With the increasing complexity of data, deep clustering, which integrates the advantages of deep learning and traditional clustering algorithms, demonstrates outstanding performance in processing high-dimensional and complex data. However, when applied to graph data, deep clustering faces two major challenges: noise and sparsity. Noise introduces misleading connections, while sparsity makes it difficult to accurately capture relationships between nodes. These two issues not only increase the difficulty of feature extraction but also significantly affect clustering performance. To address these problems, we propose a novel Self-Supervised Graph Clustering model based on Reliable Semi-Supervision (SSGC-RSS). This model innovates through upstream and downstream components. The upstream component employs a dual-decoder graph autoencoder with joint clustering optimization, preserving latent information of features and graph structure, and alleviates the sparsity problem by generating cluster centers and pseudo-labels. The downstream component utilizes a semi-supervised graph attention encoding network based on highly reliable samples and their pseudo-labels to select reliable samples for training, thereby effectively reducing the interference of noise. Experimental results on multiple graph datasets demonstrate that, compared to existing methods, SSGC-RSS achieves significant performance improvements, with accuracy improvements of 0.9%, 2.0%, and 5.6% on Cora, Citeseer, and Pubmed datasets respectively, proving its effectiveness and superiority in complex graph data clustering tasks.},
  archive      = {J_NN},
  author       = {Weijia Lu and Min Wang and Yun Yu and Liang Ma and Yaxiang Shi and Zhongqiu Huang and Ming Gong},
  doi          = {10.1016/j.neunet.2025.107418},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107418},
  shortjournal = {Neural Netw.},
  title        = {A novel self-supervised graph clustering method with reliable semi-supervision},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LUNETR: Language-infused UNETR for precise pancreatic tumor
segmentation in 3D medical image. <em>NN</em>, <em>187</em>, 107414. (<a
href="https://doi.org/10.1016/j.neunet.2025.107414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of early micro-lesions and adjacent blood vessels in CT scans plays a pivotal role in the clinical diagnosis of pancreatic cancer, considering its aggressive nature and high fatality rate. Despite the widespread application of deep learning methods for this task, several challenges persist: (1) the complex background environment in abdominal CT scans complicates the accurate localization of potential micro-tumors; (2) the subtle contrast between micro-lesions within pancreatic tissue and the surrounding tissues makes it challenging for models to capture these features accurately; and (3) tumors that invade adjacent blood vessels pose significant barriers to surgical procedures. To address these challenges, we propose LUNETR (Language-Infused UNETR), an advanced multimodal encoder model that combines textual and image information for precise medical image segmentation. The integration of an autoencoding language model with cross-attention enabling our model to effectively leverage semantic associations between textual and image data, thereby facilitating precise localization of potential pancreatic micro-tumors. Additionally, we designed a Multi-scale Aggregation Attention (MSAA) module to comprehensively capture both spatial and channel characteristics of global multi-scale image data, enhancing the model&#39;s capacity to extract features from micro-lesions embedded within pancreatic tissue. Furthermore, in order to facilitate precise segmentation of pancreatic tumors and nearby blood vessels and address the scarcity of multimodal medical datasets, we collaborated with Zhuzhou Central Hospital to construct a multimodal dataset comprising CT images and corresponding pathology reports from 135 pancreatic cancer patients. Our experimental results surpass current state-of-the-art models, with the incorporation of the semantic encoder improving the average Dice score for pancreatic tumor segmentation by 2.23 %. For the Medical Segmentation Decathlon (MSD) liver and lung cancer datasets, our model achieved an average Dice score improvement of 4.31 % and 3.67 %, respectively, demonstrating the efficacy of the LUNETR.},
  archive      = {J_NN},
  author       = {Ziyang Shi and Ruopeng Zhang and Xiajun Wei and Cheng Yu and Haojie Xie and Zhen Hu and Xili Chen and Yongzhong Zhang and Bin Xie and Zhengmao Luo and Wanxiang Peng and Xiaochun Xie and Fang Li and Xiaoli Long and Lin Li and Linan Hu},
  doi          = {10.1016/j.neunet.2025.107414},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107414},
  shortjournal = {Neural Netw.},
  title        = {LUNETR: Language-infused UNETR for precise pancreatic tumor segmentation in 3D medical image},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-resistant predefined-time convergent ZNN models for
dynamic least squares and multi-agent systems. <em>NN</em>,
<em>187</em>, 107412. (<a
href="https://doi.org/10.1016/j.neunet.2025.107412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zeroing neural networks (ZNNs) are commonly used for dynamic matrix equations, but their performance under numerically unstable conditions has not been thoroughly explored, especially in situations involving unequal row-column matrices. The challenge is further aggravated by noise, particularly in dynamic least squares (DLS) problems. To address these issues, we propose the QR decomposition-driven noise-resistant ZNN (QRDN-ZNN) model, specifically designed for DLS problems. By integrating QR decomposition into the ZNN framework, QRDN-ZNN enhances numerical stability and guarantees both precise and rapid convergence through a novel activation function (N-Af). As validated by theoretical analysis and experiments, the model can effectively counter disturbances and enhance solution accuracy in dynamic environments. Experimental results show that, in terms of noise resistance, the QRDN-ZNN model outperforms existing mainstream ZNN models, including the original ZNN, integral-enhanced ZNN, double-integral enhanced ZNN, and super-twisting ZNN. Furthermore, the N-Af offers higher accuracy and faster convergence than other state-of-the-art activation functions. To demonstrate the practical utility of the method, We develop a new noise-resistant consensus protocol inspired by QRDN-ZNN, which enables multi-agent systems to reach consensus even in noisy conditions.},
  archive      = {J_NN},
  author       = {Yiwei Li and Jiaxin Liu and Lei Jia and Liangze Yin and Xingpei Li and Yong Zhang},
  doi          = {10.1016/j.neunet.2025.107412},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107412},
  shortjournal = {Neural Netw.},
  title        = {Noise-resistant predefined-time convergent ZNN models for dynamic least squares and multi-agent systems},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Restarted multiple kernel algorithms with self-guiding for
large-scale multi-view clustering. <em>NN</em>, <em>187</em>, 107409.
(<a href="https://doi.org/10.1016/j.neunet.2025.107409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering is a powerful approach for discovering underlying structures hidden behind diverse views of datasets. Most existing multi-view spectral clustering methods use fixed similarity matrices or alternately updated ones. However, the former often fall short in adaptively capturing relationships among different views, while the latter are often time-consuming and even impractical for large-scale datasets. To the best of our knowledge, there are no multi-view spectral clustering methods can both construct multi-view similarity matrices inexpensively and preserve the valuable clustering insights from previous cycles at the same time. To fill in this gap, we present a Sum-Ratio Multi-view Ncut model that share a common representation embedding for multi-view data. Based on this model, we propose a restarted multi-view multiple kernel clustering framework with self-guiding. To release the overhead, we use similarity matrices with strict block diagonal representation, and present an efficient multiple kernel selection technique. Comprehensive experiments on benchmark multi-view datasets demonstrate that, even using randomly generated initial guesses, the restarted algorithms can improve the clustering performances by 5–10 times for some popular multi-view clustering methods. Specifically, our framework offers a potential boosting effect for most of the state-of-the-art multi-view clustering algorithms at very little cost, especially for those with poor performances.},
  archive      = {J_NN},
  author       = {Yongyan Guo and Gang Wu},
  doi          = {10.1016/j.neunet.2025.107409},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107409},
  shortjournal = {Neural Netw.},
  title        = {Restarted multiple kernel algorithms with self-guiding for large-scale multi-view clustering},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Motif and supernode-enhanced gated graph neural networks for
session-based recommendation. <em>NN</em>, <em>187</em>, 107406. (<a
href="https://doi.org/10.1016/j.neunet.2025.107406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation systems aim to predict users’ next interactions based on short-lived, anonymous sessions, a challenging yet vital task due to the sparsity and dynamic nature of user behavior. Existing Graph Neural Network (GNN)-based methods primarily focus on the session graphs while overlooking the influence of micro-structures and user behavior patterns. To address these limitations, we propose a Motif and Supernode-Enhanced Session-based Recommender System (MSERS), which constructs a global session graph, identifies and encodes motifs as supernodes, and reintegrates them into the global graph to enrich its topology and better represent item dependencies. By employing supernode-enhanced Gated Graph Neural Networks (GGNN), MSERS captures both long-term and latent item dependencies, significantly improving session representations. Extensive experiments on two real-world datasets demonstrate the superiority of MSERS over baseline methods, providing robust insights into the role of micro-structures in session-based recommendations.},
  archive      = {J_NN},
  author       = {Ronghua Lin and Chang Liu and Hao Zhong and Chengzhe Yuan and Guohua Chen and Yuncheng Jiang and Yong Tang},
  doi          = {10.1016/j.neunet.2025.107406},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107406},
  shortjournal = {Neural Netw.},
  title        = {Motif and supernode-enhanced gated graph neural networks for session-based recommendation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mathematical expression exploration with graph
representation and generative graph neural network. <em>NN</em>,
<em>187</em>, 107405. (<a
href="https://doi.org/10.1016/j.neunet.2025.107405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic Regression (SR) methods in tree representations have exhibited commendable outcomes across Genetic Programming (GP) and deep learning search paradigms. Nonetheless, the tree representation of mathematical expressions occasionally embodies redundant substructures. Representing expressions as computation graphs is more succinct and intuitive through graph representation. Despite its adoption in evolutionary strategies within SR, deep learning paradigms remain under-explored. Acknowledging the profound advancements of deep learning in tree-centric SR approaches, we advocate for addressing SR tasks using the Directed Acyclic Graph (DAG) representation of mathematical expressions, complemented by a generative graph neural network. We name the proposed method as Graph -based D eep S ymbolic R egression (GraphDSR) . We vectorize node types and employ an adjacent matrix to delineate connections. The graph neural networks craft the DAG incrementally, sampling node types and graph connections conditioned on previous DAG at every step. During each sample step, the valid check is implemented to avoid meaningless sampling, and four domain-agnostic constraints are adopted to further streamline the search. This process culminates once a coherent expression emerges. Constants undergo optimization by SGD and BFGS algorithms, and rewards refine the graph neural network through reinforcement learning. A comprehensive evaluation across 110 benchmarks underscores the potency of our approach.},
  archive      = {J_NN},
  author       = {Jingyi Liu and Weijun Li and Lina Yu and Min Wu and Wenqiang Li and Yanjie Li and Meilan Hao},
  doi          = {10.1016/j.neunet.2025.107405},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107405},
  shortjournal = {Neural Netw.},
  title        = {Mathematical expression exploration with graph representation and generative graph neural network},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). More signals matter to detection: Integrating language
knowledge and frequency representations for boosting fine-grained
aircraft recognition. <em>NN</em>, <em>187</em>, 107402. (<a
href="https://doi.org/10.1016/j.neunet.2025.107402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As object detection tasks progress rapidly, fine-grained detection flourishes as a promising extension. Fine-grained recognition naturally demands high-quality detail signals; however, existing fine-grained detectors, built upon the mainstream detection paradigm, struggle to simultaneously address the challenges of insufficient original signals and the loss of critical signals, resulting in inferior performance. We argue that language signals with advanced semantic knowledge can provide valuable information for fine-grained objects, as well as the frequency domain exhibits greater flexibility in suppressing and enhancing signals; then, we propose a fine-grained aircraft detector by integrating language knowledge and frequency representations into the one-stage detection paradigm. Concretely, by considering both original signals and deep feature signals, we develop three components, including an adaptive frequency augmentation branch (AFAB), a content-aware global features intensifier (CGFI), and a fine-grained text–image interactive feeder (FTIF), to facilitate perceiving and retaining critical signals throughout pivotal detection stages. The AFAB adaptively processes image patches according to their frequency characteristics in the Fourier domain, thus thoroughly mining critical visual content in the data space; the CGFI employs content-aware frequency filtering to enhance global features, allowing for generating an information-rich feature space; the FTIF introduces text knowledge to describe visual differences among fine-grained categories, conveying robust semantic priors from language signals to visual spaces via multimodal interaction for information supplement. Extensive experiments conducted on optical and SAR images demonstrate the superior performance of the proposed fine-grained detector, especially the FTIF, which can be plugged into most existing one-stage detectors to boost their fine-grained recognition performance significantly.},
  archive      = {J_NN},
  author       = {Xueru Xu and Zhong Chen and Yuxin Hu and Guoyou Wang},
  doi          = {10.1016/j.neunet.2025.107402},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107402},
  shortjournal = {Neural Netw.},
  title        = {More signals matter to detection: Integrating language knowledge and frequency representations for boosting fine-grained aircraft recognition},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep transfer learning method based on explainable
feature extraction and domain reconstruction. <em>NN</em>, <em>187</em>,
107401. (<a href="https://doi.org/10.1016/j.neunet.2025.107401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep transfer learning has made significant progress, its “black-box” nature and unstable feature adaptation remain key obstacles. This study proposes a multi-stage deep transfer learning method, called XDTL, which combines explainable feature extraction and domain reconstruction to enhance the performance of target models. Specifically, the study first divides features into key and regular features through cross-validation and explainability analysis, then reconstructs the target domain using a seed replacement method based on key target samples, ultimately achieving deep transfer. Experimental results show that, compared to other methods, XDTL achieves an average improvement of 27.43 % in effectiveness, demonstrating superior performance and stronger explainability. This method offers new insights into addressing the explainability challenges in transfer learning and highlights its potential for broader applications across various tasks.},
  archive      = {J_NN},
  author       = {Li Wang and Lucong Zhang and Ling Feng and Tianyu Chen and Hongwu Qin},
  doi          = {10.1016/j.neunet.2025.107401},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107401},
  shortjournal = {Neural Netw.},
  title        = {A novel deep transfer learning method based on explainable feature extraction and domain reconstruction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight all-MLP time–frequency anomaly detection for
IIoT time series. <em>NN</em>, <em>187</em>, 107400. (<a
href="https://doi.org/10.1016/j.neunet.2025.107400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection in the Industrial Internet of Things (IIoT) aims at identifying abnormal sensor signals to ensure industrial production safety. However, most existing models only focus on high accuracy by building a bulky neural network with deep structures and huge parameters. In this case, these models usually exhibit poor timeliness and high resource consumption, which makes these models unsuitable for resource-limited edge industrial scenarios. To solve this problem, a lightweight All-MLP time–frequency anomaly detection model is proposed for IIoT time series, namely LTFAD. Firstly , unlike traditional deep and bulky solutions, a shallow and lightweight All-MLP architecture is designed to achieve high timeliness and low resource consumption. Secondly , based on the lightweight architecture, a dual-branch network is constructed to improve model accuracy by simultaneously learning “global to local” and “local to global” reconstruction. Finally , time–frequency joint learning is employed in each reconstruction branch to further enhance accuracy. To the best of our knowledge, this is the first work to develop a time–frequency anomaly detection model based only on the shallow All-MLP architecture. Extensive experiments demonstrate that LTFAD can quickly and accurately identify anomalies on resource-limited edge devices, such as the Raspberry Pi 4b and Jetson Xavier NX. The source code for LTFAD is available at https://github.com/infogroup502/LTFAD .},
  archive      = {J_NN},
  author       = {Lei Chen and Xinzhe Cao and Tingqin He and Yepeng Xu and Xuxin Liu and Bowen hu},
  doi          = {10.1016/j.neunet.2025.107400},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107400},
  shortjournal = {Neural Netw.},
  title        = {A lightweight all-MLP time–frequency anomaly detection for IIoT time series},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decomposition-based multi-scale transformer framework for
time series anomaly detection. <em>NN</em>, <em>187</em>, 107399. (<a
href="https://doi.org/10.1016/j.neunet.2025.107399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series anomaly detection is crucial for maintaining stable systems. Existing methods face two main challenges. First, it is difficult to directly model the dependencies of diverse and complex patterns within the sequences. Second, many methods that optimize parameters using mean squared error struggle with noise in the time series, leading to performance deterioration. To address these challenges, we propose a transformer-based framework built on decomposition (TransDe) for multivariate time series anomaly detection. The key idea is to combine the strengths of time series decomposition and transformers to effectively learn the complex patterns in normal time series data. A multi-scale patch-based transformer architecture is proposed to exploit the representative dependencies of each decomposed component of the time series. Furthermore, a contrastive learn paradigm based on patch operation is proposed, which leverages KL divergence to align the positive pairs, namely the pure representations of normal patterns between different patch-level views. A novel asynchronous loss function with a stop-gradient strategy is further introduced to enhance the performance of TransDe effectively. It can avoid time-consuming and labor-intensive computation costs in the optimization process. Extensive experiments on five public datasets are conducted and TransDe shows superiority compared with twelve baselines in terms of F1 score. Our code is available at https://github.com/shaieesss/TransDe .},
  archive      = {J_NN},
  author       = {Wenxin Zhang and Cuicui Luo},
  doi          = {10.1016/j.neunet.2025.107399},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107399},
  shortjournal = {Neural Netw.},
  title        = {Decomposition-based multi-scale transformer framework for time series anomaly detection},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot 3D anomaly detection via online voter mechanism.
<em>NN</em>, <em>187</em>, 107398. (<a
href="https://doi.org/10.1016/j.neunet.2025.107398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D anomaly detection aims to solve the problem that image anomaly detection is greatly affected by lighting conditions. As commercial confidentiality and personal privacy become increasingly paramount, access to training samples is often restricted. To address these challenges, we propose a zero-shot 3D anomaly detection method. Unlike previous CLIP-based methods, the proposed method does not require any prompt and is capable of detecting anomalies on the depth modality. Furthermore, we also propose a pre-trained structural rerouting strategy, which modifies the transformer without retraining or fine-tuning for the anomaly detection task. Most importantly, this paper proposes an online voter mechanism that registers voters and performs majority voter scoring in a one-stage, zero-start and growth-oriented manner, enabling direct anomaly detection on unlabeled test sets. Finally, we also propose a confirmatory judge credibility assessment mechanism, which provides an efficient adaptation for possible few-shot conditions. Results on datasets such as MVTec3D-AD demonstrate that the proposed method can achieve superior zero-shot 3D anomaly detection performance, indicating its pioneering contributions within the pertinent domain.},
  archive      = {J_NN},
  author       = {Wukun Zheng and Xiao Ke and Wenzhong Guo},
  doi          = {10.1016/j.neunet.2025.107398},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107398},
  shortjournal = {Neural Netw.},
  title        = {Zero-shot 3D anomaly detection via online voter mechanism},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SympGNNs: Symplectic graph neural networks for identifying
high-dimensional hamiltonian systems and node classification.
<em>NN</em>, <em>187</em>, 107397. (<a
href="https://doi.org/10.1016/j.neunet.2025.107397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing neural network models to learn Hamiltonian systems, such as SympNets, although accurate in low-dimensions, struggle to learn the correct dynamics for high-dimensional many-body systems. Herein, we introduce Symplectic Graph Neural Networks (SympGNNs) that can effectively handle system identification in high-dimensional Hamiltonian systems, as well as node classification. SympGNNs combine symplectic maps with permutation equivariance, a property of graph neural networks. Specifically, we propose two variants of SympGNNs: (i) G-SympGNN and (ii) LA-SympGNN, arising from different parameterizations of the kinetic and potential energy. We demonstrate the capabilities of SympGNN on two physical examples: a 40-particle coupled Harmonic oscillator, and a 2000-particle molecular dynamics simulation in a two-dimensional Lennard-Jones potential. Furthermore, we demonstrate the performance of SympGNN in the node classification task, achieving accuracy comparable to the state-of-the-art. We also empirically show that SympGNN can overcome the oversmoothing and heterophily problems, two key challenges in the field of graph neural networks.},
  archive      = {J_NN},
  author       = {Alan John Varghese and Zhen Zhang and George Em Karniadakis},
  doi          = {10.1016/j.neunet.2025.107397},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107397},
  shortjournal = {Neural Netw.},
  title        = {SympGNNs: Symplectic graph neural networks for identifying high-dimensional hamiltonian systems and node classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expert guidance and partially-labeled data collaboration for
multi-organ segmentation. <em>NN</em>, <em>187</em>, 107396. (<a
href="https://doi.org/10.1016/j.neunet.2025.107396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abdominal multi-organ segmentation in computed tomography (CT) scans has exhibited successful applications in numerous real clinical scenarios. Nevertheless, prevailing methods for multi-organ segmentation often necessitate either a substantial volume of datasets derived from a single healthcare institution or the centralized storage of patient data obtained from diverse healthcare institutions. This prevailing approach significantly burdens data labeling and collection, thereby exacerbating the associated challenges. Compared to multi organ annotation labels, single organ annotation labels are extremely easy to obtain and have low costs. Therefor, this work establishes an effective collaborative mechanism between multi organ labels and single organ labels, and proposes an expert guided and partially-labeled data collaboration framework for multi organ segmentation, named EGPD-Seg. Firstly, a reward penalty loss function is proposed under the setting of partial labels to make the model more focused on the targets in single organ labels, while suppressing the influence of unlabeled organs on segmentation results. Then, an expert guided module is proposed to enable the model to learn prior knowledge, thereby enabling the model to obtain the ability to segment unlabeled organs on a single organ labeled dataset. The two modules interact with each other and jointly promote the multi organ segmentation performance of the model under label partial settings. This work has been effectively validated on five publicly available abdominal multi organ segmentation datasets, including internal datasets and invisible external datasets. Code: https://github.com/LiLiXJTU/EGPDC-Seg .},
  archive      = {J_NN},
  author       = {Li Li and Jianyi Liu and Hanguang Xiao and Guanqun Zhou and Qiyuan Liu and Zhicheng Zhang},
  doi          = {10.1016/j.neunet.2025.107396},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107396},
  shortjournal = {Neural Netw.},
  title        = {Expert guidance and partially-labeled data collaboration for multi-organ segmentation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enabling scale and rotation invariance in convolutional
neural networks with retina like transformation. <em>NN</em>,
<em>187</em>, 107395. (<a
href="https://doi.org/10.1016/j.neunet.2025.107395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional convolutional neural networks (CNNs) struggle with scale and rotation transformations, resulting in reduced performance on transformed images. Previous research focused on designing specific CNN modules to extract transformation-invariant features. However, these methods lack versatility and are not adaptable to a wide range of scenarios. Drawing inspiration from human visual invariance, we propose a novel brain-inspired approach to tackle the invariance problem in CNNs. If we consider a CNN as the visual cortex, we have the potential to design an “eye” that exhibits transformation invariance, allowing CNNs to perceive the world consistently. Therefore, we propose a retina module and then integrate it into CNNs to create transformation-invariant CNNs (TICNN), achieving scale and rotation invariance. The retina module comprises a retina-like transformation and a transformation-aware neural network (TANN). The retina-like transformation supports flexible image transformations, while the TANN regulates these transformations for scaling and rotation. Specifically, we propose a reference-based training method (RBTM) where the retina module learns to align input images with a reference scale and rotation, thereby achieving invariance. Furthermore, we provide mathematical substantiation for the retina module to confirm its feasibility. Experimental results also demonstrate that our method outperforms existing methods in recognizing images with scale and rotation variations. The code will be released at https://github.com/JiaHongZ/TICNN .},
  archive      = {J_NN},
  author       = {Jiahong Zhang and Guoqi Li and Qiaoyi Su and Lihong Cao and Yonghong Tian and Bo Xu},
  doi          = {10.1016/j.neunet.2025.107395},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107395},
  shortjournal = {Neural Netw.},
  title        = {Enabling scale and rotation invariance in convolutional neural networks with retina like transformation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature-tuning hierarchical transformer via token
communication and sample aggregation constraint for object
re-identification. <em>NN</em>, <em>187</em>, 107394. (<a
href="https://doi.org/10.1016/j.neunet.2025.107394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, transformer-based methods have shown remarkable success in object re-identification. However, most works directly embed off-the-shelf transformer backbones for feature extraction. These methods treat all patch tokens equally, ignoring the difference of distinct patch tokens for feature representation. To solve this issue, this paper designs a feature-tuning mechanism for transformer backbones to emphasize important patches and attenuate unimportant patches. Specifically, a Feature-tuning Hierarchical Transformer (FHTrans) for object re-identification is proposed. First, we propose a plug-and-play Feature-tuning module via Token Communication (TCF) deployed within transformer encoder blocks. This module regards the class token as a pivot to achieve communication between patch tokens. Important patch tokens are emphasized, while unimportant patch tokens are attenuated, focusing more precisely on the discriminative features related to object distinction. Then, we construct a FHTrans based on the designed feature-tuning module. The encoder blocks are divided into three hierarchies considering the correlation between feature representativeness and transformer depth. As the hierarchy deepens, the communication between tokens becomes tighter. This enables the model to capture more crucial feature information. Finally, we propose a Sample Aggregation (SA) loss to impose more effective constraints on statistical characteristics among samples, thereby enhancing intra-class aggregation and guiding FHTrans to learn more discriminative features. Experiments on object re-identification benchmarks demonstrate that our method can achieve state-of-the-art performance.},
  archive      = {J_NN},
  author       = {Zhi Yu and Zhiyong Huang and Mingyang Hou and Jiaming Pei and Yan Yan and Yushi Liu and Daming Sun},
  doi          = {10.1016/j.neunet.2025.107394},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107394},
  shortjournal = {Neural Netw.},
  title        = {Feature-tuning hierarchical transformer via token communication and sample aggregation constraint for object re-identification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive node-level weighted learning for directed graph
neural network. <em>NN</em>, <em>187</em>, 107393. (<a
href="https://doi.org/10.1016/j.neunet.2025.107393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Directed graph neural networks (DGNNs) have garnered increasing interest, yet few studies have focused on node-level representation in directed graphs. In this paper, we argue that different nodes rely on neighbor information from different directions. Furthermore, the commonly used mean aggregation for in-neighbor sets and out-neighbor sets may lose expressive power for certain nodes. To achieve this, first, we estimate the homophily of each node to neighbors in different directions by extending the Dirichlet energy. This approach allows us to assign larger weights to neighbors in directions exhibiting higher homophilic ratios for any node. Second, we introduce out-degree and in-degree information in the learning of weights to avoid the problem of weak expressive power ability of mean aggregation. Moreover, we theoretically demonstrate that our method enhances the expressive ability of directed graphs. Extensive experiments on seven real-world datasets demonstrate that our method outperforms state-of-the-art approaches in both node classification and link prediction tasks.},
  archive      = {J_NN},
  author       = {Jincheng Huang and Xiaofeng Zhu},
  doi          = {10.1016/j.neunet.2025.107393},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107393},
  shortjournal = {Neural Netw.},
  title        = {Adaptive node-level weighted learning for directed graph neural network},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Central loss guides coordinated transformer for reliable
anatomical landmark detection. <em>NN</em>, <em>187</em>, 107391. (<a
href="https://doi.org/10.1016/j.neunet.2025.107391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heatmap-based anatomical landmark detection is still facing two unresolved challenges: (1) inability to accurately evaluate the distribution of heatmap; (2) inability to effectively exploit global spatial structure information. To address the computational inability challenge, we propose a novel position-aware and sample-aware central loss. Specifically, our central loss can absorb position information, enabling accurate evaluation of the heatmap distribution. More advanced is that our central loss is sample-aware, which can adaptively distinguish easy and hard samples and make the model more focused on hard samples while solving the challenge of extreme imbalance between landmarks and non-landmarks. To address the challenge of ignoring structure information, a Coordinated Transformer, called CoorTransformer, is proposed, which establishes long-range dependencies under the guidance of landmark coordinate information, making the attention more focused on the sparse landmarks while taking advantage of global spatial structure. Furthermore, CoorTransformer can speed up convergence, effectively avoiding the defect that Transformers have difficulty converging in sparse representation learning. Using the advanced CoorTransformer and central loss, we propose a generalized detection model that can handle various scenarios, inherently exploiting the underlying relationship between landmarks and incorporating rich structural knowledge around the target landmarks. We analyzed and evaluated CoorTransformer and central loss on three challenging landmark detection tasks. The experimental results show that our CoorTransformer outperforms state-of-the-art methods, and the central loss significantly improves the model’s performance with p -values &lt; 0 . 05 . The source code of this work is available at the GitHub repository .},
  archive      = {J_NN},
  author       = {Qikui Zhu and Yihui Bi and Jie Chen and Xiangpeng Chu and Danxin Wang and Yanqing Wang},
  doi          = {10.1016/j.neunet.2025.107391},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107391},
  shortjournal = {Neural Netw.},
  title        = {Central loss guides coordinated transformer for reliable anatomical landmark detection},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level semantic-aware transformer for image captioning.
<em>NN</em>, <em>187</em>, 107390. (<a
href="https://doi.org/10.1016/j.neunet.2025.107390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective visual representation is crucial for image captioning task. Among the existing methods, the grid-based visual encoding methods take fragmented features extracted from the entire image as input, lacking the fine-grained semantic information focused on salient objects. To address this issue, we propose an effective method, namely Multi-Level Semantic-Aware Transformer (MLSAT) for image captioning, to simultaneously focus on contextual details and high-level semantic information centered on salient objects. First, to model the spatial correlations of grids and the semantic interactions of salient objects, we propose the Visual Content Guided Attention (VCGA), which adaptively embeds the relative position relationships of the grids into the visual features based on their visual content and is used as the attention layer of the encoder. Then, in order to enhance the visual representation, we propose the Multi-Level Semantic-Aware (MLSA) module which further models the fine-grained semantic information centered on salient objects. In this module, the primary semantic information is first extracted from the encoder by using the Semantic Information Extractor (SIE), then refined by the Semantic Refiner (SR) and adaptively integrated into the visual representation by the Visual-Semantic Fusion Block (V-SFB). Our MLSAT is extensively evaluated on the MS-COCO dataset and outperforms the state-of-the-art models, with 135.1% CIDEr (c40) on the official online testing server. The source code is available at https://github.com/XvZhao147/MLSAT},
  archive      = {J_NN},
  author       = {Qin Xu and Shan Song and Qihang Wu and Bo Jiang and Bin Luo and Jinhui Tang},
  doi          = {10.1016/j.neunet.2025.107390},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107390},
  shortjournal = {Neural Netw.},
  title        = {Multi-level semantic-aware transformer for image captioning},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A shape composition method for named entity recognition.
<em>NN</em>, <em>187</em>, 107389. (<a
href="https://doi.org/10.1016/j.neunet.2025.107389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) roughly encode a sentence into a dense representation (a vector), which mixes up the semantic expression of all named entities within a sentence. So the decoding process is easily overwhelmed by sentence-specific information learned during the pre-training process. It results in seriously performance degeneration in recognizing named entities, especially annotated with nested structures. In contrast to LLMs condensing a sentence into a single vector, our model adopts a discriminative language model to map each sentence into a high-order semantic space. In this space, named entities are decomposed into entity body and entity edge. The decomposition is effective to decode complex semantic structures of named entities. In this paper, a shape composition method is proposed for recognizing named entities. This approach leverages a multi-objective learning neural architecture to simultaneously detect entity bodies and classify entity edges. During training, the dual objectives for body and edge learning guide the deep network to encode more task-relevant semantic information. Our method is evaluated on eight widely used public datasets and demonstrated competitive performance. Analytical experiments show that the strategy of let semantic expressions take its course aligns with the entity recognition task. This approach yields finer-grained semantic representations, which enhance not only NER but also other NLP tasks.},
  archive      = {J_NN},
  author       = {Ying Hu and Yanping Chen and Yong Xu},
  doi          = {10.1016/j.neunet.2025.107389},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107389},
  shortjournal = {Neural Netw.},
  title        = {A shape composition method for named entity recognition},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A semantic enhancement-based multimodal network model for
extracting information from evidence lists. <em>NN</em>, <em>187</em>,
107387. (<a href="https://doi.org/10.1016/j.neunet.2025.107387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Courts require the extraction of crucial information about various cases from heterogeneous evidence lists for knowledge-driven decision-making. However, traditional manual screening is complex and inaccurate when confronted with massive evidence lists and cannot meet the demands of legal judgment. Therefore, we propose a semantic enhancement-based multimodal network model (SEBM) to accurately extract critical information from evidence lists. First, we construct the entity semantic graph based on the differences among entity categories in the text content. Subsequently, we extract the features of multiple modalities within the document by employing distinct methods and guide the fusion of features within each modality to enhance the semantic association among them based on the constructed entity semantic graphs. Furthermore, the improved multimodal self-attention mechanism is employed to enhance the interactions between the various modal features, and the loss function combining Taylor polynomials and supervised contrast learning is utilized to reduce the information loss. Finally, SEBM is evaluated using the authentic Chinese evidence list dataset, which includes extensive entity details from diverse case types across multiple law firms. Results from experiments conducted on the authentic evidence list dataset demonstrate that our model performs better than other high-performing models.},
  archive      = {J_NN},
  author       = {Shun Luo and Juan Yu},
  doi          = {10.1016/j.neunet.2025.107387},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107387},
  shortjournal = {Neural Netw.},
  title        = {A semantic enhancement-based multimodal network model for extracting information from evidence lists},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memristive circuit of emotion with negative feedback based
on three primary color model. <em>NN</em>, <em>187</em>, 107385. (<a
href="https://doi.org/10.1016/j.neunet.2025.107385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many memristive circuits tend to oversimplify the process of emotion generation as a linear event, disregarding crucial factors such as negative feedback and other regulatory mechanisms. In this paper, a memristive circuit of emotion with negative feedback based on three primary color model is proposed to solve the above problems. The designed circuit is composed of perception modules, synapse modules, central nervous system modules and overt behavior module. It realizes emotion generation, emotion evolution and long-term memory functions based on the neural network circuit with behavioral homeostatic negative feedback function. Meanwhile, the three primary color model of basic emotions is discussed and realized. Any two basic emotions can be mixed to produce a higher order emotion. The memristive circuit, based on the three primary color model as a theoretical foundation, offers valuable insights for the further advancement of neural networks.},
  archive      = {J_NN},
  author       = {Juntao Han and Gang Liu and Zhang Zhang},
  doi          = {10.1016/j.neunet.2025.107385},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107385},
  shortjournal = {Neural Netw.},
  title        = {Memristive circuit of emotion with negative feedback based on three primary color model},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Arch-net: Model conversion and quantization for architecture
agnostic model deployment. <em>NN</em>, <em>187</em>, 107384. (<a
href="https://doi.org/10.1016/j.neunet.2025.107384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The significant computational demands of Deep Neural Networks (DNNs) present a major challenge for their practical application. Recently, many Application-Specific Integrated Circuit (ASIC) chips have incorporated dedicated hardware support for neural network acceleration. However, the lengthy development cycle of ASIC chips means they often lag behind the latest advances in neural architecture research. For instance, Layer Normalization is not well-supported on many popular chips, and the efficiency of 7 × 7 convolution is significantly lower than the equivalent three 3 × 3 convolution. Therefore, in this paper, we introduce Arch-Net, a neural network framework comprised exclusively of a select few common operators, namely 3 × 3 Convolution, 2 × 2 Max-pooling, Batch Normalization, Fully Connected layers, and Concatenation, which are efficiently supported across the majority of ASIC architectures. To facilitate the conversion of disparate network architectures into Arch-Net, we propose the Arch-Distillation methodology, which incorporates strategies such as Residual Feature Adaptation and Teacher Attention Mechanism. These mechanisms enable effective conversion between different network structures alongside efficient model quantization. The resultant Arch-Net eliminates unconventional network constructs while maintaining robust performance even under sub-8-bit quantization, thereby enhancing compatibility and deployment efficiency. Empirical results from image classification and machine translation tasks demonstrate that using only a few types of operators in Arch-Net can achieve results comparable to those obtained with complex architectures. This provides a new insight for deploying structure-agnostic neural networks on various ASIC chips.},
  archive      = {J_NN},
  author       = {Shuangkang Fang and Weixin Xu and Zipeng Feng and Song Yuan and Yufeng Wang and Yi Yang and Wenrui Ding and Shuchang Zhou},
  doi          = {10.1016/j.neunet.2025.107384},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107384},
  shortjournal = {Neural Netw.},
  title        = {Arch-net: Model conversion and quantization for architecture agnostic model deployment},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-based distributed cooperative neural learning control
for nonlinear multiagent systems with time-varying output constraints.
<em>NN</em>, <em>187</em>, 107383. (<a
href="https://doi.org/10.1016/j.neunet.2025.107383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical engineering, many systems are required to operate under different constraint conditions due to considerations of system security. Violating these constraints conditions during operation may lead to performance degradation. Additionally, communication among agents is highly dependent on the network, which inevitably imposes a network burden on the control systems. To address these issues, this paper investigates the switching event-triggered distributed cooperative learning control issue for nonlinear multiagent systems with time-vary output constraints. An improved output-dependent universal barrier function with adjustable constraint boundaries is proposed, which can uniformly handle symmetric or asymmetric output constraints without changing the controller structure. Meanwhile, an improved switching event-triggered condition is designed based on neural networks (NNs) weight, which can allow the system to adaptively adjust the NNs weight update frequency according to the performance of the system, thereby saving communication resources. Furthermore, the Padé approximation technique is employed to address the input delay issue and simplify the controller design process. Using Lyapunov stability theory, it is proved that the outputs of all followers converge to a neighborhood around the leader output without violating output constraints, and all signals in the closed-loop system remain ultimately bounded. At last, the availability of the presented approach can be verified through some simulation results.},
  archive      = {J_NN},
  author       = {Congyan Lv and Guangliang Liu and Yingnan Pan and Zhijian Hu and Yan Lei},
  doi          = {10.1016/j.neunet.2025.107383},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107383},
  shortjournal = {Neural Netw.},
  title        = {Event-based distributed cooperative neural learning control for nonlinear multiagent systems with time-varying output constraints},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilinear spatiotemporal fusion network: An efficient
approach for traffic flow prediction. <em>NN</em>, <em>187</em>, 107382.
(<a href="https://doi.org/10.1016/j.neunet.2025.107382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow forecasting is critical for intelligent transportation systems, yet increasing model complexity in spatiotemporal graph neural networks does not always yield proportional gains. In this paper, we present a Bilinear Spatiotemporal Fusion Network (BLSTF) tailored for stable, periodic traffic scenarios. First, a temporal enhancement module is introduced to mitigate multi-step error accumulation. Second, predefined graph priors with linear feedback leverage known road topologies for straightforward yet effective spatial modeling. Finally, a bilinear fusion mechanism seamlessly integrates refined temporal and spatial features with minimal computational overhead. Extensive experiments on four real-world datasets show that BLSTF outperforms state-of-the-art methods, achieving MAE and MAPE of 14.05 and 13.90% on PEMS03, 17.93 and 12.12% on PEMS04, 18.87 and 7.86% on PEMS07, and 13.49 and 8.71% on PEMS08, demonstrating BLSTF’s potential to deliver accurate, efficient, and interpretable traffic flow forecasts.},
  archive      = {J_NN},
  author       = {Jing Chen and Shixiang Pan and Weimin Peng and Wenqiang Xu},
  doi          = {10.1016/j.neunet.2025.107382},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107382},
  shortjournal = {Neural Netw.},
  title        = {Bilinear spatiotemporal fusion network: An efficient approach for traffic flow prediction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving generalization of neural vehicle routing problem
solvers through the lens of model architecture. <em>NN</em>,
<em>187</em>, 107380. (<a
href="https://doi.org/10.1016/j.neunet.2025.107380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural models produce promising results when solving Vehicle Routing Problems (VRPs), but may often fall short in generalization. Recent attempts to enhance model generalization often incur unnecessarily large training cost or cannot be directly applied to other models solving different VRP variants. To address these issues, we take a novel perspective on model architecture in this study. Specifically, we propose a plug-and-play Entropy-based Scaling Factor (ESF) and a Distribution-Specific (DS) decoder to enhance the size and distribution generalization, respectively. ESF adjusts the attention weight pattern of the model towards familiar ones discovered during training when solving VRPs of varying sizes. The DS decoder explicitly models VRPs of multiple training distribution patterns through multiple auxiliary light decoders, expanding the model representation space to encompass a broader range of distributional scenarios. We conduct extensive experiments on both synthetic and widely recognized real-world benchmarking datasets and compare the performance with seven baseline models. The results demonstrate the effectiveness of using ESF and DS decoder to obtain a more generalizable model and showcase their applicability to solve different VRP variants, i.e., traveling salesman problem and capacitated VRP. Notably, our proposed generic components require minimal computational resources, and can be effortlessly integrated into conventional generalization strategies to further elevate model generalization.},
  archive      = {J_NN},
  author       = {Yubin Xiao and Di Wang and Xuan Wu and Yuesong Wu and Boyang Li and Wei Du and Liupu Wang and You Zhou},
  doi          = {10.1016/j.neunet.2025.107380},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107380},
  shortjournal = {Neural Netw.},
  title        = {Improving generalization of neural vehicle routing problem solvers through the lens of model architecture},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Turbulence control in memristive neural network via adaptive
magnetic flux based on DLS-ADMM technique. <em>NN</em>, <em>187</em>,
107379. (<a href="https://doi.org/10.1016/j.neunet.2025.107379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-voltage defibrillation for eliminating cardiac spiral waves has significant side effects, necessitating the pursuit of low-energy alternatives for a long time. Adaptive optimization techniques and machine learning methods provide promising solutions for adaptive control of cardiac wave propagation. In this paper, the control of spiral waves and turbulence, as well as 2D and 3D heterogeneity in memristive neural network by using adaptive magnetic flux (AMF) is investigated based on dynamic learning of synchronization - alternating direction method of multipliers (DLS-ADMM). The results show that AMF can achieve global electrical synchronization under multiple complex conditions. There is a trade-off between AMF accuracy and computational speed, lowering the resolution of AMF requires a higher flux of magnetic fields to achieve the network synchronization, resulting in an increase in average Hamiltonian energy, which implies greater energy consumption. The AMF method is more energy efficient than existing DC and AC methods, but it relies on adequate resolution. The ADMM constraints can enhance the synchronization robustness and energy efficiency of DLS techniques, albeit at the cost of increased the computational complexity. The adaptive elimination of spiral waves and turbulence using AMF presented in this paper may provide a novel approach for the low-energy defibrillation studies, and its practical application and performance enhancement deserve further research.},
  archive      = {J_NN},
  author       = {Qianming Ding and Yong Wu and Ying Xie and Yipeng Hu and Weifang Huang and Ya Jia},
  doi          = {10.1016/j.neunet.2025.107379},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107379},
  shortjournal = {Neural Netw.},
  title        = {Turbulence control in memristive neural network via adaptive magnetic flux based on DLS-ADMM technique},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deformation-invariant neural network and its applications in
distorted image restoration and analysis. <em>NN</em>, <em>187</em>,
107378. (<a href="https://doi.org/10.1016/j.neunet.2025.107378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Images degraded by geometric distortions pose a significant challenge to imaging and computer vision tasks such as object recognition. Deep learning-based imaging models usually fail to give accurate performance for geometrically distorted images. In this paper, we propose the deformation-invariant neural network (DINN), a framework to address the problem of imaging tasks for geometrically distorted images. The DINN outputs consistent latent features for images that are geometrically distorted but represent the same underlying object or scene. The idea of DINN is to incorporate a simple component, called the quasiconformal transformer network (QCTN), into other existing deep networks for imaging tasks. The QCTN is a deep neural network that outputs a quasiconformal map, which can be used to transform a geometrically distorted image into an improved version that is closer to the distribution of natural or good images. It first outputs a Beltrami coefficient, which measures the quasiconformality of the output deformation map. By controlling the Beltrami coefficient, the local geometric distortion under the quasiconformal mapping can be controlled. The QCTN is lightweight and simple, which can be readily integrated into other existing deep neural networks to enhance their performance. Leveraging our framework, we have developed an image classification network that achieves accurate classification of distorted images. Our proposed framework has been applied to restore geometrically distorted images by atmospheric turbulence and water turbulence. DINN outperforms existing GAN-based restoration methods under these scenarios, demonstrating the effectiveness of the proposed framework. Additionally, we apply our proposed framework to the 1-1 verification of human face images under atmospheric turbulence and achieve satisfactory performance, further demonstrating the efficacy of our approach.},
  archive      = {J_NN},
  author       = {Han Zhang and Qiguang Chen and Lok Ming Lui},
  doi          = {10.1016/j.neunet.2025.107378},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107378},
  shortjournal = {Neural Netw.},
  title        = {Deformation-invariant neural network and its applications in distorted image restoration and analysis},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing text-centric fake news detection via external
knowledge distillation from LLMs. <em>NN</em>, <em>187</em>, 107377. (<a
href="https://doi.org/10.1016/j.neunet.2025.107377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fake news poses a significant threat to society, making the automatic and accurate detection of fake news an urgent task. Various detection cues have been explored in extensive research, with news text content shown to be indispensable as it directly reflects the creator’s intent. Existing paradigms for developing text-centric methods, i.e., small language model (SLM)-based, external knowledge-enhanced, and large language model (LLM)-based approaches, have achieved remarkable improvements. However, each of these paradigms still faces the following challenges: (1) the low generalization ability of SLM-based methods, due to their training on limited and specific knowledge; (2) the extensive retrieval operations required by external knowledge-enhanced methods, both during training and at the inference stage, leading to increased computational costs; and (3) LLMs are prone to hallucinations and less suited for factual reasoning. To address these challenges, we propose LEKD, which combines the strengths of SLMs, external knowledge, and LLMs to enhance text-centric fake news detection. Specifically, LEKD leverages the LLM to generate external knowledge as supplementary information for the training set only and introduces a graph-based semantic-aware feature alignment module to resolve knowledge contradictions, as well as an information bottleneck-based knowledge distillation module to ensure the implicit generation of these features during inference. Extensive experiments conducted on two datasets demonstrate the advantages of LEKD over the baselines.},
  archive      = {J_NN},
  author       = {Xueqin Chen and Xiaoyu Huang and Qiang Gao and Li Huang and Guisong Liu},
  doi          = {10.1016/j.neunet.2025.107377},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107377},
  shortjournal = {Neural Netw.},
  title        = {Enhancing text-centric fake news detection via external knowledge distillation from LLMs},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic semantic-geometric guidance and structure transfer
network for cross-scene hyperspectral image classification. <em>NN</em>,
<em>187</em>, 107374. (<a
href="https://doi.org/10.1016/j.neunet.2025.107374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, cross-scene hyperspectral image classification(HSIC) via domain adaptation is drawing increasing attention. However, most existing methods either directly align the source domain and target domain without fully mining of SD information, or perform the domain adaptation from semantic and structure aspects with simply characterization method which is sensitive to noise, resulting in the negative transfer and performance decline. To address these issues, in this paper, we propose a novel Dynamic Semantic-Geometric Guidance and Structure Transfer (DSGG-ST) network for cross-scene hyperspectral image classification task. The main aspects of DSGG-ST are twofold. On the one hand, the dynamic semantic-geometric guidance (DSGG) module is designed which consists of the semantic guidance component and geometric guidance component. The proposed DSGG module can align source and target domains under the dynamical guidance of the domain-invariance learning from the semantic and geometric perspectives. On the other hand, the graph attention learning-matching (GALM) module is developed for effectively transferring the structure information between the source domain and target domain. In this module, the graph attention network is adopted to encode the underlying complex structures, and the SeedGNN is exploited for efficient graph matching and alignment. Extensive experiments on three commonly used cross-scene HSI datasets demonstrate that the proposed DSGG-ST obtains a new SOTA performance on cross-scene HSIC, verifying the effectiveness of the proposed DSGG-ST.},
  archive      = {J_NN},
  author       = {Qin Xu and Shuke Wang and Jie Wei and Bo Jiang and Zhifu Tao and Bin Luo},
  doi          = {10.1016/j.neunet.2025.107374},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107374},
  shortjournal = {Neural Netw.},
  title        = {Dynamic semantic-geometric guidance and structure transfer network for cross-scene hyperspectral image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved artificial protozoa optimizer for CNN
architecture optimization. <em>NN</em>, <em>187</em>, 107368. (<a
href="https://doi.org/10.1016/j.neunet.2025.107368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel neural architecture search (NAS) method called MAPOCNN, which leverages an enhanced version of the Artificial Protozoa Optimizer (APO) to optimize the architecture of Convolutional Neural Networks (CNNs). The APO is known for its rapid convergence, high stability, and minimal parameter involvement. To further improve its performance, we introduce MAPO (Modified Artificial Protozoa Optimizer), which incorporates the phototaxis behavior of protozoa. This addition helps mitigate the risk of premature convergence, allowing the algorithm to explore a broader range of possible CNN architectures and ultimately identify more optimal solutions. Through rigorous experimentation on benchmark datasets, including Rectangle and Mnist-random, we demonstrate that MAPOCNN not only achieves faster convergence times but also performs competitively when compared to other state-of-the-art NAS algorithms. The results highlight the effectiveness of MAPOCNN in efficiently discovering CNN architectures that outperform existing methods in terms of both speed and accuracy. This work presents a promising direction for optimizing deep learning architectures using biologically inspired optimization techniques.},
  archive      = {J_NN},
  author       = {Xiaofeng Xie and Yuelin Gao and Yuming Zhang},
  doi          = {10.1016/j.neunet.2025.107368},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107368},
  shortjournal = {Neural Netw.},
  title        = {An improved artificial protozoa optimizer for CNN architecture optimization},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive graph auto-encoder for graph embedding.
<em>NN</em>, <em>187</em>, 107367. (<a
href="https://doi.org/10.1016/j.neunet.2025.107367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding aims to embed the information of graph data into low-dimensional representation space. Prior methods generally suffer from an imbalance of preserving structural information and node features due to their pre-defined inductive biases, leading to unsatisfactory generalization performance. In order to preserve the maximal information, graph contrastive learning (GCL) has become a prominent technique for learning discriminative embeddings. However, in contrast with graph-level embeddings, existing GCL methods generally learn less discriminative node embeddings in a self-supervised way. In this paper, we ascribe above problem to two challenges: (1) graph data augmentations, which are designed for generating contrastive representations, hurt the original semantic information for nodes. (2) the nodes within the same cluster are selected as negative samples. To alleviate these challenges, we propose C ontrastive G raph A uto- E ncoder (CGAE) and C ontrastive V ariational G raph A uto- E ncoder (CVGAE). Specifically, we first propose two distribution-dependent regularizations to guide the paralleled encoders to generate contrastive representations following similar distribution, followed by theoretical derivations to verify the equivalence of the above regularizations. Then, we utilize truncated triplet loss, which only selects top-k nodes as negative samples, to avoid over-separate nodes affiliated to the same cluster. Furthermore, we give theoretical analysis of the effectiveness of our models. Experiments on several real-world datasets show that our models advanced performance over all baselines in link prediction, node clustering, and graph visualization tasks.},
  archive      = {J_NN},
  author       = {Shuaishuai Zu and Li Li and Jun Shen and Weitao Tang},
  doi          = {10.1016/j.neunet.2025.107367},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107367},
  shortjournal = {Neural Netw.},
  title        = {Contrastive graph auto-encoder for graph embedding},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic information-based attention mapping network for
few-shot knowledge graph completion. <em>NN</em>, <em>187</em>, 107366.
(<a href="https://doi.org/10.1016/j.neunet.2025.107366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot Knowledge Graph Completion (FKGC), an emerging technology capable of inferring new triples using only a few reference relation triples, has gained significant attention in recent years. However, existing FKGC methods primarily focus on structural information while failing to effectively utilize the textual semantic information inherent in triples. To address this limitation, we propose an innovative Semantic Information-based Attention Mapping Network (SI-AMN). This novel model significantly enhances knowledge graph completion accuracy through a unique dual-information fusion mechanism that effectively integrates both structural and textual semantic information. The core innovation of SI-AMN lies in its two key components: a semantic encoder for extracting high-quality textual features and an attention mapping network that learns semantic interactions between entity and relation types. Experimental results on benchmark datasets demonstrate SI-AMN’s superior performance, achieving a 40% improvement in prediction accuracy compared to state-of-the-art methods. Ablation studies further validate the effectiveness of each component in our proposed model. This research not only provides a novel solution for knowledge graph completion but also reveals the crucial value of semantic information in graph completion tasks, paving the way for future research directions in this field.},
  archive      = {J_NN},
  author       = {Fan Guo and Xiangmao Chang and Yunqi Guo and Guoliang Xing and Yunlong Zhao},
  doi          = {10.1016/j.neunet.2025.107366},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107366},
  shortjournal = {Neural Netw.},
  title        = {Semantic information-based attention mapping network for few-shot knowledge graph completion},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S2AF: An action framework to self-check the understanding
self-consistency of large language models. <em>NN</em>, <em>187</em>,
107365. (<a href="https://doi.org/10.1016/j.neunet.2025.107365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Language Models (LLMs), which are trained on massive text data, have demonstrated remarkable advancements in language understanding capabilities. Nevertheless, it remains unclear to what extent LLMs have effectively captured and utilized the implicit relationships inherent in the text. This study introduces ‘Understanding Self-Consistency’ , a new perspective that reflects LLMs’ ability to grasp in-depth knowledge relationships through their consistency performance. Specifically, Understanding Self-Consistency refers to the model’s capacity to maintain logical and contextual consistency between inputs and responses. Inspired by human cognitive behavior, we design a self-check action framework named S 2 A F . Wherein, a self-question and answering mechanism is emphasized and forms a logically closed loop including four classes of actions, allowing our S 2 A F to generate, question, answer, and evaluate autonomously. Experimental results on six LLMs across two datasets show that LLMs exhibit objective ability values of the understanding self-consistency and demonstrate their differentiated grasp of knowledge relationships across different reasoning paradigms. Moreover, our findings reveal that LLMs’ performance can be improved with their own outputs (which we call ‘self-enhanced Feedforward’). Notably, S 2 A F merely relies on factual logical relationships, showcasing its potential to advance the development of embodied artificial intelligence (EAI).},
  archive      = {J_NN},
  author       = {Huihui Shao and Fanyu Wang and Zhenping Xie},
  doi          = {10.1016/j.neunet.2025.107365},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107365},
  shortjournal = {Neural Netw.},
  title        = {S2AF: An action framework to self-check the understanding self-consistency of large language models},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep huber quantile regression networks. <em>NN</em>,
<em>187</em>, 107364. (<a
href="https://doi.org/10.1016/j.neunet.2025.107364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typical machine learning regression applications aim to report the mean or the median of the predictive probability distribution, via training with a squared or an absolute error scoring function. The importance of issuing predictions of more functionals of the predictive probability distribution (quantiles and expectiles) has been recognized as a means to quantify the uncertainty of the prediction. In deep learning (DL) applications, that is possible through quantile and expectile regression neural networks (QRNN and ERNN respectively). Here we introduce deep Huber quantile regression networks (DHQRN) that nest QRNN and ERNN as edge cases. DHQRN can predict Huber quantiles, which are more general functionals in the sense that they nest quantiles and expectiles as limiting cases. The main idea is to train a DL algorithm with the Huber quantile scoring function, which is consistent for the Huber quantile functional. As a proof of concept, DHQRN are applied to predict house prices in Melbourne, Australia and Boston, United States (US). In this context, predictive performances of three DL architectures are discussed along with evidential interpretation of results from two economic case studies. Additional simulation experiments and applications to real-world case studies using open datasets demonstrate a satisfactory absolute performance of DHQRN.},
  archive      = {J_NN},
  author       = {Hristos Tyralis and Georgia Papacharalampous and Nilay Dogulu and Kwok P. Chun},
  doi          = {10.1016/j.neunet.2025.107364},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107364},
  shortjournal = {Neural Netw.},
  title        = {Deep huber quantile regression networks},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty-aware graph contrastive fusion network for
multimodal physiological signal emotion recognition. <em>NN</em>,
<em>187</em>, 107363. (<a
href="https://doi.org/10.1016/j.neunet.2025.107363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have been widely adopted to mine topological patterns contained in physiological signals for emotion recognition. However, since physiological signals are non-stationary and susceptible to various noises, there exists inter-sensor connectivity uncertainty in each modality. Such intra-modal connectivity uncertainty may further lead to inter-modal semantic gap uncertainty, which will cause the unimodal bias problem and greatly affect the fusion effectiveness. While, such issue has never been fully considered in existing multimodal fusion models. To this end, we proposed an Uncertainty-Aware Graph Contrastive Fusion Network (UAGCFNet) to fuse multimodal physiological signals effectively for emotion recognition. Firstly, a probabilistic model-based Uncertainty-Aware Graph Convolutional Network (UAGCN), which can estimate and quantify the inter-sensor connectivity uncertainty, is constructed for each modality to extract its uncertainty-aware graph representation. Secondly, a Transitive Contrastive Fusion (TCF) module, which combines the Criss-Cross Attention (CCA)-based fusion mechanism and Transitive Contrastive Learning (TCL)-based calibration strategy organically, is designed to achieve effective fusion of multimodal graph representations by eliminating the unimodal bias problem resulting from the inter-modal semantic gap uncertainty. Extensive experimental results on DEAP, DREAMER, and MPED datasets under both subject-dependent and subject-independent scenarios demonstrate that (i) the proposed model outperforms State-Of-The-Art (SOTA) multimodal fusion models with fewer parameters and lower computational complexity; (ii) each key module and loss function contributes significantly to the performance enhancement of the proposed model; (iii) the proposed model can eliminate the unimodal bias problem effectively.},
  archive      = {J_NN},
  author       = {Guangqiang Li and Ning Chen and Hongqing Zhu and Jing Li and Zhangyong Xu and Zhiying Zhu},
  doi          = {10.1016/j.neunet.2025.107363},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107363},
  shortjournal = {Neural Netw.},
  title        = {Uncertainty-aware graph contrastive fusion network for multimodal physiological signal emotion recognition},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A neural approach to the turing test: The role of emotions.
<em>NN</em>, <em>187</em>, 107362. (<a
href="https://doi.org/10.1016/j.neunet.2025.107362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As is well known, the Turing Test proposes the possibility of distinguishing the behavior of a machine from that of a human being through an experimental session. The Turing Test assesses whether a person asking questions to two different entities, can tell from their answers which of them is the human being and which is the machine. With the progress of Artificial Intelligence, the number of contexts in which the capacities of response of a machine will be indistinguishable from those of a human being is expected to increase rapidly. In order to configure a Turing Test in which it is possible to distinguish human behavior from machine behavior independently from the advances of Artificial Intelligence, at least in the short-medium term, it would be important to base it not on the differences between man and machine in terms of performance and dialogue capacity, but on some specific characteristic of the human mind that cannot be reproduced by the machine even in principle. We studied a new kind of test based on the hypothesis that such characteristic of the human mind exists and can be made experimentally evident. This peculiar characteristic is the emotional content of human cognition and, more specifically, its link with memory enhancement. To validate this hypothesis we recorded the EEG signals of 39 subjects that underwent a specific test and analyzed their signals with a neural network able to label similar signal patterns with similar binary codes. The results showed that, with a statistically significant difference, the test participants more easily recognized images associated in the past with an emotional reaction than those not associated with such a reaction. This distinction in our view is not accessible to a software system, even AI-based, and a Turing Test based on this feature of the mind may make distinguishable human versus machine responses.},
  archive      = {J_NN},
  author       = {Rita Pizzi and Hao Quan and Matteo Matteucci and Simone Mentasti and Roberto Sassi},
  doi          = {10.1016/j.neunet.2025.107362},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107362},
  shortjournal = {Neural Netw.},
  title        = {A neural approach to the turing test: The role of emotions},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial and frequency information fusion transformer for
image super-resolution. <em>NN</em>, <em>187</em>, 107351. (<a
href="https://doi.org/10.1016/j.neunet.2025.107351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous works have indicated that Transformer-based models bring impressive image reconstruction performance in single image super-resolution (SISR). However, existing Transformer-based approaches utilize self-attention within non-overlapping windows. This restriction hinders the network’s ability to adopt large receptive fields, which are essential for capturing global information and establishing long-distance dependencies, especially in the early layers. To fully leverage global information and activate more pixels during the image reconstruction process, we have developed a Spatial and Frequency Information Fusion Transformer (SFFT) with an expansive receptive field. SFFT concurrently combines spatial and frequency domain information to comprehensively leverage their complementary strengths, capturing both local and global image features while integrating low and high-frequency information. Additionally, we utilize the overlapping cross-attention block (OCAB) to facilitate pixel transmission between adjacent windows, enhancing network performance. During the training stage, we incorporate the Fast Fourier Transform (FFT) loss, thereby fully leveraging the capabilities of our proposed modules and further tapping into the model’s potential. Extensive quantitative and qualitative evaluations on benchmark datasets indicate that the proposed algorithm surpasses state-of-the-art methods in terms of accuracy. Specifically, our method achieves a PSNR score of 32.67 dB on the Manga109 dataset, surpassing SwinIR by 0.64 dB and HAT by 0.19 dB, respectively. The source code and pre-trained models are available at https://github.com/Xufujie/SFFT},
  archive      = {J_NN},
  author       = {Yan Zhang and Fujie Xu and Yemei Sun and Jiao Wang},
  doi          = {10.1016/j.neunet.2025.107351},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107351},
  shortjournal = {Neural Netw.},
  title        = {Spatial and frequency information fusion transformer for image super-resolution},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spatial–spectral fusion convolutional transformer network
with contextual multi-head self-attention for hyperspectral image
classification. <em>NN</em>, <em>187</em>, 107350. (<a
href="https://doi.org/10.1016/j.neunet.2025.107350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) can effectively extract local features, while Vision Transformer excels at capturing global features. Combining these two networks to enhance the classification performance of hyperspectral images (HSI) has garnered significant attention. However, most existing fusion methods introduce inductive biases for the Transformer by directly connecting convolutional modules and Transformer encoders for feature extraction but rarely enhance the Transformer’s ability to extract local contextual information through convolutional embedding. In this paper, we propose a spatial–spectral fusion convolutional Transformer method (SSFCT) with contextual multi-head self-attention (CMHSA) for HSI classification. Specifically, we first designed a local feature aggregation (LFA) module that utilizes a three-branch convolution architecture and attention layers to extract and enhance local spatial–spectral fusion features. Then, a novel CMHSA is built to extract interaction information of local contextual features through integrating static and dynamic local contextual representations from 3D convolution and attention mechanisms, and the CMHSA is integrated into the devised dual-branch spatial–spectral convolutional transformer (DSSCT) module to simultaneously capture global–local associations in both spatial and spectral domains. Finally, the attention feature fusion (AFF) module is proposed to fully obtain global–local spatial–spectral comprehensive features. Extensive experiments on five HSI datasets — Indian Pines, Salinas Valley, Houston2013, Botswana, and Yellow River Delta — outperform state-of-the-art methods, achieving overall accuracies of 98.03%, 99.68%, 98.65%, 97.97%, and 89.43%, respectively, showcasing its effectiveness for HSI classification.},
  archive      = {J_NN},
  author       = {Wuli Wang and Qi Sun and Li Zhang and Peng Ren and Jianbu Wang and Guangbo Ren and Baodi Liu},
  doi          = {10.1016/j.neunet.2025.107350},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107350},
  shortjournal = {Neural Netw.},
  title        = {A spatial–spectral fusion convolutional transformer network with contextual multi-head self-attention for hyperspectral image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Task-augmented cross-view imputation network for partial
multi-view incomplete multi-label classification. <em>NN</em>,
<em>187</em>, 107349. (<a
href="https://doi.org/10.1016/j.neunet.2025.107349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world scenarios, multi-view multi-label learning often encounters the challenge of incomplete training data due to limitations in data collection and unreliable annotation processes. The absence of multi-view features impairs the comprehensive understanding of samples, omitting crucial details essential for classification. To address this issue, we present a task-augmented cross-view imputation network (TACVI-Net) for the purpose of handling partial multi-view incomplete multi-label classification. Specifically, we employ a two-stage network to derive highly task-relevant features to recover the missing views. In the first stage, we leverage the information bottleneck theory to obtain a discriminative representation of each view by extracting task-relevant information through a view-specific encoder-classifier architecture. In the second stage, an autoencoder based multi-view reconstruction network is utilized to extract high-level semantic representation of the augmented features and recover the missing data, thereby aiding the final classification task. Extensive experiments on five datasets demonstrate that our TACVI-Net outperforms other state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Lian Zhao and Jie Wen and Xiaohuan Lu and Wai Keung Wong and Jiang Long and Wulin Xie},
  doi          = {10.1016/j.neunet.2025.107349},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107349},
  shortjournal = {Neural Netw.},
  title        = {Task-augmented cross-view imputation network for partial multi-view incomplete multi-label classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards zero-shot human–object interaction detection via
vision–language integration. <em>NN</em>, <em>187</em>, 107348. (<a
href="https://doi.org/10.1016/j.neunet.2025.107348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human–object interaction (HOI) detection aims to locate human–object pairs and identify their interaction categories in images. Most existing methods primarily focus on supervised learning, which relies on extensive manual HOI annotations. Such heavy reliance on closed-set supervised learning limits their generalization capabilities to unseen object categories. Inspired by the remarkable zero-shot capabilities of VLM, we propose a novel framework, termed Knowledge Integration to HOI (KI2HOI), that effectively integrates the knowledge of the visual–language model to improve zero-shot HOI detection. Specifically, we propose a ho-pair encoder to supplement contextual and interaction-specific semantic representation decoder into our model. Additionally, we propose two fusion strategies to facilitate prior knowledge transfer of VLM. One is visual-level fusion, producing more global context interaction features; another is language-level fusion, further enhancing the capability of VLM for HOI detection. Extensive experiments conducted on the mainstream HICO-DET and V-COCO datasets demonstrate that our model outperforms the previous methods in various zero-shot and full-supervised settings. The source code is available in https://github.com/xwyscut/K2HOI .},
  archive      = {J_NN},
  author       = {Weiying Xue and Qi Liu and Yuxiao Wang and Zhenao Wei and Xiaofen Xing and Xiangmin Xu},
  doi          = {10.1016/j.neunet.2025.107348},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107348},
  shortjournal = {Neural Netw.},
  title        = {Towards zero-shot human–object interaction detection via vision–language integration},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CFI-former: Efficient lane detection by multi-granularity
perceptual query attention transformer. <em>NN</em>, <em>187</em>,
107347. (<a href="https://doi.org/10.1016/j.neunet.2025.107347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from the booming development of Transformer methods, the performance of lane detection tasks has been rapidly improved. However, due to the influence of inaccurate lane line shape constraints, the query sequences of existing transformer-based lane line detection methods contain a large number of repetitive and invalid information regions, which leads to redundant information in the detection region and makes the processing of information on localized feature details of the lanes biased. In this paper, a multi-granularity perceptual query attention transformer lane detection method, CFI-Former, is proposed to achieve more accurate lane detection. Specifically, a multi-granularity perceptual query attention (GQA) module is designed to extract lane local detail information. By a two-stage query from coarse to fine, redundant key–value pairs with low information relevance are first filtered out, and then fine-grained token-to-token attention is executed on the remaining candidate regions. This module emphasizes the multi-granularity nuances of lane features from global to local, leading to more effective models based on lane line shape constraints. In addition, weighted adaptive LIoU loss ( L φ − L I oU ) is proposed to improve lane detection in more challenging scenarios by adaptively increasing the relative gradient of high IoU lane objects and the weight of the loss. Extensive experiments show that CFI-Former outperforms the baseline on two popular lane detection benchmark datasets.},
  archive      = {J_NN},
  author       = {Rong Gao and Siqi Hu and Lingyu Yan and Lefei Zhang and Jia Wu},
  doi          = {10.1016/j.neunet.2025.107347},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107347},
  shortjournal = {Neural Netw.},
  title        = {CFI-former: Efficient lane detection by multi-granularity perceptual query attention transformer},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive decoupling-fusion in siamese network for image
classification. <em>NN</em>, <em>187</em>, 107346. (<a
href="https://doi.org/10.1016/j.neunet.2025.107346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) are highly regarded for their ability to extract semantic information from visual inputs. However, this capability often leads to the inadvertent loss of important visual details. In this paper, we introduce an Adaptive Decoupling Fusion (ADF) designed to preserve these valuable visual details and integrate seamlessly with existing hierarchical models. Our approach emphasizes retaining and leveraging appearance information from the network’s shallow layers to enhance semantic understanding. We first decouple the appearance information from one branch of a Siamese Network and embed it into the deep feature space of the other branch. This facilitates a synergistic interaction: one branch supplies appearance information that benefits semantic understanding, while the other integrates this information into the semantic space. Traditional Siamese Networks typically use shared weights, which constrains the diversity of features that can be learned. To address this, we propose a differentiated collaborative learning where both branches receive the same input but are trained with cross-entropy loss, allowing them to have distinct weights. This enhances the network’s adaptability to specific tasks. To further optimize the decoupling and fusion, we introduce a Mapper module featuring depthwise separable convolution and a gated fusion mechanism. This module regulates the information flow between branches, balancing appearance and semantic information. Under fully self-supervised conditions, utilizing only minimal data augmentation, we achieve a top-1 accuracy of 81.11% on the ImageNet-1k dataset using ADF-ResNeXt-101.},
  archive      = {J_NN},
  author       = {Xi Yang and Pai Peng and Danyang Li and Yinghao Ye and Xiaohuan Lu},
  doi          = {10.1016/j.neunet.2025.107346},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107346},
  shortjournal = {Neural Netw.},
  title        = {Adaptive decoupling-fusion in siamese network for image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-attention fusion and adaptive continual updating for
multimodal federated learning with heterogeneous data. <em>NN</em>,
<em>187</em>, 107345. (<a
href="https://doi.org/10.1016/j.neunet.2025.107345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) enables collaborative model training without direct data sharing, facilitating knowledge exchange while ensuring data privacy. Multimodal federated learning (MFL) is particularly advantageous for decentralized multimodal data, effectively managing heterogeneous information across modalities. However, the diversity in environments and data collection methods among participating devices introduces substantial challenges due to non-independent and identically distributed (non-IID) data. Our experiments reveal that, despite the theoretical benefits of multimodal data, MFL under non-IID conditions often exhibits poor performance, even trailing traditional unimodal FL approaches. Additionally, MFL frequently encounter missing modality issues, further complicating the training process. To address these challenges, we propose several improvements: the federated self-attention multimodal (FSM) feature fusion method and the multimodal federated learning adaptive continual update (FedMAC) algorithm. Moreover, we utilize a Stable Diffusion model to mitigate the impact of missing image modality. Extensive experimental results demonstrate that our proposed methods outperform other state-of-the-art FL algorithms, enhancing both accuracy and robustness in MFL.},
  archive      = {J_NN},
  author       = {Kangning Yin and Zhen Ding and Xinhui Ji and Zhiguo Wang},
  doi          = {10.1016/j.neunet.2025.107345},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107345},
  shortjournal = {Neural Netw.},
  title        = {Self-attention fusion and adaptive continual updating for multimodal federated learning with heterogeneous data},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel one-layer neural network for solving quadratic
programming problems. <em>NN</em>, <em>187</em>, 107344. (<a
href="https://doi.org/10.1016/j.neunet.2025.107344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel one-layer neural network to solve quadratic programming problems in real time by using a control parameter and transforming the optimality conditions into a system of projection equations. The proposed network includes two existing dual networks as its special cases, and an existing model can be derived from it. In particular, another new model for linear and quadratic programming problems can be obtained from the proposed network. Meanwhile, a new Lyapunov function is constructed to ensure that the proposed network is Lyapunov stable and can converge to an optimal solution of the concerned problem under mild conditions. In contrast with the existing models for quadratic programming, the proposed network requires the least neurons while maintaining weaker stability conditions. The effectiveness and characteristics of the proposed model are demonstrated by the limited simulation results.},
  archive      = {J_NN},
  author       = {Xingbao Gao and Lili Du},
  doi          = {10.1016/j.neunet.2025.107344},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107344},
  shortjournal = {Neural Netw.},
  title        = {A novel one-layer neural network for solving quadratic programming problems},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inspired by pathogenic mechanisms: A novel gradual
multi-modal fusion framework for mild cognitive impairment diagnosis.
<em>NN</em>, <em>187</em>, 107343. (<a
href="https://doi.org/10.1016/j.neunet.2025.107343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mild cognitive impairment (MCI) is a precursor to Alzheimer’s disease (AD), and its progression involves complex pathogenic mechanisms. Specifically, disturbed by gene variants, the regulation of gene expression ultimately changes brain structure, resulting in the progression of brain diseases. However, the existing works rarely take these mechanisms into account when designing their diagnosis methods. Therefore, we propose a novel gradual multi-modal fusion framework to fuse representative data from each stage of disease progression in hybrid feature space, including single nucleotide polymorphism (SNP), gene expression (GE), and magnetic resonance imaging (MRI). Specifically, to integrate genetic sequence and expression data, we design a SNP-GE fusion module, which performs multi-modal fusion to obtain genetic embedding by considering the relation between SNP and GE. Compared with SNP-GE fusion, representation of genetic embedding and MRI have more obvious heterogeneity, especially correlation with disease. Therefore, we propose to align the manifold of genetic and imaging representations, which can explore the high-order relationship between imaging and genetic data in the presence of modal heterogeneity. Our proposed framework was validated using the Alzheimer’s Disease Neuroimaging Initiative dataset, and achieved diagnosis accuracy of 76.88%, 72.84%, 87.72%, and 95.00% for distinguishing MCI from control normal, lately MCI from early MCI, MCI from AD, and AD from control normal, respectively. Additionally, our proposed framework helps to identify some multi-modal biomarkers related to MCI progression. In summary, our proposed framework is effective not only for MCI diagnosis but also for guiding the further development of genetic and imaging-based brain studies. Our code is published at https://github.com/tianxu8822/workflow_MCI/tree/main/ .},
  archive      = {J_NN},
  author       = {Xu Tian and Hong-Dong Li and Hanhe Lin and Chao Li and Yu-Ping Wang and Harrison X. Bai and Wei Lan and Jin Liu},
  doi          = {10.1016/j.neunet.2025.107343},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107343},
  shortjournal = {Neural Netw.},
  title        = {Inspired by pathogenic mechanisms: A novel gradual multi-modal fusion framework for mild cognitive impairment diagnosis},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking exploration–exploitation trade-off in
reinforcement learning via cognitive consistency. <em>NN</em>,
<em>187</em>, 107342. (<a
href="https://doi.org/10.1016/j.neunet.2025.107342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The exploration–exploitation dilemma is one of the fundamental challenges in deep reinforcement learning (RL). Agents must strike a trade-off between making decisions based on current beliefs or gathering more information. Prior work mostly prefers devising sophisticated exploration methods to ensure accurate target Q-values or learn rewards and actions association, which may not be intelligent enough for sample efficiency. In this paper, we propose to rethink the trade-off between exploration and exploitation from the perspective of cognitive consistency: humans tend to think and behave in line with their existing knowledge structures (maintaining cognitive consistency), yielding satisfactory results within a brief timeframe. We argue that maintaining consistency, specifically through pessimistic exploration, within the context of optimal policy-oriented cognition, can improve efficiency without compromising performance. To this end, we propose a Cognitive Consistency (CoCo) framework. CoCo first leverages a self-imitating distribution correction approach to pursue cognition oriented toward the optimal policy. Then, it conservatively implements pessimistic exploration by extracting novel inconsistency-minimization objectives inspired by label distribution learning. We validate our framework across various standard off-policy RL tasks and show that maintaining cognitive consistency improves sample efficiency and performance. Code is available at https://github.com/DkING-lv6/CoCo .},
  archive      = {J_NN},
  author       = {Da Wang and Wei Wei and Lin Li and Xin Wang and Jiye Liang},
  doi          = {10.1016/j.neunet.2025.107342},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107342},
  shortjournal = {Neural Netw.},
  title        = {Rethinking exploration–exploitation trade-off in reinforcement learning via cognitive consistency},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving transferability of adversarial examples via
statistical attribution-based attacks. <em>NN</em>, <em>187</em>,
107341. (<a href="https://doi.org/10.1016/j.neunet.2025.107341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks are significant in uncovering vulnerabilities and assessing the robustness of deep neural networks (DNNs), offering profound insights into their internal mechanisms. Feature-level attacks, a potent approach, craft adversarial examples by extensively corrupting the intermediate-layer features of the source model during each iteration. However, it often has imprecise metrics to assess the significance of features and may impose constraints on the transferability of adversarial examples. To address these issues, this paper introduces the Statistical Attribution-based Attack (SAA) method, which emphasizes finding feature importance representations and refining optimization objectives, thereby achieving stronger attack performance. To calculate the Comprehensive Gradient for more accurate feature representation, we introduce the Region-wise Feature Disturbance and Gradient Information Aggregation, which can effectively disrupt the model’s attention focus areas. Subsequently, a statistical attribution-based approach is employed, leveraging the average feature information across layers to provide a more advantageous optimization objective. Experiments have validated the superiority of this method. Specifically, SAA improves the attack success rate by 9.3% compared with the second-best method. When combined with input transformation methods, it achieves an average success rate of 79.2% against eight leading defense models.},
  archive      = {J_NN},
  author       = {Hegui Zhu and Yanmeng Jia and Yue Yan and Ze Yang},
  doi          = {10.1016/j.neunet.2025.107341},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107341},
  shortjournal = {Neural Netw.},
  title        = {Improving transferability of adversarial examples via statistical attribution-based attacks},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised non-negative matrix factorization with
structure preserving for image clustering. <em>NN</em>, <em>187</em>,
107340. (<a href="https://doi.org/10.1016/j.neunet.2025.107340">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning methods have wide applications thanks to the reasonable utilization for a part of label information of data. In recent years, non-negative matrix factorization (NMF) has received considerable attention because of its interpretability and practicality. Based on the advantages of semi-supervised learning and NMF, many semi-supervised NMF methods have been presented. However, these existing semi-supervised NMF methods construct a label matrix only containing elements 1 and 0 to represent the labeled data and further construct a label regularization, which neglects an intrinsic structure of NMF. To address the deficiency, in this paper, we propose a novel semi-supervised NMF method with structure preserving. Specifically, we first construct a new label matrix with weights and further construct a label constraint regularizer to both utilize the label information and maintain the intrinsic structure of NMF. Then, based on the label constraint regularizer, the basis images of labeled data are extracted for monitoring and modifying the basis images learning of all data by establishing a basis regularizer. Finally, incorporating the label constraint regularizer and the basis regularizer into NMF, we propose a new semi-supervised NMF method. To solve the optimization problem, a multiplicative updating algorithm is developed. The proposed method is applied to image clustering to test its performance. Experimental results on eight data sets demonstrate the effectiveness of the proposed method in contrast with state-of-the-art unsupervised and semi-supervised algorithms.},
  archive      = {J_NN},
  author       = {Wenjing Jing and Linzhang Lu and Weihua Ou},
  doi          = {10.1016/j.neunet.2025.107340},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107340},
  shortjournal = {Neural Netw.},
  title        = {Semi-supervised non-negative matrix factorization with structure preserving for image clustering},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing few-shot image classification through learnable
multi-scale embedding and attention mechanisms. <em>NN</em>,
<em>187</em>, 107339. (<a
href="https://doi.org/10.1016/j.neunet.2025.107339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of few-shot classification, the goal is to train a classifier using a limited number of samples while maintaining satisfactory performance. However, traditional metric-based methods exhibit certain limitations in achieving this objective. These methods typically rely on a single distance value between the query feature and support feature, thereby overlooking the contribution of shallow features. To overcome this challenge, we propose a novel approach in this paper. Our approach involves utilizing a multi-output embedding network that maps samples into distinct feature spaces. The proposed method extracts feature vectors at different stages, enabling the model to capture both global and abstract features. By utilizing these diverse feature spaces, our model enhances its performance. Moreover, employing a self-attention mechanism improves the refinement of features at each stage, leading to even more robust representations and improved overall performance. Furthermore, assigning learnable weights to each stage significantly improved performance and results. We conducted comprehensive evaluations on the MiniImageNet and FC100 datasets, specifically in the 5-way 1-shot and 5-way 5-shot scenarios. Additionally, we performed cross-domain tasks across eight benchmark datasets, achieving high accuracy in the testing domains. These evaluations demonstrate the efficacy of our proposed method in comparison to state-of-the-art approaches. https://github.com/FatemehAskari/MSENet},
  archive      = {J_NN},
  author       = {Fatemeh Askari and Amirreza Fateh and Mohammad Reza Mohammadi},
  doi          = {10.1016/j.neunet.2025.107339},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107339},
  shortjournal = {Neural Netw.},
  title        = {Enhancing few-shot image classification through learnable multi-scale embedding and attention mechanisms},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph neural networks with coarse- and fine-grained division
for mitigating label noise and sparsity. <em>NN</em>, <em>187</em>,
107338. (<a href="https://doi.org/10.1016/j.neunet.2025.107338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have gained considerable prominence in semi-supervised learning tasks in processing graph-structured data, primarily owing to their message-passing mechanism, which largely relies on the availability of clean labels. However, in real-world scenarios, labels on nodes of graphs are inevitably noisy and sparsely labeled, significantly degrading the performance of GNNs. Exploring robust GNNs for semi-supervised node classification in the presence of noisy and sparse labels remains a critical challenge. Therefore, we propose a novel G raph N eural N etwork with C oarse- and F ine- G rained D ivision for mitigating label sparsity and noise, namely GNN-CFGD. The key idea of GNN-CFGD is reducing the negative impact of noisy labels via coarse- and fine-grained division, along with graph reconstruction. Specifically, we first investigate the effectiveness of linking unlabeled nodes to cleanly labeled nodes, demonstrating that this approach is more effective in combating labeling noise than linking to potentially noisy labeled nodes. Based on this observation, we introduce a Gaussian Mixture Model (GMM) based on the memory effect to perform a coarse-grained division of the given labels into clean and noisy labels. Next, we propose a clean labels oriented link that connects unlabeled nodes to cleanly labeled nodes, aimed at mitigating label sparsity and promoting supervision propagation. Furthermore, to provide refined supervision for noisy labeled nodes and additional supervision for unlabeled nodes, we fine-grain the noisy labeled and unlabeled nodes into two candidate sets based on confidence, respectively. Extensive experiments on various datasets demonstrate the superior effectiveness and robustness of GNN-CFGD.},
  archive      = {J_NN},
  author       = {Shuangjie Li and Baoming Zhang and Jianqing Song and Gaoli Ruan and Chongjun Wang and Junyuan Xie},
  doi          = {10.1016/j.neunet.2025.107338},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107338},
  shortjournal = {Neural Netw.},
  title        = {Graph neural networks with coarse- and fine-grained division for mitigating label noise and sparsity},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-training EEG discrimination model with weakly
supervised sample construction: An age-based perspective on ASD
evaluation. <em>NN</em>, <em>187</em>, 107337. (<a
href="https://doi.org/10.1016/j.neunet.2025.107337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning for Electroencephalography (EEG) has become dominant in the tasks of discrimination and evaluation of brain disorders. However, despite its significant successes, this approach has long been facing challenges due to the limited availability of labeled samples and the individuality of subjects, particularly in complex scenarios such as Autism Spectrum Disorders (ASD). To facilitate the efficient optimization of EEG discrimination models in the face of these limitations, this study has developed a framework called STEM (Self-Training EEG Model). STEM accomplishes this by self-training the model, which involves initializing it with limited labeled samples and optimizing it with self-constructed samples. (1) Model initialization with multi-task learning: A multi-task model (MAC) comprising an AutoEncoder and a classifier offers guidance for subsequent pseudo-labeling. This guidance includes task-related latent EEG representations and prediction probabilities of unlabeled samples. The AutoEncoder, which consists of depth-separable convolutions and BiGRUs, is responsible for learning comprehensive EEG representations through the EEG reconstruction task. Meanwhile, the classifier, trained using limited labeled samples through supervised learning, directs the model’s attention towards capturing task-related features. (2) Model optimization aided by pseudo-labeled samples construction: Next, trustworthy pseudo-labels are assigned to the unlabeled samples, and this approach (PLASC) combines the sample’s distance relationship in the feature space mapped by the encoder with the sample’s predicted probability, using the initial MAC model as a reference. The constructed pseudo-labeled samples then support the self-training of MAC to learn individual information from new subjects, potentially enhancing the adaptation of the optimized model to samples from new subjects. The STEM framework has undergone an extensive evaluation, comparing it to state-of-the-art counterparts, using resting-state EEG data collected from 175 ASD-suspicious children spanning different age groups. The observed results indicate the following: (1) STEM achieves the best performance, with an accuracy of 88.33% and an F1-score of 87.24%, and (2) STEM’s multi-task learning capability outperforms supervised methods when labeled data is limited. More importantly, the use of PLASC improves the model’s performance in ASD discrimination across different age groups, resulting in an increase in accuracy (3%–8%) and F1-scores (4%–10%). These increments are approximately 6% higher than those achieved by the comparison methods.},
  archive      = {J_NN},
  author       = {Tengfei Gao and Dan Chen and Meiqi Zhou and Yaodong Wang and Yiping Zuo and Weiping Tu and Xiaoli Li and Jingying Chen},
  doi          = {10.1016/j.neunet.2025.107337},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107337},
  shortjournal = {Neural Netw.},
  title        = {Self-training EEG discrimination model with weakly supervised sample construction: An age-based perspective on ASD evaluation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse teacher–students for deep safe semi-supervised
learning under class mismatch. <em>NN</em>, <em>187</em>, 107336. (<a
href="https://doi.org/10.1016/j.neunet.2025.107336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning can significantly boost model performance by leveraging unlabeled data, particularly when labeled data is scarce. However, real-world unlabeled data often contain unseen-class samples, which can hinder the classification of seen classes. To address this issue, mainstream safe SSL methods suggest detecting and discarding unseen-class samples from unlabeled data. Nevertheless, these methods typically employ a single-model strategy to simultaneously tackle both the classification of seen classes and the detection of unseen classes. Our research indicates that such an approach may lead to conflicts during training, resulting in suboptimal model optimization. Inspired by this, we introduce a novel framework named Diverse Teacher–Students ( DTS ), which uniquely utilizes dual teacher–student models to individually and effectively handle these two tasks. DTS employs a novel uncertainty score to softly separate unseen-class and seen-class data from the unlabeled set, and intelligently creates an additional ( K +1)th class supervisory signal for training. By training both teacher–student models with all unlabeled samples, DTS can enhance the classification of seen classes while simultaneously improving the detection of unseen classes. Comprehensive experiments demonstrate that DTS surpasses baseline methods across a variety of datasets and configurations. Our code and models can be publicly accessible on the link https://github.com/Zhanlo/DTS .},
  archive      = {J_NN},
  author       = {Qikai Wang and Rundong He and Yongshun Gong and Chunxiao Ren and Haoliang Sun and Xiaoshui Huang and Yilong Yin},
  doi          = {10.1016/j.neunet.2025.107336},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107336},
  shortjournal = {Neural Netw.},
  title        = {Diverse Teacher–Students for deep safe semi-supervised learning under class mismatch},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comprehensive evaluation of pipelines for classification of
psychiatric disorders using multi-site resting-state fMRI datasets.
<em>NN</em>, <em>187</em>, 107335. (<a
href="https://doi.org/10.1016/j.neunet.2025.107335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objective classification biomarkers that are developed using resting-state functional magnetic resonance imaging (rs-fMRI) data are expected to contribute to more effective treatment for psychiatric disorders. Unfortunately, no widely accepted biomarkers are available at present, partially because of the large variety of analysis pipelines for their development. In this study, we comprehensively evaluated analysis pipelines using a large-scale, multi-site fMRI dataset for major depressive disorder (MDD). We explored combinations of options in four sub-processes of the analysis pipelines: six types of brain parcellation, four types of functional connectivity (FC) estimations, three types of site-difference harmonization, and five types of machine-learning methods. A total of 360 different MDD classification biomarkers were constructed using the SRPBS dataset acquired with unified protocols (713 participants from four sites) as the discovery dataset, and datasets from other projects acquired with heterogeneous protocols (449 participants from four sites) were used for independent validation. We repeated the procedure after swapping the roles of the two datasets to identify superior pipelines, regardless of the discovery dataset. The classification results of the top 10 biomarkers showed high similarity, and weight similarity was observed between eight of the biomarkers, except for two that used both data-driven parcellation and FC computation. We applied the top 10 pipelines to the datasets of other psychiatric disorders (autism spectrum disorder and schizophrenia), and eight of the biomarkers exhibited sufficient classification performance for both disorders. Our results will be useful for establishing a standardized pipeline for classification biomarkers.},
  archive      = {J_NN},
  author       = {Yuji Takahara and Yuto Kashiwagi and Tomoki Tokuda and Junichiro Yoshimoto and Yuki Sakai and Ayumu Yamashita and Toshinori Yoshioka and Hidehiko Takahashi and Hiroto Mizuta and Kiyoto Kasai and Akira Kunimitsu and Naohiro Okada and Eri Itai and Hotaka Shinzato and Satoshi Yokoyama and Yoshikazu Masuda and Yuki Mitsuyama and Go Okada and Yasumasa Okamoto and Takashi Itahashi and Okito Yamashita},
  doi          = {10.1016/j.neunet.2025.107335},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107335},
  shortjournal = {Neural Netw.},
  title        = {Comprehensive evaluation of pipelines for classification of psychiatric disorders using multi-site resting-state fMRI datasets},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SHFormer: Dynamic spectral filtering convolutional neural
network and high-pass kernel generation transformer for adaptive MRI
reconstruction. <em>NN</em>, <em>187</em>, 107334. (<a
href="https://doi.org/10.1016/j.neunet.2025.107334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention Mechanism (AM) selectively focuses on essential information for imaging tasks and captures relationships between regions from distant pixel neighborhoods to compute feature representations. Accelerated magnetic resonance image (MRI) reconstruction can benefit from AM, as the imaging process involves acquiring Fourier domain measurements that influence the image representation in a non-local manner. However, AM-based models are more adept at capturing low-frequency information and have limited capacity in constructing high-frequency representations, restricting the models to smooth reconstruction. Secondly, AM-based models need mode-specific retraining for multimodal MRI data as their knowledge is restricted to local contextual variations within modes that might be inadequate to capture the diverse transferable features across heterogeneous data domains. To address these challenges, we propose a neuromodulation-based discriminative multi-spectral AM for scalable MRI reconstruction, that can (i) propagate the context-aware high-frequency details for high-quality image reconstruction, and (ii) capture features reusable to deviated unseen domains in multimodal MRI, to offer high practical value for the healthcare industry and researchers. The proposed network consists of a spectral filtering convolutional neural network to capture mode-specific transferable features to generalize to deviated MRI data domains and a dynamic high-pass kernel generation transformer that focuses on high-frequency details for improved reconstruction. We have evaluated our model on various aspects, such as comparative studies in supervised and self-supervised learning, diffusion model-based training, closed-set and open-set generalization under heterogeneous MRI data, and interpretation-based analysis. Our results show that the proposed method offers scalable and high-quality reconstruction with best improvement margins of ∼ 1 dB in PSNR and ∼ 0.01 in SSIM under unseen scenarios. Our code is available at https://github.com/sriprabhar/SHFormer .},
  archive      = {J_NN},
  author       = {Sriprabha Ramanarayanan and Rahul G.S. and Mohammad Al Fahim and Keerthi Ram and Ramesh Venkatesan and Mohanasankar Sivaprakasam},
  doi          = {10.1016/j.neunet.2025.107334},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107334},
  shortjournal = {Neural Netw.},
  title        = {SHFormer: Dynamic spectral filtering convolutional neural network and high-pass kernel generation transformer for adaptive MRI reconstruction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ternary spike-based neuromorphic signal processing system.
<em>NN</em>, <em>187</em>, 107333. (<a
href="https://doi.org/10.1016/j.neunet.2025.107333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNNs) have been successfully implemented across various signal processing fields, resulting in significant enhancements in performance. However, DNNs generally require substantial computational resources, leading to significant economic costs and posing challenges for their deployment on resource-constrained edge devices. In this study, we take advantage of spiking neural networks (SNNs) and quantization technologies to develop an energy-efficient and lightweight neuromorphic signal processing system. Our system is characterized by two principal innovations: a threshold-adaptive encoding (TAE) method and a quantized ternary SNN (QT-SNN). The TAE method can efficiently encode time-varying analog signals into sparse ternary spike trains, thereby reducing energy and memory demands for signal processing. QT-SNN, compatible with ternary spike trains from the TAE method, quantifies both membrane potentials and synaptic weights to reduce memory requirements while maintaining performance. Extensive experiments are conducted on two typical signal-processing tasks: speech and electroencephalogram recognition. The results demonstrate that our neuromorphic signal processing system achieves state-of-the-art (SOTA) performance with a 94% reduced memory requirement. Furthermore, through theoretical energy consumption analysis, our system shows 7 . 5 × energy saving compared to other SNN works. The efficiency and efficacy of the proposed system highlight its potential as a promising avenue for energy-efficient signal processing.},
  archive      = {J_NN},
  author       = {Shuai Wang and Dehao Zhang and Ammar Belatreche and Yichen Xiao and Hongyu Qing and Wenjie Wei and Malu Zhang and Yang Yang},
  doi          = {10.1016/j.neunet.2025.107333},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107333},
  shortjournal = {Neural Netw.},
  title        = {Ternary spike-based neuromorphic signal processing system},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute-guided feature fusion network with
knowledge-inspired attention mechanism for multi-source remote sensing
classification. <em>NN</em>, <em>187</em>, 107332. (<a
href="https://doi.org/10.1016/j.neunet.2025.107332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Land use and land cover (LULC) classification is a popular research area in remote sensing. The information of single-modal data is insufficient for accurate classification, especially in complex scenes, while the complementarity of multi-modal data such as hyperspectral images (HSIs) and light detection and ranging (LiDAR) data could effectively improve classification performance. The attention mechanism has recently been widely used in multi-modal LULC classification methods to achieve better feature representation. However, the knowledge of data is insufficiently considered in these methods, such as spectral mixture in HSIs and inconsistent spatial scales of different categories in LiDAR data. Moreover, multi-modal features contain different physical attributes, HSI features can represent spectral information of several channels while LiDAR features focus on elevation information at the spatial dimension. Ignoring these attributes, feature fusion may introduce redundant information and effect detrimentally on classification. In this paper, we propose an attribute-guided feature fusion network with knowledge-inspired attention mechanisms, named AFNKA. Focusing on the spectral characteristics of HSI and elevation information of LiDAR data, we design the knowledge-inspired attention mechanism to explore enhanced features. Especially, a novel adaptive cosine estimator (ACE) based attention module is presented to learn features with more discriminability, which adequately utilizes the spatial–spectral correlation of HSI mixed pixels. In the fusion stage, two novel attribute-guided fusion modules are developed to selectively aggregate multi-modal features, which sufficiently exploit the correlations between the spatial–spectral property of HSI features and the spatial-elevation property of LiDAR features. Experimental results on several multi-source datasets quantitatively indicate that the proposed AFNKA significantly outperforms the state-of-the-art methods.},
  archive      = {J_NN},
  author       = {Xiao Pan and Changzhe Jiao and Bo Yang and Hao Zhu and Jinjian Wu},
  doi          = {10.1016/j.neunet.2025.107332},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107332},
  shortjournal = {Neural Netw.},
  title        = {Attribute-guided feature fusion network with knowledge-inspired attention mechanism for multi-source remote sensing classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential stability of infinite-dimensional impulsive
stochastic systems with poisson jumps under aperiodically intermittent
control. <em>NN</em>, <em>187</em>, 107331. (<a
href="https://doi.org/10.1016/j.neunet.2025.107331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of mean square exponential stability (ES) for a class of impulsive stochastic infinite-dimensional systems with Poisson jumps (ISIDSP) using aperiodically intermittent control (AIC). It provides a detailed analysis of impulsive disturbances, and the related inequalities are given for the two cases when the impulse perturbation occurs at the start time points of the control and rest intervals or non-startpoints, respectively. Additionally, in virtue of Yosida approximating systems, combining with the Lyapunov method, graph theory and the above inequalities, criteria for ES of the above impulsive stochastic infinite-dimensional systems are established under AIC for these two perturbation scenarios. These criteria elucidate the effects of the impulsive perturbation strength, the ratio of control period, to rest period, and network topology on ES. Finally, the theoretical results are applied to a class of neural networks with reaction–diffusion processes, and the effectiveness of the findings is validated through numerical simulations.},
  archive      = {J_NN},
  author       = {Yiqun Liu and Lili Chen and Yanfeng Zhao and Zhen Wang},
  doi          = {10.1016/j.neunet.2025.107331},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107331},
  shortjournal = {Neural Netw.},
  title        = {Exponential stability of infinite-dimensional impulsive stochastic systems with poisson jumps under aperiodically intermittent control},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PanoGen++: Domain-adapted text-guided panoramic environment
generation for vision-and-language navigation. <em>NN</em>,
<em>187</em>, 107320. (<a
href="https://doi.org/10.1016/j.neunet.2025.107320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-and-language navigation (VLN) tasks require agents to navigate three-dimensional environments guided by natural language instructions, offering substantial potential for diverse applications. However, the scarcity of training data impedes progress in this field. This paper introduces PanoGen++, a novel framework that addresses this limitation by generating varied and pertinent panoramic environments for VLN tasks. PanoGen++ incorporates pre-trained diffusion models with domain-specific fine-tuning, employing parameter-efficient techniques such as low-rank adaptation to minimize computational costs. We investigate two settings for environment generation: masked image inpainting and recursive image outpainting. The former maximizes novel environment creation by inpainting masked regions based on textual descriptions, while the latter facilitates agents’ learning of spatial relationships within panoramas. Empirical evaluations on room-to-room (R2R), room-for-room (R4R), and cooperative vision-and-dialog navigation (CVDN) datasets reveal significant performance enhancements: a 2.44% increase in success rate on the R2R test leaderboard, a 0.63% improvement on the R4R validation unseen set, and a 0.75-meter enhancement in goal progress on the CVDN validation unseen set. PanoGen++ augments the diversity and relevance of training environments, resulting in improved generalization and efficacy in VLN tasks.},
  archive      = {J_NN},
  author       = {Sen Wang and Dongliang Zhou and Liang Xie and Chao Xu and Ye Yan and Erwei Yin},
  doi          = {10.1016/j.neunet.2025.107320},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107320},
  shortjournal = {Neural Netw.},
  title        = {PanoGen++: Domain-adapted text-guided panoramic environment generation for vision-and-language navigation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learn the global prompt in the low-rank tensor space for
heterogeneous federated learning. <em>NN</em>, <em>187</em>, 107319. (<a
href="https://doi.org/10.1016/j.neunet.2025.107319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning collaborates with multiple clients to train a global model, enhancing the model generalization while allowing the local data transmission-free and security. However, federated learning currently faces three intractable challenges: (1) The large number of model parameters result in an excessive communication burden. (2) The non-independently and identically distributed local data induces the degradation of global model. (3) The model heterogeneity renders traditional federated aggregation infeasible. To dissipate the three difficulties, we propose to learn the global prompt in the low-rank tensor space (FedGPT) for heterogeneous federated learning. Specifically, we employ the prompts rather than the model parameters as the carrier of local knowledge to achieve the information interaction between multiple clients. Since the prompts only have a very small number of variables, the communication volume is greatly reduced. To cope with the data heterogeneity, the prompts from different clients are stacked into the third-order tensors, on which the tensor singular value decomposition is performed to extract the global information. Furthermore, the proposed FedGPT possesses the ability to handle the model heterogeneity, the local models of different sizes can transfer the knowledge with the help of the prompts to improve the performance. Extensive experiments on three real-world datasets are conducted. Overall, FedGPT outperforms other state-of-the-art compared methods by up to 13.21%, and achieves less than 3% of communication volume of FedAvg, demonstrating the superiority of the proposed FedGPT.},
  archive      = {J_NN},
  author       = {Lele Fu and Sheng Huang and Yuecheng Li and Chuan Chen and Chuanfu Zhang and Zibin Zheng},
  doi          = {10.1016/j.neunet.2025.107319},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107319},
  shortjournal = {Neural Netw.},
  title        = {Learn the global prompt in the low-rank tensor space for heterogeneous federated learning},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HCPI-HRL: Human causal perception and inference-driven
hierarchical reinforcement learning. <em>NN</em>, <em>187</em>, 107318.
(<a href="https://doi.org/10.1016/j.neunet.2025.107318">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dependency on extensive expert knowledge for defining subgoals in hierarchical reinforcement learning (HRL) restricts the training efficiency and adaptability of HRL agents in complex, dynamic environments. Inspired by human-guided causal discovery skills, we proposed a novel method, Human Causal Perception and Inference-driven Hierarchical Reinforcement Learning (HCPI-HRL), designed to infer diverse, effective subgoal structures as intrinsic rewards and incorporate critical objects from dynamic environmental states using stable causal relationships. The HCPI-HRL method is supposed to guide an agent’s exploration direction and promote the reuse of learned subgoal structures across different tasks. Our designed HCPI-HRL comprises two levels: the top level operates as a meta controller, assigning subgoals discovered based on human-driven causal critical object perception and causal structure inference; the bottom level employs the Proximal Policy Optimisation (PPO) algorithm to accomplish the assigned subgoals. Experiments conducted across discrete and continuous control environments demonstrated that HCPI-HRL outperforms benchmark methods such as hierarchical and adjacency PPO in terms of training efficiency, exploration capability, and transferability. Our research extends the potential of HRL methods incorporating human-guided causal modelling to infer the effective relationships across subgoals, enhancing the agent’s capability to learn efficient policies in dynamic environments with sparse reward signals.},
  archive      = {J_NN},
  author       = {Bin Chen and Zehong Cao and Wolfgang Mayer and Markus Stumptner and Ryszard Kowalczyk},
  doi          = {10.1016/j.neunet.2025.107318},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107318},
  shortjournal = {Neural Netw.},
  title        = {HCPI-HRL: Human causal perception and inference-driven hierarchical reinforcement learning},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing user preferences by social networks: A
condition-guided social recommendation model for mitigating popularity
bias. <em>NN</em>, <em>187</em>, 107317. (<a
href="https://doi.org/10.1016/j.neunet.2025.107317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social recommendation models weave social interactions into their design to provide uniquely personalized recommendation results for users. However, social networks not only amplify the popularity bias in recommendation models, resulting in more frequent recommendation of hot items and fewer long-tail items, but also include a substantial amount of redundant information that is essentially meaningless for the model’s performance. Existing social recommendation models often integrate the entire social network directly, with little effort to filter or adjust social information to mitigate popularity bias introduced by the social network. In this paper, we propose a Condition-Guided Social Recommendation Model (named CGSoRec) to mitigate the model’s popularity bias by denoising the social network and adjusting the weights of user’s social preferences. More specifically, CGSoRec first includes a Condition-Guided Social Denoising Model (CSD) to remove redundant social relations in the social network for capturing users’ social preferences with items more precisely. Then, CGSoRec calculates users’ social preferences based on denoised social network and adjusts the weights in users’ social preferences to make them can counteract the popularity bias present in the recommendation model. At last, CGSoRec includes a Condition-Guided Diffusion Recommendation Model (CGD) to introduce the adjusted social preferences as conditions to control the recommendation results for a debiased direction. Comprehensive experiments on three real-world datasets demonstrate the effectiveness of our proposed method. The anonymous code is in: https://anonymous.4open.science/r/CGSoRec-2B72 .},
  archive      = {J_NN},
  author       = {Xin He and Wenqi Fan and Ruobing Wang and Yili Wang and Ying Wang and Shirui Pan and Xin Wang},
  doi          = {10.1016/j.neunet.2025.107317},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107317},
  shortjournal = {Neural Netw.},
  title        = {Balancing user preferences by social networks: A condition-guided social recommendation model for mitigating popularity bias},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADAMT: Adaptive distributed multi-task learning for
efficient image recognition in mobile ad-hoc networks. <em>NN</em>,
<em>187</em>, 107316. (<a
href="https://doi.org/10.1016/j.neunet.2025.107316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed machine learning in mobile adhoc networks faces significant challenges due to the limited computational resources of devices, non-IID data distribution, and dynamic network topology. Existing approaches often rely on centralized coordination and stable network conditions, which may not be feasible in practice. To address these issues, we propose an adaptive distributed multi-task learning framework called ADAMT for efficient image recognition in resource-constrained mobile ad hoc networks. ADAMT introduces three key innovations: (1) a feature expansion mechanism that enhances the expressiveness of local models by leveraging task-specific information; (2) a deep hashing technique that enables efficient on-device retrieval and multi-task fusion; and (3) an adaptive communication strategy that dynamically adjusts the model updating process based on network conditions and node reliability. The proposed framework allows each device to perform personalized model training on its local dataset while collaboratively updating the shared parameters with neighboring nodes. Extensive experiments on the ImageNet dataset demonstrate the superiority of ADAMT over state-of-the-art methods. ADAMT achieves a top-1 accuracy of 0.867, outperforming existing distributed learning approaches. Moreover, ADAMT significantly reduces the communication overhead and accelerates the convergence speed by 2.69 times compared to traditional distributed SGD. The adaptive communication strategy effectively balances the trade-off between model performance and resource consumption, making ADAMT particularly suitable for resource-constrained environments. Our work sheds light on the design of efficient and robust distributed learning algorithms for mobile adhoc networks and paves the way for deploying advanced machine learning applications on edge devices.},
  archive      = {J_NN},
  author       = {Jia Zhao and Wei Zhao and Yunan Zhai and Liyuan Zhang and Yan Ding},
  doi          = {10.1016/j.neunet.2025.107316},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107316},
  shortjournal = {Neural Netw.},
  title        = {ADAMT: Adaptive distributed multi-task learning for efficient image recognition in mobile ad-hoc networks},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FingerPoseNet: A finger-level multitask learning network
with residual feature sharing for 3D hand pose estimation. <em>NN</em>,
<em>187</em>, 107315. (<a
href="https://doi.org/10.1016/j.neunet.2025.107315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hand pose estimation approaches commonly rely on shared hand feature maps to regress the 3D locations of all hand joints. Subsequently, they struggle to enhance finger-level features which are invaluable in capturing joint-to-finger associations and articulations. To address this limitation, we propose a finger-level multitask learning network with residual feature sharing, named FingerPoseNet, for accurate 3D hand pose estimation from a depth image. FingerPoseNet comprises three stages: (a) a shared base feature map extraction backbone based on pre-trained ResNet-50; (b) a finger-level multitask learning stage that extracts and enhances feature maps for each finger and the palm; and (c) a multitask fusion layer for consolidating the estimation results obtained by each subtask. We exploit multitask learning by decoupling the hand pose estimation task into six subtasks dedicated to each finger and palm. Each subtask is responsible for subtask-specific feature extraction, enhancement, and 3D keypoint regression. To enhance subtask-specific features, we propose a residual feature-sharing approach scaled up to mine supplementary information from all subtasks. Experiments performed on five challenging public hand pose datasets, including ICVL, NYU, MSRA, Hands-2019-Task1, and HO3D-v3 demonstrate significant improvements in accuracy compared with state-of-the-art approaches.},
  archive      = {J_NN},
  author       = {Tekie Tsegay Tewolde and Ali Asghar Manjotho and Prodip Kumar Sarker and Zhendong Niu},
  doi          = {10.1016/j.neunet.2025.107315},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107315},
  shortjournal = {Neural Netw.},
  title        = {FingerPoseNet: A finger-level multitask learning network with residual feature sharing for 3D hand pose estimation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A general debiasing framework with counterfactual reasoning
for multimodal public speaking anxiety detection. <em>NN</em>,
<em>187</em>, 107314. (<a
href="https://doi.org/10.1016/j.neunet.2025.107314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Public Speaking Anxiety Detection (MPSAD), which aims to identify the anxiety states of learners, has attracted widespread attention. Unfortunately, the current MPSAD task inevitably suffers from the impact of latent different types of multimodal hybrid biases, such as context bias, label bias and keyword bias. Models may rely on these biases as shortcuts, preventing them from fully utilizing all three modalities to learn multimodal knowledge. Existing methods primarily focus on addressing specific types of biases, but anticipating bias types when designing these methods is challenging, as we cannot foresee all possible biases. To tackle this issue, we propose a General Multimodal Counterfactual Reasoning debiasing framework (GMCR), which eliminates multimodal hybrid biases from a unified causal perspective. Specifically, this plug-and-play debiasing framework removes multimodal hybrid biases by disentangling causal and biased features and capturing adverse effects via a counterfactual branch. It then subtracts spurious correlations during inference for unbiased predictions. Due to the challenge of collecting speech video data, there are currently limited high-quality datasets available for the MPSAD task. To overcome this scarcity, we create a new large-scale fine-grained Multimodal English Public Speaking Anxiety (ME-PSA) dataset. Extensive experiments on our ME-PSA and two benchmarks demonstrate the superiority of our proposed framework, with improvements of over 2.00% in accuracy and 4.00% in F1 score compared to the vanilla SOTA baselines. 1},
  archive      = {J_NN},
  author       = {Tingting Zhang and Yangfu Zhu and Bin Wu and Chunping Zheng and Jiachen Tan and Zihua Xiong},
  doi          = {10.1016/j.neunet.2025.107314},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107314},
  shortjournal = {Neural Netw.},
  title        = {A general debiasing framework with counterfactual reasoning for multimodal public speaking anxiety detection},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous graph neural network with adaptive relation
reconstruction. <em>NN</em>, <em>187</em>, 107313. (<a
href="https://doi.org/10.1016/j.neunet.2025.107313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological structures of real-world graphs often exhibit heterogeneity involving diverse nodes and relation types. In recent years, heterogeneous graph learning methods utilizing meta-paths to capture composite relations and guide neighbor selection have garnered considerable attention. However, meta-path based approaches may establish connections between nodes of different categories while overlooking relations between nodes of the same category, decreasing the quality of node embeddings. In light of this, this paper proposes a Heterogeneous Graph Neural Network with Adaptive Relation Reconstruction (HGNN-AR 2 ) that adaptively adjusts the relations to alleviate connection deficiencies and heteromorphic issues. HGNN-AR 2 is grounded on distinct connections derived from multiple meta-paths. By examining the homomorphic correlations of latent features from each meta-path, we reshape the cross-node connections to explore the pertinent latent relations. Through the relation reconstruction, we unveil unique connections reflected by each meta-path and incorporate them into graph convolutional networks for more comprehensive representations. The proposed model is evaluated on various benchmark heterogeneous graph datasets, demonstrating superior performance compared to state-of-the-art competitors.},
  archive      = {J_NN},
  author       = {Weihong Lin and Zhaoliang Chen and Yuhong Chen and Shiping Wang},
  doi          = {10.1016/j.neunet.2025.107313},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107313},
  shortjournal = {Neural Netw.},
  title        = {Heterogeneous graph neural network with adaptive relation reconstruction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ABVS breast tumour segmentation via integrating CNN with
dilated sampling self-attention and feature interaction transformer.
<em>NN</em>, <em>187</em>, 107312. (<a
href="https://doi.org/10.1016/j.neunet.2025.107312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the rapid increase in breast cancer incidence, the Automated Breast Volume Scanner (ABVS) is developed to screen breast tumours efficiently and accurately. However, reviewing ABVS images is a challenging task owing to the significant variations in sizes and shapes of breast tumours. We propose a novel 3D segmentation network (i.e., DST-C) that combines a convolutional neural network (CNN) with a dilated sampling self-attention Transformer (DST). In our network, the global features extracted from the DST branch are guided by the detailed local information provided by the CNN branch, which adapts to the diversity of tumour size and morphology. For medical images, especially ABVS images, the scarcity of annotation leads to difficulty in model training. Therefore, a self-supervised learning method based on a dual-path approach for mask image modelling is introduced to generate valuable representations of images. In addition, a unique postprocessing method is proposed to reduce the false-positive rate and improve the sensitivity simultaneously. The experimental results demonstrate that our model has achieved promising 3D segmentation and detection performance using our in-house dataset. Our code is available at: https://github.com/magnetliu/dstc-net .},
  archive      = {J_NN},
  author       = {Yiyao Liu and Jinyao Li and Yi Yang and Cheng Zhao and Yongtao Zhang and Peng Yang and Lei Dong and Xiaofei Deng and Ting Zhu and Tianfu Wang and Wei Jiang and Baiying Lei},
  doi          = {10.1016/j.neunet.2025.107312},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107312},
  shortjournal = {Neural Netw.},
  title        = {ABVS breast tumour segmentation via integrating CNN with dilated sampling self-attention and feature interaction transformer},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual selective fusion transformer network for hyperspectral
image classification. <em>NN</em>, <em>187</em>, 107311. (<a
href="https://doi.org/10.1016/j.neunet.2025.107311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer has achieved satisfactory results in the field of hyperspectral image (HSI) classification. However, existing Transformer models face two key challenges when dealing with HSI scenes characterized by diverse land cover types and rich spectral information: (1) A fixed receptive field overlooks the effective contextual scales required by various HSI objects; (2) invalid self-attention features in context fusion affect model performance. To address these limitations, we propose a novel Dual Selective Fusion Transformer Network (DSFormer) for HSI classification. DSFormer achieves joint spatial and spectral contextual modeling by flexibly selecting and fusing features across different receptive fields, effectively reducing unnecessary information interference by focusing on the most relevant spatial–spectral tokens. Specifically, we design a Kernel Selective Fusion Transformer Block (KSFTB) to learn an optimal receptive field by adaptively fusing spatial and spectral features across different scales, enhancing the model’s ability to accurately identify diverse HSI objects. Additionally, we introduce a Token Selective Fusion Transformer Block (TSFTB), which strategically selects and combines essential tokens during the spatial–spectral self-attention fusion process to capture the most crucial contexts. Extensive experiments conducted on four benchmark HSI datasets demonstrate that the proposed DSFormer significantly improves land cover classification accuracy, outperforming existing state-of-the-art methods. Specifically, DSFormer achieves overall accuracies of 96.59%, 97.66%, 95.17%, and 94.59% in the Pavia University, Houston, Indian Pines, and Whu-HongHu datasets, respectively, reflecting improvements of 3.19%, 1.14%, 0.91%, and 2.80% over the previous model. The code will be available online at https://github.com/YichuXu/DSFormer .},
  archive      = {J_NN},
  author       = {Yichu Xu and Di Wang and Lefei Zhang and Liangpei Zhang},
  doi          = {10.1016/j.neunet.2025.107311},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107311},
  shortjournal = {Neural Netw.},
  title        = {Dual selective fusion transformer network for hyperspectral image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting face forgery detection towards generalization.
<em>NN</em>, <em>187</em>, 107310. (<a
href="https://doi.org/10.1016/j.neunet.2025.107310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face forgery detection aims to distinguish AI generated fake faces with real faces. With the rapid development of face forgery creation algorithms, a large number of generative models have been proposed, which gradually reduce the local distortion phenomenon or the specific frequency traces in these models. At the same time, in the process of face data compression and transmission, distortion phenomenon and specific frequency cues could be eliminated, which brings severe challenges to the performance and generalization ability of face forgery detection. To promote the progress on face forgery detection research towards generalization, we present the first comprehensive overview and in-depth analysis of the generalizable face forgery detection methods. We categorize the target of generalizable face forgery detection into the robustness on novel and unknown forged images, and robustness on damaged low-quality images. We discuss representative generalization strategies including the aspects of data augmentation, multi-source learning, fingerprints detection, feature enhancement, temporal analysis, vision-language detection. We summarize the widely used datasets and the generalization performance of state-of-the-art methods in terms of robustness to novel unknown forgery as well as damaged quality forgery types. Finally, we discuss under-investigated open issues on face forgery detection towards generalization in six directions, including building a new generation of datasets, extracting strong forgery cues, considering identity features in face forgery detection, security and fairness of forgery detectors, the potential of large models in forgery detection and test-time adaptation. Our revisit of face forgery detection towards generalization will help promote the research and application of face forgery detection on real-world unconstrained conditions in the future.},
  archive      = {J_NN},
  author       = {Chunlei Peng and Tao Chen and Decheng Liu and Huiqing Guo and Nannan Wang and Xinbo Gao},
  doi          = {10.1016/j.neunet.2025.107310},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107310},
  shortjournal = {Neural Netw.},
  title        = {Revisiting face forgery detection towards generalization},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRTN: Dual relation transformer network with feature erasure
and contrastive learning for multi-label image classification.
<em>NN</em>, <em>187</em>, 107309. (<a
href="https://doi.org/10.1016/j.neunet.2025.107309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of multi-label image classification (MLIC) task is to simultaneously identify multiple objects present in an image. Several researchers directly flatten 2D feature maps into 1D grid feature sequences, and utilize Transformer encoder to capture the correlations of grid features to learn object relationships. Although obtaining promising results, these Transformer-based methods lose spatial information. In addition, current attention-based models often focus only on salient feature regions, but ignore other potential useful features that contribute to MLIC task. To tackle these problems, we present a novel D ual R elation T ransformer N etwork ( DRTN ) for MLIC task, which can be trained in an end-to-end manner. Concretely, to compensate for the loss of spatial information of grid features resulting from the flattening operation, we adopt a grid aggregation scheme to generate pseudo-region features, which does not need to make additional expensive annotations to train object detector. Then, a new dual relation enhancement (DRE) module is proposed to capture correlations between objects using two different visual features, thereby complementing the advantages provided by both grid and pseudo-region features. After that, we design a new feature enhancement and erasure (FEE) module to learn discriminative features and mine additional potential valuable features. By using attention mechanism to discover the most salient feature regions and removing them with region-level erasure strategy, our FEE module is able to mine other potential useful features from the remaining parts. Further, we devise a novel contrastive learning (CL) module to encourage the foregrounds of salient and potential features to be closer, while pushing their foregrounds further away from background features. This manner compels our model to learn discriminative and valuable features more comprehensively. Extensive experiments demonstrate that DRTN method surpasses current MLIC models on three challenging benchmarks, i.e. , MS-COCO 2014, PASCAL VOC 2007, and NUS-WIDE datasets.},
  archive      = {J_NN},
  author       = {Wei Zhou and Kang Lin and Zhijie Zheng and Dihu Chen and Tao Su and Haifeng Hu},
  doi          = {10.1016/j.neunet.2025.107309},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107309},
  shortjournal = {Neural Netw.},
  title        = {DRTN: Dual relation transformer network with feature erasure and contrastive learning for multi-label image classification},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structural network measures reveal the emergence of
heavy-tailed degree distributions in lottery ticket multilayer
perceptrons. <em>NN</em>, <em>187</em>, 107308. (<a
href="https://doi.org/10.1016/j.neunet.2025.107308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) were originally modeled after their biological counterparts, but have since conceptually diverged in many ways. The resulting network architectures are not well understood, and furthermore, we lack the quantitative tools to characterize their structures. Network science provides an ideal mathematical framework with which to characterize systems of interacting components, and has transformed our understanding across many domains, including the mammalian brain. Yet, little has been done to bring network science to ANNs. In this work, we propose tools that leverage and adapt network science methods to measure both global- and local-level characteristics of ANNs. Specifically, we focus on the structures of efficient multilayer perceptrons as a case study, which are sparse and systematically pruned such that they share many characteristics with real-world networks. We use adapted network science metrics to show that the pruning process leads to the emergence of a spanning subnetwork (lottery ticket multilayer perceptrons) with complex architecture. This complex network exhibits global and local characteristics, including heavy-tailed nodal degree distributions and dominant weighted pathways, that mirror patterns observed in human neuronal connectivity. Furthermore, alterations in network metrics precede catastrophic decay in performance as the network is heavily pruned. This network science-driven approach to the analysis of artificial neural networks serves as a valuable tool to establish and improve biological fidelity, increase the interpretability, and assess the performance of artificial neural networks. Significance Statement Artificial neural network architectures have become increasingly complex, often diverging from their biological counterparts in many ways. To design plausible “brain-like” architectures, whether to advance neuroscience research or to improve explainability, it is essential that these networks optimally resemble their biological counterparts. Network science tools offer valuable information about interconnected systems, including the brain, but have not attracted much attention for analyzing artificial neural networks. Here, we present the significance of our work: •We adapt network science tools to analyze the structural characteristics of artificial neural networks. •We demonstrate that organizational patterns similar to those observed in the mammalian brain emerge through the pruning process alone. The convergence on these complex network features in both artificial neural networks and biological brain networks is compelling evidence for their optimality in information processing capabilities. •Our approach is a significant first step towards a network science-based understanding of artificial neural networks, and has the potential to shed light on the biological fidelity of artificial neural networks.},
  archive      = {J_NN},
  author       = {Chris Kang and Jasmine A. Moore and Samuel Robertson and Matthias Wilms and Emma K. Towlson and Nils D. Forkert},
  doi          = {10.1016/j.neunet.2025.107308},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107308},
  shortjournal = {Neural Netw.},
  title        = {Structural network measures reveal the emergence of heavy-tailed degree distributions in lottery ticket multilayer perceptrons},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PrivCore: Multiplication-activation co-reduction for
efficient private inference. <em>NN</em>, <em>187</em>, 107307. (<a
href="https://doi.org/10.1016/j.neunet.2025.107307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The marriage of deep neural network (DNN) and secure 2-party computation (2PC) enables private inference (PI) on the encrypted client-side data and server-side models with both privacy and accuracy guarantees, coming at the cost of orders of magnitude communication and latency penalties. Prior works on designing PI-friendly network architectures are confined to mitigating the overheads associated with non-linear (e.g., ReLU) operations, assuming other linear computations are free. Recent works have shown that linear convolutions can no longer be ignored and are responsible for the majority of communication in PI protocols. In this work, we present PrivCore , a framework that jointly optimizes the alternating linear and non-linear DNN operators via a careful co-design of sparse Winograd convolution and fine-grained activation reduction, to improve high-efficiency ciphertext computation without impacting the inference precision. Specifically, being aware of the incompatibility between the spatial pruning and Winograd convolution, we propose a two-tiered Winograd-aware structured pruning method that removes spatial filters and Winograd vectors from coarse to fine-grained for multiplication reduction, both of which are specifically optimized for Winograd convolution in a structured pattern. PrivCore further develops a novel sensitivity-based differentiable activation approximation to automate the selection of ineffectual ReLUs and polynomial options. PrivCore also supports the dynamic determination of coefficient-adaptive polynomial replacement to mitigate the accuracy degradation. Extensive experiments on various models and datasets consistently validate the effectiveness of PrivCore , achieving 2 . 2 × communication reduction with 1.8% higher accuracy compared with SENet (ICLR 2023) on CIFAR-100, and 2 . 0 × total communication reduction with iso-accuracy compared with CoPriv (NeurIPS 2023) on ImageNet.},
  archive      = {J_NN},
  author       = {Zhi Pang and Lina Wang and Fangchao Yu and Kai Zhao and Bo Zeng and Shuwang Xu},
  doi          = {10.1016/j.neunet.2025.107307},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107307},
  shortjournal = {Neural Netw.},
  title        = {PrivCore: Multiplication-activation co-reduction for efficient private inference},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DuPt: Rehearsal-based continual learning with dual prompts.
<em>NN</em>, <em>187</em>, 107306. (<a
href="https://doi.org/10.1016/j.neunet.2025.107306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rehearsal-based continual learning methods usually involve reviewing a small number of representative samples to enable the network to learn new contents while retaining old knowledge. However, existing works overlook two crucial factors: (1) While the network prioritizes learning new data at incremental stages, it exhibits weaker generalization capabilities when trained individually on limited samples from specific categories, in contrast to training on large-scale samples across multiple categories simultaneously. (2) Knowledge distillation of a limited set of old samples can transfer certain existing knowledge, but imposing strong constraints may hinder knowledge transfer and restrict the ability of the network from the current stage to capture fresh knowledge. To alleviate these issues, we propose a rehearsal-based continual learning method with dual prompts, termed DuPt. First, we propose an input-aware prompt, an input-level cue that utilizes an input prior to querying for valid cue information. These hints serve as an additional complement to help the input samples generate more rational and diverse distributions. Second, we introduce a proxy feature prompt, a feature-level hint that bridges the knowledge gap between the teacher and student models to maintain consistency in the feature transfer process, reinforcing feature plasticity and stability. This is because differences in network features between the new and old incremental stages could affect the generalization of their new models if strictly aligned. Our proposed prompt can act as a consistency regularization to avoid feature conflicts caused by the differences between network features. Extensive experiments validate the effectiveness of our method, which can seamlessly integrate with existing methods, leading to performance improvements.},
  archive      = {J_NN},
  author       = {Shengqin Jiang and Daolong Zhang and Fengna Cheng and Xiaobo Lu and Qingshan Liu},
  doi          = {10.1016/j.neunet.2025.107306},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107306},
  shortjournal = {Neural Netw.},
  title        = {DuPt: Rehearsal-based continual learning with dual prompts},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex quantized minimum error entropy with fiducial
points: Theory and application in model regression. <em>NN</em>,
<em>187</em>, 107305. (<a
href="https://doi.org/10.1016/j.neunet.2025.107305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Minimum error entropy with fiducial points (MEEF) has gained significant attention due to its excellent performance in mitigating the adverse effects of non-Gaussian noise in the fields of machine learning and signal processing. However, the original MEEF algorithm suffers from high computational complexity due to the double summation of error samples. The quantized MEEF (QMEEF), proposed by Zheng et al. alleviates this computational burden through strategic quantization techniques, providing a more efficient solution. In this paper, we extend the application of these techniques to the complex domain, introducing complex QMEEF (CQMEEF). We theoretically introduce and prove the fundamental properties and convergence of CQMEEF. Furthermore, we apply this novel method to the training of a range of Linear-in-parameters (LIP) models, demonstrating its broad applicability. Experimental results show that CQMEEF achieves high precision in regression tasks involving various noise-corrupted datasets, exhibiting effectiveness under unfavorable conditions, and surpassing existing methods across critical performance metrics. Consequently, CQMEEF not only offers an efficient computational alternative but also opens up new avenues for dealing with complex data in regression tasks.},
  archive      = {J_NN},
  author       = {Bingqing Lin and Guobing Qian and Zongli Ruan and Junhui Qian and Shiyuan Wang},
  doi          = {10.1016/j.neunet.2025.107305},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107305},
  shortjournal = {Neural Netw.},
  title        = {Complex quantized minimum error entropy with fiducial points: Theory and application in model regression},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RISE-editing: Rotation-invariant neural point fields with
interactive segmentation for fine-grained and efficient editing.
<em>NN</em>, <em>187</em>, 107304. (<a
href="https://doi.org/10.1016/j.neunet.2025.107304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Radiance Fields (NeRF) have shown great potential for synthesizing novel views. Currently, despite the existence of some initial controllable and editable NeRF methods, they remain limited in terms of efficient and fine-grained editing capabilities, hinders the creative editing abilities and potential applications for NeRF. In this paper, we present the rotation-invariant neural point fields with interactive segmentation for fine-grained and efficient editing. Editing the implicit field presents a significant challenge, as varying the orientation of the corresponding explicit scaffold—whether point, mesh, volume, or other representations—may lead to a notable decline in rendering quality. By leveraging the complementary strengths of implicit NeRF-based representations and explicit point-based representations, we introduce a novel rotation-invariant neural point field representation. This representation enables the learning of local contents using Cartesian coordinates, leading to significant improvements in scene rendering quality after fine-grained editing. To achieve this rotation-invariant representation, we carefully design a Rotation-Invariant Neural Inverse Distance Weighting Interpolation (RNIDWI) module to aggregate the neural points. To enable more efficient and flexible cross-scene compositing, we disentangle the traditional NeRF representation into two components: a scene-agnostic rendering module and the scene-specific neural point fields. Furthermore, we present a multi-view ensemble learning strategy to lift the 2D inconsistent zero-shot segmentation results to 3D neural points field in real-time without post retraining. With simple click-based prompts on 2D images, user can efficiently segment the 3D neural point field and manipulate the corresponding neural points, enabling fine-grained editing of the implicit fields. Extensive experimental results demonstrate that our method offers enhanced editing capabilities and simplified editing process for users, delivers photorealistic rendering quality for novel views, and surpasses related methods in terms of the space–time efficiency and the types of editing functions they can achieve. The code is available at https://github.com/yuzewang1998/RISE-Editing .},
  archive      = {J_NN},
  author       = {Yuze Wang and Junyi Wang and Chen Wang and Yue Qi},
  doi          = {10.1016/j.neunet.2025.107304},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107304},
  shortjournal = {Neural Netw.},
  title        = {RISE-editing: Rotation-invariant neural point fields with interactive segmentation for fine-grained and efficient editing},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unambiguous granularity distillation for asymmetric image
retrieval. <em>NN</em>, <em>187</em>, 107303. (<a
href="https://doi.org/10.1016/j.neunet.2025.107303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous asymmetric image retrieval methods based on knowledge distillation have primarily focused on aligning the global features of two networks to transfer global semantic information from the gallery network to the query network. However, these methods often fail to effectively transfer local semantic information, limiting the fine-grained alignment of feature representation spaces between the two networks. To overcome this limitation, we propose a novel approach called Layered-Granularity Localized Distillation (GranDist). GranDist constructs layered feature representations that balance the richness of contextual information with the granularity of local features. As we progress through the layers, the contextual information becomes more detailed, but the semantic gap between networks can widen, complicating the transfer process. To address this challenge, GranDist decouples the feature maps at each layer to capture local features at different granularities and establishes distillation pipelines focused on effectively transferring these contextualized local features. In addition, we introduce an Unambiguous Localized Feature Selection (UnamSel) method, which leverages a well-trained fully connected layer to classify these contextual features as either ambiguous or unambiguous. By discarding the ambiguous features, we prevent the transfer of irrelevant or misleading information, such as background elements that are not pertinent to the retrieval task. Extensive experiments on various benchmark datasets demonstrate that our method outperforms state-of-the-art techniques and significantly enhances the performance of previous asymmetric retrieval approaches.},
  archive      = {J_NN},
  author       = {Hongrui Zhang and Yi Xie and Haoquan Zhang and Cheng Xu and Xuandi Luo and Donglei Chen and Xuemiao Xu and Huaidong Zhang and Pheng Ann Heng and Shengfeng He},
  doi          = {10.1016/j.neunet.2025.107303},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107303},
  shortjournal = {Neural Netw.},
  title        = {Unambiguous granularity distillation for asymmetric image retrieval},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hy-DeFake: Hypergraph neural networks for detecting fake
news in online social networks. <em>NN</em>, <em>187</em>, 107302. (<a
href="https://doi.org/10.1016/j.neunet.2025.107302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays social media is the primary platform for people to obtain news and share information. Combating online fake news has become an urgent task to reduce the damage it causes to society. Existing methods typically improve their fake news detection performances by utilizing textual auxiliary information (such as relevant retweets and comments) or simple structural information ( i.e. , graph construction). However, these methods face two challenges. First, an increasing number of users tend to directly forward the source news without adding comments, resulting in a lack of textual auxiliary information. Second, simple graphs are unable to extract complex relations beyond pairwise association in a social context. Given that real-world social networks are intricate and involve high-order relations, we argue that exploring beyond pairwise relations between news and users is crucial for fake news detection. Therefore, we propose constructing an attributed hypergraph to represent non-textual and high-order relations for user participation in news spreading. We also introduce a hypergraph neural network-based method called Hy-DeFake to tackle the challenges. Our proposed method captures semantic information from news content, credibility information from involved users, and high-order correlations between news and users to learn distinctive embeddings for fake news detection. The superiority of Hy-DeFake is demonstrated through experiments conducted on four widely-used datasets, and it is compared against nine baselines using four evaluation metrics.},
  archive      = {J_NN},
  author       = {Xing Su and Jian Yang and Jia Wu and Zitai Qiu},
  doi          = {10.1016/j.neunet.2025.107302},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107302},
  shortjournal = {Neural Netw.},
  title        = {Hy-DeFake: Hypergraph neural networks for detecting fake news in online social networks},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum federated learning with pole-angle quantum local
training and trainable measurement. <em>NN</em>, <em>187</em>, 107301.
(<a href="https://doi.org/10.1016/j.neunet.2025.107301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, quantum federated learning (QFL) has received significant attention as an innovative paradigm. QFL has remarkable features by employing quantum neural networks (QNNs) instead of conventional neural networks owing to quantum supremacy. In order to enhance the flexibility and reliability of classical QFL frameworks, this paper proposes a novel slimmable QFL (SlimQFL) incorporating QNN-grounded slimmable neural network (QSNN) architectures. This innovative design considers time-varying wireless communication channels and computing resource constraints. This framework ensures higher efficiency by using fewer parameters with no performance loss. Furthermore, the proposed QNN is novel according to the implementation of trainable measurement within QFL. The fundamental concept of our QSNN is designed based on the key characteristics of separated training and the dynamic exploitation of joint angle and pole parameters. Our performance evaluation results verify that using both parameters, our proposed QSNN-based SlimQFL achieves higher classification accuracy than QFL and ensures transmission stability, particularly in poor channel conditions.},
  archive      = {J_NN},
  author       = {Soohyun Park and Hyunsoo Lee and Seok Bin Son and Soyi Jung and Joongheon Kim},
  doi          = {10.1016/j.neunet.2025.107301},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107301},
  shortjournal = {Neural Netw.},
  title        = {Quantum federated learning with pole-angle quantum local training and trainable measurement},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EBM-WGF: Training energy-based models with wasserstein
gradient flow. <em>NN</em>, <em>187</em>, 107300. (<a
href="https://doi.org/10.1016/j.neunet.2025.107300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy-based models (EBMs) show their efficiency in density estimation. However, MCMC sampling in traditional EBMs suffers from expensive computation. Although EBMs with minimax game avoid the above drawback, the energy estimation and generator’s optimization are not always stable. We find that the reason for this instability arises from the inaccuracy of minimizing KL divergence between generative and energy distribution along a vanilla gradient flow. In this paper, we leverage the Wasserstein gradient flow (WGF) of the KL divergence to correct the optimization direction of the generator in the minimax game. Different from existing WGF-based models, we pullback the WGF to parameter space and solve it with a variational scheme for bounded solution error. We propose a new EBM with WGF that overcomes the instability of the minimax game and avoids computational MCMC sampling in traditional methods, as we observe that the solution of WGF in our approach is equivalent to Langevin dynamic in EBMs with MCMC sampling. The empirical experiments on toy and natural datasets validate the effectiveness of our approach.},
  archive      = {J_NN},
  author       = {Ben Wan and Cong Geng and Tianyi Zheng and Jia Wang},
  doi          = {10.1016/j.neunet.2025.107300},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107300},
  shortjournal = {Neural Netw.},
  title        = {EBM-WGF: Training energy-based models with wasserstein gradient flow},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Probabilistic memory auto-encoding network for abnormal
behavior detection in surveillance video. <em>NN</em>, <em>187</em>,
107299. (<a href="https://doi.org/10.1016/j.neunet.2025.107299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abnormal behavior detection in surveillance video, as one of the essential functions in the intelligent surveillance system, plays a vital role in anti-terrorism, maintaining stability, and ensuring social security. Aiming at the problem of extremely imbalance between normal behavior data and abnormal behavior data, the probabilistic memory model-based network is designed to learn from the distribution of normal behaviors and guide the detection of abnormal behavior. An auto-encoding model is employed as the backbone network, and the gap between the predicted future frame and the real frame is used to measure the degree of abnormality. An autoregressive conditional probability estimation model and a normal distribution memory model are employed as auxiliary modules, to achieve the prediction of normal frames. When extracting temporal and spatial features in the backbone network, the causal three-dimensional convolution and time-dimension shared fully connected layers are used to avoid future information leakage and ensure the timing of information. In addition, from the perspective of probability entropy and behavioral modality diversity, autoregressive probability model is proposed to fit the distribution of input normal frame, so the network converges to the low entropy state of the normal behavior distribution. The memory module stores the feature of normal behavior in historical data, and injects the current input data. The memory vector and the encoding vector are concatenated along the time dimension and input to the decoder, realizing normal frame prediction. Using public datasets, ablation and comparison experiments show that the proposed algorithm has significant advantages in anomaly detection.},
  archive      = {J_NN},
  author       = {Jinsheng Xiao and Jingyi Wu and Shurui Wang and Qiuze Yu and Honggang Xie and Yuan-Fang Wang},
  doi          = {10.1016/j.neunet.2025.107299},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107299},
  shortjournal = {Neural Netw.},
  title        = {Probabilistic memory auto-encoding network for abnormal behavior detection in surveillance video},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dataset-free weight-initialization on restricted boltzmann
machine. <em>NN</em>, <em>187</em>, 107297. (<a
href="https://doi.org/10.1016/j.neunet.2025.107297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In feed-forward neural networks, dataset-free weight-initialization methods such as LeCun, Xavier (or Glorot), and He initializations have been developed. These methods randomly determine the initial values of weight parameters based on specific distributions (e.g., Gaussian or uniform distributions) without using training datasets. To the best of the authors’ knowledge, such a dataset-free weight-initialization method is yet to be developed for restricted Boltzmann machines (RBMs), which are probabilistic neural networks consisting of two layers. In this study, we derive a dataset-free weight-initialization method for Bernoulli–Bernoulli RBMs based on statistical mechanical analysis. In the proposed weight-initialization method, the weight parameters are drawn from a Gaussian distribution with zero mean. The standard deviation of the Gaussian distribution is optimized based on our hypothesis that a standard deviation providing a larger layer correlation (LC) between the two layers improves the learning efficiency. The expression of the LC is derived based on a statistical mechanical analysis. The optimal value of the standard deviation corresponds to the maximum point of the LC. The proposed weight-initialization method is identical to Xavier initialization in a specific case (i.e., when the sizes of the two layers are the same, the random variables of the layers are { − 1 , 1 } -binary, and all bias parameters are zero). The validity of the proposed weight-initialization method is demonstrated in numerical experiments using a toy dataset and real-world datasets.},
  archive      = {J_NN},
  author       = {Muneki Yasuda and Ryosuke Maeno and Chako Takahashi},
  doi          = {10.1016/j.neunet.2025.107297},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107297},
  shortjournal = {Neural Netw.},
  title        = {Dataset-free weight-initialization on restricted boltzmann machine},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning of conjugated visual representations
through higher-order motion flows. <em>NN</em>, <em>187</em>, 107296.
(<a href="https://doi.org/10.1016/j.neunet.2025.107296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning with neural networks from a continuous stream of visual information presents several challenges due to the non-i.i.d. nature of the data. However, it also offers novel opportunities to develop representations that are consistent with the information flow. In this paper we investigate the case of unsupervised continual learning of pixel-wise features subject to multiple motion-induced constraints, therefore named motion-conjugated feature representations . Differently from existing approaches, motion is not a given signal (either ground-truth or estimated by external modules), but is the outcome of a progressive and autonomous learning process, occurring at various levels of the feature hierarchy. Multiple motion flows are estimated with neural networks and characterized by different levels of abstractions, spanning from traditional optical flow to other latent signals originating from higher-level features, hence called higher-order motions. Continuously learning to develop consistent multi-order flows and representations is prone to trivial solutions, which we counteract by introducing a self-supervised contrastive loss, spatially-aware and based on flow-induced similarity. We assess our model on photorealistic synthetic streams and real-world videos, comparing to pre-trained state-of-the art feature extractors (also based on Transformers) and to recent unsupervised learning models, significantly outperforming these alternatives.},
  archive      = {J_NN},
  author       = {Simone Marullo and Matteo Tiezzi and Marco Gori and Stefano Melacci},
  doi          = {10.1016/j.neunet.2025.107296},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107296},
  shortjournal = {Neural Netw.},
  title        = {Continual learning of conjugated visual representations through higher-order motion flows},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmenting sparse behavior data for user identity linkage
with self-generated by model and mixup-generated samples. <em>NN</em>,
<em>187</em>, 107295. (<a
href="https://doi.org/10.1016/j.neunet.2025.107295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The user identity linkage task aims to associate user accounts belonging to the same individual by utilizing user data. This task is relevant in domains such as recommendation systems, where user-generated content (i.e., behavioral data) serves as the key information for identifying users. However, user identity linkage tasks relying on behavioral data face two primary challenges due to data sparsity: insufficient user behavior data and the presence of low-frequency behavior items. These issues hinder accurate modeling and exacerbate representation errors. To address these challenges, we propose two data augmentation methods: self-generated samples by the model and mixup-generated samples. Collectively, these methods are referred to as SGAMDA (Self-generated by Model and Mixup-generated Samples-based Data Augmentation). The self-generated samples method uses Variational Autoencoders to generate new training data by decoding samples in the representation space. The mixup-generated samples method creates new training data by mixing the behavior data of different user groups, thereby alleviating data sparsity. SGAMDA categorizes user behavior data based on data volume and the proportion of low-frequency behaviors to guide the two data augmentation strategies. We evaluate SGAMDA on the Movies2Books and CDs2Movies datasets for user identity linkage tasks. The results show that SGAMDA significantly improves prediction accuracy, enhancing behavior representation through the proposed data augmentation methods.},
  archive      = {J_NN},
  author       = {Hongren Huang and Jianxin Li and Feihong Lu and Lihong Wang and Qian Li and Qingyun Sun},
  doi          = {10.1016/j.neunet.2025.107295},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107295},
  shortjournal = {Neural Netw.},
  title        = {Augmenting sparse behavior data for user identity linkage with self-generated by model and mixup-generated samples},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral anomaly detection with self-supervised anomaly
prior. <em>NN</em>, <em>187</em>, 107294. (<a
href="https://doi.org/10.1016/j.neunet.2025.107294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral anomaly detection (HAD) can identify and locate the targets without any known information and is widely applied in Earth observation and military fields. The majority of existing HAD methods use the low-rank representation (LRR) model to separate the background and anomaly through mathematical optimization, in which the anomaly is optimized with a handcrafted sparse prior (e.g., ℓ 2 , 1 -norm). However, this may not be ideal since they overlook the spatial structure present in anomalies and make the detection result largely dependent on manually set sparsity. To tackle these problems, we redefine the optimization criterion for the anomaly in the LRR model with a self-supervised network called self-supervised anomaly prior (SAP). This prior is obtained by the pretext task of self-supervised learning, which is customized to learn the characteristics of hyperspectral anomalies. Specifically, this pretext task is a classification task to distinguish the original hyperspectral image (HSI) and the pseudo-anomaly HSI, where the pseudo-anomaly is generated from the original HSI and designed as a prism with arbitrary polygon bases and arbitrary spectral bands. In addition, a dual-purified strategy is proposed to provide a more refined background representation with an enriched background dictionary, facilitating the separation of anomalies from complex backgrounds. Extensive experiments on various hyperspectral datasets demonstrate that the proposed SAP offers a more accurate and interpretable solution than other advanced HAD methods.},
  archive      = {J_NN},
  author       = {Yidan Liu and Kai Jiang and Weiying Xie and Jiaqing Zhang and Yunsong Li and Leyuan Fang},
  doi          = {10.1016/j.neunet.2025.107294},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107294},
  shortjournal = {Neural Netw.},
  title        = {Hyperspectral anomaly detection with self-supervised anomaly prior},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anxiety disorder identification with biomarker detection
through subspace-enhanced hypergraph neural network. <em>NN</em>,
<em>187</em>, 107293. (<a
href="https://doi.org/10.1016/j.neunet.2025.107293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a subspace-enhanced hypergraph neural network (seHGNN) for classifying anxiety disorders (AD), which are prevalent mental illnesses that affect a significant portion of the global population. Our seHGNN model utilizes a learnable incidence matrix to strengthen the influence of hyperedges in graphs and enhance the feature extraction performance of hypergraph neural networks (HGNNs). Then, we integrate multimodal data on the brain limbic system into a hypergraph within an existing binary hypothesis testing framework. Experimental results demonstrate that our seHGNN achieves a remarkable accuracy of 84.46% for AD classification. By employing an ensemble learning strategy, we can further improve its performance, achieving a high accuracy of 94.1%. Our method outperforms other deep-learning-based methods, particularly GNN-based methods. Furthermore, our seHGNN successfully identifies discriminative AD biomarkers that align with existing reports, providing strong evidence supporting the effectiveness and interpretability of our proposed method.},
  archive      = {J_NN},
  author       = {Yibin Tang and Jikang Ding and Ying Chen and Yuan Gao and Aimin Jiang and Chun Wang},
  doi          = {10.1016/j.neunet.2025.107293},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107293},
  shortjournal = {Neural Netw.},
  title        = {Anxiety disorder identification with biomarker detection through subspace-enhanced hypergraph neural network},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory flow-controlled knowledge tracing with three stages.
<em>NN</em>, <em>187</em>, 107292. (<a
href="https://doi.org/10.1016/j.neunet.2025.107292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT), as a pivotal technology in intelligent education systems, analyzes students’ learning data to infer their knowledge acquisition and predict their future performance. Recent advancements in KT recognize the importance of memory laws on knowledge acquisition but neglect modeling the inherent structure of memory, which leads to the inconsistency between explicit student learning and implicit memory transformation. Therefore, to enhance the consistency, we propose a novel memory flow-controlled knowledge tracing with three stages (MFCKT). According to information processing theory, we deconstruct learning into: sensory registration, short-term encoding, and long-term memory retrieval stages. Specifically, to extract sensory memory, MFCKT maximizes the similarity between positive augmentation views of learning sequence representations through contrastive pre-training. Then, to transform sensory memory into short-term memory, MFCKT fuses relational and temporal properties of sensory memory through a dual-channel structure composed of attention and recurrent neural networks. Furthermore, for obtaining long-term memory, MFCKT designs a monotonic gating mechanism to compute weights of hidden memory states, and then performs read-write operations on the memory matrix. Finally, MFCKT combines long-term and short-term memory vectors to retrieve latent knowledge states for future performance prediction. Extensive experimental results on five real-world datasets verify the superiority and interpretability of MFCKT.},
  archive      = {J_NN},
  author       = {Tao Huang and Junjie Hu and Huali Yang and Shengze Hu and Jing Geng and Xinjia Ou},
  doi          = {10.1016/j.neunet.2025.107292},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107292},
  shortjournal = {Neural Netw.},
  title        = {Memory flow-controlled knowledge tracing with three stages},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-view graph-of-graph representation learning with graph
transformer for graph-level anomaly detection. <em>NN</em>,
<em>187</em>, 107291. (<a
href="https://doi.org/10.1016/j.neunet.2025.107291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-Level Anomaly Detection (GLAD) endeavors to pinpoint a small subset of anomalous graphs that deviate from the normal data distribution within a given set of graph data. Existing GLAD methods typically rely on Graph Neural Networks (GNNs) to extract graph-level representations, which are then used for the detection task. However, the inherent limited receptive field of GNNs may exclude crucial anomalous information embedded within the graph. Moreover, the inadequate modeling of cross-graph relationships limits the exploration of connections between different graphs, thus restricting the model’s ability to uncover inter-graph anomalous patterns. In this paper, we propose a novel approach called Dual-View Graph-of-Graph Representation Learning Network for unsupervised GLAD, which takes into account both intra-graph and inter-graph perspectives. Firstly, to enhance the capability of mining intra-graph information, we introduce a Graph Transformer that enhances the receptive field of the GNNs by considering both attribute and structural information. This augmentation enables a comprehensive exploration of the information encoded within the graph. Secondly, to explicitly capture the cross-graph dependencies, we devise a Graph-of-Graph-based dual-view representation learning network to explicitly capture cross-graph interdependencies. Attribute and structure-based graph-of-graph representations are induced, facilitating a comprehensive understanding of the relationships between graphs. Finally, we utilize anomaly scores from different perspectives to quantify the extent of anomalies present in each graph. This multi-perspective evaluation provides a more comprehensive assessment of anomalies within the graph data. Extensive experiments conducted on multiple benchmark datasets demonstrate the effectiveness of our proposed method in detecting anomalies within graph data.},
  archive      = {J_NN},
  author       = {Wangyu Jin and Huifang Ma and Yingyue Zhang and Zhixin Li and Liang Chang},
  doi          = {10.1016/j.neunet.2025.107291},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107291},
  shortjournal = {Neural Netw.},
  title        = {Dual-view graph-of-graph representation learning with graph transformer for graph-level anomaly detection},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Episodic memory-double actor–critic twin delayed deep
deterministic policy gradient. <em>NN</em>, <em>187</em>, 107286. (<a
href="https://doi.org/10.1016/j.neunet.2025.107286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing deep reinforcement learning (DRL) algorithms suffer from the problem of low sample efficiency. Episodic memory allows DRL algorithms to remember and use past experiences with high return, thereby improving sample efficiency. However, due to the high dimensionality of the state–action space in continuous action tasks, previous methods in continuous action tasks often only utilize the information stored in episodic memory, rather than directly employing episodic memory for action selection as done in discrete action tasks. We suppose that episodic memory retains the potential to guide action selection in continuous control tasks. Our objective is to enhance sample efficiency by leveraging episodic memory for action selection in such tasks—either reducing the number of training steps required to achieve comparable performance or enabling the agent to obtain higher rewards within the same number of training steps. To this end, we propose an “Episodic Memory-Double Actor–Critic (EMDAC)” framework, which can use episodic memory for action selection in continuous action tasks. The critics and episodic memory evaluate the value of state–action pairs selected by the two actors to determine the final action. Meanwhile, we design an episodic memory based on a Kalman filter optimizer, which updates using the episodic rewards of collected state–action pairs. The Kalman filter optimizer assigns different weights to experiences collected at different time periods during the memory update process. In our episodic memory, state–action pair clusters are used as indices, recording both the occurrence frequency of these clusters and the value estimates for the corresponding state–action pairs. This enables the estimation of the value of state–action pair clusters by querying the episodic memory. After that, we design intrinsic reward based on the novelty of state–action pairs with episodic memory, defined by the occurrence frequency of state–action pair clusters, to enhance the exploration capability of the agent. Ultimately, we propose an “EMDAC-TD3” algorithm by applying this three modules to Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm within an Actor–Critic framework. Through evaluations in MuJoCo environments within the OpenAI Gym domain, EMDAC-TD3 achieves higher sample efficiency compared to baseline algorithms. EMDAC-TD3 demonstrates superior final performance compared to state-of-the-art episodic control algorithms and advanced Actor–Critic algorithms, by comparing the final rewards, Median, Interquartile Mean, Mean, and Optimality Gap. The final rewards can directly demonstrate the advantages of the algorithms. Based on the final rewards, EMDAC-TD3 achieves an average performance improvement of 11.01% over TD3, surpassing the current state-of-the-art algorithms in the same category.},
  archive      = {J_NN},
  author       = {Man Shu and Shuai Lü and Xiaoyu Gong and Daolong An and Songlin Li},
  doi          = {10.1016/j.neunet.2025.107286},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107286},
  shortjournal = {Neural Netw.},
  title        = {Episodic memory-double Actor–Critic twin delayed deep deterministic policy gradient},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation by non-symmetric networks for cross-domain
learning. <em>NN</em>, <em>187</em>, 107282. (<a
href="https://doi.org/10.1016/j.neunet.2025.107282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the past 30 years or so, machine learning has stimulated a great deal of research in the study of approximation capabilities (expressive power) of a multitude of processes, such as approximation by shallow or deep neural networks, radial basis function networks, and a variety of kernel based methods. Motivated by applications such as invariant learning, transfer learning, and synthetic aperture radar imaging, we initiate in this paper a general approach to study the approximation capabilities of kernel based networks using non-symmetric kernels. While singular value decomposition is a natural instinct to study such kernels, we consider a more general approach to include the use of a family of kernels, such as generalized translation networks (which include neural networks and translation invariant kernels as special cases) and rotated zonal function kernels. Naturally, unlike traditional kernel based approximation, we cannot require the kernels to be positive definite. In particular, we obtain estimates on the accuracy of uniform approximation of functions in a Sobolev class by ReLU r networks when r is not necessarily an integer. Our general results apply to the approximation of functions with small smoothness compared to the dimension of the input space.},
  archive      = {J_NN},
  author       = {H.N. Mhaskar},
  doi          = {10.1016/j.neunet.2025.107282},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107282},
  shortjournal = {Neural Netw.},
  title        = {Approximation by non-symmetric networks for cross-domain learning},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StoCFL: A stochastically clustered federated learning
framework for non-IID data with dynamic client participation.
<em>NN</em>, <em>187</em>, 107278. (<a
href="https://doi.org/10.1016/j.neunet.2025.107278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is a distributed learning framework that takes full advantage of private data samples kept on edge devices. In real-world federated learning systems, these data samples are often decentralized and Non-Independently Identically Distributed (Non-IID), causing divergence and performance degradation in the federated learning process. As a new solution, clustered federated learning groups federated clients with similar data distributions to impair the Non-IID effects and train a better model for every cluster. However, existing CFL algorithms are ineffective because they lack an information-sharing mechanism across clusters resulting in low data efficiency and model performance. Meanwhile, their performance is highly subjected to ideal client clustering results which are practically unavailable. This paper proposes StoCFL, a novel clustered federated learning framework for generic Non-IID issues. In detail, StoCFL implements a flexible CFL framework that supports an arbitrary proportion of client participation and newly joined clients for a varying FL system, while maintaining a great improvement in model performance. The intensive experiments are conducted by using four basic Non-IID settings and a real-world dataset. The results show that StoCFL could obtain promising cluster results even when the number of clusters is unknown. Based on the client clustering results, models trained with StoCFL outperform baseline approaches in a variety of scenarios.},
  archive      = {J_NN},
  author       = {Dun Zeng and Xiangjing Hu and Shiyu Liu and Yue Yu and Qifan Wang and Zenglin Xu},
  doi          = {10.1016/j.neunet.2025.107278},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107278},
  shortjournal = {Neural Netw.},
  title        = {StoCFL: A stochastically clustered federated learning framework for non-IID data with dynamic client participation},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural networks trained by weight permutation are universal
approximators. <em>NN</em>, <em>187</em>, 107277. (<a
href="https://doi.org/10.1016/j.neunet.2025.107277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The universal approximation property is fundamental to the success of neural networks, and has traditionally been achieved by training networks without any constraints on their parameters. However, recent experimental research proposed a novel permutation-based training method, which exhibited a desired classification performance without modifying the exact weight values. In this paper, we provide a theoretical guarantee of this permutation training method by proving its ability to guide a ReLU network to approximate one-dimensional continuous functions. Our numerical results further validate this method’s efficiency in regression tasks with various initializations. The notable observations during weight permutation suggest that permutation training can provide an innovative tool for describing network learning behavior.},
  archive      = {J_NN},
  author       = {Yongqiang Cai and Gaohang Chen and Zhonghua Qiao},
  doi          = {10.1016/j.neunet.2025.107277},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107277},
  shortjournal = {Neural Netw.},
  title        = {Neural networks trained by weight permutation are universal approximators},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedELR: When federated learning meets learning with noisy
labels. <em>NN</em>, <em>187</em>, 107275. (<a
href="https://doi.org/10.1016/j.neunet.2025.107275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research on federated learning (FL) usually assumes that training labels are of high quality for each client, which is impractical in many real-world scenarios (e.g., noisy labels by crowd-sourced annotations), leading to dramatic performance degradation. In this work, we investigate noisy FL through the lens of early-time training phenomenon (ETP). Specifically, a key finding of this paper is that the early training phase varies among different local clients due to the different noisy classes in each client. In addition, we show that such an inconsistency also exists between the local and global models. As a result, local clients would always begin to memorize noisy labels before the global model reaches the optimal, which inevitably leads to the degradation of the quality of service in real-world FL applications (e.g. tumor image classification among different hospitals). Our findings provide new insights into the learning dynamics and shed light on the essence cause of this degradation in noisy FL. To address this problem, we reveal a new principle for noisy FL: it is necessary to align the early training phases across local models. To this end, we propose FedELR, a simple yet effective framework that aims to force local models to stick to their early training phase via an early learning regularization (ELR), so that the learning dynamics of local models can be kept at the same pace. Moreover, this also leverages the ETP in local clients, leading each client to take more training steps in learning a more robust local model for optimal global aggregation. Extensive experiments on various real-world datasets also validate the effectiveness of our proposed methods.},
  archive      = {J_NN},
  author       = {Ruizhi Pu and Lixing Yu and Shaojie Zhan and Gezheng Xu and Fan Zhou and Charles X. Ling and Boyu Wang},
  doi          = {10.1016/j.neunet.2025.107275},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107275},
  shortjournal = {Neural Netw.},
  title        = {FedELR: When federated learning meets learning with noisy labels},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image debanding using cross-scale invertible networks with
banded deformable convolutions. <em>NN</em>, <em>187</em>, 107270. (<a
href="https://doi.org/10.1016/j.neunet.2025.107270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Banding artifacts in images stem from limitations in color bit depth, image compression, or over-editing, significantly degrades image quality, especially in regions with smooth gradients. Image debanding is about eliminating these artifacts while preserving the authenticity of image details. This paper introduces a novel approach to image debanding using a cross-scale invertible neural network (INN). The proposed INN is information-lossless and enhanced by a more effective cross-scale scheme. Additionally, we present a technique called banded deformable convolution, which fully leverages the anisotropic properties of banding artifacts. This technique is more compact, efficient, and exhibits better generalization compared to existing deformable convolution methods. Our proposed INN exhibits superior performance in both quantitative metrics and visual quality, as evidenced by the results of the experiments.},
  archive      = {J_NN},
  author       = {Yuhui Quan and Xuyi He and Ruotao Xu and Yong Xu and Hui Ji},
  doi          = {10.1016/j.neunet.2025.107270},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107270},
  shortjournal = {Neural Netw.},
  title        = {Image debanding using cross-scale invertible networks with banded deformable convolutions},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting instance-label dynamics through reciprocal
anchored contrastive learning for few-shot relation extraction.
<em>NN</em>, <em>187</em>, 107259. (<a
href="https://doi.org/10.1016/j.neunet.2025.107259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of Few-shot Relation Extraction (FSRE), the primary objective is to distill relational facts from limited labeled datasets. This task has recently witnessed significant advancements through the integration of Pre-trained Language Models (PLMs) within a supervised contrastive learning schema, which effectively leverages the dynamics between instance and label information. Despite these advancements, the comprehensive utilization of extensive instance-label pairs, aimed at facilitating the extraction of semantically rich representations within this paradigm, has yet to be fully harnessed. To bridge this gap, we introduce a R eciprocal A nchored C ontrastive L earning framework (RACL) for few-shot relation extraction, which is predicated on the premise that instance-label pairs provide distinct yet inherently complementary insights into textual semantics. Specifically, RACL employs a symmetric contrastive objective that incorporates both instance-level and label-level contrastive losses, promoting a more integrated and unified representational space. This approach is engineered to effectively delineate the nuanced relationships between instance attributes and relational facts, while simultaneously optimizing information sharing across different perspectives within the same relations. Extensive experiments on the FSRE benchmark datasets demonstrate the superiority of our approach as compared to the state-of-the-art baselines. Further ablation studies on Zero-shot and None-of-the-above settings confirm its robustness and adaptability in practical applications.},
  archive      = {J_NN},
  author       = {Yanglei Gan and Qiao Liu and Run Lin and Tian Lan and Yuxiang Cai and Xueyi Liu and Changlin Li and Yan Liu},
  doi          = {10.1016/j.neunet.2025.107259},
  journal      = {Neural Networks},
  month        = {7},
  pages        = {107259},
  shortjournal = {Neural Netw.},
  title        = {Exploiting instance-label dynamics through reciprocal anchored contrastive learning for few-shot relation extraction},
  volume       = {187},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="orl---15">ORL - 15</h2>
<ul>
<li><details>
<summary>
(2025). Erratum to “cooperative equilibria of strategy-form games
with both nontransferable and transferable utilities” [oper. Res. Lett.
54 (2024) 107109]. <em>ORL</em>, <em>59</em>, 107254. (<a
href="https://doi.org/10.1016/j.orl.2025.107254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We correct an error in the statement of Theorem 3.2. Moreover, we correct some typos.},
  archive      = {J_ORL},
  author       = {Zhe Yang and Xinyu Yang},
  doi          = {10.1016/j.orl.2025.107254},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107254},
  shortjournal = {Oper. Res. Lett.},
  title        = {Erratum to “Cooperative equilibria of strategy-form games with both nontransferable and transferable utilities” [Oper. res. lett. 54 (2024) 107109]},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An option pricing model with double-exponential jumps in
returns and GARCH diffusion in volatilities. <em>ORL</em>, <em>59</em>,
107253. (<a href="https://doi.org/10.1016/j.orl.2025.107253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new stochastic volatility model with double-exponential jumps in returns and GARCH-type volatility diffusion for option pricing. Previously unexplored due to the lack of analytical option pricing formulas, we obtain closed-form expansions for European option prices under various volatility specifications and jump types, making model calibration feasible. Empirical studies show that this model outperforms alternatives.},
  archive      = {J_ORL},
  author       = {Chunhui Qiao and Xiangwei Wan and Nian Yang},
  doi          = {10.1016/j.orl.2025.107253},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107253},
  shortjournal = {Oper. Res. Lett.},
  title        = {An option pricing model with double-exponential jumps in returns and GARCH diffusion in volatilities},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The inverse optimal value problem for linear fractional
programming. <em>ORL</em>, <em>59</em>, 107251. (<a
href="https://doi.org/10.1016/j.orl.2025.107251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the inverse optimal value problem for linear fractional programming, where the goal is to find the coefficients of the fractional objective function such that the resulting optimal objective function value is as close as possible to some given target value. We show that this problem is NP -hard. Then, we provide some structural results, which are exploited to derive several reformulations and two solution algorithms. The proposed approaches are based on the Charnes-Cooper and parametric transformations.},
  archive      = {J_ORL},
  author       = {Sina Nadi and Taewoo Lee and Oleg A. Prokopyev},
  doi          = {10.1016/j.orl.2025.107251},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107251},
  shortjournal = {Oper. Res. Lett.},
  title        = {The inverse optimal value problem for linear fractional programming},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximation algorithms for the k+-star packing problem.
<em>ORL</em>, <em>59</em>, 107249. (<a
href="https://doi.org/10.1016/j.orl.2025.107249">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a target graph G and a set G of k + -stars, that is, stars with at least k satellites, a k + -star packing of G is a set of vertex-disjoint subgraphs of G with each isomorphic to some element of G . The k + -star packing problem is to find one such packing that covers as many vertices of G as possible. It is known to be NP-hard for any fixed k ≥ 2 , and has a simple 2-approximation algorithm when k = 2 . In this paper, we present an improved algorithm with a tight approximation ratio of 9/5 for k = 2 , and a k + 2 2 -approximation algorithm for general k ≥ 2 using the local search approach.},
  archive      = {J_ORL},
  author       = {Zhihua Huang and An Zhang and Mingqi Gao and Jiayi Sun and Yong Chen},
  doi          = {10.1016/j.orl.2025.107249},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107249},
  shortjournal = {Oper. Res. Lett.},
  title        = {Approximation algorithms for the k+-star packing problem},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the core of information sharing games. <em>ORL</em>,
<em>59</em>, 107247. (<a
href="https://doi.org/10.1016/j.orl.2025.107247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information sharing games deal with allocating payoffs created by information sharing among agents in the cooperative-game approach. In this study, we preset several properties of the core of those games, such as a necessary and sufficient condition for the singleton core and simple computation of an agent&#39;s maximum payoff in the core.},
  archive      = {J_ORL},
  author       = {Yasuo Sasaki},
  doi          = {10.1016/j.orl.2025.107247},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107247},
  shortjournal = {Oper. Res. Lett.},
  title        = {On the core of information sharing games},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On linear threshold policies for continuous-time dynamic
yield management. <em>ORL</em>, <em>59</em>, 107245. (<a
href="https://doi.org/10.1016/j.orl.2025.107245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the finite-horizon continuous-time dynamic yield management problem with stationary arrival rates and two customer types. We consider a class of linear threshold policies proposed by Hodge (2008) [5] , in which each less-profitable customer is accepted if and only if the remaining inventory exceeds a threshold that linearly decreases over the horizon. We use a Markov chain representation to show that such policies achieve uniformly bounded regret. We then generalize this result to analogous policies for arbitrarily many customer types.},
  archive      = {J_ORL},
  author       = {Dipayan Banerjee and Alan L. Erera and Alejandro Toriello},
  doi          = {10.1016/j.orl.2025.107245},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107245},
  shortjournal = {Oper. Res. Lett.},
  title        = {On linear threshold policies for continuous-time dynamic yield management},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smoothed analysis of the k-swap neighborhood for makespan
scheduling. <em>ORL</em>, <em>59</em>, 107244. (<a
href="https://doi.org/10.1016/j.orl.2025.107244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of scheduling a set of n jobs on m identical parallel machines with the objective of makespan minimization, by considering a local search neighborhood, called k -swap. In our previous study, we provided an exponential lower bound of 2 Ω ( n ) for k ≥ 3 . In this study, we show that the smoothed number of iterations in finding a local optimum with respect to the k -swap neighborhood is O ( m 2 ⋅ n 2 k + 2 ⋅ log ⁡ m ⋅ ϕ ) , where ϕ ≥ 1 is the perturbation parameter.},
  archive      = {J_ORL},
  author       = {Lars Rohwedder and Ashkan Safari and Tjark Vredeveld},
  doi          = {10.1016/j.orl.2025.107244},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107244},
  shortjournal = {Oper. Res. Lett.},
  title        = {Smoothed analysis of the k-swap neighborhood for makespan scheduling},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New facets of the clique partitioning polytope.
<em>ORL</em>, <em>59</em>, 107242. (<a
href="https://doi.org/10.1016/j.orl.2025.107242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clique partitioning problem is a combinatorial optimisation problem which has many applications. At present, the most promising exact algorithms are those that are based on an understanding of the associated polytope. We present two new families of valid inequalities for that polytope, and show that the inequalities define facets under certain conditions.},
  archive      = {J_ORL},
  author       = {Adam N. Letchford and Michael M. Sørensen},
  doi          = {10.1016/j.orl.2025.107242},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107242},
  shortjournal = {Oper. Res. Lett.},
  title        = {New facets of the clique partitioning polytope},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the capacity inequalities for the heterogeneous vehicle
routing problem. <em>ORL</em>, <em>59</em>, 107239. (<a
href="https://doi.org/10.1016/j.orl.2024.107239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fractional and Rounded capacity inequalities are two important families of valid inequalities known for the homogeneous Capacitated Vehicle Routing Problem (CVRP). Such inequalities impose the minimum number of vehicles required to service each and every subset of customers, be it a fractional or an integer value. In case of the Heterogeneous version of the routing problem (HCVRP), the minimum number of vehicles required for a subset of customers is not defined uniquely: it depends on the vehicle types and fleet composition that was engaged in serving the customers. This paper revises existing literature on the capacity-based valid inequalities for the HCVRP and presents new routines to separate them exactly using mixed integer linear programming (MILP). In addition, this paper proposes a new family of capacity-based valid inequalities for the HCVRP together with an exact routine to separate them. A computational study demonstrates applicability of considered inequalities in solving HCVRP instances using a standard MILP solver.},
  archive      = {J_ORL},
  author       = {Konstantin Pavlikov},
  doi          = {10.1016/j.orl.2024.107239},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107239},
  shortjournal = {Oper. Res. Lett.},
  title        = {On the capacity inequalities for the heterogeneous vehicle routing problem},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Assortment optimization under the multinomial logit choice
model with product-specific capacities. <em>ORL</em>, <em>59</em>,
107238. (<a href="https://doi.org/10.1016/j.orl.2024.107238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider assortment optimization with product-specific capacities under the multinomial logit (MNL) choice model, wherein each product has a finite capacity, i.e., a limited number of units for sale. The number of customers served by each product is the smaller of its demand and capacity. We assume the demand of each product is deterministic as a function of the assortment offered. We show that this assortment optimization problem is NP-hard. We devise a 1/2-approximation algorithm and a fully polynomial-time approximation scheme (FPTAS) by exploiting its connection to a series of knapsack problems.},
  archive      = {J_ORL},
  author       = {Woonghee Tim Huh and Siyue Liu},
  doi          = {10.1016/j.orl.2024.107238},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107238},
  shortjournal = {Oper. Res. Lett.},
  title        = {Assortment optimization under the multinomial logit choice model with product-specific capacities},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal arrangement of servers for a tollbooth tandem queue
with two heterogeneous servers. <em>ORL</em>, <em>59</em>, 107222. (<a
href="https://doi.org/10.1016/j.orl.2024.107222">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a tollbooth tandem queue with a Poisson arrival process and two heterogeneous servers of exponential service times. We show that performance measures, such as queue length, system size, waiting time and sojourn time, are stochastically larger when a server with a larger service rate is used as the first server. Our results include a rigorous proof of the observation made by He and Chao (2014) and Do (2015) regarding the performance comparison between two alternative server arrangements.},
  archive      = {J_ORL},
  author       = {Bara Kim and Jeongsim Kim},
  doi          = {10.1016/j.orl.2024.107222},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107222},
  shortjournal = {Oper. Res. Lett.},
  title        = {Optimal arrangement of servers for a tollbooth tandem queue with two heterogeneous servers},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An augmented lagrangian-type stochastic approximation method
for convex stochastic semidefinite programming defined by expectations.
<em>ORL</em>, <em>59</em>, 107221. (<a
href="https://doi.org/10.1016/j.orl.2024.107221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An augmented Lagrangian-type stochastic approximation method (ALSAssdp) is proposed to solve the convex stochastic semidefinite optimization problem defined by expectations and regrets of this method are analyzed. Under mild conditions, we show that this method exhibits O ( T − 1 / 2 ) regret for both objective reduction and constraint violation. Moreover, we show that, with at least 1 − 1 / T probability, the method has no more than O ( log ⁡ ( T ) / T ) for both objective regret and constraint violation regret.},
  archive      = {J_ORL},
  author       = {Yule Zhang and Jia Wu and Liwei Zhang},
  doi          = {10.1016/j.orl.2024.107221},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107221},
  shortjournal = {Oper. Res. Lett.},
  title        = {An augmented lagrangian-type stochastic approximation method for convex stochastic semidefinite programming defined by expectations},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal control of queues with demand-driven discharge.
<em>ORL</em>, <em>59</em>, 107220. (<a
href="https://doi.org/10.1016/j.orl.2024.107220">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider a Markovian queueing system with finite buffer space. Arriving customers belong to different classes and have class dependent service rates. At the time of an arrival, if the system is full, one of the existing customers has to be discharged prematurely, incurring a class dependent cost, whereas class dependent rewards are earned upon successful service completions. Our objective is to determine which customer class to discharge prematurely in order to maximize the long-run average profit.},
  archive      = {J_ORL},
  author       = {Guergana P. Ilieva and Hayriye Ayhan},
  doi          = {10.1016/j.orl.2024.107220},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107220},
  shortjournal = {Oper. Res. Lett.},
  title        = {Optimal control of queues with demand-driven discharge},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new sampling approach for bayesian sample size analysis in
applications of queueing models. <em>ORL</em>, <em>59</em>, 107219. (<a
href="https://doi.org/10.1016/j.orl.2024.107219">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In statistics, sample size determination (SSD) is of fundamental interest. In this paper, we focus on Bayesian sample size analysis, under the well-known ACC and WOC criteria, for queueing systems. Our study is based on a different method from the literature studies that is supported by the fact that observed data (sample or samples) from the population in applications can be significantly different from samples generated from the selected prior distribution.},
  archive      = {J_ORL},
  author       = {Dujuan Zhou},
  doi          = {10.1016/j.orl.2024.107219},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107219},
  shortjournal = {Oper. Res. Lett.},
  title        = {A new sampling approach for bayesian sample size analysis in applications of queueing models},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of the two-for-one swap heuristic for approximating
the maximum independent set in a k-polymatroid. <em>ORL</em>,
<em>59</em>, 107217. (<a
href="https://doi.org/10.1016/j.orl.2024.107217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let f : 2 N → Z + be a polymatroid (an integer-valued non-decreasing submodular set function with f ( ∅ ) = 0 ). A k -polymatroid satisfies that f ( e ) ≤ k for all e ∈ N . We call S ⊆ N independent if f ( S ) = ∑ e ∈ S f ( e ) and f ( e ) &gt; 0 for all e ∈ S . Such a set was also called a matching . Finding a maximum-size independent set in a 2-polymatroid has been studied and polynomial-time algorithms are known for linear polymatroids. For k ≥ 3 , the problem is NP-hard, and a ( ( 2 / k ) − ϵ ) -approximation is known and is obtained by swapping as long as possible a subset of up to ( 1 / ϵ ) log k − 1 ⁡ ( 2 k + 1 ) elements from the current solution by a set with one more element. Here we give a simple analysis of the more particular two-for-one repeated swapping heuristic, obtaining a tight (weaker) ( 2 / ( k + 1 ) ) -approximation.},
  archive      = {J_ORL},
  author       = {Adrian Calinescu and Gruia Călinescu},
  doi          = {10.1016/j.orl.2024.107217},
  journal      = {Operations Research Letters},
  month        = {3},
  pages        = {107217},
  shortjournal = {Oper. Res. Lett.},
  title        = {Analysis of the two-for-one swap heuristic for approximating the maximum independent set in a k-polymatroid},
  volume       = {59},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="parco---6">PARCO - 6</h2>
<ul>
<li><details>
<summary>
(2025). Estimating resource budgets to ensure autotuning efficiency.
<em>PARCO</em>, <em>123</em>, 103126. (<a
href="https://doi.org/10.1016/j.parco.2025.103126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many state-of-the-art HPC applications rely on autotuning to maintain peak performance. Autotuning allows a program to be re-optimized for new hardware, settings, or input — even during execution. However, the approach has an inherent problem that has yet to be properly addressed: since the autotuning process itself requires computational resources, it is also subject to optimization. In other words, while autotuning aims to decrease a program’s run time by improving its efficiency, it also introduces additional overhead that can extend the overall run time. To achieve optimal performance, both the application and the autotuning process should be optimized together, treating them as a single optimization criterion. This framing allows us to determine a reasonable tuning budget to avoid both undertuning, where insufficient autotuning leads to suboptimal performance, and overtuning, where excessive autotuning imposes overhead that outweighs the benefits of program optimization. In this paper, we explore the tuning budget optimization problem in detail, highlighting its interesting properties and implications, which have largely been overlooked in the literature. Additionally, we present several viable solutions for tuning budget optimization and evaluate their efficiency across a range of commonly used HPC kernels.},
  archive      = {J_PARCO},
  author       = {Jaroslav Olha and Jana Hozzová and Matej Antol and Jiří Filipovič},
  doi          = {10.1016/j.parco.2025.103126},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103126},
  shortjournal = {Parallel Comput.},
  title        = {Estimating resource budgets to ensure autotuning efficiency},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lowering entry barriers to developing custom simulators of
distributed applications and platforms with SimGrid. <em>PARCO</em>,
<em>123</em>, 103125. (<a
href="https://doi.org/10.1016/j.parco.2025.103125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers in parallel and distributed computing (PDC) often resort to simulation because experiments conducted using a simulator can be for arbitrary experimental scenarios, are less resource-, labor-, and time-consuming than their real-world counterparts, and are perfectly repeatable and observable. Many frameworks have been developed to ease the development of PDC simulators, and these frameworks provide different levels of accuracy, scalability, versatility, extensibility, and usability. The SimGrid framework has been used by many PDC researchers to produce a wide range of simulators for over two decades. Its popularity is due to a large emphasis placed on accuracy, scalability, and versatility, and is in spite of shortcomings in terms of extensibility and usability. Although SimGrid provides sensible simulation models for the common case, it was difficult for users to extend these models to meet domain-specific needs. Furthermore, SimGrid only provided relatively low-level simulation abstractions, making the implementation of a simulator of a complex system a labor-intensive undertaking. In this work we describe developments in the last decade that have contributed to vastly improving extensibility and usability, thus lowering or removing entry barriers for users to develop custom SimGrid simulators.},
  archive      = {J_PARCO},
  author       = {Henri Casanova and Arnaud Giersch and Arnaud Legrand and Martin Quinson and Frédéric Suter},
  doi          = {10.1016/j.parco.2025.103125},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103125},
  shortjournal = {Parallel Comput.},
  title        = {Lowering entry barriers to developing custom simulators of distributed applications and platforms with SimGrid},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable tasking runtime with parallelized builders for
explicit message passing architectures. <em>PARCO</em>, <em>123</em>,
103124. (<a href="https://doi.org/10.1016/j.parco.2024.103124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sequential task flow (STF) model introduces implicit data dependences to exploit task-based parallelism, simplifying programming but also introducing non-negligible runtime overhead. On emerging cache-less, explicit inter-core message passing (EMP) architectures, the long latency of memory access further amplifies the runtime overhead of the traditional STF model, resulting in unsatisfactory performance. This paper addresses two main components in the STF tasking runtime. We uncover abundant concurrency in the task dependence graph (TDG) building process through three sufficient conditions, put forward PBH, a parallelized TDG building algorithm with helpers which mixes pipeline parallelism and data parallelism to overcome the TDG building bottleneck for fine-grained tasks. We also introduce a centralized, lock-less task scheduler, EMP-C, based on the EMP interface, and propose three optimizations. These two techniques are implemented and evaluated on a product processor with EMP support, i.e. SW26010. Experimental results show that compared to traditional techniques, PBH achieves an average speedup of 1.55 for fine-grained task workloads, and the EMP-C scheduler brings speedups as high as 1.52 and 2.38 for fine-grained and coarse-grained task workloads, respectively. And the combination of these two techniques significantly improves the granularity scalability of the runtime, reducing the minimum effective task granularity (METG) to 0.1 ms and achieving an order of magnitude decrease in some cases.},
  archive      = {J_PARCO},
  author       = {Xiran Gao and Li Chen and Haoyu Wang and Huimin Cui and Xiaobing Feng},
  doi          = {10.1016/j.parco.2024.103124},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103124},
  shortjournal = {Parallel Comput.},
  title        = {Scalable tasking runtime with parallelized builders for explicit message passing architectures},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative methods in GPU-resident linear solvers for
nonlinear constrained optimization. <em>PARCO</em>, <em>123</em>,
103123. (<a href="https://doi.org/10.1016/j.parco.2024.103123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear solvers are major computational bottlenecks in a wide range of decision support and optimization computations. The challenges become even more pronounced on heterogeneous hardware, where traditional sparse numerical linear algebra methods are often inefficient. For example, methods for solving ill-conditioned linear systems have relied on conditional branching, which degrades performance on hardware accelerators such as graphical processing units (GPUs). To improve the efficiency of solving ill-conditioned systems, our computational strategy separates computations that are efficient on GPUs from those that need to run on traditional central processing units (CPUs). Our strategy maximizes the reuse of expensive CPU computations. Iterative methods, which thus far have not been broadly used for ill-conditioned linear systems, play an important role in our approach. In particular, we extend ideas from Arioli et al., (2007) to implement iterative refinement using inexact LU factors and flexible generalized minimal residual (FGMRES), with the aim of efficient performance on GPUs. We focus on solutions that are effective within broader application contexts, and discuss how early performance tests could be improved to be more predictive of the performance in a realistic environment.},
  archive      = {J_PARCO},
  author       = {Kasia Świrydowicz and Nicholson Koukpaizan and Maksudul Alam and Shaked Regev and Michael Saunders and Slaven Peleš},
  doi          = {10.1016/j.parco.2024.103123},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103123},
  shortjournal = {Parallel Comput.},
  title        = {Iterative methods in GPU-resident linear solvers for nonlinear constrained optimization},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards resilient and energy efficient scalable krylov
solvers. <em>PARCO</em>, <em>123</em>, 103122. (<a
href="https://doi.org/10.1016/j.parco.2024.103122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exascale computing must simultaneously address both energy efficiency and resilience as power limits impact scalability and faults are more common. Unfortunately, energy efficiency and resilience have been traditionally studied in isolation and optimizing one typically detrimentally impacts the other. To deliver the promised performance within the given power budget, exascale computing mandates a deep understanding of the interplay among energy efficiency, resilience, and scalability. In this work, we propose novel methods to analyze and optimize the costs of common resilience techniques including checkpoint-restart and forward recovery. We focus on sparse linear solvers as they are the fundamental kernels in many scientific applications. In particular, we present generalized analytical and experimental methods to analyze and quantify the time and energy costs of various recovery schemes on computer clusters, and develop and prototype performance optimization and power management strategies to improve energy efficiency. Moreover, we take a deep dive into the forward recovery that recently started to draw attention from researchers, and propose a practical matrix-aware optimization technique to reduce its recovery time. This work shows that while the time and energy costs of various resilience techniques are different, they share the common components and can be quantitatively evaluated with a generalized framework. This analysis framework can be used to guide the design of performance and energy optimization technologies. While each resilience technique has its advantages depending on the fault rate, system size, and power budget, the forward recovery can further benefit from matrix-aware optimizations for large-scale computing.},
  archive      = {J_PARCO},
  author       = {Zheng Miao and Jon C. Calhoun and Rong Ge},
  doi          = {10.1016/j.parco.2024.103122},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103122},
  shortjournal = {Parallel Comput.},
  title        = {Towards resilient and energy efficient scalable krylov solvers},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Seesaw: A 4096-bit vector processor for accelerating kyber
based on RISC-v ISA extensions. <em>PARCO</em>, <em>123</em>, 103121.
(<a href="https://doi.org/10.1016/j.parco.2024.103121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ML-KEM standard based on Kyber algorithm is one of the post-quantum cryptography (PQC) standards released by the National Institute of Standards and Technology (NIST) to withstand quantum attacks. To increase throughput and reduce the execution time that is limited by the high computational complexity of the Kyber algorithm, an RISC-V-based processor Seesaw is designed to accelerate the Kyber algorithm. The 32 specialized extension instructions are mainly designed to enhance the parallel computing ability of the processor and accelerate all the processes of the Kyber algorithm by thoroughly analyzing its characteristics. Subsequently, by carefully designing hardware such as poly vector registers and algorithm execution units on the RISC-V processor, the support of microarchitecture for extension instructions was achieved. Seesaw supports 4096-bit vector calculations through its poly vector registers and execution unit to meet high-throughput requirements and is implemented on the field-programmable gate array (FPGA). In addition, we modify the compiler simultaneously to adapt to the instruction extension and execution of Seesaw. Experimental results indicate that the processor achieves a speed-up of 432 × and 18864 × for hash and NTT, respectively, compared with that without extension instructions and a speed-up of 5.6 × for the execution of the Kyber algorithm compared with the advanced hardware design.},
  archive      = {J_PARCO},
  author       = {Xiaofeng Zou and Yuanxi Peng and Tuo Li and Lingjun Kong and Lu Zhang},
  doi          = {10.1016/j.parco.2024.103121},
  journal      = {Parallel Computing},
  month        = {3},
  pages        = {103121},
  shortjournal = {Parallel Comput.},
  title        = {Seesaw: A 4096-bit vector processor for accelerating kyber based on RISC-V ISA extensions},
  volume       = {123},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="pr---83">PR - 83</h2>
<ul>
<li><details>
<summary>
(2025). A feature pair-based neural network embedded decision tree
for synergistic drug combination prediction. <em>PR</em>, <em>164</em>,
111608. (<a href="https://doi.org/10.1016/j.patcog.2025.111608">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the realm of combination therapy, it&#39;s a vital step to evaluate the synergistic effects of anti-tumor drug pairs. However, most existing machine learning methods only focus on the attributes of individual drugs, overlooking the implicit relationships of drug pairs, which are essential for understanding their synergistic effects. To address this issue, this paper constructs a novel Neural network Embedded Decision Tree model (NEDT) under a novel paradigm of synergistic drug combination prediction, synonymous feature pairing for drug pairs . It matches synonymous features of drug pairs to construct molecular-level correlations, capturing the implicit relationships of drugs. Our work distinguishes itself from previous neural decision trees by introducing a bi-objective optimization strategy into the fine-tuning process. Experimental results validate that NEDT performs well in predicting synergistic drug combinations. Systematically interpretability analyses demonstrate that NEDT can yield valuable insights into drug synergy, confirming its potential in the biomedical field.},
  archive      = {J_PR},
  author       = {Jiayu Zou and Lianlian Wu and Kunhong Liu and Yong Xu and Song He and Xiaochen Bo},
  doi          = {10.1016/j.patcog.2025.111608},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111608},
  shortjournal = {Pattern Recognition},
  title        = {A feature pair-based neural network embedded decision tree for synergistic drug combination prediction},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor-based incomplete multiple kernel clustering with
auto-weighted late fusion alignment. <em>PR</em>, <em>164</em>, 111601.
(<a href="https://doi.org/10.1016/j.patcog.2025.111601">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, the rapid increase in data volume is accompanied by substantial missing data issues. Incomplete multiple kernel clustering (IMKC) investigates how to perform clustering when certain rows or columns of the predefined kernel matrix are missing. Among existing IMKC methods, the recent proposed late fusion IMKC (LF-IMKC) algorithm has garnered considerable attention due to its superior clustering accuracy and computational efficiency. However, existing LF-IMKC algorithms still suffer from several limitations. Firstly, we observe that in existing methods, the missing kernel imputation, kernel partition learning and subsequent late fusion processes are treated separately, which may lead to suboptimal solutions and adversely affect the clustering performance. Secondly, existing LF-IMKC algorithms treat each base partition equally, overlooking the differences in their contributions to the consistent clustering process. Thirdly, Existing algorithms typically overlook the higher-order correlations between the base partitions as well as the strong correlations between the base and consensus partitions, let alone leveraging these correlations for clustering. To address these issues, we propose a novel method, i.e., tensor-based incomplete multiple kernel clustering with auto-weighted late fusion alignment (TIKC-ALFA). Specifically, we first integrate the missing kernel imputation, base partition learning and subsequent late fusion processes within a unified framework. Secondly, we construct a third-order tensor using the weighted base partitions, offering an innovative perspective on tensor slices through the lens of weight distribution and then utilize the tensor nuclear norm (TNN) to approximate the true rank of the tensor. Furthermore, we incorporate the consensus partition into the tensor structure originally constructed solely from weighted base partitions to further investigate the strong correlations between the base partitions and the consensus partition. The experimental results on six commonly used datasets demonstrate the effectiveness of our algorithm.},
  archive      = {J_PR},
  author       = {Xiaoxing Guo and Gui-Fu Lu},
  doi          = {10.1016/j.patcog.2025.111601},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111601},
  shortjournal = {Pattern Recognition},
  title        = {Tensor-based incomplete multiple kernel clustering with auto-weighted late fusion alignment},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MPE: Multi-frame prediction error-based video anomaly
detection framework for robust anomaly inference. <em>PR</em>,
<em>164</em>, 111595. (<a
href="https://doi.org/10.1016/j.patcog.2025.111595">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As video surveillance has become increasingly widespread, the necessity of video anomaly detection to support surveillance-related tasks has grown significantly. We propose a novel multi-frame prediction error-based framework (MPE) to enhance anomaly detection accuracy and efficiency. MPE mitigates false positives in prediction models by leveraging multi-frame prediction errors and reduces the time required for their generation through a frame prediction error storage method. The core idea of MPE is to reduce the prediction error of a normal frame while increasing the prediction error of an abnormal frame by leveraging the prediction errors of adjacent frames. We evaluated our method on the Ped2, Avenue, and ShanghaiTech datasets. The experimental results demonstrate that MPE improved the frame-level area under the curve (AUC) of prediction models while maintaining low computational overhead across all datasets. These results show that MPE makes prediction models robust and efficient for video anomaly detection in real-world scenarios.},
  archive      = {J_PR},
  author       = {Yujun Kim and Young-Gab Kim},
  doi          = {10.1016/j.patcog.2025.111595},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111595},
  shortjournal = {Pattern Recognition},
  title        = {MPE: Multi-frame prediction error-based video anomaly detection framework for robust anomaly inference},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HaarFuse: A dual-branch infrared and visible light image
fusion network based on haar wavelet transform. <em>PR</em>,
<em>164</em>, 111594. (<a
href="https://doi.org/10.1016/j.patcog.2025.111594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared-visible image fusion remains challenging due to the inherent conflict between preserving multi-modal complementary features and minimizing reconstruction loss. Existing methods often suffer from inadequate feature representation and information degradation during fusion. To address this, we propose HaarFuse, a wavelet-enhanced auto-encoder network that hierarchically integrates multi-scale features for robust fusion. The network first employs wavelet transform to extend the receptive field of convolutional layers, extracting shared shallow features that encode both low-frequency structural contours and high-frequency texture primitives. Subsequently, the shallow features are decomposed into high-frequency and low-frequency components through Haar wavelet transform, and techniques such as INN, Gabor layer, and Transformer are adopted to further optimize and process these features. Finally, the fused image is reconstructed via the inverse wavelet transform. Experiments on TNO, MSRS, and M3FD benchmarks validate HaarFuse&#39;s superiority: it achieves the highest thermal saliency (SD=45.78, +5.5%↑ on MSRS; EN=6.98, +4.0%↑ on M3FD), optimal edge fidelity (Qabf=0.62, +1.6%↑ on M3FD), and 34.2 × faster inference than SwinFusion with 0.468 MB parameters. Further validation in machine vision and medical imaging confirms its robustness for real-time applications.},
  archive      = {J_PR},
  author       = {Yuequn Wang and Jie Liu and Jianli Wang and Leqiang Yang and Bo Dong and Zhengwei Li},
  doi          = {10.1016/j.patcog.2025.111594},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111594},
  shortjournal = {Pattern Recognition},
  title        = {HaarFuse: A dual-branch infrared and visible light image fusion network based on haar wavelet transform},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SyntaPulse: An unsupervised framework for sentiment
annotation and semantic topic extraction. <em>PR</em>, <em>164</em>,
111593. (<a href="https://doi.org/10.1016/j.patcog.2025.111593">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is a critical area within natural language processing, with applications in various domains like marketing, social media analytics, and politics. However, current methods encounter challenges in handling contextual ambiguities, accurately detecting sarcasm and irony, and effectively processing domain-specific vocabulary without extensive labeled datasets. Addressing these issues is essential, as the nuanced nature of language can lead to diverse interpretations across contexts, complicating reliable sentiment analysis. Furthermore, sarcasm and irony remain difficult to identify precisely, while reliance on labeled data and limitations in handling domain-specific vocabulary restrict adaptability across different fields. This paper presents SyntaPulse, a novel framework for sentiment classification in social networks, developed to overcome these challenges. The framework combines an innovative dictionary-based approach with Probabilistic Syntactic Latent Semantic Analysis (PSLSA) for semantic topic extraction. This integration enables it to handle homographs effectively, thereby enhancing sarcasm detection, facilitating the interpretation of domain-specific vocabulary, and reducing dependency on labeled data. Evaluated on 12 datasets, our framework demonstrates adaptability across various domains and achieves high Macro-F1 scores, ranging from 72.89 % to 96.22 %. SyntaPulse has also obtained improvements on seven datasets, with the lowest improvement rate being 0.21 % and the highest reaching 2.97 %.},
  archive      = {J_PR},
  author       = {Hadis Bashiri and Hassan Naderi},
  doi          = {10.1016/j.patcog.2025.111593},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111593},
  shortjournal = {Pattern Recognition},
  title        = {SyntaPulse: An unsupervised framework for sentiment annotation and semantic topic extraction},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transformer-driven feature fusion network and visual feature
coding for multi-label image classification. <em>PR</em>, <em>164</em>,
111584. (<a href="https://doi.org/10.1016/j.patcog.2025.111584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label image classification (MLIC) has attracted extensive research attention in recent years. Nevertheless, most of the existing methods have difficulty in effectively fusing multi-scale features and focusing on critical visual information, which makes it difficult to recognize objects from images. Besides, recent studies have utilized graph convolutional networks and attention mechanisms to model label dependencies in order to improve the model performance. However, these methods often rely on manually predefined label structures, which limits flexibility and model generality. And they also fail to capture intrinsic object correlations within images and spatial contexts. To address these challenges, we propose a novel Feature Fusion network combined with Transformer (FFTran) to fuse different visual features. Firstly, to address the difficulties of current methods in recognizing small objects, we propose a Multi-level Scale Information Integration Mechanism (MSIIM) that fuses different feature maps from the backbone network. Secondly, we develop an Intra-Image Spatial-Channel Semantic Mining (ISCM) module for learning important spaces and channel information. Thirdly, we design a Visual Feature Coding based on Transformer (VFCT) module to enhance the contextual information by pooling different visual features. Compared to the baseline model, FFTran achieves a significant boost in mean Average Precision (mAP) on both the VOC2007 and COCO2014 datasets, with enhancements of 2.9% and 5.1% respectively, highlighting its superior performance in multi-label image classification tasks.},
  archive      = {J_PR},
  author       = {Pingzhu Liu and Wenbin Qian and Jintao Huang and Yanqiang Tu and Yiu-Ming Cheung},
  doi          = {10.1016/j.patcog.2025.111584},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111584},
  shortjournal = {Pattern Recognition},
  title        = {Transformer-driven feature fusion network and visual feature coding for multi-label image classification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online signature verification based on the lagrange
formulation with 2D and 3D robotic models. <em>PR</em>, <em>164</em>,
111581. (<a href="https://doi.org/10.1016/j.patcog.2025.111581">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online Signature Verification commonly relies on function-based features, such as time-sampled horizontal and vertical coordinates, as well as the pressure exerted by the writer, obtained through a digitizer. Although inferring additional information about the writer’s arm pose, kinematics, and dynamics based on digitizer data can be useful, it constitutes a challenge. In this paper, we tackle this challenge by proposing a new set of features based on the dynamics of online signatures. These new features are inferred through a Lagrangian formulation, obtaining the sequences of generalized coordinates and torques for 2D and 3D robotic arm models. By combining kinematic and dynamic robotic features, our results demonstrate their significant effectiveness for online automatic signature verification and achieving state-of-the-art results when integrated into deep learning models.},
  archive      = {J_PR},
  author       = {Moises Diaz and Miguel A. Ferrer and Juan M. Gil and Rafael Rodriguez and Peirong Zhang and Lianwen Jin},
  doi          = {10.1016/j.patcog.2025.111581},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111581},
  shortjournal = {Pattern Recognition},
  title        = {Online signature verification based on the lagrange formulation with 2D and 3D robotic models},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LMFNet: Lightweight multimodal fusion network for
high-resolution remote sensing image segmentation. <em>PR</em>,
<em>164</em>, 111579. (<a
href="https://doi.org/10.1016/j.patcog.2025.111579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the rapid evolution of semantic segmentation for land cover classification in high-resolution remote sensing imagery, integrating multiple data modalities such as Digital Surface Model (DSM), RGB, and Near-infrared (NIR) remains a challenge. Current methods often process only two types of data, missing out on the rich information that additional modalities can provide. Addressing this gap, we propose a novel L ightweight M ultimodal data F usion Net work (LMFNet) to accomplish the tasks of fusion and semantic segmentation of multimodal remote sensing images. LMFNet uniquely accommodates various data types simultaneously, including RGB, NirRG, and DSM, through a weight-sharing, multi-branch vision transformer that minimizes parameter count while ensuring robust feature extraction. Our proposed multimodal fusion module integrates a Multimodal Feature Fusion Reconstruction Layer and Multimodal Feature Self-Attention Fusion Layer , which can reconstruct and fuse multimodal features. Our method achieves a mean Intersection over Union ( m I o U ) of 85.09% on the US3D dataset, marking a significant improvement over existing methods. We also studied the scalability of our method, directly extending the input modality to the SAR and hyperspectral fields. Our experimental results on the C2Seg dataset show that our method has generalization applicability to data of various modalities.},
  archive      = {J_PR},
  author       = {Tong Wang and Guanzhou Chen and Xiaodong Zhang and Chenxi Liu and Jiaqi Wang and Xiaoliang Tan and Wenlin Zhou and Chanjuan He},
  doi          = {10.1016/j.patcog.2025.111579},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111579},
  shortjournal = {Pattern Recognition},
  title        = {LMFNet: Lightweight multimodal fusion network for high-resolution remote sensing image segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SAPFormer: Shape-aware propagation transformer for point
clouds. <em>PR</em>, <em>164</em>, 111578. (<a
href="https://doi.org/10.1016/j.patcog.2025.111578">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformer-based networks have achieved impressive performance on three-dimensional point cloud data. However, most existing methods focus on aggregating local features in the neighborhoods of a point cloud, ignoring the global feature information. Therefore, it is difficult to capture the long-range dependencies of a point cloud. In this paper, we propose the Shape-Aware Propagation Transformer (SAPFormer) , which flexibly captures the semantic information of point clouds in geometric space and effectively extracts the contextual geometric space information. Specifically, we first design local group self-attention (LGA) to capture the local interaction information in each region. To capture the separated local region feature relationships, we propose local group propagation (LGP) to pass the information between different regions via query points. This allows features to propagate among neighbors for more fine-grained feature information. To further enlarge the receptive field, we propose the global shape feature module (GSFM) to learn global context information through key shape points (KSPs). Finally, to solve the positional information cues between global contexts, we introduce spatial-shape relative position encoding (SS-RPE), which obtains positional relationships between points. Extensive experiments demonstrate the effectiveness and superiority of our method on the S3DIS, SensatUrban, ScanNet V2, ShapeNetPart, and ModelNet40 datasets. The code is available at https://github.com/viivan/SAPFormer-main .},
  archive      = {J_PR},
  author       = {Gang Xiao and Sihan Ge and Yangsheng Zhong and Zhongcheng Xiao and Junfeng Song and Jiawei Lu},
  doi          = {10.1016/j.patcog.2025.111578},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111578},
  shortjournal = {Pattern Recognition},
  title        = {SAPFormer: Shape-aware propagation transformer for point clouds},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AFIFC: Adaptive fuzzy neighborhood mutual information-based
feature selection via label correlation. <em>PR</em>, <em>164</em>,
111577. (<a href="https://doi.org/10.1016/j.patcog.2025.111577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing feature selection schemes do not comprehensively consider correlation between features and labels and between labels, and certain neighborhood radius affects the prediction accuracy of multilabel classification. To solve these deficiencies, this paper develops an adaptive fuzzy neighborhood mutual information-based feature selection scheme via label correlation. Firstly, to study different distribution structures of multilabel data, the standard Euclidean distance as classification interval is employed to construct adaptive fuzzy neighborhood radius. Adaptive fuzzy neighborhood similarity relation and fuzzy neighborhood granule will be presented via difference between samples for features. Uncertainty measures via fuzzy neighborhood entropy can be developed. Secondly, to select features strongly associated with labels, adaptive fuzzy neighborhood mutual information measures this correlation between candidate features and labels, and the correlation between features and labels relative to those selected features is computed by mutual information. Then discriminant function of correlation is provided. Thirdly, to improve efficacy of multilabel classification, adaptive fuzzy neighborhood granules are employed to study the membership degree of labels. To assess the correlation between labels, Jaccard similarity and adaptive fuzzy neighborhood mutual information are combined, and to reflect this internal correlation between label and label set, the correlation ratio is studied. Finally, maximum relevance between the candidate features and labels and minimum redundancy between features are calculated, and then a new multilabel feature selection scheme is provided to acquire this best feature subset. Experiments on 12 datasets show the efficacy of this designed scheme in several evaluation metrics.},
  archive      = {J_PR},
  author       = {Lin Sun and Feng Xu and Weiping Ding and Jiucheng Xu},
  doi          = {10.1016/j.patcog.2025.111577},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111577},
  shortjournal = {Pattern Recognition},
  title        = {AFIFC: Adaptive fuzzy neighborhood mutual information-based feature selection via label correlation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent policy gradients with dynamic weighted value
decomposition. <em>PR</em>, <em>164</em>, 111576. (<a
href="https://doi.org/10.1016/j.patcog.2025.111576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-world multi-agent systems, multiple agents need to coordinate with other agents due to some limitations of observation and communication ability. Multi-agent policy gradient methods recently have witnessed vigorous progress in such challenging settings. However, multi-agent policy gradient methods have scalability and credit assignment issues due to the centralized critic. To solve these issues, a novel D ynamic Weighted QMI X Based M ulti-Agent Policy Gradients (DXM) is proposed in this paper, where the idea of dynamic weighted value decomposition is introduced into the framework of multi-agent actor-critic. Based on this idea, the proposed DXM approach has a more general decomposition on centralized critic than existing value decomposition methods, which address the scalability and credit assignment issue in both continuous and discrete action spaces. Briefly, in the presented DXM, deep deterministic policy gradient is employed to learn policies and a single centralized but factored critic, which can decompose the dynamic weighted nonlinear nonmonotonic summation of individual value functions. Empirical evaluations on the discrete action space environment StarCraft multi-agent challenge benchmark and the continuous action space environment continuous predator-prey benchmark show that the DXM approach successfully addresses the scalability and credit allocation issues. DXM significantly outperforms other baselines, with an average win rate improvement of &gt;15 %.},
  archive      = {J_PR},
  author       = {Shifei Ding and Xiaomin Dong and Jian Zhang and Lili Guo and Wei Du and Chenglong Zhang},
  doi          = {10.1016/j.patcog.2025.111576},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111576},
  shortjournal = {Pattern Recognition},
  title        = {Multi-agent policy gradients with dynamic weighted value decomposition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TLR-3DRN: Unsupervised single-view reconstruction via
tri-layer renderer. <em>PR</em>, <em>164</em>, 111568. (<a
href="https://doi.org/10.1016/j.patcog.2025.111568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-view three-dimensional (3D) reconstruction is a challenging task in computer vision, focusing on reconstructing 3D objects from a single image. Existing single-view object reconstruction approaches typically rely on viewpoints, silhouettes, multiple views of the same instance, and strategy-specific priors, which are difficult to obtain in the wild. To address this issue, we propose a novel end-to-end single-view reconstruction method based on a tri-layer renderer, named the Tri-Layer Renderer-based 3D Reconstruction Network (TLR-3DRN). TLR-3DRN recovers 3D structures from original image collections without requiring additional supervision, assumptions, or priors. In particular, TLR-3DRN employs a tri-layer renderer that enables the model to extract more 3D details from unprocessed image data. To obtain an optimizable interlayer, we developed a robust interlayer generation network based on a nonparametric memory bank. Notably, we designed a joint optimization strategy for the overall framework. Additionally, a shape and texture consistency loss based on image–text models is proposed to enhance the optimization process. Owing to the aforementioned proposed modules, TLR-3DRN can achieve high-quality, diverse-category reconstruction under completely unsupervised conditions. TLR-3DRN is validated on synthetic datasets and real-world datasets. Experimental results demonstrate that TLR-3DRN outperforms state-of-the-art unsupervised and two-dimensional supervised methods, achieving performance comparable to 3D supervised methods.},
  archive      = {J_PR},
  author       = {HaoYu Guo and Ying Li and Chunyan Deng},
  doi          = {10.1016/j.patcog.2025.111568},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111568},
  shortjournal = {Pattern Recognition},
  title        = {TLR-3DRN: Unsupervised single-view reconstruction via tri-layer renderer},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical multi-granular multi-label contrastive
learning. <em>PR</em>, <em>164</em>, 111567. (<a
href="https://doi.org/10.1016/j.patcog.2025.111567">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is a task wherein predictive models are developed to assign relevant label sets to unseen instances. Label correlation extraction and utilization have been widely implemented in multi-label classification methodologies. However, current multi-label contrastive learning algorithms inadequately incorporate label correlations into the feature space, thus limiting the learning of optimal feature representations for multi-label samples. To address this limitation, a novel hierarchical multi-granularity multi-label contrastive learning approach is proposed in this paper. The proposed method encompasses the construction of multi-label hierarchical correlations, label expansion based on hierarchical relationships, and representation learning through multi-granularity contrastive learning built upon these structures. Experimental results demonstrate the superiority of the proposed method over state-of-the-art techniques across widely used datasets.},
  archive      = {J_PR},
  author       = {Haixiang Li and Min Fang and Xiao Li and Bo Chen and Guizhi Wang},
  doi          = {10.1016/j.patcog.2025.111567},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111567},
  shortjournal = {Pattern Recognition},
  title        = {Hierarchical multi-granular multi-label contrastive learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robustifying vision transformer for image forgery
localization with multi-exit architectures. <em>PR</em>, <em>164</em>,
111565. (<a href="https://doi.org/10.1016/j.patcog.2025.111565">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of image manipulation tools has led to an increase in the number of manipulated images being disseminated online, posing risks like the propagation of fake news and telecom fraud. Thus, there is an increasing demand for precise, generic, and robust methods for detecting and locating manipulated images. In this paper, we propose a simple and clean model, named MEAFormer, for image forgery localization that does not heavily rely on pre-trained models. MEAFormer comprises three main components: an encoder network , a neck network , and a decoder network . Specifically, the transformer-based encoder network extracts hierarchical feature representations from the input image, providing rich contextual information in each layer. The neck network , incorporating our proposed cross-layer feature aggregation (CFA), aggregates these hierarchical features. To achieve better spatial feature co-occurrence, instead of using noise or edge artifacts, we introduce a multi-scale graph reasoning (MGR) module within the decoder network via bipartite graphs over the encoder and decoder features in a multi-scale fashion. The cross-level enhancement (CLE) further performs adjacent-level feature fusion to amplify the regions of interest in aggregated manipulation features. Finally, the multi-exit architecture (MEA) guides the model to learn fine-grained features and segment out the manipulated region. Extensive experiments across diverse and challenging datasets conclusively establish the superiority of MEAFormer over existing state-of-the-art methods, excelling in accuracy, generalization, and robustness.},
  archive      = {J_PR},
  author       = {Zenan Shi and Haipeng Chen and Dong Zhang},
  doi          = {10.1016/j.patcog.2025.111565},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111565},
  shortjournal = {Pattern Recognition},
  title        = {Robustifying vision transformer for image forgery localization with multi-exit architectures},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information bottleneck approach for feature selection.
<em>PR</em>, <em>164</em>, 111564. (<a
href="https://doi.org/10.1016/j.patcog.2025.111564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has been studied extensively over the last few decades. As a widely used method, the information-theoretic feature selection methods have attracted considerable attention due to their better interpretation and desirable performance. From an information-theoretic perspective, a golden rule for feature selection is to maximize the mutual information I ( X s , Y ) between the selected feature subset X s and the class labels Y . Despite its simplicity, explicitly optimizing this objective is a non-trivial task. In this work, we propose a novel global neural network-based feature selection framework with the information bottleneck principle and establish its connection to the rule of maximizing I ( X s , Y ) . Using the matrix-based Rényi’s α -order entropy functional, our framework enjoys a simple and tractable objective without any variational approximation or distributional assumption. We further extend the framework to multi-view scenarios and verify it with two large-scale, high-dimensional real-world biomedical applications. Comprehensive experimental results demonstrate the superior performance of our framework not only in terms of classification accuracy but also in terms of good interpretability within and across each view, effectively proving that the proposed framework is trustworthy. Code is available at https://github.com/archy666/IBFS .},
  archive      = {J_PR},
  author       = {Qi Zhang and Mingfei Lu and Shujian Yu and Jingmin Xin and Badong Chen},
  doi          = {10.1016/j.patcog.2025.111564},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111564},
  shortjournal = {Pattern Recognition},
  title        = {An information bottleneck approach for feature selection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient approach for finger vein verification to
solving the biometric recognition technique. <em>PR</em>, <em>164</em>,
111563. (<a href="https://doi.org/10.1016/j.patcog.2025.111563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vein authentication is a novel biometric method to authenticate a person&#39;s individuality. The conventional biometric technique employs shape images and exact segments of finger veins for the verification process. The proposed deep belief structure model aims to improve verification accuracy using a novel Anisotropic Filtered Stromberg Feature Transform based on Tucker&#39;s Congruence Deep Belief Structure Learning (AFSFT-TCDBSL) technique. The main aim of the AFSFT-TCDBSL technique is to improve verification accuracy and minimize time consumption. The proposed AFSFT-TCDBSL technique comprises one input layer, three hidden layers, and one output layer. The numbers of images are collected in the input layer, and the input images are pre-processed using anisotropic diffusion filtering in the first hidden layer. Then the pre-processed input images are sent to the next layer, where the feature extraction process is carried out using the Stromberg wavelet transform. Finally, the verification process is performed using Tucker&#39;s congruence correlation coefficient. Based on the correlation, the verification results are obtained at the output layer. In this way, accurate finger vein verification is performed with superior accuracy and with a minimum false rate. We performed experimental assessments with different factors, such as the Peak Signal-to-Noise Ratio (PSNR), Finger Vein Verification Accuracy (FVVA), False Positive Rate (FPR), Processing Time (PT), and Feature Extraction Time (FET). The results of the proposed ADFSFT-TCDBSL technique were conducted on 9% of improved peak signal-to-noise ratio and accuracy with a minimum 59% false positive rate and 16% time as well as 19% feature extraction time than the state-of-the-art FVV methods; therefore, it better facilitates the application of real-time finger vein verification.},
  archive      = {J_PR},
  author       = {Dharmalingam Muthusamy and Rakkimuthu Ponnusamy},
  doi          = {10.1016/j.patcog.2025.111563},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111563},
  shortjournal = {Pattern Recognition},
  title        = {An efficient approach for finger vein verification to solving the biometric recognition technique},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HMSFT: Hierarchical multi-scale spatial-frequency-temporal
collaborative transformer for 3D human pose estimation. <em>PR</em>,
<em>164</em>, 111562. (<a
href="https://doi.org/10.1016/j.patcog.2025.111562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstructing 3D poses from monocular video sequences faces formidable challenges due to noise-induced jitters and intricate joint dependencies. With this in mind, we propose the hierarchical multi-scale spatial-frequency-temporal collaborative transformer (HMSFT), which obtains robust multi-level joint relations by synergistically combining the complementary strengths of the spatial, frequency, and temporal domains. First, we utilize the spatial kinematics aware block to acquire geometric relationships across joints within the same frame. Subsequently, the adaptive frequency encoding block is presented to optimize the frequency representation of single poses and action sequences in response to distinctive feature attributes, thus alleviating the adverse impact of short-term and long-term jitters. Finally, through comprehensive temporal modeling across multiple scales, we explicitly capture the motion dependencies of the joint-level, part-level and body-level over time. Experimental validations on three benchmarks (Human 3.6M, HumanEva-I and MPI-INF-3DHP) show that the proposed HMSFT obtains significant improvements and excellent robust performance over several state-of-the-art techniques.},
  archive      = {J_PR},
  author       = {Hehao Zhang and Zhengping Hu and Shuai Bi and Jirui Di and Zhe Sun},
  doi          = {10.1016/j.patcog.2025.111562},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111562},
  shortjournal = {Pattern Recognition},
  title        = {HMSFT: Hierarchical multi-scale spatial-frequency-temporal collaborative transformer for 3D human pose estimation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-driven acoustic properties learning for underwater
target ranging. <em>PR</em>, <em>164</em>, 111560. (<a
href="https://doi.org/10.1016/j.patcog.2025.111560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater acoustic ranging (UAR) plays a crucial role in estimating object distances for ocean exploration. However, a reliable UAR method remains elusive, with current approaches either being reliant on inadequate hand-crafted features or neglecting the unique underwater acoustic properties. To address this, we propose Multi-attentional Underwater Acoustic Ranging (MUAR), a highly effective and robust UAR framework. MUAR incorporates multiple attention mechanisms tailored to the acoustic properties. Specifically, to better leverage the rich channel information in UAR data, we design a grouped channel attention module that can efficiently capture informative channels of the input data. Then, a feature-balancing strategy based on spatial-attention is introduced to mitigate information redundancy and conflicts, thereby enhancing the multi-level expressive capability of the model. We further theoretically analyze the connection between the self-attention mechanism and the acoustical signal correlations, such that achieving a better interpretation for the extracted features. Through extensive experiments and analysis on three authentic datasets, we show that MUAR outperforms previous approaches by obtaining state-of-the-art performance, i.e , achieving a MSE of 0.44 (vs. 2.72) and a MAPE of 0.97 (vs. 2.42). The source code of the proposed MUAR is released at https://github.com/TiernosChu/MUAR .},
  archive      = {J_PR},
  author       = {Xiaohui Chu and Hantao Zhou and Yan Zhang and Yachao Zhang and Runze Hu and Haoran Duan and Yawen Huang and Yefeng Zheng and Rongrong Ji},
  doi          = {10.1016/j.patcog.2025.111560},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111560},
  shortjournal = {Pattern Recognition},
  title        = {Attention-driven acoustic properties learning for underwater target ranging},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph augmentation guided federated knowledge distillation
for multisite functional MRI analysis. <em>PR</em>, <em>164</em>,
111559. (<a href="https://doi.org/10.1016/j.patcog.2025.111559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resting-state functional MRI (rs-fMRI) is a non-invasive tool increasingly used to detect abnormalities in brain connectivity for disorder analysis. Many learning models have been explored for fMRI analysis but usually require extensive data for reliable training. Multisite studies increase sample sizes by pooling data from multiple sites, but often face data security and privacy challenges. Federated learning (FL) facilitates collaborative model training without pooling fMRI data from different sites/clients. However, many FL methods share model parameters between clients, posing significant security risks during communication and greatly increasing communication costs. Besides, fMRI data for local model training is usually limited at each site, which may hinder local model training. To this end, we propose a graph augmentation guided federated distillation (GAFD) framework for multisite fMRI analysis and brain disorder identification. At each client, we augment each input functional connectivity network/graph derived from fMRI by perturbing node features and edges, followed by a feature encoder for graph representation learning. A contrastive loss is used to maximize the agreement of learned representations from the same subject, further enhancing discriminative power of fMRI representations. On the server side, the server receives model outputs ( i.e. , logit scores) corresponding to augmented graphs from each client and merges them. The merged logit score is then sent back to each client for knowledge distillation. This can promote knowledge sharing among clients, reduce the risk of privacy leakage, and greatly decrease communication costs. Experimental results on two multisite fMRI datasets indicate that our approach outperforms several state-of-the-arts.},
  archive      = {J_PR},
  author       = {Qianqian Wang and Junhao Zhang and Long Li and Lishan Qiao and Pew-Thian Yap and Mingxia Liu},
  doi          = {10.1016/j.patcog.2025.111559},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111559},
  shortjournal = {Pattern Recognition},
  title        = {Graph augmentation guided federated knowledge distillation for multisite functional MRI analysis},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spectral approximation of gaussian random graph laplacians
and applications to pattern recognition. <em>PR</em>, <em>164</em>,
111555. (<a href="https://doi.org/10.1016/j.patcog.2025.111555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spectral decomposition of Gaussian Random Graph Laplacian (GRGLs) is at the core of the solutions to many graph-based problems. Most prevalent are graph signal processing, graph matching, and graph learning problems. Proposed here is the Eigen Approximation Theorem (EAT), which states that the diagonal entries of a GRGL matrix are reliable empirical approximations of its eigenvalues, given certain general conditions. This theorem provides a more precise bound for eigenvalues in a subspace derived from the Courant–Fischer min–max theorem. Consequently, the k th eigenvalue and eigenvector of a GRGL can be computed efficiently using deflated power iteration. Simulation results demonstrate the accuracy and computational speed of the EAT application. Hence, it can solve problems involving GRGLs like graph signal processing, graph matching, and graph learning. The EAT can also be used directly when approximations to spectral decomposition suffice. The real-time applications are also demonstrated.},
  archive      = {J_PR},
  author       = {Rajeev Airani and Sachin Kamble},
  doi          = {10.1016/j.patcog.2025.111555},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111555},
  shortjournal = {Pattern Recognition},
  title        = {Spectral approximation of gaussian random graph laplacians and applications to pattern recognition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-light image enhancement via clustering contrastive
learning for visual recognition. <em>PR</em>, <em>164</em>, 111554. (<a
href="https://doi.org/10.1016/j.patcog.2025.111554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual recognition tasks of low-light images remain a big challenge. We propose an unsupervised low-light image enhancement module that can be integrated into any baseline visual model to enhance the performance. The proposed method is based on Clustering Contrastive Learning and Grad-CAM (Gradient-Class Activation Map) feature alignment, called CCGC. The CCGC method enhances the luminance semantic information of low-light images and remains the semantic feature information focusing. Simulation experimental results on various low-light image datasets demonstrate the significant feature enhancement and generalization capability of CCGC. Evaluation of the established CUB-2011 low-light image dataset shows a substantial increase in classification accuracy across multiple benchmark models. Furthermore, the proposed method significantly improves the classification accuracy on a real low-light traditional Chinese medicine dataset and enhances face detection performance on dark face detection datasets.},
  archive      = {J_PR},
  author       = {Guanglei Sheng and Gang Hu and Xiaofeng Wang and Wei Chen and Jinlin Jiang},
  doi          = {10.1016/j.patcog.2025.111554},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111554},
  shortjournal = {Pattern Recognition},
  title        = {Low-light image enhancement via clustering contrastive learning for visual recognition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contribution-based imbalanced hybrid resampling ensemble.
<em>PR</em>, <em>164</em>, 111553. (<a
href="https://doi.org/10.1016/j.patcog.2025.111553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resampling is an effective method for addressing data imbalance. Prevailing methods adjust the data distribution by either describing information or noise, and exhibit superiority in many scenarios. However, current studies face challenges in considering both information and noise simultaneously, as noisy samples usually have high information levels, potentially leading to misestimation. In this paper, a Contribution-Based Hybrid Resampling Ensemble (CHRE) is proposed to address the correlation problem between information and noise. CHRE is a semi-supervised algorithm based on a novel Global Unified Data Evaluation (GUDE) framework. Firstly, GUDE describes sample contribution by redefining the information and noise levels. Subsequently, based on sample contribution, CHRE removes negatively contributing majority samples, and oversamples minority samples Concurrently, pseudo-labels related to these minority samples are included in the oversampling. Throughout this process, CHRE resamples based on the sample contribution and optimizes the model. GUDE provides sample contribution based on the model feedback, with both interacting for iterative optimization. Extensive experiments are conducted on 53 benchmark datasets, involving three base classifiers and 13 state-of-the-art imbalance algorithms. The results demonstrate significant advantages of CHRE. Noise studies further indicate the high robustness of CHRE.},
  archive      = {J_PR},
  author       = {Lingyun Zhao and Fei Han and Qinghua Ling and Yubin Ge and Yuze Zhang and Qing Liu and Henry Han},
  doi          = {10.1016/j.patcog.2025.111553},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111553},
  shortjournal = {Pattern Recognition},
  title        = {Contribution-based imbalanced hybrid resampling ensemble},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-distribution-based ensemble sampler for imbalanced
semi-supervised learning. <em>PR</em>, <em>164</em>, 111552. (<a
href="https://doi.org/10.1016/j.patcog.2025.111552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning (SSL) on imbalanced data is largely under-explored and suffers from erroneous pseudo-labels, biased model training, or intolerable training costs. To alleviate these issues, we propose a meta-distribution-based ensemble sampler (MDSampler) approach 1 for imbalanced SSL. MDSampler is a unified framework that integrates SSL, imbalanced learning, and ensemble learning via iterative instance under-sampling and cascade classifier aggregation. Specifically, MDSampler considers the confidence-diversity distribution of both labeled and unlabeled samples and obtains the so-called meta-distribution via 2-D histogram discretization. Sampling on the meta-distribution (1) assigns pseudo-labels to unlabeled data for SSL, (2) alleviates class imbalance since the sampling process is unbiased, (3) improves the diversity of the ensemble learning framework, and (4) is highly efficient and flexible. Additionally, an adaptive instance interpolation strategy is presented to improve the quality of pseudo-labeled samples. Extensive experiments show that MDSampler can be organically combined with various classifiers to achieve superior performance in imbalanced SSL.},
  archive      = {J_PR},
  author       = {Zhihan Ning and Chaoxun Guo and David Zhang},
  doi          = {10.1016/j.patcog.2025.111552},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111552},
  shortjournal = {Pattern Recognition},
  title        = {Meta-distribution-based ensemble sampler for imbalanced semi-supervised learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anisotropic multiresolution analyses for deepfake detection.
<em>PR</em>, <em>164</em>, 111551. (<a
href="https://doi.org/10.1016/j.patcog.2025.111551">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Networks (GANs) can be misused to fabricate elaborate lies. The threat posed by GANs has sparked the need to discern between genuine and fabricated content. We argue that since GANs primarily utilize isotropic convolutions to generate their output, they leave clear traces, their fingerprint, in the coefficient distribution on sub-bands extracted by anisotropic multiresolution transforms. We employ the fully separable wavelet transform and anisotropic multiwavelets to obtain anisotropic features to feed to lightweight convolutional neural network classifiers. The proposed approach is capable of considerably improving the state-of-the-art in detecting fully GAN-generated images. It is particularly resilient to common perturbations, such as compression, noise or blur. We find that anisotropic transforms, when combined with XceptionNet, also significantly enhance the state-of-the-art in detecting partially manipulated images.},
  archive      = {J_PR},
  author       = {Wei Huang and Michelangelo Valsecchi and Michael Multerer},
  doi          = {10.1016/j.patcog.2025.111551},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111551},
  shortjournal = {Pattern Recognition},
  title        = {Anisotropic multiresolution analyses for deepfake detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Concept-guided domain generalization for semantic
segmentation. <em>PR</em>, <em>164</em>, 111550. (<a
href="https://doi.org/10.1016/j.patcog.2025.111550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent domain generalization semantic segmentation methods are proposed to use vision foundation models (VFMs) for achieving superior performance in unseen domains. However, unlike human vision, which naturally adapts to recognize objects in different contexts, VFMs still suffer from the distribution shift problem. Based on this, a concept-guided domain generalization (CDG) approach is proposed for semantic segmentation. First, considering that humans can recognize objects in various environments after humans learn the conception of objects, a concept token learning module is proposed to learn the semantic concept token from semantic prototypes, which aims to exploit domain-invariant instance-aware knowledge. Second, when the recognition of objects is uncertain, humans recognize the objects by contextual information. Thus, a concept-contextual calibration strategy is proposed to generate concept-contextual relations by the semantic concepts to calibrate uncertain regions for refining final predictions. Extensive experiments demonstrate that the proposed approach achieves superior performance on multiple benchmarks. The code is released on GitHub: https://github.com/seabearlmx/CDG .},
  archive      = {J_PR},
  author       = {Muxin Liao and Wei Li and Chengle Yin and Yuling Jin and Yingqiong Peng},
  doi          = {10.1016/j.patcog.2025.111550},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111550},
  shortjournal = {Pattern Recognition},
  title        = {Concept-guided domain generalization for semantic segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive spatial and scale label assignment for anchor-free
object detection. <em>PR</em>, <em>164</em>, 111549. (<a
href="https://doi.org/10.1016/j.patcog.2025.111549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, anchor-free object detection has attracted widespread attention due to its simplicity and efficiency. The mainstream anchor-free object detectors allocate positive/negative candidate samples through prior guidance at a fixed spatial position and assign positive/negative samples according to predefined scale constraints. However, artificially designing assignment strategies according to prior data distribution may hinder further optimization of label assignment. To this end, this paper proposes Adaptive Spatial and Scale Label Assignment (ASS-LA) to improve the performance of anchor-free object detection. Positive/negative samples are distributed from different pyramid levels using spatial and scale constraints. Specifically, an adaptive Intersection-over-Union (IoU) space assignment is designed to select candidate positive sample points. The membership degree is introduced at each pyramid level to adaptively fuzzy the scale assignment range so that the detector selects the final positive sample from the candidate sample points. Furthermore, a reference box is introduced to design the predicted IoU branch of coupled regression. In the inference stage, the predicted IoU and classification scores are combined as the confidence of the regression bounding box to alleviate the inconsistency between classification and regression. Extensive experiments show that our method achieves comparable performance to other existing label assignment schemes. With the introduction of ASS-LA, the anchor-free object detector has significant performance improvements without introducing other overhead.},
  archive      = {J_PR},
  author       = {Min Dang and Gang Liu and Chao Chen and Di Wang and Xike Li and Quan Wang},
  doi          = {10.1016/j.patcog.2025.111549},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111549},
  shortjournal = {Pattern Recognition},
  title        = {Adaptive spatial and scale label assignment for anchor-free object detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced seed selection for k-means clustering with
determinantal point process. <em>PR</em>, <em>164</em>, 111548. (<a
href="https://doi.org/10.1016/j.patcog.2025.111548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {K-means is one of the most popular and effective partitional clustering algorithms. However, in K-means, the initial seeds (centroids) play a critical role in determining the quality of the clusters. The existing methods address this problem either by factoring in the distance between the points on n-dimensional space so that the seeds are spaced apart or by choosing points from the dense regions to avoid the selection of outliers. We introduce a novel approach for seed selection that jointly models diversity as well as the quality of the seeds in a unified probabilistic framework based on a fixed-size determinantal point process. The quality indicator measures the reliability of the point to be considered as a potential seed, while the diversity measure factors in the spatial relation between the points on Euclidean space. The results show that the proposed algorithm outperforms the state-of-the-art models on several datasets.},
  archive      = {J_PR},
  author       = {Namita Bajpai and Jiaul H. Paik and Sudeshna Sarkar},
  doi          = {10.1016/j.patcog.2025.111548},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111548},
  shortjournal = {Pattern Recognition},
  title        = {Balanced seed selection for K-means clustering with determinantal point process},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DC-CLIP: Multilingual CLIP compression via vision-language
distillation and vision-language alignment. <em>PR</em>, <em>164</em>,
111547. (<a href="https://doi.org/10.1016/j.patcog.2025.111547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-trained vision-language (V-L) models such as CLIP have shown excellent performance in many downstream cross-modal tasks. However, most of them are only applicable to the English context. Subsequent research has focused on this problem and proposed improved models, such as CN-CLIP and AltCLIP, to facilitate their applicability to Chinese and even other languages. Nevertheless, these models suffer from high latency and a large memory footprint in inference, which limits their further deployment on resource-constrained edge devices. In this work, we propose a conceptually simple yet effective multilingual CLIP Compression framework and train a lightweight multilingual vision-language model, called DC-CLIP, for both Chinese and English contexts. In this framework, we collect a high-quality Chinese–English multi-source dataset and design two training stages, including multilingual vision-language feature distillation and alignment. During the first stage, lightweight image/text student models are designed to learn robust visual/multilingual textual feature representation ability from corresponding teacher models, respectively. Subsequently, the multilingual vision-language alignment stage enables effective alignment of visual and multilingual textual features to further improve the model’s multilingual performance. Comprehensive experiments in zero-shot image classification, conducted based on the ELEVATER benchmark, showcase that DC-CLIP achieves superior performance in the English context and competitive performance in the Chinese context, even with less training data, when compared to existing models of similar parameter magnitude. The evaluation demonstrates the effectiveness of our designed training mechanism.},
  archive      = {J_PR},
  author       = {Wenbo Zhang and Yifan Zhang and Jianfeng Lin and Binqiang Huang and Jinlu Zhang and Wenhao Yu},
  doi          = {10.1016/j.patcog.2025.111547},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111547},
  shortjournal = {Pattern Recognition},
  title        = {DC-CLIP: Multilingual CLIP compression via vision-language distillation and vision-language alignment},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural normalized cut: A differential and generalizable
approach for spectral clustering. <em>PR</em>, <em>164</em>, 111545. (<a
href="https://doi.org/10.1016/j.patcog.2025.111545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering, as a popular tool for data clustering, requires an eigen-decomposition step on a given affinity to obtain the spectral embedding. Nevertheless, such a step suffers from the lack of generalizability and scalability. Moreover, the obtained spectral embeddings can hardly provide a good approximation to the ground-truth partition and thus a k -means step is adopted to quantize the embedding. In this paper, we propose a simple yet effective scalable and generalizable approach, called Neural Normalized Cut (NeuNcut), to learn the clustering membership for spectral clustering directly. In NeuNcut, we properly reparameterize the unknown cluster membership via a neural network, and train the neural network via stochastic gradient descent with a properly relaxed normalized cut loss. As a result, our NeuNcut enjoys a desired generalization ability to directly infer clustering membership for out-of-sample unseen data and hence brings us an efficient way to handle clustering task with ultra large-scale data. We conduct extensive experiments on both synthetic data and benchmark datasets and experimental results validate the effectiveness and the superiority of our approach.},
  archive      = {J_PR},
  author       = {Wei He and Shangzhi Zhang and Chun-Guang Li and Xianbiao Qi and Rong Xiao and Jun Guo},
  doi          = {10.1016/j.patcog.2025.111545},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111545},
  shortjournal = {Pattern Recognition},
  title        = {Neural normalized cut: A differential and generalizable approach for spectral clustering},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient sampling-based gaussian processes for few-shot
semantic segmentation. <em>PR</em>, <em>164</em>, 111542. (<a
href="https://doi.org/10.1016/j.patcog.2025.111542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot segmentation (FSS) is a longstanding challenge in computer vision. Previous methods adopting Gaussian Processes (GPs) aggregate detailed information and manage complex distributions from small support sets, thereby modeling uncertainty of features and handling wide variations in context. However, the exact GP-based FSS methods struggle with computational burden and information redundancy. To tackle the issues, we propose ESGP, an Efficient Sampling-based Gaussian Process framework for few-shot segmentation. The model decouples the GP into a two-step process: weight space approximation for the prior and function space update for the posterior. Additionally, we adopt Deep Kernel Learning to enhance ESGP’s performance. This combination results in a faster, more accurate FSS model that effectively concentrates support sample information. Moreover, GP’s inherent ability to model uncertainty provides robust predictions and valuable insights into segmentation reliability. Experimental results demonstrate that ESGP outperforms previous GP-based methods and achieves competitive performance with state-of-the-art techniques.},
  archive      = {J_PR},
  author       = {Xin-Yi Zhang and Xian-Kai Lu and Yi-Long Yin and Han-Jia Ye and De-Chuan Zhan},
  doi          = {10.1016/j.patcog.2025.111542},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111542},
  shortjournal = {Pattern Recognition},
  title        = {Efficient sampling-based gaussian processes for few-shot semantic segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bijective inference network for interpretable
identification of RNA n6-methyladenosine modification sites.
<em>PR</em>, <em>164</em>, 111541. (<a
href="https://doi.org/10.1016/j.patcog.2025.111541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accurate identification of N 6 -methyladenosine (m 6 A) modification sites is crucial for unraveling various functional mechanisms. While existing methods primarily focus on learning high-quality embeddings of RNA sequences for this task, few of them consider incorporating specific RNA secondary structures, limiting their interpretability for in-depth post-transcriptional analysis. In this work, we introduce a novel bijective inference network, named m 6 A-BIN, which integrates RNA sequences and secondary structures within a unified parameter-shared framework, enhancing the accuracy of m 6 A modification site identification through the auxiliary supervision of RNA secondary structures. To begin with, m 6 A-BIN constructs sequential and structural graphs from RNA sequences and secondary structures, respectively. Bijective mapping functions are then specifically designed to couple the procedures of graph representation learning and interpretable dependency inference, providing informative supervision for learning sequential and structural embeddings of RNA. By fusing these two types of RNA embeddings, m 6 A-BIN efficiently performs the identification task. The attribution phase of m 6 A-BIN further ascribes the prediction results to nucleotide dependencies acquired during the interpretable dependency inference, including RNA sequence and structural patterns, thereby enhancing its interpretability. Extensive experimental results demonstrate the promising performance of m 6 A-BIN, showcasing its efficacy in terms of both accuracy and interpretability for the identification of novel m 6 A modification sites.},
  archive      = {J_PR},
  author       = {Guodong Li and Yue Yang and Dongxu Li and Xiaorui Su and Zhi Zeng and Pengwei Hu and Lun Hu},
  doi          = {10.1016/j.patcog.2025.111541},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111541},
  shortjournal = {Pattern Recognition},
  title        = {A bijective inference network for interpretable identification of RNA n6-methyladenosine modification sites},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic feature regularized loss for weakly supervised
semantic segmentation. <em>PR</em>, <em>164</em>, 111540. (<a
href="https://doi.org/10.1016/j.patcog.2025.111540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on confronting weakly supervised semantic segmentation with scribble-level annotation. The regularized loss has proven to be an effective solution for this task. However, most existing regularized losses only leverage static shallow features (color, spatial information) to compute the regularized kernel, which limits its final performance since such static shallow features fail to describe pair-wise pixel relationships in complicated cases. In this paper, we propose a new regularized loss that utilizes both shallow and deep features that are dynamically updated to aggregate sufficient information to represent the relationship of different pixels. Moreover, to provide accurate deep features, we design a feature consistency head to train the pair-wise feature relationship. In contrast to most approaches that adopt a multi-stage training strategy with complicated training settings and high time-consuming steps, our approach can be directly trained in an end-to-end manner, in which the feature consistency head and our regularized loss can benefit from each other. We evaluate our approach on different backbones, and extensive experiments show that our approach achieves new state-of-the-art performances on different cases, e.g. , using our approach with a vision transformer outperforms other approaches by a substantial margin (more than 5% mIoU increase). The source code will be released at: https://github.com/zbf1991/DFR .},
  archive      = {J_PR},
  author       = {Bingfeng Zhang and Jimin Xiao and Yao Zhao},
  doi          = {10.1016/j.patcog.2025.111540},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111540},
  shortjournal = {Pattern Recognition},
  title        = {Dynamic feature regularized loss for weakly supervised semantic segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interpretable 2.5D network by hierarchical attention and
consistency learning for 3D MRI classification. <em>PR</em>,
<em>164</em>, 111539. (<a
href="https://doi.org/10.1016/j.patcog.2025.111539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have been widely applied in diagnostic research on MRI data. Among the existing methods, attention-based multiple-instance learning, which not only provides classification results but also explains significant regions related to the task, has attracted considerable attention from scholars. However, prior methods might be restricted by these issues: (i) the loss of spatial or volume information, (ii) semantic inconsistency of attention weights, (iii) missing information exchange between attention mechanisms within different branches. To overcome these issues, we propose an innovative dual-branch attention-based deep multiple-instance learning framework, namely HA-CSL, which consists of a 2D branch and a 3D branch, a hierarchical attention (HA) module and a consistency learning (CSL) module. Specifically, the 2D and 3D branches employ the 2D and 3D convolutional neural networks to extract 2D and 3D patch-level features, respectively, so as to learn more richer image information. Additionally, the HA module comprises slice-, region- and channel-level attentions to interpret the significance of slices, regions and channels, respectively. Moreover, the CSL module is to enhance the consistency of attention weights obtained by the two branches, so as to reduce the semantic gap of attentions and promote better information exchange of two branches. Experiments on two 3D MRI image datasets demonstrate the superior classification and interpretation performance of the proposed framework over recent state-of-the-art methods. The source codes are available at https://github.com/shuting-pang/HA_CSL .},
  archive      = {J_PR},
  author       = {Shuting Pang and Yidi Chen and Xiaoshuang Shi and Rui Wang and Mingzhe Dai and Xiaofeng Zhu and Bin Song and Kang Li},
  doi          = {10.1016/j.patcog.2025.111539},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111539},
  shortjournal = {Pattern Recognition},
  title        = {Interpretable 2.5D network by hierarchical attention and consistency learning for 3D MRI classification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-randomized focuses effectively boost metric-based
few-shot classifiers. <em>PR</em>, <em>164</em>, 111538. (<a
href="https://doi.org/10.1016/j.patcog.2025.111538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Towards solving a few-shot image classification task, deep metric learning is the de-facto approach. Usually the idea here is to train a deep metric model on base data, and evaluate it using novel data without any fine-tuning. Enhancing model performance is mostly focused upon improving feature or class representations, or designing or learning new metrics, often ignoring deep exploration of data-augmentation techniques to enhance few-shot learning. Interestingly, we discover that augmentation strategies, such as Cutout, Mixup and CutMix, would in fact greatly enhance performance of few-shot models. We conjecture, this is because such augmentation techniques encourage the model to extend its focus on multiple discriminative regions of an object instead of restricting to just the single-most discriminative point. Following this important discovery, we propose two simple yet effective novel data augmentation methods, viz. CutRot and CutCov, specifically designed to self-randomize focuses within an image itself for metric-based few-shot image classification. While CutRot involves random rotation of any patch within the image, CutCov focuses on random swapping of patches, again within the image. Extensive experiments verify that CutRot or CutCov can significantly boost performances of both classic and recent popular metric-based methods and performs much better than other augmentation methods of Cutout, Mixup, and CutMix on four few-shot image classification datasets. Code is available at https://github.com/liz-lut/CutRot-and-CutCov-main .},
  archive      = {J_PR},
  author       = {Zhen Li and Zhongyuan Liu and Dongliang Chang and Aneeshan Sain and Xiaoxu Li and Zhanyu Ma and Jing-Hao Xue and Yi-Zhe Song},
  doi          = {10.1016/j.patcog.2025.111538},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111538},
  shortjournal = {Pattern Recognition},
  title        = {Self-randomized focuses effectively boost metric-based few-shot classifiers},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bridging domain spaces for unsupervised domain adaptation.
<em>PR</em>, <em>164</em>, 111537. (<a
href="https://doi.org/10.1016/j.patcog.2025.111537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) aims to transfer knowledge obtained from a labeled source domain to an unlabeled target domain, facing challenges due to domain shift—significant discrepancies in data distribution that impair model performance when applied to unseen domains. While recent approaches have achieved remarkable progress in mitigating these domain shifts, the focus remains on direct adaptation strategies from source to target domains. However, when the gap between the source and target domains is too substantial, directly aligning their distributions becomes increasingly difficult. Pseudo-labeling, a common strategy in direct adaptation, can further exacerbate this issue when the domain shift is severe. In such cases, incorrect pseudo-labels are likely to propagate through the adaptation process, leading to degraded performance and unstable training. Effective adaptation thus requires methods that can address these challenges by improving the reliability of pseudo-labels or reducing dependency on them. To address this challenge, we propose a novel approach that effectively alleviates domain shift by leveraging intermediate domains as bridges between the source and target domains. Specifically, we introduce a fixed ratio-based mixup to generate distinct intermediate domains between the source and target domains. By training on these augmented domains, we construct source-dominant and target-dominant models that possess distinct strengths and weaknesses, enabling us to implement effective complementary learning strategies. Furthermore, we enhance our fixed ratio-based mixup with uncertainty-aware learning, which addresses not only the image-level space but also the feature space, aiming to reduce the uncertainty at the most critical points within these spaces. Finally, we integrate confidence-based learning strategies, including bidirectional matching with high-confidence predictions and self-penalization with low-confidence predictions. Our extensive experiments on seven public benchmarks, including both single-source and multi-source scenarios, demonstrate the effectiveness of our method in UDA tasks.},
  archive      = {J_PR},
  author       = {Jaemin Na and Heechul Jung and Hyung Jin Chang and Wonjun Hwang},
  doi          = {10.1016/j.patcog.2025.111537},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111537},
  shortjournal = {Pattern Recognition},
  title        = {Bridging domain spaces for unsupervised domain adaptation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADGaze: Anisotropic gaussian label distribution learning for
fine-grained gaze estimation. <em>PR</em>, <em>164</em>, 111536. (<a
href="https://doi.org/10.1016/j.patcog.2025.111536">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaze estimation technology is crucial for enhancing the effectiveness and safety of applications in human–computer interaction, intelligent driving, virtual reality, and medical diagnosis. With advancements in deep learning, gaze estimation methods using deep neural networks have been extensively researched and applied. However, existing methods have yet to address the anisotropic characteristics of eye features. Based on the discovered anisotropic characteristics, we propose an Anisotropic Gaussian Label Distribution Learning Network for Gaze Estimation (ADGaze). ADGaze is capable of catching neighboring information by taking advantage of coarse-to-fine methodology and the anisotropic soft label construct. The coarse-to-fine framework initially performs classification tasks for gaze estimation, grouping gaze images with small variations into the same category, followed by regression tasks for each category. The construction of anisotropic Gaussian label distributions adopts methods based on data statistics and feature similarity. Extensive experimentation on public datasets has been carried out to substantiate the efficacy of this model. Our code is publicly available at https://github.com/dacilab/ADGaze .},
  archive      = {J_PR},
  author       = {Duantengchuan Li and Shutong Wang and Wanli Zhao and Lingyun Kang and Liangshan Dong and Jiazhang Wang and Xiaoguang Wang},
  doi          = {10.1016/j.patcog.2025.111536},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111536},
  shortjournal = {Pattern Recognition},
  title        = {ADGaze: Anisotropic gaussian label distribution learning for fine-grained gaze estimation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HIAN: A hybrid interactive attention network for multimodal
sarcasm detection. <em>PR</em>, <em>164</em>, 111535. (<a
href="https://doi.org/10.1016/j.patcog.2025.111535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sarcasm detection aims to use various modalities of data, such as text, images, etc., to identify whether they contain sarcastic meanings. Both images and texts contain rich sarcastic clues, but there are differences in dimension between them, and the quality of the sarcastic information they contain is very different. Therefore, seeking an appropriate feature fusion strategy to align modal features to maximize the utilization of inconsistent relationships between modalities is a significant challenge in this task. To this end, we introduce a novel sarcasm detection fusion model based on multimodal hybrid interactive attention (HIAN). We concatenate class words obtained from images with text and use the proposed bidirectional long short-term memory network with an interactive attention layer to enhance the extraction of text features. The text features obtained in this way can fully capture the contextual information of the text and the supplementary information in the image. To further enhance the feature fusion between modalities, we propose a multimodal interactive attention network and a fusion-enhanced transformer to promote the sharing of high-order complementary information, which represents the complementary non-linear semantic relationship between the three modalities and captures more inconsistencies between modalities. Extensive experiments conducted on publicly available multimodal sarcasm detection benchmark datasets show that our results surpass those of the baseline model and current state-of-the-art methods for the case of using the base BERT model.},
  archive      = {J_PR},
  author       = {Yongtang Bao and Xin Zhao and Peng Zhang and Yue Qi and Haojie Li},
  doi          = {10.1016/j.patcog.2025.111535},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111535},
  shortjournal = {Pattern Recognition},
  title        = {HIAN: A hybrid interactive attention network for multimodal sarcasm detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Behavior capture guided engagement recognition. <em>PR</em>,
<em>164</em>, 111534. (<a
href="https://doi.org/10.1016/j.patcog.2025.111534">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Engagement recognition aims to assess an individual’s involvement in various activities, which is essential in fields like education, healthcare, and driving. However, existing methods often suffer from performance degradation due to excessive data and distractions. In this paper, we introduce a novel model, the Behavior Capture-guided Transformer (BCTR). One of its key innovations lies in the proposed architecture for extracting regional features. Specifically, BCTR employs three independent class tokens to capture regional features – ocular, head, and trunk – from image sequences. These features are then used to model the dynamic streams of these regions for video-based engagement recognition. Another unique innovation of BCTR is its ability to mimic the observational techniques used by human teachers. By leveraging both frame-level and video-level class tokens, the model uses dual branches to detect both static and dynamic disengagement behaviors. This approach not only enables BCTR to achieve superior performance – 64.51% accuracy on the DAiSEE dataset and 0.0602 MSE loss on the EmotiW-EP dataset – but also enhances the interpretability of engagement levels by identifying these disengagements.},
  archive      = {J_PR},
  author       = {Yijun Bei and Songyuan Guo and Kewei Gao and Zunlei Feng},
  doi          = {10.1016/j.patcog.2025.111534},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111534},
  shortjournal = {Pattern Recognition},
  title        = {Behavior capture guided engagement recognition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REHair: Efficient hairstyle transfer robust to face
misalignment. <em>PR</em>, <em>164</em>, 111533. (<a
href="https://doi.org/10.1016/j.patcog.2025.111533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hairstyle transfer is challenging due to intricate nature of hairstyles. In particular, face misalignment leads to distortion or deformation of the transferred hairstyle. To address this issue, we propose a Robust and Efficient Hairstyle transfer (REHair) framework, which comprises three stages: adaptive angle alignment, adaptive depth alignment, and efficient hairstyle editing. Firstly, we perform head pose estimation and adjust the facial rotation angle based on the latent code, thus ensuring consistent facial orientation between the face image and the hairstyle reference image and preventing hair shape and texture loss from iterative optimization methods. Secondly, we employ monocular depth estimation to predict the face depth of both images and perform adaptive depth alignment, ensuring the preservation of more hairstyle details. Finally, we propose a fast image embedding algorithm and integrate it with the latent code, significantly reducing the image embedding time in StyleGAN2. This adaptation enables REHair to be suitable for real-time applications. Quantitative and qualitative evaluations on the FFHQ and CelebA-HQ dataset demonstrate that REHair achieves state-of-the-art performance by successfully transferring hairstyles between images with different poses. The proposed method significantly reduces image embedding time while preserving image quality, and effectively addresses challenges associated with sub-optimal photography conditions and slow generation speed. Source code avaliable at https://github.com/fdwxfy/REHair .},
  archive      = {J_PR},
  author       = {Yiwen Xu and Liping Ling and Qingxu Lin and Ying Fang and Tiesong Zhao},
  doi          = {10.1016/j.patcog.2025.111533},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111533},
  shortjournal = {Pattern Recognition},
  title        = {REHair: Efficient hairstyle transfer robust to face misalignment},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EACE: Explain anomaly via counterfactual explanations.
<em>PR</em>, <em>164</em>, 111532. (<a
href="https://doi.org/10.1016/j.patcog.2025.111532">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection aims to identify data points that deviate from the prevailing data distribution. Despite numerous anomaly detection models, there is a prevailing oversight in their interpretability, specifically regarding the rationale behind classifying a specific data point as an anomaly. Therefore, Interpretable Machine Learning has become a current research hotspot and is crucial for users to trust models. As one of the representative models, Counterfactual Explanation (CFE) methods generate alternative scenarios different from the observed data to explain model decisions. CFE tries to answer how the model’s output would change if certain factors (features) were altered. However, most existing CFE methods are designed for classification tasks, and it is a challenge for them to transform anomalies into counterfactual explanation samples effectively. To overcome this limitation, we propose a novel method for Explaining Anomaly via Counterfactual Explanation named EACE. Specifically, based on existing CFE methods’ limitations in handling anomalies, we propose a novel optimization objective by incorporating density loss and boundary loss. Meanwhile, we improved the genetic algorithm to solve this optimization problem since the new loss function is not differentiable. To evaluate the quality of the generated counterfactual explanations, we compare comprehensively with state-of-the-art counterfactual explanation methods and feature importance-based explanation methods. Experimental results demonstrate that EACE has a notable ability to convert anomalies into counterfactual explanation samples that are highly aligned with the normal cluster.},
  archive      = {J_PR},
  author       = {Peng Zhou and Qihui Tong and Shiji Chen and Yunyun Zhang and Xindong Wu},
  doi          = {10.1016/j.patcog.2025.111532},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111532},
  shortjournal = {Pattern Recognition},
  title        = {EACE: Explain anomaly via counterfactual explanations},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Meta-learning of pseudo force field generation and
estimation for enhancing 3D molecular property prediction. <em>PR</em>,
<em>164</em>, 111531. (<a
href="https://doi.org/10.1016/j.patcog.2025.111531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning Energy-based Model via 3D molecular denoising has been shown to be effective in pretraining the 3D molecular representation. However, existing works carry out denoising in task-agnostic manner, causing inevitable domain gap with the downstream tasks. To overcome this issue, we introduce a task-aware pretraining framework, dubbed Mol-MFFGE, for adapting the energy-based pretraining to downstream tasks in meta-learning approach. In this framework, we design learnable pretraining tasks as generating and estimating pseudo force fields. This is achieved by proposing a learnable noise transformation module to generate the noisy motions of atoms and the model is pretrained to estimate them. These tasks are taken as the auxiliary self-supervised training tasks and learned with the downstream task jointly, formulated as a bi-level meta-learning optimization problem. Based on such an approach, the force field generation and estimation tasks are meta-learned to enhance the downstream tasks for molecular property prediction. Extensive experiments are conducted on three molecular property prediction datasets, and results demonstrate performance improvement over the state-of-the-art 3D molecular pretrained models.},
  archive      = {J_PR},
  author       = {Yufei Luo and Heran Yang and Jian Sun},
  doi          = {10.1016/j.patcog.2025.111531},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111531},
  shortjournal = {Pattern Recognition},
  title        = {Meta-learning of pseudo force field generation and estimation for enhancing 3D molecular property prediction},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive domain adaptation with test-time training for
out-of-context news detection. <em>PR</em>, <em>164</em>, 111530. (<a
href="https://doi.org/10.1016/j.patcog.2025.111530">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Out-of-context news is a common type of misinformation on online media platforms. This involves posting a caption, alongside a mismatched news image. Reflecting its importance, researchers have developed models to detect such misinformation. However, a common limitation of these models is that they only consider the scenario where pre-labelled data is available for each news topic or agency, failing to address the out-of-context news detection on unverified news of other topics or agencies. In this work, we therefore focus on domain adaptive out-of-context news detection. We regard news topic or news agency as the domain . In order to effectively adapt the detection model to unlabelled news topics or agencies, we propose Con trastive D omain A daptation with T est- T ime T raining (ConDA-TTT). It first applies contrastive learning to learn a more separable representation space for news inputs, and then uses maximum mean discrepancy (MMD) to remove the domain-specific features so as to keep the domain-invariant features. During test time, it uses the trained model to predict pseudo labels for the target domain test data, and selects those with higher confidence scores to train the classifier of the model, in order to further adapt the model to the target domain data distribution. This approach adapts the model at both training and test phase, making the domain adaptation more robust to distribution shifts. Experimental results demonstrate that our approach outperforms state-of-the-art baselines in all the domain adaptation settings on two benchmark datasets, by as much as 2.6% in F1 and 2.4% in accuracy.},
  archive      = {J_PR},
  author       = {Yimeng Gu and Mengqi Zhang and Ignacio Castro and Shu Wu and Gareth Tyson},
  doi          = {10.1016/j.patcog.2025.111530},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111530},
  shortjournal = {Pattern Recognition},
  title        = {Contrastive domain adaptation with test-time training for out-of-context news detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Zero-shot sketch-based image retrieval with teacher-guided
and student-centered cross-modal bidirectional knowledge distillation.
<em>PR</em>, <em>164</em>, 111529. (<a
href="https://doi.org/10.1016/j.patcog.2025.111529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of zero-shot learning, the task of using unseen-class sketches as queries to retrieve real images is referred to as Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR). The ZS-SBIR task aims to generalize knowledge learned from known categories to unknown ones. Current research primarily relies on fine-tuning networks via loss functions or by unidirectionally extracting knowledge from fixed-parameter teacher models for training student models. However, unidirectional knowledge extraction from teacher models often lacks mutual learning and knowledge alignment between the teacher and student models, while fine-tuning networks via loss functions struggles to handle both photo and sketch modalities simultaneously. Therefore, we designed a modal perception and distribution alignment scheme based on gradient weighting to explore both photo and sketch features bidirectionally and deeply investigate the relationships between different modalities. Building on this, we propose a teacher-guided and student-centered cross-modal bidirectional knowledge distillation framework. During training, the student and teacher models mutually learn discriminative information based on the relationships between different modalities and synchronize their parameters guided by the teacher model, thus effectively achieving cross-modal alignment. Extensive experiments conducted on the TU-Berlin Ext, Sketchy Ext and QuickDraw Ext datasets demonstrate that our method significantly enhances retrieval performance.},
  archive      = {J_PR},
  author       = {Jiale Du and Yang Liu and Xinbo Gao and Jungong Han and Lei Zhang},
  doi          = {10.1016/j.patcog.2025.111529},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111529},
  shortjournal = {Pattern Recognition},
  title        = {Zero-shot sketch-based image retrieval with teacher-guided and student-centered cross-modal bidirectional knowledge distillation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging facial landmarks improves generalization ability
for deepfake detection. <em>PR</em>, <em>164</em>, 111528. (<a
href="https://doi.org/10.1016/j.patcog.2025.111528">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, facial forgery technology has become increasingly sophisticated and published datasets aim to cover a wide range of data variations. Existing deepfake detection models have benefited from the powerful feature embedding of deep networks and carefully designed fine-tuning modules, resulting in an excellent performance on in-dataset evaluations. However, the performance declines in cross-dataset evaluations due to various forgery methods and dataset shifts. In this study, we concentrate on the generalization issue of deepfake detection and find that forgery traces appear to gather around the facial interest points even manipulated by different forgery methods. To facilitate this, we propose a Trail Tracing Network (TTNet) to capture the generalized feature representation, which leverages facial landmarks to eliminate redundant information and expand the forged traces in the feature space. We conduct extensive experiments on the widely employed benchmarks, including FaceForensics++, DFDCp, and Celeb-DF. Experimental results demonstrate the outstanding generalization ability of our method against existing state-of-the-art methods by a large margin. In addition, the proposed method also exhibits excellent performance on the in-dataset evaluation.},
  archive      = {J_PR},
  author       = {Qi Gao and Baopeng Zhang and Jianghao Wu and Wenxin Luo and Zhu Teng and Jianping Fan},
  doi          = {10.1016/j.patcog.2025.111528},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111528},
  shortjournal = {Pattern Recognition},
  title        = {Leveraging facial landmarks improves generalization ability for deepfake detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSTKD: Triple-spike train kernel-driven supervised learning
algorithm. <em>PR</em>, <em>164</em>, 111525. (<a
href="https://doi.org/10.1016/j.patcog.2025.111525">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise artificial intelligence is one of the most promising research fields, where supervised learning for spiking neurons (SNs) plays an imperative and fundamental role. This study proposes a novel supervised learning algorithm based on triple-spike train kernels to address the shortcomings of the latest learning algorithms, such as local best learning and low learning accuracy. First, we divided the time intervals of the spike trains, including the firing time of the input spikes. Subsequently, we discovered and analyzed the relationship between the firing times of all spikes, added a third spike to solve the existing problem, and constructed a triple-spike-driven (TSD) minimum direct computational unit. In addition to the simple and efficient adjustment of synaptic weights based on pair-spike, TSD maintains a relationship between all useful spikes to approximate the global best learning. Finally, we proposed a triple-spike train kernel driven (TSTKD) supervised learning algorithm to improve the learning performance. Many fundamental experiments were implemented to demonstrate the learning performance, which proved that the successful learning ability and some learning factors of our proposed algorithm in spike train learning. We then verified the positive effect of the TSD on the proposed algorithm. Many experiments also proved the much higher learning accuracy of the proposed state-of-the-art algorithm compared to some of the latest algorithms, especially in the complex spike train learning. In addition, the proposed algorithm is more adaptive to SNs and much better at generalizing, memorizing, and classifying than the corresponding algorithm with pair-spike and some of the latest algorithms. Considering the above experimental results, our study blazes a trail for pattern recognition using spike train supervised learning with global optimization.},
  archive      = {J_PR},
  author       = {Guojun Chen and Guoen Wang},
  doi          = {10.1016/j.patcog.2025.111525},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111525},
  shortjournal = {Pattern Recognition},
  title        = {TSTKD: Triple-spike train kernel-driven supervised learning algorithm},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial multi-label feature selection based on label
distribution learning. <em>PR</em>, <em>164</em>, 111523. (<a
href="https://doi.org/10.1016/j.patcog.2025.111523">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Multi-label Learning (PML) induces a multi-classifier in an imprecise supervised environment, where the candidate labels associated with each training sample are partially valid. The high-dimensional feature space, presented in PML data accompanied by ambiguous labeling information, is a significant challenge for learning. In this paper, we propose a PML feature selection method based on Label Distribution Learning (LDL), which handles the above challenges by correcting misleading and then selecting common and label-specific features. In the first procedure, the error distribution hypothesis is constructed, which divides the structure of ambiguous label information into minority and majority error distribution according to the error amount that may appear in the data annotation process. Under the analysis of the hypothesis, the label credibility distribution data (LCDD) was generated by identifying and correcting errors, where the fractional category of each label associated with each training sample describes the probability that the label belongs to that sample. In the second procedure, a discriminative feature subset is selected for PML based on LCDD by common and label-specific feature constraints. Experiments on three synthetic and five real PML datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_PR},
  author       = {Yaojin Lin and Yulin Li and Shidong Lin and Lei Guo and Yu Mao},
  doi          = {10.1016/j.patcog.2025.111523},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111523},
  shortjournal = {Pattern Recognition},
  title        = {Partial multi-label feature selection based on label distribution learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DEVICE: Depth and visual concepts aware transformer for
OCR-based image captioning. <em>PR</em>, <em>164</em>, 111522. (<a
href="https://doi.org/10.1016/j.patcog.2025.111522">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {OCR-based image captioning is an important but under-explored task, aiming to generate descriptions containing visual objects and scene text. Recent studies have made encouraging progress, but they are still suffering from a lack of overall understanding of scenes and generating inaccurate captions. One possible reason is that current studies mainly focus on constructing the plane-level geometric relationship of scene text without depth information. This leads to insufficient scene text relational reasoning so that models may describe scene text inaccurately. The other possible reason is that existing methods fail to generate fine-grained descriptions of some visual objects. In addition, they may ignore essential visual objects, leading to the scene text belonging to these ignored objects not being utilized. To address the above issues, we propose a Depth and Visual Concepts Aware Transformer (DEVICE) for OCR-based image captioning. Concretely, to construct three-dimensional geometric relations, we introduce depth information and propose a depth-enhanced feature updating module to ameliorate OCR token features. To generate more precise and comprehensive captions, we introduce semantic features of detected visual concepts as auxiliary information, and propose a semantic-guided alignment module to improve the model’s ability to utilize visual concepts. Our DEVICE is capable of comprehending scenes more comprehensively and boosting the accuracy of described visual entities. Sufficient experiments demonstrate the effectiveness of our proposed DEVICE, which outperforms state-of-the-art models on the TextCaps test set.},
  archive      = {J_PR},
  author       = {Dongsheng Xu and Qingbao Huang and Xingmao Zhang and Haonan Cheng and Feng Shuang and Yi Cai},
  doi          = {10.1016/j.patcog.2025.111522},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111522},
  shortjournal = {Pattern Recognition},
  title        = {DEVICE: Depth and visual concepts aware transformer for OCR-based image captioning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generically contrastive spatiotemporal representation
enhancement for 3D skeleton action recognition. <em>PR</em>,
<em>164</em>, 111521. (<a
href="https://doi.org/10.1016/j.patcog.2025.111521">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton-based action recognition is a central task in computer vision and human–robot interaction. However, most previous methods suffer from overlooking the explicit exploitation of the latent data distributions ( i.e. , the intra-class variations and inter-class relations), thereby leading to confusion about ambiguous samples and sub-optimum solutions of the skeleton encoders. To mitigate this, we propose a C ontrastive S patiotemporal R epresentation E nhancement (CSRE) framework to obtain more discriminative representations from the sequences, which can be incorporated into various previous skeleton encoders and can be removed when testing. Specifically, we decompose the representation into spatial- and temporal-specific features to explore fine-grained motion patterns along the corresponding dimensions. Furthermore, to explicitly exploit the latent data distributions, we employ the attentive features to contrastive learning, which models the cross-sequence semantic relations by pulling together the features from the positive pairs and pushing away the negative pairs. Extensive experiments show that CSRE with five various skeleton encoders (HCN, 2S-AGCN, CTR-GCN, Hyperformer, and BlockGCN) achieves solid improvements on five benchmarks. The code will be released at https://github.com/zhshj0110/CSRE .},
  archive      = {J_PR},
  author       = {Shaojie Zhang and Jianqin Yin and Yonghao Dang},
  doi          = {10.1016/j.patcog.2025.111521},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111521},
  shortjournal = {Pattern Recognition},
  title        = {A generically contrastive spatiotemporal representation enhancement for 3D skeleton action recognition},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TextDiff: Enhancing scene text image super-resolution with
mask-guided residual diffusion models. <em>PR</em>, <em>164</em>,
111513. (<a href="https://doi.org/10.1016/j.patcog.2025.111513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of scene text image super-resolution (STISR) is to reconstruct high-resolution text-line images from unrecognizable low-resolution inputs. The existing methods relying on the optimization of pixel-level loss tend to yield text edges that exhibit a notable degree of blurring, thereby exerting a substantial impact on both the readability and recognizability of the text. To address these issues, we propose TextDiff, the first diffusion-based framework tailored for STISR. It contains two modules: the Text Enhancement Module (TEM) and the Mask-Guided Residual Diffusion Module (MRD). The TEM generates an initial deblurred text image and a mask that encodes the spatial location of the text. The MRD is responsible for effectively sharpening the text edge by modeling the residuals between the ground-truth images and the initial deblurred images. Extensive experiments demonstrate that our TextDiff achieves state-of-the-art (SOTA) performance on public benchmark datasets, with a maximum improvement of 2.0% in recognition accuracy over existing methods while enhancing the readability of scene text images. Moreover, our proposed MRD module is plug-and-play that effectively sharpens the text edges produced by SOTA methods. This enhancement not only improves the readability and recognizability of the results generated by SOTA methods but also does not require any additional joint training.},
  archive      = {J_PR},
  author       = {Baolin Liu and Zongyuan Yang and Chinwai Chiu and Yongping Xiong},
  doi          = {10.1016/j.patcog.2025.111513},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111513},
  shortjournal = {Pattern Recognition},
  title        = {TextDiff: Enhancing scene text image super-resolution with mask-guided residual diffusion models},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Iterative knowledge distillation and pruning for model
compression in unsupervised domain adaptation. <em>PR</em>,
<em>164</em>, 111512. (<a
href="https://doi.org/10.1016/j.patcog.2025.111512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, deep learning models often face the challenges of inconsistent distribution between training data and test data and insufficient labeled data. To address these problems, unsupervised domain adaptation (UDA) based transfer learning has gained significant attention. However, the existing UDA models are difficult to meet the requirements of real-time and resource-constrained scenarios. Although model compression can accelerate UDA, it usually leads to performance degradation. In this paper, we propose an iterative transfer model compression (ITMC) method, which centers on two key modules, i.e., transfer knowledge distillation (TKD) and adaptive channel pruning (ACP), by executing them alternately. The tight coupling of the two modules realizes the effective compression of the model while ensuring the performance of the model on the target domain. In the TKD phase, the teacher model and the student model are gradually adapted to the target domain, and the real-time updated teacher model efficiently guides the student model learning, while the ACP phase employs a dynamic pruning strategy based on the training epoch, which removes unimportant channels based on the loss of the TKD student model. Experimental results demonstrate that ITMC approach achieves higher accuracy under the same compression ratio compared with the state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Zhiyuan Wang and Long Shi and Zhen Mei and Xiang Zhao and Zhe Wang and Jun Li},
  doi          = {10.1016/j.patcog.2025.111512},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111512},
  shortjournal = {Pattern Recognition},
  title        = {Iterative knowledge distillation and pruning for model compression in unsupervised domain adaptation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RhythmFormer: Extracting patterned rPPG signals based on
periodic sparse attention. <em>PR</em>, <em>164</em>, 111511. (<a
href="https://doi.org/10.1016/j.patcog.2025.111511">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote photoplethysmography (rPPG) is a non-contact method for detecting physiological signals based on facial videos, holding high potential in various applications. Due to the periodicity nature of rPPG signals, the long-range dependency capturing capacity of the transformer was assumed to be advantageous for such signals. However, existing methods have not conclusively demonstrated the superior performance of transformers over traditional convolutional neural networks. This may be attributed to the quadratic scaling exhibited by transformer with sequence length, resulting in coarse-grained feature extraction, which in turn affects robustness and generalization. To address that, this paper proposes a periodic sparse attention mechanism based on temporal attention sparsity induced by periodicity. A pre-attention stage is introduced before the conventional attention mechanism. This stage learns periodic patterns to filter out a large number of irrelevant attention computations, thus enabling fine-grained feature extraction. Moreover, to address the issue of fine-grained features being more susceptible to noise interference, a fusion stem is proposed to effectively guide self-attention towards rPPG features. It can be easily integrated into existing methods to enhance their performance. Extensive experiments show that the proposed method achieves state-of-the-art performance in both intra-dataset and cross-dataset evaluations. The codes are available at https://github.com/zizheng-guo/RhythmFormer .},
  archive      = {J_PR},
  author       = {Bochao Zou and Zizheng Guo and Jiansheng Chen and Junbao Zhuo and Weiran Huang and Huimin Ma},
  doi          = {10.1016/j.patcog.2025.111511},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111511},
  shortjournal = {Pattern Recognition},
  title        = {RhythmFormer: Extracting patterned rPPG signals based on periodic sparse attention},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning multi-granularity representation with transformer
for visible-infrared person re-identification. <em>PR</em>,
<em>164</em>, 111510. (<a
href="https://doi.org/10.1016/j.patcog.2025.111510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared person re-identification (VI-ReID) aims to match pedestrian images from visible and near-infrared modalities. The pedestrian images of two modalities contain discriminative features in different sizes and positions, e.g. , the global color of the cloth, the body’s local pose, and the shoe’s pixel size. However, existing methods mainly capture features at a single granularity, ignoring multi-granularity information contributing to pedestrian identification. Therefore, we propose a cross-modality multi-granularity Transformer (CM 2 GT) framework to solve this issue. CM 2 GT learns coarse-to-fine feature representations and integrates discriminative information across various granularities, which alleviates problems of the irrelevant matching and ambiguous alignment caused by matching single granularity features. Specifically, we first design a multi-granularity feature extractor (MGFE) module based on Transformer to capture the global-patch-pixel level features of each modality, which can flexibly represent semantic information at multiple scales. Secondly, a multi-granularity fusion Transformer (MGFT) module mines the hierarchical relationships between multi-granularity features by a saliency-enhanced Transformer, which ensures the identity-wise saliency consistency across different granularities and modalities. Furthermore, to further enhance cross-modality intra-class clustering in latent space, we design a cross-modality nearest-neighbor clustering (CNC) loss function to minimize the distance between the anchor sample and its cross-modality nearest neighbor. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods.},
  archive      = {J_PR},
  author       = {Yujian Feng and Feng Chen and Guozi Sun and Fei Wu and Yimu Ji and Tianliang Liu and Shangdong Liu and Xiao-Yuan Jing and Jiebo Luo},
  doi          = {10.1016/j.patcog.2025.111510},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111510},
  shortjournal = {Pattern Recognition},
  title        = {Learning multi-granularity representation with transformer for visible-infrared person re-identification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mask-aware 3D axial transformer for video inpainting.
<em>PR</em>, <em>164</em>, 111509. (<a
href="https://doi.org/10.1016/j.patcog.2025.111509">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a Mask-Aware 3D Axial Transformer for efficient and effective video inpainting, which aims to recover the missing content of a video by leveraging long-range information in an efficient way. Recent works show that the transformer architecture achieves promising video inpainting performance, due to its powerful capability to exploit long-range consistency across frames. However, it requires high time complexity to compute the global self-attention. On the other hand, existing transformer-based inpainting methods treat the valid and invalid regions in the masked image the same when calculating self-attention, causing the network not to distinguish their differences. To address these issues, we first design a 3D Axial Transformer which splits the input features into three shapes of stripes, including a horizontal stripe, a vertical stripe to perform intra-frame attention, and a temporal stripe for inter-frame attention. With three such transformer blocks stacked, the relevance between two arbitrary spatial–temporal pixels across all video frames can be reached while maintaining high efficiency. We also devise a mask-aware module to predict the reliability score of masked pixels, which helps the transformer avoid leveraging information from the invalid region. Extensive experimental results on the Youtube-VOS and DAVIS datasets show that our approach outperforms the state-of-the-arts.},
  archive      = {J_PR},
  author       = {Hongyi Sun and Wanhua Li and Jiwen Lu and Jie Zhou},
  doi          = {10.1016/j.patcog.2025.111509},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111509},
  shortjournal = {Pattern Recognition},
  title        = {Mask-aware 3D axial transformer for video inpainting},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised group re-identification from aerial perspective
via strategic member harmonization. <em>PR</em>, <em>164</em>, 111508.
(<a href="https://doi.org/10.1016/j.patcog.2025.111508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Group re-identification (G-ReID) aims to match group images of the same identity. Existing G-ReID methods perform well on ground-based datasets, but remain unexplored in aerial perspective. One reason is the significant human effort required for aerial associations and the inability of unsupervised methods to address low-quality aerial pedestrian detection and reduced feature visibility. To address these issues, we propose Strategic Member Harmonization. Strategic members are harmonized to complement potential information lost or destroyed due to low-quality detections or significant member variations, thus forming harmonization groups. Harmonization groups introduce a richer layer of the underlying information, mitigating clustering inaccuracies gradually. To address the lack of aerial G-ReID datasets, we construct a new aerial dataset with 10,168 group images and 653 different group identities. Our approach achieves state-of-the-art performance on our dataset and performs well on other ground-based datasets. Our dataset is available at https://github.com/chen1hx/UAV-Group.},
  archive      = {J_PR},
  author       = {Hongxu Chen and Quan Zhang and Xiaohua Xie and Jianhuang Lai},
  doi          = {10.1016/j.patcog.2025.111508},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111508},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised group re-identification from aerial perspective via strategic member harmonization},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scientific poster generation: A new dataset and approach.
<em>PR</em>, <em>164</em>, 111507. (<a
href="https://doi.org/10.1016/j.patcog.2025.111507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automating poster creation from research papers saves scientists time. However, training models for this task is challenging due to limited datasets. Moreover, existing methods are mostly rule/template-based, which lack the flexibility to adapt to different content and design requirements in scientific posters. Our contributions aim to address these issues. We introduce Sci-PosterLayout , a dataset comprising 1,226 scientific posters with greater variety in content , layout and domains . Using a template-free method with a seq2seq model and Design Pattern Schema ( DPS ), we learn various content and design patterns for poster layout generation. Evaluations against existing methods and datasets show our approach produces high-quality posters with diverse layouts. Our work seeks to advance research in scientific poster generation by building a new dataset and proposing template-free methods that require minimal human intervention. The Sci-PosterLayout dataset will be publicly available at https://github.com/kitman0000/Sci-PosterLayout-Data .},
  archive      = {J_PR},
  author       = {Xinyi Zhong and Zusheng Tan and Jing Li and Shen Gao and Jing Ma and Shanshan Feng and Billy Chiu},
  doi          = {10.1016/j.patcog.2025.111507},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111507},
  shortjournal = {Pattern Recognition},
  title        = {Scientific poster generation: A new dataset and approach},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S2DiNet: Towards lightweight and fast high-resolution
dichotomous image segmentation. <em>PR</em>, <em>164</em>, 111506. (<a
href="https://doi.org/10.1016/j.patcog.2025.111506">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Dichotomous Image Segmentation task aims to achieve ultra-high precision binary segmentation for category-agnostic objects, including salient, camouflaged, structurally complex, or feature-similar entities. Traditional methods designed for low-resolution inputs produce blurred segmentation, failing to meet such critical safety and stability requirements. Although existing DIS methods achieve high accuracy, they are often parameter-heavy and slow, neglecting practical application needs. To address these challenges, this paper proposes a light-weight and fast framework, aims at improving processing efficiency while ensuring accuracy in high-resolution natural scenes. The proposed method utilizes a shared-weight ResNet-18 backbone to process inputs of different scales. A Feature Synchronization module is employed to enhance the correlation between encoded features of different resolutions. To reduce the parameter and increase the inference speed, the number of feature channels are decreased; however, this also resulted in information loss. The Star Fusion module is introduced to mitigate this issue. Furthermore, a Decoupling and Integration Decoder is adopted to progressively decode and fuse the body, detail, and mask features of the object, enhancing feature decoding accuracy. The proposed model runs at 26.3 FPS with a 48.7 MB size, reducing parameters by 72.4% and increasing speed by 30.8% compared to baseline method ISNet, while maintaining superior performance. Moreover, it surpasses several existing high-resolution methods in terms of accuracy.},
  archive      = {J_PR},
  author       = {Shuhan Chen and Haonan Tang and Yuan Huang and Lifeng Zhang and Xuelong Hu},
  doi          = {10.1016/j.patcog.2025.111506},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111506},
  shortjournal = {Pattern Recognition},
  title        = {S2DiNet: Towards lightweight and fast high-resolution dichotomous image segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CGViT: Cross-image GroupViT for zero-shot semantic
segmentation. <em>PR</em>, <em>164</em>, 111505. (<a
href="https://doi.org/10.1016/j.patcog.2025.111505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, with the increase of image-text data, such coarse data has also been introduced to address the image semantic segmentation task. However, previous works simply transfer the methods used in other visual tasks to image semantic segmentation, ignoring the task characteristics of semantic segmentation. In this work, we propose a C ross-image G roup ViT (CGViT) for zero-shot semantic segmentation, constructing a semantically consistent feature representation across images. Specifically, we improve the previous work GroupViT in two aspects. We propose two grouping blocks and update them with a momentum-based method, constructing a semantically consistent feature representation across images. Then we introduce an image-level supervision for learning semantic information and a token-level supervision for fine-grained information, obtaining hierarchical information for semantic segmentation. We train the model with image-text data and transfer it to zero-shot semantic segmentation without fine-tuning. Furthermore, the CGViT achieves new state-of-the-art results on three challenging datasets. Especially, the CGViT obtains 49.30% in mIoU on PASCAL VOC dataset, when only pre-trained on CC12M dataset.},
  archive      = {J_PR},
  author       = {Jie Jiang and Xingjian He and Xinxin Zhu and Weining Wang and Jing Liu},
  doi          = {10.1016/j.patcog.2025.111505},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111505},
  shortjournal = {Pattern Recognition},
  title        = {CGViT: Cross-image GroupViT for zero-shot semantic segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to restore arbitrary hybrid adverse weather
conditions in one go. <em>PR</em>, <em>164</em>, 111504. (<a
href="https://doi.org/10.1016/j.patcog.2025.111504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adverse conditions typically suffer from stochastic hybrid weather degradations (e.g., rainy and hazy night), while existing image restoration algorithms envisage that weather degradations occur independently, thus may fail to handle real-world complicated scenarios. Besides, supervised training is not feasible due to the lack of comprehensive paired dataset to characterize hybrid weather conditions. To this end, we have advanced the forementioned limitations with two tactics: framework and data. First, we present a novel unified framework, dubbed RAHC, to Restore Arbitrary Hybrid adverse weather Conditions in one go. Specifically, our RAHC leverages a multi-head aggregation architecture to learn multiple degradation representation subspaces and then constrains the network to flexibly handle multiple hybrid adverse weather in a unified paradigm through a discrimination mechanism in the output space. Furthermore, we devise a reconstruction vectors aided scheme to provide auxiliary visual content cues for reconstruction, thus can comfortably cope with hybrid scenarios with insufficient remaining image constituents. Second, we establish a new dataset, termed HAC, for learning and benchmarking arbitrary Hybrid Adverse Conditions restoration. HAC contains 31 scenarios composed of an arbitrary fusion of five common weather, with a total of ∼ 316 K adverse-weather/clean pairs. As for fabrication, the training set is automatically generated by a dedicated AdverseGAN with no-frills labor, while the test set is manually modulated by experts for authoritative evaluation. Extensive experiments yield superior results and in particular establish new state-of-the-art results on both HAC and conventional datasets.},
  archive      = {J_PR},
  author       = {Yecong Wan and Mingwen Shao and Yuanshuo Cheng and Yuexian Liu and Zhiyuan Bao},
  doi          = {10.1016/j.patcog.2025.111504},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111504},
  shortjournal = {Pattern Recognition},
  title        = {Learning to restore arbitrary hybrid adverse weather conditions in one go},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Progressive class-aware instance enhancement for aircraft
detection in remote sensing imagery. <em>PR</em>, <em>164</em>, 111503.
(<a href="https://doi.org/10.1016/j.patcog.2025.111503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aircraft detection and type identification in optical remote sensing imagery are critical for civilian and military applications, including air traffic control and strategic surveillance. However, existing methods ignore the unique cross-shaped geometric structure and low spatial occupancy of aircraft, leading to inaccurate localization and category confusion. In response, this paper proposes a novel anchor-free detection network that leverages point set representation, integrating the progressive class-aware dual branches (PCA-DB) and instance-guided enhancement module (IGEM). Specifically, considering the underlying structure of aircraft, PCA-DB consists of the coarse foreground instance branch and the refined cross-shaped branch to facilitate high-quality point set generation. Through multi-task learning, the auxiliary branches implicitly inject geometric priors into shared features, effectively suppressing background interference. Subsequently, IGEM introduces the interactive attention mechanism to adaptively fuse the instance-level information in the auxiliary branch with features in the main branches, explicitly enhancing the discriminative features of aircraft. Extensive experiments validate the superior performance of the proposed method on several aircraft datasets, including MAR20, FAIR1M-Plane, and CORS-ADD. There are 5.42%, 4.28%, and 1.37% improvements in mAP in our method compared to the baseline network.},
  archive      = {J_PR},
  author       = {Tianjun Shi and Jinnan Gong and Jianming Hu and Yu Sun and Guangzhen Bao and Pengfei Zhang and Junjie Wang and Xiyang Zhi and Wei Zhang},
  doi          = {10.1016/j.patcog.2025.111503},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111503},
  shortjournal = {Pattern Recognition},
  title        = {Progressive class-aware instance enhancement for aircraft detection in remote sensing imagery},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for efficient registration
between intraoral-scan meshes and CT images. <em>PR</em>, <em>164</em>,
111502. (<a href="https://doi.org/10.1016/j.patcog.2025.111502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Registration between computed tomography (CT) images and intraoral-scan (IOS) meshes facilitates dental procedure planning. However, the spatial complexity of 3D-space computations presents a significant challenge, necessitating the reduction of computational cost through efficient sampling while maintaining robustness via global approximation without segmentation. Herein, we introduce an efficient and robust method for registering CT images and IOS meshes, eliminating the need for segmentation. We utilized an effective sampling technique to identify key vertices in IOS meshes by calculating the negative curvatures between adjacent faces. The significant vertices are transformed into a novel graph representation, serving as the input state for the graph convolution-based backbone network within a deep reinforcement learning (DRL) framework. This framework approximates an optimal solution through sequential decision-making, selecting the best among 12 actions by considering translation and rotation to accurately locate the 3D mesh at arbitrary positions and angles on maxillary or mandibular teeth in CT images. The proposed method was evaluated against conventional and deep learning-based methods, demonstrating mean absolute errors of 1.955 ± 1.310 and 1.399 ± 0.644 mm for maxillary and mandibular teeth, respectively. Additionally, it required only 0.48 M floating-point operations for the calculations, making it more efficient than existing methods.},
  archive      = {J_PR},
  author       = {Seungpil Choi and Seoyeon Jang and Sunghee Jung and Heon Jae Cho and Byunghwan Jeon},
  doi          = {10.1016/j.patcog.2025.111502},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111502},
  shortjournal = {Pattern Recognition},
  title        = {Deep reinforcement learning for efficient registration between intraoral-scan meshes and CT images},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal fusion via voting network for 3D object detection
in indoors. <em>PR</em>, <em>164</em>, 111501. (<a
href="https://doi.org/10.1016/j.patcog.2025.111501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, 3D object detection has become essential in machine vision systems, as it requires more spatial information, such as position and size, compared to traditional 2D detection. Numerous studies have successfully achieved accurate localization, size estimation, orientation estimation, and classification of objects in diverse scenarios. Building on this foundation, we propose a novel method called &quot;Point Cloud and Image VoteNet,&quot; which enhances 3D object detection through the early fusion of radar point cloud data and image features. Our Point-Fusion technique projects radar point clouds onto images to extract complementary features. By incorporating point cloud density parameters, we improve the object matching mechanism, resulting in precise detections. Experimental results demonstrate that our model effectively leverages the combined information from point clouds and images, achieving superior performance. The fusion techniques and optimization strategies employed significantly enhance accuracy and robustness, showcasing promising potential in applications such as autonomous driving, robotics, and augmented reality.},
  archive      = {J_PR},
  author       = {Jianxin Li and Guannan Si and Xinyu Liang and Zhaoliang An and Pengxin Tian and Fengyu Zhou and Xiaoliang Wang},
  doi          = {10.1016/j.patcog.2025.111501},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111501},
  shortjournal = {Pattern Recognition},
  title        = {Multimodal fusion via voting network for 3D object detection in indoors},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based vector quantized variational autoencoder for
anomaly detection by using orthogonal subspace constraints. <em>PR</em>,
<em>164</em>, 111500. (<a
href="https://doi.org/10.1016/j.patcog.2025.111500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new framework that uses a vector quantized variational autoencoder (VQVAE) enhanced by orthogonal subspace constraints (OSC) and pyramid criss-cross attention (PCCA). The framework was designed for anomaly detection in industrial product image datasets. Previous studies on modeling low-dimensional feature distributions have been unable to effectively distinguish between normal features and noisy/abnormal information, which is effectively addressed using OSC in this study. Then, the vector quantized mechanism is embodied in these two complementary subspaces to obtain normal and abnormal embedding subspaces and discrete representations for normal and noisy information, respectively. The proposed approach robustly represents low-dimensional discrete manifolds to present the information from normal data using a limited number of feature vectors. Additionally, two PCCA modules are proposed to capture feature maps from different layers in the encoder and decoder, benefitting the low-dimensional mapping and reconstruction process. The features of different layers are treated as the query (Q), key (K), and value (V), which could capture both low-level and high-level features, incorporating comprehensive contextual information. The effectiveness of the proposed framework for anomaly detection is assessed by comparing its performance with those of the state-of-the-art approaches on various publicly available industrial product image datasets.},
  archive      = {J_PR},
  author       = {Qien Yu and Shengxin Dai and Ran Dong and Soichiro Ikuno},
  doi          = {10.1016/j.patcog.2025.111500},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111500},
  shortjournal = {Pattern Recognition},
  title        = {Attention-based vector quantized variational autoencoder for anomaly detection by using orthogonal subspace constraints},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multimodal urban traffic flow prediction based on
multi-scale time series imaging. <em>PR</em>, <em>164</em>, 111499. (<a
href="https://doi.org/10.1016/j.patcog.2025.111499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is of great significance for administrators and travelers to make informed decisions in advance. Since the increasing correlation between predicted flow and historical flow from more recent periods, most existing traffic flow prediction models generally learn spatial-temporal patterns from historical single-scale time series data with time steps not exceeding 12. However, such short-term flow does not contain continuous and dynamic long-term spatial-temporal patterns. Thus, how to comprehensively learn the diverse patterns and achieve a satisfactory balance between effectiveness and efficiency presents a challenge. To this end, we propose a multimodal urban traffic flow prediction model based on multi-scale time series imaging (MM-TSI). Specifically, a data processing mechanism of multi-scale time series imaging is specially designed to efficiently learn both short- and long-term spatial-temporal patterns. After that, an image-based module is proposed to be parallelly integrated into a traditional time series-based module. By adaptively fusing the two-modal features extracted from image-based module and time series-based module, MM-TSI is capable of effectively learning more comprehensive and diverse spatial-temporal patterns while maintaining efficiency to a certain extent. Extensive experiments are conducted on three real-world urban traffic flow datasets. The results demonstrate that the proposed MM-TSI significantly outperforms the state-of-the-art (SOTA) models and exhibits generalization ability in both short- and long-term prediction.},
  archive      = {J_PR},
  author       = {Qinzhi Lv and Lijuan Liu and Ruotong Yang and Yan Wang},
  doi          = {10.1016/j.patcog.2025.111499},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111499},
  shortjournal = {Pattern Recognition},
  title        = {Multimodal urban traffic flow prediction based on multi-scale time series imaging},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bayesian dual-pathway network for unsupervised domain
adaptation. <em>PR</em>, <em>164</em>, 111498. (<a
href="https://doi.org/10.1016/j.patcog.2025.111498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised Domain Adaptation (UDA) endeavors to address the challenges presented by domain shifts between domains characterized by differing yet related distributions. Traditional adversarial approaches typically adopt a single-pathway adversarial paradigm, which relies on a singular pathway to align the marginal distributions at the domain level. Despite notable advancements, this paradigm is constrained by two major limitations that lead to sub-optimal performance in both source and target domains. First, naive domain-level alignment often results in class mismatches. Second, the single-pathway adversarial approach grapples with the conflicting demands of reducing domain shift while simultaneously learning comprehensive features. Drawing inspiration from cognitive neuroscience, we propose a Bayesian Dual-Pathway Network (BDNet) for UDA to compute a classification prior for each domain, comprising a domain-shared pathway and a domain-specific pathway, designed to enhance target domain performance while preserving source domain efficacy. Specifically, the domain-shared pathway is employed to learn classification prior features through an adversarial paradigm grounded in structural alignment. Concurrently, a domain-specific pathway is crafted to extract distinct features, incorporating domain likelihood and domain prior features. Comprehensive features are synthesized through the fusion of common and specific attributes via a lightweight fusion module. Extensive experiments across three publicly available datasets demonstrate the efficacy of our approach, evidencing superior performance in both source and target domains.},
  archive      = {J_PR},
  author       = {Yuhang He and Junzhe Chen and Jiehua Zhang and Wei Ke and Yihong Gong},
  doi          = {10.1016/j.patcog.2025.111498},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111498},
  shortjournal = {Pattern Recognition},
  title        = {A bayesian dual-pathway network for unsupervised domain adaptation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guiding prototype networks with label semantics for few-shot
text classification. <em>PR</em>, <em>164</em>, 111497. (<a
href="https://doi.org/10.1016/j.patcog.2025.111497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot text classification aims to recognize unseen classes with limited labeled text samples. Typical meta-learning methods, e.g., Prototypical Networks, face several problems. (1) The limited words in each sentence make it difficult to extract fine-grained class-related semantic information. (2) The semantic information from labels is not fully utilized, leading to ambiguities in class definitions. (3) The randomly selected support samples cannot represent their corresponding classes well. In this paper, we propose to leverage label semantics tackling the above problems and present L abel G uided P rototype N etworks (LGPN). Firstly, we use prompt encoding to generate text representations instead of aggregating the words in the sentences, extracting more class-related semantic information. Secondly, we propose Label-guided Distance Scaling (LDS), in the training stage, we design label-guided loss to pull the samples closer to their corresponding labels, making class distributions distinguishable. Thirdly, in the testing stage, we scale the text representations with the label semantics to pull each support sample closer to the class center, which reduces the prediction contradictions caused by randomly selected support samples (i.e., unsatisfactory support sample representations). We conduct extensive experiments on six benchmark datasets, and our LGPN shows obvious advantages over state-of-the-art models. Additionally, we further explore the effectiveness and universality of our modules.},
  archive      = {J_PR},
  author       = {Xinyue Liu and Yunlong Gao and Linlin Zong and Wenxin Liang and Bo Xu},
  doi          = {10.1016/j.patcog.2025.111497},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111497},
  shortjournal = {Pattern Recognition},
  title        = {Guiding prototype networks with label semantics for few-shot text classification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rank gap sensitive deep AUC maximization for CTR prediction.
<em>PR</em>, <em>164</em>, 111496. (<a
href="https://doi.org/10.1016/j.patcog.2025.111496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Network (DNN) stands out as one widely adopted and effective technique for Click-Through Rate (CTR) prediction in live recommender systems. However, the prevalent DNN-based CTR methods exhibit two main drawbacks. On one hand, they fail to align their optimization objectives with the benchmark metric, such as the Area Under the ROC Curve (AUC), designed for ranking tasks. On the other hand, current DNN-based CTR solutions indiscriminately treat all positive-negative item pairs, ignoring the fact that each item pair differently contributes to AUC optimization. To this end, we propose R ank G ap S ensitive Deep AUC maximization method for accurate CTR prediction, namely RgsAUC. Specifically, we target AUC as the learning objective by relaxing the Heaviside function via sigmoid function to render it differentiable and thus can be optimized directly using gradient-descent methods, which is the de facto choice for solving DNN-based CTR tasks. Furthermore, we incorporate a rank gap sensitive weight in estimating gradients for items, aiming to assign greater significance to item pairs with substantial rank gaps during the learning process. In particular, we reduce the computational complexity from quadratic to linear through reformulation, enabling efficient deployment. Consequently, these designs sharply minimize the number of erroneously-ranked item pairs, which is beneficial to AUC optimization. Notably, RgsAUC is model-agnostic and we implement it in five classic DNN models for the CTR prediction task. Extensive experiments on six real-world datasets clearly demonstrate the effectiveness of our proposed method.},
  archive      = {J_PR},
  author       = {Fangyuan Luo and Yankai Chen and Jun Wu and Yidong Li},
  doi          = {10.1016/j.patcog.2025.111496},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111496},
  shortjournal = {Pattern Recognition},
  title        = {Rank gap sensitive deep AUC maximization for CTR prediction},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extremely fast graph integration for semi-supervised
learning via gaussian fields with neumann approximation. <em>PR</em>,
<em>164</em>, 111495. (<a
href="https://doi.org/10.1016/j.patcog.2025.111495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid growth in data availability, it has become more important to utilize multiple data sources containing different but complementary information for a given task. Using multiple graphs can technically be interpreted as finding the optimal combination of each graph. There have been various approaches for graph integration or graph fusion, but most of them have suffered from scalability issues as data size increases due to long computation time. This makes them difficult to utilize in the current trend of data size becoming huge. To circumvent this difficulty, our approach introduces a fast graph integration method based on semi-supervised learning (SSL), which incorporates the Neumann approximation during the maximum likelihood estimation process. Empirical studies show that the proposed method significantly reduces computation time by at least a factor of two compared to state-of-the-art methods, while still performing competitively with other methods. This advantage becomes more apparent as the size of the data increases, since the complexity of the proposed method depends mostly on the number of graphs to be integrated and not on the number of nodes, unlike other methods. Experimental results demonstrate the scalability and efficiency of the proposed method for graph integration.},
  archive      = {J_PR},
  author       = {Taehwan Yun and Myung Jun Kim and Hyunjung Shin},
  doi          = {10.1016/j.patcog.2025.111495},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111495},
  shortjournal = {Pattern Recognition},
  title        = {Extremely fast graph integration for semi-supervised learning via gaussian fields with neumann approximation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Auxiliary action unit model for facial expression
adversarial training. <em>PR</em>, <em>164</em>, 111493. (<a
href="https://doi.org/10.1016/j.patcog.2025.111493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adversarial training of neural networks against adversarial attacks is increasingly gaining attention due to the demands for artificial intelligence security. However, there have been few studies on adversarial training for facial expression recognition (FER) models. In this work, we propose a novel adversarial training method for FER models. Specifically, we employ an action unit (AU) model to enhance the adversarial robustness of the FER model during the training process. Experimental results demonstrate that our method (i) exhibits greater generalization and robustness than other existing methods for FER models; (ii) incurs feasible computational training costs; and (iii) can converge under extreme circumstances, such as random labels. Our research makes sense as it paves the way for future studies in adversarial training for FER models.},
  archive      = {J_PR},
  author       = {Yudao Sun and Fan Zhang and Minjiao Yang},
  doi          = {10.1016/j.patcog.2025.111493},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111493},
  shortjournal = {Pattern Recognition},
  title        = {Auxiliary action unit model for facial expression adversarial training},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A perturbed match filtering approach for face image quality
assessment. <em>PR</em>, <em>164</em>, 111492. (<a
href="https://doi.org/10.1016/j.patcog.2025.111492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face image quality assessment (FIQA) that estimates the utility of face images is essential for reliable face recognition. However, current state-of-the-art analysis-based FIQA methods suffer from excessively long execution time. Inspired by an observation that comparing to low-quality images, the features of high-quality images more likely maintain stronger robustness after perturbation, we propose a novel training-free FIQA approach, called Perturbed Match Filtering (PMF), in which a quality score function is defined based on the output of a match filter that takes as input the perturbed feature manipulated by selectively dropping a proportion of elements within an internal activation of the network. In addition, our proposed PMF approach can be implemented as a post-processing step for a pre-trained quality regression model to further improve its performance. We conduct extensive experiments on eight benchmark datasets with four target face recognition models. The experimental results demonstrate the superiority of our proposed approach compared to twelve state-of-the-art FIQA algorithms.},
  archive      = {J_PR},
  author       = {Yuying Zhao and Mei Wang and Jiani Hu and Weihong Deng and Chun-Guang Li},
  doi          = {10.1016/j.patcog.2025.111492},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111492},
  shortjournal = {Pattern Recognition},
  title        = {A perturbed match filtering approach for face image quality assessment},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refining attention weights for facial super-resolution with
counterfactual attention learning. <em>PR</em>, <em>164</em>, 111491.
(<a href="https://doi.org/10.1016/j.patcog.2025.111491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Super-resolution is a challenging problem involving reconstructing High- Resolution (HR) images from Low-Resolution (LR) inputs with attention mechanisms being a widely used approach. This paper introduces counterfactual attention learning (CAL), a novel framework based on causal inference that enhances attention quality in super-resolution tasks. CAL provides a strong supervisory signal, enabling the refinement of attention mechanisms during training. Through counterfactual interventions, CAL optimizes learned attention to improve super-resolution outcomes. This method is evaluated using the Scale- Arbitrary Super-Resolution model (ArbSR), which accommodates non-integer scale factors. Experiments conducted on CelebA, FFHQ, and CMU Multi-PIE datasets across different scale factors show that CAL significantly enhances super-resolution performance. On the CMU Multi-PIE dataset, CAL improves Peak Signal-to-Noise Ratio (PSNR) by up to 13.6 % compared to baseline attention mechanisms, even under challenging variations in illumination, pose, and expression. PSNR improvement of 15.5 % was observed for CelebA dataset whereas for the FFHQ dataset, 14.5 % improvement was observed under occlusion conditions. These results highlight the robustness and effectiveness of CAL in advancing the state of super-resolution, offering substantial quantitative and qualitative improvements and showcasing its potential for face superresolution in real-world conditions.},
  archive      = {J_PR},
  author       = {Jayanthi Raghavan and Majid Ahmadi},
  doi          = {10.1016/j.patcog.2025.111491},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111491},
  shortjournal = {Pattern Recognition},
  title        = {Refining attention weights for facial super-resolution with counterfactual attention learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NRGAN: A noise-resilient GAN with adaptive feature
modulation for SAR image segmentation. <em>PR</em>, <em>164</em>,
111490. (<a href="https://doi.org/10.1016/j.patcog.2025.111490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The information extraction of offshore aquaculture rafts from synthetic aperture radar (SAR) images is important for large-scale marine resource exploration and utilization. In this paper, a deep learning model, called Noise-Resilient Generative Adversarial Network (NRGAN), is proposed for SAR image segmentation captured under varying sea conditions to monitor aquaculture rafts. NRGAN consists of an image generator and two regressors. The image generator is used for image segmentation and the regressors for discriminating the generated results and the actual labels. As a key component of the generator, a pixel-level contextual feature adaptation module is designed to improve the performance of the model in dealing with issues such as noise interference and complex image features commonly found in SAR images. The module consists of three parts: one for spatial-feature adaptation to aggregate spatial information from input feature maps and generate a spatial attention map to focus on relevant areas in images, one for contextual-feature adaptation to integrate contextual information for improving feature learning and increasing the expressiveness of input data, and one for pixel-level feature adaptation to refine the contribution of regions within the images, thereby enhancing the coherence of the overall segmentation.},
  archive      = {J_PR},
  author       = {Shuo Lian and Jianchao Fan and Jun Wang},
  doi          = {10.1016/j.patcog.2025.111490},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111490},
  shortjournal = {Pattern Recognition},
  title        = {NRGAN: A noise-resilient GAN with adaptive feature modulation for SAR image segmentation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modality average precision optimization for visible
thermal person re-identification. <em>PR</em>, <em>164</em>, 111489. (<a
href="https://doi.org/10.1016/j.patcog.2025.111489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric learning has emerged as a popular approach for addressing the challenges of visible thermal person re-identification (VT-ReID), such as the cross-modality discrepancy and intra-class variations. However, existing metric learning-based methods often focus on optimizing the model for hard positive samples, neglecting the importance of high-ranking ones, due to failing to consider the overall ranking order within a batch. To overcome this limitation, we propose a novel approach called Cross-modality Average Precision (CAP) that directly optimizes the cross-modality overall ranking order in VT-ReID. Unlike the recently introduced Smooth Average Precision (Smooth-AP), which primarily corrects misordered samples at high ranks, CAP specifically targets the main challenge of cross-modality discrepancy in VT-ReID. Our method involves setting a query instance from one modality and calculating the CAP using galleries from another modality. CAP encompasses two complementary aspects: CAP with Visible queries (CAPV) and CAP with Thermal queries (CAPT). By jointly optimizing these two aspects, we can effectively improve the cross-modality overall ranking order. Additionally, to enhance the effectiveness of CAP, we introduce two techniques. The first technique is Dynamic Modality Alignment (DMA), which reduces the cross-modality discrepancy by adaptively adjusting the weights of modality alignment. The second technique involves implementing CAP and DMA on the Global and Local Features (GLF), enabling us to optimize the model at both global and local levels, further enhancing the advantages of CAP and DMA. We conducted extensive experiments on two VT-ReID datasets, and the results demonstrate the effectiveness of our proposed method, which achieves state-of-the-art performance.},
  archive      = {J_PR},
  author       = {Yongguo Ling and Zhiming Luo and Dazhen Lin and Shaozi Li and Min Jiang and Nicu Sebe and Zhun Zhong},
  doi          = {10.1016/j.patcog.2025.111489},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111489},
  shortjournal = {Pattern Recognition},
  title        = {Cross-modality average precision optimization for visible thermal person re-identification},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view diabetic retinopathy grading via cross-view
spatial alignment and adaptive vessel reinforcing. <em>PR</em>,
<em>164</em>, 111487. (<a
href="https://doi.org/10.1016/j.patcog.2025.111487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our research introduces a novel deep learning framework that leverages multi-view fundus images for Diabetic Retinopathy (DR) grading. Existing models for fundus image analysis often prioritize salient features, such as the optic disk, potentially overlooking finer details critical for DR detection, like retinal vessel information. To address this, we introduce a learnable retinal vessel reinforcement block to enhance the representation of retinal vessels. Additionally, recognizing the limitations of traditional multi-view models in capturing the spatial correlation between 2D appearances from different views, we propose a cross-view spatial region aligning vision transformer (ViT). This ViT-structured model is crucial for modeling cross-view relationships and integrating lesion information across individual views. Furthermore, a multi-view decision fusion module synergistically fuses diagnostic insights from multiple perspectives, enhancing the model’s diagnostic capabilities. Our method demonstrates significant superiority over existing single-view and multi-view models across key performance metrics, including accuracy, precision, sensitivity, specificity, and F1 score.},
  archive      = {J_PR},
  author       = {Yuxin Lin and Xiaoyan Dou and Xiaoling Luo and Zhihao Wu and Chengliang Liu and Tianyi Luo and Jie Wen and Bingo Wing-kuen Ling and Yong Xu and Wei Wang},
  doi          = {10.1016/j.patcog.2025.111487},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111487},
  shortjournal = {Pattern Recognition},
  title        = {Multi-view diabetic retinopathy grading via cross-view spatial alignment and adaptive vessel reinforcing},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CLEAR: Cross-transformers with pre-trained language model
for person attribute recognition and retrieval. <em>PR</em>,
<em>164</em>, 111486. (<a
href="https://doi.org/10.1016/j.patcog.2025.111486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person attribute recognition and attribute-based person retrieval are two core human-centric tasks. In the recognition task, the challenge lies in identifying attributes based on a person’s appearance, while the retrieval task involves searching for matching persons using attribute-based queries. In this paper, we present CLEAR , a unified network designed to address both tasks. We leverage our C 2 T-Net, a strong Cross-Transformers backbone that achieved state-of-the-art performance in the person attribute recognition task during the UPAR Challenge 2024, to extract visual embeddings. We then adapt it for the attribute-based person retrieval task.To extend its capabilities for the attribute-based person retrieval task, we construct pseudo-textual descriptions for attribute queries, leverage a pretrained language model to generate language-rich feature embeddings, and introduce an effective training strategy, which involves finetuning only a few additional parameters in the form of adapters to produce visual and query embeddings within the retrieval space. As the visual embeddings extracted by C 2 T-Net are highly discriminative, they align well with the proposed query embeddings during the finetuning process, facilitating improved retrieval performance.The unified CLEAR , model is evaluated on five benchmarks: PETA, PA100K, Market-1501, RAPv2, and UPAR2024, achieving state-of-the-art or competitive results for both tasks. Notably, it ranks as the top performer on the large-scale UPAR2024 dataset, specifically designed to test domain generalizability in real-world scenarios where test samples differ from training samples.},
  archive      = {J_PR},
  author       = {Doanh C. Bui and Thinh V. Le and Ba Hung Ngo and Tae Jong Choi},
  doi          = {10.1016/j.patcog.2025.111486},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111486},
  shortjournal = {Pattern Recognition},
  title        = {CLEAR: Cross-transformers with pre-trained language model for person attribute recognition and retrieval},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced multi-modal learning with hierarchical fusion for
fake news detection. <em>PR</em>, <em>164</em>, 111485. (<a
href="https://doi.org/10.1016/j.patcog.2025.111485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal fake news detection (MFND) leverages data from various modalities, including text, image, video, and audio, to identify the authenticity of news content. Most existing MFND methods focus on extracting feature representations of each modality and integrating them by fusion strategies. However, they ignore the problem of modality imbalance where the dominant modality suppresses the performance of other modalities during optimization process, which leads to insufficient utilization of multi-modal information. To address the issue of modality imbalance and guarantee the effective utilization of each modality, we propose an approach called Balanced Multi-modal Learning with Hierarchical Fusion (BMLHF), which contains a Multi-modal Information Balancing (MIB) module and a Hierarchical Fusion (HF) module. Specifically, we extract multi-view semantic and pattern features of text and image. MIB calculates the modal information firstly to estimate the modal difference ratio, and it dynamically allocates corresponding weight for optimization of each view of modalities, which facilitates the modal information balance state. HF fully explores the diversity and correlation of multi-modal information in two stages. Intra-modal multi-view information fusion stage designs multi-view attention sub-network to sufficiently fuse semantic and pattern features within modalities. Inter-modal correlation fusion stage designs the joint correlation matrix based cross-attention strategy to learn multi-modal fused features with complementary characteristics. Extensive benchmark experiments demonstrate that our approach significantly surpasses state-of-the-art MFND methods.},
  archive      = {J_PR},
  author       = {Fei Wu and Shu Chen and Guangwei Gao and Yimu Ji and Xiao-Yuan Jing},
  doi          = {10.1016/j.patcog.2025.111485},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111485},
  shortjournal = {Pattern Recognition},
  title        = {Balanced multi-modal learning with hierarchical fusion for fake news detection},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GAD: Domain generalized diabetic retinopathy grading by
grade-aware de-stylization. <em>PR</em>, <em>164</em>, 111484. (<a
href="https://doi.org/10.1016/j.patcog.2025.111484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy (DR) is a prevalent complication of diabetes that can result in vision impairment and blindness, making accurate DR grading essential for early diagnosis and treatment. Most existing DR grading methods assume that the training and test images share the same distribution. However, the generalization performance on unseen target domains has not been adequately addressed. In this paper, we observe that images from the same domain tend to cluster together in the feature space, rather than images of the same grade. This is largely due to the fact that when the representation of lesions is influenced by style variations, the network tends to remember features of different image domains through separate channels. This phenomenon significantly impacts the generalization capability of deep learning models. To address this issue, we propose a global-aware channel similarity to reduce the influence of lesion position and size when measuring the distance in the feature space. This is further utilized in a grade-aware contrastive learning approach, which guides the learning of domain-invariant features by mapping images of the same grade into a compact subspace. Additionally, we develop a multi-scale de-stylization method to explicitly eliminate style information from the features, which also compels the model to exploit diverse representations of the lesion. Extensive experiments on multiple DR grading datasets show the state-of-the-art generalization ability of the proposed method.},
  archive      = {J_PR},
  author       = {Qi Bi and Jingjun Yi and Hao Zheng and Haolan Zhan and Yawen Huang and Wei Ji and Yuexiang Li and Yefeng Zheng},
  doi          = {10.1016/j.patcog.2025.111484},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111484},
  shortjournal = {Pattern Recognition},
  title        = {GAD: Domain generalized diabetic retinopathy grading by grade-aware de-stylization},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised feature selection via maximum relevance and
minimum global redundancy. <em>PR</em>, <em>164</em>, 111483. (<a
href="https://doi.org/10.1016/j.patcog.2025.111483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature selection has been an important research topic in various fields since real datasets often lack complete label information. Many existing unsupervised feature selection algorithms select features based on feature relevance only without considering the redundancy between features, which may result in the selection of suboptimal features. To obtain the optimal feature subset, we propose a new unsupervised feature selection algorithm, called unsupervised Feature Selection with Max-Relevance and Minimum Global Redundancy (MRMGRFS) to select a subset of features with max-relevance and minimum global redundancy. In terms of relevance, we propose an unsupervised Feature Selection algorithm based on Spectral Clustering (SCFS), which divides all features into different clusters using spectral clustering and evaluates the relevance of features by measuring the distance between the features and the mean centers of own-cluster and heterogeneous-clusters. In terms of redundancy, the SCFS algorithm only considers the relevance of features and ignores the redundancy between features, which may select the redundant features that degrade performance. To tackle this issue, a Global Redundancy Minimization model (SJGRM) based on the SCFS and Jensen–Shannon divergence (JSD) is proposed to optimize the relevance score of the features. Furthermore, we propose an effective iterative algorithm for solving SJGRM based on the Alternating Direction Method of Multipliers (ADMM). Extensive experimental results on various public datasets demonstrate the superiority of the proposed algorithm.},
  archive      = {J_PR},
  author       = {Xianyu Zuo and Wenbo Zhang and Xiangyu Wang and Lanxue Dang and Baojun Qiao and Yadi Wang},
  doi          = {10.1016/j.patcog.2025.111483},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111483},
  shortjournal = {Pattern Recognition},
  title        = {Unsupervised feature selection via maximum relevance and minimum global redundancy},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On inferring prototypes for multi-label few-shot learning
via partial aggregation. <em>PR</em>, <em>164</em>, 111482. (<a
href="https://doi.org/10.1016/j.patcog.2025.111482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label few-shot learning (ML-FSL) aims to endow the learning system to recognize multiple objects within an image, trained with insufficient samples. Existing methods have significantly improved ML-FSL and focused on mining the correlation of labels, resulting in a discriminative prototype per class. However, those methods often engage irrelevant information, i.e. , the tangled region with other classes, in the phase of constructing prototypes, limiting their performance gain. Following the intuition that only part regions of an image correspond to a target label, this paper addresses this issue by creating prototypes via a partial aggregation scheme. This is realized by first generating aggregation weights via partial optimal transport (POT) between image and label features and producing features per class using relevant regions within an image. Having the refined class features in a support set, one can obtain a better prototype for each class. We evaluate our model on multiple benchmarks and obtain state-of-the-art performance. A thorough study also reveals the superiority of POT as a way of mining important information for generating prototypes.},
  archive      = {J_PR},
  author       = {Pengfei Fang and Zhihong Chen and Hui Xue},
  doi          = {10.1016/j.patcog.2025.111482},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111482},
  shortjournal = {Pattern Recognition},
  title        = {On inferring prototypes for multi-label few-shot learning via partial aggregation},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ALStereo: Active learning for stereo matching. <em>PR</em>,
<em>164</em>, 111480. (<a
href="https://doi.org/10.1016/j.patcog.2025.111480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With advancements in deep stereo matching, recent networks have achieved impressive accuracy in estimating depth information from image pairs. However, stereo matching networks require sufficient disparity labels, which always come at high annotation costs. In this paper, we propose the ALStereo framework for training stereo matching networks under limited labeling budgets, which selects informative samples for manual labeling and conducts semi-supervised learning to propagate the knowledge to unlabeled samples. Specifically, we embed image pairs as nodes in a graph representation, where edges denote the similarity in terms of stereo matching challenges. Based on the graph representation, we divide the labeling budget into two parts for conducting representativeness-based and uncertainty-based strategies, balancing the selection of the most representative and challenging samples. To fully exploit the labeled samples to train networks, we propose a two-stage semi-supervised training pipeline, where the first stage mitigates the domain shifts and the second stage propagates the knowledge of manually annotated samples to unlabeled samples. We set the first benchmark for evaluating training stereo matching networks under limited labeling budgets and demonstrate our method significantly outperforms the compared methods. We also provide analysis to demonstrate our graph representation effectively models the similarity between samples in terms of stereo matching challenges.},
  archive      = {J_PR},
  author       = {Jiawei Zhang and Jiahe Li and Meiying Gu and Xiaohan Yu and Jin Zheng and Xiao Bai and Edwin Hancock},
  doi          = {10.1016/j.patcog.2025.111480},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111480},
  shortjournal = {Pattern Recognition},
  title        = {ALStereo: Active learning for stereo matching},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Token-aware and step-aware acceleration for stable
diffusion. <em>PR</em>, <em>164</em>, 111479. (<a
href="https://doi.org/10.1016/j.patcog.2025.111479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stable Diffusion has shown strong ability to generate high-quality and diverse images. However, Stable Diffusion suffers from high computational cost, due to the heavy model and step-by-step denoising process. To address these issues, we propose a token-aware and step-aware acceleration approach for Stable Diffusion, named TSA-SD. We first build a simple and efficient baseline by combining exiting intra-step and cross-step acceleration strategies, including token merging and feature caching, into Stable Diffusion. To improve image generation quality of the baseline, we introduce token-aware merging–unmerging and step-aware acceleration. The token-aware merging–unmerging aims to select informative tokens when merging and recover merged tokens using token ratio information. Therefore, the token-aware merging–unmerging can fully utilize token-specific information, thereby reducing token information loss. In addition, we observe that different steps have different functional linearity, and propose step-aware acceleration to perform different merging operations according to functional linearity at different steps. With these two modules, our proposed TSA-SD is able to generate high-quality images at a high speed. We perform the experiments on two widely-used datasets, including ImageNet and MS-COCO. The experimental results demonstrate the effectiveness and efficiency of our proposed method. For instance, on ImageNet validation set, compared to Stable Diffusion, ToMe-SD has a lower FID of 33.68 at 1.96 × speedup, while our method achieves a lower FID of 32.49 at 4.68 × speedup.},
  archive      = {J_PR},
  author       = {Ting Zhen and Jiale Cao and Xuebin Sun and Jing Pan and Zhong Ji and Yanwei Pang},
  doi          = {10.1016/j.patcog.2025.111479},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111479},
  shortjournal = {Pattern Recognition},
  title        = {Token-aware and step-aware acceleration for stable diffusion},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optical remote sensing image salient object detection via
bidirectional cross-attention and attention restoration. <em>PR</em>,
<em>164</em>, 111478. (<a
href="https://doi.org/10.1016/j.patcog.2025.111478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection (SOD) in optical remote sensing images (ORSI) has garnered considerable attention in recent years. The inherent high complexity of scenes in ORSI poses significant challenges to SOD methods. Current models face two major limitations. First, they fail to fully exploit the relationships between features due to ignoring the bidirectional attention relationship and continuity among adjacent feature layers. Second, while non-local modules are designed to enhance global context understanding by modeling pixel-wise relationships, their traditional implementations suffer from attention vacuity, as they treat all spatial locations equally without focusing on the most informative regions. To overcome these limitations, we introduce a novel Bidirectional Cross-Attention and Attention Restoration Neural Network (BCAR-Net), comprising the Bidirectional Cross-Attention Module (BCAM) and the Attention Restoration Module (ARM). BCAM enhances the semantic representation of detail features in lower-level maps and improves the detail representation of semantic features in higher-level maps. This is achieved by computing cross-attention between two adjacent layers in a parallel bidirectional manner, playing a crucial role in spatial information representation. Additionally, ARM addresses attention vacuity through the Foreground-Background Decoupling (FBD) and Local Attention Vacuity Supplementation (LAVS) components. Specifically, FBD refines the segmentation of salient objects from their backgrounds, while LAVS remedies local object detection omissions. Experimental results demonstrate that our proposed model performs favorably and outperforms existing methods overall. Specifically, on the ORSSD and EORSSD benchmark datasets, our method outperforms the SOTA approaches by 10% and 5% in terms of MAE, respectively. The source codes and the outcomes can be accessed at https://github.com/ClimBin/BCARNet .},
  archive      = {J_PR},
  author       = {Yubin Gu and Siting Chen and Xiaoshuai Sun and Jiayi Ji and Yiyi Zhou and Rongrong Ji},
  doi          = {10.1016/j.patcog.2025.111478},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111478},
  shortjournal = {Pattern Recognition},
  title        = {Optical remote sensing image salient object detection via bidirectional cross-attention and attention restoration},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning pathways for automatic sign language
processing. <em>PR</em>, <em>164</em>, 111475. (<a
href="https://doi.org/10.1016/j.patcog.2025.111475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study provides a comprehensive review of the current state of the sign language processing (SLP) field, encompassing sign language recognition (SLR), translation (SLT), production (SLPn), and the associated datasets (SLD). It analyzes the advancements and challenges in each area, highlighting key methodologies and technologies. The authors explore feature extraction techniques, model architectures, and multimodal data integration in SLR. For SLT, they examine neural machine translation and sequence-to-sequence frameworks, emphasizing the need for context-aware systems. In SLPn, they review avatar-based systems and motion capture techniques, identifying gaps in generating natural and expressive sign language. The survey of SLD evaluates existing datasets and underscores the importance of comprehensive data collection. It also discusses current SLP systems’ limitations and proposes future research directions to enhance accuracy, naturalness, and user-centric applications.},
  archive      = {J_PR},
  author       = {Mukhiddin Toshpulatov and Wookey Lee and Jaesung Jun and Suan Lee},
  doi          = {10.1016/j.patcog.2025.111475},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111475},
  shortjournal = {Pattern Recognition},
  title        = {Deep learning pathways for automatic sign language processing},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inversed pyramid network with spatial-adapted and
task-oriented tuning for few-shot learning. <em>PR</em>, <em>164</em>,
111415. (<a href="https://doi.org/10.1016/j.patcog.2025.111415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of artificial intelligence, deep neural networks have achieved great performance in many tasks. However, traditional deep learning methods require a large amount of training data, which may not be available in certain practical scenarios. In contrast, few-shot learning aims to learn a model that can be readily adapted to new unseen classes from only one or a few labeled examples. Despite this success, most existing methods rely on pre-trained feature extractor networks trained with global features, ignoring the discrimination of local features, and weak generalization capabilities limit their performance. To address the problem, according to the human’s coarse-to-fine cognition paradigm, we propose an Inverted Pyramid Network with Spatial-adapted and Task-oriented Tuning (TIPN) for few-shot learning. Specifically, the proposed framework represents local features for categories that are difficult to distinguish by global features and recognizes objects from both global and local perspectives. Moreover, to ensure the calibration validity of the proposed model at the local stage, we introduce the Spatial-adapted Layer to preserve the discriminative global representation ability of the pre-trained backbone network. Meanwhile, as the representations extracted from the past categories are not applicable to the current new tasks, we further propose the Task-oriented Tuning strategy to adjust the parameters of the Batch Normalization layer in the pre-trained feature extractor network, to explicitly transfer knowledge from base classes to novel classes according to the support samples of each task. Extensive experiments conducted on multiple benchmark datasets demonstrate that our method can significantly outperform many state-of-the-art few-shot learning methods.},
  archive      = {J_PR},
  author       = {Xiaowei Zhao and Duorui Wang and Shihao Bai and Shuo Wang and Yajun Gao and Yu Liang and Yuqing Ma and Xianglong Liu},
  doi          = {10.1016/j.patcog.2025.111415},
  journal      = {Pattern Recognition},
  month        = {8},
  pages        = {111415},
  shortjournal = {Pattern Recognition},
  title        = {Inversed pyramid network with spatial-adapted and task-oriented tuning for few-shot learning},
  volume       = {164},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="ras---12">RAS - 12</h2>
<ul>
<li><details>
<summary>
(2025). Development of a soft gripper for replicating human grasps
in forest nursery tasks. <em>RAS</em>, <em>189</em>, 104987. (<a
href="https://doi.org/10.1016/j.robot.2025.104987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to automate labour-intensive tasks in forest nurseries by developing a soft gripper that mimics human workers&#39; grasps to perform the singulation and sorting of tree saplings. By analysing human workers and conducting experimental investigations, the required grasp types and grip forces were identified. The Fin Ray Effect (FRE) structure, noted for its adaptability to asymmetric shapes, was chosen as the gripper&#39;s basis. However, modifications were necessary to achieve the required power and pinch grasp types and to provide the desired grip forces. Simulation analysis explored various beam configurations and boundary conditions of FRE fingers, resulting in a proposed modified design. Experimental investigations confirmed that the proposed gripper effectively delivered required grasps and grip forces. The new design enabled three additional grasp types for FRE grippers and increased grip forces by over 200 %. This gripper design is suitable for industrial pick-and-place applications where precise pinching grasp and various power grasps with sufficient payload capacity are needed.},
  archive      = {J_RAS},
  author       = {Mohammad Sheikh Sofla and Hanita Golshanian and Elizabeth I. Sklar and Marcello Calisti},
  doi          = {10.1016/j.robot.2025.104987},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104987},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Development of a soft gripper for replicating human grasps in forest nursery tasks},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online optimization enhanced closed-loop control of
multi-section continuum robots. <em>RAS</em>, <em>189</em>, 104986. (<a
href="https://doi.org/10.1016/j.robot.2025.104986">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent characteristics of continuum robots (high flexibility, multiple degrees of freedom), controlling the continuum robots safely and precisely in practical applications has always been a challenging task. In this paper,a real-time kinematic closed-loop controller that optimizes the step length to boost control performance is proposed. Initially, a differential-based generalized inverse kinematics solution is formulated to resolve the DOF coupling in twin-pivot continuum robots that intertwined two DOFs in one joint. Subsequently, an adaptive online optimization strategy utilizing the algorithm of Particle Swarm Optimization (PSO) is proposed to refine the controller, overcoming the limitations of traditional Jacobian-based approaches. This novel method innovatively decouples control direction and step length, optimizing safety and efficiency. Comparative simulations and tracking tests confirm the controller&#39;s superior precision and efficiency, with an average accuracy of 0.33 %, a 35 % enhancement over the Jacobian controller, thus facilitating the broader application of multi-section continuum robots.},
  archive      = {J_RAS},
  author       = {Laihao Yang and Yi Zheng and Yu Sun and Xuefeng Chen},
  doi          = {10.1016/j.robot.2025.104986},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104986},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Online optimization enhanced closed-loop control of multi-section continuum robots},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient nonlinear model predictive control for
formation-containment of multi-mobile robot systems. <em>RAS</em>,
<em>189</em>, 104983. (<a
href="https://doi.org/10.1016/j.robot.2025.104983">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on resilient nonlinear model predictive control (NMPC) for the formation containment of multiple nonholonomic mobile robots in the presence of Denial-of-Service (DoS) attacks. The proposed strategy addresses obstacle and collision avoidance between agents by defining a safe circular region for each agent. The scenario-based cost function of NMPC encompasses terms dedicated to achieving the desired formation by leaders, converging the states of followers to the convex hull spanned by leaders, and minimizing control efforts. Utilizing an acknowledgment-based packet transmission strategy, coupled with a buffer mechanism on the actuator side, alleviates the impact of control signal absence during DoS attacks on the controller-to-actuator (C-A) channel. As a Lyapunov-based approach, the contractive constraint in MPC is employed to establish the stability of Multi-Robot Systems (MRS) throughout the mission. A search and rescue application, utilized as a simulation case study, verifies the proposed method’s usefulness and efficiency. Moreover, In the evaluation of real-time implementation, the proposed scheme was validated through a laboratory-based experiment involving a customized mobile robot and low-cost hardware-in-the-loop (HIL) agents based on Raspberry Pi.},
  archive      = {J_RAS},
  author       = {Alireza Kazemi and Iman Sharifi},
  doi          = {10.1016/j.robot.2025.104983},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104983},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Resilient nonlinear model predictive control for formation-containment of multi-mobile robot systems},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal path planning for unmanned aerial vehicles with
multiple round-trip flights in coverage tasks. <em>RAS</em>,
<em>189</em>, 104970. (<a
href="https://doi.org/10.1016/j.robot.2025.104970">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As high-tech equipment for rescue and relief, unmanned aerial vehicles (UAVs) are widely used in remote relief operations during disasters, significantly improving the efficiency of rescue efforts. However, one significant challenge of UAVs is the limitation of their onboard battery, which prohibits them from completing coverage tasks in a single journey, requiring multiple round-trip flights and frequent battery charging or replacement. As a result, it will greatly prolong the task time. To improve the efficiency of coverage tasks, we allocate task points reasonably to minimize the coverage rounds, and carry out path planning to optimize the travel time of each UAV. This study first formulates a path planning model with the optimization objective of minimizing the overall task time. Then, a task allocation strategy is designed based on the priority of task points, including a max-weight allocation scheme for special scenarios with absolute priority rules and a min-delay allocation scheme for general scenarios with relative priority rules. To optimize the paths of UAVs, we further develop an improved beetle antennae search algorithm based on mutation operations (MBAS). The performance of the developed integrated methods is finally tested through simulation, yielding good results. Source code of the algorithm can be found at https://github.com/lijing0966/MBAS.git .},
  archive      = {J_RAS},
  author       = {Jing Li and Yonghua Xiong and Jinhua She and Anjun Yu},
  doi          = {10.1016/j.robot.2025.104970},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104970},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Optimal path planning for unmanned aerial vehicles with multiple round-trip flights in coverage tasks},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive bézier curve-based path following control for
autonomous driving robots. <em>RAS</em>, <em>189</em>, 104969. (<a
href="https://doi.org/10.1016/j.robot.2025.104969">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a concise and efficient path-following strategy, along with a set of real robot experiments to evaluate its superior performance. The following trajectory is generated in the form of a quartic Bézier curve with an adaptive control point generation method based on the integral length and curvature of the reference path. An impressive merit is that the cutting-corner problem during sharp turns can be avoided and smooth speed regulation can be achieved automatically. Another advantage is that the robot can quickly return to the reference path from a large lateral position or heading deviation, without any large space requirement for adjustment. The first few commands derived from the differentiation of the following trajectory are utilized. Simulation results show that the proposed method has a higher accuracy under the same-level computation time compared with other simple geometric methods . Real-world robot experiments are conducted in various environments to verify the proposed algorithm&#39;s accuracy, robustness, and flexibility. The average path-following error of real-world experiments is under 0.1 m, even with sudden path changing for obstacle avoidance. Additionally, with the proposed algorithm, the robot can navigate safely in a residential community where frequent pedestrian incursions occur.},
  archive      = {J_RAS},
  author       = {Li An and Xiuwei Huang and Peng Yang and Zhen Liu},
  doi          = {10.1016/j.robot.2025.104969},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104969},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Adaptive bézier curve-based path following control for autonomous driving robots},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Model predictive variable impedance control towards safe
robotic interaction in unknown disturbance-rich environments.
<em>RAS</em>, <em>189</em>, 104961. (<a
href="https://doi.org/10.1016/j.robot.2025.104961">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic systems have evolved to handle various significant interaction tasks in different environments. Under these conditions, the involvement of humans in the environment drastically complicates such interaction tasks; as the safety of humans should be prioritized while seeking to achieve the desired task aim. It is thus paramount that appropriate developments should be pursued with specific considerations for such safety-performance-balanced interaction tasks on unknown soft environments (e.g., humans). Towards this end, we present an adaptive robust, and passive control scheme based on model predictive control and variable impedance control that addresses this challenge. Under this control scheme, during robotic interaction tasks with complex environments (e.g., humans), the presented development and design incorporate safety thresholds that are carefully satisfied via impedance adaptation, and realized by a safety-related mode-switching mechanism. Once the safety thresholds are satisfied, task performance is then focused on. Additionally, a real-time adaptive robust parameter estimator is designed and utilized to estimate the environment contact model for the model predictive control, and thus this control scheme is robust against disturbances (e.g., which would invariably arise from the inevitable small bounded human motions) during the interaction tasks. Finally, the key safety and performance attainments of the proposed control scheme are verified via experiments. The experiments are conducted on two silicone rubber models and a human arm. These show that the proposed control scheme effectively outperformed various currently available control schemes in these interaction tasks with unknown environment contact models, and bounded but unpredictable environment position shifts, such as in robotic ultrasound scanning applications.},
  archive      = {J_RAS},
  author       = {Junyuan Xue and Wenyu Liang and Yan Wu and Tong Heng Lee},
  doi          = {10.1016/j.robot.2025.104961},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104961},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Model predictive variable impedance control towards safe robotic interaction in unknown disturbance-rich environments},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sli-EfficientDet: A slimming and efficient water surface
object detection model. <em>RAS</em>, <em>189</em>, 104960. (<a
href="https://doi.org/10.1016/j.robot.2025.104960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of water surface object detection, deep learning technology has become a mainstream method. Unmanned Surface Vehicles (USVs), which perform precise sensing and measurement tasks on water surfaces, particularly benefit from these advancements. However, for hardware resource-constrained USVs, current detection models still struggle to find a balance between being lightweight and maintaining accuracy. To address this challenge, we first reduce parameters by clipping channels in the backbone network through a dependency graph based pruning method. Additionally, we introduce the Simple Attention Module (SimAM) into the backbone network to derive excellent three-dimensional attention weights without adding additional parameters during computation. Furthermore, we utilize the ghost module to reconstruct the feature fusion network by using simple linear operations to process feature maps, which enhances the network performance in feature extraction while further compressing the model. Experiments show that our model achieves a 15.56 % improvement in mean Average Precision (mAP) while reducing the count of model parameters by 55 % compared to the original EfficientDet-D0 model, and balancing lightweight and accuracy compared to the majority of current models.},
  archive      = {J_RAS},
  author       = {Sai Ma and Zhibin Xie and Changbin Shao and Xin Shu and Peiyu Yan},
  doi          = {10.1016/j.robot.2025.104960},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104960},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Sli-EfficientDet: A slimming and efficient water surface object detection model},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A combined learning and optimization framework to transfer
human whole-body loco-manipulation skills to mobile manipulators.
<em>RAS</em>, <em>189</em>, 104958. (<a
href="https://doi.org/10.1016/j.robot.2025.104958">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans’ ability to smoothly switch between locomotion and manipulation is a remarkable feature of sensorimotor coordination. Learning and replicating such human-like strategies can lead to the development of more sophisticated robots capable of performing complex whole-body tasks in real-world environments. To this end, this paper proposes a combined learning and optimization framework for transferring human loco-manipulation soft-switching skills to mobile manipulators. The methodology starts with data collection of human demonstrations for locomotion-integrated manipulation tasks through a vision system. Next, the wrist and pelvis motions are mapped to the mobile manipulators’ End-Effector (EE) and mobile base. A kernelized movement primitive algorithm learns the wrist and pelvis trajectories and generalizes them to new desired points according to task requirements. Then, the reference trajectories are sent to a hierarchical quadratic programming controller, where the EE and the mobile base reference trajectories are provided as the first and second priority tasks, respectively, generating the feasible and optimal joint level commands. Locomotion-integrated pick-and-place and door opening tasks have been chosen to validate the proposed approach. After a human demonstrates the two tasks, a mobile manipulator executes them with the same and new settings. The results showed that the proposed approach successfully transfers and generalizes the human loco-manipulation skills to mobile manipulators, even with different geometry.},
  archive      = {J_RAS},
  author       = {Jianzhuang Zhao and Francesco Tassi and Yanlong Huang and Elena De Momi and Arash Ajoudani},
  doi          = {10.1016/j.robot.2025.104958},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104958},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A combined learning and optimization framework to transfer human whole-body loco-manipulation skills to mobile manipulators},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A feasibility-driven MPC scheme for robust gait generation
in humanoids. <em>RAS</em>, <em>189</em>, 104957. (<a
href="https://doi.org/10.1016/j.robot.2025.104957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Robust Intrinsically Stable Model Predictive Control (RIS-MPC) framework for humanoid gait generation, which realizes as closely as possible a predefined sequence of footsteps in the presence of both persistent and impulsive perturbations. The MPC-based controller has two modes of operations, each involving a Quadratic Program. Since perturbations act by modifying the state, as well as the feasibility region itself, the fundamental idea is to select in real time the operation mode based on the feasibility properties of the current state. In standard mode , footsteps are regarded as fixed and the MPC computes a Center of Mass (CoM) and a Zero Moment Point (ZMP) trajectory. Robustness is ensured by a robust stability constraint which uses a disturbance estimate and by restricted ZMP constraints along the control horizon. In the presence of strong perturbations, that violate the aforementioned conditions, the system switches to recovery mode , in which footsteps positions and timings can be modified in order to recover feasibility. We analyze the feasibility of both modes of operation and provide conditions for recursive feasibility of the standard mode. Simulations on an HRP-4 robot as well as experiments on NAO and OP3 are provided to validate the scheme.},
  archive      = {J_RAS},
  author       = {Nicola Scianca and Filippo M. Smaldone and Leonardo Lanari and Giuseppe Oriolo},
  doi          = {10.1016/j.robot.2025.104957},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104957},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A feasibility-driven MPC scheme for robust gait generation in humanoids},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based optimal formation control of
multiple robotic rollers in cooperative rolling compaction.
<em>RAS</em>, <em>189</em>, 104947. (<a
href="https://doi.org/10.1016/j.robot.2025.104947">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the sake of enhancing the rolling compaction quality and operation efficiency in infrastructure construction, this paper addresses the issue of optimal formation control for cooperative rolling compaction of a group of robotic rollers (RRs) by a combination of the reinforcement learning (RL)-based tracking control technique and the virtual structure method. The RR’s kinematic model is first established by fully considering the structural characteristics of the active revolute joint. Via the kinematic model and the virtual structure method, formation control of multiple RRs is formulated as path-following control with respect to their corresponding node in the desired rolling compaction formation shape. Then, optimal formation control policies of RRs are derived by the value functional that is the solution to tracking Hamilton–Jacobi-Bellman equation. By resorting to the RL-based tracking control, approximate optimal control policies are obtained by forward-in-time online neural network estimation of the value functional. Locally uniform ultimate boundedness of the closed-loop formation error system is analyzed rigorously by the Lyapunov technique. Finally, numerical simulation results are presented for three-RR cooperative rolling compaction of a clay core wall dam in Qianping reservoir to show the effectiveness of the main results of this paper.},
  archive      = {J_RAS},
  author       = {Yong-Hang Wei and Jun-Wei Wang and Qinglong Zhang},
  doi          = {10.1016/j.robot.2025.104947},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104947},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Reinforcement learning-based optimal formation control of multiple robotic rollers in cooperative rolling compaction},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A task and motion planning framework using iteratively
deepened AND/OR graph networks. <em>RAS</em>, <em>189</em>, 104943. (<a
href="https://doi.org/10.1016/j.robot.2025.104943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present an approach for integrated task and motion planning based on an AND/OR graph network, which is used to represent task-level states and actions, and we leverage it to implement different classes of task and motion planning problems (TAMP). Several problems that fall under task and motion planning do not have a predetermined number of sub-tasks to achieve a goal. For example, while retrieving a target object from a cluttered workspace, in principle the number of object re-arrangements required to finally grasp it cannot be known ahead of time. To address this challenge, and in contrast to traditional planners, also those based on AND/OR graphs, we grow the AND/OR graph at run-time by progressively adding sub-graphs until grasping the target object becomes feasible, which yields a network of AND/OR graphs. The approach is extended to enable multi-robot task and motion planning, and (i) it allows us to perform task allocation while coordinating the activity of a given number of robots, and (ii) can handle multi-robot tasks involving an a priori unknown number of sub-tasks. The approach is evaluated and validated both in simulation and with a real dual-arm robot manipulator, that is, Baxter from Rethink Robotics. In particular, for the single-robot task and motion planning, we validated our approach in three different TAMP domains. Furthermore, we also use three different robots for simulation, namely, Baxter, Franka Emika Panda manipulators, and a PR2 robot. Experiments show that our approach can be readily scaled to scenarios with many objects and robots, and is capable of handling different classes of TAMP problems.},
  archive      = {J_RAS},
  author       = {Hossein Karami and Antony Thomas and Fulvio Mastrogiovanni},
  doi          = {10.1016/j.robot.2025.104943},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104943},
  shortjournal = {Robot. Auton. Syst.},
  title        = {A task and motion planning framework using iteratively deepened AND/OR graph networks},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging motion perceptibility and deep reinforcement
learning for visual control of nonholonomic mobile robots. <em>RAS</em>,
<em>189</em>, 104920. (<a
href="https://doi.org/10.1016/j.robot.2025.104920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a novel deep reinforcement learning framework to tackle the problem of visual servoing of nonholonomic mobile robots. The visual control of nonholonomic mobile robots becomes particularly challenging within the classical paradigm of visual servoing, mainly due to motion and visibility constraints, which makes it impossible to reach a given desired pose for certain configurations without losing essential visual information from the camera field of view. Previous work has demonstrated the effectiveness of deep reinforcement learning in addressing various vision-based robotics tasks. In light of this, we propose a framework that integrates deep recurrent policies, intrinsic motivation, and a novel auxiliary task that leverages the interaction matrix, the core of classical visual servoing approaches, to address the problem of vision-based control of nonholonomic robotic systems. Firstly, we analyze the influence of the nonholonomic constraints on control policy learning. Subsequently, we validate and evaluate our approach in both simulated and real-world environments. Our approach exhibits an emergent control behavior that enables the robot to accurately attain the desired pose while maintaining the desired visual content within the camera’s field of view. The proposed method outperforms the state-of-the-art approaches, demonstrating its effectiveness, robustness, and accuracy.},
  archive      = {J_RAS},
  author       = {Takieddine Soualhi and Nathan Crombez and Alexandre Lombard and Yassine Ruichek and Stéphane Galland},
  doi          = {10.1016/j.robot.2025.104920},
  journal      = {Robotics and Autonomous Systems},
  month        = {7},
  pages        = {104920},
  shortjournal = {Robot. Auton. Syst.},
  title        = {Leveraging motion perceptibility and deep reinforcement learning for visual control of nonholonomic mobile robots},
  volume       = {189},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="spa---13">SPA - 13</h2>
<ul>
<li><details>
<summary>
(2025). A lower bound for pc in range-r bond percolation in four,
five and six dimensions. <em>SPA</em>, <em>185</em>, 104637. (<a
href="https://doi.org/10.1016/j.spa.2025.104637">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the range- R bond percolation in d = 4 , 5 , 6 , we obtain a lower bound for the critical probability p c for R large, agreeing with the conjectured asymptotics and thus complementing the corresponding results of Van der Hofstad and Sakai (2005) for d &gt; 6 , and Frei and Perkins (2016), Hong (2023) for d ≤ 3 . The lower bound proof is completed by showing the extinction of the associated SIR epidemic model. To prove the extinction of the SIR epidemics, we introduce a refined model of the branching random walk, called a self-avoiding branching random walk, whose total range dominates that of the SIR epidemic process.},
  archive      = {J_SPA},
  author       = {Jieliang Hong},
  doi          = {10.1016/j.spa.2025.104637},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104637},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {A lower bound for pc in range-R bond percolation in four, five and six dimensions},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Symmetric KL-divergence by stein’s method. <em>SPA</em>,
<em>185</em>, 104635. (<a
href="https://doi.org/10.1016/j.spa.2025.104635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the symmetric KL-divergence between the sum of independent variables and a Gaussian distribution, and obtain a convergence rate of order O ln n n . The proof is based on Stein’s method. The convergence rate of order O 1 n and O 1 n are also obtained under higher moment condition.},
  archive      = {J_SPA},
  author       = {Liu-Quan Yao and Song-Hao Liu},
  doi          = {10.1016/j.spa.2025.104635},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104635},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Symmetric KL-divergence by stein’s method},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence of the open WASEP stationary measure without
liggett’s condition. <em>SPA</em>, <em>185</em>, 104634. (<a
href="https://doi.org/10.1016/j.spa.2025.104634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate that Liggett’s condition can be relaxed without disrupting the convergence of open ASEP stationary measures to the open KPZ stationary measure. This is equivalent to demonstrating that, under weak asymmetry scaling and appropriate scaling of time and space, the four-parameter Askey–Wilson process converges to a two-parameter continuous dual Hahn process. We conjecture that the convergence of the open ASEP height function process to solutions to the open KPZ equation will hold for a wider range of ASEP parameters than those permitted by Liggett’s condition.},
  archive      = {J_SPA},
  author       = {Zoe Himwich},
  doi          = {10.1016/j.spa.2025.104634},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104634},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Convergence of the open WASEP stationary measure without liggett’s condition},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A benamou–brenier formula for transport distances between
stationary random measures. <em>SPA</em>, <em>185</em>, 104633. (<a
href="https://doi.org/10.1016/j.spa.2025.104633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We derive a Benamou–Brenier type dynamical formulation for the Kantorovich–Wasserstein extended metric W p between stationary random measures recently introduced in Erbar et al., (2024). A key step is a reformulation of the extended metric W p using Palm probabilities.},
  archive      = {J_SPA},
  author       = {Martin Huesmann and Bastian Müller},
  doi          = {10.1016/j.spa.2025.104633},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104633},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {A Benamou–Brenier formula for transport distances between stationary random measures},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial divisibility of random sets. <em>SPA</em>,
<em>185</em>, 104632. (<a
href="https://doi.org/10.1016/j.spa.2025.104632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we ask the following question: Let V X be the void functional of a random closed set X . For which α &gt; 0 is V X α a void functional? We answer this question when X is a random subset of a finite set. The result is then generalized to exponents which preserve complete monotonicity of functions on finite lattices. Also, we study the question of approximating an m -divisible random set by infinitely divisible random sets. We prove a theorem analogous to that of Arak’s classical result (Arak, 1981, 1982) on approximating an m -divisible random variable by infinitely divisible random variables.},
  archive      = {J_SPA},
  author       = {Jnaneshwar Baslingker and Biltu Dan},
  doi          = {10.1016/j.spa.2025.104632},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104632},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Partial divisibility of random sets},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotics for irregularly observed long memory processes.
<em>SPA</em>, <em>185</em>, 104631. (<a
href="https://doi.org/10.1016/j.spa.2025.104631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the effect of observing a long-memory stationary process at irregular time points via a renewal process. We establish a sharp difference in the asymptotic behaviour of the self-normalized sample mean of the observed process depending on the renewal process. In particular, we show that if the renewal process has a moderate heavy-tail distribution, then the limit is a so-called Normal Variance Mixture (NVM) and we characterize the randomized variance part of the limiting NVM as an integral function of a Lévy stable motion. Otherwise, the normalized sample mean will be asymptotically normal.},
  archive      = {J_SPA},
  author       = {Mohamedou Ould Haye and Anne Philippe},
  doi          = {10.1016/j.spa.2025.104631},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104631},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Asymptotics for irregularly observed long memory processes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On a class of exponential changes of measure for stochastic
PDEs. <em>SPA</em>, <em>185</em>, 104630. (<a
href="https://doi.org/10.1016/j.spa.2025.104630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a mild solution X to a semilinear stochastic partial differential equation (SPDE), we consider an exponential change of measure based on its infinitesimal generator L , defined in the topology of bounded pointwise convergence. The changed measure P h depends on the choice of a function h in the domain of L . In our main result, we derive conditions on h for which the change of measure is of Girsanov-type. The process X under P h is then shown to be a mild solution to another SPDE with an extra additive drift-term. We illustrate how different choices of h impact the law of X under P h in selected applications. These include the derivation of an infinite-dimensional diffusion bridge as well as the introduction of guided processes for SPDEs, generalizing results known for finite-dimensional diffusion processes to the infinite-dimensional case.},
  archive      = {J_SPA},
  author       = {Thorben Pieper-Sethmacher and Frank van der Meulen and Aad van der Vaart},
  doi          = {10.1016/j.spa.2025.104630},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104630},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {On a class of exponential changes of measure for stochastic PDEs},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Preventing finite-time blowup in a constrained potential for
reaction–diffusion equations. <em>SPA</em>, <em>185</em>, 104627. (<a
href="https://doi.org/10.1016/j.spa.2025.104627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We examine stochastic reaction–diffusion equations of the form ∂ u ∂ t = A u ( t , x ) + f ( u ( t , x ) ) + σ ( u ( t , x ) ) W ̇ ( t , x ) on a bounded spatial domain D ⊂ R d , where f models a constrained, dissipative force that keeps solutions between − 1 and 1. To model this, we assume that f ( u ) , σ ( u ) are unbounded as u approaches ± 1 . We identify sufficient conditions on the growth rates of f and σ that guarantee solutions to not escape this bounded set.},
  archive      = {J_SPA},
  author       = {John Ivanhoe and Michael Salins},
  doi          = {10.1016/j.spa.2025.104627},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104627},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Preventing finite-time blowup in a constrained potential for reaction–diffusion equations},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Expected hitting time estimates on finite graphs.
<em>SPA</em>, <em>185</em>, 104626. (<a
href="https://doi.org/10.1016/j.spa.2025.104626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expected hitting time from vertex a to vertex b , H ( a , b ) , is the expected value of the time it takes a random walk starting at a to reach b . In this paper, we give estimates for H ( a , b ) when the distance between a and b is comparable to the diameter of the graph, and the graph satisfies a Harnack condition. We show that, in such cases, H ( a , b ) can be estimated in terms of the volumes of balls around b . Using our results, we estimate H ( a , b ) on various graphs, such as rectangular tori, some convex traces in Z d , and fractal graphs. Our proofs use heat kernel estimates.},
  archive      = {J_SPA},
  author       = {Laurent Saloff-Coste and Yuwen Wang},
  doi          = {10.1016/j.spa.2025.104626},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104626},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Expected hitting time estimates on finite graphs},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On strong solutions of time inhomogeneous itô’s equations
with morrey diffusion gradient and drift. A supercritical case.
<em>SPA</em>, <em>185</em>, 104619. (<a
href="https://doi.org/10.1016/j.spa.2025.104619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We prove the existence of strong solutions of Itô’s stochastic time dependent equations with irregular diffusion and drift terms of Morrey spaces. Strong uniqueness is also discussed. The results are new even if there is no drift.},
  archive      = {J_SPA},
  author       = {N.V. Krylov},
  doi          = {10.1016/j.spa.2025.104619},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104619},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {On strong solutions of time inhomogeneous itô’s equations with morrey diffusion gradient and drift. a supercritical case},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Averaging principle for slow–fast systems of stochastic PDEs
with rough coefficients. <em>SPA</em>, <em>185</em>, 104618. (<a
href="https://doi.org/10.1016/j.spa.2025.104618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper examines a class of slow–fast systems of stochastic partial differential equations in which the nonlinearity in the slow equation is unbounded and discontinuous. We establish conditions that guarantee the existence of a martingale solution, and we demonstrate that the laws of the slow motions are tight, with any of their limiting points serving as a martingale solution for an appropriate averaged equation. Our findings have particular relevance for systems of stochastic reaction–diffusion equations, where the reaction term in the slow equation is only continuous and has arbitrary polynomial growth.},
  archive      = {J_SPA},
  author       = {Sandra Cerrai and Yichun Zhu},
  doi          = {10.1016/j.spa.2025.104618},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104618},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Averaging principle for slow–fast systems of stochastic PDEs with rough coefficients},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fluctuations of omega-killed level-dependent spectrally
negative lévy processes. <em>SPA</em>, <em>185</em>, 104617. (<a
href="https://doi.org/10.1016/j.spa.2025.104617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we solve exit problems for a level-dependent Lévy process which is exponentially killed with a killing intensity that depends on the present state of the process. Moreover, we analyse the respective resolvents. All identities are given in terms of new generalisations of scale functions (counterparts of the scale function from the theory of Lévy processes), which are solutions of Volterra integral equations. Furthermore, we obtain similar results for the reflected level-dependent Lévy processes. The existence of the solution of the stochastic differential equation for reflected level-dependent Lévy processes is also discussed. Finally, to illustrate our result, the probability of bankruptcy is obtained for an insurance risk process.},
  archive      = {J_SPA},
  author       = {Zbigniew Palmowski and Meral Şimşek and Apostolos D. Papaioannou},
  doi          = {10.1016/j.spa.2025.104617},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104617},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Fluctuations of omega-killed level-dependent spectrally negative lévy processes},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intersections of poisson k-flats in hyperbolic space:
Completing the picture. <em>SPA</em>, <em>185</em>, 104613. (<a
href="https://doi.org/10.1016/j.spa.2025.104613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Let η be an isometry invariant Poisson process of k -flats, 0 ≤ k ≤ d − 1 , in d -dimensional hyperbolic space. For d − m ( d − k ) ≥ 0 , the m -th order intersection process of η consists of all nonempty intersections of distinct flats E 1 , … , E m ∈ η . Of particular interest is the total volume F r ( m ) of this intersection process in a ball of radius r . For 2 k &gt; d + 1 , we determine the asymptotic distribution of F r ( m ) , as r → ∞ , previously known only for m = 1 , and derive rates of convergence in the Kolmogorov distance. Properties of the non-Gaussian limit distribution are discussed. We further study the asymptotic covariance matrix of the vector ( F r ( 1 ) , … , F r ( m ) ) ⊤ .},
  archive      = {J_SPA},
  author       = {Tillmann Bühler and Daniel Hug},
  doi          = {10.1016/j.spa.2025.104613},
  journal      = {Stochastic Processes and Their Applications},
  month        = {7},
  pages        = {104613},
  shortjournal = {Stoch. Proc. Appl.},
  title        = {Intersections of poisson k-flats in hyperbolic space: Completing the picture},
  volume       = {185},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="swevo---51">SWEVO - 51</h2>
<ul>
<li><details>
<summary>
(2025). An improved NSGA-II algorithm based on reinforcement
learning for aircraft moving assembly line integration optimization
problem. <em>SWEVO</em>, <em>94</em>, 101911. (<a
href="https://doi.org/10.1016/j.swevo.2025.101911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the aircraft moving assembly line, the focus of the assembly line balancing problem is to balance the workload in each workstation, the scheduling of aircraft assembly lines must consider the parallel relationship between assembly tasks and meet supply constraints. The aircraft moving assembly line integration optimization problem integrates the aircraft assembly line balancing problem with the aircraft assembly line scheduling problem to enhance aircraft assembly efficiency. The decision involves allocating all assembly tasks to a given number of workstations, auxiliary decisions pertain to determining the start times for assembly operations and the number of operators required. The objective is to minimize the cycle time and smoothness of the assembly line while ensuring that the number of workers on the assembly line is minimized. An integer linear programming model has been established to solve the aircraft moving assembly line integration optimization problem, and a new decoding method has been designed for this problem. A Bayesian reinforcement learning-improved NSGA-II algorithm (RLINSGA-II) has been proposed. After non-dominated sorting, the population is hierarchically divided, and a selection strategy is established among individuals of different levels. Through Bayesian reinforcement learning formulas, the selection strategy undergoes continuous adjustment throughout the population iteration process, thereby enhancing the quality of offspring individuals produced by the crossover operator. Finally, five test cases of different scales were designed based on actual cases, and the proposed RLINSGA-II was compared with five multi-objective optimization algorithms. Computational experiments and a real case study reveal the superiority of our proposed approach.},
  archive      = {J_SWEVO},
  author       = {Xiaoyu Wen and Xinyu Zhang and Hao Li and Shuo Ji and Haoqi Wang and Guoyong Ye and Hongwen Xing and Siren Liu},
  doi          = {10.1016/j.swevo.2025.101911},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101911},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An improved NSGA-II algorithm based on reinforcement learning for aircraft moving assembly line integration optimization problem},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel deep self-learning method for flexible job-shop
scheduling problems with multiplicity: Deep reinforcement learning
assisted the fluid master-apprentice evolutionary algorithm.
<em>SWEVO</em>, <em>94</em>, 101907. (<a
href="https://doi.org/10.1016/j.swevo.2025.101907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s dynamic environment, companies must navigate highly competitive markets. They consistently need to implement new technologies and deliver the right product at the right time in response to customer demand. This necessitates a high level of adaptability and efficiency in their manufacturing processes. Flexible job-shops offer a more efficient alternative to traditional manufacturing practices by accommodating these needs. Additionally, in actual manufacturing plants, multiple jobs are typically required for each part type. To address this complexity, this article investigates the flexible job-shop scheduling problem with multiplicity (MFJSP). We propose a deep self-learning method based on deep reinforcement learning and fluid master-apprentice evolutionary algorithm (DSLFMAE) to minimize makespan for the MFJSP. The proposed DSLFMAE is the integration of a fluid master-apprentice evolutionary (FMAE) algorithm and a proximal policy optimization (PPO) algorithm. The FMAE algorithm serves as the core optimization method, employing the PPO algorithm to dynamically adjust the control parameters of the FMAE algorithm during the optimization process. Twelve state features are extracted to capture the evolutionary states of the FMAE algorithm accurately, and a long short-term memory Q-network (LSTM-Q) is designed to encode these continuous states. Subsequently, to adjust multiple interrelated control parameters of the FMAE algorithm simultaneously, a multivariate Gaussian distribution-based PPO algorithm is developed to train the LSTM-Q network. Numerical outcomes show the efficacy and superiority of the DSLFMAE in addressing the flexible job-shop scheduling problem with multiplicity (MFJSP) across different scales.},
  archive      = {J_SWEVO},
  author       = {Linshan Ding and Dan Luo and Rauf Mudassar and Lei Yue and Leilei Meng},
  doi          = {10.1016/j.swevo.2025.101907},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101907},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A novel deep self-learning method for flexible job-shop scheduling problems with multiplicity: Deep reinforcement learning assisted the fluid master-apprentice evolutionary algorithm},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Un-evaluated solutions may be valuable in expensive
optimization. <em>SWEVO</em>, <em>94</em>, 101905. (<a
href="https://doi.org/10.1016/j.swevo.2025.101905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expensive optimization problems (EOPs) are prevalent in real-world applications, where the evaluation of a single solution requires a significant amount of resources. In our study of surrogate-assisted evolutionary algorithms (SAEAs) in EOPs, we discovered an intriguing phenomenon. Because only a limited number of solutions are evaluated in each iteration, relying solely on these evaluated solutions for evolution can lead to reduced disparity in successive populations. This, in turn, hampers the reproduction operators’ ability to generate superior solutions, thereby reducing the algorithm’s convergence speed. To address this issue, we propose a strategic approach that incorporates high-quality, un-evaluated solutions predicted by surrogate models during the selection phase. This approach aims to improve the distribution of evaluated solutions, thereby generating a superior next generation of solutions. This work details specific implementations of this concept across various reproduction operators and validates its effectiveness using multiple surrogate models. Experimental results demonstrate that the proposed strategy significantly enhances the performance of surrogate-assisted evolutionary algorithms. Compared to mainstream SAEAs and Bayesian optimization algorithms, our approach incorporating the un-evaluated solution strategy shows a marked improvement.},
  archive      = {J_SWEVO},
  author       = {Hao Hao and Xiaoqun Zhang and Aimin Zhou},
  doi          = {10.1016/j.swevo.2025.101905},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101905},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Un-evaluated solutions may be valuable in expensive optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical multi-objective optimization for precise
performance design of closed-chain legged mechanisms. <em>SWEVO</em>,
<em>94</em>, 101904. (<a
href="https://doi.org/10.1016/j.swevo.2025.101904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decades, the performance design of closed-chain legged mechanisms (CLMs) has not been adequately addressed. Most existing design methodologies have predominantly relied on trajectory synthesis, which inadvertently prioritizes less critical performance aspects. This study proposes a hierarchical multi-objective optimization strategy to address this limitation. First, the numerical performance-trajectory mapping is derived based on a foot-ground contact model, aiming to decouple the performance characteristics. Subsequently, a hierarchical optimization strategy is employed for two types of CLM design scenarios: In trajectory shape-constrained scenarios, a coarse-to-fine optimization process, integrating Fourier descriptors, refines the design from overall shape to local features. In scenarios without trajectory shape constraints, a stepwise optimization process is proposed for reconfigurable CLMs to transition from primary motion to auxiliary motion. The robustness of the proposed design strategy is validated across three configurations and seven algorithms. The effectiveness of the proposed design strategy is verified by comparison with other existing CLM design methods. The applicability of the proposed strategy is confirmed through simulation and prototype experiments. The results demonstrate that the hierarchical strategy effectively addresses the challenges of precise performance design in CLMs. Our work provides a general framework for the CLM design and offers insights for the optimization design of other closed-chain linkages.},
  archive      = {J_SWEVO},
  author       = {Long Guo and Ying Zhang and Qi Qin and Guanjun Liu and Hanyu Chen and Yan-an Yao},
  doi          = {10.1016/j.swevo.2025.101904},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101904},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Hierarchical multi-objective optimization for precise performance design of closed-chain legged mechanisms},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-objective evolutionary algorithm based on
the correlation between objectives and constraints. <em>SWEVO</em>,
<em>94</em>, 101903. (<a
href="https://doi.org/10.1016/j.swevo.2025.101903">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many engineering optimization problems require simultaneous optimization of multiple objective functions under certain constraints, which are collectively referred to as constrained multi-objective problems (CMOPs). The crucial issue in solving CMOPs is to balance constraints and objectives. This paper proposes a constrained multi-objective evolutionary algorithm based on the correlation between objectives and constraints, termed CORCMO. CORCMO mainly comprises two stages: the learning stage and the evolving stage. The learning stage focuses on analyzing the correlation between each objective and constraints. In the evolving stage, the CMOP is decomposed into M constraint single-objective problems, which are optimized by M subpopulations cooperatively. For each subproblem, the corresponding fitness function, computed based on the correlation, is adopted to guide the evolution. Subsequently, CORCMO employs archive population update strategy to find the optimal solutions of the given CMOP. Experiments conducted on a series of benchmark problems demonstrate that CORCMO is promising to solve CMOPs.},
  archive      = {J_SWEVO},
  author       = {Jianxia Li and Ruochen Liu and Xilong Zhang and Ruinan Wang},
  doi          = {10.1016/j.swevo.2025.101903},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101903},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Constrained multi-objective evolutionary algorithm based on the correlation between objectives and constraints},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed heterogeneous flexible job-shop scheduling
problem considering automated guided vehicle transportation via improved
deep q network. <em>SWEVO</em>, <em>94</em>, 101902. (<a
href="https://doi.org/10.1016/j.swevo.2025.101902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed manufacturing has become a research hotspot in the context of economic globalization. The distributed heterogeneous flexible job-shop scheduling problem considering automated guided vehicle transportation (DHFJSP-AGV) extends the classic flexible job-shop scheduling problem (FJSP) but remains underexplored. DHFJSP-AGV involves four subproblems: assigning jobs to heterogeneous factories, scheduling jobs to machines, sequencing operations on machines and transporting jobs between machines using AGVs. Due to its complexity, this study proposes an improved deep Q network (DQN) real-time scheduling method aimed at minimizing makespan. A mixed integer linear programming model (MILP) of DHFJSP-AGV is developed and transformed into a Markov decision process (MDP). Eight general state features are extracted and normalized to represent the state space, while appropriate combination dispatching rules are selected as the action space. The state features of each scheduling point are input to the DQN, determining the factory, job, machine, and AGV for each process. Additionally, double DQN and an improved ε-greedy exploration are used to enhance the DQN. Numerical comparison experiments under different production configurations and real-world application in distributed flexible job-shop with dynamic map environment demonstrate the effectiveness and generalization capabilities of improved DQN.},
  archive      = {J_SWEVO},
  author       = {Minghai Yuan and Songwei Lu and Liang Zheng and Qi Yu and Fengque Pei and Wenbin Gu},
  doi          = {10.1016/j.swevo.2025.101902},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101902},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Distributed heterogeneous flexible job-shop scheduling problem considering automated guided vehicle transportation via improved deep q network},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A learning-based dual-population optimization algorithm for
hybrid seru system scheduling with assembly. <em>SWEVO</em>,
<em>94</em>, 101901. (<a
href="https://doi.org/10.1016/j.swevo.2025.101901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the personalized demand increases, the hybrid seru system (HSS) has emerged as an efficient production paradigm to address the volatile market and intricate production conditions due to its reconfigurability. To satisfy the actual production demands, it is common to consider multiple assembly stages in the HSS. However, the increasing complexity poses challenges for the design of scheduling optimization algorithms. In this paper, a learning-based dual-population optimization algorithm (LDPOA) is designed for the hybrid seru system scheduling problem with assembly. Based on a problem-specific decomposition paradigm, a dual-population cooperative search framework is proposed to enhance the exploration capability by focusing on different subproblem optimizations in different populations. During the evolution, a fusion strategy and filtering mechanism are designed to avoid invalid searches by allocating computing resources to more potential individuals. A learning-guided search mode selection strategy and a population communication strategy are proposed to further improve search efficiency and population diversity. Finally, the adjustment strategies are proposed to improve the solution quality by leveraging problem knowledge. Extensive experiments are conducted to assess the performance of the LDPOA. The comparisons show that the HSS can improve production efficiency by 35.3 % compared to the traditional manufacturing mode.},
  archive      = {J_SWEVO},
  author       = {Yuting Wu and Ling Wang and Rui Li and Yuxiang Xu and Jie Zheng},
  doi          = {10.1016/j.swevo.2025.101901},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101901},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A learning-based dual-population optimization algorithm for hybrid seru system scheduling with assembly},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parking vehicle-assisted task offloading in edge computing:
A dynamic multi-objective evolutionary algorithm with multi-strategy
fusion response. <em>SWEVO</em>, <em>94</em>, 101900. (<a
href="https://doi.org/10.1016/j.swevo.2025.101900">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle-edge computing, as a promising paradigm, is employed to support applications that require low latency and high computational capability. In this study, we consider the idle resources of the surrounding parked vehicles (PVs) and roadside units (RSUs) as service providers to enhance the performance of User Equipment (UE). We propose a joint offloading architecture that uses parked vehicles. Additionally, owing to the dynamic and uncertain nature of the environment, we model computation offloading as a dynamic multi-objective optimization problem to simultaneously optimize the latency and energy consumption of UE applications. In this study, we propose a dynamic multi-objective evolutionary algorithm with a multi-strategy fusion response (DMOEA/D-MSFR). Specifically, we introduce a population center positioning strategy and a learnable prediction mechanism using Long Short-Term Memory (LSTM) in DMOEA-MSFR, which divides the prediction optimization process into two stages and exhibits a rapid response to environmental changes. In the static optimization phase, an adaptive weight vector adjustment strategy is employed, which significantly aids in the distribution and diversity of the solutions. Comprehensive experiments demonstrate that our proposed framework balances the trade-off between latency and energy consumption, and the convergence, feasibility, and diversity of the non-dominated solutions obtained.},
  archive      = {J_SWEVO},
  author       = {Yingbo Zhou and Zheng-Yi Chai and Ya-Lun Li and Jun-Jie Li},
  doi          = {10.1016/j.swevo.2025.101900},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101900},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Parking vehicle-assisted task offloading in edge computing: A dynamic multi-objective evolutionary algorithm with multi-strategy fusion response},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A high-dimensional feature selection algorithm via fast
dimensionality reduction and multi-objective differential evolution.
<em>SWEVO</em>, <em>94</em>, 101899. (<a
href="https://doi.org/10.1016/j.swevo.2025.101899">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-objective feature selection problem typically involves two key objectives: minimizing the number of selected features and maximizing classification performance. However, most multi-objective evolutionary algorithms (MOEAs) face challenges in high-dimensional datasets, including low search efficiency and potential loss of search space. To address these challenges, this paper proposes a hybrid algorithm based on fast dimensionality reduction and multi-objective differential evolution with redundant and preference processing (termed DR-RPMODE). In DR-RPMODE, the DR phase uses the freezing and activation operators to remove many irrelevant and redundant features in the high-dimensional datasets, thereby achieving fast dimensionality reduction. Subsequently, the RPMODE algorithm continues the search on the reduced datasets, improving the traditional differential evolutionary framework from two aspects: duplicated and redundant solutions are filtered by redundant handling, and a preference handling method that pays more attention to classification performance is designed for different preference objectives of decision-makers. In the experiment, DR-RPMODE is compared with seven feature selection algorithms on 16 classification datasets. The results indicate that DR-RPMODE outperforms the comparison algorithms on most datasets, demonstrating that it not only achieves outstanding optimization performance but also obtains good classification and scalability results.},
  archive      = {J_SWEVO},
  author       = {Xuezhi Yue and Yihang Liao and Hu Peng and Lanlan Kang and Yuan Zeng},
  doi          = {10.1016/j.swevo.2025.101899},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101899},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A high-dimensional feature selection algorithm via fast dimensionality reduction and multi-objective differential evolution},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A heuristic distributed and no-wait method for solving
multiagent task allocation problems with coupled temporal constraints.
<em>SWEVO</em>, <em>94</em>, 101898. (<a
href="https://doi.org/10.1016/j.swevo.2025.101898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal constraints, primarily arising from engagement rules and requiring tasks to be performed in a specific order, are critical in task allocation problems (TAPs). However, existing allocation methods often fall short of handling temporal constraints. This paper proposes a heuristic distributed and no-wait algorithm, called the Temporal-Constraints Performance Impact (TC-PI) algorithm, for solving multi-agent TAPs with temporal constraints. By requiring each agent either travels to or immediately executes its assigned task, the TC-PI eliminates unnecessary waiting time and effectively reduces the average task completion time . The proposed algorithm consists of three phases. Firstly, each agent sequentially adds tasks to its task list while ensuring temporal constraints are satisfied. Secondly, conflicts where multiple agents select the same task are resolved through local communication. Finally, any remaining conflicts caused by temporal constraints are further addressed. To maintain task order and minimize completion time, task significance is redefined by incorporating temporal relationships among tasks. A penalty mechanism prevents infinite task reallocation cycles, enhancing system robustness and avoiding deadlocks. Simulation results demonstrate that TC-PI effectively resolves temporal conflicts, achieves no-wait task allocations, and flexibly handles dynamic task arrivals.},
  archive      = {J_SWEVO},
  author       = {Wei Cui and Yanxiang Feng and Ye Cao and Xiaoling Li and Yikang Yang},
  doi          = {10.1016/j.swevo.2025.101898},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101898},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A heuristic distributed and no-wait method for solving multiagent task allocation problems with coupled temporal constraints},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A discrete water source cycle algorithm design for solving
production scheduling problem in flexible manufacturing systems.
<em>SWEVO</em>, <em>94</em>, 101897. (<a
href="https://doi.org/10.1016/j.swevo.2025.101897">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at solving the production scheduling problems in flexible manufacturing systems including the flexible job shop scheduling (FJSP) and distributed flexible job shop scheduling (DFJSP) with operation outsourcing, which are two kinds of typical NP-hard problems, the general mathematical model with two optimization objectives including minimizing the total costs as well as makespan are developed. Then, an innovative discrete water source cycle algorithm (IDWCA) inspired by the water cycle process is proposed to address the model. In the IDWCA, the operators including evaporation mixing, precipitation, local mixing, modification of water source composition and water source loss are designed to search for optimization solutions. Finally, 15 FJSP comparison experiments and 45 DFJSP comparison experiments with different scales are provided to verify the comprehensive performance of the IDWCA, in which the IDWCA, the original water cycle algorithm (OWCA), and the two general meta-heuristic algorithms genetic algorithm (GA) and particle swarm optimization (PSO) are involved. Compared with OWCA, GA and PSO, IDWCA performs significantly better in all FJSP experiments, while it performs better in 43 out of 45 DFJSP experiments, and its advantages are more significant in solving the medium-scale and large-scale problems. In addition, the evolutionary curves of the above algorithms indicate that the IDWCA has the better convergence speed and results than that of OWCA, GA and PSO. Therefore, the developed mathematical model and IDWCA are effective in solving the studied FJSP and DFJSP, the proposed algorithm enriches the theoretical researches on meta-heuristic algorithms and production scheduling.},
  archive      = {J_SWEVO},
  author       = {Wenxiang Xu and Shimin Xu and Junyong Liang and Tao Qin and Dezheng Liu and Lei Wang},
  doi          = {10.1016/j.swevo.2025.101897},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101897},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A discrete water source cycle algorithm design for solving production scheduling problem in flexible manufacturing systems},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online feature subset selection for mining feature streams
in big data via incremental learning and evolutionary computation.
<em>SWEVO</em>, <em>94</em>, 101896. (<a
href="https://doi.org/10.1016/j.swevo.2025.101896">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online streaming feature subset selection (OSFSS) presents a noteworthy challenge when data samples arrive rapidly and in a time-dependent manner. The complexity of this problem is further exacerbated when features arrive as a stream. Despite several attempts to solve OSFSS over feature streams, existing methods lack scalability, cannot handle interaction effects among features, and fail to efficiently handle high-velocity feature streams. To address these challenges, we propose a novel wrapper-for OSFSS named OSFSS-W (wrapper-for OSFSS), specifically designed to mine feature streams within the Apache Spark environment. Our proposed method incorporates (i) two vigilance tests: for removing (a) irrelevant features and (b) redundant features (ii) incremental learning and (iii) a tolerance-based feedback mechanism that retains and utilizes previous knowledge while adhering to the predefined tolerance thresholds. Additionally, for the purpose of optimization, we introduce a Bare Bones Particle Swarm Optimization (BBPSO-L) algorithm driven by the logistic distribution. Further, the BBPSO-L is parallelized within Apache Spark, following an island-based approach. We evaluated the performance of the proposed algorithm on the datasets taken from the cybersecurity, bioinformatics, and finance domains. The results demonstrate that incorporating two vigilance tests coupled with a tolerance-based feedback mechanism significantly improved the median Area under the receiver operating characteristic curve (AUC) and median cardinality across all datasets.},
  archive      = {J_SWEVO},
  author       = {Yelleti Vivek and Vadlamani Ravi and P. Radha Krishna},
  doi          = {10.1016/j.swevo.2025.101896},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101896},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Online feature subset selection for mining feature streams in big data via incremental learning and evolutionary computation},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Benchmarking footprints of continuous black-box optimization
algorithms: Explainable insights into algorithm success and failure.
<em>SWEVO</em>, <em>94</em>, 101895. (<a
href="https://doi.org/10.1016/j.swevo.2025.101895">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The practices for comparing black-box optimization algorithms based on performance statistics over a benchmark suite are being increasingly criticized. Critics argue that these practices fail to explain why particular algorithms outperform others. Consequently, there is a growing demand for more robust comparison methods that assess the overall efficiency of the algorithms in terms of performance and also consider the specific landscape properties of the optimization problems on which the algorithms are compared. This study introduces a novel approach for comparing algorithms based on the concept of an algorithm footprint , which aims to identify easy and challenging problem instances for a given algorithm. A unique footprint is assigned to each algorithm and then compared, to highlight problem instances where an algorithm either uniquely succeeds or falls, as well as how the algorithms complement each other across the problem instances. Our solution employs a multi-task regression model (MTR) to simultaneously link the performance of multiple algorithms with the landscape features of the problem instances. By applying an Explainable Machine Learning (XML) technique, we quantify and compare the importance of the landscape features for each algorithm. The methodology is applied to a portfolio of three different BBO algorithms, highlighting their success and failure on the Black-Box Optimization Benchmarking (BBOB) suite. The efficacy of our approach is further demonstrated through a comparative analysis with two existing algorithm comparison methods, showcasing the robustness and depth of insights provided by the proposed approach.},
  archive      = {J_SWEVO},
  author       = {Ana Nikolikj and Mario Andrés Muñoz and Tome Eftimov},
  doi          = {10.1016/j.swevo.2025.101895},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101895},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Benchmarking footprints of continuous black-box optimization algorithms: Explainable insights into algorithm success and failure},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Landscape features in single-objective continuous
optimization: Have we hit a wall in algorithm selection generalization?
<em>SWEVO</em>, <em>94</em>, 101894. (<a
href="https://doi.org/10.1016/j.swevo.2025.101894">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The process of identifying the most suitable optimization algorithm for a specific problem, referred to as algorithm selection (AS), entails training models that leverage problem landscape features to forecast algorithm performance. A significant challenge in this domain is ensuring that AS models can generalize effectively to novel, unseen problems. This study evaluates the generalizability of AS models based on different problem representations in the context of single-objective continuous optimization. In particular, it considers the most widely used Exploratory Landscape Analysis features, as well as recently proposed Topological Landscape Analysis features, and features based on deep learning, such as DeepELA, TransOptAS and Doe2Vec. Our results indicate that when presented with out-of-distribution evaluation data, none of the feature-based AS models outperform a simple baseline model, i.e., a Single Best Solver.},
  archive      = {J_SWEVO},
  author       = {Gjorgjina Cenikj and Gašper Petelin and Moritz Seiler and Nikola Cenikj and Tome Eftimov},
  doi          = {10.1016/j.swevo.2025.101894},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101894},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Landscape features in single-objective continuous optimization: Have we hit a wall in algorithm selection generalization?},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EABC-AS: Elite-driven artificial bee colony algorithm with
adaptive population scaling. <em>SWEVO</em>, <em>94</em>, 101893. (<a
href="https://doi.org/10.1016/j.swevo.2025.101893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Artificial Bee Colony Algorithm (ABC) is a widely recognized optimization algorithm known for its effectiveness. However, many variants of the ABC algorithm fail to fully leverage the potential of each population, and their inherent random search strategies often limit the algorithm’s convergence capabilities, leading to diminished performance. To address these issues, we introduce an enhanced version of the ABC algorithm, which incorporates two essential features: adaptive population scaling and an elite-driven evolutionary strategy. The adaptive population scaling mechanism dynamically adjusts the population size of each bee colony based on their respective function, and the elite-driven evolutionary strategy with external archive makes bees evolve by utilizing information from elite individuals while ensuring diversity is maintained. These two features enhance the algorithm’s convergence ability. We employ the CEC 2017 and CEC 2022 benchmarks to assess the optimization capabilities of the proposed algorithm. The experimental results indicate that the EABC-AS algorithm displays significant competitiveness relative to CEC excellent algorithms and other state-of-the-art (SOTA) algorithms.},
  archive      = {J_SWEVO},
  author       = {Ruiyang Lin and Zesong Xu and Liyang Yu and Tongquan Wei},
  doi          = {10.1016/j.swevo.2025.101893},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101893},
  shortjournal = {Swarm Evol. Comput.},
  title        = {EABC-AS: Elite-driven artificial bee colony algorithm with adaptive population scaling},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An indicator-based multi-objective evolutionary algorithm
assisted by improved graph convolutional networks. <em>SWEVO</em>,
<em>94</em>, 101892. (<a
href="https://doi.org/10.1016/j.swevo.2025.101892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph convolutional networks (GCN) have attracted significant attention due to their superior performance in handling non-Euclidean spaces, which enables GCN to model and analyze complex data structures that cannot be handled by traditional methods. Neural network-based multi-objective evolutionary algorithms (NNMOEAs) have made significant strides, predominantly focusing on mapping the decision space to the objective space, but may fail to focus on the interconnectedness of solutions within the decision space. To address this problem, this paper proposes a two-stage multi-objective optimization algorithm that utilizes graph convolutional networks to enhance population evolution. In the initial stage, the algorithm employs cosine similarity to represent the population as graph-structured data. A hypervolume-guided self-attention update mechanism is then introduced to balance exploration and exploitation, achieved by establishing an exploratory neighborhood population alongside an expanded neighborhood population. In the subsequent stage, a key node detection strategy is implemented, which considers both the global influence and local mediation roles of nodes. This strategy selects individuals with highly concentrated information to generate new solutions, thereby facilitating a thorough exploration of the solution space. The proposed algorithm is evaluated against five state-of-the-art MOEAs across five benchmark test suites and five real-world problems. The experimental results demonstrate its superior performance in addressing robust, variable linkages and imbalance mapping multi-objective optimization problems, as well as its feasibility in practical problems.},
  archive      = {J_SWEVO},
  author       = {Pengguo Yan and Ye Tian and Yu Liu},
  doi          = {10.1016/j.swevo.2025.101892},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101892},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An indicator-based multi-objective evolutionary algorithm assisted by improved graph convolutional networks},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Strengthened grey wolf optimization algorithms for numerical
optimization tasks and AutoML. <em>SWEVO</em>, <em>94</em>, 101891. (<a
href="https://doi.org/10.1016/j.swevo.2025.101891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The grey wolf optimization algorithm (GWO) is an efficient optimization technology. However, it still has some problems such as immature convergence and stagnation at local optima. In this paper, a strengthened grey wolf optimization algorithm (SGWO) is proposed based on three strengthening mechanisms: the exponential decreasing convergence factor, the elite reselection strategy in per generation and the Cauchy mutation (CM) operator. Seven variants of SGWO are designed according to different deployment modes of three reinforcement mechanisms. Experiments on thirteen numerical optimization problems are carried out to compare the differences between GWO and SGWOs. The experimental results reveal that SGWOs can significantly improve the search performance of GWO in most tasks. Among them, SGWO7 is the most successful competitor. Furthermore, several optimizers have demonstrated through comparison on engineering design problems that SGWO7 outperforms the vast majority of competitors. Subsequently, MHHO, TLBO, GWO and SGWO7 are used to build automatic machine learning (AutoML) model. The experimental results of the four methods on MNIST dataset further illustrate the advantages of SGWO7 designed in this research.},
  archive      = {J_SWEVO},
  author       = {Xuefen Chen and Chunming Ye and Yang Zhang},
  doi          = {10.1016/j.swevo.2025.101891},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101891},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Strengthened grey wolf optimization algorithms for numerical optimization tasks and AutoML},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive distance-based multi-objective particle swarm
optimization algorithm with simple position update. <em>SWEVO</em>,
<em>94</em>, 101890. (<a
href="https://doi.org/10.1016/j.swevo.2025.101890">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-objective particle swarm optimization algorithms have been widely used in science and engineering due to their advantages of fast convergence speed and easy implementation. However, the selection of globally optimal particle is an important and challenging problem in the design of multi-objective particle swarm optimization algorithms. In this regard, this paper proposes an adaptive distance-based multi-objective particle swarm optimization algorithm with simple position update, named ADMOPSO. First, an adaptive penalty-based boundary intersection (PBI) distance strategy is designed to select the globally optimal particle from two elite particles which are randomly chosen from an elite particle set. This strategy better balances the diversity and convergence requirements of particle swarm optimization algorithm in the optimization process. Second, a simple position probabilistic update strategy is constructed to rewrite the velocity update method with the weight and use the learning rate to control the scale of the updated velocity in the position update equation to avoid particle swarm falling into the local optimum. Finally, an extensive experimental study is conducted to test the performance of several selected multi-objective optimization algorithms on ZDT, WFG and DTLZ benchmark problems, as well as 7 real-world problems were conducted to test the proposed algorithm. Comparative experimental results show that the algorithm proposed in this paper has significant advantages over other algorithms. This shows that the ADMOPSO algorithm is competitive in dealing with multi-objective problems.},
  archive      = {J_SWEVO},
  author       = {Liangying Wang and Lihuan Hong and Haoxuan Fu and Zhiling Cai and Yiwen Zhong and Lijin Wang},
  doi          = {10.1016/j.swevo.2025.101890},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101890},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Adaptive distance-based multi-objective particle swarm optimization algorithm with simple position update},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Smart cities optimization using computational intelligence
in power-constrained IoT sensor networks. <em>SWEVO</em>, <em>94</em>,
101889. (<a href="https://doi.org/10.1016/j.swevo.2025.101889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the Innovative Clustering Energy Efficient Equilibrium Optimizer-based Multi-Hop Routing Protocol (ICEE-EO-MHRP) for addressing the energy constraint in Internet of Things (IoT) network clustering utilizing the Equilibrium Optimizer (EO), a yet efficient computational intelligence method that is used for selecting Designated Cluster Head (DCH) and Backup DCH (BDCH). Additionally, ICEE-EO-MHRP deals with the IoT energy problem by incorporating a novel cost function that ends up of selecting Designated Relays (DRs) and backup DRs for the purpose of forwarding the traffic towards the sink node. Our protocol substantially reduces messages’ exchanges between IoT Sensor Nodes (SNs) by making the replacement of DCH and BDCH dependent on their energy levels dropping below a threshold. To ensure a balanced communication load and efficient scheduling, an innovative deterministic distributed-time division multiple access system is employed. Not only to this extent, but we address data redundancy issue, raised among those quite adjacent SNs, and accordingly propose an efficient management that guarantees having a coherent protocol. In addition to that, device and link failures are professionally addressed by suggesting recovery mechanisms that optimize the proposed protocol. Dealing with these impairments puts our approach well ahead of the competition since it addresses the most practical issues and scenarios, particularly those with challenging environmental constraints. The simulation results demonstrate primarily that our protocol significantly improves the network lifetime by 157.83 % and 109.81 % in comparison to Particle Swarm Optimization and Tabu Search (Tabu-PSO) and Energy-Efficient CH Selection by Improved Sparrow Search Algorithm utilizing Differential Evolution (EECHS-ISSADE), respectively. Comparing ICEE-EO-MHRP to Tabu-PSO and EECHS-ISSADE reveals improvements in residual energy of 335.87 % and 230.05 %, respectively. Furthermore, in comparison to Tabu-PSO and EECHS-ISSADE, the proposed protocol optimizes the throughput by 252.36 % and 168.64 %, respectively. In terms of average delay, our protocol outperforms Tabu-PSO, EECHS-ISSADE, PEGASIS with Artificial Bee Colony (PEG-ABC), Metaheuristics Cluster-based Routing Technique for Energy-Efficient WSN (MHCRT-EEWSN), as well as Hybrid Bald Eagle Search Optimization Algorithm (HBESAOA) by improvements of 57.53 %, 55.15 %, 86.89 %, 20.52 %, and 94.60 %, respectively.},
  archive      = {J_SWEVO},
  author       = {Khalid A. Darabkh and Muna Al-Akhras},
  doi          = {10.1016/j.swevo.2025.101889},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101889},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Smart cities optimization using computational intelligence in power-constrained IoT sensor networks},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning assisted differential evolution with
adaptive resource allocation strategy for multimodal optimization
problems. <em>SWEVO</em>, <em>94</em>, 101888. (<a
href="https://doi.org/10.1016/j.swevo.2025.101888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal optimization problems (MMOPs) present the challenge of identifying multiple optimal solutions within a search space, requiring algorithms to effectively balance exploration and exploitation. To enhance solution accuracy, the local search methods often focus on elite individuals, allocating additional fitness evaluations (FEs) to refine their solutions. However, once the optima near these elite individuals are identified, continued allocation of FEs becomes inefficient, leading to a waste of limited resources. This highlights the inherent difficulty of achieving a balance between exploration and exploitation within the population under constrained resources. To solve this problem, this paper proposes a new reinforcement learning-assisted differential evolution (RLDE) algorithm with adaptive resource allocation strategy. Firstly, the exploitation population is proposed, and the original population focuses on exploring undiscovered optimal regions and generating exploitation populations, while each exploitation population focuses on finding high-precision optima within its responsible optimal region. Secondly, a reinforcement learning-assisted adaptive resource allocation (RLRA) strategy is proposed to allocate FEs, which can reduce the waste of FEs and balance the exploration and exploitation ability among multiple populations. Finally, a local greedy mutation (LGM) strategy is proposed to help individuals evolve toward the neighborhood with better fitness values. Compared with 11 state-of-the-art multimodal algorithms, the RLDE achieves better or more competitive results in all accuracy levels. Besides, the results on the dielectric composite optimization problem verify the practicality of RLDE.},
  archive      = {J_SWEVO},
  author       = {Tao Ma and Hong Zhao and Xiangqian Li and Fang Yang and Chun-sheng Liu and Jing Liu},
  doi          = {10.1016/j.swevo.2025.101888},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101888},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Reinforcement learning assisted differential evolution with adaptive resource allocation strategy for multimodal optimization problems},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning-assisted improvements in adaptive variable
neighborhood search. <em>SWEVO</em>, <em>94</em>, 101887. (<a
href="https://doi.org/10.1016/j.swevo.2025.101887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents the design and integration of novel adaptive components within the Double-Adaptive General Variable Neighborhood Search (DA-GVNS) algorithm, aimed at improving its overall efficiency. These adaptations utilize iteration-based data to refine the search process, with enhancements such as an adaptive reordering mechanism in the refinement phase and a knowledge-guided approach to adjust the search strategy. Additionally, an adaptive mechanism for dynamically controlling the shaking intensity was introduced. The proposed knowledge-guided adaptations demonstrated superior performance over the original DA-GVNS framework, with the most effective scheme selected for further evaluation. Initially, the symmetric Traveling Salesman Problem (TSP) was used as a benchmark to quantify the impact of these mechanisms, showing significant improvements through rigorous statistical analysis. A comparative study was then conducted against six advanced heuristics from the literature. Finally, the most promising knowledge-guided GVNS (KG-GVNS) was tested against the original DA-GVNS on selected instances of the Quadratic Assignment Problem (QAP), where detailed statistical analysis highlighted its competitive advantage and robustness in addressing complex combinatorial optimization problems.},
  archive      = {J_SWEVO},
  author       = {Panagiotis Karakostas and Angelo Sifaleras},
  doi          = {10.1016/j.swevo.2025.101887},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101887},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Learning-assisted improvements in adaptive variable neighborhood search},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel MINLP model and lamarckian learning-enhanced
multi-objective optimization algorithm for smart household appliance
scheduling. <em>SWEVO</em>, <em>94</em>, 101886. (<a
href="https://doi.org/10.1016/j.swevo.2025.101886">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information and communication technology, a home energy management system (HEMS) on the demand side, embedded with advanced scheduling models and optimization algorithms, has the potential to conserve energy, reduce users’ electricity costs and dissatisfaction, while ensuring the stable operation of the power grid. This paper first develops a novel mixed-integer non-linear programming (MINLP) model for the smart household appliance scheduling problem with solar energy and energy storage to minimize the total electricity consumption cost and the user dissatisfaction simultaneously over a day. Next, to the best of our knowledge, this is the first work to propose a novel Lamarckian-learning enhanced multi-objective particle swarm optimization (LLMOPSO) algorithm to solve the studied problem. To validate the effectiveness of the improved model and algorithm, comparative experiments are conducted on four case studies under different scenarios. The experimental results demonstrate that the proposed LLMOPSO outperforms the existing ones in terms of eight commonly used performance metrics, such as the number of non-dominated solutions ( ND ), the ratio of non-dominated solutions ( R nd ), the generational distance ( GD ), and the metric of diversity ( DM ). Compared to four existing optimization algorithms, our novel approach can provide better schedules for users, enabling them to manage smart household appliances in a more flexible, comfortable, and cost-effective way.},
  archive      = {J_SWEVO},
  author       = {Weidong Lei and Ziheng You and Jiawei Zhu and Pengyu Yan and Zhen Zhou and Jikun Chen},
  doi          = {10.1016/j.swevo.2025.101886},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101886},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Novel MINLP model and lamarckian learning-enhanced multi-objective optimization algorithm for smart household appliance scheduling},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-based memetic algorithm for
solving dynamic distributed green flexible job shop scheduling problem
with finite transportation resources. <em>SWEVO</em>, <em>94</em>,
101885. (<a href="https://doi.org/10.1016/j.swevo.2025.101885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the dynamic distributed green flexible job shop scheduling problem with integrated multi-automated guided vehicles (AGVs) transportation (DDGFJSP-MT), a coupled mathematical model is constructed in this study with the objective of minimizing the makespan and total carbon emissions. The complex coupled roles between factories, jobs, machines, and AGVs induced by machine breakdown are explored. Meanwhile, a deep Q-network-based dynamic efficient memetic algorithm (DQN-DEMA) is proposed to solve the problem. First, a four-layer coding is designed to characterize the DDGFJSP-MT, and a novel dynamic decoding technique is developed based on the state variations of the involved subjects and their strong coupling effects following the machine breakdown. Second, an alternating hybrid initialization strategy is employed to improve the quality and diversity of the rescheduled population. Then, several neighborhood search structures are designed based on critical path and bottleneck operation, and DQN is applied to recommend the most suitable local search operator for each elite individual, accelerating the convergence of the rescheduled population and effectively avoiding the waste of algorithmic resources. Finally, performance validation on 20 instances demonstrates that DQN-DEMA obtains the Pareto frontier with higher quality and diversity in 15 instances compared to the six state-of-the-art algorithms.},
  archive      = {J_SWEVO},
  author       = {Xinxin Zhou and Fuyu Wang and Bin Wu and Yan Li and Nannan Shen},
  doi          = {10.1016/j.swevo.2025.101885},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101885},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Deep reinforcement learning-based memetic algorithm for solving dynamic distributed green flexible job shop scheduling problem with finite transportation resources},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic quadratic decomposition-based evolutionary algorithm
for multi-objective fuzzy flexible jobshop scheduling. <em>SWEVO</em>,
<em>94</em>, 101884. (<a
href="https://doi.org/10.1016/j.swevo.2025.101884">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective Fuzzy Flexible Jobshop Scheduling Problems (MFFJSPs) have garnered widespread attention since they are able to handle the uncertainty of processing time in actual production. Nevertheless, making a good balance between the diversity and convergence of non-dominated solutions is a challenging issue that cannot be overlooked when MFFJSP is solved. To deal with these issues, this work proposes a Dynamic Quadratic Decomposition-based Multi-objective Evolutionary Algorithm (DQD-MOEA) to solve MFFJSP by minimizing makespan and total machine workload. To solve a problem that the distribution and diversity of searched non-dominant solutions are poor due to the discrete decision space and objective space of MFFJSP, it proposes a dynamic quadratic decomposition method. Its core idea is to eliminate all the failed reference vectors because they have no intersection with a real Pareto front, and ensure that solutions evolve along effective reference vectors. This work also introduces a problem-specific local search method to accelerate the solution convergence for MFFJSP. It proposes a hybrid initialization method to improve the quality of initial solutions. Finally, a series of experiments are performed and the results demonstrate that DQD-MOEA is significantly better than state-of-the-art algorithms in terms of convergence and solution diversity when solving widely-tested benchmark cases.},
  archive      = {J_SWEVO},
  author       = {XuWei Zhang and ZiYan Zhao and ShuJin Qin and ShiXin Liu and MengChu Zhou},
  doi          = {10.1016/j.swevo.2025.101884},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101884},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Dynamic quadratic decomposition-based evolutionary algorithm for multi-objective fuzzy flexible jobshop scheduling},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gaussian process regression for evolutionary dynamic
multiobjective optimization in complex environments. <em>SWEVO</em>,
<em>94</em>, 101883. (<a
href="https://doi.org/10.1016/j.swevo.2025.101883">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiobjective Evolutionary Algorithms (MOEAs) face significant challenges when addressing dynamic multiobjective optimization problems, particularly those with frequent changes. The complexity of dynamic environments makes it difficult for MOEAs to accurately approximate the true Pareto-optimal solutions before subsequent changes occur. Typically, historical approximations of Pareto-optimal solutions are utilized to predict solutions in future environments. However, existing predictors often overlook the nondeterministic nature of historical solutions, potentially compromising prediction accuracy. In this paper, we propose a novel predictor based on Gaussian Process Regression (GPR) for evolutionary dynamic multiobjective optimization. Unlike traditional deterministic predictors, our approach aims to provide a probability distribution of predicted results, thereby addressing the inherent nondeterminism of historical solutions. We employ GPR to model relationships among historical solutions across different time steps. Within the framework of the classical MOEA, MOEA/D, we introduce a new method MOEA/D-GPR for Evolutionary Dynamic Multiobjective Optimization (EDMO). Experimental results demonstrate that our method achieves state-of-the-art performance.},
  archive      = {J_SWEVO},
  author       = {Youpeng Deng and Yan Zheng and Zhaopeng Meng and Haobo Gao and Yueyang Hua and Qiangguo Jin and Leilei Cao},
  doi          = {10.1016/j.swevo.2025.101883},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101883},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Gaussian process regression for evolutionary dynamic multiobjective optimization in complex environments},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained multi-objective particle swarm optimization for
bistatic RFID network planning with distributed antennas.
<em>SWEVO</em>, <em>94</em>, 101882. (<a
href="https://doi.org/10.1016/j.swevo.2025.101882">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio Frequency Identification (RFID) network planning (RNP) is crucial for optimizing network performance by setting system parameters. The new bistatic RFID architecture with a distributed antenna system (DAS) offers advantages for the passive Internet of Things (IoT). It separates transmission and reception to minimize self-interference and extend uplink communication range, while using distributed antennas for broader coverage. Bistatic DAS RNP differs from monostatic in various aspects. Monostatic RNP focuses on factors like reader number, location, and power, while bistatic DAS RNP involves more parameters, including antenna and device numbers, locations, and interconnections. Coverage and interference are more complex, and practical planning faces constraints on antenna ports and feeder line length. Consequently, bistatic DAS RFID network planning (BDRNP) problems are novel, complex, high-dimensional, and constrained, making them relatively unexplored and highly challenging. This paper analyzes bistatic DAS RFID network coverage and interference, and proposes a mathematical model for BDRNP problems. A modified multi-objective discrete particle optimization (M2DPSO) algorithm is introduced, incorporating a modified k-means clustering method to group antennas, which ensures satisfaction constraints and reduces decision variable dimensionality from 4 | C S | + | C S | 2 to 4 | C S | to 4 | C S | where | C S | is the problem size. Redundant SDRs/carrier emitters are dynamically eliminated based on global best solution set changes. Experimental results show that M2DPSO algorithm significantly outperforms three existing popular algorithms – nondominated sorting genetic algorithm II (NSGAII), discrete particle swarm optimization (DPSO), and multi-objective evolutionary algorithm based on decomposition (MOEAD) – by 265%, 361%, and 726% respectively, in average inverted generational distance (IGD) metrics.},
  archive      = {J_SWEVO},
  author       = {Yamin Wang and Shuai Ma and Yuan Li and Hongyu Qian and Qianfan Jia and Shanpeng Xiao and Yuhong Huang},
  doi          = {10.1016/j.swevo.2025.101882},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101882},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Constrained multi-objective particle swarm optimization for bistatic RFID network planning with distributed antennas},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving sparse multi-objective optimization problems via
dynamic adaptive grouping and reward-penalty sparse strategies.
<em>SWEVO</em>, <em>94</em>, 101881. (<a
href="https://doi.org/10.1016/j.swevo.2025.101881">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse Multi-Objective Optimization Problems (SMOPs) are commonly encountered in various fields such as machine learning, signal processing, and data mining. While evolutionary algorithms have shown good performance in tackling complex problems, many algorithms tend to exhibit performance degradation when dealing with SMOPs. The primary reasons for this performance decline are the curse of dimensionality and the inability to effectively leverage the sparsity of Pareto-optimal solutions. To address this issue, this paper proposes a model method to solve sparse multi-objective optimization problems through dynamic adaptive grouping and reward-penalty sparse strategies. Specifically, to obtain more effective prior information, a sparse initialization strategy is proposed in the initialization phase. This strategy aims to incorporate more prior knowledge and information about the sparsity of Pareto-optimal solutions. In the evolutionary phase, a decision variable dynamic adaptive grouping strategy is introduced. This strategy, combined with crossover and mutation operators, guides the population towards effective sparse directions. Furthermore, to further identify zero-value decision variables in Pareto-optimal solutions, a reward-penalty mechanism is designed to update the scores of decision variables. By combining this mechanism with the adaptive grouping strategy, this method can effectively flip low-scoring decision variables to zero with a higher probability. To validate the advantages of the proposed algorithm, experiments were conducted on eight benchmark problems, with comparative experiments conducted for different initialization methods. The results indicate that our algorithm exhibits significant advantages in solving SMOPs.},
  archive      = {J_SWEVO},
  author       = {Zhenxing Yu and Qinwei Fan and Jacek M. Zurada and Jigen Peng and Haiyang Li and Jian Wang},
  doi          = {10.1016/j.swevo.2025.101881},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101881},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Solving sparse multi-objective optimization problems via dynamic adaptive grouping and reward-penalty sparse strategies},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data stream driven evolutionary algorithm for cost sensitive
robust optimization over time. <em>SWEVO</em>, <em>94</em>, 101880. (<a
href="https://doi.org/10.1016/j.swevo.2025.101880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many dynamic optimization problems in real-world domains like engineering and management science require considerations of robustness, where a balance between tracking optimal solutions in changing environments and managing costs of switching solutions is needed. However, in some cases, the objective functions are not analytically available and must be approximated based on data collected from numerical simulations or experiments. These dynamic problems are formulated as data stream driven robust optimization over time (DDROOT G ) problems, which cannot be satisfactorily addressed by existing dynamic optimization algorithms. Therefore, we propose a data stream driven multi-form evolutionary algorithm (DDMFEA), employing two separate Kriging models to approximate the unavailable objective function and the computationally expensive robustness estimation, respectively. In the proposed algorithm, DDROOT G problems are addressed with two distinct formulations with single- and multi-objectives. These formulations are utilized as a multi-form optimization process to mitigate the impact of approximation errors from both Kriging models. In addition, a novel solution selection mechanism is designed to consider both robustness and predicted objective values, facilitating the deployment of the optimal robust solution. Throughout the experiment, four robust comparison algorithms are employed to assess the performance of the proposed DDMFEA across various problems in different decision dimensions. The experimental results validate the significance of each proposed contribution and demonstrate the exceptional performance of DDMFEA.},
  archive      = {J_SWEVO},
  author       = {Zhening Liu and Handing Wang and Jinliang Ding and Cuie Yang and Yaochu Jin},
  doi          = {10.1016/j.swevo.2025.101880},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101880},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Data stream driven evolutionary algorithm for cost sensitive robust optimization over time},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Surrogate-assisted differential evolution: A survey.
<em>SWEVO</em>, <em>94</em>, 101879. (<a
href="https://doi.org/10.1016/j.swevo.2025.101879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Expensive Optimization Problems (EOPs) are a pressing challenge in real-world applications because they require high-quality solutions under tight computational budgets. To tackle this, numerous Surrogate-Assisted Evolutionary Algorithms (SAEAs) have been proposed that combine Evolutionary Algorithms (EAs) with surrogate models. Recently, researchers have conducted systematic surveys on SAEAs to better showcase their potential in solving EOPs. However, most of these efforts have focused on surrogate models, while largely overlooking EAs. This imbalance poses a challenge to the long-term development of SAEAs. Among various SAEAs, Surrogate-Assisted Differential Evolution (SADE) is widely favored by researchers due to the competitive performance of DE in Evolutionary Computation. It has been broadly applied across diverse engineering and scientific domains. Nevertheless, there is still no work that systematically investigates the progress of SADE. To balance the research direction of SAEAs and fill the gap, this paper provides a comprehensive survey of SADE. Its contributions are summarized as follows: This paper first introduces the general optimization framework of SAEAs and briefly reviews the research directions and advances of its key components. Next, a comprehensive survey of SADE is conducted, covering commonly used surrogate models and DE algorithms. It also examines how existing SADE algorithms use DE, performance evaluation methods, and real-world applications. Finally, future challenges and potential research directions are discussed. We hope this work will draw attention to EAs and inspire further research to advance related fields.},
  archive      = {J_SWEVO},
  author       = {Laiqi Yu and Zhenyu Meng and Lingping Kong and Vaclav Snasel and Jeng-Shyang Pan},
  doi          = {10.1016/j.swevo.2025.101879},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101879},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Surrogate-assisted differential evolution: A survey},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent reinforcement learning for task allocation in
the internet of vehicles: Exploring benefits and paving the future.
<em>SWEVO</em>, <em>94</em>, 101878. (<a
href="https://doi.org/10.1016/j.swevo.2025.101878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles (IoV) and its applications are undergoing massive development, requiring diverse autonomous or self-directed vehicles/agents to fulfill various objective and responsibilities in vehicular technology. Similarly, Multi-Agent Systems (MAS) and multi-agent task allocation are currently the main focus of multiple researchers and scholars, and they play a key role in IoV and the Internet of Things (IoT). The development of the IoV and autonomous vehicles plays a significant role in Intelligent Transportation Systems (ITS), which are empowered by vehicular networks. However, the dynamic nature of these networks presents substantial challenges that need to be addressed. In this regard, we trace the historical evolution of the multi-agent task allocation of IoV, highlight its fundamentals and progress, and discuss the existing survey works. This paper comprehensively reviews various IoV strategies, both multi-agent task allocation strategies and Multi-Agent Reinforcement Learning (MARL), emphasizing the intelligent learning architecture, concepts, and security-related issues. Additionally, we highlight various computing platforms and the diverse applications of multi-agent task allocation in IoV, where task allocation is challenging and presents security concerns of multi-agent task allocation in IoV. Finally, we discuss major open problems regarding multi-agent task allocation scalability, complexity, communication overhead, resource allocation, security, privacy, etc., and potential future perspectives on multi-agent task allocation methods are highlighted.},
  archive      = {J_SWEVO},
  author       = {Inam Ullah and Sushil Kumar Singh and Deepak Adhikari and Habib Khan and Weiwei Jiang and Xiaoshan Bai},
  doi          = {10.1016/j.swevo.2025.101878},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101878},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multi-agent reinforcement learning for task allocation in the internet of vehicles: Exploring benefits and paving the future},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Energy-efficient task scheduling with binary random faults
in cloud computing environments. <em>SWEVO</em>, <em>94</em>, 101877.
(<a href="https://doi.org/10.1016/j.swevo.2025.101877">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fault management and energy consumption control have become focal topics in the rapid development of cloud computing services. This paper addresses the task scheduling problem with binary random faults in the networking and power supply of cloud computing environments and proposes a task scheduling model with the multiobjectives of minimizing energy consumption and task completion time while maximizing task completion rate. An estimation of distribution algorithm (EDA) with crowding distance (C) and neighborhood search (N) (EDA-CN) is designed for the model, into which a multi-model probability matrix, regional dislocation backup mechanism, neighborhood search operator, and crowding distance operator are integrated. Numerical experiments examine the effectiveness of EDA-CN in comparison with EDA, EDA-C, and the classic non-dominated sorting genetic algorithm III (NSGA3). The results show that EDA-CN consistently outperformed EDA and EDAC, and EDA-CN and NSGA3 performed comparably often yet EDA-CN still outperformed statistically significantly.},
  archive      = {J_SWEVO},
  author       = {Lei Jin and Jie Yuan and Dequn Zhou and Xiuzhi Sang and Shi Chen and Xianyu Yu and Guohui Lin},
  doi          = {10.1016/j.swevo.2025.101877},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101877},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Energy-efficient task scheduling with binary random faults in cloud computing environments},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic multi-objective evolutionary algorithm based on
dual-layer collaborative prediction under multiple perspective.
<em>SWEVO</em>, <em>94</em>, 101876. (<a
href="https://doi.org/10.1016/j.swevo.2025.101876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction-based strategies become increasingly prominent in addressing dynamic multi-objective optimization problems (DMOPs). However, challenges remain in selecting predictive models and effectively utilizing historical solutions. In this paper, we propose a multiple perspective dual-layer collaborative prediction strategy to efficiently tackle both challenges. The multi-perspective approach is further divided into a search perspective and a spatial perspective and realized through the collaboration of three sub-strategies. From the search perspective, we employ a dual-layer prediction strategy that focuses on both global and local information. Specifically, the first layer utilizes Gaussian process regression (GPR) to predict centrality, which serves as a measure of the population’s collective intelligence. This layer effectively captures global insights into population dynamics, identifying overarching movement trends over time. Building on these global insights, the second layer employs a knee-point interval partitioning strategy that combines vector partitioning with knee-point-based predictions. This layer provides localized insights that complement the broader movement trends identified by the first layer. From the spatial perspective, we implement dual-layer historical similarity detection across non-dominated solutions in both decision and objective spaces. Specifically, the historical Pareto-similarity selection strategy identifies populations in these spaces that demonstrate the greatest similarity to the current population’s non-dominated solutions. The spatial perspective complements the search perspective, forming a coherent framework that systematically integrates global, local, and historical information. Experimental results indicate that the proposed algorithm performs better than previous state-of-the-art methods.},
  archive      = {J_SWEVO},
  author       = {Yaru Hu and Yana Li and Junwei Ou and Jiankang Peng and Jun Li and Jinhua Zheng},
  doi          = {10.1016/j.swevo.2025.101876},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101876},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Dynamic multi-objective evolutionary algorithm based on dual-layer collaborative prediction under multiple perspective},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective genetic programming based on decomposition
for feature learning in image classification. <em>SWEVO</em>,
<em>94</em>, 101875. (<a
href="https://doi.org/10.1016/j.swevo.2025.101875">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification presents a challenge due to its high dimensionality and extensive variations. Feature learning is a powerful method in addressing this challenge, constituting a multi-objective problem aimed at maximizing classification accuracy and minimizing the number of learned features. A few multi-objective genetic programming (MOGP) methods have been proposed to optimize these two objectives, simultaneously. However, existing MOGP methods ignore the characteristics of feature learning tasks. Therefore, this work proposes a decomposition-based MOGP approach with a global replacement strategy for feature learning in data-efficient image classification. To handle the different value ranges of the two objectives, a transformation function is designed to uniform the range of the number of learned features. In addition, a preference-based decomposition strategy is proposed to address the preference for the objective of classification accuracy. The proposed approach is compared with existing MOGP methods for feature learning on five different image classification datasets with different numbers of training images. The experimental results demonstrate the effectiveness of the proposed approach by achieving better HVs than or comparable to the existing MOGP methods in at least 13 out of 20 cases and classification accuracy significantly better than a popular neural architecture search method in all cases.},
  archive      = {J_SWEVO},
  author       = {Tuo Zhang and Ying Bi and Jing Liang and Bing Xue and Mengjie Zhang},
  doi          = {10.1016/j.swevo.2025.101875},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101875},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multi-objective genetic programming based on decomposition for feature learning in image classification},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural network combined with reinforcement
learning-based dual-mode grey wolf optimizer to identify crop diseases
and pests. <em>SWEVO</em>, <em>94</em>, 101874. (<a
href="https://doi.org/10.1016/j.swevo.2025.101874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Agriculture is crucial for national food security, but crop pests and diseases pose significant threats. Traditional manual methods for detection are subjective, costly, and less accurate. Deep learning, especially convolutional neural network, is revolutionizing crop pest and disease identification, manual hyperparameter tuning can lead to suboptimal results. In contrast, grey wolf optimizer has demonstrated effective global search capabilities in hyperparameter optimization, improving model performance. Therefore, a reinforcement learning-based dual-mode grey wolf optimizer is introduced to enhance the performance of the original algorithm in hyperparameter optimization and identify the optimal hyperparameters, which combines a dynamic elite learning strategy and a dual-mode adaptive strategy well balanced with the exploration and exploitation of populations, while the integration of the reinforcement learning technique strengthens the information feedback. To validate the effectiveness of the proposed algorithm, additional ablation experiments were conducted, and experiments using CPU time as the termination criterion were included to increase rigor and ensure fairness. The main hyperparameters of convolutional neural network optimized by the proposed algorithm is utilized for the recognition of the pentatomidae stinkbug pests and corn diseases, with experimental results compared against six other intelligent optimization algorithms. Results from two sets of experiments indicate that the proposed algorithm improves the recognition accuracy of the original convolutional neural networks model, achieving the highest accuracy on the pest dataset at 95.83 % and on the corn disease dataset at 96.51 %.},
  archive      = {J_SWEVO},
  author       = {Yangchen Lu and Xiaobing Yu and Zhengpeng Hu and Xuming Wang},
  doi          = {10.1016/j.swevo.2025.101874},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101874},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Convolutional neural network combined with reinforcement learning-based dual-mode grey wolf optimizer to identify crop diseases and pests},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved adaptive hybrid algorithm for solving
distributed flexible job shop scheduling problem. <em>SWEVO</em>,
<em>94</em>, 101873. (<a
href="https://doi.org/10.1016/j.swevo.2025.101873">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With economic globalization, collaboration between enterprises has increased significantly. Complex products are now often produced in multiple workshops, either within a single company or across several. This shift has led to the rise of distributed manufacturing, a modern and rapidly expanding production method. This paper puts forward an Improved Adaptive Hybrid Algorithm (IAHA) to address the Distributed Flexible Job Shop Problem (DFJSP). A mathematical model of DFJSP is established based on the characteristics of distributed manufacturing. A hybrid decoding rule is proposed, using a dual-layer encoding approach to represent both factories and jobs. The initialization, crossover, and mutation operators are designed to efficiently tackle the job allocation challenge across distributed factories. In the local search phase, an adaptive variable neighborhood search method focuses on critical factories. Numerical experiments on a benchmark set of DFJSP instances with 2, 3, and 4 factories demonstrate the effectiveness of IAHA, breaking records for several instances and achieving optimal results for others. Comparisons with other algorithms show the IAHA&#39;s superior performance in solving the DFJSP.},
  archive      = {J_SWEVO},
  author       = {Cuiyu Wang and Mengxi Wei and Qihao Liu and Xinjian Zhang and Xinyu Li},
  doi          = {10.1016/j.swevo.2025.101873},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101873},
  shortjournal = {Swarm Evol. Comput.},
  title        = {An improved adaptive hybrid algorithm for solving distributed flexible job shop scheduling problem},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced QPSO driven by swarm cooperative evolution and its
applications in portfolio optimization. <em>SWEVO</em>, <em>94</em>,
101872. (<a href="https://doi.org/10.1016/j.swevo.2025.101872">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being a simple and popular method grounded in swarm evolution, Quantum-behaved particle swarm optimization (QPSO) has been extensively implemented to seek the optimal solution of various practical cases. Nevertheless, while managing intricate multimodal problems, the original QPSO algorithm renders the algorithm susceptible to premature convergence, characterized by slow iteration speed and suboptimal searching precision. To deal with these disadvantages, this paper puts forward an enhanced QPSO driven by swarm cooperative evolution (SCQPSO). In the SCQPSO algorithm, a binary swarm cooperative evolution strategy is designed to enhance QPSO’s convergence speed and optimization precision. Additionally, some improvement measures including Halton sequence initialization of individual locations, maintenance of population diversity, and mutation strategy for out-of-bounds particles, are also adopted to facilitate prevention of premature convergence and assist the algorithm in overcoming local optimality. Then, compared results obtained by SCQPSO and six improved intelligent approaches on CEC 2017 cases indicate that SCQPSO offers highly competitive solutions when solving complex multimodal problems. Further, the exceptional capability of SCQPSO in addressing two portfolio optimization issues demonstrates its outstanding global search performance.},
  archive      = {J_SWEVO},
  author       = {Xiao-li Lu and Guang He},
  doi          = {10.1016/j.swevo.2025.101872},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101872},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Enhanced QPSO driven by swarm cooperative evolution and its applications in portfolio optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-assisted particle swarm algorithm for
effluent scheduling problem with an influent estimation of WWTP.
<em>SWEVO</em>, <em>94</em>, 101871. (<a
href="https://doi.org/10.1016/j.swevo.2025.101871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effluent scheduling of wastewater treatment process (WWTP) is essential to ensure compliance with regulatory standards regarding effluent quality. Through the integration of pipe and plant systems, the influent can be estimated prior to entering the treatment process, providing additional information for scheduling. However, the traditional evolutionary computation methods face challenges in utilizing information from inflow estimation, resulting in decisions that do not account for long-term returns. For solving effluent scheduling problems with influent estimation, reinforcement learning can facilitate decision-making based on long-term environmental factors to improve the optimization ability of evolutionary computations. Thus, a framework of reinforcement learning-assisted particle swarm optimization algorithm (RLA-PSO) is proposed, using reinforcement learning part to generate solutions and guide optimization by learning from the influent estimation on a long-time scale. Meanwhile, it employs the optimization part to find the optimal solutions to intensify the learning effect of the reinforcement learning part. For the reinforcement learning part, a deep Q -network method with appropriate states and rewards is designed to efficiently learn the relationship between state, action and reward for the coming period. For the optimization part, a set-based particle optimization algorithm is employed to search for the optimized solution in a future period. The benchmark simulation model No.1(BSM1) is used to evaluate the performance of the proposed RLA-PSO algorithm for the effluent scheduling problem of WWTP. The computational experiments to the state-of-the-art methods show the proposed algorithm can achieve superior performance in effluent quality and process efficiency.},
  archive      = {J_SWEVO},
  author       = {HAN HongGui and XU ZiAng and WANG JingJing},
  doi          = {10.1016/j.swevo.2025.101871},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101871},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Reinforcement learning-assisted particle swarm algorithm for effluent scheduling problem with an influent estimation of WWTP},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval many-objective evolutionary algorithm guided by
dynamic dual-sequence mechanism. <em>SWEVO</em>, <em>94</em>, 101870.
(<a href="https://doi.org/10.1016/j.swevo.2025.101870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval many-objective evolutionary algorithms (IMaOEAs) have received significant achievements in recent years. However, it is difficult for the algorithm to quickly select good interval individuals since the uncertainty affects the definition of interval dominance relations. To further reduce the computational burden of uncertainty on the interval optimization process, this paper proposes a dual-sequence mechanism-guided interval many-objective evolutionary algorithm. First, the interval binary R2 evaluation indicator IR2 was designed, which can effectively evaluate the convergence and diversity of interval individuals. Second, an uncertainty dominance relation for interval individuals is proposed and uncertainty is quantified using the weighted LP norm (WLP). Finally, the dynamic dual-sequence (DDS) mechanism was ultimately employed to retain the most exceptional individuals within the population, while simultaneously eliminating those with subpar performance in terms of convergence, diversity, and uncertainty. To extensively evaluate the performance of the proposed approach, 16 benchmark problems were used as the test suite. The experimental results demonstrate that the approach outperforms five advanced interval many-objective evolutionary algorithms, showcasing its superior performance and competitiveness.},
  archive      = {J_SWEVO},
  author       = {Xingjuan Cai and Jinli Li and Jinlong Ma and Zhixia Zhang and Qingyuan Xu and Wensheng Zhang and Jinjun Chen},
  doi          = {10.1016/j.swevo.2025.101870},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101870},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Interval many-objective evolutionary algorithm guided by dynamic dual-sequence mechanism},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). State-space adaptive exploration for explainable particle
swarm optimization. <em>SWEVO</em>, <em>94</em>, 101868. (<a
href="https://doi.org/10.1016/j.swevo.2025.101868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A systems theory framework for swarm optimization algorithms promises the rigorous analysis of swarm behaviors and systematic approaches that could avoid ad hoc parameter settings and achieve guaranteed performances. However, optimization processes must treat various systems theory concepts, such as stability and controllability, differently, as swarm optimization relies on preserving diversity rather than reaching uniform agent behavior. This work addresses this duality of perspective and proposes State-Space Particle Swarm Optimization (SS-PSO) using the feedback concept in control systems theory. By exploiting the hidden analogy between these two paradigms, we introduce the concept of controllability for optimization purposes through state-space representation. Extending controllability to particle swarm optimization (PSO) highlights the ability to span the search space, emphasizing the significance of particles&#39; movement rather than their loss of diversity. Furthermore, adaptive exploration (AE) using an iterative bisection algorithm is proposed for the PSO parameters that leverages this controllability measure and its minimum singular value to facilitate explainable swarm behaviors and escape local minima. Theoretical and numerical analyses reveal that SS-PSO is only uncontrollable when the cognitive factor is zero, implying less exploration. Finally, AE enhances exploration by increasing the controllability matrix&#39;s minimum singular value. This result underscores the profound connection between the controllability matrix and exploration, a critical insight that significantly enhances our understanding of swarm optimization. AE-based State-Space-PSO (AESS-PSO) shows improved exploration and performance over PSO in 86 SOP and CEC benchmarks, particularly for smaller populations.},
  archive      = {J_SWEVO},
  author       = {Mehdi Alimohammadi and Mohammad-R. Akbarzadeh-T},
  doi          = {10.1016/j.swevo.2025.101868},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101868},
  shortjournal = {Swarm Evol. Comput.},
  title        = {State-space adaptive exploration for explainable particle swarm optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A spiking neural network based proximal policy optimization
method for multi-point imaging mission scheduling of earth observation
satellite. <em>SWEVO</em>, <em>94</em>, 101867. (<a
href="https://doi.org/10.1016/j.swevo.2025.101867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the escalating demand for earth observation, a solitary satellite will be required to undertake an expanded array of missions, thereby rendering the scheduling of multipoint earth observation satellite imaging missions increasingly intricate. Herein, we propose a proximal policy optimization (PPO) algorithm based on a spiking neural network (SNN) to solve the multipoint satellite mission scheduling problem. Initially, we preprocess the mission–transition time by incorporating satellite attitude constraints and conceptualize the mission planning process as a Markov decision. Then, our methodology integrates SNN with PPO to effectively handle a high-dimensional state space by leveraging temporal information–processing capabilities. The SNN-based actor-critic network is trained to enhance the scheduling policy via PPO. Our method exhibits superior performance across various satellite orbits, satellite attitude maneuver speeds, and mission scales. In comparison with heuristic methods and traditional reinforcement learning techniques, our method shows a swifter convergence rate and an increased success rate of observation, coupled with superior convergence speed, robustness, and stability.},
  archive      = {J_SWEVO},
  author       = {Wei Yao and Xin Shen and Guo Zhang and Zezhong Lu and Jiaying Wang and Yanjie Song and Zhiwei Li},
  doi          = {10.1016/j.swevo.2025.101867},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101867},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A spiking neural network based proximal policy optimization method for multi-point imaging mission scheduling of earth observation satellite},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective optimization-assisted single-objective
differential evolution by reinforcement learning. <em>SWEVO</em>,
<em>94</em>, 101866. (<a
href="https://doi.org/10.1016/j.swevo.2025.101866">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {“Learning to optimize” design systems for evolutionary algorithm (EA) automatic design have become a trend, especially for differential evolution (DE). “Learning to optimize” design systems for EAs have two main parts: an excellent “backbone” algorithm with learnable components, and a learning scheme to determine the components of the “backbone” algorithm. A good “backbone” algorithm is of great importance for the algorithm design, because it determines the algorithm design space and potential. The learning scheme determines whether we can realize the potential or not. Existing studies generally choose one developed EA as the “backbone” algorithm, which constrains the potential of the design system because the “backbone” algorithm is relatively simple. To solve the problem and design a good EA, in this paper, we first propose a three-stage hybrid DE framework for single objective optimization, called SMS-DE, which implements single-objective DE, multi-objective DE, and single-objective DE sequentially. The multi-objective DE aims to enhance exploration ability. Second, we apply the framework to two advanced DEs, JADE and LSHADE, which results in two new algorithms: SMS-JADE and SMS-LSHADE. Third, the newly proposed algorithm, SMS-LSHADE, is considered the “backbone” algorithm, and the reinforcement learning method (Q-learning) is used to control the parameter for allocating computational resources to each stage, which results in another algorithm called QSMS-LSHADE. Experimental results on the CEC 2018 test suite show that SMS-DE, SMS-JADE, and SMS-LSHADE can perform significantly better than their counterparts and that SMS-QLSHADE performs the best among many developed DEs.},
  archive      = {J_SWEVO},
  author       = {Haotian Zhang and Xiaohong Guan and Yixin Wang and Nan Nan},
  doi          = {10.1016/j.swevo.2025.101866},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101866},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multi-objective optimization-assisted single-objective differential evolution by reinforcement learning},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neuro-PSO algorithm for large-scale dynamic optimization.
<em>SWEVO</em>, <em>94</em>, 101865. (<a
href="https://doi.org/10.1016/j.swevo.2025.101865">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last few decades, dynamic optimization and large-scale optimization have been two challenging research topics. In this context, dynamic optimization with high dimensionality is undoubtedly another important research topic. For such a combined problem, this paper develops: (1) an algorithm that incorporates problem decomposition to deal with high dimensionality, (2) a search algorithm for optimization, and (3) a prediction strategy to deal with dynamic changes. Firstly, a decomposition method is introduced to divide the problem into multiple subproblems based on the level of interactions among the decision variables. For optimization, a multi-population search algorithm is proposed, where each subpopulation evolves individually. Finally, a machine learning-based prediction strategy is developed to learn information from historical solutions and predict some solutions that may be useful for the new environment. The proposed algorithm is tested using the generalized moving peaks benchmark problems. The results show that the proposed algorithm can find better solutions than existing approaches.},
  archive      = {J_SWEVO},
  author       = {Mohamed Radwan and Saber Elsayed and Ruhul Sarker and Daryl Essam and Carlos Coello Coello},
  doi          = {10.1016/j.swevo.2025.101865},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101865},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Neuro-PSO algorithm for large-scale dynamic optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scheduling two-stage healthcare appointment systems via a
knowledge-based biased random-key genetic algorithm. <em>SWEVO</em>,
<em>94</em>, 101864. (<a
href="https://doi.org/10.1016/j.swevo.2025.101864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the scheduling problem of two-stage healthcare appointment systems, previous studies always assume that a positive linear correlation is obeyed between the customer waiting time and service dissatisfaction, and an arrived customer is served immediately if the provider at the first stage becomes available, which usually leads to heavy congestion at the second stage and a rapid decline in service satisfaction. To tackle this problem further, this paper assumes that customer waiting time within different ranges impacts service dissatisfaction differently. Then, it develops an efficient real-time scheduling strategy to decide the exact starting time of each customer&#39;s service at the first stage. Considering no-shows and non-punctual appointments, a knowledge-based biased random-key genetic algorithm ( K-BRKGA ) is used to determine the number of customers at each appointment slot, such that the total weighted cost associated with customers’ waiting time, providers’ idle time, and overtime at two stages can be minimized. Based on the data sets used, K-BRKGA reduces the total cost by 2.01 % and 1.01 % compared to the other two famous algorithms.},
  archive      = {J_SWEVO},
  author       = {Fajun Yang and Chao Li and Feng Wang and Zhi Yang and Kaizhou Gao},
  doi          = {10.1016/j.swevo.2025.101864},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101864},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Scheduling two-stage healthcare appointment systems via a knowledge-based biased random-key genetic algorithm},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large-scale optimization algorithm based on variable
decomposition and space compression. <em>SWEVO</em>, <em>94</em>,
101863. (<a href="https://doi.org/10.1016/j.swevo.2025.101863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing large-scale problem is very challenging due to the unknown landscape, huge search space of countless combinations of decision variables and the inner complexity of the problem. To better solve this kind of problem, a decomposition and compression based algorithm (DCBA) is proposed to decompose the problem and compress the search space for efficient optimization. Firstly, three space compression based linear search methods are designed with two functionalities: (1) to carry out a quick and rough optimization and find relatively good initial solutions; (2) to gather important information of each dimension (decision variable) for subsequent processing. In the three linear search methods, we design ways to evaluate the search region and compress it into smaller regions that may contain better solutions. Then, four decomposition methods are designed for fully non-separable large-scale problems. These methods can generate as many as twenty-nine different decomposition results to enhance the decomposition diversity in order to make a better trade-off of the non-separability characteristic and the decomposition for complexity reduction of fully non-separable large-scale problems. Finally, a decomposition and compression based algorithm (DCBA) is proposed to solve large-scale problems. Numerical experiments are conducted on two widely used benchmark suites and comparisons with state-of-the-art algorithms are made. The results show that the proposed algorithm is effective and efficient.},
  archive      = {J_SWEVO},
  author       = {Haiyan Liu and Wenlong Song and Yi Cheng and Shouheng Tuo and Yuping Wang},
  doi          = {10.1016/j.swevo.2025.101863},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101863},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A large-scale optimization algorithm based on variable decomposition and space compression},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A dual-population co-evolution algorithm with balanced
environmental selection for constrained multimodal multiobjective
optimization problems. <em>SWEVO</em>, <em>94</em>, 101862. (<a
href="https://doi.org/10.1016/j.swevo.2025.101862">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In constrained multimodal multiobjective optimization problems (CMMOPs), the principal challenge is to explore multiple conflicting objectives and multiple equivalent Pareto sets under complex constraints, while balancing feasibility, convergence, and diversity of solutions. This paper proposes the DPCMMOEA-BES algorithm, which is based on dual-population co-evolution and incorporates a balanced environmental selection (BES) component to solve CMMOPs. In DPCMMOEA-BES, parent information from dual populations is shared through the mating selection operator based on speciation to generate offspring. Additionally, the BES component proposed in this paper enhances the algorithm’s overall performance by utilizing the dynamic-range-based constrained dominance principle and the accurate selection operation based on global Bi-crowding Distance, where the introduction of Bi-crowding Distance effectively balances the diversity of solutions in both the objective and decision spaces. The BES component also demonstrates its potential as a universal plugin, which can be integrated into various constrained multiobjective evolutionary algorithms and multimodal multiobjective evolutionary algorithms. The proposed DPCMMOEA-BES is evaluated on 31 test instances and compared with other state-of-the-art algorithms. The experimental results show that it is a highly competitive approach. Moreover, the comparative results confirm that integrating the BES component significantly improves the algorithm’s performance in solving CMMOPs.},
  archive      = {J_SWEVO},
  author       = {FuLong Wu and Yu Sun},
  doi          = {10.1016/j.swevo.2025.101862},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101862},
  shortjournal = {Swarm Evol. Comput.},
  title        = {A dual-population co-evolution algorithm with balanced environmental selection for constrained multimodal multiobjective optimization problems},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrated scheduling problem of multi-load AGVs and
parallel machines considering the recovery process. <em>SWEVO</em>,
<em>94</em>, 101861. (<a
href="https://doi.org/10.1016/j.swevo.2025.101861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern manufacturing workshops, parallel machine scheduling and automated guided vehicle (AGV) scheduling are two closely coupled problems. However, the two problems are often solved independently, which reduces the performance of manufacturing system to a large extent. To address this issue, this paper investigates the integrated scheduling problem of multi-load AGV and parallel machine considering the recovery process (MAGVPM-R). Firstly, a mathematical model is established to optimize the completion time. Second, a weight priority integration heuristic (WPIH) and four neighborhood operators are designed based on MAGVPM-R characteristics. Third, a discrete grey wolf optimization (DGWO) algorithm is proposed. Finally, the mathematical model is validated using the GUROBI solver and the performance of DGWO is tested with 100 instances of different scales. The experimental results show that DGWO solves the MAGVPM-R problem better than other competing algorithms.},
  archive      = {J_SWEVO},
  author       = {Xin Fan and Hongyan Sang and Mengxi Tian and Yang Yu and Song Chen},
  doi          = {10.1016/j.swevo.2025.101861},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101861},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Integrated scheduling problem of multi-load AGVs and parallel machines considering the recovery process},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Handling objective preference and variable uncertainty in
evolutionary multi-objective optimization. <em>SWEVO</em>, <em>94</em>,
101860. (<a href="https://doi.org/10.1016/j.swevo.2025.101860">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms (EAs) are widely employed in multi-objective optimization (MOO) to find a well-distributed set of near-Pareto solutions. Among various types of practicalities that demand standard evolutionary multi-objective optimization (EMO) algorithms to be modified suitably, we propose here a framework for handling two important ones: (i) decision-making to choose one or more preferred Pareto regions, rather than finding the entire Pareto set, and (i) uncertainty in variables and parameters of the problem which is inevitable in any practical problem. While the first practicality will allow a focused set of preferred solutions to be found, the second practicality will enable finding robust yet high-performing non-dominated solutions. We propose and analyze four different approaches for finding preferred and robust solutions for handling both practicalities simultaneously. Our results on a number of two to 10-objective tests and engineering problems indicate the superiority of one specific approach. For a comprehensive evaluation of new EMO algorithms for finding a preferred and robust solution set, we also propose a new performance metric by identifying and utilizing a number of desired properties of such trade-off solutions. The study is comprehensive and should encourage researchers to develop more competitive EMO algorithms for finding preferred and robust Pareto solutions.},
  archive      = {J_SWEVO},
  author       = {Deepanshu Yadav and Palaniappan Ramu and Kalyanmoy Deb},
  doi          = {10.1016/j.swevo.2025.101860},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101860},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Handling objective preference and variable uncertainty in evolutionary multi-objective optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing healthcare resource allocation through large
language models. <em>SWEVO</em>, <em>94</em>, 101859. (<a
href="https://doi.org/10.1016/j.swevo.2025.101859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognizing the growing capabilities of large language models (LLMs) and their potential in healthcare, this study explores the application of LLMs in healthcare resource allocation using Prompt Engineering, Retrieval-Augmented Generation (RAG), and Tool Utilization. It addresses both optimizable and non-optimizable challenges in allocating operating rooms (ORs), postoperative beds, and surgeons, while also identifying key factors like ethical and legal constraints through a medical knowledge Q&amp;A survey. Among the seven evaluated LLMs, including LaMDA 2, PaLM 2, and Qwen, ChatGPT-4o demonstrated superior performance by reducing OR and surgeon overtime, alleviating peak bed demand, and achieving the highest accuracy in medical knowledge queries. Comprehensive comparisons with traditional methods (exact and heuristic algorithm), varying problem sizes, and hybrid approaches from the literature revealed that as problem size increased, LLMs performed better and faster by integrating historical experience with new data. They adapted to changes in problem scale or demand without requiring re-optimization, effectively addressing the runtime limitations of traditional methods. These findings underscore the potential of LLMs in advancing dynamic and efficient healthcare resource management.},
  archive      = {J_SWEVO},
  author       = {Fang Wan and Kezhi Wang and Tao Wang and Hu Qin and Julien Fondrevelle and Antoine Duclos},
  doi          = {10.1016/j.swevo.2025.101859},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101859},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Enhancing healthcare resource allocation through large language models},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-objective neural policy approach for agile earth
satellite scheduling problem considering image quality. <em>SWEVO</em>,
<em>94</em>, 101857. (<a
href="https://doi.org/10.1016/j.swevo.2025.101857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The agile earth satellite scheduling problem (AEOSSP) aims to output reasonable execution plans to manage observation requests and satisfy different user requirements. By analyzing the factors which impact the quality of satellite observation, a specific multi-objective AEOSSP (MO-AEOSSP) is studied, integrating observation profit and average image quality as optimization objectives. To overcome the limitations of traditional iterative methods, we introduce a multi-objective neural policy approach (MONP) which consists of problem decomposition, parameter initialization and subproblem modeling. Through problem decomposition a given MO-AEOSSP can be partitioned into several subproblems, subsequently modeled and trained as encoder–decoder structure neural networks. Various features including the most typical satellite attitude angle are characterized to support the MONP, while parameter transfer initialization is employed to accelerate the overall deep reinforcement learning procedure by leveraging params acquired from optimized subproblem. An end-to-end manner is implemented after all subproblems are trained to output the final non-dominated solutions. Experimental results on various scenarios demonstrate that MONP outperforms four representative multi-objective evolutionary algorithms in terms of metrics including Pareto Front, hypervolume and computational overhead, appearing remarkable ability of convergence, distribution, efficiency and scalability. Experiments further verify the effectiveness of the adopted parameter initialization strategy. To the best of our understanding, this study is an innovative attempt to combine the neural policy approach with MO-AEOSSP considering time-dependent satellite transition.},
  archive      = {J_SWEVO},
  author       = {Luona Wei and Yongqiang Cui and Ming Chen and Qian Wan and Lining Xing},
  doi          = {10.1016/j.swevo.2025.101857},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101857},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Multi-objective neural policy approach for agile earth satellite scheduling problem considering image quality},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DANCE: Distributed co-evolutionary design of velocity
controllers for swarm intelligence robots in flocking and entrapping
tasks. <em>SWEVO</em>, <em>94</em>, 101854. (<a
href="https://doi.org/10.1016/j.swevo.2025.101854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study combined evolutionary algorithm and reinforcement learning to propose a new automated design method for generating swarm robots velocity controller model. It alternately evolves heterogeneous swarm and homogeneous swarm through a gene expression programming method that introduces reinforcement learning, and assembles function nodes and leaf nodes into new mathematical formulas during the evolution process. The method enable to realize the effect of swarm robots emerging to perform swarm tasks such as flocking and entrapping. What is more, a new swarm rule was discovered during the evolution process, which is used to realize the flocking of swarm robots at any angle. The experimental results show that the swarm motion controller automatically generated by the model has high task completion efficiency and strong generalization.},
  archive      = {J_SWEVO},
  author       = {Chen Wang and Cheng Zhu and Xianqiang Zhu and Hongtao Lei and Weiming Zhang and Meng Wu},
  doi          = {10.1016/j.swevo.2025.101854},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101854},
  shortjournal = {Swarm Evol. Comput.},
  title        = {DANCE: Distributed co-evolutionary design of velocity controllers for swarm intelligence robots in flocking and entrapping tasks},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary algorithm based on multi-probability
distribution model for stochastic optimization. <em>SWEVO</em>,
<em>94</em>, 101839. (<a
href="https://doi.org/10.1016/j.swevo.2024.101839">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic optimization, which aims at optimizing the expected value of a stochastic objective function, is challenging and commonly-seen in engineering applications. One crucial challenge of stochastic optimization problems (SOPs) is that the objective function value is impossible to calculate accurately due to the existence of uncertainty. As probability distribution is a common mathematical tool for handling uncertainty, this paper intends to explore the use of probability-distribution-based evolutionary algorithms (EAs) for solving complicated SOPs. First, an in-depth analysis of how to sample and construct probability distributions for probability-distribution-based EAs in SOPs is performed through both empirical and theoretical studies. Based on the analysis, it can be concluded that the implicit averaging method is helpful for probability-distribution-based EAs to solve SOPs. Second, evolutionary algorithm based on multiple probability distribution models (EA-mPD) framework is proposed. Instead of using a single probability distribution, the whole population is divided into several clusters by clustering, and several local probability models are built for different clusters. Finally, probability-distribution-based EAs such as estimation of distribution algorithm (EDA) and ant colony optimization (ACO) are introduced in the proposed EA-mPD to solve SOPs. Experimental results show that the proposed EA-mPD method is promising in terms of both accuracy and efficiency.},
  archive      = {J_SWEVO},
  author       = {Hao Cong and Xiao-Min Hu and Wei-Neng Chen and Wen Shi and Jun Zhang},
  doi          = {10.1016/j.swevo.2024.101839},
  journal      = {Swarm and Evolutionary Computation},
  month        = {4},
  pages        = {101839},
  shortjournal = {Swarm Evol. Comput.},
  title        = {Evolutionary algorithm based on multi-probability distribution model for stochastic optimization},
  volume       = {94},
  year         = {2025},
}
</textarea>
</details></li>
</ul>
<h2 id="tcs---7">TCS - 7</h2>
<ul>
<li><details>
<summary>
(2025). A theory of fine-grained lineage for functions on structured
objects. <em>TCS</em>, <em>1039</em>, 115192. (<a
href="https://doi.org/10.1016/j.tcs.2025.115192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lineage is the process of keeping track of the relationship between the inputs of a data processing task and the parts of the output they contribute to produce. Depending on its precise definition, lineage can be seen as a form of database provenance, a means of tracking information flow in computer programs, or be used to express causality and provide counter-examples for the falsity of a logical statement. In this paper, we establish the formal foundations of a notion of lineage for arbitrary abstract functions manipulating objects that are “composite” –that is, can be made of multiple other objects. Three definitions of lineage over functions are formally defined, respectively called explanation, participation and extraction; we then establish explanation relationships for a set of elementary functions, and for compositions thereof. A fully functional implementation of these concepts is finally presented and experimentally evaluated.},
  archive      = {J_TCS},
  author       = {Sylvain Hallé and Hugo Tremblay},
  doi          = {10.1016/j.tcs.2025.115192},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115192},
  shortjournal = {Theor. Comput. Sci.},
  title        = {A theory of fine-grained lineage for functions on structured objects},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved algorithms for optimal k sink location on path
networks. <em>TCS</em>, <em>1039</em>, 115190. (<a
href="https://doi.org/10.1016/j.tcs.2025.115190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the problem of placing k sinks on dynamic-flow path networks with n vertices so as to minimize their maximum evacuation completion time. We develop two different algorithms that, when all edges have the same capacity, run respectively in O ( n + k 2 log 2 ⁡ n ) and O ( n log ⁡ n ) time. When the edge capacities can be different, i.e., are general , they run respectively in O ( n log ⁡ n + k 2 log 4 ⁡ n ) and O ( n log 3 ⁡ n ) time. These algorithms improve upon the previously most efficient algorithms, which had time complexities O ( k n ) and O ( k n log 2 ⁡ n ) , respectively, for the uniform and general edge capacity models. The improvements are achieved by moving from a dynamic programming based approach to a parametric-search based one.},
  archive      = {J_TCS},
  author       = {Binay Bhattacharya and Mordecai J. Golin and Yuya Higashikawa and Tsunehiko Kameda and Naoki Katoh},
  doi          = {10.1016/j.tcs.2025.115190},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115190},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Improved algorithms for optimal k sink location on path networks},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The reliability of (n,k)-star network in terms of
non-inclusive fault pattern. <em>TCS</em>, <em>1039</em>, 115189. (<a
href="https://doi.org/10.1016/j.tcs.2025.115189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability assessment is of significant importance in the design maintenance and improvement of multiprocessor systems which take interconnection networks as underlying topologies. System-level diagnosis is a primary strategy to identify faulty processors by analyzing the syndrome of testing in a system. The newly proposed non-inclusive diagnosability greatly enhances the ability in evaluating the reliability of interconnection networks when comparing to the classical diagnosability. In this article, we first study the non-inclusive diagnosability and the non-inclusive 1-extra diagnosability of ( n , k ) -star network under the MM* model, respectively. Then we design a fast and adaptive non-inclusive fault identification algorithm to identify faulty nodes and fault-free nodes in the ( n , k ) -star network. Furthermore, we implement simulation experiments in terms of TNR, TPR, ACCR, FNR, FPR and F1. Simulation results demonstrate that our proposed method achieves excellent performance in fault detection and network reliability.},
  archive      = {J_TCS},
  author       = {Qigong Chen and Jiafei Liu and Chia-Wei Lee and Jingli Wu and Gaoshi Li},
  doi          = {10.1016/j.tcs.2025.115189},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115189},
  shortjournal = {Theor. Comput. Sci.},
  title        = {The reliability of (n,k)-star network in terms of non-inclusive fault pattern},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Opinion diffusion in graphs: An adversarial approach.
<em>TCS</em>, <em>1039</em>, 115188. (<a
href="https://doi.org/10.1016/j.tcs.2025.115188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and study a novel majority-based opinion diffusion model. Consider a graph G , which represents a social network. Assume that initially a subset of nodes, called seed nodes or early adopters, are colored either black or white, which correspond to positive or negative opinion regarding a consumer product or a technological innovation. Then, in each round an uncolored node, which is adjacent to at least one colored node, chooses the most frequent color among its neighbors. Consider a marketing campaign which advertises a product of poor quality and its ultimate goal is that more than half of the population believe in the quality of the product at the end of the opinion diffusion process. We focus on three types of attackers which can select the seed nodes in a deterministic or random fashion and manipulate almost half of them to adopt a positive opinion toward the product (that is, to choose black color). We say that an attacker succeeds if a majority of nodes are black at the end of the process. Our main purpose is to characterize classes of graphs where an attacker cannot succeed. In particular, we prove that if the maximum degree of the underlying graph is not too large or if it has strong expansion properties, then it is fairly resilient to such attacks. Furthermore, we prove tight bounds on the stabilization time of the process (that is, the number of rounds it needs to end) in both settings of choosing the seed nodes deterministically and randomly. We also provide several hardness results for some optimization problems regarding stabilization time and choice of seed nodes.},
  archive      = {J_TCS},
  author       = {Ahad N. Zehmakan},
  doi          = {10.1016/j.tcs.2025.115188},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115188},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Opinion diffusion in graphs: An adversarial approach},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cost-sharing games with rank-based utilities. <em>TCS</em>,
<em>1039</em>, 115186. (<a
href="https://doi.org/10.1016/j.tcs.2025.115186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies in behavioral science show that individuals are often concerned primarily about their relative welfare, rather than their absolute well-being. In this paper we define and study a variant of congestion games that reflects this phenomenon. In a cost-sharing game with rank-based utilities (CSRB-game, for short), the players are partitioned into competition sets , and the goal of every player is to minimize its cost relative to its competitors . Specifically, the primary goal of a player is to minimize the rank of its cost among its competitors, while minimizing the cost itself is a secondary objective. We show that CSRB-games are significantly different from classical cost-sharing games, and that competition may lead to a poor outcome. In particular, singleton CSRB-games need not have a pure Nash equilibrium, and even when a NE exists, natural dynamics may not converge to a NE, and the price of stability is linear in the number of players. We then analyze several natural restricted classes of singleton CSRB-games, for which we present positive results. We provide tight characterization of classes for which a NE exists and can be computed efficiently, and bound the equilibrium inefficiency, based on the competition structure, the number of players and resources, the uniformity of resources&#39; costs, and the strategy space of competing players.},
  archive      = {J_TCS},
  author       = {Shaul Rosner and Tami Tamir},
  doi          = {10.1016/j.tcs.2025.115186},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115186},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Cost-sharing games with rank-based utilities},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-stabilizing multivalued consensus in the presence of
byzantine faults and asynchrony. <em>TCS</em>, <em>1039</em>, 115184.
(<a href="https://doi.org/10.1016/j.tcs.2025.115184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Consensus, abstracting myriad problems in which processes must agree on a single value, is one of the most celebrated problems of fault-tolerant distributed computing. Consensus applications include fundamental services for the Cloud and Blockchain environments, and in such challenging environments, malicious behaviors are often modeled as adversarial Byzantine faults. At OPODIS 2010, Mostéfaoui and Raynal (in short, MR) presented a Byzantine-tolerant solution to consensus in which the decided value cannot be proposed only by Byzantine processes. MR has optimal resilience coping with up to t &lt; n / 3 Byzantine nodes over n processes. MR provides this multivalued consensus object (which accepts proposals taken from a finite set of values), assuming the availability of a single binary consensus object (which accepts proposals taken from the set { 0 , 1 } ). This work, which focuses on multivalued consensus, aims to design an even more robust solution than MR. Our proposal expands MR&#39;s fault-model with self-stabilization, a vigorous notion of fault-tolerance. In addition to tolerating Byzantine, self-stabilizing systems can automatically recover after arbitrary transient-faults occur. These faults represent any violation of the assumptions according to which the system was designed to operate (provided that the algorithm code remains intact). To the best of our knowledge, we propose the first self-stabilizing solution for multivalued consensus for asynchronous message-passing systems prone to Byzantine failures. Our solution has an O ( t ) stabilization time from arbitrary transient faults.},
  archive      = {J_TCS},
  author       = {Romaric Duvignau and Michel Raynal and Elad Michael Schiller},
  doi          = {10.1016/j.tcs.2025.115184},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115184},
  shortjournal = {Theor. Comput. Sci.},
  title        = {Self-stabilizing multivalued consensus in the presence of byzantine faults and asynchrony},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). K-shortest simple paths in bounded treewidth graphs.
<em>TCS</em>, <em>1039</em>, 115182. (<a
href="https://doi.org/10.1016/j.tcs.2025.115182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k -shortest simple paths problem asks to compute a set of top- k shortest simple paths from a source to a sink in a graph G = ( V , E ) with | V | = n vertices and | E | = m edges. The most well-known algorithm for solving this problem is due to Yen (1971) with time complexity in O ( k n ( m + n log ⁡ n ) ) and the fastest algorithm is due to Gotthilf and Lewenstein (2009) with time complexity in O ( k n ( m + n log ⁡ log ⁡ n ) ) . For bounded treewidth graphs, Eppstein and Kurz (2017) lowered the computational complexity to O ( k n ) by retrieving paths from the k smallest solutions of a monadic second-order formula, and to O ( n + k log ⁡ ( n ) ) to retrieve the k shortest simple distances only. In this paper, we provide an algorithm that answers k -shortest simple distances in O ( k + n ) time on graphs with treewidth at most 2, and a constructive algorithm, simpler than that of Eppstein and Kurz, that solves the k -shortest simple paths problem in O ( k n ) time on bounded treewidth graphs.},
  archive      = {J_TCS},
  author       = {David Coudert and Andrea D&#39;Ascenzo and Clément Rambaud},
  doi          = {10.1016/j.tcs.2025.115182},
  journal      = {Theoretical Computer Science},
  month        = {6},
  pages        = {115182},
  shortjournal = {Theor. Comput. Sci.},
  title        = {K-shortest simple paths in bounded treewidth graphs},
  volume       = {1039},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
