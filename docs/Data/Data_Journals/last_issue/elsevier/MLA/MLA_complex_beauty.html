<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MLA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mla---22">MLA - 22</h2>
<ul>
<li><details>
<summary>
(2025). Predicting classification errors using NLP-based machine
learning algorithms and expert opinions. <em>MLA</em>, <em>19</em>,
100630. (<a href="https://doi.org/10.1016/j.mlwa.2025.100630">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various intentional and unintentional biases of humans manifest in classification tasks, such as those related to risk management. In this paper we demonstrate the role of ML algorithms when accomplishing these tasks and highlight the role of expert know-how when training the staff as well as, and very importantly, when training and fine-tuning ML algorithms. In the process of doing so and when facing well-known inefficiencies of the traditional F1 score, especially when working with unbalanced datasets, we suggest a modification of the score by incorporating human-experience-trained algorithms, which include both expert-trained algorithms (i.e., with the involvement of expert experiences in classification tasks) and staff-trained algorithms (i.e., with the involvement of experiences of those staff who have been trained by experts). Our findings reveal that the modified F1 score diverges from the traditional staff F1 score when the staff labels exhibit weak correlation with expert labels, which indicates insufficient staff training. Furthermore, the Long Short-Term Memory (LSTM) model outperforms other classifiers in terms of the modified F1 score when applied to the classification of textual narratives in consumer complaints.},
  archive      = {J_MLA},
  author       = {Peiheng Gao and Chen Yang and Ning Sun and Ričardas Zitikis},
  doi          = {10.1016/j.mlwa.2025.100630},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100630},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predicting classification errors using NLP-based machine learning algorithms and expert opinions},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning framework for accurate COVID-19
classification in CT-scan images. <em>MLA</em>, <em>19</em>, 100628. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100628">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background In response to the global COVID-19 pandemic, we have introduced a binary classification model that employs convolutional layers to differentiate between normal cases and COVID-19-infected cases. Our primary aim was to address the urgent need for a highly efficient and accurate diagnostic tool to combat the widespread outbreak of COVID-19. Methods To achieve the background, we proposed a convolutional structure that comprises 10 layers in the encoder and 3 dense layers in the decoder. We conducted comprehensive experiments and evaluations using four distinct datasets. Results The outcomes of our study consistently demonstrated remarkable performance, with our proposed model achieving an accuracy of 89.00 %, a sensitivity of 0.95, a specificity of 0.88, and an impressive AUC of 0.92. Notably, Dataset 4 yielded the most promising results among all datasets, underscoring the effectiveness of our approach. Conclusion Our research substantiates the superiority of our model over previous methodologies and pre-trained models. Furthermore, it significantly contributes to global efforts in combating COVID-19 by providing an advanced diagnostic tool. This work also paves the way for future breakthroughs in the field of medical image analysis.},
  archive      = {J_MLA},
  author       = {Shirin Kordnoori and Maliheh Sabeti and Hamidreza Mostafaei and Saeed Seyed Agha Banihashemi},
  doi          = {10.1016/j.mlwa.2025.100628},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100628},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A deep learning framework for accurate COVID-19 classification in CT-scan images},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Corrigendum to “machine learning for sports betting: Should
model selection be based on accuracy or calibration?” [Machine learning
with applications volume 16, june 2024, 100539]. <em>MLA</em>,
<em>19</em>, 100627. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100627">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MLA},
  author       = {Conor Walsh and Alok Joshi},
  doi          = {10.1016/j.mlwa.2025.100627},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100627},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Corrigendum to “Machine learning for sports betting: Should model selection be based on accuracy or calibration?” [Machine learning with applications volume 16, june 2024, 100539]},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noninvasive estimation of blood glucose and HbA1c using
quantum machine learning technique. <em>MLA</em>, <em>19</em>, 100626.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100626">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we developed models with quantum and classical machine learning algorithms to detect blood glucose and HbA1c noninvasively from ten-second fingertip video by deploying a smartphone and near-infrared spectroscopy. Using our developed framework, we collected 136 participants’ ten-second fingertip videos with their baseline blood glucose and HbA1c levels after getting approval from the Institutional Review Board (IRB). We extracted 45 PPG (photoplethysmography) features from the ten-second fingertip video by using the Beer–Lambert law and applied feature engineering to select the most important features. We applied two Quantum Machine Learning (QML) based algorithms and seven Classical Machine Learning (CML) based algorithms for estimating blood glucose and HbA1c levels. The application of QML for the noninvasive estimation of blood glucose and HbA1c is a new and unexplored research area. Among all developed models, the Quantum Support Vector Machine performs best for predicting both blood glucose and HbA1c. The Quantum Support Vector Machine provides an accuracy of 89.30% and an average k-fold cross-validation score of 92.50% for blood glucose prediction and an accuracy of 96.30% and an average k-fold cross-validation score of 92.50% for HbA1c prediction. Our study signifies the potential of QML algorithms in noninvasive health monitoring, especially in the less-explored area of blood glucose and HbA1c estimation. The high performance of the developed models paves the way for advancing noninvasive techniques for measuring blood constituents. These findings offer promising applications in personalized healthcare, including continuous monitoring, early disease diagnosis, and more convenient management of chronic conditions.},
  archive      = {J_MLA},
  author       = {Parama Sridevi and Masud Rabbani and Md Hasanul Aziz and Paramita Basak Upama and Sayed Mashroor Mamun and Rumi Ahmed Khan and Sheikh Iqbal Ahamed},
  doi          = {10.1016/j.mlwa.2025.100626},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100626},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Noninvasive estimation of blood glucose and HbA1c using quantum machine learning technique},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiobjective continuation method to compute the
regularization path of deep neural networks. <em>MLA</em>, <em>19</em>,
100625. (<a href="https://doi.org/10.1016/j.mlwa.2025.100625">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability (due to the smaller number of relevant features), and robustness. For linear models, it is well known that there exists a regularization path connecting the sparsest solution in terms of the ℓ 1 norm, i.e., zero weights and the non-regularized solution. Recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ( ℓ 1 norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the ℓ 1 norm and the large number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto front for the above-mentioned objectives in a very efficient manner for high-dimensional DNNs with millions of parameters. We present numerical examples using both deterministic and stochastic gradients. We furthermore demonstrate that knowledge of the regularization path allows for a well-generalizing network parametrization.},
  archive      = {J_MLA},
  author       = {Augustina Chidinma Amakor and Konstantin Sonntag and Sebastian Peitz},
  doi          = {10.1016/j.mlwa.2025.100625},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100625},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A multiobjective continuation method to compute the regularization path of deep neural networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Apply a deep learning hybrid model optimized by an improved
chimp optimization algorithm in PM2.5 prediction. <em>MLA</em>,
<em>19</em>, 100624. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100624">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PM 2.5 pollution in the atmosphere not only contaminates the environment but also seriously affects human health. Therefore, studying how to accurately predict future PM 2.5 concentrations holds significant importance and practical value. This paper innovatively P M 2 . 5 proposes a high-accuracy prediction model: RF-ICHOA-CNN-LSTM-Attention. First, the Random Forest (RF) model is utilized to evaluate the importance of air pollution and meteorological features and select more suitable input features. Subsequently, a one-dimensional convolutional neural network (1DCNN) with efficient feature extraction capability is used to extract dynamic features from sequences. The extracted feature vector sequences are then fed into a Long Short-Term Memory Network (LSTM). After the LSTM, an Attention Mechanism is incorporated to assign different weights to the input features, emphasizing the role of the important features. Additionally, the Improved Chimp Optimization Algorithm (IChOA) is employed to optimize the number of neurons in the two hidden layers of LSTM, the learning rate, and the number of training epochs. The experimental results on 12 test functions demonstrate that the optimization performance of IChOA is better than that of ChOA and the representative swarm optimization algorithms used for comparison. In the case of PM 2.5 predictions in Yining and Beijing, experimental results show that the proposed model achieved the best performance in terms of RMSE, MAE, and R 2 This indicates its excellent prediction accuracy and generalization capability, Thus proving its effectiveness in predicting PM 2.5 concentration in the real world.},
  archive      = {J_MLA},
  author       = {Ming Wei and Xiaopeng Du},
  doi          = {10.1016/j.mlwa.2025.100624},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100624},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Apply a deep learning hybrid model optimized by an improved chimp optimization algorithm in PM2.5 prediction},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning techniques and multi-objective programming
to select the best suppliers and determine the orders. <em>MLA</em>,
<em>19</em>, 100623. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selection of appropriate suppliers and allocation the orders among them have become the two key strategic decisions regarding purchasing. In this study, a two-phase integrated approach is proposed for solving supplier selection and order allocation problems. Phase 1 contains four techniques from statistics and Machine Learning (ML), including Auto-Regressive Integrated Moving Average, Random Forest, Gradient Boosting Regression, and Long Short-term Memory for forecasting the demands, using large amounts of real historical data. In Phase 2, suppliers’ qualitative weights are determined by a fuzzy logic model. Then, a new multi-objective programming model is designed, considering multiple periods and products. In this phase, the results of Phase 1 and the results of the fuzzy model are utilized as inputs for the multi-objective model. The weighted-sum method is applied for solving the multi-objective model. The results show Random Forest model leads to more accurate predictions than the other examined models in this study. In addition, based on the results, the selection of the forecasting techniques and different weights of suppliers affect both supplier selection and the related orders.},
  archive      = {J_MLA},
  author       = {Asma ul Husna and Saman Hassanzadeh Amin and Ahmad Ghasempoor},
  doi          = {10.1016/j.mlwa.2025.100623},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100623},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning techniques and multi-objective programming to select the best suppliers and determine the orders},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safety analysis in the era of large language models: A case
study of STPA using ChatGPT. <em>MLA</em>, <em>19</em>, 100622. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Can safety analysis leverage Large Language Models (LLMs)? This study examines the application of Systems Theoretic Process Analysis (STPA) to Automatic Emergency Brake (AEB) and Electricity Demand Side Management (DSM) systems, utilising Chat Generative Pre-Trained Transformer (ChatGPT). We investigate the impact of collaboration schemes, input semantic complexity, and prompt engineering on STPA results. Comparative results indicate that using ChatGPT without human intervention may be inadequate due to reliability issues. However, with careful design, it has the potential to outperform human experts. No statistically significant differences were observed when varying the input semantic complexity or using domain-agnostic prompt guidelines. While STPA-specific prompt engineering produced statistically significant and more pertinent results, ChatGPT generally yielded more conservative and less comprehensive outcomes. We also identify future challenges, such as concerns regarding the trustworthiness of LLMs and the need for standardisation and regulation in this field. All experimental data are publicly accessible.},
  archive      = {J_MLA},
  author       = {Yi Qi and Xingyu Zhao and Siddartha Khastgir and Xiaowei Huang},
  doi          = {10.1016/j.mlwa.2025.100622},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100622},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Safety analysis in the era of large language models: A case study of STPA using ChatGPT},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ensembles of deep one-class classifiers for multi-class
image classification. <em>MLA</em>, <em>19</em>, 100621. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional methods for multi-class classification (MCC) involve using a monolithic feature extractor and classifier trained on data from all the classes simultaneously. These methods are dependent on the number and types of classes and are therefore rigid against changes to the class structure. For instance, if the number of classes needs to be modified or new training data becomes available, retraining would be required for optimum classification performance. Moreover, these classifiers can become biased toward classes with a large data imbalance. An alternative, more attractive framework is to consider an ensemble of one-class classifiers (EOCC) where each one-class classifier (OCC) is trained with data from a single class only, without using any information from the other classes. Although this framework has not yet systematically matched or surpassed the performance of traditional MCC approaches, it deserves further investigation for several reasons. First, it provides a more flexible framework for handling changes in class structure compared to the traditional MCC approach. Second, it is less biased toward classes with large data imbalances compared to the multi-class classification approach. Finally, each OCC can be separately optimized depending on the characteristics of the class it represents. In this paper, we have performed extensive experiments to evaluate EOCC for MCC using traditional OCCs based on Principal Component Analysis (PCA) and Auto-encoders (AE) as well as newly proposed OCCs based on Generative Adversarial Networks (GANs). Moreover, we have compared the performance of EOCC with traditional multi-class DL classifiers including VGG-19, Resnet and EfficientNet. Two different datasets were used in our experiments: (i) a subset from the Plant Village dataset plant disease dataset with high variance in the number of classes and amount of data in each class, and (ii) an Alzheimer’s disease dataset with low amounts of data and a large imbalance in data between classes. Our results show that the GAN-based EOCC outperform previous EOCC approaches and improve the performance gap with traditional MCC approaches.},
  archive      = {J_MLA},
  author       = {Alexander Novotny and George Bebis and Alireza Tavakkoli and Mircea Nicolescu},
  doi          = {10.1016/j.mlwa.2025.100621},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100621},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Ensembles of deep one-class classifiers for multi-class image classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-agent deep reinforcement learning with online and fair
optimal dispatch of EV aggregators. <em>MLA</em>, <em>19</em>, 100620.
(<a href="https://doi.org/10.1016/j.mlwa.2025.100620">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing popularity of electric vehicles (EVs) and the unpredictable behavior of EV owners have attracted attention to real-time coordination of EVs charging management. This paper presents a hierarchical structure for charging management of EVs by integrating fairness and efficiency concepts within the operations of the distribution system operator (DSO) while utilizing a multi-agent deep reinforcement learning (MADRL) framework to tackle the complexities of energy purchasing and distribution among EV aggregators (EVAs). At the upper level, DSO calculates the maximum allowable power for each EVA based on power flow constraints to ensure grid safety. Then, it finds the optimal efficiency-Jain tradeoff (EJT) point, where it sells the highest energy amount while ensuring equitable energy distribution. At the lower level, initially, each EVA acts as an agent employing a double deep Q-network (DDQN) with adaptive learning rates and prioritized experience replay to determine optimal energy purchases from the DSO. Then, the real-time smart dispatch (RSD) controller prioritizes EVs for energy dispatch based on relevant EVs information. Findings indicate the proposed enhanced DDQN outperforms deep deterministic policy gradient (DDPG) and proximal policy optimization (PPO) in cumulative rewards and convergence speed. Finally, the framework’s performance is evaluated against uncontrolled charging and the first come first serve (FCFS) scenario using the 118-bus distribution system, demonstrating superior performance in maintaining safe operation of the grid while reducing charging costs for EVAs. Additionally, the framework’s integration with renewable energy sources (RESs), such as photovoltaic (PV), demonstrates its potential to enhance grid reliability.},
  archive      = {J_MLA},
  author       = {Arian Shah Kamrani and Anoosh Dini and Hanane Dagdougui and Keyhan Sheshyekani},
  doi          = {10.1016/j.mlwa.2025.100620},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100620},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Multi-agent deep reinforcement learning with online and fair optimal dispatch of EV aggregators},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving mango ripeness grading accuracy: A comprehensive
analysis of deep learning, traditional machine learning, and transfer
learning techniques. <em>MLA</em>, <em>19</em>, 100619. (<a
href="https://doi.org/10.1016/j.mlwa.2025.100619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bangladesh ranks among the top 10 countries globally in mango output. Mangoes can be classified based on their ripeness, with skin color being the most significant aspect. The current classification procedure is done manually, leading to mistakes and vulnerability to human error. Most research often focuses on using a single method to assess the ripeness of fruits. The study comprises a set of comprehensive tests showcasing different tactics for determining the most efficient methods through various models. One unique dataset was used for all five models: Gaussian Naive Bayes (GNB), Support Vector Machine (SVM), Gradient Boosting (GB), Random Forest (RF), and K-Nearest Neighbors (KNN). Utilizing convolutional neural networks (CNNs) and VGG16, a pre-trained CNN model, to extract features and train the dataset. Used these training datasets as input to calculate the average accuracy of the five models during testing. In addition to these experiments, these five models using standard techniques also evaluated. The study also included a comparative analysis that emphasized the best performance of each model in various scenarios. This analysis shows that the CNN model consistently performs better than the transfer learning model (VGG16) and classical machine learning methods. Except for the KNN and Naive Bayes scenarios, the VGG16 model achieved much higher accuracy compared to typical machine learning methods. In three other models, classical machine learning outperforms the VGG16 model. The Gradient Boosting model in deep learning (CNN) demonstrated the highest accuracy of 96.28 % compared to other models and techniques.},
  archive      = {J_MLA},
  author       = {Md․ Saon Sikder and Mohammad Shamsul Islam and Momenatul Islam and Md․ Suman Reza},
  doi          = {10.1016/j.mlwa.2025.100619},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100619},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Improving mango ripeness grading accuracy: A comprehensive analysis of deep learning, traditional machine learning, and transfer learning techniques},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting customer subscription in bank telemarketing
campaigns using ensemble learning models. <em>MLA</em>, <em>19</em>,
100618. (<a href="https://doi.org/10.1016/j.mlwa.2025.100618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the use of ensemble learning models bagging, boosting, and stacking to enhance the accuracy and reliability of predicting customer subscriptions in bank telemarketing campaigns. Recognizing the challenges posed by class imbalance and complex customer behaviors, we employ multiple ensemble techniques to build a robust predictive framework. Our analysis demonstrates that stacking models achieve the best overall performance, with an accuracy of 91.88% and an Receiver Operating Characteristic Area Under the Curve (ROC-AUC) score of 0.9491, indicating a strong capability to differentiate between subscribers and non-subscribers. Additionally, feature importance analysis reveals that contact duration, economic indicators like the Euro interbank offered (Euribor) rate, and customer age are the most influential factors in predicting subscription likelihood. These findings suggest that by focusing on customer engagement and economic trends, banks can improve telemarketing campaign effectiveness. We recommend the integration of advanced balancing techniques and real-time prediction systems to further enhance model performance and adaptability. Future work could explore deep learning models and interpretability techniques to gain deeper insights into customer behavior patterns. Overall, this study highlights the potential of ensemble models in predictive modeling for telemarketing, providing a data-driven foundation for more targeted and efficient customer acquisition strategies.},
  archive      = {J_MLA},
  author       = {Michael Peter and Hawa Mofi and Said Likoko and Julius Sabas and Ramadhani Mbura and Neema Mduma},
  doi          = {10.1016/j.mlwa.2025.100618},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100618},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predicting customer subscription in bank telemarketing campaigns using ensemble learning models},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). S&amp;p-500 vs. Nasdaq-100 price movement prediction with
LSTM for different daily periods. <em>MLA</em>, <em>19</em>, 100617. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100617">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores the efficiency of LSTM neural networks in predicting price movements for the two major U.S. stock indices: the S&amp;P-500 and the Nasdaq-100 index. We consider three distinct daily periods: “overnight” (Close-to-Open), “daytime” (Open-to-Close) and “24-hour” (Close-to-Close) trading sessions. Using historical pricing data for these indices since 2000, this study shows how well the standard LSTM model captures price movement patterns to improve short-term trading strategies. The findings reveal that, for the S&amp;P-500, a one-year training with 24-hour periods delivers a 14.5% more return over the Buy-and-Hold strategy. Moreover, combining “overnight” and “daytime” strategies delivers more than 40% return compared to passive index investing. By contrast, for the Nasdaq-100, a shorter training period of three months for “24-hour” periods delivers 90% more return than passive index investing. These results suggest that LSTM effectively learns the unique market dynamics associated with each index and different time periods, offering further insights into how deep learning can enhance financial forecasting and trading opportunities.},
  archive      = {J_MLA},
  author       = {Xiang Zhang and Eugene Pinsky},
  doi          = {10.1016/j.mlwa.2024.100617},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100617},
  shortjournal = {Mach. Learn. Appl.},
  title        = {S&amp;P-500 vs. nasdaq-100 price movement prediction with LSTM for different daily periods},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified wound diagnostic framework for wound segmentation
and classification. <em>MLA</em>, <em>19</em>, 100616. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100616">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chronic wounds affect millions worldwide, posing significant challenges for healthcare systems and a heavy economic burden globally. The segmentation and classification (S&amp;C) of chronic wounds are critical for wound care management and diagnosis, aiding clinicians in selecting appropriate treatments. Existing approaches have utilized either traditional machine learning or deep learning methods for S&amp;C. However, most focus on binary classification, with few addressing multi-class classification, often showing degraded performance for pressure and diabetic wounds. Wound segmentation has been largely limited to foot ulcer images, and there is no unified diagnostic tool for both S&amp;C tasks. To address these gaps, we developed a unified approach that performs S&amp;C simultaneously. For segmentation, we proposed Attention-Dense-UNet (Att- d -UNet), and for classification, we introduced a feature concatenation-based method. Our framework segments wound images using Att- d -UNet, followed by classification into one of the wound types using our proposed method. We evaluated our models on publicly available wound classification datasets (AZH and Medetec) and segmentation datasets (FUSeg and AZH). To test our unified approach, we extended wound classification datasets by generating segmentation masks for Medetec and AZH images. The proposed unified approach achieved 90% accuracy and an 86.55% dice score on the Medetec dataset and 81% accuracy and an 86.53% dice score on the AZH dataset These results demonstrate the effectiveness of our separate models and unified approach for wound S&amp;C.},
  archive      = {J_MLA},
  author       = {Mustafa Alhababi and Gregory Auner and Hafiz Malik and Muteb Aljasem and Zaid Aldoulah},
  doi          = {10.1016/j.mlwa.2024.100616},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100616},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Unified wound diagnostic framework for wound segmentation and classification},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combinations of distributional regression algorithms with
application in uncertainty estimation of corrected satellite
precipitation products. <em>MLA</em>, <em>19</em>, 100615. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To facilitate effective decision-making, precipitation datasets should include uncertainty estimates. Quantile regression with machine learning has been proposed for issuing such estimates. Distributional regression offers distinct advantages over quantile regression, including the ability to model intermittency as well as a stronger ability to extrapolate beyond the training data, which is critical for predicting extreme precipitation. Therefore, here, we introduce the concept of distributional regression in precipitation dataset creation, specifically for the spatial prediction task of correcting satellite precipitation products. Building upon this concept, we formulated new ensemble learning methods that can be valuable not only for spatial prediction but also for other prediction problems. These methods exploit conditional zero-adjusted probability distributions estimated with generalized additive models for location, scale and shape (GAMLSS), spline-based GAMLSS and distributional regression forests as well as their ensembles (stacking based on quantile regression and equal-weight averaging). To identify the most effective methods for our specific problem, we compared them to benchmarks using a large, multi-source precipitation dataset. Stacking was shown to be superior to individual methods at most quantile levels when evaluated with the quantile loss function. Moreover, while the relative ranking of the methods varied across different quantile levels, stacking methods, and to a lesser extent mean combiners, exhibited lower variance in their performance across different quantiles compared to individual methods that occasionally ranked extremely low. Overall, a task-specific combination of multiple distributional regression algorithms could yield significant benefits in terms of stability.},
  archive      = {J_MLA},
  author       = {Georgia Papacharalampous and Hristos Tyralis and Nikolaos Doulamis and Anastasios Doulamis},
  doi          = {10.1016/j.mlwa.2024.100615},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100615},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Combinations of distributional regression algorithms with application in uncertainty estimation of corrected satellite precipitation products},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The association between mindfulness, psychological
flexibility, and rumination in predicting mental health and well-being
among university students using machine learning and structural equation
modeling. <em>MLA</em>, <em>19</em>, 100614. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objectives This study explores the intricate relationships between mindfulness, psychological flexibility, rumination, and their combined impact on mental health and well-being. Methods Random forest regression on survey data from 524 undergraduate students was used to identify significant predictors from a comprehensive set of psychological variables. Neural networks were then trained on various combinations of these predictors to evaluate their performance in predicting mental health and well-being outcomes. Finally, structural equation modeling (SEM) was employed to validate a model based on the identified key predictors, focusing on pathways from mindfulness through psychological flexibility to rumination and well-being. Results The random forest analysis revealed that the mindfulness variables exerted their influence partially indirectly through psychological flexibility and rumination. The deep neural network analysis supported these findings and additionally showed that the mindfulness manifold model (consisting of self-awareness, self-regulation, and self-transcendence) was superior to the Five Facet Mindfulness Questionnaire variables in predicting mental health outcomes. The SEM analysis confirmed that psychological flexibility, particularly its avoidance and acceptance components, mediated the relationship between mindfulness and mental health. The hypothesized serial mediation pathway—mindfulness affecting psychological flexibility, which then influences rumination and subsequently mental health and well-being—was supported by the data. Self-transcendence was a particularly powerful predictor of mental health outcomes. Conclusions The findings underscore the critical role of psychological flexibility and rumination in mediating the effects of mindfulness on mental health and well-being, suggesting that enhancing mindfulness and psychological flexibility might significantly reduce rumination, thereby improving overall mental health and well-being.},
  archive      = {J_MLA},
  author       = {Ruohan Feng and Vaibhav Mishra and Xin Hao and Paul Verhaeghen},
  doi          = {10.1016/j.mlwa.2024.100614},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100614},
  shortjournal = {Mach. Learn. Appl.},
  title        = {The association between mindfulness, psychological flexibility, and rumination in predicting mental health and well-being among university students using machine learning and structural equation modeling},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stairway to heaven: An emotional journey in divina commedia
with threshold-based naïve bayes classifier. <em>MLA</em>, <em>19</em>,
100613. (<a href="https://doi.org/10.1016/j.mlwa.2024.100613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational literary uses data science and computer science techniques to study literature. In this framework, we investigate how an expert system can acquire knowledge from the specific content of a narrative text without any pre-existing information about it. We utilize the Threshold-based Naïve Bayes (Tb-NB) classifier to analyze the content of Dante Alighieri’s Divina Commedia poem. Tb-NB is a probabilistic data-driven model that predicts the polarity of a binary response based on the probability of an event occurring given certain features, and assigns a log-likelihood score to each word in a text. Our first task is understanding if and how the links between lexical forms and meanings characterize the three parts of the poem (Inferno, Purgatorio and Paradiso) in order to predict if a Canto belongs to Inferno or Paradiso based on its specific content, and to determine if a Canto of Purgatorio is more similar to those of Inferno or to those of Paradiso. We show Tb-NB outperform other similar approaches and achieves the same performance of Random Forest (F1-score = 0.985) but providing much more information to interpret the specific content and the lexical forms used by Dante Alighieri in its poem. The Tb-NB’s scores are the base of knowledge for the implementation of an expert system, like a search engine, that can help users to identify the most informative verses of a Canto or by better comprehend or discover the content of the poem from a word related to a particular feeling or emotion.},
  archive      = {J_MLA},
  author       = {Maurizio Romano and Claudio Conversano},
  doi          = {10.1016/j.mlwa.2024.100613},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100613},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Stairway to heaven: An emotional journey in divina commedia with threshold-based naïve bayes classifier},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive gate residual connection and multi-scale RCNN for
fake news detection. <em>MLA</em>, <em>19</em>, 100612. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100612">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of false news based on text classification technology has significant research significance and practical value in the current information age. However, existing methods overlook the problem of uneven sample distribution in the false news dataset and fail to consider the mutual influence between news articles. In light of this, this paper proposes a new method for false news detection. Firstly, news texts are embedded using Electra (Efficiently Learning an Encoder that Classifies Token Replacements Accurately) to obtain word embedding representations. Secondly, Multi-Scale Recurrent Convolutional Neural Network (RCNN) is employed to further extract contextual information from news texts. Self-attention is introduced to calculate attention scores between news articles, allowing for mutual influence between news features. The establishment of connections between modules is achieved through adaptive gated residual connections. Finally, the focal loss function is used to balance the relationship between few-sample and multi-sample data in the dataset. Experimental results on publicly available false news detection datasets demonstrate that the proposed method achieves higher prediction accuracy than the comparative methods. This method provides a new perspective for the field of false news detection, playing a positive role in promoting information authenticity and protecting public interests.},
  archive      = {J_MLA},
  author       = {QunHui Zhou and Tijian Cai},
  doi          = {10.1016/j.mlwa.2024.100612},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100612},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Adaptive gate residual connection and multi-scale RCNN for fake news detection},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Practical classification accuracy of sequential data using
neural networks. <em>MLA</em>, <em>19</em>, 100611. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing studies on neural network accuracy utilize datasets that may not always reflect real-world conditions. While it has been demonstrated that accuracy tends to decrease as the number of benign samples increases, this effect has not been quantitatively assessed within neural networks. Moreover, its relevance to security tasks beyond malware classification remains unexplored. In this research, we refined the metric to evaluate the degradation of accuracy with an increased number of benign samples in test data. Utilizing both standard and specific neural network models, we conducted experiments to adapt this metric to neural networks and various feature extraction techniques. Using the FFRI dataset, comprising 150,000 malware and 400,000 benign samples, along with the URL dataset, containing 3143 malicious and 106,545,781 benign samples, we increased benign samples in the test set while keeping the training set’s malicious and benign samples constant. Our findings indicate that neural networks can indeed overestimate their accuracy with a smaller count of benign samples. Importantly, our refined metric is not only applicable to neural networks but is also effective for other feature extraction methods and security tasks beyond malware detection.},
  archive      = {J_MLA},
  author       = {Mamoru Mimura},
  doi          = {10.1016/j.mlwa.2024.100611},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100611},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Practical classification accuracy of sequential data using neural networks},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Demographic bias mitigation at test-time using uncertainty
estimation and human–machine partnership. <em>MLA</em>, <em>19</em>,
100610. (<a href="https://doi.org/10.1016/j.mlwa.2024.100610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial attribute classification algorithms frequently manifest demographic biases by obtaining differential performance across gender and racial groups. Existing bias mitigation techniques are mostly in-processing techniques, i.e., implemented during the classifier’s training stage, that often lack generalizability, require demographically annotated training sets, and exhibit a trade-off between fairness and classification accuracy. In this paper, we propose a technique to mitigate bias at the test time i.e., during the deployment stage, by harnessing prediction uncertainty and human–machine partnership. To this front, we propose to utilize those lowest percentages of test data samples identified as outliers with high prediction uncertainty. These identified uncertain samples at test-time are labeled by human analysts for decision rendering and for subsequently re-training the deep neural network in a continual learning framework. With minimal human involvement and through iterative refinement of the network with human guidance at test-time, we seek to enhance the accuracy as well as the fairness of the already deployed facial attribute classification algorithms. Extensive experiments are conducted on gender and smile attribute classification tasks using four publicly available datasets and with gender and race as the protected attributes. The obtained outcomes consistently demonstrate improved accuracy by up to 2% and 5% for the gender and smile attribute classification tasks, respectively, using our proposed approaches. Further, the demographic bias was significantly reduced, outperforming the State-of-the-Art (SOTA) bias mitigation and baseline techniques by up to 55% for both classification tasks. The demo shall be released on https://github.com/hashtaglensman/HumanintheLoop .},
  archive      = {J_MLA},
  author       = {Anoop Krishnan Upendran Nair and Ajita Rattani},
  doi          = {10.1016/j.mlwa.2024.100610},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100610},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Demographic bias mitigation at test-time using uncertainty estimation and human–machine partnership},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of convolutional neural networks and ensemble
methods in the fiber volume content analysis of natural fiber
composites. <em>MLA</em>, <em>19</em>, 100609. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incorporation of natural fibers into fiber-reinforced polymer composites (FRPC) has the potential to bolster their sustainability. A critical attribute of FRPC is the fiber volume content ( FVC ), a parameter that profoundly influences their thermo-mechanical characteristics. However, the determination of FVC in natural fiber composites (NFC) through manual analysis of light microscopy images is a labor-intensive process. In this work, it is demonstrated that the pixels from light microscopy images of NFC can be utilized to predict FVC using machine learning (ML) models. In this proof-of-concept investigation, it is shown that convolutional neural network-based models predict FVC with an accuracy required in polymer engineering applications, with a mean average error of 2.72 % and an R 2 coefficient of 0.85. Finally, it is shown that much simpler ML models, non-specialized in image recognition, besides being much easier and more efficient to optimize and train, can also deliver good accuracies required for FVC characterization, which not only contributes to the sustainability, but also facilitates the access of such models by researchers in regions with little computational resources. This study marks a substantial advancement in the area of automated characterization of NFC, and democratization of knowledge, offering a promising avenue for the enhancement of sustainable materials.},
  archive      = {J_MLA},
  author       = {Florian Rothenhäusler and Rodrigo Queiroz Albuquerque and Marcel Sticher and Christopher Kuenneth and Holger Ruckdaeschel},
  doi          = {10.1016/j.mlwa.2024.100609},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100609},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Application of convolutional neural networks and ensemble methods in the fiber volume content analysis of natural fiber composites},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of fraud in IoT based credit card collected
dataset using machine learning. <em>MLA</em>, <em>19</em>, 100603. (<a
href="https://doi.org/10.1016/j.mlwa.2024.100603">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due in large part to the proliferation of electronic financial transactions, credit card fraud is a serious problem for customers, merchants, and banks. For this reason, a novel approach is offered to fraud detection that makes use of cutting-edge ML methods in an IoT setting. The method in this paper employs a carefully selected set of cutting-edge ML algorithms specifically designed to handle the complexities of fraud detection, in contrast to older approaches that have difficulty adapting to shifting fraud patterns. In order to address the many facets of the problem, the methodology employs a large collection of ML models. These models include deep neural networks, decision trees, support vector machines, random forests, and clustering methods. This paper provides a solution that is able to detect fraudulent activity in real time by efficiently analyzing massive amounts of transactional data thanks to the power of big data processing and cloud computing. The model is able to distinguish between valid and fraudulent transactions thanks to careful feature engineering and anomaly detection methods. Extensive experiments on a large and diverse collection of real and simulated credit card transactions, both legitimate and fraudulent, prove the success of this technique. The findings demonstrate state-of-the-art performance in fraud detection, with increased precision and recall rates compared to traditional methods. And because the presented ML models are easy to understand, they improve fraud risk management and prevention techniques. The findings of this study provide banking institutions, government agencies, and policymakers with vital information for combating the negative effects of credit card fraud on consumers, companies, and the economy as a whole. This study provides a solution to the problem of fraud in the Internet of Things (IoT) ecosystem and paves the way for future developments in this crucial area by proposing a unique ML-driven approach to the problem.},
  archive      = {J_MLA},
  author       = {Mohammed Naif Alatawi},
  doi          = {10.1016/j.mlwa.2024.100603},
  journal      = {Machine Learning with Applications},
  month        = {3},
  pages        = {100603},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Detection of fraud in IoT based credit card collected dataset using machine learning},
  volume       = {19},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
