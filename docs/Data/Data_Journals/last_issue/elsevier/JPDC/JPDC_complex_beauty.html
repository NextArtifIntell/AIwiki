<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JPDC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jpdc---9">JPDC - 9</h2>
<ul>
<li><details>
<summary>
(2025). Front matter 1 - full title page (regular issues)/special
issue title page (special issues). <em>JPDC</em>, <em>199</em>, 105060.
(<a href="https://doi.org/10.1016/S0743-7315(25)00027-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JPDC},
  doi          = {10.1016/S0743-7315(25)00027-9},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105060},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Front matter 1 - full title page (regular issues)/Special issue title page (special issues)},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DePoL: Assuring training integrity in collaborative learning
via decentralized verification. <em>JPDC</em>, <em>199</em>, 105056. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative learning enables multiple participants to jointly train complex models but is vulnerable to attacks like model poisoning or backdoor attacks. Ensuring training integrity can prevent these threats by blocking any tampered contributions from affecting the model. However, traditional approaches often suffer from single points of bottleneck or failure in decentralized environments. To address these issues, we propose DePoL , a secure, scalable, and efficient decentralized verification framework based on duplicated execution. DePoL leverages blockchain to distribute the verification tasks across multiple participant-formed groups, eliminating single-point bottlenecks. Within each group, redundant verification and a majority-based arbitration prevent single points of failure. To further enhance security, DePoL introduces a two-stage plagiarism-free commitment scheme to prevent untrusted verifiers from exploiting public on-chain data. Additionally, a hybrid verification method employs fuzzy matching to handle unpredictable reproduction errors, while a “slow path” ensures zero false positives for honest trainers. Our theoretical analysis demonstrates DePoL &#39;s security and termination properties. Extensive evaluations show that DePoL has overhead similar to common distributed machine learning algorithms, while outperforming centralized verification schemes in scalability, reducing training latency by up to 46%. Additionally, DePoL effectively handles reproduction errors with 0 false positives.},
  archive      = {J_JPDC},
  author       = {Zhicheng Xu and Xiaoli Zhang and Xuanyu Yin and Hongbing Cheng},
  doi          = {10.1016/j.jpdc.2025.105056},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105056},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {DePoL: Assuring training integrity in collaborative learning via decentralized verification},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Massive parallel simulation of gas turbine combustion using
a fully implicit unstructured solver on the heterogeneous sunway
taihulight supercomputer. <em>JPDC</em>, <em>199</em>, 105055. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive parallel simulations of a full annular aeroengine combustor chamber have been achieved on the on-chip heterogeneous Sunway Taihulight supercomputer. A billion-size unstructured mesh is generated through grid replication and rotation, accompanied by the development of an efficient geometric matching algorithm to address the conformal interface issue. We developed graph-based and tree-based loop fusion approaches for implicit solving procedure of the momentum equation, it is found that the strategic utilization of data reuse and separation of vector computation significantly enhances the performance on many-core processor. For linear system, a finer-grained parallelization based on sparse matrix-vector multiplication and vector computation is validated. Massive parallel tests utilizing 16 K processes with 1 M cores are successfully conducted to simulate the turbulent non-premixed combustion in an aeroengine combustor with nearly one billion cells. Compared to the pre-optimization version, this fully accelerated code achieves an impressive 5.48 times speedup in overall performance, with a parallel efficiency of up to 59 %.},
  archive      = {J_JPDC},
  author       = {Fei Gao and Hu Ren and Zhuyin Ren and Ming Liu and Chengpeng Zhao and Guangwen Yang},
  doi          = {10.1016/j.jpdc.2025.105055},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105055},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Massive parallel simulation of gas turbine combustion using a fully implicit unstructured solver on the heterogeneous sunway taihulight supercomputer},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient GPU-accelerated parallel cross-correlation.
<em>JPDC</em>, <em>199</em>, 105054. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-correlation is a data analysis method widely employed in various signal processing and similarity-search applications. Our objective is to design a highly optimized GPU-accelerated implementation that will speed up the applications and also improve energy efficiency since GPUs are more efficient than CPUs in data-parallel tasks. There are two rudimentary ways to compute cross-correlation — a definition-based algorithm that tries all possible overlaps and an algorithm based on the Fourier transform, which is much more complex but has better asymptotical time complexity. We have focused mainly on the definition-based approach which is better suited for smaller input data and we have implemented multiple CUDA-enabled algorithms with multiple optimization options. The algorithms were evaluated on various scenarios, including the most typical types of multi-signal correlations, and we provide empirically verified optimal solutions for each of the studied scenarios.},
  archive      = {J_JPDC},
  author       = {Karel Maděra and Adam Šmelko and Martin Kruliš},
  doi          = {10.1016/j.jpdc.2025.105054},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105054},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Efficient GPU-accelerated parallel cross-correlation},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GPU memory usage optimization for backward propagation in
deep network training. <em>JPDC</em>, <em>199</em>, 105053. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern Deep Learning, it has been a trend to design larger Deep Neural Networks (DNNs) for the execution of more complex tasks and better accuracy. On the other hand, Convolutional Neural Networks (CNNs) have become the standard method for most of computer vision tasks. However, the memory allocation for the intermediate data in convolution layers can cause severe memory pressure during model training. Many solutions have been proposed to resolve the problem. Besides hardware-dependent solutions, a general methodology rematerialization can reduce GPU memory usage by trading computation for memory efficiently. The idea is to select a set of intermediate results during the forward phase as checkpoints , and only save them in memory to reduce memory usage. The backward phase recomputes the intermediate data from the closest checkpoints in memory as needed. This recomputation increases execution time but saves memory by not storing all intermediate results in memory during the forward phase. In this paper, we will focus on efficiently finding the optimal checkpoint subset to achieve the least peak memory usage during the model training. We first describe the theoretical background of the training of a neural network using mathematical equations. We use these equations to identify all essential data required during both forward and backward phases to compute the gradient of weights of the model. We first identify the checkpoint selection problem and propose a dynamic programming algorithm with time complexity O ( n 3 ) to solve the problem of finding the optimal checkpoint subset. With extensive experiments, we formulate a more accurate description of the problem using our theoretical analysis and revise the objective function based on the tracing, and propose an O ( n ) -time algorithm for finding the optimal checkpoint subset.},
  archive      = {J_JPDC},
  author       = {Ding-Yong Hong and Tzu-Hsien Tsai and Ning Wang and Pangfeng Liu and Jan-Jan Wu},
  doi          = {10.1016/j.jpdc.2025.105053},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105053},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {GPU memory usage optimization for backward propagation in deep network training},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An introductory-level undergraduate CS course that
introduces parallel computing. <em>JPDC</em>, <em>199</em>, 105044. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present the curricular design, pedagogy, and goals of an introductory-level course on computer systems that introduces parallel and distributed computing (PDC) to students who have only a CS1 background. With the ubiquity of multicore processors, cloud computing, and hardware accelerators, PDC topics have become fundamental knowledge areas in the undergraduate CS curriculum. As a result, it is increasingly important for students to learn a common core of introductory parallel and distributed computing topics and to develop parallel thinking skills early in their CS studies. Our introductory-level course focuses on three main curricular goals: 1) understanding how a computer runs a program, 2) evaluating system costs associated with running a program, and 3) taking advantage of the power of parallel computing. We elaborate on the goals and details of our course&#39;s key modules, and we discuss our pedagogical approach that includes active-learning techniques. We also include an evaluation of our course and a discussion of our experiences teaching it since Fall 2012. We find that the PDC foundation gained through early exposure in our course helps students gain confidence in their ability to expand and apply their understanding of PDC concepts throughout their CS education.},
  archive      = {J_JPDC},
  author       = {Tia Newhall and Kevin C. Webb and Vasanta Chaganti and Andrew Danner},
  doi          = {10.1016/j.jpdc.2025.105044},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105044},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {An introductory-level undergraduate CS course that introduces parallel computing},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRViT: A dynamic redundancy-aware vision transformer
accelerator via algorithm and architecture co-design on FPGA.
<em>JPDC</em>, <em>199</em>, 105042. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multi-modal artificial intelligence (MAI) has attracted significant interest due to its capability to process and integrate data from multiple modalities, including images, text, and audio. Addressing MAI tasks in distributed systems necessitate robust and efficient architectures. The Transformer architecture has emerged as a primary network in this context. The integration of Vision Transformers (ViTs) within multimodal frameworks is crucial for enhancing the processing and comprehension of image data across diverse modalities. However, the complex architecture of ViTs and the extensive resources required for processing large-scale image data pose high computational and storage demands. These demands are particularly challenging for deploying ViTs on edge devices within distributed frameworks. To address this issue, we propose a novel dynamic redundancy-aware ViT accelerator based on parallel computing, termed DRViT. DRViT is supported by an algorithm and architecture co-design. We first propose a hardware-friendly lightweight algorithm featuring token merging, token pruning, and an INT8 quantization scheme. Then, we design a specialized architecture to support this algorithm, transforming the lightweight algorithm into significant latency and energy-efficiency improvements. Our design is implemented on the Xilinx Alveo U250, achieving an overall inference latency of 0.86 ms and 1.17 ms per image for ViT-tiny at 140 MHz and 100 MHz, respectively. The throughput can reach 1,380 GOP/s at peak, demonstrating superior performance compared to state-of-the-art accelerators, even at lower frequencies.},
  archive      = {J_JPDC},
  author       = {Xiangfeng Sun and Yuanting Zhang and Qinyu Wang and Xiaofeng Zou and Yujia Liu and Ziqian Zeng and Huiping Zhuang},
  doi          = {10.1016/j.jpdc.2025.105042},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105042},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {DRViT: A dynamic redundancy-aware vision transformer accelerator via algorithm and architecture co-design on FPGA},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latency-aware placement of stream processing operators in
modern-day stream processing frameworks. <em>JPDC</em>, <em>199</em>,
105041. (<a href="https://doi.org/10.1016/j.jpdc.2025.105041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rise of the Internet of Things has substantially increased the number of interconnected devices at the edge of the network. As a result, a large number of computations are now distributed in the compute continuum, spanning from the edge to the cloud, generating vast amounts of data. Stream processing is typically employed to process this data in near real-time due to its efficiency in handling continuous streams of information in a scalable manner. However, many stream processing approaches do not consider the underlying network devices of the compute continuum as candidate resources for processing data. Moreover, many existing works do not consider the incurred network latency of performing computations on multiple devices in a distributed way. To avoid this, we formulate an optimization problem for utilizing the complete compute continuum resources and design heuristics to solve this problem efficiently. Furthermore, we integrate our heuristics into Apache Storm and perform experiments that show latency- and throughput-related benefits compared to alternatives.},
  archive      = {J_JPDC},
  author       = {Raphael Ecker and Vasileios Karagiannis and Michael Sober and Stefan Schulte},
  doi          = {10.1016/j.jpdc.2025.105041},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105041},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Latency-aware placement of stream processing operators in modern-day stream processing frameworks},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Skyward secure: Advancing drone data-sharing in 6G with
decentralized dataspace and supported technologies. <em>JPDC</em>,
<em>199</em>, 105040. (<a
href="https://doi.org/10.1016/j.jpdc.2025.105040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacity of Dataspace enables the distribution of heterogeneous data from several sources and domains and has attracted attention for resolving data integration challenges. Drone data sharing faces challenges such as protecting privacy and security, building trust and dependability, controlling latency and scalability, facilitating real-time data processing, and preserving the caliber of shared models. Therefore, sixth-generation (6G) networks provide high throughput and low latency to improve drone operations; security issues are exacerbated by the sensitive nature of shared data and the lack of centralized monitoring. To address the challenges, this paper presents a conceptual framework for a Dataspace in the Sky to enable secure and efficient drone data-sharing within 6G networks in the transition from Industry 4.0 to Industry 5.0. The Dataspace in the Sky integrates Federated Learning (FL), a decentralized Machine Learning (ML) approach that enhances security and privacy by sharing models instead of raw data, facilitating effective drone collaboration. However, the quality of shared local models often suffers due to inconsistent data contributions and unreliable recording mechanisms, which can undermine the performance of FL. To tackle the challenges, the framework employs blockchain (BC) to decentralize and secure the Dataspace, ensuring the integrity of contribution records and improving the reliability of shared models. Dataspace in the Sky empowered decentralized data sharing which addresses latency issues by decentralizing decision-making and enhances trust and reliability by leveraging immutable and transparent BC mechanisms. The robustness of Dataspace in the Sky solution is not only secures drone-sharing operations in 6G environments but enables the development of citizen-friendly mobility services, expanding opportunities across smart environments.},
  archive      = {J_JPDC},
  author       = {Saeed Hamood Alsamhi and Sumit Srivastava and Mamoon Rashid and Amnnah Alhabeeb and Santosh Kumar and Navin Singh Rajput and Ammar Hawbani and Liang Zhao and Mohammed A.A. Al-qaness and Edward Curry},
  doi          = {10.1016/j.jpdc.2025.105040},
  journal      = {Journal of Parallel and Distributed Computing},
  month        = {5},
  pages        = {105040},
  shortjournal = {J. Parallel Distrib. Comput.},
  title        = {Skyward secure: Advancing drone data-sharing in 6G with decentralized dataspace and supported technologies},
  volume       = {199},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
