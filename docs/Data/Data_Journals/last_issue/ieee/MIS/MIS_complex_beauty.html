<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MIS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mis---13">MIS - 13</h2>
<ul>
<li><details>
<summary>
(2025). Exploring ChatGPT-based augmentation strategies for
contrastive aspect-based sentiment analysis. <em>MIS</em>,
<em>40</em>(1), 69–76. (<a
href="https://doi.org/10.1109/MIS.2024.3508432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) involves identifying sentiment toward specific aspect terms in a sentence and allows us to uncover people’s nuanced perspectives and attitudes on particular aspects of a product, service, or topic. However, the scarcity of labeled data poses a significant challenge to training high-quality models. To address this issue, we explore the potential of data augmentation using ChatGPT, a well-performing large language model, to enhance the sentiment classification performance toward aspect terms. Specifically, we explore three data augmentation strategies based on ChatGPT: context-focused, aspect-focused, and context–aspect data augmentation techniques. Context-focused data augmentation focuses on changing the word expression of context words in the sentence while keeping aspect terms unchanged. In contrast, aspect-focused data augmentation aims to change aspect terms but keep context words unchanged. Context–aspect data augmentation integrates these two data augmentations to generate augmented samples. Furthermore, we incorporate contrastive learning into the ABSA tasks to improve performance. Extensive experiments show that all three data augmentation techniques lead to performance improvements, with the context–aspect data augmentation strategy performing best and surpassing the performance of the baseline models.},
  archive      = {J_MIS},
  author       = {Lingling Xu and Haoran Xie and S. Joe Qin and Fu Lee Wang and Xiaohui Tao},
  doi          = {10.1109/MIS.2024.3508432},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {69-76},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Exploring ChatGPT-based augmentation strategies for contrastive aspect-based sentiment analysis},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Confirmation and specificity biases in large language
models: An explorative study. <em>MIS</em>, <em>40</em>(1), 63–68. (<a
href="https://doi.org/10.1109/MIS.2024.3513992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article explores the presence of confirmation bias and specificity bias in three large language models (LLMs): ChatGPT, Claude, and Gemini. To investigate these biases, I adapted a test originally designed for human subjects to study confirmation bias. Using this test, I analyzed how each LLM responded to an identical prompt regarding a rule for a sequence of numbers. Like human subjects, the LLMs exhibited confirmation bias in their responses and generated solutions prone to “overfitting” the data, leading to specificity bias.},
  archive      = {J_MIS},
  author       = {Daniel E. O’Leary},
  doi          = {10.1109/MIS.2024.3513992},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {63-68},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Confirmation and specificity biases in large language models: An explorative study},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Large-scale package deliveries with unmanned aerial vehicles
using collective learning. <em>MIS</em>, <em>40</em>(1), 53–62. (<a
href="https://doi.org/10.1109/MIS.2024.3439535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) have significant practical advantages for delivering packages, and many logistics companies have begun deploying UAVs for commercial package deliveries. To deliver packages quickly and cost-effectively, the routes taken by UAVs from depots to customers must be optimized. We present an innovative, practical package-delivery model wherein multiple UAVs deliver multiple packages to customers, who are compensated for late deliveries. Further, we propose a novel methodology that combines a new plan-generation algorithm with a collective-learning heuristic to quickly determine cost-effective paths of UAVs, even for large-scale deliveries up to 10,000 customers. To demonstrate our methodology, we applied our highly flexible approach to a depot in Heathrow Airport, London. We show that our coordinated approach, in which the UAVs collectively determine their flight paths, leads to similar operational costs as those of the ant colony optimization technique and outperforms it for large-scale package deliveries.},
  archive      = {J_MIS},
  author       = {Arun Narayanan and Evangelos Pournaras and Pedro H. J. Nardelli},
  doi          = {10.1109/MIS.2024.3439535},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {53-62},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Large-scale package deliveries with unmanned aerial vehicles using collective learning},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facilitating autonomous driving tasks with large language
models. <em>MIS</em>, <em>40</em>(1), 45–52. (<a
href="https://doi.org/10.1109/MIS.2024.3466518">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore how large language models (LLMs) can expedite and automate the learning process for autonomous driving tasks. This involves harnessing LLM knowledge to shape a learning framework and utilizing LLMs to guide the learning process. We conduct a case study to demonstrate LLMs’ ability to export driving rules. LLM outputs may not be entirely reliable for the direct handling of driving decisions due to potential inaccuracies and inconsistencies. To address these issues, we propose integrating LLM knowledge with statistical learning. This enables LLMs to export task-specific knowledge as symbolic rules, forming the initial learning structure. Rule weights are calculated based on statistical salience derived from training data, resulting in a set of weighted rules for robust decision making. Furthermore, this set of weighted rules preserves strong semantics, allowing LLMs to comprehend and make modifications based on varying needs. Simulations using a highway driving simulator validate the effectiveness of our approach.},
  archive      = {J_MIS},
  author       = {Mengyao Wu and F. Richard Yu and Peter Xiaoping Liu and Ying He},
  doi          = {10.1109/MIS.2024.3466518},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {45-52},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Facilitating autonomous driving tasks with large language models},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge routing in decentralized learning. <em>MIS</em>,
<em>40</em>(1), 38–44. (<a
href="https://doi.org/10.1109/MIS.2024.3505543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With mobile and Internet of Things devices becoming pervasive in our lives and recent advances in edge computational intelligence [e.g., edge artificial intelligence/machine learning (AI/ML)], it became evident that the traditional methods for training AI/ML models are becoming obsolete, especially with the growing concerns over privacy and security. This work highlights the key challenges that prevent edge AI/ML from seeing wide-range adoption in different sectors, especially for large-scale scenarios. We advocate a knowledge-centric design in which the produced knowledge in the network is discovered and routed to the knowledge requester. This work highlights the importance of knowledge routing for the proposed decentralized learning framework to be effective.},
  archive      = {J_MIS},
  author       = {Ahmed M. Abdelmoniem and Yuchen Zhao},
  doi          = {10.1109/MIS.2024.3505543},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {38-44},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Knowledge routing in decentralized learning},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The rise of small language models. <em>MIS</em>,
<em>40</em>(1), 30–37. (<a
href="https://doi.org/10.1109/MIS.2024.3517792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs), such as GPT and LLAMA, exhibit exceptional comprehension and reasoning capabilities across a wide range of tasks, which are a result of the extensive corpora and the enormous number of parameters in a model. However, their size can pose significant challenges for deployment, particularly on resource-constrained devices. For issues that degrade the user experience, such as efficiency, latency, safety, and privacy, small language models (SLMs) offer a solution. This article begins by outlining the key principles behind SLMs and the reasons for their importance in the field. Subsequently, we discuss the methods used to develop SLMs and explore the collaboration between SLMs and LLMs. By exploring the pathways for harnessing the unique capabilities of SLMs and optimizing their integration with LLMs, it contributes to the ongoing discussion on their application and collaboration in natural language processing and offers insights for advancement and innovation in the field.},
  archive      = {J_MIS},
  author       = {Qin Zhang and Ziqi Liu and Shirui Pan},
  doi          = {10.1109/MIS.2024.3517792},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {30-37},
  shortjournal = {IEEE Intell. Syst.},
  title        = {The rise of small language models},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence: Looking forward 15 years.
<em>MIS</em>, <em>40</em>(1), 25–29. (<a
href="https://doi.org/10.1109/MIS.2024.3517793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Almost 10 years ago, I co-authored a report that predicted the effects of Artificial Intelligence on daily life in the year 2030. This article reflects on and evaluates our predictions from a decade ago and looks forward another decade and a half. While there are good reasons for both excitement and apprehension, it remains within our hands, as a society, to ensure that the benefits of AI outweigh the risks.},
  archive      = {J_MIS},
  author       = {Peter Stone},
  doi          = {10.1109/MIS.2024.3517793},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {25-29},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Artificial intelligence: Looking forward 15 years},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The turing test at 75: Its legacy and future prospects.
<em>MIS</em>, <em>40</em>(1), 20–24. (<a
href="https://doi.org/10.1109/MIS.2024.3517892">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Turing test, proposed by Alan Turing in 1950, is the most iconic concept in artificial intelligence (AI). This article commemorates 75 years of the Turing test by exploring its origins, significance, and evolving relevance in the age of modern AI. It also highlights the Turing test’s legacy and discusses its multifaceted impact on AI’s evolution and future prospects. Despite its limitations, the Turing test remains a cornerstone of philosophical thought, and a foundational tool for discussing and researching AI, an idea envisioned 75 years ago—long before the field of AI had begun to take shape.},
  archive      = {J_MIS},
  author       = {San Murugesan},
  doi          = {10.1109/MIS.2024.3517892},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {20-24},
  shortjournal = {IEEE Intell. Syst.},
  title        = {The turing test at 75: Its legacy and future prospects},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI’s 10 to watch for 2024. <em>MIS</em>, <em>40</em>(1),
14–19. (<a href="https://doi.org/10.1109/MIS.2024.3517893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article features the official announcement of the 2024 edition of the IEEE Computer Society biennial competition of AI&#39;s 10 to Watch focusing on identifying the rising stars in various areas of the broad AI communities. The 10 awardees are introduced in this article.},
  archive      = {J_MIS},
  author       = {Jurgen Dix and Zhongfei Mark Zhang},
  doi          = {10.1109/MIS.2024.3517893},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {14-19},
  shortjournal = {IEEE Intell. Syst.},
  title        = {AI’s 10 to watch for 2024},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reflections from former EICs: 40 years of IEEE intelligent
systems. <em>MIS</em>, <em>40</em>(1), 9–13. (<a
href="https://doi.org/10.1109/MIS.2024.3517972">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this commemorative article, five past editors-in-chief of IEEE Intelligent Systems reflect on the magazine’s first 40 years and share their memories.},
  archive      = {J_MIS},
  author       = {Daniel Edmund O’Leary and James Hendler and Daniel Zeng and V.S. Subrahmanian and San Murugesan},
  doi          = {10.1109/MIS.2024.3517972},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {9-13},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Reflections from former EICs: 40 years of IEEE intelligent systems},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Forty years of IEEE intelligent systems: Heralding research
and innovation in AI. <em>MIS</em>, <em>40</em>(1), 8. (<a
href="https://doi.org/10.1109/MIS.2024.3517933">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MIS},
  author       = {Jaideep Vaidya},
  doi          = {10.1109/MIS.2024.3517933},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {8},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Forty years of IEEE intelligent systems: Heralding research and innovation in AI},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IEEE intelligent systems: Celebrating 40 years of excellence
and looking ahead to the future. <em>MIS</em>, <em>40</em>(1), 7. (<a
href="https://doi.org/10.1109/MIS.2024.3517912">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MIS},
  author       = {Hironori Washizaki},
  doi          = {10.1109/MIS.2024.3517912},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {7},
  shortjournal = {IEEE Intell. Syst.},
  title        = {IEEE intelligent systems: Celebrating 40 years of excellence and looking ahead to the future},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pioneering the future: Advancing innovation and
collaboration. <em>MIS</em>, <em>40</em>(1), 5–6. (<a
href="https://doi.org/10.1109/MIS.2024.3515752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_MIS},
  author       = {Bo An},
  doi          = {10.1109/MIS.2024.3515752},
  journal      = {IEEE Intelligent Systems},
  month        = {1-2},
  number       = {1},
  pages        = {5-6},
  shortjournal = {IEEE Intell. Syst.},
  title        = {Pioneering the future: Advancing innovation and collaboration},
  volume       = {40},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
