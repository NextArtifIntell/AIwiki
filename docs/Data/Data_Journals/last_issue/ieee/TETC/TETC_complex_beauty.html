<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TETC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tetc---21">TETC - 21</h2>
<ul>
<li><details>
<summary>
(2025). Fair influence maximization in social networks: A
community-based evolutionary algorithm. <em>TETC</em>, <em>13</em>(1),
262–275. (<a href="https://doi.org/10.1109/TETC.2024.3403891">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) has been extensively studied in network science, which attempts to find a subset of users to maximize the influence spread. A new variant of IM, fair IM (FIM), which primarily enhances the fair propagation of information, has attracted increasing attention in academia. However, existing algorithms for FIM suffer from a trade-off between fairness and running time, as it is difficult to ensure that users are fairly influenced in terms of sensitive attributes, such as race or gender, while maintaining a high influence spread. To tackle this problem, herein, we propose an effective and efficient community-based evolutionary algorithm for FIM (named CEA-FIM). In CEA-FIM, a community-based node selection strategy is proposed to identify potential nodes, which not only considers the size of the community but also the attributes of the nodes in the community. Subsequently, we designed an evolutionary algorithm based on the proposed node selection strategy to hasten the solution search, including the novel initialization, crossover, and mutation strategies. We validated the proposed algorithm by performing experiments on real-world and synthetic networks. The experimental results show that the proposed CEA-FIM achieves a better balance between effectiveness and efficiency than state-of-the-art methods do.},
  archive      = {J_TETC},
  author       = {Kaicong Ma and Xinxiang Xu and Haipeng Yang and Renzhi Cao and Lei Zhang},
  doi          = {10.1109/TETC.2024.3403891},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {262-275},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Fair influence maximization in social networks: A community-based evolutionary algorithm},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Linearizing binary optimization problems using variable
posets for ising machines. <em>TETC</em>, <em>13</em>(1), 250–261. (<a
href="https://doi.org/10.1109/TETC.2024.3403871">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ising machines are next-generation computers expected to efficiently sample near-optimal solutions of combinatorial optimization problems. Combinatorial optimization problems are modeled as quadratic unconstrained binary optimization (QUBO) problems to apply an Ising machine. However, current state-of-the-art Ising machines still often fail to output near-optimal solutions due to the complicated energy landscape of QUBO problems. Furthermore, the physical implementation of Ising machines severely restricts the size of QUBO problems to be input as a result of limited hardware graph structures. In this study, we take a new approach to these challenges by injecting auxiliary penalties preserving the optimum, which reduces quadratic terms in QUBO objective functions. The process simultaneously simplifies the energy landscape of QUBO problems, allowing the search for near-optimal solutions, and makes QUBO problems sparser, facilitating encoding into Ising machines with restriction on the hardware graph structure. We propose linearization of QUBO problems using variable posets as an outcome of the approach. By applying the proposed method to synthetic QUBO instances and to multi-dimensional knapsack problems, we empirically validate the effects on enhancing minor-embedding of QUBO problems and the performance of Ising machines.},
  archive      = {J_TETC},
  author       = {Kentaro Ohno and Nozomu Togawa},
  doi          = {10.1109/TETC.2024.3403871},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {250-261},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Linearizing binary optimization problems using variable posets for ising machines},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online resource provisioning and batch scheduling for AIoT
inference serving in an XPU edge cloud. <em>TETC</em>, <em>13</em>(1),
234–249. (<a href="https://doi.org/10.1109/TETC.2024.3403874">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driven by the accelerated convergence of artificial intelligence (AI) and the Internet of Things (IoT), the recent years have witnessed the booming of Artificial Intelligence of Things (AIoT). Edge clouds place computing and service capabilities at the network edges to reduce network transmission overhead, which has been widely recognized as the critical infrastructure for AIoT applications. Meanwhile, to accelerate computation-intensive edge cloud AI operations, specialized AI accelerators such as GPU, NPU, and TPU have been increasingly integrated into edge clouds. For such emerging XPU edge clouds, utilizing costly XPUs more efficiently has become a significant challenge. In this paper, we present an online optimization framework for joint resource provisioning and batch scheduling for more cost-efficient AIoT inference serving in an XPU edge cloud. The essential optimization process for the online framework is to first adaptively batch inference tasks to increase the system throughput without compromising the service level agreement (SLA). Next, heterogeneous XPU resources are provisioned for the batches. Finally, the resource instance is consolidated to a minimum of physical servers. Via extensive trace-driven simulations, we verify the performance of the presented online optimization framework.},
  archive      = {J_TETC},
  author       = {Rongkai Liu and Yuting Wu and Kongyange Zhao and Zhi Zhou and Xiang Gao and Xianchen Lin and Xiaoxi Zhang and Xu Chen and Gang Lu},
  doi          = {10.1109/TETC.2024.3403874},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {234-249},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Online resource provisioning and batch scheduling for AIoT inference serving in an XPU edge cloud},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamically activated de-glaring and detail- recovery for
low-light image enhancement directly on smart cameras. <em>TETC</em>,
<em>13</em>(1), 222–233. (<a
href="https://doi.org/10.1109/TETC.2024.3403935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-light conditions often significantly affect the stability of a computer-vision system. Existing studies of unpaired-learning-based low-light image enhancement do not consider glare that occurs during the night, which can lead to significant degradation of image quality. To improve image quality, our study proposes an additional enhancement module that can be applied to existing methods. That is, our proposed “lightweight low-light image de-glaring network” can remove glare from low-light images. We also propose a “low-light image-detail-recovery network” to enhance the boundary details of low-light images after removing glare to further improve image quality. The experimental results show that our proposed approaches can effectively improve low-light image quality. In addition, we propose “dynamically activated de-glaring” to assess the quality of input images first to determine whether de-glaring should be undertaken in order to effectively utilize the computational resources of a smart camera and avoid unnecessary image enhancement. The experimental results show that running time and frames per second can be greatly improved when applied to real-world scenarios.},
  archive      = {J_TETC},
  author       = {Shao-Wei Dong and Ching-Hu Lu},
  doi          = {10.1109/TETC.2024.3403935},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {222-233},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Dynamically activated de-glaring and detail- recovery for low-light image enhancement directly on smart cameras},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing knowledge reusability: A distributed multitask
machine learning approach. <em>TETC</em>, <em>13</em>(1), 207–221. (<a
href="https://doi.org/10.1109/TETC.2024.3390811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of the Internet of Things, the unprecedented growth of data surpasses current predictive analytics and processing capabilities. Due to the potential redundancy of similar data and analytics tasks, it is imperative to extract patterns from distributed data and predictive models so that existing schemes can be efficiently reused in distributed computing environments. This is expected to avoid building and maintaining reduplicative predictive models. The fundamental challenge, however, is the detection of reusable tasks and tuning models in order to improve predictive capacity while being reused. We introduce a two-phase Distributed Multi-task Machine Learning (DMtL) framework coping with this challenge. In the first phase, similar tasks are identified and efficiently grouped together according to locally trained models’ performance meta-features, using Partial Learning Curves (PLC). In the subsequent phase, we leverage the PLC-driven DMtL paradigm to boost the performance of candidate reusable models per group of tasks in distributed computing environments. We provide a thorough analysis of our framework along with a comparative assessment against relevant approaches and prior work found in the respective literature. Our experimental results showcase the feasibility of the PLC-driven DMtL method in terms of adaptability and reusability of existing knowledge in distributed computing systems.},
  archive      = {J_TETC},
  author       = {Qianyu Long and Christos Anagnostopoulos and Kostas Kolomvatsos},
  doi          = {10.1109/TETC.2024.3390811},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {207-221},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Enhancing knowledge reusability: A distributed multitask machine learning approach},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SelfVis: Self-supervised learning for human activity
recognition based on area charts. <em>TETC</em>, <em>13</em>(1),
196–206. (<a href="https://doi.org/10.1109/TETC.2024.3392850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) has long been an active research topic as it enables us to infer human behaviors and daily routines from sensor data collected on wearables or on sensors embedded in a pervasive sensing environment. In recent years, deep learning has been widely used in HAR for feature extraction and multimodal fusion, and has achieved promising performance on activity recognition. However, they often require a large number of labeled data for training. To directly tackle this challenge, this paper proposes SelfVis, a novel visualization-based self-supervised learning technique, which aims to extract effective features without the need of labeled data. To achieve this goal, it encodes time-series IMU sensor readings into images and then employs ResNet, a pre-trained, state-of-the-art convolutional neural network (CNN) as the backbone feature extractor. It leverages the fact that there exist multiple sensors often being used and uses sensor identifications that are generated automatically as a prediction target during the self-supervised learning process. With these two, SelfVis has achieved high activity recognition accuracy even when only a small number of labeled data are available; that is, with only 1% training data, SelfVis has demonstrated the ability to achieve higher performance than state-of-the-art techniques by up to 0.46 in macro F1-scores.},
  archive      = {J_TETC},
  author       = {Ai Jiang and Juan Ye},
  doi          = {10.1109/TETC.2024.3392850},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {196-206},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {SelfVis: Self-supervised learning for human activity recognition based on area charts},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Janus: A trusted execution environment approach for attack
detection in industrial robot controllers. <em>TETC</em>,
<em>13</em>(1), 185–195. (<a
href="https://doi.org/10.1109/TETC.2024.3390435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few decades, technological progress has led to a spike in the adoption of robots by the manufacturing industry. With the new “Industry 4.0” paradigm, companies strive to automate their production processes by interconnecting and integrating different industrial systems. The resulting increase in complexity contributes to a larger attack surface and paves the way for novel attacks. In the context of cyber-physical systems, consequences include economic and physical damage, as well as harm to human workers. In this article, we present Janus, a novel monitoring mechanism for industrial robot controllers that exploits the trusted execution environment (TEE) to guarantee the integrity of the attack detection algorithm even in case the controller&#39;s software is compromised, while not requiring external hardware for its detection process. In particular, we use the state observers strategy for detecting low-level controller (LLC) attacks. We assess our approach by testing it against various attacks, identifying those that are simpler to detect and pinpointing the more elusive ones, which are mostly detected nonetheless. Finally, we demonstrate that our approach does not add significant computation overheads.},
  archive      = {J_TETC},
  author       = {Stefano Longari and Jacopo Jannone and Mario Polino and Michele Carminati and Andrea Zanchettin and Mara Tanelli and Stefano Zanero},
  doi          = {10.1109/TETC.2024.3390435},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {185-195},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Janus: A trusted execution environment approach for attack detection in industrial robot controllers},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HARPOCRATES: An approach towards efficient encryption of
data-at-rest. <em>TETC</em>, <em>13</em>(1), 173–184. (<a
href="https://doi.org/10.1109/TETC.2024.3387558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new block cipher called HARPOCRATES, which is different from traditional SPN, Feistel, or ARX designs. The new design structure that we use is called the substitution convolution network. The novelty of the approach lies in that the substitution function does not use fixed S-boxes. Instead, it uses a key-driven lookup table storing a permutation of all 8-bit values. If the lookup table is sufficiently randomly shuffled, the round sub-operations achieve good confusion and diffusion to the cipher. While designing the cipher, the security, cost, and performances are balanced, keeping the requirements of encryption of data-at-rest in mind. The round sub-operations are massively parallelizable and designed such that a single active bit may make the entire state (an $8 \times 16$ binary matrix) active in one round. We analyze the security of the cipher against linear, differential, and impossible differential cryptanalysis. The cipher&#39;s resistance against many other attacks like algebraic attacks, structural attacks, and weak keys are also shown. We implemented the cipher in software and hardware; found that the software implementation of the cipher results in better throughput than many well-known ciphers. Although HARPOCRATES is appropriate for the encryption of data-at-rest, it is also well-suited in data-in-transit environments.},
  archive      = {J_TETC},
  author       = {Md Rasid Ali and Debranjan Pal and Abhijit Das and Dipanwita Roy Chowdhury},
  doi          = {10.1109/TETC.2024.3387558},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {173-184},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {HARPOCRATES: An approach towards efficient encryption of data-at-rest},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). One-spike SNN: Single-spike phase coding with base
manipulation for ANN-to-SNN conversion loss minimization. <em>TETC</em>,
<em>13</em>(1), 162–172. (<a
href="https://doi.org/10.1109/TETC.2024.3386893">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As spiking neural networks (SNNs) are event-driven, energy efficiency is higher than conventional artificial neural networks (ANNs). Since SNN delivers data through discrete spikes, it is difficult to use gradient methods for training, limiting its accuracy. To keep the accuracy of SNNs similar to ANN counterparts, pre-trained ANNs are converted to SNNs (ANN-to-SNN conversion). During the conversion, encoding activations of ANNs to a set of spikes in SNNs is crucial for minimizing the conversion loss. In this work, we propose a single-spike phase coding as an encoding scheme that minimizes the number of spikes to transfer data between SNN layers. To minimize the encoding error due to single-spike approximation in phase coding, threshold shift and base manipulation are proposed. Without any additional retraining or architectural constraints on ANNs, the proposed conversion method does not lose inference accuracy (0.58% on average) verified on three convolutional neural networks (CNNs) with CIFAR and ImageNet datasets. In addition, graph convolutional networks (GCNs) are converted to SNNs successfully with an average accuracy loss of 0.90%. Most importantly, the energy efficiency of our SNN improves by 4.6$\sim\!\! 17.3\times$ compared to the ANN baseline.},
  archive      = {J_TETC},
  author       = {Sangwoo Hwang and Jaeha Kung},
  doi          = {10.1109/TETC.2024.3386893},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {162-172},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {One-spike SNN: Single-spike phase coding with base manipulation for ANN-to-SNN conversion loss minimization},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LP-star: Embedding longest paths into star networks with
large-scale missing edges under an emerging assessment model.
<em>TETC</em>, <em>13</em>(1), 147–161. (<a
href="https://doi.org/10.1109/TETC.2024.3387119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Star networks play an essential role in designing parallel and distributed systems. With the massive growth of faulty edges and the widespread applications of the longest paths and cycles, it is crucial to embed the longest fault-free paths and cycles in edge-faulty networks. However, the traditional fault model allows a concentrated distribution of faulty edges and thus can only tolerate faults that depend on the minimum degree of the network vertices. This article introduces an improved fault model called the partitioned fault model, which is an emerging assessment model for fault tolerance. Based on this model, we first explore the longest fault-free paths and cycles by proving the edge fault-tolerant Hamiltonian laceability, edge fault-tolerant strongly Hamiltonian laceability, and edge fault-tolerant Hamiltonicity in the $n$-dimensional star network $S_{n}$. Furthermore, based on the theoretical proof, we give an $O(nN)$ algorithm to construct the longest fault-free paths in star networks based on the partitioned fault model, where $N$ is the number of vertices in $S_{n}$. We also make comparisons to show that our result of edge fault tolerance has exponentially improved other known results.},
  archive      = {J_TETC},
  author       = {Xiao-Yan Li and Jou-Ming Chang},
  doi          = {10.1109/TETC.2024.3387119},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {147-161},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {LP-star: Embedding longest paths into star networks with large-scale missing edges under an emerging assessment model},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FakeTracer: Catching face-swap DeepFakes via implanting
traces in training. <em>TETC</em>, <em>13</em>(1), 134–146. (<a
href="https://doi.org/10.1109/TETC.2024.3386960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face-swap DeepFake is an emerging AI-based face forgery technique that can replace the original face in a video with a generated face of the target identity while retaining consistent facial attributes such as expression and orientation. Due to the high privacy of faces, the misuse of this technique can raise severe social concerns, drawing tremendous attention to defend against DeepFakes recently. In this article, we describe a new proactive defense method called FakeTracer to expose face-swap DeepFakes via implanting traces in training. Compared to general face-synthesis DeepFake, the face-swap DeepFake is more complex as it involves identity change, is subjected to the encoding-decoding process, and is trained unsupervised, increasing the difficulty of implanting traces into the training phase. To effectively defend against face-swap DeepFake, we design two types of traces, sustainable trace (STrace) and erasable trace (ETrace), to be added to training faces. During the training, these manipulated faces affect the learning of the face-swap DeepFake model, enabling it to generate faces that only contain sustainable traces. In light of these two traces, our method can effectively expose DeepFakes by identifying them. Extensive experiments corroborate the efficacy of our method on defending against face-swap DeepFake.},
  archive      = {J_TETC},
  author       = {Pu Sun and Honggang Qi and Yuezun Li and Siwei Lyu},
  doi          = {10.1109/TETC.2024.3386960},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {134-146},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {FakeTracer: Catching face-swap DeepFakes via implanting traces in training},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A bio-inspired implementation of a sparse-learning
spike-based hippocampus memory model. <em>TETC</em>, <em>13</em>(1),
119–133. (<a href="https://doi.org/10.1109/TETC.2024.3387026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The brain is capable of solving complex problems simply and efficiently, far surpassing modern computers. In this regard, neuromorphic engineering focuses on mimicking the basic principles that govern the brain in order to develop systems that achieve such computational capabilities. Within this field, bio-inspired learning and memory systems are still a challenge to be solved, and this is where the hippocampus is involved. It is the region of the brain that acts as a short-term memory, allowing the learning and storage of information from all the sensory nuclei of the cerebral cortex and its subsequent recall. In this work, we propose a novel bio-inspired hippocampal memory model with the ability to learn memories, recall them from a fragment of itself (cue) and even forget memories when trying to learn others with the same cue. This model has been implemented on SpiNNaker using Spiking Neural Networks, and a set of experiments were performed to demonstrate its correct operation. This work presents the first simulation implemented on a special-purpose hardware platform for Spiking Neural Networks of a fully functional bio-inspired spike-based hippocampus memory model, paving the road for the development of future more complex neuromorphic systems.},
  archive      = {J_TETC},
  author       = {Daniel Casanueva-Morato and Alvaro Ayuso-Martinez and Juan P. Dominguez-Morales and Angel Jimenez-Fernandez and Gabriel Jimenez-Moreno},
  doi          = {10.1109/TETC.2024.3387026},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {119-133},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A bio-inspired implementation of a sparse-learning spike-based hippocampus memory model},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel privacy-preserving range query scheme with
permissioned blockchain for smart grid. <em>TETC</em>, <em>13</em>(1),
105–118. (<a href="https://doi.org/10.1109/TETC.2024.3386803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain-enhanced Smart Grid is being deeply studied by many scholars because of its unique advantages in system and security of distributed accounting and traceability. However, the problems of data privacy disclosure and low efficiency are still worthy of the attention of most researchers. In this paper, we design a general three-tier architecture of Smart Grid based on blockchain, including edge layer, permissioned blockchain layer, and application layer. Furthermore, for the three-tier architecture, a novel privacy-preserving range query scheme without a trusted authority is proposed by adopting fog computing, permissioned blockchain, Paillier homomorphic encryption system, and Goldwasser-Micali cryptosystems. This scheme can realize range query in batch, while it can also protect privacy and resist collusion attack. Performance evaluations and experiment comparisons show that our scheme has good advantages: higher efficiency and lower storage, and thus it can meet increasing data service requirements.},
  archive      = {J_TETC},
  author       = {Kun-Chang Li and Peng-Bo Wang and Run-Hua Shi},
  doi          = {10.1109/TETC.2024.3386803},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {105-118},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A novel privacy-preserving range query scheme with permissioned blockchain for smart grid},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep learning based intelligent tumor analytics framework
for quantitative grading and analyzing cancer metastasis: Case of lymph
node breast cancer. <em>TETC</em>, <em>13</em>(1), 90–104. (<a
href="https://doi.org/10.1109/TETC.2024.3487258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {False-positive or false-negative detection, and the resulting inappropriate treatments in cancer metastasis cases, have led to numerous fatal instances due to human errors. Traditional cancer diagnoses are often subjectively interpreted through naked-eye observation, which can vary among different medical practitioners. In this research, we propose a novel deep learning-based framework called Intelligent Tumor Analytics (ITA). ITA facilitates on-the-fly assessment of Whole Slide Imaging (WSI) at the histopathological level, primarily utilizing cellular appearance, spatial arrangement, and the relative proximities of various cell types (e.g., tumor cells, immune cells, and other objects of interest) observed within scanned WSI images of tumors. By automatically quantifying relevant indicators and estimating their scores, ITA establishes a standardized evaluation that aligns with widely recognized international tumor grading standards, including the TNM and Nottingham Grading Standards. The objective measurements and assessments offered by ITA provide informative and unbiased insights to users (i.e., pathologists) involved in determining prognosis and treatment plans. The quantified information regarding tumor risk and potential for further metastasis possibilities serves as crucial early knowledge during cancer development.},
  archive      = {J_TETC},
  author       = {Tengyue Li and Simon Fong and Yaoyang Wu and Xin Zhang and Qun Song and Huafeng Qin and Sabah Mohammed and Tian Feng and Juntao Gao and Andrea Sciarrone},
  doi          = {10.1109/TETC.2024.3487258},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {90-104},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Deep learning based intelligent tumor analytics framework for quantitative grading and analyzing cancer metastasis: Case of lymph node breast cancer},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low-power real-time seizure monitoring using AI-assisted
sonification of neonatal EEG. <em>TETC</em>, <em>13</em>(1), 80–89. (<a
href="https://doi.org/10.1109/TETC.2024.3481035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting seizures in neonates requires continuous electroencephalography (EEG) monitoring, a costly process that demands trained experts. Although recent advancements in machine learning offer promising solutions for automated seizure detection, the opaque nature of these algorithms poses significant challenges to their adoption in healthcare settings. A prior study demonstrated that integrating machine learning with sonification—an interpretation method that converts bio-signals into sound—can mitigate the black-box problem while enhancing seizure detection performance. This AI-assisted sonification algorithm can provide a valuable complementary tool in seizure monitoring besides the traditional visualization method. A low-power and affordable implementation of the algorithm is presented in this study using a microcontroller. To improve its practicality, we also introduce a real-time design that allows the sonification algorithm to function in parallel with data acquisition. The system consumes 12 mW in average, making it suitable for a battery-powered device.},
  archive      = {J_TETC},
  author       = {Tien Nguyen and Aengus Daly and Sergi Gomez-Quintana and Feargal O&#39;Sullivan and Andriy Temko and Emanuel Popovici},
  doi          = {10.1109/TETC.2024.3481035},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {80-89},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Low-power real-time seizure monitoring using AI-assisted sonification of neonatal EEG},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning approach for collaborative and secure
smart healthcare applications. <em>TETC</em>, <em>13</em>(1), 68–79. (<a
href="https://doi.org/10.1109/TETC.2024.3473911">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Across all periods of human history, the importance attributed to health has remained a fundamental and significant facet. This statement holds greater validity within the present context. The pressing demand for healthcare solutions with real-time capabilities, affordability, and high precision is crucial in medical research and technology progress. In recent times, there has been a significant advancement in emerging technologies such as AI, IoT, blockchain, and edge computing. These breakthrough developments have led to the creation of various intelligent applications. Smart healthcare applications can be realized by combining robust AI detection and prediction capabilities with edge computing architecture, which offers low computing costs and latency. In this paper, we begin by conducting a literature review of AI-assisted EC-based smart healthcare applications from the past three years. Our goal is to identify gaps and barriers in this field. We propose a smart healthcare architecture model that integrates AI technology into the edge. Finally, we summarize the challenges and research directions associated with the proposed model.},
  archive      = {J_TETC},
  author       = {Quy Vu Khanh and Abdellah Chehri and Van Anh Dang and Quy Nguyen Minh},
  doi          = {10.1109/TETC.2024.3473911},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {68-79},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Federated learning approach for collaborative and secure smart healthcare applications},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FedRDF: A robust and dynamic aggregation function against
poisoning attacks in federated learning. <em>TETC</em>, <em>13</em>(1),
48–67. (<a href="https://doi.org/10.1109/TETC.2024.3474484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) represents a promising approach to typical privacy concerns associated with centralized Machine Learning (ML) deployments. Despite its well-known advantages, FL is vulnerable to security attacks such as Byzantine behaviors and poisoning attacks, which can significantly degrade model performance and hinder convergence. The effectiveness of existing approaches to mitigate complex attacks, such as median, trimmed mean, or Krum aggregation functions, has been only partially demonstrated in the case of specific attacks. Our study introduces a novel robust aggregation mechanism utilizing the Fourier Transform (FT), which is able to effectively handle sophisticated attacks without prior knowledge of the number of attackers. Employing this data technique, weights generated by FL clients are projected into the frequency domain to ascertain their density function, selecting the one exhibiting the highest frequency. Consequently, malicious clients’ weights are excluded. Our proposed approach was tested against various model poisoning attacks, demonstrating superior performance over state-of-the-art aggregation methods.},
  archive      = {J_TETC},
  author       = {Enrique Mármol Campos and Aurora Gonzalez-Vidal and José L. Hernández-Ramos and Antonio Skarmeta},
  doi          = {10.1109/TETC.2024.3474484},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {48-67},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {FedRDF: A robust and dynamic aggregation function against poisoning attacks in federated learning},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge-based live learning for robot survival. <em>TETC</em>,
<em>13</em>(1), 34–47. (<a
href="https://doi.org/10.1109/TETC.2024.3479082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce survival-critical machine learning (SCML), in which a robot encounters dynamically evolving threats that it recognizes via machine learning (ML), and then neutralizes. We model survivability in SCML, and show the value of the recently developed approach of Live Learning. This edge-based ML technique embodies an iterative human-in-the-loop workflow that concurrently enlarges the training set, trains the next model in a sequence of “best-so-far” models, and performs inferencing for both threat detection and pseudo-labeling. We present experimental results using datasets from the domains of drone surveillance, planetary exploration, and underwater sensing to quantify the effectiveness of Live Learning as a mechanism for SCML.},
  archive      = {J_TETC},
  author       = {Eric Sturzinger and Jan Harkes and Padmanabhan Pillai and Mahadev Satyanarayanan},
  doi          = {10.1109/TETC.2024.3479082},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {34-47},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Edge-based live learning for robot survival},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). X-RAFT: Improve RAFT consensus to make blockchain better
secure EdgeAI-human-IoT data. <em>TETC</em>, <em>13</em>(1), 22–33. (<a
href="https://doi.org/10.1109/TETC.2024.3472059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of IoT devices, advancements in edge computing, and innovations in AI technology have created an ideal environment for the birth and growth of Edge AI. With the trend towards the Internet of Everything (IoE), the EdgeAI- Human-IoT architectural framework highlights the necessity for efficient data exchange interconnectivity. Ensuring secure data sharing and efficient data storage are pivotal challenges in achieving seamless data interconnection. Owing to its simplicity, ease of deployment, and consensus-reaching capabilities, the RAFT consensus algorithm, which is commonly used in distributed storage, faces limitations as the IoT scale expands. The computational, communication, and storage capabilities of nodes are constraints, and the security of data remains a concern. To address these complex challenges, we introduce the X-RAFT consensus algorithm, which is tailored for blockchain technology. This algorithm enhances system performance and robustness, mitigates the impact of system load, enhances system sustainability, and increases Byzantine fault tolerance. Through analysis and simulations, our proposed solution has been evidenced to provide reliable security and efficient performance.},
  archive      = {J_TETC},
  author       = {Fengqi Li and Jiaheng Wang and Weilin Xie and Ning Tong and Deguang Wang},
  doi          = {10.1109/TETC.2024.3472059},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {22-33},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {X-RAFT: Improve RAFT consensus to make blockchain better secure EdgeAI-human-IoT data},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel prediction technique for federated learning.
<em>TETC</em>, <em>13</em>(1), 5–21. (<a
href="https://doi.org/10.1109/TETC.2024.3471458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have studied how to improve Federated Learning (FL) in various areas, such as statistical and system heterogeneity, communication cost, and privacy. So far, most of the proposed solutions are either very tied to the application context or complex to be broadly reproduced in real-life applications involving humans. Developing modular solutions that can be leveraged by the vast majority of FL structures and are independent of the application people use is the new research direction opened by this paper. In this work, we propose a plugin (named FedPredict) to address three problems simultaneously: data heterogeneity, low performance of new/untrained and/or outdated clients, and communication cost. We do so mainly by combining global and local parameters (which brings generalization and personalization) in the inference step while adapting layer selection and matrix factorization techniques to reduce the downlink communication cost (server to client). Due to its simplicity, it can be applied to federated learning of different number of topologies. Results show that adding the proposed plugin to a given FL solution can significantly reduce the downlink communication cost by up to 83.3% and improve accuracy by up to 304% compared to the original solution.},
  archive      = {J_TETC},
  author       = {Cláudio G. S. Capanema and Allan M. de Souza and Joahannes B. D. da Costa and Fabrício A. Silva and Leandro A. Villas and Antonio A. F. Loureiro},
  doi          = {10.1109/TETC.2024.3471458},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {5-21},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {A novel prediction technique for federated learning},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Editorial special section on emerging edge AI for
human-in-the-loop cyber physical systems. <em>TETC</em>, <em>13</em>(1),
3–4. (<a href="https://doi.org/10.1109/TETC.2024.3472428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge Artificial Intelligence (AI) enables us to deploy distributed AI models, optimize computational and energy resources, minimize communication demands, and, most importantly, meet privacy requirements for Internet of Things (IoT) applications. Since data remains on the end-devices and only model parameters are shared with the server, it becomes possible to leverage the vast amount of data collected from smartphones and IoT devices without compromising the user&#39;s privacy. However, Federated Learning (FL) solutions also have well-known limitations. In particular, as systems that account for human behaviour become increasingly vital, future technologies need to become attuned to human behaviours. Indeed, we are already witnessing unparalleled advancements in technology that empower our tools and devices with intelligence, sensory abilities, and communication features. At the same time, continued advances in the miniaturization of computational capabilities can enable us to go far beyond the simple tagging and identification, towards integrating computational resources directly into these objects, thus making our tools “intelligent”. Yet, there is limited scientific work that considers humans as an integral part of these IoT-powered cyber-physical systems.},
  archive      = {J_TETC},
  author       = {Radu Marculescu and Jorge Sá Silva},
  doi          = {10.1109/TETC.2024.3472428},
  journal      = {IEEE Transactions on Emerging Topics in Computing},
  month        = {1-3},
  number       = {1},
  pages        = {3-4},
  shortjournal = {IEEE Trans. Emerg. Topics Comput.},
  title        = {Editorial special section on emerging edge AI for human-in-the-loop cyber physical systems},
  volume       = {13},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
