<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SADM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sadm---13">SADM - 13</h2>
<ul>
<li><details>
<summary>
(2025). Detection of unknown functional departure in generalized
functional regression. <em>Statistical Analysis and Data Mining: The ASA
Data Science Journal</em>, <em>18</em>(1), e70013. (<a
href="https://doi.org/10.1002/sam.70013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Detecting statistical differences among functional dataset or streaming signal dataset is of interest to many diverse fields, including neurophysiology, imaging, biomedical engineering, and public health. For example in our study, our interest is to provide the guideline for detecting the lowest drug dosage level for glioblastoma as quickly as possible in which the intensity functional curves are different among dosage groups. However, such functional data often have unknown and nonlinear massive correlated curves that lead to difficulties in detecting their significant differences without explicit likelihood functions. Existing detecting procedures mainly test a linear, quadratic, or specific parametric form of departure and require explicit likelihood functions due to estimating specific models. In this paper, we propose a flexible detecting method to test any unknown functional departure in a generalized functional regression without estimating models. We develop our detecting method under a generalized semiparametric functional model framework in which the explicit likelihood function does not exist. We develop our detecting method using the approximated Bayes factor, a score-type test, and the estimating equations. The decision of rejecting (or not) the null hypothesis is made using the Frequentist p -values. We also studied the asymptotic properties of our method. We compare our detecting method to the alternative method regarding the type-I error and power under various simulation settings. We demonstrate the advantages of our method by applying two real datasets: functional data of drug-exposed glioblastoma cell line and diffusion tensor imaging tractography.},
  archive  = {J},
  author   = {Mengkun Chen and Inyoung Kim},
  doi      = {10.1002/sam.70013},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70013},
  title    = {Detection of unknown functional departure in generalized functional regression},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-parametric least-area linear-circular regression
through möbius transformation. <em>Statistical Analysis and Data Mining:
The ASA Data Science Journal</em>, <em>18</em>(1), e70012. (<a
href="https://doi.org/10.1002/sam.70012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper introduces a novel regression model designed for angular response variables with linear predictors, utilizing a generalized Möbius transformation to define the regression curve. By mapping the real axis to the circle, the model effectively captures the relationship between linear and angular components. A key innovation is the introduction of an area-based loss function, inspired by the geometry of a curved torus, for efficient parameter estimation. The semi-parametric nature of the model eliminates the need for specific distributional assumptions about the angular error, enhancing its versatility. Extensive simulation studies, incorporating von Mises and wrapped Cauchy distributions, highlight the robustness of the framework. The model&#39;s practical utility is demonstrated through real-world data analysis of Bitcoin and Ethereum, showcasing its ability to derive meaningful insights from complex data structures.},
  archive  = {J},
  author   = {Surojit Biswas and Buddhananda Banerjee},
  doi      = {10.1002/sam.70012},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70012},
  title    = {Semi-parametric least-area linear-circular regression through möbius transformation},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robustifying marginal linear models for correlated responses
using a constructive multivariate huber distribution. <em>Statistical
Analysis and Data Mining: The ASA Data Science Journal</em>,
<em>18</em>(1), e70011. (<a
href="https://doi.org/10.1002/sam.70011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The marginal regression model is convenient for analyzing correlated responses, including repeated measures and longitudinal data. This paper proposes a robust marginal linear model for analyzing a vector of univariate responses with correlated components by incorporating an innovative multivariate Huber distribution. It employs a flexible parameterization using modified Cholesky decomposition, provides a convenient approach for estimating the covariance matrix, and allows for subject-varying the tuning parameter. Our research introduces a method for estimating parameters by employing the exact likelihood function through the Hamiltonian Monte Carlo algorithm. To highlight the advantage of our model, we carried out a simulation experiment and reanalyzed two real-world case studies in the health and economics fields. The results indicate that our model offers a more robust analysis by assigning appropriate weights to extreme observations, thereby handling outliers more effectively than traditional models.},
  archive  = {J},
  author   = {Raziyeh Mohammadi and Iraj Kazemi},
  doi      = {10.1002/sam.70011},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70011},
  title    = {Robustifying marginal linear models for correlated responses using a constructive multivariate huber distribution},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Noise-augmented ℓ0 regularization of tensor regression with
tucker decomposition. <em>Statistical Analysis and Data Mining: The ASA
Data Science Journal</em>, <em>18</em>(1), e70010. (<a
href="https://doi.org/10.1002/sam.70010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Tensor data are multi-dimensional arrays. Low-rank decomposition-based regression methods with tensor predictors exploit the structural information in tensor predictors while significantly reducing the number of parameters in tensor regression. We propose a method named NA 0 CT 2 $$ {\mathrm{NA}}_0{\mathrm{CT}}^2 $$ (Noise Augmentation for ℓ 0 $$ {\mathrm{\ell}}_0 $$ regularization on Core Tensor in Tucker decomposition) to regularize the parameters in tensor regression (TR), coupled with Tucker decomposition. We establish theoretically that NA 0 CT 2 $$ {\mathrm{NA}}_0{\mathrm{CT}}^2 $$ achieves exact ℓ 0 $$ {\mathrm{\ell}}_0 $$ regularization on the core tensor from the Tucker decomposition in linear TR and generalized linear TR. To our knowledge, NA 0 CT 2 $$ {\mathrm{NA}}_0{\mathrm{CT}}^2 $$ is the first Tucker decomposition-based regularization method in TR to achieve ℓ 0 $$ {\mathrm{\ell}}_0 $$ regularization in core tensors. NA 0 CT 2 $$ {\mathrm{NA}}_0{\mathrm{CT}}^2 $$ is implemented through an iterative procedure and involves two straightforward steps in each iteration—generating noisy data based on the core tensor from the Tucker decomposition of the updated parameter estimate and running a regular GLM on noise-augmented data on vectorized predictors. We demonstrate the implementation of NA 0 CT 2 $$ {\mathrm{NA}}_0{\mathrm{CT}}^2 $$ and its ℓ 0 $$ {\mathrm{\ell}}_0 $$ regularization effect in both simulation studies and real data applications. The results suggest that NA 0 CT 2 $$ {\mathrm{NA}}_0{\mathrm{CT}}^2 $$ can improve predictions compared with other decomposition-based TR approaches, with or without regularization and it identifies important predictors though not designed for that purpose.},
  archive  = {J},
  author   = {Tian Yan and Yinan Li and Fang Liu},
  doi      = {10.1002/sam.70010},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70010},
  title    = {Noise-augmented ℓ0 regularization of tensor regression with tucker decomposition},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BayesMultiomics: An r package for bayesian shrinkage models
for integration and analysis of multi-platform high-dimensional genomics
data. <em>Statistical Analysis and Data Mining: The ASA Data Science
Journal</em>, <em>18</em>(1), e70009. (<a
href="https://doi.org/10.1002/sam.70009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the growing availability of multi-platform biomedical data—such as epigenomics, gene expression, and clinical features—there is an increasing need for methods that jointly analyze these datasets. We present BayesMultiomics, an R package for integrating and analyzing gene expression, DNA methylation, gene function annotations, and clinical variables using a two-stage hierarchical Bayesian model. Built with user-friendliness in mind, the package caters to multidisciplinary researchers without extensive programming expertise in Bayesian hierarchical models. Its application is demonstrated using an illustrative Glioblastoma (GBM) dataset.},
  archive  = {J},
  author   = {Mansoo Cho and Tanujit Dey and Hao Xue and Sounak Chakraborty},
  doi      = {10.1002/sam.70009},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70009},
  title    = {BayesMultiomics: An r package for bayesian shrinkage models for integration and analysis of multi-platform high-dimensional genomics data},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Using neural networks to identify mixture components in
hyperspectral reflectance data. <em>Statistical Analysis and Data
Mining: The ASA Data Science Journal</em>, <em>18</em>(1), e70008. (<a
href="https://doi.org/10.1002/sam.70008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Neural networks have been employed to identify materials of interest from hyperspectral data (generally imagery) based on their unique spectral signatures. This approach assumes that there is a single material that is standing out from the rest of the spectrum to be identified. However, pixels often contain more than one material, or a material of interest may itself be a mixture of multiple materials. Neural networks are only as good as the data used to train them, and it takes a great deal of work in the laboratory to identify, make, and measure all potential mixtures of interest. Thus, researchers often calculate synthetic spectra using algorithms with varying degrees of fidelity to the physics that govern the interactions between light and multiple materials. In this work, we have (1) adapted a neural network designed to identify mixture components from Raman spectroscopy to work with visible to near-infrared reflectance data and (2) tested three common mixture algorithms to determine the most accurate and least computationally expensive method to build synthetic training datasets. With our initial test dataset, we have achieved accuracies of &gt; 90% and found that the synthetic training dataset produced using the Hapke mixture model provides the best results.},
  archive  = {J},
  author   = {Allison M. Zastrow and Eric Flynn},
  doi      = {10.1002/sam.70008},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70008},
  title    = {Using neural networks to identify mixture components in hyperspectral reflectance data},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Greenwood statistic under distortion measurement errors.
<em>Statistical Analysis and Data Mining: The ASA Data Science
Journal</em>, <em>18</em>(1), e70007. (<a
href="https://doi.org/10.1002/sam.70007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this paper, we address the crucial necessity of understanding the behavior of the Greenwood statistic when dealing with data corrupted by multiplicative measurement errors. The unobservable variable is subject to a multiplicative distortion influenced by an unknown smoothing function dependent on a confounding variable. We introduce the conditional mean calibrated Greenwood statistic and its variants, including the coefficient of variation, to adapt to this complex situation. The asymptotic results we present showcase their effectiveness even when such distortions are present. Moreover, for general distributions of the unobserved variable, we extend the methodology by proposing calibrated-modified Greenwood statistics and the coefficient of variation. These methods are demonstrated to be asymptotically efficient under various assumptions about the distortion function. Furthermore, we conduct Monte Carlo simulation experiments to assess the performance of the proposed estimators and test statistics, during which we compare our proposed test statistics with existing ones. For illustrative purposes, these methods are then applied to analyze a real-world dataset. MSC2020 Classification: 62G05, 62G08, 62G20},
  archive  = {J},
  author   = {Chaolin Yao and Jun Zhang},
  doi      = {10.1002/sam.70007},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70007},
  title    = {Greenwood statistic under distortion measurement errors},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive microbiome-based truncated test. <em>Statistical
Analysis and Data Mining: The ASA Data Science Journal</em>,
<em>18</em>(1), e70006. (<a
href="https://doi.org/10.1002/sam.70006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The human microbiome has been demonstrated to be associated with many complex diseases. Identifying the differences in microbial taxa across two different health conditions is clinically important, as it can enhance our understanding of disease pathology from a microbiome perspective and potentially lead to preventive or therapeutic strategies. However, there are three main challenges for analyzing microbiome data, due to compositionality, sparsity, and high dimensionality of the relative abundances. Although a few two-sample tests have been proposed for analyzing microbiome data, the statistical power cannot be guaranteed as the true alternative hypothesis is unknown. To potentially address this issue, we propose an adaptive microbiome-based truncated test (AMTT) that produces high power for various alternative hypotheses. Simulation studies with a wide range of scenarios are conducted, the results indicate that AMTT is not only powerful in almost all the scenarios but also effectively controls type I error rates. Real data about Parkinson&#39;s intestinal microbiome is analyzed to demonstrate its practical performance.},
  archive  = {J},
  author   = {Hailong Gao and Deliang Bu and Hongping Guo and Xiao Wang},
  doi      = {10.1002/sam.70006},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70006},
  title    = {An adaptive microbiome-based truncated test},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach for APT detection based on ensemble
learning model. <em>Statistical Analysis and Data Mining: The ASA Data
Science Journal</em>, <em>18</em>(1), e70005. (<a
href="https://doi.org/10.1002/sam.70005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In recent years, the number and complexity of advanced persistent threat (APT) attacks have significantly increased, posing major challenges for organizations in effectively detecting and mitigating these threats. Although various APT detection methods have been developed, current approaches still face limitations, such as poor generalization leading to high false alarm rates. To address these challenges, this article proposes a novel ensemble learning model called MCG, based on the combination of three main components: multilayer perceptron (MLP), correlated recursion (CR) layer, and graph attention network (GAT). The MLP component extracts flow features from network traffic, the CR layer constructs the IP information network by grouping and linking network behaviors, and finally, the GAT layer analyzes relationships between IPs through an attention mechanism. The MCG model proposed in this article has demonstrated superior performance in APT detection by effectively leveraging the strengths of each component, enabling more accurate identification of abnormal behaviors and reducing false alarms. The experimental results, presented in Section 4.4, show that the MCG model significantly improves accuracy and outperforms traditional methods. This demonstrates that the proposed model not only makes significant theoretical contributions but also offers practical value, providing a more reliable and effective solution for early detection and warning of APT attacks.},
  archive  = {J},
  author   = {Nguyen Hoa Cuong and Cho Do Xuan and Vu Thanh Long and Nguyen Duy Dat and Tran Quang Anh},
  doi      = {10.1002/sam.70005},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70005},
  title    = {A novel approach for APT detection based on ensemble learning model},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The classification algorithm based on functional logistic
regression model with spatial effects and its application in air quality
analysis. <em>Statistical Analysis and Data Mining: The ASA Data Science
Journal</em>, <em>18</em>(1), e70004. (<a
href="https://doi.org/10.1002/sam.70004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the acceleration of economic development and urbanization, air pollution has become increasingly severe and has been a crucial issue affecting social advancement. Considering the spatial correlation between regions in air quality analysis can improve the accuracy of model estimation for the data on air pollution. First, we propose the functional Logistic regression model with spatial effects. Second, we fit the original data into functional data using B-spline basis functions and apply functional principal component analysis for dimension reduction. Further, the model is estimated using the maximum likelihood method. Finally, the effectiveness of the proposed model is validated through numerical simulations and a real data analysis for PM2.5 air quality in the Sichuan-Chongqing region of China.},
  archive  = {J},
  author   = {Cai Xinran and Tian Yuzhu and Yue Wang and Tian Maozai},
  doi      = {10.1002/sam.70004},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70004},
  title    = {The classification algorithm based on functional logistic regression model with spatial effects and its application in air quality analysis},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interaction tests with covariate-adaptive randomization.
<em>Statistical Analysis and Data Mining: The ASA Data Science
Journal</em>, <em>18</em>(1), e70003. (<a
href="https://doi.org/10.1002/sam.70003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Treatment-covariate interaction tests are commonly applied by researchers to examine whether the treatment effect varies across patient subgroups defined by baseline characteristics. The objective of this study is to explore treatment-covariate interaction tests involving covariate-adaptive randomization. Without assuming a parametric data-generating model, we investigate usual interaction tests and observe that they tend to be conservative: specifically, their limiting rejection probabilities under the null hypothesis are typically strictly lower than the nominal level. To address this problem, we propose modifications to the usual tests to obtain corresponding valid tests with limiting rejection probabilities equal to the nominal level. Moreover, we introduce a novel class of stratified-adjusted interaction tests that are simple, more powerful than the usual and modified tests, and broadly applicable to most covariate-adaptive randomization methods. The results encompass two types of interaction tests: one involving stratification covariates and the other involving additional covariates that are not used for randomization. Our study clarifies the application of interaction tests in clinical trials and offers valuable tools for revealing treatment heterogeneity, crucial for advancing personalized medicine.},
  archive  = {J},
  author   = {Likun Zhang and Wei Ma},
  doi      = {10.1002/sam.70003},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70003},
  title    = {Interaction tests with covariate-adaptive randomization},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sequence outlier detection and application of gated
recurrent unit autoencoder gaussian mixture model based on various loss
optimization. <em>Statistical Analysis and Data Mining: The ASA Data
Science Journal</em>, <em>18</em>(1), e70001. (<a
href="https://doi.org/10.1002/sam.70001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the era of big data, detecting outliers in time series data is crucial, particularly in fields such as finance and engineering. This article proposes a novel sequence outlier detection method based on the gated recurrent unit autoencoder with Gaussian mixture model (GRU-AE-GMM), which combines gated recurrent unit (GRU), autoencoder (AE), Gaussian mixture model (GMM), and optimization algorithms. The GRU captures long-term dependencies within the sequence, while the AE measures sequence abnormality. Meanwhile, the GMM models the relationship between the original and reconstructed sequences, employing the Expectation–Maximization (EM) algorithm for parameter estimation to calculate the likelihood of each hidden variable belonging to each Gaussian mixture component. In this article, we first train the model with mean-squared error loss (MSEL), and then further enhanced by substituting it with quantile loss (QL), composite quantile loss (CQL), and Huber loss (HL), respectively. Next, we validate the effectiveness and robustness of the proposed model through Monte Carlo experiments conducted under different error terms. Finally, the method is applied to Amazon stock data for 2022, demonstrating its significant potential for application in dynamic and unpredictable market environments.},
  archive  = {J},
  author   = {Ting Xu and Yuzhu Tian and Chunho Wu and Zhibao Mian},
  doi      = {10.1002/sam.70001},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e70001},
  title    = {Sequence outlier detection and application of gated recurrent unit autoencoder gaussian mixture model based on various loss optimization},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Persistent classification: Understanding adversarial attacks
by studying decision boundary dynamics. <em>Statistical Analysis and
Data Mining: The ASA Data Science Journal</em>, <em>18</em>(1), e11716.
(<a href="https://doi.org/10.1002/sam.11716">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {There are a number of hypotheses underlying the existence of adversarial examples for classification problems. These include the high-dimensionality of the data, the high codimension in the ambient space of the data manifolds of interest, and that the structure of machine learning models may encourage classifiers to develop decision boundaries close to data points. This article proposes a new framework for studying adversarial examples that does not depend directly on the distance to the decision boundary. Similarly to the smoothed classifier literature, we define a (natural or adversarial) data point to be ( γ , σ)-stable if the probability of the same classification is at least γ $$ \gamma $$ for points sampled in a Gaussian neighborhood of the point with a given standard deviation σ $$ \sigma $$ . We focus on studying the differences between persistence metrics along interpolants of natural and adversarial points. We show that adversarial examples have significantly lower persistence than natural examples for large neural networks in the context of the MNIST and ImageNet datasets. We connect this lack of persistence with decision boundary geometry by measuring angles of interpolants with respect to decision boundaries. Finally, we connect this approach with robustness by developing a manifold alignment gradient metric and demonstrating the increase in robustness that can be achieved when training with the addition of this metric.},
  archive  = {J},
  author   = {Brian Bell and Michael Geyer and David Glickenstein and Keaton Hamm and Carlos Scheidegger and Amanda Fernandez and Juston Moore},
  doi      = {10.1002/sam.11716},
  journal  = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  month    = {2},
  number   = {1},
  pages    = {e11716},
  title    = {Persistent classification: Understanding adversarial attacks by studying decision boundary dynamics},
  volume   = {18},
  year     = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
