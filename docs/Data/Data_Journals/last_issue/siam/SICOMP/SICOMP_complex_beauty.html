<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SICOMP_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sicomp---4">SICOMP - 4</h2>
<ul>
<li><details>
<summary>
(2025). Constant inapproximability for PPA. <em>SICOMP</em>,
<em>54</em>(1), 163–192. (<a
href="https://doi.org/10.1137/22M1536613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In the -Consensus-Halving problem, we are given probability measures on the interval , and the goal is to partition into two parts and using at most cuts, so that for all . This fundamental fair division problem was the first natural problem shown to be complete for the class PPA, and all subsequent PPA-completeness results for other natural problems have been obtained by reducing from it. We show that -Consensus-Halving is PPA-complete even when the parameter is a constant. In fact, we prove that this holds for any constant . As a result, we obtain constant inapproximability results for all known natural PPA-complete problems, including necklace splitting, the discrete ham sandwich problem, two variants of the pizza sharing problem, and for finding fair independent sets in cycles and paths.},
  archive      = {J_SICOMP},
  author       = {Argyrios Deligkas and John Fearnley and Alexandros Hollender and Themistoklis Melissourgos},
  doi          = {10.1137/22M1536613},
  journal      = {SIAM Journal on Computing},
  month        = {2},
  number       = {1},
  pages        = {163-192},
  shortjournal = {SIAM J. Comput.},
  title        = {Constant inapproximability for PPA},
  volume       = {54},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Algebraic algorithms for fractional linear matroid parity
via noncommutative rank. <em>SICOMP</em>, <em>54</em>(1), 134–162. (<a
href="https://doi.org/10.1137/22M1537096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Matrix representations are a powerful tool for designing efficient algorithms for combinatorial optimization problems such as matching, and linear matroid intersection and parity. In this paper, we initiate the study of matrix representations using the concept of noncommutative rank (nc-rank), which has recently attracted attention in the research of Edmonds’ problem. We reveal that the nc-rank of the matrix representation of linear matroid parity corresponds to the optimal value of fractional linear matroid parity: a half-integral relaxation of linear matroid parity. Based on our representation, we present an algebraic algorithm for the fractional linear matroid parity problem by building a new technique to incorporate the search-to-decision reduction into the half-integral problem represented via the nc-rank. We further present a faster divide-and-conquer algorithm for finding a maximum fractional matroid matching and an algebraic algorithm for finding a dual optimal solution. They together lead to an algebraic algorithm for the weighted fractional linear matroid parity problem. Our algorithms are significantly simpler and faster than the existing algorithms.},
  archive      = {J_SICOMP},
  author       = {Taihei Oki and Tasuku Soma},
  doi          = {10.1137/22M1537096},
  journal      = {SIAM Journal on Computing},
  month        = {2},
  number       = {1},
  pages        = {134-162},
  shortjournal = {SIAM J. Comput.},
  title        = {Algebraic algorithms for fractional linear matroid parity via noncommutative rank},
  volume       = {54},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fitting metrics and ultrametrics with minimum disagreements.
<em>SICOMP</em>, <em>54</em>(1), 92–133. (<a
href="https://doi.org/10.1137/22M1520190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Given recording pairwise distances, the Metric Violation Distance problem asks to compute the distance between and the metric cone; i.e., modify the minimum number of entries of to make it a metric. Due to its large number of applications in various data analysis and optimization tasks, this problem has been actively studied recently. We present an -approximation algorithm for Metric Violation Distance, exponentially improving the previous best approximation ratio of of Fan, Raichel, and Van Buskirk [SODA, 2018]. Furthermore, a major strength of our algorithm is its simplicity and running time. We also study the related problem of Ultrametric Violation Distance, where the goal is to compute the distance to the cone of ultrametrics, and achieve a constant factor approximation algorithm. The Ultrametric Violation Distance problem can be regarded as an extension of the problem of fitting ultrametrics studied by Ailon and Charikar [SIAM J. Comput., 2011] and by Cohen-Addad, Das, Kipouridis, Parotsidis, and Thorup [FOCS, 2021] from norm to norm. We show that this problem can be favorably interpreted as an instance of Correlation Clustering with an additional hierarchical structure, which we solve using a new -approximation algorithm for correlation clustering that has the structural property that it outputs a refinement of the optimum clusters. An algorithm satisfying such a property can be considered of independent interest. We also provide an -approximation algorithm for a weighted version of Ultrametric Violation Distance. Finally, we investigate the complementary version of these problems where one aims at choosing a maximum number of entries of forming an (ultra)metric. In stark contrast to the minimization versions, we prove that these maximization versions are hard to approximate within any constant factor assuming the Unique Games Conjecture.},
  archive      = {J_SICOMP},
  author       = {Vincent Cohen-Addad and Chenglin Fan and Euiwoong Lee and Arnaud de Mesmay},
  doi          = {10.1137/22M1520190},
  journal      = {SIAM Journal on Computing},
  month        = {2},
  number       = {1},
  pages        = {92-133},
  shortjournal = {SIAM J. Comput.},
  title        = {Fitting metrics and ultrametrics with minimum disagreements},
  volume       = {54},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lossy planarization: A constant-factor approximate
kernelization for planar vertex deletion. <em>SICOMP</em>,
<em>54</em>(1), 1–91. (<a
href="https://doi.org/10.1137/22M152058X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In the -minor-free deletion problem we are given an undirected graph and the goal is to find a minimum vertex set that intersects all minor models of graphs from the family . This captures numerous important problems including Vertex cover, Feedback vertex set, Treewidth- modulator, and Vertex planarization. In the latter one, we ask for a minimum vertex set whose removal makes the graph planar. This is a special case of -minor-free deletion for the family . Whenever the family contains at least one planar graph, then -minor-free deletion is known to admit a constant-factor approximation algorithm and a polynomial kernelization [F. Fomin et al., Proceedings of the 53rd Annual Symposium on Foundations of Computer Science, IEEE, 2012, pp. 470–479]. A polynomial kernelization is a polynomial-time algorithm that, given a graph and integer , outputs a graph on vertices and integer , so that if and only if . The Vertex planarization problem is arguably the simplest setting for which does not contain a planar graph and the existence of a constant-factor approximation or a polynomial kernelization remains a major open problem. In this work we show that Vertex planarization admits an algorithm which is a combination of both approaches. Namely, we present a polynomial -approximate kernelization, for some constant , based on the framework of lossy kernelization [D. Lokshtanov et al., Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing, ACM, 2017, pp. 224–237]. Simply speaking, when given a graph and integer , we show how to compute a graph on vertices so that any -approximate solution to can be lifted to an -approximate solution to , as long as . In order to achieve this, we develop a toolkit for sparsification of planar graphs which approximately preserves all separators and near-separators between subsets of the given terminal set. Our result yields an improvement over the state-of-the-art approximation algorithms for Vertex planarization. The problem admits a polynomial-time -approximation algorithm, for any , and a quasi-polynomial-time -approximation algorithm, where is the input size, both randomized [K. Kawarabayashi and A. Sidiropoulos, Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, ACM, 2019, pp. 164–175]. By pipelining these algorithms with our approximate kernelization, we improve the approximation factors to respectively and .},
  archive      = {J_SICOMP},
  author       = {Bart M. P. Jansen and Michał Włodarczyk},
  doi          = {10.1137/22M152058X},
  journal      = {SIAM Journal on Computing},
  month        = {2},
  number       = {1},
  pages        = {1-91},
  shortjournal = {SIAM J. Comput.},
  title        = {Lossy planarization: A constant-factor approximate kernelization for planar vertex deletion},
  volume       = {54},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
