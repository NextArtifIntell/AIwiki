<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MLST_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mlst---32">MLST - 32</h2>
<ul>
<li><details>
<summary>
(2025). Enhanced feature encoding and classification on distributed
quantum hardware. <em>MLST</em>, <em>6</em>(1), 015056. (<a
href="https://doi.org/10.1088/2632-2153/adb4bc">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The steady progress of quantum hardware is motivating the search for novel quantum algorithm optimization strategies for near-term, real-world applications. In this study, we propose a novel feature map optimization strategy for quantum support vector machines (QSVMs), designed to enhance binary classification while taking into account backend-specific parameters, including qubit connectivity, native gate sets, and circuit depth, which are critical factors in noisy intermediate scale quantum devices. The dataset we utilised belongs to the neutrino physics domain, with applications in the search for neutrinoless double beta decay. A key contribution of this work is the parallelization of the classification task to commercially available superconducting quantum hardware to speed up the genetic search processes. The study was carried out by partitioning each quantum processing unit (QPU) into several sub-units with the same topology to implement individual QSVM instances. We conducted parallelization experiments with three IBM backends with more than 100 qubits, ranking the sub-units based on their susceptibility to noise. Data-driven simulations show how, under certain restrictions, parallelized genetic optimization can occur with the tested devices when retaining the top 20% ranked sub-units in the QPU.},
  archive      = {J_MLST},
  author       = {R Moretti and A Giachero and V Radescu and M Grossi},
  doi          = {10.1088/2632-2153/adb4bc},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015056},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Enhanced feature encoding and classification on distributed quantum hardware},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DCG—differentiable connected geometries for AI-compatible
multi-domain optimization and inverse design. <em>MLST</em>,
<em>6</em>(1), 015055. (<a
href="https://doi.org/10.1088/2632-2153/adb3ef">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of geometry and topology optimization, discovering geometries that optimally satisfy specific problem criteria is a complex challenge in both engineering and scientific research. In this work, we propose a new approach for the creation of multidomain connected geometries that are designed to work with automatic differentiation. We introduce the concept of differentiable connected geometries, discussing its theoretical aspects and illustrating its application through simple toy examples and a more sophisticated photonic optimization task. Since these geometries are built upon the principles of automatic differentiation, they are compatible with existing deep learning frameworks, a feature we demonstrate via the application examples. This methodology provides a systematic way to approach geometric design and optimization in computational fields involving dependent geometries, potentially improving the efficiency and effectiveness of optimization tasks in scientific and engineering applications.},
  archive      = {J_MLST},
  author       = {Alexander Luce and Daniel Grünbaum and Florian Marquardt},
  doi          = {10.1088/2632-2153/adb3ef},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015055},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {DCG—differentiable connected geometries for AI-compatible multi-domain optimization and inverse design},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). New gravitational wave discoveries enabled by machine
learning. <em>MLST</em>, <em>6</em>(1), 015054. (<a
href="https://doi.org/10.1088/2632-2153/adb5ed">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The detection of gravitational waves (GWs) has revolutionized our understanding of the Universe, offering unprecedented insights into its dynamics. A major goal of GW data analysis is to speed up the detection and parameter estimation process using machine learning (ML) techniques, in light of an anticipated surge in detected events that would render traditional methods impractical. Here, we present new GW candidate events, the first to be identified in data from a network of interferometric detectors through ML. We discuss several new enhancements of our ResNet-based deep learning code, AresGW, that increased its sensitivity, including a new hierarchical classification of triggers, based on different noise and frequency filters. The enhancements resulted in a significant reduction in the false alarm rate, allowing AresGW to surpass traditional pipelines in the number of detected events in its effective training range (single source masses between 7 and 50 solar masses and source chirp masses between 10 and 40 solar masses), when the new detections are included. We calculate the astrophysical significance of events detected with AresGW using a logarithmic ranking statistic and injections into O3 data. Furthermore, we present spectrograms, parameter estimation, and reconstruction in the time domain for our new candidate events and discuss the distribution of their properties. In addition, the AresGW code exhibited very good performance when tested across various two-detector setups and on observational data from the O1 and O2 observing periods. Our findings underscore the remarkable potential of AresGW as a fast and sensitive detection algorithm for GW astronomy, paving the way for a larger number of future discoveries.},
  archive      = {J_MLST},
  author       = {Alexandra E Koloniari and Evdokia C Koursoumpa and Paraskevi Nousi and Paraskevas Lampropoulos and Nikolaos Passalis and Anastasios Tefas and Nikolaos Stergioulas},
  doi          = {10.1088/2632-2153/adb5ed},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015054},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {New gravitational wave discoveries enabled by machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scalable and accurate simulation of electrolyte solutions
with quantum chemical accuracy. <em>MLST</em>, <em>6</em>(1), 015053.
(<a href="https://doi.org/10.1088/2632-2153/adaf76">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrolyte solutions play critical role in a vast range of important applications, yet an accurate and scalable method of predicting their properties without fitting to experiment has remained out of reach, despite over a century of effort. Here, we combine state-of-the-art density functional theory and equivariant neural network potentials to demonstrate this capability, reproducing key structural, thermodynamic, and kinetic properties. We show that neural network potentials can be recursively trained on a subset of their own output to enable coarse-grained/continuum-solvent molecular simulations that can access much longer timescales than possible with all atom simulations. We observe the surprising formation of Li cation dimers along with identical anion-anion pairing of chloride and bromide anions. Finally, we simulate the crystal phase and infinite dilution pairing free energies despite being trained only on moderate concentration solutions. This approach should be scaled to build a greatly expanded database of electrolyte solution properties than currently exists.},
  archive      = {J_MLST},
  author       = {Junji Zhang and Joshua Pagotto and Tim Gould and Timothy T Duignan},
  doi          = {10.1088/2632-2153/adaf76},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015053},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Scalable and accurate simulation of electrolyte solutions with quantum chemical accuracy},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Refereeing the referees: Evaluating two-sample tests for
validating generators in precision sciences. <em>MLST</em>,
<em>6</em>(1), 015052. (<a
href="https://doi.org/10.1088/2632-2153/adb3ee">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a robust methodology to evaluate the performance and computational efficiency of non-parametric two-sample tests, specifically designed for high-dimensional generative models in scientific applications such as in particle physics. The study focuses on tests built from univariate integral probability measures: the sliced Wasserstein distance and the mean of the Kolmogorov–Smirnov (KS) statistics, already discussed in the literature, and the novel sliced KS statistic. These metrics can be evaluated in parallel, allowing for fast and reliable estimates of their distribution under the null hypothesis. We also compare these metrics with the recently proposed unbiased Fréchet Gaussian distance and the unbiased quadratic Maximum Mean Discrepancy, computed with a quartic polynomial kernel. We evaluate the proposed tests on various distributions, focusing on their sensitivity to deformations parameterized by a single parameter ε . Our experiments include correlated Gaussians and mixtures of Gaussians in 5, 20, and 100 dimensions, and a particle physics dataset of gluon jets from the JetNet dataset, considering both jet- and particle-level features. Our results demonstrate that one-dimensional-based tests provide a level of sensitivity comparable to other multivariate metrics, but with significantly lower computational cost, making them ideal for evaluating generative models in high-dimensional settings. This methodology offers an efficient, standardized tool for model comparison and can serve as a benchmark for more advanced tests, including machine-learning-based approaches.},
  archive      = {J_MLST},
  author       = {Samuele Grossi and Marco Letizia and Riccardo Torre},
  doi          = {10.1088/2632-2153/adb3ee},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015052},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Refereeing the referees: Evaluating two-sample tests for validating generators in precision sciences},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Autoencoder-assisted study of directed percolation with
spatial long-range interactions. <em>MLST</em>, <em>6</em>(1), 015051.
(<a href="https://doi.org/10.1088/2632-2153/adb370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the universality class of reaction–diffusion processes with long-range interactions in non-equilibrium phase transitions is both challenging and intriguing. Identifying critical points is fundamental for studying the phase transition characteristics of these universality classes. Unlike Monte Carlo simulations of statistical system observables, machine learning methods can extract evolutionary information from clusters of such systems, enabling a faster approach to phase transition regions. We developed a method that uses the one-dimensional encoding output of a stacked autoencoder (SAE) to determine the critical point in systems undergoing (1+1)-dimensional directed percolation with spatial long-range interactions. We validate this method by examining the power-law behavior of particle density at the critical point, which strongly supports our approach. As the system adheres to the scaling relation t_f{\sim}L^{z} at the critical point, we conducted extensive simulations at this critical probability to determine the dynamic exponent z . In addition, the SAE is also capable of identifying the characteristic time of critical states. Finally, we tested two other heavy-tailed distributions that generate random step lengths: the Lévy distribution and the Cauchy distribution, which introduce different global spreading mechanisms. This method remains effective for determining the critical points in these systems. Our findings highlight the promising applications of SAE techniques for processes involving long-range interactions.},
  archive      = {J_MLST},
  author       = {Yanyang Wang and Yuxiang Yang and Wei Li},
  doi          = {10.1088/2632-2153/adb370},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015051},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Autoencoder-assisted study of directed percolation with spatial long-range interactions},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning group invariant calabi–yau metrics by fundamental
domain projections. <em>MLST</em>, <em>6</em>(1), 015050. (<a
href="https://doi.org/10.1088/2632-2153/adb4bb">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present new invariant machine learning models that approximate the Ricci-flat metric on Calabi–Yau (CY) manifolds with discrete symmetries. We accomplish this by combining state of the art models for predicting such metrics, based on the so-called φ -model of the cymetric package, with non-trainable, G -invariant, canonicalization layers that project the φ -model&#39;s input data (i.e. points sampled from the CY geometry) to the fundamental domain of a given symmetry group G . These G -invariant layers are easy to concatenate, provided one compatibility condition is fulfilled, and combine well with both standard and spectral versions of the φ -model. Through experiments on different CY geometries, we find that, for fixed point sample size and training time, canonicalized models give slightly more accurate metric approximations than the standard φ -model. On highly symmetric spaces, we also observe significantly faster convergence upon training. The method may also be used to compute the Ricci-flat metric on smooth CY quotients. We demonstrate this aspect by experiments on a smooth \mathbb{Z}^2_5 quotient of a 5-parameter quintic CY manifold.},
  archive      = {J_MLST},
  author       = {Yacoub Hendi and Magdalena Larfors and Moritz Walden},
  doi          = {10.1088/2632-2153/adb4bb},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015050},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Learning group invariant Calabi–Yau metrics by fundamental domain projections},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast bayesian inference for neutrino non-standard
interactions at dark matter direct detection experiments. <em>MLST</em>,
<em>6</em>(1), 015049. (<a
href="https://doi.org/10.1088/2632-2153/adb3ed">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-dimensional parameter spaces are commonly encountered in physics theories that go beyond the standard model. However, they often possess complicated posterior geometries that are expensive to traverse using techniques traditional to astroparticle physics. Several recent innovations, which are only beginning to make their way into this field, have made navigating such complex posteriors possible. These include GPU acceleration, automatic differentiation, and neural-network-guided reparameterization. We apply these advancements to dark matter direct detection experiments in the context of non-standard neutrino interactions and benchmark their performances against traditional nested sampling techniques when conducting Bayesian inference. Compared to nested sampling alone, we find that these techniques increase performance for both nested sampling and Hamiltonian Monte Carlo, accelerating inference by factors of \mathord{\sim} 100 and \mathord{\sim} 60 , respectively. As nested sampling also evaluates the Bayesian evidence, these advancements can be exploited to improve model comparison performance while retaining compatibility with existing implementations that are widely used in the natural sciences. Using these techniques, we perform the first scan in the neutrino non-standard interactions parameter space for direct detection experiments whereby all parameters are allowed to vary simultaneously. We expect that these advancements are broadly applicable to other areas of astroparticle physics featuring multi-dimensional parameter spaces.},
  archive      = {J_MLST},
  author       = {Dorian W P Amaral and Shixiao Liang and Juehang Qin and Christopher Tunnell},
  doi          = {10.1088/2632-2153/adb3ed},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015049},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Fast bayesian inference for neutrino non-standard interactions at dark matter direct detection experiments},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LTAU-FF: Loss trajectory analysis for uncertainty in
atomistic force fields. <em>MLST</em>, <em>6</em>(1), 015048. (<a
href="https://doi.org/10.1088/2632-2153/adb4b9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model ensembles are effective tools for estimating prediction uncertainty in deep learning atomistic force fields. However, their widespread adoption is hindered by high computational costs and overconfident error estimates. In this work, we address these challenges by leveraging distributions of per-sample errors obtained during training and employing a distance-based similarity search in the model latent space. Our method, which we call LTAU (Loss Trajectory Analysis for Uncertainty), efficiently estimates the full probability distribution function of errors for any test point using the logged training errors, achieving speeds that are 2–3 orders of magnitudes faster than typical ensemble methods and allowing it to be used for tasks where training or evaluating multiple models would be infeasible. We apply LTAU towards estimating parametric uncertainty in atomistic force fields ( LTAU-FF ), demonstrating that it produces well-calibrated confidence intervals and predicts errors that correlate strongly with the true errors for data near the training domain. Furthermore, we show that the errors predicted by LTAU-FF can be used in practical applications for detecting out-of-domain data, tuning model performance, and predicting failure during simulations. We believe that LTAU will be a valuable tool for uncertainty quantification in atomistic force fields and is a promising method that should be further explored in other domains of machine learning.},
  archive      = {J_MLST},
  author       = {Joshua A Vita and Amit Samanta and Fei Zhou and Vincenzo Lordi},
  doi          = {10.1088/2632-2153/adb4b9},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015048},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {LTAU-FF: Loss trajectory analysis for uncertainty in atomistic force fields},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Validating large-scale quantum machine learning: Efficient
simulation of quantum support vector machines using tensor networks.
<em>MLST</em>, <em>6</em>(1), 015047. (<a
href="https://doi.org/10.1088/2632-2153/adb4ba">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an efficient tensor-network-based approach for simulating large-scale quantum circuits exemplified by quantum support vector machines (QSVMs). Experimentally, leveraging the cuTensorNet library on multiple GPUs, our method effectively reduces the exponential runtime growth to near-quadratic scaling with respect to the number of qubits in practical scenarios. Traditional state-vector simulations become computationally infeasible beyond approximately 50 qubits; in contrast, our simulator successfully handles QSVMs with up to 784 qubits, executing simulations within seconds on a single high-performance GPU. Furthermore, utilizing the message passing interface for multi-GPU environments, our method demonstrates strong linear scalability, effectively decreasing computation time as dataset sizes increase. We validate our framework using the MNIST and Fashion MNIST datasets, achieving successful multiclass classification and highlighting the potential of QSVMs for high-dimensional data analysis. By integrating tensor-network techniques with advanced high-performance computing resources, this work demonstrates both the feasibility and scalability of simulating large-qubit quantum machine learning models, providing a valuable validation tool within the emerging Quantum-HPC ecosystem.},
  archive      = {J_MLST},
  author       = {Kuan-Cheng Chen and Tai-Yue Li and Yun-Yuan Wang and Simon See and Chun-Chieh Wang and Robert Wille and Nan-Yow Chen and An-Cheng Yang and Chun-Yu Lin},
  doi          = {10.1088/2632-2153/adb4ba},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015047},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Validating large-scale quantum machine learning: Efficient simulation of quantum support vector machines using tensor networks},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overcoming sparse datasets with multi-task learning as
applied to high entropy alloys. <em>MLST</em>, <em>6</em>(1), 015046.
(<a href="https://doi.org/10.1088/2632-2153/adb53c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of novel High Entropy Alloys for use in high-temperature applications is an area of active interest due to their potential to provide exceptional properties compared to conventional alloys. Since the increased popularity of machine learning, an important cog in the design process has been training surrogate models on alloy properties. However, these Single-Task models are trained on individual mechanical properties and do not take advantage of the relatedness between properties. Multi-Task models can capture the interdependencies between tasks, leading to potentially more accurate predictions for all tasks. In this paper, we investigate if Multi-Task models can show improvement over Single-Task models when used for predicting the mechanical properties of these alloys. To ensure fair evaluation between the models, we apply L 0 regularization and skip connections to the models, which allows them to adjust the number of model parameters and depth for optimal performance. We find that the Multi-Task models can leverage task relationships to perform better than Single-Task models, especially for high amounts of missing data in the tasks. Furthermore, adding simple auxiliary targets can boost Multi-Task performance even further despite not being effective as input descriptors to single-task models themselves. We anticipate that the proposed strategies can achieve more accurate predictions and consequently enable better design capabilities for such data-constrained domains without incurring much additional computational cost.},
  archive      = {J_MLST},
  author       = {Arindam Debnath and Wesley F Reinhart},
  doi          = {10.1088/2632-2153/adb53c},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015046},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Overcoming sparse datasets with multi-task learning as applied to high entropy alloys},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging multi-task learning regressor chains for small
and sparse tabular data in materials design. <em>MLST</em>,
<em>6</em>(1), 015045. (<a
href="https://doi.org/10.1088/2632-2153/adae53">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning has become increasingly important in materials design, yet traditional single-task learning (STL) models fail to fully exploit the potential of available data in scenarios involving multiple targets and incomplete datasets. While STL models overlook the inherent correlations between target properties, this study showcases how multi-task learning (MTL) effectively leverages these correlations. Therefore, the performance of MTL methods compared to STL is evaluated across five datasets, covering twelve prediction tasks and incorporating different types and levels of data sparsity. Our findings reveal that MTL significantly outperforms STL, particularly in sparse data scenarios, with up to 15% prediction improvements across all tasks. Moreover, MTL methods utilizing regressor chains with automated machine learning tools achieve superior performance compared to those based on neural networks, with minimal training effort required. This work advances data efficiency in data-driven materials design, establishing MTL as a potent tool for simultaneous learning and predicting multiple material properties.},
  archive      = {J_MLST},
  author       = {Felix Conrad and Hajo Wiemer and Steffen Ihlenfeldt},
  doi          = {10.1088/2632-2153/adae53},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015045},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Leveraging multi-task learning regressor chains for small and sparse tabular data in materials design},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph neural network simulation of dispersed systems.
<em>MLST</em>, <em>6</em>(1), 015044. (<a
href="https://doi.org/10.1088/2632-2153/adb0a0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a graph neural network (GNN) that accurately simulates a multidisperse suspension of interacting spherical particles. Our machine learning framework is built upon the recent work of Sanchez-Gonzalez et al (2020 ICML vol 119 (PMLR) pp 8459–68) on graph network simulators, and efficiently learns the intricate dynamics of the interacting particles. Nodes and edges of the GNN correspond, respectively, to the particles with their individual properties/data (e.g. radius, position, velocity) and the pairwise interactions between the particles (e.g. electrostatics, hydrodynamics). A key contribution of our work is to account for the finite dimensions of the particles and their impact on the system dynamics. We test our GNN against a representative case study of a multidisperse mixture of two-dimensional spheres sedimenting under gravity in a liquid and interacting with each other by a Lennard–Jones potential. The present GNN framework offers a fast and accurate method for the theoretical study of complex physical systems such as field-induced behavior of colloidal suspensions and ionic liquids. Our implementation of the GNN is available on GitHub at github.com/rfjd/GNS-DispersedSystems .},
  archive      = {J_MLST},
  author       = {Aref Hashemi and Aliakbar Izadkhah},
  doi          = {10.1088/2632-2153/adb0a0},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015044},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A graph neural network simulation of dispersed systems},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Satellite image classification with neural quantum kernels.
<em>MLST</em>, <em>6</em>(1), 015043. (<a
href="https://doi.org/10.1088/2632-2153/ada86c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Achieving practical applications of quantum machine learning (QML) for real-world scenarios remains challenging despite significant theoretical progress. This paper proposes a novel approach for classifying satellite images, a task of particular relevance to the earth observation industry, using QML techniques. Specifically, we focus on classifying images that contain solar panels, addressing a complex real-world classification problem. Our approach begins with classical pre-processing to reduce the dimensionality of the satellite image dataset. We then apply neural quantum kernels-quantum kernels derived from trained quantum neural networks-for classification. We evaluate several strategies within this framework, demonstrating results that are competitive with the best classical methods. Key findings include the robustness of or results and their scalability, with successful performance achieved up to 8 qubits.},
  archive      = {J_MLST},
  author       = {Pablo Rodriguez-Grasa and Robert Farzan-Rodriguez and Gabriele Novelli and Yue Ban and Mikel Sanz},
  doi          = {10.1088/2632-2153/ada86c},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015043},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Satellite image classification with neural quantum kernels},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantum resources of quantum and classical variational
methods. <em>MLST</em>, <em>6</em>(1), 015042. (<a
href="https://doi.org/10.1088/2632-2153/adaca2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational techniques have long been at the heart of atomic, solid-state, and many-body physics. They have recently extended to quantum and classical machine learning, providing a basis for representing quantum states via neural networks. These methods generally aim to minimize the energy of a given ansatz, though open questions remain about the expressivity of quantum and classical variational ansätze. The connection between variational techniques and quantum computing, through variational quantum algorithms, offers opportunities to explore the quantum complexity of classical methods. We demonstrate how the concept of non-stabilizerness, or magic, can create a bridge between quantum information and variational techniques and we show that energy accuracy is a necessary but not always sufficient condition for accuracy in non-stabilizerness. Through systematic benchmarking of neural network quantum states, matrix product states, and variational quantum methods, we show that while classical techniques are more accurate in non-stabilizerness, not accounting for the symmetries of the system can have a severe impact on this accuracy. Our findings form a basis for a universal expressivity characterization of both quantum and classical variational methods.},
  archive      = {J_MLST},
  author       = {Thomas Spriggs and Arash Ahmadi and Bokai Chen and Eliska Greplova},
  doi          = {10.1088/2632-2153/adaca2},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015042},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantum resources of quantum and classical variational methods},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based architecture search for quantum
machine learning. <em>MLST</em>, <em>6</em>(1), 015041. (<a
href="https://doi.org/10.1088/2632-2153/adaf75">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantum machine learning (QML) models use encoding circuits to map data into a quantum Hilbert space. While it is well known that the architecture of these circuits significantly influences core properties of the resulting model, they are often chosen heuristically. In this work, we present a approach using reinforcement learning techniques to generate problem-specific encoding circuits to improve the performance of QML models. By specifically using a model-based reinforcement learning algorithm, we reduce the number of necessary circuit evaluations during the search, providing a sample-efficient framework. In contrast to previous search algorithms, our method uses a layered circuit structure that significantly reduces the search space. Additionally, our approach can account for multiple objectives such as solution quality and circuit depth. We benchmark our tailored circuits against various reference models, including models with problem-agnostic circuits and classical models. Our results highlight the effectiveness of problem-specific encoding circuits in enhancing QML model performance.},
  archive      = {J_MLST},
  author       = {Frederic Rapp and David A Kreplin and Marco F Huber and Marco Roth},
  doi          = {10.1088/2632-2153/adaf75},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015041},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Reinforcement learning-based architecture search for quantum machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Medical image segmentation assisted with clinical inputs via
language encoder in a deep learning framework. <em>MLST</em>,
<em>6</em>(1), 015040. (<a
href="https://doi.org/10.1088/2632-2153/adb371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Introduction: Auto-segmentation of tumor volumes and organs at risk (OARs) is a critical step in cancer radiotherapy treatment planning, where rapid, precise adjustments to treatment plans are required to match the patient anatomy. Although auto-segmentation has been clinically accepted for most OARs, auto-segmentation of tumor volumes, particularly clinical target volumes (CTVs), remains a challenge. This difficulty arises because images alone are often insufficient to capture the necessary information for accurate delineation of microscopic tumor invasion invisible on the image itself. Methods: We propose a deep learning-based medical image segmentation framework designed to mimic the clinical process of delineating CTVs and OARs. At its core, the model performs precise segmentation of medical images while enhancing accuracy by integrating clinical information in text format. A transformer-based text encoder converts textual clinical data into vectors, which are incorporated into the segmentation process with image features. This integration bridges the gap between traditional automated segmentation methods and clinician-guided, context-rich delineations. The framework&#39;s effectiveness is demonstrated through a prostate segmentation example in the context of radiation therapy for localized prostate cancer, where incorporating clinical context significantly impacts the delineation process. Results: In our experiments, we included additional clinical information potentially influencing clinicians&#39; prostate segmentation. The results show that our proposed method not only outperforms the baseline model, but also surpasses current state-of-the-art methods, with or without clinical contexts. Furthermore, our method demonstrates high performance even with limited data. Conclusion: This proposed segmentation framework has shown to significantly improve auto-segmentation, particularly for CTVs, in cancer radiotherapy.},
  archive      = {J_MLST},
  author       = {Hengrui Zhao and Biling Wang and Deepkumar Mistry and Jing Wang and Michael Dohopolski and Daniel Yang and Weiguo Lu and Steve Jiang and Dan Nguyen},
  doi          = {10.1088/2632-2153/adb371},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015040},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Medical image segmentation assisted with clinical inputs via language encoder in a deep learning framework},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A generative modeling approach to reconstructing 21 cm
tomographic data. <em>MLST</em>, <em>6</em>(1), 015039. (<a
href="https://doi.org/10.1088/2632-2153/adb19c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyses of the cosmic 21 cm signal are hampered by astrophysical foregrounds that are far stronger than the signal itself. These foregrounds, typically confined to a wedge-shaped region in Fourier space, often necessitate the removal of a vast majority of modes, thereby degrading the quality of the data anisotropically. To address this challenge, we introduce a novel deep generative model based on stochastic interpolants to reconstruct the 21 cm data lost to wedge filtering. Our method leverages the non-Gaussian nature of the 21 cm signal to effectively map wedge-filtered 3D lightcones to samples from the conditional distribution of wedge-recovered lightcones. We demonstrate how our method is able to restore spatial information effectively, considering both varying cosmological initial conditions and astrophysics. Furthermore, we discuss a number of future avenues where this approach could be applied in analyses of the 21 cm signal, potentially offering new opportunities to improve our understanding of the Universe during the epochs of cosmic dawn and reionization. Code, pre-trained models, and scripts for making plots in this paper can be found here .},
  archive      = {J_MLST},
  author       = {Nashwan Sabti and Ram Purandhar Reddy Sudha and Julian B Muñoz and Siddharth Mishra-Sharma and Taewook Youn},
  doi          = {10.1088/2632-2153/adb19c},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015039},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {A generative modeling approach to reconstructing 21 cm tomographic data},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Coupled CANN-DEM simulation in solid mechanics.
<em>MLST</em>, <em>6</em>(1), 015038. (<a
href="https://doi.org/10.1088/2632-2153/adaf74">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A general, unified neural network approach as replacement for the finite element method without the need for analytic expressions for material laws is suggested. The complete simulation process from the material characterization to simulations on a structural level takes place in the new neural network framework. The drawback of many conventional analytic expressions of material laws to require large numbers of experiments for parametrization is addressed by an integrated inverse approach. Specifically, an adaptation of the Deep Energy Method is combined with a Constitutive Artificial Neural Network (CANN) and trained on measured displacement fields and prescribed boundary conditions in a coupled procedure. Tests on compressible and incompressible Neo-Hookean solids with up to twelve CANN parameters show high accuracy of the approach and very good generalization of CANNs. A small extent of data is required for robust and reliable training.},
  archive      = {J_MLST},
  author       = {Stefan Hildebrand and Jonathan Georg Friedrich and Melika Mohammadkhah and Sandra Klinge},
  doi          = {10.1088/2632-2153/adaf74},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015038},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Coupled CANN-DEM simulation in solid mechanics},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain knowledge-based deterministic graph traversal method
for white blood cell classification. <em>MLST</em>, <em>6</em>(1),
015037. (<a href="https://doi.org/10.1088/2632-2153/adb126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {White blood cells (WBCs) play a crucial role in human immunity by defending the body against harmful antigens. Classifying WBCs into their five distinct types provides valuable information for assessing human health and identifying various medical conditions. Computer vision models in the literature utilize machine learning and deep learning techniques, to attain high classification accuracy, but they involve complex architectures. In contrast, the proposed work leverages domain knowledge about WBCs to construct a directed graph and applies a deterministic traversal method to the graph to perform classification. The proposed method is trained and tested using multiple datasets namely, the Blood Cell Count and Detection (BCCD) and LISC datasets to evaluate the performance on varying datasets. The performance metrics include accuracy, precision, recall, and F1-score. The results demonstrate the effectiveness of the approach, achieving 99.13% accuracy, 99.25% precision, 99.25% recall, and 99.25% F1 score, on the BCCD dataset. 97.05% accuracy, 97.04% precision, 96.93% recall, and 96.94% F1 score on the LISC dataset making it efficient for WBC classification task.},
  archive      = {J_MLST},
  author       = {Jeneessha P and Vinoth Kumar Balasubramanian},
  doi          = {10.1088/2632-2153/adb126},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015037},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Domain knowledge-based deterministic graph traversal method for white blood cell classification},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient monte carlo simulation of streamer discharges with
deep-learning denoising models. <em>MLST</em>, <em>6</em>(1), 015036.
(<a href="https://doi.org/10.1088/2632-2153/adaca1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric breakdown in non-conducting gases is a complex process that in its first stages is characterized by filamentary discharges called streamers. Streamer dynamics are inherently nonlinear and span broad temporal and spatial scales, making numerical simulation challenging. Although Monte Carlo methods are intuitive and they model the full electron energy distribution without a priori prescriptions, they suffer from artificial sampling noise which, combined with the non-linearity of streamers, distorts their evolution. Here we investigate the use of deep-learning techniques to mitigate the noise introduced by Monte Carlo sampling. We observe that traditional techniques for noise reduction in images are not satisfactory because they do not impose strict conservation of electric charge. Then we present a charge-conserving denoising filter to improve the efficiency of Monte Carlo simulations of streamers.},
  archive      = {J_MLST},
  author       = {F M Bayo-Muñoz and A Malagón-Romero and A Luque},
  doi          = {10.1088/2632-2153/adaca1},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015036},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Efficient monte carlo simulation of streamer discharges with deep-learning denoising models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Closed-form interpretation of neural network classifiers
with symbolic gradients. <em>MLST</em>, <em>6</em>(1), 015035. (<a
href="https://doi.org/10.1088/2632-2153/ad9fd0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {I introduce a unified framework for finding a closed-form interpretation of any single neuron in an artificial neural network. Using this framework I demonstrate how to interpret neural network classifiers to reveal closed-form expressions of the concepts encoded in their decision boundaries. In contrast to neural network-based regression, for classification, it is in general impossible to express the neural network in the form of a symbolic equation even if the neural network itself bases its classification on a quantity that can be written as a closed-form equation. The interpretation framework is based on embedding trained neural networks into an equivalence class of functions that encode the same concept. I interpret these neural networks by finding an intersection between the equivalence class and human-readable equations defined by a symbolic search space. The approach is not limited to classifiers or full neural networks and can be applied to arbitrary neurons in hidden layers or latent spaces.},
  archive      = {J_MLST},
  author       = {Sebastian J Wetzel},
  doi          = {10.1088/2632-2153/ad9fd0},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015035},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Closed-form interpretation of neural network classifiers with symbolic gradients},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Inception networks, data augmentation and transfer learning
in EEG-based photosensitivity diagnosis. <em>MLST</em>, <em>6</em>(1),
015034. (<a href="https://doi.org/10.1088/2632-2153/adb008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Photosensitivity refers to a neurophysiological condition in which the brain generates epileptic discharges known as Photoparoxysmal Responses (PPR) in response to light flashes. In severe cases, these PPR can lead to epileptic seizures. The standardized diagnostic procedure for this condition is called Intermittent Photic Stimulation. During this procedure, the patient is exposed to a flashing light, aiming to trigger these epileptic reactions while preventing their full development. Meanwhile, brain activity is monitored using Electroencephalography, which is visually analyzed by clinical staff to identify these responses. Hence, the automatic detection of PPR becomes a highly unbalanced problem that has been barely studied in the literature due to photosensitivity&#39;s low prevalence. This research tackles this problem and proposes using Inception-based deep learning (DL) neural networks that, together with transfer learning, are trained in epilepsy seizure detection and tuned in the PPR automatic detection task. A data augmentation (DA) technique is also applied to balance the available data set, evaluating its effects on the DL models. The proposal outperformed state-of-the-art solutions in the literature, achieving higher ratios on standard performance metrics, and with DA significantly improving the Sensitivity without affecting Accuracy and Specificity. This project is currently being developed with patients from Burgos University Hospital, Spain.},
  archive      = {J_MLST},
  author       = {Fernando Moncada Martins and Víctor M González and José R Villar and Beatriz García López and Ana Isabel Gómez-Menéndez},
  doi          = {10.1088/2632-2153/adb008},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015034},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Inception networks, data augmentation and transfer learning in EEG-based photosensitivity diagnosis},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Randomized radial basis function neural network for solving
multiscale elliptic equations. <em>MLST</em>, <em>6</em>(1), 015033. (<a
href="https://doi.org/10.1088/2632-2153/ad979c">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinary deep neural network (DNN)-based methods frequently encounter difficulties when tackling multiscale and high-frequency partial differential equations. To overcome these obstacles and improve computational accuracy and efficiency, this paper presents the Randomized Radial Basis Function Neural Network (RRNN), an innovative approach explicitly crafted for solving multiscale elliptic equations. The RRNN method commences by decomposing the computational domain into non-overlapping subdomains. Within each subdomain, the solution to the localized subproblem is approximated by a RRNN with a Gaussian kernel. This network is distinguished by the random assignment of width and center coefficients for its activation functions, thereby rendering the training process focused solely on determining the weight coefficients of the output layer. For each subproblem, similar to the Petrov–Galerkin finite element method, a linear system will be formulated on the foundation of a weak formulation. Subsequently, a selection of collocation points is stochastically sampled at the boundaries of the subdomain, ensuring the satisfaction of C 0 and C 1 continuity and boundary conditions to couple these localized solutions. The network is ultimately trained using the least squares method to ascertain the output layer weights. To validate the RRNN method&#39;s effectiveness, an extensive array of numerical experiments has been executed. The RRNN is firstly compared with a variety of DNN methods based on gradient descent optimization. The comparative analysis demonstrates the RRNN&#39;s superior performance with respect to computational accuracy and training time. Furthermore, it is contrasted with to local extreme learning machine method, which also utilizes domain decomposition and the least squares method. The comparative findings suggest that the RRNN method can attain enhanced accuracy at a comparable computational cost, particularly pronounced in scenarios with a smaller scale ratio ɛ .},
  archive      = {J_MLST},
  author       = {Yuhang Wu and Ziyuan Liu and Wenjun Sun and Xu Qian},
  doi          = {10.1088/2632-2153/ad979c},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015033},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Randomized radial basis function neural network for solving multiscale elliptic equations},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Quantitative assessment of PINN inference on experimental
data for gravity currents flows. <em>MLST</em>, <em>6</em>(1), 015032.
(<a href="https://doi.org/10.1088/2632-2153/adaca0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we apply physics informed neural networks (PINNs) to infer velocity and pressure field from light attenuation technique (LAT) measurements for gravity current induced by lock-exchange. In a PINN model, physical laws are embedded in the loss function of a neural network, such that the model fits the training data but is also constrained to reduce the residuals of the governing equations. PINNs are able to solve ill-posed inverse problems training on sparse and noisy data, and therefore can be applied to real engineering applications. The noise robustness of PINNs and the model parameters are investigated in a 2 dimensions toy case on a lock-exchange configuration, employing synthetic data. Then we train a PINN with experimental LAT measurements and quantitatively compare the velocity fields inferred to particle image velocimetry measurements performed simultaneously on the same experiment. The results state that accurate and useful quantities can be derived from a PINN model trained on real experimental data which is encouraging for a better description of gravity currents.},
  archive      = {J_MLST},
  author       = {Mickaël Delcey and Yoann Cheny and Jean Schneider and Simon Becker and Sébastien Kiesgen De Richter},
  doi          = {10.1088/2632-2153/adaca0},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015032},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Quantitative assessment of PINN inference on experimental data for gravity currents flows},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Into the latent space of capacitive sensors: Interpolation
and synthetic data generation using variational autoencoders.
<em>MLST</em>, <em>6</em>(1), 015031. (<a
href="https://doi.org/10.1088/2632-2153/adb009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many sensing applications, collecting a large experimental dataset could be a time-consuming and expensive task that can also hinder the implementation of Machine Learning models for analyzing sensor data. Therefore, this paper proposes the generation of synthetic signals through a Variational Autoencoder (VAE) to enlarge a spectra dataset acquired with a capacitive sensor based on a Dielectric Resonator. Trained with signals of several water/glycerine concentrations, this generative model learns the dataset characteristics and builds a representative latent space. Consequently, exploring this latent space is a critical task to control the generation of synthetic signals and interpolating concentrations unmeasured by the sensor. For this reason, this paper proposes a search method based on Bayesian Optimization that automatically explores the latent space. The results show excellent signal reconstruction quality, proving that the VAE architecture can successfully generate realistic synthetic signals from capacitive sensors. In addition, the proposed search method obtains a reasonable interpolation capability by finding latent encodings that generate signals related to the target glycerin concentrations. Moreover, this approach could be extended to other sensing technologies.},
  archive      = {J_MLST},
  author       = {Miguel Monteagudo Honrubia and Francisco Javier Herraiz-Martínez and Javier Matanza Domingo},
  doi          = {10.1088/2632-2153/adb009},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015031},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Into the latent space of capacitive sensors: Interpolation and synthetic data generation using variational autoencoders},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine-learning emergent spacetime from linear response in
future tabletop quantum gravity experiments. <em>MLST</em>,
<em>6</em>(1), 015030. (<a
href="https://doi.org/10.1088/2632-2153/adb09f">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel interpretable neural network (NN) model designed to perform precision bulk reconstruction under the AdS/CFT correspondence. According to the correspondence, a specific condensed matter system on a ring is holographically equivalent to a gravitational system on a bulk disk, through which tabletop quantum gravity experiments may be possible as reported in (Hashimoto et al 2023 Phys. Rev. Res. 5 023168). The purpose of this paper is to reconstruct a higher-dimensional gravity metric from the condensed matter system data via machine learning using the NN. Our machine reads spatially and temporarily inhomogeneous linear response data of the condensed matter system, and incorporates a novel layer that implements the Runge–Kutta method to achieve better numerical control. We confirm that our machine can let a higher-dimensional gravity metric be automatically emergent as its interpretable weights, using a linear response of the condensed matter system as data, through supervised machine learning. The developed method could serve as a foundation for generic bulk reconstruction, i.e. a practical solution to the AdS/CFT correspondence, and would be implemented in future tabletop quantum gravity experiments.},
  archive      = {J_MLST},
  author       = {Koji Hashimoto and Koshiro Matsuo and Masaki Murata and Gakuto Ogiwara and Daichi Takeda},
  doi          = {10.1088/2632-2153/adb09f},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015030},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Machine-learning emergent spacetime from linear response in future tabletop quantum gravity experiments},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering emergent connections in quantum physics research
via dynamic word embeddings. <em>MLST</em>, <em>6</em>(1), 015029. (<a
href="https://doi.org/10.1088/2632-2153/adb00a">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the field of quantum physics evolves, researchers naturally form subgroups focusing on specialized problems. While this encourages in-depth exploration, it can limit the exchange of ideas across structurally similar problems in different subfields. To encourage cross-talk among these different specialized areas, data-driven approaches using machine learning have recently shown promise to uncover meaningful connections between research concepts, promoting cross-disciplinary innovation. Current state-of-the-art approaches represent concepts using knowledge graphs and frame the task as a link prediction problem, where connections between concepts are explicitly modeled. In this work, we introduce a novel approach based on dynamic word embeddings for concept combination prediction. Unlike knowledge graphs, our method captures implicit relationships between concepts, can be learned in a fully unsupervised manner, and encodes a broader spectrum of information. We demonstrate that this representation enables accurate predictions about the co-occurrence of concepts within research abstracts over time. To validate the effectiveness of our approach, we provide a comprehensive benchmark against existing methods and offer insights into the interpretability of these embeddings, particularly in the context of quantum physics research. Our findings suggest that this representation offers a more flexible and informative way of modeling conceptual relationships in scientific literature.},
  archive      = {J_MLST},
  author       = {Felix Frohnert and Xuemei Gu and Mario Krenn and Evert van Nieuwenburg},
  doi          = {10.1088/2632-2153/adb00a},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015029},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Discovering emergent connections in quantum physics research via dynamic word embeddings},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep(er) reconstruction of imaging cherenkov detectors with
swin transformers and normalizing flow models. <em>MLST</em>,
<em>6</em>(1), 015028. (<a
href="https://doi.org/10.1088/2632-2153/ada8f4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imaging Cherenkov detectors are crucial for particle identification (PID) in nuclear and particle physics experiments. Fast reconstruction algorithms are essential for near real-time alignment, calibration, data quality control, and efficient analysis. At the future electron–ion collider (EIC), the ePIC detector will feature a dual Ring Imaging Cherenkov (RICH) detector in the hadron direction, a Detector of Internally Reflected Cherenkov (DIRC) in the barrel, and a proximity focus RICH in the electron direction. This paper focuses on the DIRC detector, which presents complex hit patterns and is also used for PID of pions and kaons in the experiment at JLab. We present Deep(er)RICH, an extension of the seminal DeepRICH work, offering improved and faster PID compared to traditional methods and, for the first time, fast and accurate simulation. This advancement addresses a major bottleneck in Cherenkov detector simulations involving photon tracking through complex optical elements. Our results leverage advancements in Vision Transformers, specifically hierarchical Swin Transformer and normalizing flows. These methods enable direct learning from real data and the reconstruction of complex topologies. We conclude by discussing the implications and future extensions of this work, which can offer capabilities for PID for multiple cutting-edge experiments like the future EIC.},
  archive      = {J_MLST},
  author       = {C Fanelli and J Giroux and J Stevens},
  doi          = {10.1088/2632-2153/ada8f4},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015028},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Deep(er) reconstruction of imaging cherenkov detectors with swin transformers and normalizing flow models},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting nonequilibrium green’s function dynamics and
photoemission spectra via nonlinear integral operator learning.
<em>MLST</em>, <em>6</em>(1), 015027. (<a
href="https://doi.org/10.1088/2632-2153/ada99d">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the dynamics of nonequilibrium quantum many-body systems is an important research topic in a wide range of fields across condensed matter physics, quantum optics, and high-energy physics. However, numerical studies of large-scale nonequilibrium phenomena in realistic materials face serious challenges due to intrinsic high-dimensionality of quantum many-body problems and the absence of time-invariance. The nonequilibrium properties of many-body systems can be described by the dynamics of the correlator, or the Green&#39;s function of the system, whose time evolution is given by a high-dimensional system of integro-differential equations, known as the Kadanoff–Baym equations (KBEs). The time-convolution term in KBEs, which needs to be recalculated at each time step, makes it difficult to perform long-time numerical simulation. In this paper, we develop an operator-learning framework based on recurrent neural networks (RNNs) to address this challenge. We utilize RNNs to learn the nonlinear mapping between Green&#39;s functions and convolution integrals in KBEs. By using the learned operators as a surrogate model in the KBE solver, we obtain a general machine-learning scheme for predicting the dynamics of nonequilibrium Green&#39;s functions. Besides significant savings per each time step, the new methodology reduces the temporal computational complexity from O(N_t^3) to O(N_t) where N t is the number of steps taken in a simulation, thereby making it possible to study large many-body problems which are currently infeasible with conventional KBE solvers. Through various numerical examples, we demonstrate the effectiveness of the operator-learning based approach in providing accurate predictions of physical observables such as the reduced density matrix and time-resolved photoemission spectra. Moreover, our framework exhibits clear numerical convergence and can be easily parallelized, thereby facilitating many possible further developments and applications.},
  archive      = {J_MLST},
  author       = {Yuanran Zhu and Jia Yin and Cian C Reeves and Chao Yang and Vojtěch Vlček},
  doi          = {10.1088/2632-2153/ada99d},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015027},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Predicting nonequilibrium green’s function dynamics and photoemission spectra via nonlinear integral operator learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving detection of parkinson’s disease with acoustic
feature optimization using particle swarm optimization and machine
learning. <em>MLST</em>, <em>6</em>(1), 015026. (<a
href="https://doi.org/10.1088/2632-2153/adadc3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parkinson&#39;s disease (PD), characterized by motor impairments and tremors, also presents early-stage vocal abnormalities that hold diagnostic potential. Leveraging voice analysis and classification techniques, numerous studies explore the feasibility of early PD detection through automated systems. While several databases offer acoustic features for this purpose, their effectiveness largely depends on the classification methodology employed. This study aims to refine PD detection systems by introducing customized weighting to acoustic features, adjusting their significance based on their correlation with the disease and the classification algorithm utilized. The particle swarm optimization algorithm is employed for this purpose, with the Oxford PD dataset serving as the source data for training and validation. Performance evaluation encompasses four classification algorithms: support vector machine, Gradient Boosting (GB), k-nearest neighbors (KNN), and Naïve Bayes. A 5-fold cross-validation technique was adopted to evaluate the effectiveness of our method for PD detection. The results show that our approach significantly improves performance regardless of the classifier used, demonstrating its generalization capability. The KNN classifier surpasses state-of-the-art results, achieving an accuracy of 97.44% and a sensitivity of 98.02%.},
  archive      = {J_MLST},
  author       = {Elmoundher Hadjaidji and Mohamed Cherif Amara Korba and Khaled Khelil},
  doi          = {10.1088/2632-2153/adadc3},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {015026},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Improving detection of parkinson’s disease with acoustic feature optimization using particle swarm optimization and machine learning},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Comparing AI versus optimization workflows for
simulation-based inference of spatial-stochastic systems. <em>MLST</em>,
<em>6</em>(1), 010502. (<a
href="https://doi.org/10.1088/2632-2153/ada0a3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model parameter inference is a universal problem across science. This challenge is particularly pronounced in developmental biology, where faithful mechanistic descriptions require spatial-stochastic models with numerous parameters, yet quantitative empirical data often lack sufficient granularity due to experimental limitations. Parameterizing such complex models therefore necessitates methods that elaborate on classical Bayesian inference by incorporating notions of optimality and goal-orientation through low-dimensional objective functions that quantitatively encapsulate target system behavior. In this study, we contrast two such inference workflows and apply them to biophysically inspired spatial-stochastic models. Technically, both workflows employ simulation-based inference (SBI) methods: the first leverages a modern deep-learning technique known as sequential neural posterior estimation, while the second relies on a classical optimization technique called simulated annealing. We evaluate these workflows by inferring the parameters of two complementary models for the inner cell mass (ICM) lineage differentiation in the blastocyst-stage mouse embryo. This developmental biology system serves as a paradigmatic example of a highly robust and reproducible cell-fate proportioning process that self-organizes under strongly stochastic conditions, such as intrinsic biochemical noise and cell–cell signaling delays. Our results reveal that while both methods provide consistent model parameter estimates, the modern SBI workflow yields significantly richer inferred distributions at an equivalent computational cost. We identify the computational scenarios that favor the modern SBI method over its classical counterpart, and propose a plausible strategy to exploit the complementary strengths of both workflows for enhanced parameter space exploration.},
  archive      = {J_MLST},
  author       = {Michael Alexander Ramirez Sierra and Thomas R Sokolowski},
  doi          = {10.1088/2632-2153/ada0a3},
  journal      = {Machine Learning: Science and Technology},
  month        = {2},
  number       = {1},
  pages        = {010502},
  shortjournal = {Mach. Learn.: Sci. Technol.},
  title        = {Comparing AI versus optimization workflows for simulation-based inference of spatial-stochastic systems},
  volume       = {6},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
