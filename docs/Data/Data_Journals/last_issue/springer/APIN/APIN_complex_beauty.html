<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>APIN_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="apin---185">APIN - 185</h2>
<ul>
<li><details>
<summary>
(2025). MOEA/d with adaptive weight vector adjustment and parameter
selection based on q-learning. <em>APIN</em>, <em>55</em>(6), 1–43. (<a
href="https://doi.org/10.1007/s10489-024-05906-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective evolutionary algorithms (MOEAs) are widely utilized for addressing multi-objective optimization problems (MOPs), demonstrating effectiveness in handling low-dimensional and regular Pareto fronts (PFs) MOPs. However, when the number of objectives increases (&gt;3) and the PFs become increasingly intricate, maintaining both the convergence and diversity of solutions presents a significant challenge. To address this, an adaptive weight vector adjustment and parameter selection based on Q-learning (QLMOEA/D-AWA) is proposed. In the algorithm, Q-learning is employed to select both the Tchebycheff value and the number of weight vectors, aiming to balance convergence and diversity. To enhance the convergence, an improved Tchebycheff approach is proposed. To better solve problems in high-dimensional objective spaces, the niche technique is adopted to retain elite individuals. In addition, to address MOPs with irregular PFs, a two-stage weight vector deletion strategy is proposed to remove invalid weight vectors, and a certain number of weight vectors are added based on sparsity rules. An experiment study of objective numbers ranging from 2 to 10 is conducted on DTLZ, WFG, MaF and multi-objective traveling salesman problem (MOTSP). Among 115 benchmark problems, QLMOEA/D-AWA achieves 54 and 49 best results in IGD and HV, respectively.},
  archive      = {J_APIN},
  author       = {Xue, Fei and Chen, Yuezheng and Dong, Tingting and Wang, Peiwen and Fan, Wenyu},
  doi          = {10.1007/s10489-024-05906-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-43},
  shortjournal = {Appl. Intell.},
  title        = {MOEA/D with adaptive weight vector adjustment and parameter selection based on Q-learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel drift detection method using parallel detection and
anti-noise techniques. <em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-024-05988-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of the Internet industry, a large amount of streaming data with significant application value will be generated on the Internet. The distribution of stream data is evolving over time compared to traditional data, posing a significant challenge in the learning process from streaming data. In order to adapt the change of data distribution, concept drift detection methods are proposed to pinpoint when the concept drift occurs. Most existing drift detection methods, however, overlook the improvement of the current classifier and the influence of noise data on drift detection. This oversight leads to a decrease in the effectiveness of drift detection. In this paper, we propose a novel adaptation drift detection method to overcome the shortcomings of previous algorithms, such as error detection and lack of anti-noise capability. Meanwhile, stream computing and parallel computing are used to enhance the efficiency of our algorithm. The results of a simulation experiment on 9 synthetic stream data and 6 real-world stream data, all exhibiting concept drift, demonstrate that our method is more effective in handling concept drift compared to other state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Zhang, Qian and Liu, Guanjun},
  doi          = {10.1007/s10489-024-05988-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A novel drift detection method using parallel detection and anti-noise techniques},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Domain adaptation for improving automatic airborne pollen
classification with expert-verified measurements. <em>APIN</em>,
<em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-024-06021-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel approach to enhance the accuracy of automatic classification systems for airborne pollen particles by integrating domain adaptation techniques. Our method incorporates expert-verified measurements into the convolutional neural network (CNN) training process to address the discrepancy between laboratory test data and real-world environmental measurements. We systematically fine-tuned CNN models, initially developed on standard reference datasets, with these expert-verified measurements. A comprehensive exploration of hyperparameters was conducted to optimize the CNN models, ensuring their robustness and adaptability across various environmental conditions and pollen types. Empirical results indicate a significant improvement, evidenced by a 22.52% increase in correlation and a 38.05% reduction in standard deviation across 29 cases of different pollen classes over multiple study years. This research highlights the potential of domain adaptation techniques in environmental monitoring, particularly in contexts where the integrity and representativeness of reference datasets are difficult to verify.},
  archive      = {J_APIN},
  author       = {Matavulj, Predrag and Jelic, Slobodan and Severdija, Domagoj and Brdar, Sanja and Radovanovic, Milos and Tesendic, Danijela and Sikoparija, Branko},
  doi          = {10.1007/s10489-024-06021-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Domain adaptation for improving automatic airborne pollen classification with expert-verified measurements},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selections based on uncertainty measurements from
dual-quantitative improvement and double-hierarchical fusion.
<em>APIN</em>, <em>55</em>(6), 1–35. (<a
href="https://doi.org/10.1007/s10489-024-06075-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selections promote classification learning, and rough set theory offers effective mathematical methods; in practice, the performance enhancement of feature selection algorithms formulates a research target and challenge, and the corresponding problem solving usually resorts to improvement constructions of uncertainty measures. By fitting fuzzy rough sets (FFRSs), the relative dependency complement mutual information (FDCIE) motivates a recent algorithm of feature selection, called FNRDCI; however, FDCIE has improvement space of quantification view and fusion hierarchy, so the corresponding feature selection and heuristic algorithm can be advanced. In this paper, the dependency is improved by information localization, while the mutual information is enriched by information fuzzification and decision-class combination, so improved fusion measures and robuster feature selections are established by double-hierarchical fusion on decision classification and class. At first, the correctional dependency is proposed by fuzzy decision localization, and it induces a classification fusion measure (i.e. FCDCIE); based on two types of fuzzy decisions, two types of mutual information (i.e. FRCEmI and FRCFmI) are established by information fuzzification and class combination. Then, two types of dependency and two types of mutual information combinedly generate $$2\times 2=4$$ classification fusion measures (i.e. IFRDCEmI, IFRDCFmI, IFRCDCEmI, IFRCDCFmI) by pursuing class-level priority fusion; these new measures acquire semantics uncertainty, system equations, and granulation monotonicity/nonmonotonicity. Furthermore, $$1+2\times 2=5$$ fusion measures yield 5 novel feature selections with heuristic algorithms. Finally, experimental comparisons demonstrate the effectiveness and efficiency of the proposed novel methods of uncertainty measures and selection algorithms.},
  archive      = {J_APIN},
  author       = {Wang, Qian and Zhang, Xianyong and Lv, Zhiying and Mo, Zhiwen},
  doi          = {10.1007/s10489-024-06075-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-35},
  shortjournal = {Appl. Intell.},
  title        = {Feature selections based on uncertainty measurements from dual-quantitative improvement and double-hierarchical fusion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Daily power generation forecasting for a grid-connected
solar power plant using transfer learning technique. <em>APIN</em>,
<em>55</em>(6), 1–19. (<a
href="https://doi.org/10.1007/s10489-024-06090-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is efficiently used for photovoltaic power generation forecasting to handle the intermittent nature of solar energy. However, big data are required for training deep networks which are not available for newly installed plants. Therefore, in this study, a novel strategy is proposed to train a deep learning model using a transfer learning technique to cop up with the unavailability of enough training datasets. A new 400 kWp solar power plant installed in the Himalayan region is considered as a case study to evaluate the proposed model. The proposed approach utilizes solar radiation data to train a deep neural network and then fine-tune the model using the power generation data from the plant. The network architecture is optimized using grey wolf optimizer to find the best suitable model for the data. The evaluation results show that the same model can achieve higher performance in generation forecasting with percentage error improved by 2% and R-value increased by 7.7% after applying transfer learning. Moreover, SHapley Additive exPlanation and Partial Dependence Plots are used to interpret the model behavior and showed that the model is mostly dependent on the previous generation values (up to 4 days) followed by the temperature and solar radiation.},
  archive      = {J_APIN},
  author       = {Tajjour, Salwan and Chandel, Shyam Singh and Malik, Hasmat and Márquez, Fausto Pedro García and Alotaibi, Majed A.},
  doi          = {10.1007/s10489-024-06090-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Daily power generation forecasting for a grid-connected solar power plant using transfer learning technique},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Dirichlet stochastic weights averaging for
graph neural networks. <em>APIN</em>, <em>55</em>(6), 1. (<a
href="https://doi.org/10.1007/s10489-024-06099-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Park, Minhoi and Chang, Rakwoo and Song, Kyungwoo},
  doi          = {10.1007/s10489-024-06099-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Dirichlet stochastic weights averaging for graph neural networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing the imitation game: A trust-based model for
distinguishing human and machine participants. <em>APIN</em>,
<em>55</em>(6), 1–39. (<a
href="https://doi.org/10.1007/s10489-024-06133-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since 1950, the imitation game has captured the interest of researchers investigating human‒machine differences. Designed to evaluate machine cognition through a game-based framework, its complexity demands refinement. The imitation game utilizes this game-based setup, but its inherent intricacy calls for further enhancements. The fundamental question of whether machines are capable of genuine thought has been a key issue in artificial intelligence (AI) studies. Recent developments challenge the ease of differentiation, as AI enables machines to display human-like characteristics. This paper seeks to address the shortcomings of the original Turing test and criticisms of the imitation game by introducing an integrated model. Although machines currently operate based on our instructions, they can learn from errors and produce novel responses through generative AI techniques, even though they do not experience emotions. In this study, a new trust-based model was introduced to improve the imitation game. This model integrated various factors to assess the reliability of participants’ responses, including grammatical accuracy, response time, thinking duration, response speed, creativity, and the use of human-like expressions. The goal was to calculate a trust factor that determines the likelihood of a participant being a human or machine. To evaluate the model’s performance, a comprehensive dataset was developed using a chat generative pretrained transformer (ChatGPT-3.5). Two other large language models (LLMs), the large language model meta AI (Llama 3) and the Claude LLM, were also taken into account. To simulate the experiment with human participants, human-generated text was also included. The simulation results revealed that GPT-3.5 Turbo, Llama 3, and Claude LLM performed differently in terms of grammatical accuracy, human-like phrasing, creativity, and trust factors. GPT-3.5 and Llama 3 had lower error rates but struggled with human-like phrases. Claude resulted in more grammatical errors but better creativity. The human participants consistently showed greater trust and human-like phrase usage. Probability assessments categorized machines with 71–78% accuracy, whereas humans were identified with only a 29–36% chance of being a machine.},
  archive      = {J_APIN},
  author       = {Gupta, Tanisha and Tripathi, Akarsh and Dubey, Ashutosh Kumar and Chahar, Ravita},
  doi          = {10.1007/s10489-024-06133-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-39},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing the imitation game: A trust-based model for distinguishing human and machine participants},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Freeway optimal control based on emission oriented
microscopic graph convolutional neural network. <em>APIN</em>,
<em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-024-06143-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction and control in the active traffic control system is considered as one of the most critical issues in Intelligent Transportation Systems (ITS). Among the proposed AI-based approaches, Deep Learning (DL) has been largely applied while showing better performances. This research improves macroscopic traffic flow model METANET by establishing a graph convolution neural network (GCN) to explicitly and more precisely incorporate microscopic traffic flow dynamics. The microscopic emission model utilizes the feature extraction function of GCN to reduce the complexity of measuring the environmental profits for the whole traffic network. By introducing the GCN model to facilitate the aggregation of vehicle information, the proposed framework reduces the computational burden and obtains better optimization performance. The designed algorithms are tested on a microscopic simulation platform based on field data. The results demonstrate that the proposed control method produce a more robust and smooth traffic flow environment, which leads to improved traffic efficiency and overall carbon emissions of the road network.},
  archive      = {J_APIN},
  author       = {Fang, Jie and Lu, Mingwen and Fu, Lina and Wang, Juanmeizi and Xu, Mengyun},
  doi          = {10.1007/s10489-024-06143-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Freeway optimal control based on emission oriented microscopic graph convolutional neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving vehicle detection accuracy in complex traffic
scenes through context attention and multi-scale feature fusion module.
<em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-024-06146-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle detection is a fundamental task for automated driving systems. However, achieving robust performance in complex traffic scenarios remains a formidable challenge. In this paper, we propose a novel vehicle detection model that leverages contextual attention mechanisms and multi-scale feature fusion to effectively tackle the inherent challenges presented by complex scenarios, such as occlusion, truncation, and small-scale vehicle instances. The proposed model introduces a contextual attention module tailored to address vehicle occlusion, augmenting the model’s reasoning ability and overall performance through the integration of global contextual information. Additionally, we introduce a Multi-Scale Feature Fusion Module to mitigate the impact of drastic changes in vehicle scales observed in dynamic traffic scenarios. Through the deployment of a dedicated multi-scale feature fusion module, our model adeptly adapts to significant size variations of vehicles in traffic scene images, thereby enhancing its capability to handle vehicles of varying sizes. Our contributions are validated through comprehensive qualitative and quantitative experiments conducted on both the KITTI dataset and the Cityscapes dataset. The experimental results demonstrate the exceptional robustness and accuracy of our proposed model. These findings provide conclusive evidence of the superior performance and effectiveness of our model in real-world applications.},
  archive      = {J_APIN},
  author       = {Liu, Wenbo and Zhao, Binglin and Zhu, Yuxin and Deng, Tao and Yan, Fei},
  doi          = {10.1007/s10489-024-06146-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Improving vehicle detection accuracy in complex traffic scenes through context attention and multi-scale feature fusion module},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement knowledge graph reasoning based on dual agents
and attention mechanism. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-024-06162-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning can model knowledge graph multi-hop reasoning as Markov Decision Processes and improve the accuracy and interpretability of predicting paths between entities. Existing reasoning methods usually ignore the logic of action selection when facing one-to-many or many-to-many relationships, resulting in poor performance in knowledge graph reasoning. Furthermore, the general multi-hop reasoning only achieves effective short-path reasoning and lacks efficiency in long-distance reasoning. To address the above challenges, we propose a reinforcement learning reasoning model based on dual agents and attention mechanism, where two agents are trained at the macro and micro levels, and the macro agent guides the reasoning of the micro agent. The model employs an attention mechanism to enhance the representation of the current state of the agent, to help the policy network in making more appropriate action selections when facing one-to-many or many-to-many relationships, so as to improve the selection efficiency. Simultaneously, we propose a reward function with a penalty mechanism that penalizes the agent for prematurely reaching the correct answer without staying in place, and enhances the reward of the micro agent with the reward of the macro agent. The two agents cooperate with each other to find reasoning paths on the knowledge graph. Finally, we compare the proposed model with six well-known inference method baselines on three benchmark datasets, and the experimental results show that our proposed method achieves very competitive results.},
  archive      = {J_APIN},
  author       = {Yang, Xu-Hua and Wang, Tao and Gan, Ji-Song and Gao, Liang-Yu and Ma, Gang-Feng and Zhou, Yan-Bo},
  doi          = {10.1007/s10489-024-06162-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Reinforcement knowledge graph reasoning based on dual agents and attention mechanism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Explainable cognitive decline detection in
free dialogues with a machine learning approach based on pre-trained
large language models. <em>APIN</em>, <em>55</em>(6), 1. (<a
href="https://doi.org/10.1007/s10489-024-06169-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {de Arriba-Pérez, Francisco and García-Méndez, Silvia and Otero-Mosquera, Javier and González-Castaño, Francisco J.},
  doi          = {10.1007/s10489-024-06169-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Explainable cognitive decline detection in free dialogues with a machine learning approach based on pre-trained large language models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Applications of pre-trained CNN models and data fusion
techniques in Unity3D for connected vehicles. <em>APIN</em>,
<em>55</em>(6), 1–29. (<a
href="https://doi.org/10.1007/s10489-024-06213-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Transportation Systems (ITS) aim to enhance road safety and Internet of Things (IoT)-related solutions are crucial in achieving this objective. By leveraging Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I) technologies, drivers can access valuable information about their surroundings. This research utilized the Unity 3D game engine to simulate various traffic scenarios, exploring a stochastic environment with two data sources: camera and road sign labels. We developed a full-duplex communication system to enable the communication between Python and Unity. This allows the vehicle to capture images in Unity and classify them using Convolutional Neural Network (CNN) models coded in Python. To improve road sign detection accuracy, we applied multi-sensor Data Fusion (DF) techniques to fuse the information received from the sources. We applied DF methods such as the Kalman filter, Dempster-Shafer theory, and Fuzzy Integral Operators to combine the two sources of information. Furthermore, our proposed CNN model incorporates an Ordered Weighted Averaging (OWA) layer to fuse information from three pre-trained CNN models. Our results show that the proposed model integrating the OWA layer achieved an accuracy of 98.81%, outperforming six state-of-the-art models. We compared the Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF). In our work, EKF exhibited a lower execution time (0.02 seconds), yielding less accurate results. UKF, however, provided a more accurate estimate while being more computationally complex. Furthermore, the Dempster-Shafer model showed approximately 30% better accuracy compared to the Fuzzy Integral Operator. Using this methodology on autonomous vehicles in our virtual environment led to making more accurate decisions, even in a variety of weather conditions and accident scenarios. The findings of this research contribute to the development of more efficient and safer vehicles.},
  archive      = {J_APIN},
  author       = {Norouzi, Mojtaba and Hosseini, Seyed Hossein and Khoshnevisan, Mohammad and Moshiri, Behzad},
  doi          = {10.1007/s10489-024-06213-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Applications of pre-trained CNN models and data fusion techniques in Unity3D for connected vehicles},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computational analysis of virus-host protein-protein
interactions using gene ontology and natural language processing.
<em>APIN</em>, <em>55</em>(6), 1–22. (<a
href="https://doi.org/10.1007/s10489-024-06223-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The role of in-silico computational methods in identifying protein-protein interactions (PPIs) between target and host proteins is crucial for developing effective infection treatments. These methods are essential for quickly determining high-quality and accurate PPIs, predicting protein pairs with the highest likelihood of physical interaction from a large pool, and reducing the need for experimental confirmation or prioritizing pairs for experiments. This study proposes using gene ontology and natural language processing (NLP) approaches to extract and quantify features from protein sequences. In the first step, proteins were represented using gene ontology terms, and a set of features was generated. In the second step, NLP techniques treated gene ontology terms as a word dictionary, creating numerical vectors using the bag of words (BoW), count vector, term frequency-inverse document frequency (TF-IDF), and information content methods. In the third step, different machine learning methods, including Decision Tree, Random Forest, Bagging-RepTree, Bagging-RF, BayesNet, Deep Neural Network (DNN), Logistic Regression, Support Vector Machine (SVM), and VotedPerceptron, were employed to predict protein interactions in the datasets. In the fourth step, the Max-Min Parents and Children (MMPC) feature selection algorithm was applied to improve predictions using fewer features. The performance of the developed method was tested on the SARS-CoV-2 protein interaction dataset. The MMPC algorithm reduced the feature count by over 99%, enhancing protein interaction prediction. After feature selection, the DNN method achieved the highest predictive performance, with an AUC of 0.878 and an F-Measure of 0.793. Sequence-based protein encoding methods AAC, APAAC, CKSAAPP, CTriad, DC, and PAAC were applied to proteins in the SARS-CoV-2 interaction dataset and their performance was compared with GO-NLP. The performance of the relevant methods was measured separately and combined. The highest performance was obtained from the combined dataset with an AUC value of 0.888. This study demonstrates that the proposed gene ontology and NLP approach can successfully predict protein-protein interactions for antiviral drug design with significantly fewer features using the MMPC-DNN model.},
  archive      = {J_APIN},
  author       = {Cihan, Pınar and Ozger, Zeynep Banu and Cakabay, Zeynep},
  doi          = {10.1007/s10489-024-06223-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Computational analysis of virus-host protein-protein interactions using gene ontology and natural language processing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluating cruise user satisfaction through online reviews:
A method based on sentiment analysis and large-scale group
decision-making. <em>APIN</em>, <em>55</em>(6), 1–23. (<a
href="https://doi.org/10.1007/s10489-025-06241-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online reviews of cruise tourism, as user-generated information, contain customers’ evaluations of various aspects of the cruise tourism industry. They influence the development of this industry by affecting potential users’ purchasing decisions. To promote the sustainable development of the cruise tourism industry, it is crucial to understand the factors influencing high user satisfaction and to ensure high levels of user satisfaction. With a focus on the factors influencing the cruise travel experience, this paper proposes a method for determining user requirements (URs) and evaluating user satisfaction with cruise tourism by integrating online review analysis with large-scale group decision-making (LSGDM). First, we establish a sentiment dictionary for the cruise domain based on online reviews, selecting seed sentiment words according to word frequency and expanding them using the Word2vec and semantic orientation using pointwise mutual information algorithms. Second, we use the latent Dirichlet allocation topic model to analyze online reviews and identify the 10 URs that are of actual concern to cruise customers. Then we perform dependency syntax analysis to conduct a fine-grained sentiment analysis of each review to identify the sentiment intensity values toward different cruise URs. Third, we evaluate the final satisfaction and ranking of URs using the LSGDM method, which includes a consensus model with a personalized feedback mechanism based on the minimum adjustment cost. We conclude by providing suggestions for improving the cruise tourism experience.},
  archive      = {J_APIN},
  author       = {Shi, Jing and Chen, Jing and Wu, Jian and Liu, Yujia},
  doi          = {10.1007/s10489-025-06241-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Evaluating cruise user satisfaction through online reviews: A method based on sentiment analysis and large-scale group decision-making},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predictive control approach incorporating incremental
learning. <em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06243-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Incremental Learning MPC (ILMPC), a novel Model Predictive Control (MPC) approach designed to enhance the adaptability of control systems in dynamic environments with unpredictable disturbances. Traditional MPC methods are often limited by their reliance on static models and fixed optimization schemes, making them less effective in handling disturbances and model inaccuracies. To overcome these limitations, ILMPC integrates incremental learning, enabling continuous refinement of the control model using real-time data. This innovation improves prediction accuracy and control performance, allowing the system to adapt to changing operational conditions and unknown disturbances. Key advances include the development of a sequence prediction model that continuously updates the state-space model through incremental learning, improved disturbance suppression for more stable control, and a reduction in computational complexity by incrementally model parameters. Experimental results show that ILMPC enhances deviation suppression significantly compared to conventional methods and significantly reduces control input volatility, demonstrating its superior performance in real-time disturbance suppression and adaptability.},
  archive      = {J_APIN},
  author       = {Chen, Jian and Pan, Haiwei and Zhang, Kejia and Lan, Haiyan and Xu, Xu and Luo, Wenhui},
  doi          = {10.1007/s10489-025-06243-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Predictive control approach incorporating incremental learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boundary-sensitive adaptive decoupled knowledge distillation
for acne grading. <em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06260-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acne grading is a critical step in the treatment and customization of personalized therapeutic plans. Although the knowledge distillation architecture exhibits outstanding performance on acne grading task, the impact of non-label classes is not considered separately, resulting in low distillation efficiency for non-label classes. Such insufficiency will cause the misclassification of the acne images located on the edge of the decision boundary. To address this issue, a novel method named Adaptive Decoupled Knowledge Distillation (ADKD) which considers the uniqueness of the acne images is proposed. In order to explore the influence of non-label classes and enhance the model’s distillation efficiency on them, ADKD splits the traditional KD loss into two parts: non-label class knowledge distillation (NCKD), and label class knowledge distillation (LCKD). Additionally, it dynamically adjusts the NCKD based on the distance between the sample and each non-label class. This allows the model to allocate different learning intensities to various non-label classes, reducing the overrecognition of classes near the sample and the underrecognition of distant classes. The proposed method enables the model to better learn the fuzzy features between acne images, and more accurately classify the samples located on the decision boundary. To verify the proposed method, extensive experiments were carried out on ACNE04 dataset, ACNEHX dataset, and DermaMnist dataset. The experimental results demonstrate the effectiveness of this method, and its performance surpasses that of current state-of-the-art (SOTA) method.},
  archive      = {J_APIN},
  author       = {Zhou, Xinyang and Liu, Wenjie and Zhang, Lei and Zhang, Xianliang},
  doi          = {10.1007/s10489-025-06260-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Boundary-sensitive adaptive decoupled knowledge distillation for acne grading},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Facial StO2-based personal identification: Dataset
construction, feasibility study, and recognition framework.
<em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06267-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometrics have been extensively utilized in the realm of identity recognition. However, each biometric method has its inherent limitations in specific scenarios. For example, identity recognition based on facial images is contactless but can be forged; finger vein recognition is very secure but generally requires contact collection to ensure accurate identification. In some scenarios with high security requirements, there is often a need for contactless acquisition of biometric features that cannot be forged to recognize identity. Therefore, a novel biometric, facial tissue oxygen saturation (StO2) with the advantages of robust anti-spoofing capabilities and non-contact measurement, is proposed for identity recognition. To more comprehensively verify the feasibility of facial StO2 for identity recognition, a Facial StO2 Identity Dataset (FSID148) containing 148 identities is collected and the feasibility of facial StO2 identity recognition is validated by performing verification, close-set identification, and open-set identification tasks. In order to enhance the performance of facial StO2 identity recognition, an attention-guided contrastive learning framework that enables backbones to derive discriminative identity representations from both local and global facial StO2 regions is proposed. The method proposed has achieved accuracies of 96.11%, 94.60%, and 88.51% in the aforementioned tasks, positioning facial StO2 as a promising biometric for a wide array of application scenarios.},
  archive      = {J_APIN},
  author       = {Zhang, Zheyuan and Liu, Xinyu and Jia, Yingjuan and Zhou, Ju and Wang, Hanpu and Wang, Jiaxiu and Chen, Tong},
  doi          = {10.1007/s10489-025-06267-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Facial StO2-based personal identification: Dataset construction, feasibility study, and recognition framework},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mind the naive forecast! A rigorous evaluation of
forecasting models for time series with low predictability.
<em>APIN</em>, <em>55</em>(6), 1–27. (<a
href="https://doi.org/10.1007/s10489-025-06268-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of time series forecasting, numerous machine learning studies have assessed the performance of new methods on highly volatile data from macroeconomics and finance. Unlike in other domains, where models are also compared to simpler statistical or naive baselines, they mostly compare the performance solely relative to other complex models. This approach may lead to limited conclusions and reduce the practical significance of the results, as it overlooks the unpredictability of some highly volatile time series in the datasets used. We apply state-of-the-art methods from time-series econometrics and machine learning, including autoregressive integrated moving average (ARIMA), exponential smoothing (ETS), Bayesian vector autoregressive model (BVAR), long-short term memory neural networks (LSTM), historical consistent neural networks (HCNN), deep vector autoregressive neural networks (DeepVAR), temporal fusion transformers (TFT), and extreme gradient boosting (XGBoost). Our results demonstrate that no method consistently outperforms the naive (no-change) forecast for highly volatile time series from two popular datasets containing exchange rates and stock prices, rendering comparative analysis between complex models less meaningful. In contrast, when applied to more predictable macroeconomic price indices, many of the methods significantly outperform naive forecasts. We find that the performance of machine learning models deteriorates more than that of statistical models for high-volatility time series. This study highlights the critical importance of using appropriate benchmark models, including cost-effective, simple approaches, on datasets that permit meaningful conclusions.},
  archive      = {J_APIN},
  author       = {Beck, Nico and Dovern, Jonas and Vogl, Stefanie},
  doi          = {10.1007/s10489-025-06268-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {Mind the naive forecast! a rigorous evaluation of forecasting models for time series with low predictability},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Long-tailed classification by efficient contrast learning
with high quality and high relevance latent features. <em>APIN</em>,
<em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06269-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning robust feature representations from long-tail distributed data is essential. Recently, contrastive learning has shown impressive progress in addressing long-tail learning challenges. While contrastive learning aims to optimize the lower bound of mutual information between feature distribution and label distribution, the previous approaches often substantially rely on less accurate and unrealistic assumptions about model distribution and overlook the long-tail nature of the instance space. Consequently, these methods fail to achieve a sufficiently tight lower bound. To address these concerns, we first propose a loss function derived from mini-Batch instance Features and Class Prototypes to construct a Conditional Gaussian mixture distribution (CGM-BF-CP), and prove its generalization ability from the perspective of generalization error upper bound. Then we create high quality and high relevance KNN graph to model relation between features. And propose a corresponding loss function, i.e., Graph based Contrast Learning Loss (GCLL). The feature information can be transferred between classes through this graph, so that the tail class features can be better learned. The experimental results on Cifar10/100-LT and ImageNet-LT show that our proposed model is competitive with the latest state-of-the-art methods. Our code is available at https://github.com/error030/CGM-BP-CP/tree/main .},
  archive      = {J_APIN},
  author       = {Yuan, Hong-li and Liu, Jian-wei},
  doi          = {10.1007/s10489-025-06269-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Long-tailed classification by efficient contrast learning with high quality and high relevance latent features},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision transformer-based generalized zero-shot learning with
data criticizing. <em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06271-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized Zero-Shot Learning (GZSL) aims to enable accurate testing and recognition of unseen classes by utilizing training data from seen classes and leveraging attribute knowledge. However, GZSL faces a challenge wherein the model, trained solely on seen class data, tends to be biased towards recognizing visual features of seen classes, resulting in poorer recognition performance for unseen classes. To address this issue, we propose an approach called Vision Transformer-Based Generalized Zero-Shot Learning with Data Criticizing (ViT-DaCr). In order to obtain improved visual features, we thoroughly examine features extracted by Vision Transformer (ViT) with a new design. Additionally, we recognize that not all training data align with our model during the training process, leading the model to exhibit a bias towards recognizing visual features of seen classes and directly impacting visual feature recognition. Therefore, we propose a data critic mechanism that utilizes Adjusted Boxplot to filter out such data automatically during the training process. Extensive experiments demonstrate the advanced performance of our model on three challenging and popular datasets.},
  archive      = {J_APIN},
  author       = {Zhou, Quan and Liang, Yucuan and Zhang, Zhenqi and Cao, Wenming},
  doi          = {10.1007/s10489-025-06271-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Vision transformer-based generalized zero-shot learning with data criticizing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Dynamic interactive weighted feature
selection using fuzzy interaction information. <em>APIN</em>,
<em>55</em>(6), 1. (<a
href="https://doi.org/10.1007/s10489-025-06273-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Ma, Xi-Ao and Xu, Hao and Liu, Yi},
  doi          = {10.1007/s10489-025-06273-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Dynamic interactive weighted feature selection using fuzzy interaction information},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PTLO: A model-agnostic training strategy based on
progressive training and label optimization for fine-grained image
classification. <em>APIN</em>, <em>55</em>(6), 1–11. (<a
href="https://doi.org/10.1007/s10489-025-06276-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to conventional image recognition, fine-grained classification exhibits increased vulnerability to labeling noise due to the presence of closely related categories, resulting in degraded performance on complex and non-representative samples. While existing approaches mitigate these issues through data cleaning, loss modification, and semi-supervised learning techniques, they often overlook the intrinsic attributes within training samples. Instead of designing any network architectures, this study introduces a model-agnostic progressive training strategy comprising of progressive training and label optimization, where the former is to decrease the affect from the noisy samples by facilitating a graduated learning approach in an easy-to-hard manner, while the latter is to denoise the label noises. Theoretical analysis also demonstrates that the proposed method uncovers valuable cues hidden in the training data, thereby enhancing the robustness of any learning-based models. Experimental evaluations on fine-grained classification benchmarks (e.g., CUB-200-2011, DTD, and Food-101) across various mainstream classification networks demonstrate the effectiveness of our training strategy. Code is available at https://github.com/cb-rep/LPPT .},
  archive      = {J_APIN},
  author       = {Chen, Yiming and Tao, Xiuting and Chen, Bo and Guo, Jian and Li, Shi},
  doi          = {10.1007/s10489-025-06276-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-11},
  shortjournal = {Appl. Intell.},
  title        = {PTLO: A model-agnostic training strategy based on progressive training and label optimization for fine-grained image classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-contextual stress prediction: Simple methodology for
comparing features and sample domain adaptation techniques in vital sign
analysis. <em>APIN</em>, <em>55</em>(6), 1–26. (<a
href="https://doi.org/10.1007/s10489-025-06277-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stress significantly impacts individuals, particularly in professions like nursing and driving, leading to severe health risks and accidents. Accurate stress measurement is critical for effective interventions, yet research is hindered by incomplete datasets and inconsistent methodologies, slowing the development of reliable predictive models. This paper introduces a framework for cross-contextual stress prediction, enabling the generation of general stress prediction models adaptable to specific domain challenges. The methodology leverages two general daily life datasets and three domain-specific datasets, employing steps such as dataset selection, feature extraction, significant feature identification, feature preprocessing, fine-tuning, domain adaptation, and application to specific contexts. Through this framework, key vital signs were identified as significant predictors of stress, including electrocardiography (ECG), heart rate (HR), heart rate variability (HRV) - low frequency (LF), electrodermal activity (EDA), body temperature (TEMP), and skin conductance response (SCR). The experiments conducted include: 1) Utilizing HR and HRV-LF through domain adaptation from general to automobile driving datasets; 2) Applying EDA, HR, and TEMP from general to specific nurse activity datasets; and 3) Adapting ECG, HR, and TEMP from general to automobile driving datasets. Results demonstrate the potential of the proposed framework for cross-contextual stress prediction, with HR and HRV-LF identified as pivotal features. When applied to target datasets specific to stress scenarios, the model achieved a 62% F1 score, demonstrating the effectiveness of the feature-based Correlation Alignment (CORAL) technique combined with Random Forest models in transferring learned knowledge across domains. These findings highlight the robustness of the approach in adapting general stress prediction models to specific contexts, paving the way for real-world applications such as stress monitoring in driving and nursing during high-stress periods like COVID-19.},
  archive      = {J_APIN},
  author       = {Mihirette, Samson and De la Cal, Enrique A. and Tan, Qing and Sedano, Javier},
  doi          = {10.1007/s10489-025-06277-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Cross-contextual stress prediction: Simple methodology for comparing features and sample domain adaptation techniques in vital sign analysis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unsupervised feature learning using locality-preserved
auto-encoder with complexity-invariant distance for intelligent fault
diagnosis of machinery. <em>APIN</em>, <em>55</em>(6), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06278-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised feature learning (UFL) has been recognized as a promising feature extractor in machinery fault diagnosis, where the auto-encoder is a very popular UFL framework. For the auto-encoder methods, however, it is still a great challenge to learn discriminative features from complex signals in an unsupervised manner. In this paper, a new UFL method named locality-preserved auto-encoder (LPAE) is proposed by explicitly designing a locality-preserved penalty term. Concretely, the penalty term constrains local geometry of samples in the original space to be well preserved in the reconstruction space, enabling more discriminative features to be learned accordingly. To better formulate this term, the complexity-invariant distance (CID) is employed to measure similarity between two mechanical signals so as to construct a reliable neighbor graph. On a rolling bearing dataset, experimental results verify that the proposed LPAE can learn sufficiently discriminative features from complex vibration signals collected from varying operating conditions, and achieves a remarkable and superior diagnosis performance over the existing advanced UFL methods. Moreover, the effectiveness of CID has been adequately validated by comparing with several other distance measurement methods. The proposed LPAE can be applied to the feature extraction stage of machinery fault diagnosis, which provides a potential solution for engineers to realize unsupervised learning of discriminative features.},
  archive      = {J_APIN},
  author       = {Lu, Zhenghua and Chu, Zhaobi and Zhu, Min and Dong, Xueping},
  doi          = {10.1007/s10489-025-06278-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Unsupervised feature learning using locality-preserved auto-encoder with complexity-invariant distance for intelligent fault diagnosis of machinery},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised symmetric non-negative matrix factorization
with graph quality improvement and constraints. <em>APIN</em>,
<em>55</em>(6), 1–22. (<a
href="https://doi.org/10.1007/s10489-025-06282-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetric non-negative matrix factorization (SNMF) decomposes a similarity matrix into the product of an indicator matrix and its transpose, allowing clustering results to be directly extracted from the indicator matrix without additional clustering methods. Furthermore, SNMF has been shown to be effective in clustering nonlinearly separable data. SNMF-based clustering methods significantly depend on the quality of the pairwise similarity matrix, yet their effectiveness is often hindered by the reliance on predefined matrices in most semi-supervised SNMF approaches. Thus, we propose a novel algorithm, named semi-supervised symmetric non-negative matrix factorization with graph quality improvement and constraints ( $$\text {S}^{3}\text {NMFGC}$$ ), addressing this limitation by employing an integrated clustering strategy that dynamically generates and adaptively updates the similarity matrices. This is accomplished by integrating a weighted graph construction based on multiple clustering results, a label propagation algorithm, and pairwise constraint terms into a unified optimization framework that enhances the semi-supervised SNMF model. Subsequently, we adopt an alternating iterative update method to solve the optimization problem and prove its convergence. Rigorous experiments highlight the superiority of our model, which outperforms seven state-of-the-art NMF methods across six datasets.},
  archive      = {J_APIN},
  author       = {Ren, Xiaowan and Yang, Youlong},
  doi          = {10.1007/s10489-025-06282-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised symmetric non-negative matrix factorization with graph quality improvement and constraints},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypergraph denoising neural network for session-based
recommendation. <em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06283-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation (SBR) predicts the next interaction of users based on their clicked items in a session. Previous studies have shown that hypergraphs are superior in capturing complex item transitions which contribute to SBR performance. However, existing hypergraph-based methods fail to model item co-occurrence and sequential patterns simultaneously, limiting the improvement of recommendation performance. Moreover, they are more sensitive to noisy items than conventional graph models due to the item association mechanism. In this paper, we propose a novel hypergraph-based method named Hypergraph Denoising Neural Network (HDNN) for SBR to tackle the abovementioned problems. The proposed method involves two newly-designed modules: a sequential pattern learning module (SPLM) and an adaptive attention selection module (AASM). In particular, SPLM models item sequential patterns to complement the hypergraph-based models which only focus on co-occurrence patterns. Meanwhile, AASM employs learnable attention score thresholds to exclude items with low attention scores, mitigating the impact of noisy items in hypergraphs. Furthermore, the sequential denoising unit (SDU) designed in SPLM is employed to eliminate noise in item sequential patterns, thus realizing the dual denoising purpose. Extensive experiments are conducted on three real-world datasets. The results of the experiments show that our HDNN framework shows better performance than the state-of-the-art models. In particular, all evaluation metrics in Tmall and RetailRocket showed improvements of over 15% and 5%, respectively.},
  archive      = {J_APIN},
  author       = {Ding, Jiawei and Tan, Zhiyi and Lu, Guanming and Wei, Jinsheng},
  doi          = {10.1007/s10489-025-06283-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Hypergraph denoising neural network for session-based recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rethinking probability volume for multi-view stereo: A
probability analysis method. <em>APIN</em>, <em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06284-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing learning-based multi-view stereo (MVS) models primarily focus on predicting depth maps through a cascaded structure to achieve more robust reconstruction results. However, they often emphasize improving the quality of stereo matching while overlooking the importance of depth hypotheses. In this paper, we propose a novel MVS model from the perspective of probability volume analysis. First, the guiding effect of the probability volume is considered for depth refinement. Ideally, the probability distribution along the depth dimension of the probability volume follows an unimodal pattern. We design an unimodal curve to fit this pattern. Then, a reasonable depth refinement range is adaptively selected for each pixel position based on a predefined probability threshold. Additionally, considering that matching noise may cause the probability volume to appear as a blurred unimodal peak, we design the probability volume split-merge module (PVS-PVM). This module performs a peak search based on conditional constraints, splitting the probability volume into main and sub probability volumes, then computes the two sets of depth hypotheses from them. Finally, the new main and sub probability volumes are computed based on these depth hypotheses and merged to predict the depth. This approach allows for a more comprehensive consideration of the regions with higher probability, improving the robustness of depth hypotheses. Experimental results demonstrate that our method effectively utilizes probability volume information to guide depth map refinement and yields enhanced reconstruction results on the DTU and Tanks &amp; Temples datasets. Our code will be released at https://github.com/zongh5a/ProbMVSNet .},
  archive      = {J_APIN},
  author       = {Yu, Zonghua and Wang, Huaijun and Li, Junhuai and Jin, Haiyan and Cao, Ting and Cheng, Kuanhong},
  doi          = {10.1007/s10489-025-06284-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Rethinking probability volume for multi-view stereo: A probability analysis method},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). You are what your feeds make you: A study of user aggressive
behavior on twitter. <em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06286-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread use of aggressive language on Twitter raises concerns about potential negative influences on user behavior. Despite previous research exploring aggression and negativity on the platform, the relationship between consuming aggressive content and users’ aggressive behavior remains underexplored. This study investigates whether exposure to aggressive content on Twitter can lead users to behave more aggressively. Our methodological approach contains four stages: data collection and annotation, aggressive post detection, user aggression intensity metric, and user profiling. We proposed the English Twitter Aggression dataset (TAG-EN) with substantial inter-annotator agreement (Krippendorff’s alpha=0.78). Subsequently, we benchmark the aggression detection performance on TAG-EN dataset (macro F1=0.92) by fine-tuning a pre-trained RoBERTa-large. We quantified user aggression with a proposed “user aggression intensity” metric based on their overall aggressive activity. Our analysis of 14M posts from 63K users revealed that aggressive Twitter feeds can influence users to behave more aggressively online. Furthermore, the study found that users tend to support and encourage aggressive content on social media, which can contribute to the proliferation of aggressive behavior.},
  archive      = {J_APIN},
  author       = {Mane, Swapnil and Kundu, Suman and Sharma, Rajesh},
  doi          = {10.1007/s10489-025-06286-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {You are what your feeds make you: A study of user aggressive behavior on twitter},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view learning based on product and process metrics for
software defect prediction. <em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06288-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction plays a crucial role as a quality assurance technology in software development. The software metrics are associated with the software quality and are vital for prediction models. Most existing defect prediction methods build the prediction model ignoring the complementary information between these two kinds of metrics. In this work, we intend to jointly leverage these two kinds of metrics. For a software instance, we regard the product metrics and the process metrics as its two views. We model the problem of discriminative feature learning from these two kinds of metrics as the problem of multi-view learning. However, it is a challenging task to construct an effective prediction model based on both product and process metrics due to the heterogeneity in data of product and process metrics, and the defect data often has class imbalance characteristic. How to explore the discriminant both inter-view and intra-view effectively has not been well studied. These characteristics make it challenging to construct an effective prediction model. In this paper, we propose a Deep Multi-view Defect Prediction (DMDP) approach, which can predict software defect based on both product and process metrics. We design a neural network with two sub-network branches, which are enforced to share the weights in the last output layer, to map the data from different views to a common space. To guide the training of networks, we design the loss function including the discrepancy loss, discrimination loss and classification loss, which further promotes the distribution consistency across views, makes full use of label information to obtain the discriminative representations, and utilizes the complementarity information for prediction. To alleviate the class imbalance problem, we design a dynamic sampling strategy for dealing with class-imbalanced data. Comprehensive experiments are conducted on 15 projects from three widely used defect datasets. The experimental results demonstrate that multi-view learning based on product and process metrics is helpful for software defect prediction and DMDP outperforms the state-of-the-art baselines.},
  archive      = {J_APIN},
  author       = {Sun, Ying and Wu, Fei and Wu, Di and Jing, Xiao-Yuan and Sun, Yanfei},
  doi          = {10.1007/s10489-025-06288-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view learning based on product and process metrics for software defect prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A user preference knowledge graph incorporating
spatio-temporal transfer features for next POI recommendation.
<em>APIN</em>, <em>55</em>(6), 1–21. (<a
href="https://doi.org/10.1007/s10489-025-06290-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs can improve the performance of recommendation systems and provide explanations for recommendation results, which have been widely applied in the next Point-of-Interest (POI) recommendation. However, the current knowledge graph method for the next POI recommendation focuses on the static attributes of POIs, and only describes the spatio-temporal characteristics when the user transfers between POIs. To fully tap into user preferences for different POIs, we have done the following innovative work. (1) We construct a user preference knowledge graph with spatio-temporal characteristics, named UPSTKG, which expresses preference information from both individual user and global user perspectives. (2) We use local preference triplets in preference knowledge graphs to construct user preference graphs. And use GCN to obtain user preference vectors to replace common user vectors in the sequence, thereby strengthening the potential connection between users and different POIs. (3) We combine UPSTKG and user preference graph to propose the UPSTKGRec method for the next POI recommendation. To evaluate the effectiveness of UPSTKGRec, it is compared to six highly regarded techniques on three distinct benchmark datasets. Compared with the baseline, the average performance of indicators recell@5 and NDCG@5 has increased by 13.8% and 13.1%.},
  archive      = {J_APIN},
  author       = {Sang, Chun-Yan and Yang, Yang and Zhang, Yi-Bo and Liao, Shi-Gen},
  doi          = {10.1007/s10489-025-06290-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A user preference knowledge graph incorporating spatio-temporal transfer features for next POI recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive sparsity detection-based evolutionary algorithm for
large-scale sparse multi-objective optimization problems. <em>APIN</em>,
<em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06291-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale sparse multi-objective optimization problems (LSSMOPs) widely exist in practical applications, which have large-scale decision variables and sparse Pareto optimal solutions. Existing algorithms have some shortcomings in dealing with LSSMOPs: (1) failing to make full use of the knowledge of the sparsity of the Pareto optimal solutions, leading to insufficient sparsity detection; (2) ignoring the connection between binary and real variables, leading to insufficient variables optimization. This paper proposes an adaptive sparsity detection-based evolutionary algorithm (ASD-MOEA) to address these issues, which is a two-stage algorithm. The first stage performs an adaptive sparsity detection strategy, which dynamically adjusts the probability of binary variables flipping and the fitness of decision variables according to the iteration ratio. Then, non-zero variables are mined based on fitness. The second stage performs a variable grouping-based optimization strategy, grouping decision variables according to their sparsity in the set of non-dominated solutions to reduce the search space, then performs genetic operations in the subspace. Finally, we compare ASD-MOEA with six mainstream algorithms. The results show that the proposed algorithm significantly outperforms the existing algorithms in dealing with LSSMOPs, and achieves a balance between sparsity maintenance and variable optimization.},
  archive      = {J_APIN},
  author       = {Qiu, Feiyue and Long, Donghui and Chen, Qi and Hu, Huizhen and Qiu, Qicang},
  doi          = {10.1007/s10489-025-06291-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Adaptive sparsity detection-based evolutionary algorithm for large-scale sparse multi-objective optimization problems},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TITD: Enhancing optimized temporal position encoding with
time intervals and temporal decay in irregular time series forecasting.
<em>APIN</em>, <em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06293-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate Time Series (MTS) acquisition processes often exhibit irregularities, making accurate MTS forecasting challenging. Previous researches focused on interpolation approaches to address data completeness in irregular MTS, but these approaches may introduce noise, thereby altering the feature distributions of irregular MTS. Recent researches trend advocate embedding the missing temporal information through position encoding for forecasting irregular MTS. However, these position encodings were typically designed for text sequences and assumed fixed time intervals, which lead to the loss or distortion of temporal information when applied to irregular MTS. Moreover, they struggled to capture the temporal dynamic information in irregular MTS. To address these challenges, we propose a novel approach called TITD (Time Interval and Temporal Decay), which utilizes time interval and temporal decay information to enhance irregular MTS forecasting. TITD optimizes position encoding to effectively capture both local time interval features and long-term temporal decay patterns, breaking the limitations of static and fixed interval position encoding on time dynamic representation. Simultaneously, TITD integrates multi-view input information from irregular MTS to enhance the representation learning of the relationships across different views, thereby achieving superior forecasting performance without interpolation. Extensive experiments on three real-world time series datasets have demonstrated that TITD provides significant improvements over state-of-the-art methods in irregular MTS forecasting.},
  archive      = {J_APIN},
  author       = {Ji, Jinquan and Cao, Yu and Ma, Yukun and Yan, Jianzhuo},
  doi          = {10.1007/s10489-025-06293-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {TITD: Enhancing optimized temporal position encoding with time intervals and temporal decay in irregular time series forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Rail-PatchCore: Unsupervised learning-based detection of
visual anomalies in the railway-turnout environment. <em>APIN</em>,
<em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06294-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complexity and openness of railway turnout environments pose great challenges to anomaly detection, and supervised methods are highly dependent on labels, making it difficult to address the diverse types of anomalies and the scarcity of samples in turnout environments. To solve these problems, this paper proposes a new method, Rail-PatchCore, which is based on unsupervised learning and effectively reduces the interference of background noise and enhances the ability to capture anomalous features by adding a Dual-Dimensional Channel Attention (DDCA) module and a projection anomaly scoring module to the PatchCore model. The experiments on our railway-turnout anomaly detection dataset(RTAD) and other datasets (RSDDs, MVTec-AD, BTAD, AEBAD-S) show that the detection performance of Rail-PatchCore is better than that of the existing methods, and the image-level and pixel-level AUCROC indices of Rail-PatchCore on the railway turnout anomaly detection dataset reach 72.2% and 95.3%, respectively. This approach provides an efficient and reliable solution for anomaly detection in railway turnout environments.},
  archive      = {J_APIN},
  author       = {Zhang, YuanHao and Yu, Zujun and Zhu, Liqiang and Guo, Baoqing and Wang, Yao},
  doi          = {10.1007/s10489-025-06294-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Rail-PatchCore: Unsupervised learning-based detection of visual anomalies in the railway-turnout environment},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view human point cloud registration method with
overlapping regions semantic constraints and feature weighting.
<em>APIN</em>, <em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06296-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view human point cloud registration is a crucial step in 3D human reconstruction tasks. The symmetric structures and similar geometric features in human point clouds often lead to feature mismatches in point cloud registration. Therefore, we propose a pipeline for game tree registration based on semantic constraints and feature weighting (GTR-SCFW) that enhances the stability and accuracy of feature matching, thereby improving the registration precision of multi-view point clouds. First, we calculate and compare the feature similarity between multi-view point clouds and use a generalized best-first search (BFS) method to construct a multi-layered registration game tree. At each game node, overlapping regions are divided into multiple sub-regions based on semantic information, and global fast registration is used to determine the matching relationships of features within each sub-region. Then, the best matching points in each sub-region are selected based on the confidence of feature pairs, and the weights of all the best point pairs are calculated. Finally, the initial rigid transformation matrix is computed using weighted least squares (WLS), and ICP is employed to achieve fast fine registration. GTR-SCFW effectively avoids incorrect matching relationships caused by geometric feature similarity during the initial transformation estimation, providing a good initial pose for iterative closest point (ICP) fine registration. For point clouds with different initial poses, the registration’s rotational error approaches 0 $$^\circ $$ , while the translational error is as low as 1.203e-4 mm. Comparative experimental results show that this method outperforms existing feature-based registration methods regarding robustness, reliability, and computational efficiency.},
  archive      = {J_APIN},
  author       = {Li, Ming and Li, Guiqin and Li, Xihang and Li, Tiancai},
  doi          = {10.1007/s10489-025-06296-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Multi-view human point cloud registration method with overlapping regions semantic constraints and feature weighting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A complex history browsing text categorization method with
improved BERT embedding layer. <em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06298-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For long texts composed of multiple short fragments, the importance of each fragment to the classification task varies. Some fragments have higher discriminative power and positively contribute to the classification, while others lack discriminative power or even mislead it. Existing methods struggle to converge when handling texts with negative examples. This study analyzes user behavior and assigns interest scores to text fragments based on their classification relevance, allowing the model to focus more on important fragments. Building on bidirectional encoder representations from transformers (BERT), we propose an interest encoding layer model for historical browsing texts. By analyzing user behavior and incorporating an improved term frequency-inverse document frequency (TF-IDF) method, the model adds indicators to fragments with higher discriminative power for user behavior analysis, enabling the model to focus more on these during training. Finally, comparative experiments on the BERT model series validate the advantages of the proposed approach.},
  archive      = {J_APIN},
  author       = {Wang, Yuanhang and Zhou, Yonghua and Qi, Huiyu and Wang, Dingyi and Huang, Annan},
  doi          = {10.1007/s10489-025-06298-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {A complex history browsing text categorization method with improved BERT embedding layer},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end audio classification framework with diverse
features for obstructive sleep apnea-hypopnea syndrome diagnosis.
<em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06299-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Obstructive sleep apnea-hypopnea syndrome (OSAHS) is a prevalent chronic disorder that affects sleep quality and general health. The current diagnostic methods, primarily polysomnography (PSG), are laborious. Furthermore, audio-based methods for diagnosing OSAHS face limited sample sizes and neglect patients’ physiological signs and medical histories. To address these challenges, we introduce a data-driven framework called DFNet, which also considers patients’ medical histories and health indicators. DFNet incorporates an automated audio segmentation- and labeling-based preprocessing procedure to reduce expert annotation costs and subjective errors. We employed random convolutional kernels based on receptive fields for audio feature extraction purposes. These kernels captured both local and global features within the input audio. Additionally, for the first time, we introduced a medical language model that utilizes patients’ medical histories and physiological information as covariates to enhance features. We extensively validated DFNet on an OSAHS dataset obtained from a collaborative university hospital. Our framework classified patients into four categories according to their OSAHS severity: normal, mild, moderate, and severe. DFNet achieved state-of-the-art performance, with a four-class accuracy of 84.12%. DFNet offers a large-scale and cost-effective screening approach for diagnosing OSAHS, reducing the labor requirements of diagnosis. Our code is available at https://github.com/testlbin/DFNet .},
  archive      = {J_APIN},
  author       = {Li, Bin and Qiu, Xihe and Tan, Xiaoyu and Yang, Long and Tao, Jing and Fang, Zhijun and Huang, Jingjing},
  doi          = {10.1007/s10489-025-06299-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {An end-to-end audio classification framework with diverse features for obstructive sleep apnea-hypopnea syndrome diagnosis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiple instance learning with hierarchical discrimination
and smoothing attention for histopathological diagnosis. <em>APIN</em>,
<em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06300-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The microscopic structure of human tissue can be observed by pathological slides, which provides a strong basis for cancer diagnosis. However, the serious lack of experienced pathologists and the complexity of the diagnostic process have facilitated the development of computer-aided pathological image analysis. Pathological slides generally have high resolution, and multiple instance learning (MIL) has been widely used in histopathological whole slide image (WSI) analysis, where each WSI has a large number of unlabelled patches and only a WSI-level label is given. The bag-based MIL methods often learn the decision boundary at the bag level, and thus hard to learn the discriminative features at the instance level. Furthermore, the difficulty of identification varies between positive instances in a bag, and the existing attention-based aggregation methods always assign higher attention scores for the easy-to-identify positive instances, but assign lower attention scores for the difficult-to-identify positive instances and thus cannot learn these difficult instances sufficiently. In this paper, we propose a novel MIL method with hierarchical discrimination learning and a smoothing attention strategy for cancer subtype diagnosis. Particularly, to learn hierarchical discriminative features, the proposed MIL method simultaneously trains a bag classifier and multiple instance classifiers, where the multi-way attention scores of each instance for different categories are used to guide the selection of training samples for the instance classifimer. The smoothing strategy is designed to trade off the attention weights between the easily and hardly identifiable positive instances. We conducted experiments on histopathological diagnosis datasets and achieved state-of-the-art performance. Codes are available at https://github.com/bravePinocchio/HDSA-MIL.},
  archive      = {J_APIN},
  author       = {Zhao, Jing and Zhao, Zhikang and Song, Xueru and Sun, Shiliang},
  doi          = {10.1007/s10489-025-06300-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Multiple instance learning with hierarchical discrimination and smoothing attention for histopathological diagnosis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Complex layout generation for large-scale floor plans via
deep edge-aware GNNs. <em>APIN</em>, <em>55</em>(6), 1–21. (<a
href="https://doi.org/10.1007/s10489-025-06311-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In architectural layout generation, deep learning techniques have advanced the residential generation in multiple scenarios. However, current approaches fail to extract complex graph features from large-scale layouts, neglecting large-scale global context. Additionally, the lack of robust, quantitative evaluation metrics for layouts hampers the objective comparison of different generative approaches. To address these issues, we propose a multi-scale applicable layout generation method based on deep edge-aware GNNs, stressing edge-specific and non-local spatial information. Next, we introduce quantitative metrics to assess layout quality, including room accessibility index and space property proportion, whose purpose is to establish layout standards in the computer-aided design field. Lastly, we create the Public Space Floor Plan Dataset (P-PLAN), a collection of 4,535 annotated layout samples designed to serve as a robust evaluation platform for large-scale layout models. We conducted extensive qualitative and quantitative experiments on the Residential Floor Plan Dataset (R-PLAN) and P-PLAN dataset to demonstrate the effectiveness of the proposed method. Notably, with the proposed evaluation metrics, our method significantly outperforms existing models in accessibility and diversity.},
  archive      = {J_APIN},
  author       = {Lu, Zhengyang and Li, Yifan and Wang, Feng},
  doi          = {10.1007/s10489-025-06311-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Complex layout generation for large-scale floor plans via deep edge-aware GNNs},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-attention fusion and edge-guided fully supervised
contrastive learning network for rail surface defect detection.
<em>APIN</em>, <em>55</em>(6), 1–13. (<a
href="https://doi.org/10.1007/s10489-025-06314-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been significant research focus on efficiently and accurately detecting defects on rail surfaces using computer vision. Utilizing depth information from the rail surface has emerged as an effective approach for detecting visually insignificant types of defects that are unique in nature. However, previous methods have typically overlooked the long-distance dependency between the two modalities when fusing them using conventional convolutional network methods. Additionally, these methods have often relied on traditional cross-entropy loss for edge supervision without considering the intra and inter-pixel relationships associated with edge features. To address these limitations, we propose a novel approach called CECLNet (cross-attention fusion and edge-guided fully supervised contrastive learning network) for rail surface defect detection (RSDD). The proposed CECLNet incorporates a module for inter-modal cross-attention fusion, which effectively explores the complementary information by considering the long-range relationship. Furthermore, we introduce a progressive aggregation-based multiscale feature interactions decoder to promote sufficient information interaction between multiscale features, thus facilitating the generation of final predictions. Finally, we propose a pixel-level fully supervised contrastive learning approach to enhance the efficiency of utilizing edge-assisted information. Extensive experiments conducted on the industrial NEU RGB-D RSDDS-AUG dataset demonstrate the superiority of our proposed CECLNet over 17 state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Yang, Jinxin and Zhou, Wujie},
  doi          = {10.1007/s10489-025-06314-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Cross-attention fusion and edge-guided fully supervised contrastive learning network for rail surface defect detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamically modulated robot compliance via online fuzzy
neural networks for individualized ankle rehabilitation. <em>APIN</em>,
<em>55</em>(6), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06317-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Admittance control, benefiting from human-robot interaction compliance, is widely used in rehabilitation robot studies. However, using inappropriate parameters for the admittance control model can cause harm like overuse syndrome. Therefore, it is necessary to dynamically adjust these parameters to assist patients under varying recovery periods, enabling active rehabilitation training across a wider range of recovery stages. Integrating multiple intelligent approaches presents a promising solution to this challenge. This paper proposes a variable admittance control strategy that employs a variable operator fuzzy neural network (VAC-VOFNN). The VOFNN facilitates the fuzzification of the inference process, leading to superior non-linear fitting capability. Additionally, the network’s parameters are updated online to match the rehabilitation stages of different subjects. Compared to the admittance control strategy with fixed parameters (ACS-FP) and the variable admittance control strategy with fuzzy neural networks (VAC-FNN), the proposed strategy reduces the root mean square (RMS) of surface electromyography (sEMG) from the medial gastrocnemius by 29.14% and 29.04%, respectively, while also decreasing the average interaction torque by 28.63% and 12.24%, respectively. These results suggest that the proposed strategy leads to reduced effort from subjects and increased training cycles before muscle fatigue during the same rehabilitation activities. This makes it beneficial for ankle rehabilitation of patients in different recovery periods.},
  archive      = {J_APIN},
  author       = {Li, Jianfeng and Zhou, Yu and Zuo, Shiping and Dong, Mingjie},
  doi          = {10.1007/s10489-025-06317-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Dynamically modulated robot compliance via online fuzzy neural networks for individualized ankle rehabilitation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust decision-making for autonomous vehicles via deep
reinforcement learning and expert guidance. <em>APIN</em>,
<em>55</em>(6), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06319-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate decision-making within highly interactive driving environments is vital for the safety of self-driving vehicles. Despite the significant progress achieved by the existing models for autonomous vehicle decision-making tasks, there remains untapped potential for further exploration in this field. Previous models have focused primarily on specific scenarios or single tasks, with inefficient sample utilization and weak robustness problems, making them challenging to apply in practice. Motivated by this, a robust decision-making method named DRL-EPKG is proposed, which enables the simultaneous determination of vertical and horizontal behaviors of driverless vehicles without being limited to specific driving scenarios. Specifically, the DRL-EPKG integrates human driving knowledge into a framework of soft actor-critic (SAC), where we derive expert policy by a generative model: variational autoencoders (VAE), train agent policy by employing the SAC algorithm and further guide the behaviors of the agent by regulating the Wasserstein distance between the two policies. Moreover, a multidimensional reward function is designed to comprehensively consider safety, driving velocity, energy efficiency, and passenger comfort. Finally, several baseline models are employed for comparative evaluation in three highly dynamic driving scenarios. The findings demonstrate that the proposed model outperforms the baselines regarding the success rate, highlighting the practical applicability and robustness of DRL-EPKG in addressing complex, real-world problems in autonomous driving.},
  archive      = {J_APIN},
  author       = {Li, Feng-Jie and Zhang, Chun-Yang and Chen, C. L. Philip},
  doi          = {10.1007/s10489-025-06319-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Robust decision-making for autonomous vehicles via deep reinforcement learning and expert guidance},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chaotic opposition-based plant propagation algorithm for
engineering problem. <em>APIN</em>, <em>55</em>(6), 1–21. (<a
href="https://doi.org/10.1007/s10489-025-06320-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Plant Propagation Algorithm (PPA), often exemplified by the Strawberry Algorithm, has demonstrated its effectiveness in solving lower-dimensional optimization problems as a neighborhood search algorithm. While multiple enhancements have been introduced to boost its performance, PPA remains a population-based metaheuristic algorithm. A key element of PPA involves balancing exploration and exploitation, akin to a strawberry plant seeking the best survival strategy. This paper delves into the integration of chaotic numbers and opposition theory in PPA, focusing on how these additions impact its efficiency. The primary research questions revolve around enhancing PPA’s performance and reducing its search space to expedite the algorithm, ultimately leading to faster overall results. Experiments were carried out on three challenging engineering problems: the Pressure Vessel Optimization, the Spring Design Optimization, and the Welded Beam Problem, to fully assess the effectiveness of the improved PPA. The effectiveness of the original PPA, the Chaotic Opposition-Based PPA (COPPA), and several other metaheuristic algorithms were examined in each of these problems. In terms of efficiency and solution quality, the findings consistently demonstrate that COPPA performs better than the traditional PPA and other algorithms. The results indicate that using chaotic-based oppositional processes decreases the search space and enhances performance, resulting in faster and more resource-efficient optimization. The investigation reveals that incorporating chaotic-based oppositional PPA yields improved results while conserving resources and accelerating execution.},
  archive      = {J_APIN},
  author       = {Suny, Alfe and Liza, Maimuna Akter and Fahim, Md. and Reza, Ahmed Wasif and Siddique, Nazmul},
  doi          = {10.1007/s10489-025-06320-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Chaotic opposition-based plant propagation algorithm for engineering problem},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep random walk inspired multi-view graph convolutional
networks for semi-supervised classification. <em>APIN</em>,
<em>55</em>(6), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06322-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies highlight the growing appeal of multi-view learning due to its enhanced generalization. Semi-supervised classification, using few labeled samples to classify the unlabeled majority, is gaining popularity for its time and cost efficiency, particularly with high-dimensional and large-scale multi-view data. Existing graph-based methods for multi-view semi-supervised classification still have potential for improvement in further enhancing classification accuracy. Since deep random walk has demonstrated promising performance across diverse fields and shows potential for semi-supervised classification. This paper proposes a deep random walk inspired multi-view graph convolutional network model for semi-supervised classification tasks that builds signal propagation between connected vertices of the graph based on transfer probabilities. The learned representation matrices from different views are fused by an aggregator to learn appropriate weights, which are then normalized for label prediction. The proposed method partially reduces overfitting, and comprehensive experiments show it delivers impressive performance compared to other state-of-the-art algorithms, with classification accuracy improving by more than 5% on certain test datasets.},
  archive      = {J_APIN},
  author       = {Chen, Zexi and Chen, Weibin and Yao, Jie and Li, Jinbo and Wang, Shiping},
  doi          = {10.1007/s10489-025-06322-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Deep random walk inspired multi-view graph convolutional networks for semi-supervised classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Overview of the application of intelligent optimization
algorithms in multi-attribute group decision making. <em>APIN</em>,
<em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06324-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent Optimization Algorithms (IOAs) have great potential in solving multi-attribute group decision-making (MAGDM) problems. These problems have gradually become a research hotspot in the field of intelligent decision-making due to their advantages of high decision-making accuracy, versatility, and objective evaluation. This study provides a detailed analysis of the challenges in the MAGDM process and evaluates the feasibility of applying IOAs in this context. Specifically, we study the application of IOAs in the MAGDM process and discuss the advantages and limitations across various application scenarios, including the applications of granulating linguistic information, adjusting decision information, optimizing weights, and aggregating decision information. In addition, the development prospects and challenges of IOAs integration with MAGDM are summarized.},
  archive      = {J_APIN},
  author       = {Kang, Kaiying and Xie, Jialiang and Liu, Xiaohui and Wang, Honghui},
  doi          = {10.1007/s10489-025-06324-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Overview of the application of intelligent optimization algorithms in multi-attribute group decision making},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MVSRF: Point cloud semantic segmentation and optimization
method for granular construction objects. <em>APIN</em>, <em>55</em>(6),
1–16. (<a href="https://doi.org/10.1007/s10489-025-06326-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying shapeless granular materials in complex construction scenarios is critical for achieving automation in engineering equipment such as wheel loaders. The challenges of segmenting point clouds for granular materials involve dealing with sparsity, real-time processing requirements, the lack of distinct shape representation, and the issue of different materials sharing similar shapes. This paper proposes MVSRF, a real-time multi-view based point cloud semantic segmentation method incorporating a single-frame re-segmentation component and a multi-frame semantic filter to enhance accuracy and robustness. First, the segmentation system generates a sparse pixel-depth grid map via semantic projection to encapsulate global points and their behaviors, while employing an edge detector to label boundary points around objects. Second, a zero-shot re-segmentation algorithm involving seed extension, novel one-dimensional DBSCAN, Delaunay triangulation, and semantic reassignment corrects mis-segmented points caused by mapping bias. Finally, a lightweight semantic filter is designed to suppress semantic noise during multiple observations. We have built a multi-sensor platform on a wheel loader and collected experimental data to verify the effectiveness of our method. Two optimization components illustrated exceptional performance on the annotated dataset. The MVSRF method possesses strong robustness against external calibration errors, camera pose estimation errors, and inaccurate image segmentation, providing a practical solution for real-time perception of granular materials.},
  archive      = {J_APIN},
  author       = {Zhang, Lunhui and Liu, Guangjun and Lu, Jiaqi and Wang, Changxin},
  doi          = {10.1007/s10489-025-06326-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {MVSRF: Point cloud semantic segmentation and optimization method for granular construction objects},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A 3D-CNN and multi-loss video prediction architecture.
<em>APIN</em>, <em>55</em>(6), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06328-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The achievements of deep learning in the sphere of computer vision have elevated video prediction to a prominent research focus. The prevailing trend in current deep learning endeavors is to pursue advanced optimization of model architectures and enhancement of their performance metrics. The task of video prediction is inherently complex, and most of the algorithm models proposed in the past are also. In this paper, we propose a novel simple video prediction network structure based on three-Dimensional Convolutional Neural Network (3D-CNN) and multi-loss, abbreviated as ML3DVP. Our network model is completely based on 3D-CNN. Compared with Convolutional Long Short-Term Memory (ConvLSTM), Recurrent Neural Network (RNN), Generative Adversarial Network (GAN) and its variants, we start from the most basic network structure to reduce complexity, thereby improving the speed of model prediction. In addition, most models today will encounter quality problems such as insufficient clarity. To solve this problem, we introduced multiple losses for back propagation. Using multiple quality evaluation indicators, Structural Similarity (SSIM) and Peak Signal-to-Noise Ratio (PSNR), as optimization objectives, continuously improves the prediction quality during the training process. The evaluation of model complexity, parameter count, and predictive outcomes across four datasets substantiates that our proposed model has successfully attained the objectives of structural refinement and enhanced performance.},
  archive      = {J_APIN},
  author       = {Qin, Ziru and Dai, Qun},
  doi          = {10.1007/s10489-025-06328-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {A 3D-CNN and multi-loss video prediction architecture},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Concept agent network for zero-base generalized few-shot
learning. <em>APIN</em>, <em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06331-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized Few-Shot Learning (GFSL) aims to recognize novel classes with limited training samples without forgetting knowledge of auxiliary data (base classes). Most current approaches re-engage the base classes after initial training to balance the predictive bias between the base and novel classes. However, re-using the auxiliary data might not always be possible due to privacy or ethical constraints. Consequently, the zero-base GFSL paradigm emerges, where models trained on the base classes are directly fine-tuned on the novel classes without revisiting the auxiliary data, avoiding the re-balancing of prediction biases. We believe that solving this paradigm relies on a critical yet often overlooked issue: feature overlap between the base and novel classes in the embedding space. To tackle this issue, we propose the Concept Agent Network, a novel framework that interprets visual features as affinity features, thereby effectively diminishing feature overlap by aggregating feature embeddings of the novel classes according to their similarity with the base classes. Additionally, we present the Concept Catena Generator, which creates multiple concepts per base class, improving understanding of the feature distribution of the base classes and clarifying the relationships between the base and novel concepts. To prevent the catastrophic forgetting of the base classes when adapting to the novel ones, we propose an Active Training Regularization strategy, promoting the preservation of base class knowledge. Extensive experimental results on two benchmarks, mini-ImageNet and tiered-ImageNet, have demonstrated the effectiveness of our framework. The potential utility of our framework spans several real-world applications, including autonomous driving, medical image analysis, and real-time surveillance, where the ability to rapidly learn from a few examples without forgetting previously acquired knowledge is critical.},
  archive      = {J_APIN},
  author       = {Wang, Xuan and Ji, Zhong and Liu, Xiyao and Pang, Yanwei and Li, Xuelong},
  doi          = {10.1007/s10489-025-06331-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Concept agent network for zero-base generalized few-shot learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DAAR: Dual attention cooperative adaptive pruning rate by
data-driven for filter pruning. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06332-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model compression can address the limitations of deep learning in resource-constrained situations by reducing the computational and storage requirements of the model. Structured pruning has emerged as an important compression technique because of its operational flexibility and effectiveness. However, the existing structural pruning methods have two limitations: 1) They use a single measurement to identify the importance of the filters in all the layers, resulting in a loss of spatial information in the shallow layers. 2) The pruning rate is highly dependent on manual interference, which is highly subjective. In this paper, a filter pruning method called dual attention cooperative adaptive pruning rate (DAAR) is proposed. Specifically, a dual attention module that combines spatial attention and channel attention is proposed to measure the effectiveness of the filters. Spatial attention is used in the shallow layers, and channel attention is used in the deep layers. This allows the filter measurements to consider spatial information effectively. An adaptive pruning rate adjustment strategy is also used to eliminate manual subjectivity, achieving precision pruning of each convolutional layer. The experimental results on various datasets and networks demonstrate that the DAAR method achieves improved model performance after pruning. For example, in the CIFAR10 dataset, the precision increases from 93.5% to 93.75% after removing the floating point operations (FLOPs) of 84.1%, outperforming the state-of-the-art pruning methods.},
  archive      = {J_APIN},
  author       = {Lian, Suyun and Zhao, Yang and Pei, Jihong},
  doi          = {10.1007/s10489-025-06332-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {DAAR: Dual attention cooperative adaptive pruning rate by data-driven for filter pruning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ED-END: Robust watermarking technology based on deep
coupling of feature extractors. <em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06333-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning-based watermarking methods have been developed to address the shortcomings of traditional watermarking algorithms. Some methods adopt an end-to-end framework to train the watermarking model, enabling excellent watermark embedding and extraction. However, the visual quality and robustness of these approaches remain insufficient, especially ignoring the adequacy of image feature extraction and the correlation between network modules. We propose a feature extractor and decoder deep coupled watermark network, which can help generate high-robust watermarked images. Specifically, a down-sampling feature extractor is employed to supplement image features post-decoder, the extracted features are synchronously provided to the encoder for watermark embedding. Additionally, skip-connection is introduced to share each layer feature information of the decoder with the encoder, thereby improving the correlation between network modules. Comprehensive experimental results show that the proposed scheme can achieve high robustness against screen-shooting and paper printing processes while maintaining the visual quality of the watermarked image.},
  archive      = {J_APIN},
  author       = {Li, Jun and Fang, Yixiang and Zhao, Yi and Xu, Kangkang and Wang, Junxiang},
  doi          = {10.1007/s10489-025-06333-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {ED-END: Robust watermarking technology based on deep coupling of feature extractors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Control of traffic network signals based on deep
deterministic policy gradients. <em>APIN</em>, <em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-024-06208-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The centralized control of traffic signals is a challenging problem due to the high randomness and complexity of traffic flow on urban road networks and the interaction between intersections. Centralized control leads to high spatial dimensionality of joint actions for traffic road network signal control. However, the decisive action output can solve the problem of “dimensional explosion” caused by joint actions. In this paper, we propose a deep deterministic policy gradient-based algorithm for centralized control of urban traffic road network signals. We simplify the traffic signal control to a four-phase green signal ratio, and the deep deterministic policy gradient-based algorithm deterministically outputs the control signal for each intersection based on the information of the whole traffic network, thus avoiding the problem of “dimensional explosion”. In particular, a new normalization function is proposed to generate the green rate of traffic signals and constrain it to a range of maximum and minimum sustained green time by linear transformation, which makes the generated traffic signals more realistic. Our proposed algorithm is shown to be optimal and robust compared to Deep Q-Network(DQN) based and fixed time control for 7-hour SUMO simulation of a single-peak traffic network with three intersections.},
  archive      = {J_APIN},
  author       = {Hu, Huifeng and Lin, Shu and Wang, Ping and Xu, Jungang},
  doi          = {10.1007/s10489-024-06208-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Control of traffic network signals based on deep deterministic policy gradients},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Loop closure detection based on image feature matching and
motion trajectory similarity for mobile robot. <em>APIN</em>,
<em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-024-05874-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In visual simultaneous localization and mapping (SLAM), loop closure detection plays an irreplaceable role in eliminating cumulative errors, optimizing robot poses, and ensuring map consistency. Most loop closure detection algorithms adopt single feature or feature fusion to detect loop closures, which makes it difficult to ensure accuracy in environments with changing lighting or high-similarity scenes. In this work, image features and motion trajectories are combined to improve the effectiveness of loop closure detection via a staged detection method. First, histogram equalization is used to reduce the algorithm’s sensitivity to lighting. Then, LBP features are used to divide keyframes into multiple sequences, and the sequence where the loop closure candidate frame is located is determined according to the image feature matching results. Then, the most matched keyframe is searched in the sequence as a candidate loop closure. Finally, the true loop closure is confirmed by comparing the motion trajectory similarity to improve the algorithm’s adaptability to high-similarity scenes. The experimental results show that in different application scenarios, the proposed method can achieve good results in terms of precision, recall, area under the curve (AUC), and recall when the precision is 100%.},
  archive      = {J_APIN},
  author       = {Hao, Weilong and Wang, Peng and Ni, Cui and Huangfu, Wenjun and Liu, Zhu and Qi, Kaiyuan},
  doi          = {10.1007/s10489-024-05874-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Loop closure detection based on image feature matching and motion trajectory similarity for mobile robot},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous multi-modal graph network for arterial travel
time prediction. <em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-024-05895-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Travel time prediction has important influence on the overall control of urban Intelligent Transportation Systems (ITS). Urban arterial networks are typically composed of links and intersections, where each link or intersection can be regarded as a spatial node within the network. However, existing researches predominantly focus on modeling spatial nodes in the link modality to predict travel times in urban arterial networks, neglecting the potential correlations among heterogeneous modal nodes. To overcome these limitations, we propose a Heterogeneous Multi-Modal Graph Neural Network (HMGNN) specifically tailored for travel time prediction in arterial networks. Specifically, we innovatively construct spatial correlation graphs that capture the unique traffic characteristics of intersection modal nodes. Furthermore, we design a cross-modal graph generator that captures the latent spatiotemporal features between spatial nodes of distinct modalities, resulting in the generation of heterogeneous modal graphs. Finally, our proposed HMGNN model incorporates tailored network structures for graphs of varying complexities, enabling targeted mining of their inherent information to derive the final prediction results. Extensive experiments conducted using real-world traffic data from Zhangzhou, China, demonstrate that our HMGNN model achieves significant improvements in prediction accuracy.},
  archive      = {J_APIN},
  author       = {Fang, Jie and He, Hangyu and Xu, Mengyun and Wu, Xiongwei},
  doi          = {10.1007/s10489-024-05895-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Heterogeneous multi-modal graph network for arterial travel time prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel consensus reaching approach for large-scale
multi-attribute emergency group decision-making under social network
clustering based on graph attention mechanism. <em>APIN</em>,
<em>55</em>(6), 1–28. (<a
href="https://doi.org/10.1007/s10489-024-05992-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergency decision-making problem is common in our daily life. To solve this kind of problem, a group of decision-makers (DMs) are usually invited to make a decision in a limited time. Since multiple attributes are usually considered, it’s called large-scale multi-attribute emergency group decision-making (LS-MA-EGDM). There are two issues in the general research of LS-MA-EGDM. First, clustering and consensus-reaching process (CRP) should consider the influence of DMs’ intrinsic features. Second, consensus adjustment within and among sub-clusters ought to be fast to prevent multi-round iteration. Accordingly, (1) we introduce graph attention mechanism to calculate the attention coefficients between DM pair’s intrinsic features. The multi-head graph attention coefficient based on social network analysis (SNA) is proposed, which is then combined with opinion similarity to construct a social network clustering method. (2) The Einstein product operator is introduced to propagate the attention coefficients and yield DMs’ weights, which is then incorporated in the subsequent adjustment allocation. (3) Identification rules are provided based on four consensus types in the CRP. The one-iteration personalized adjustment strategies corresponding to different consensus types are then proposed. (4) Evidential reasoning (ER) algorithm is finally utilized to aggregate the preferences of clusters after consensus is reaching. The proposed method is further applied to a chemical plant explosion in Texas to illustrate its effectiveness and validity in dealing with emergencies.},
  archive      = {J_APIN},
  author       = {Zhou, Mi and Zhang, Ying and Fan, Xin-Yu and Wu, Ting and Cheng, Ba-Yi and Wu, Jian},
  doi          = {10.1007/s10489-024-05992-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-28},
  shortjournal = {Appl. Intell.},
  title        = {A novel consensus reaching approach for large-scale multi-attribute emergency group decision-making under social network clustering based on graph attention mechanism},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised learning for intelligent disease diagnosis
using audio signals: Beyond copd to a spectrum of diseases.
<em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-024-06028-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the widespread prevalence and significant patient base of COPD (Chronic Obstructive Pulmonary Disease), the development of simple and rapid diagnostic methods has emerged as a key research focus. Through pathological studies, the medical community has identified the potential of cough sounds for diagnosing COPD, sparking interest in leveraging deep learning to analyze various disease-related sounds, including those associated with COVID-19 and cardiac conditions, etc. Yet, research specifically targeting COPD remains scarce, primarily due to two challenges: traditional models trained on small medical datasets often fall short of expectations due to stringent data privacy and collection requirements in healthcare; and the scarcity of publicly accessible COPD datasets, particularly those that could obviate the need for medical equipment. Addressing these challenges, our paper introduces a novel dataset of smartphone-recorded cough sounds, termed the CC (COPD-Cough) dataset. It comprises 221 recordings from COPD patients and 632 from healthy individuals, marking the first dataset explicitly curated for COPD cough sound analysis. The dataset, endorsed by clinical professionals and collected independently of medical devices, promises to propel advancements in straightforward COPD diagnostics. Furthermore, we propose a self-supervised learning model enhanced by unique data augmentation techniques and an efficient sound feature extractor, demonstrating superior performance across three distinct disease datasets and achieving state-of-the-art results. Comprehensive ablation studies affirm our model’s efficacy, while sensitivity analyses optimize its applicability to various tasks. For further engagement, the framework’s source code and dataset are available at https://github.com/auto-chao/COPD_Diagnosis and https://zenodo.org/records/10209837 , respectively.},
  archive      = {J_APIN},
  author       = {Sun, Wenchao and Wu, Gang and Ming, Ming and Zhang, Jiameng and Shi, Chun and Qin, Linlin},
  doi          = {10.1007/s10489-024-06028-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Self-supervised learning for intelligent disease diagnosis using audio signals: Beyond copd to a spectrum of diseases},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A BERT-based review helpfulness prediction model utilizing
consistency of ratings and texts. <em>APIN</em>, <em>55</em>(6), 1–14.
(<a href="https://doi.org/10.1007/s10489-024-06100-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting review helpfulness (RH) to ensure that consumers make effective purchasing decisions is a significant area of study. Many scholars have attempted to develop accurate review helpfulness prediction (RHP) methodologies. However, most previous studies have mainly focused on predictions using product review texts, and few studies have used product satisfaction as indicated by star ratings, particularly the consistency between review texts and star ratings. This study proposes a novel model called BHelP-CoRT (Bidirectional Encoder Representations from Transformers based RHP model utilizing consistency of ratings and texts) to predict RH. The proposed model consists of a review text encoder, star rating encoder, and text-rating interaction. The review text encoder was developed by applying the BERT model to extract contextual semantic features embedded in review texts. The star rating encoder was designed to embed star ratings into feature vectors. The text-rating interaction was constructed by applying an attention mechanism to extract the text-rating interaction and introduce consistency into the RHP tasks. This study conducted extensive experiments to demonstrate the effectiveness of the proposed model from multiple perspectives using real-world online reviews collected from Amazon. The experimental results show that the proposed model outperforms the state-of-the-art models, indicating that it can improve the RHP performance. Specifically, this effectiveness is reflected in the processing of reviews containing inconsistent information. This study supports the marketing efforts of the e-commerce industry by providing an RHP service to address consumer information overload.},
  archive      = {J_APIN},
  author       = {Li, Xinzhe and Li, Qinglong and Ryu, Dongyeop and Kim, Jaekyeong},
  doi          = {10.1007/s10489-024-06100-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {A BERT-based review helpfulness prediction model utilizing consistency of ratings and texts},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCSNet: A novel transformer-CNN fusion architecture for
enhanced segmentation and classification on high-resolution
semiconductor micro-scale defects. <em>APIN</em>, <em>55</em>(6), 1–18.
(<a href="https://doi.org/10.1007/s10489-024-06122-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of semiconductor integrated circuit manufacturing, accurately identifying the root causes of defects is critical for enhancing yield rates. Traditionally, this analytical process has been both time-intensive and challenged by inaccuracies, primarily due to the intricate and varied morphology of wafer defects. While convolutional neural networks (CNNs) with encoder-decoder architectures have made significant strides in the segmentation of defects, they inherently struggle to capture distant interactions and achieve high performance in classification tasks. Conversely, recent advancements in transformers have showcased their proficiency in learning global image dependencies. However, transformers often lack the specific graphical priors and the adaptability typically associated with CNNs. Addressing these limitations, we introduce SCSNet, an innovative architecture that merges the strengths of transformers and CNNs. This fusion network is designed to enhance both segmentation and classification of scanning electron microscopy (SEM) images of wafer defects. SCSNet incorporates a conventional encoder-decoder framework, supplemented by shape flow branches and multi-cross-attention (MCF) modules within a skip connection architecture. Rigorous experimentation on a dataset of 4425 high-resolution wafer defects, sourced from our operational wafer fabrication facility, demonstrates SCSNet’s superior performance. Notably, SCSNet surpasses existing advanced CNNs, transformers, and their hybrid counterparts, achieving a classification accuracy of 97.62% and a segmentation Intersection over Union (IoU) of 84.09%. Currently implemented on our local server for engineering use, SCSNet represents a major advancement in semiconductor manufacturing, offering a more precise and efficient tool for wafer defect analysis.},
  archive      = {J_APIN},
  author       = {Luo, Yuening and Mei, Zhouzhouzhou and Qiao, Yibo and Chen, Yining},
  doi          = {10.1007/s10489-024-06122-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {SCSNet: A novel transformer-CNN fusion architecture for enhanced segmentation and classification on high-resolution semiconductor micro-scale defects},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FreqFaceNet: An enhanced transformer architecture with
dual-order frequency attention for deepfake detection. <em>APIN</em>,
<em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-024-06168-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of AI-based image synthesis tools and techniques, Deepfakes have become a serious problem as they pose a massive threat to one’s information security and personal privacy. Several architectures have been proposed to achieve robust Deep Fake detection. However, these methods suffer a drastic drop in performance if the images are visually degraded or have low resolution. To resolve these two issues, a novel FreqFaceNet model has been proposed that employs two novel attentions namely, Wavelet Attention and Fourier Attention, for extracting important frequency-based features from low-resolution images. The extraction of frequency-based features ensures minimal interference of noise due to image compression or low resolution. The proposed model excels on two public benchmark datasets—the DFDC and CelebDF. On the DFDC dataset, FreqFaceNet achieves 98.041% accuracy, an AUC value of 99.748, and a Mathews Correlation Coefficient (MCC) value of 93.857, while on the CelebDF dataset, it obtains an accuracy of 98.325%, an AUC value of 99.81, and an MCC value of 92.819. Qualitative analysis of the proposed model indicates strong classification capabilities. An ablation study has also been conducted to verify the complementary contributions of both Wavelet and Fourier Attention mechanisms.},
  archive      = {J_APIN},
  author       = {Gupta, Varun and Srivastava, Vaibhav and Yadav, Ankit and Vishwakarma, Dinesh Kumar and Kumar, Narendra},
  doi          = {10.1007/s10489-024-06168-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {FreqFaceNet: An enhanced transformer architecture with dual-order frequency attention for deepfake detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). VAEneu: A new avenue for VAE application on probabilistic
forecasting. <em>APIN</em>, <em>55</em>(6), 1–23. (<a
href="https://doi.org/10.1007/s10489-024-06203-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces VAEneu, a novel autoregressive method for multistep ahead univariate probabilistic time series forecasting, designed to address the challenges of generating sharp and well-calibrated probabilistic forecasts without assuming a specific parametric form for the predictive distribution. VAEneu leverages the Conditional VAE framework and optimizes the likelihood of the predictive distribution using the Continuous Ranked Probability Score (CRPS), a strictly proper scoring rule, as the loss function. This approach enables the model to learn flexible, sharp, and well-calibrated predictive distributions without the need for a tractable likelihood function. In a comprehensive empirical study, VAEneu is rigorously benchmarked against 12 baseline models across 12 datasets, demonstrating superior performance in both forecasting accuracy and uncertainty quantification. VAEneu provides a valuable tool for quantifying future uncertainties, and our extensive empirical study lays the foundation for future comparative studies for univariate multistep ahead probabilistic forecasting.},
  archive      = {J_APIN},
  author       = {Koochali, Alireza and Tahaei, Ensiye and Dengel, Andreas and Ahmed, Sheraz},
  doi          = {10.1007/s10489-024-06203-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {VAEneu: A new avenue for VAE application on probabilistic forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: A diverse/converged individual competition
algorithm for computationally expensive many-objective optimization.
<em>APIN</em>, <em>55</em>(6), 1. (<a
href="https://doi.org/10.1007/s10489-024-06225-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Lin, Jie and Zhang, Sheng Xin and Zheng, Shao Yong},
  doi          = {10.1007/s10489-024-06225-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: A diverse/converged individual competition algorithm for computationally expensive many-objective optimization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IPAttack: Imperceptible adversarial patch to attack object
detectors. <em>APIN</em>, <em>55</em>(6), 1–12. (<a
href="https://doi.org/10.1007/s10489-025-06246-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread application of deep learning, general object detectors have become increasingly popular in our daily lives. Extensive research, however, has shown that existing detectors are vulnerable to patch-based adversarial attacks, which fool such detectors by crafting adversarial patches. Although existing methods have made significant progress in terms of attack success rate, they still suffer from a highly perceptible problem, making it easy for humans to distinguish these evil examples. To address this issue, in this paper, we propose a novel spatial transform-based end-to-end patch attack method, called IPAttack, to synthesize imperceptible adversarial patches. Our approach estimates a flow field $$\varvec{f}$$ to formulate adversarial examples rather than introduce small $$L_p$$ -norm constrained external perturbations. Besides, to improve the imperceptibility and maintain a high attack performance, we propose the Object Detector Class Activation Map (OD-CAM) for objectors to extract the most interesting region, which will be applied to spatial transform to generate the final adversarial examples. Extensive experiments demonstrate that the proposed IPAttack can generate patch-wised adversarial examples with high imperceptibility while achieving the best attack performance compared to existing methods.},
  archive      = {J_APIN},
  author       = {Wen, Yongming and Si, Peiyuan and Zhou, Wei and Zhao, Zongheng and Yi, Chao and Liu, Renyang},
  doi          = {10.1007/s10489-025-06246-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {IPAttack: Imperceptible adversarial patch to attack object detectors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FinCaKG-onto: The financial expertise depiction via
causality knowledge graph and domain ontology. <em>APIN</em>,
<em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06247-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality stands as an essential relation for elucidating the reasoning behind given contents. However, current causality knowledge graphs fall short in effectively illustrating the inner logic in a specific domain, i.e. finance. To generate such a functional knowledge graph, we propose the multi-faceted approach encompassing causality detection module, entity linking module, and causality alignment module to automatically construct FinCaKG-Onto with the guidance of expert financial ontology - FIBO. In this paper, we outline the resources and methodology employed for FinCaKG-Onto construction, present the schema of FinCaKG-Onto, and share the final knowledge graph FinCaKG-Onto. Through various user scenarios, we demonstrate that FinCaKG-Onto not only captures nuanced domain expertise but also explicitly unveils the causal logic for any anchor terms. To facilitate your convenience of future use, a check table is conducted as well to showcase the quality of FinCaKG-Onto. The related resources are available in the webpage&lt; https://www.ai.iee.e.titech.ac.jp/FinCaKG-Onto/ &gt;.},
  archive      = {J_APIN},
  author       = {Xu, Ziwei and Ichise, Ryutaro},
  doi          = {10.1007/s10489-025-06247-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {FinCaKG-onto: The financial expertise depiction via causality knowledge graph and domain ontology},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-guided classification and regression surrogates
co-assisted multi-objective soft subspace clustering algorithm.
<em>APIN</em>, <em>55</em>(6), 1–29. (<a
href="https://doi.org/10.1007/s10489-025-06266-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficiency of multi-objective soft subspace clustering algorithms (MSSCAs) can be low when applied to large-scale datasets. This inefficiency arises because the multi-objective evolutionary algorithms (MOEAs) utilized in MSSCAs often require a large number of soft subspace clustering objective function evaluations due to their population-based nature. Moreover, relying solely on negative Shannon entropy to constrain feature weights is inadequate for soft subspace clustering algorithms. To address these issues, a knowledge-guided classification and regression surrogates co-assisted multi-objective soft subspace clustering (KCRS-MOSSC) algorithm is presented. First, an inter-cluster feature weight dissimilarity function is designed to further constrain the feature weights. Furthermore, a novel surrogate-based optimization framework called the knowledge-guided classification and regression surrogates co-assisted multi-objective evolutionary framework (KCRS-MOEF) is proposed to efficiently optimize the proposed inter-cluster feature weight dissimilarity function, intra-cluster compactness function, inter-cluster separation function, and negative Shannon entropy function. In KCRS-MOEF, a classification decision tree is utilized as the classification surrogate model to help generate a set of promising offspring, while a radial basis function (RBF) model is employed as the regression surrogate model to assist in the infill criterion by predicting the objective function values of the offspring. Furthermore, to fully leverage the knowledge of the evolutionary process, an infill criterion guided by dynamic process knowledge of elite individuals is designed to enhance the convergence and diversity of the population. Finally, a clustering ensemble strategy based on knee point guidance is proposed to generate a final solution from a set of non-dominated individuals. KCRS-MOEF outperforms state-of-the-art counterparts in terms of convergence, diversity, and time efficiency, as demonstrated in four experiments conducted on the DTLZ benchmark. Furthermore, experiments on various datasets show that the clustering performance and time efficiency of KCRS-MOSSC exceed those of comparison algorithms.},
  archive      = {J_APIN},
  author       = {Zhao, Feng and Li, Lu and Liu, Hanqiang},
  doi          = {10.1007/s10489-025-06266-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Knowledge-guided classification and regression surrogates co-assisted multi-objective soft subspace clustering algorithm},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reusability of bayesian networks case studies: A survey.
<em>APIN</em>, <em>55</em>(6), 1–25. (<a
href="https://doi.org/10.1007/s10489-025-06289-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Networks (BNs) are probabilistic graphical models used to represent variables and their conditional dependencies, making them highly valuable in a wide range of fields, such as radiology, agriculture, neuroscience, construction management, medicine, and engineering systems, among many others. Despite their widespread application, the reusability of BNs presented in papers that describe their application to real-world tasks has not been thoroughly examined. In this paper, we perform a structured survey on the reusability of BNs using the PRISMA methodology, analyzing 147 papers from various domains. Our results indicate that only 18% of the papers provide sufficient information to enable the reusability of the described BNs. This creates significant challenges for other researchers attempting to reuse these models, especially since many BNs are developed using expert knowledge elicitation. Additionally, direct requests to authors for reusable BNs yielded positive results in only 12% of cases. These findings underscore the importance of improving reusability and reproducibility practices within the BN research community, a need that is equally relevant across the broader field of Artificial Intelligence.},
  archive      = {J_APIN},
  author       = {Babakov, Nikolay and Sivaprasad, Adarsa and Reiter, Ehud and Bugarín-Diz, Alberto},
  doi          = {10.1007/s10489-025-06289-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Reusability of bayesian networks case studies: A survey},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NPGCL: Neighbor enhancement and embedding perturbation with
graph contrastive learning for recommendation. <em>APIN</em>,
<em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06301-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNNs) have significantly advanced recommendation systems by modeling user-item interactions through bipartite graphs. However, real-world user-item interaction data are often sparse and noisy. Traditional bipartite graph modeling fails to capture higher-order relationships between users and items, limiting the ability of GNNs to learn high-quality node embeddings. While existing graph contrastive learning methods address data sparsity by partitioning nodes into positive and negative pairs, they also neglect these higher-order relationships, thus limiting the effectiveness of contrastive learning in recommendation systems. Furthermore, due to the inherent limitations of graph convolution, noise can propagate and amplify with increasing layers in deep graph convolutional networks. To address these challenges, Neighbor Enhancement and Embedding Perturbation for Graph Contrastive Learning (NPGCL) is proposed, which introduces two key modules - Relational Neighbor Enhancement Module and Collaborative Neighbor Enhancement Module - to capture higher-order relationships between homogeneous nodes and calculate interaction importance for noise suppression. Moreover, NPGCL employs an Embedding Perturbation Strategy and applies inter-layer contrastive learning to mitigate the noise impact caused by multi-layer graph convolutions. Experimental results demonstrate that NPGCL significantly improves performance across four publicly available datasets, with a notable enhancement in robustness, especially in noisy environments. Specifically, NPGCL achieves performance improvements of 1.77%-3.34% and 3.87%-9.07% on the Gowalla and Amazon-books datasets, respectively. In noisy datasets, NPGCL improves Recall@20 by 4.98% and 10.92%, respectively.},
  archive      = {J_APIN},
  author       = {Wu, Xing and Wang, Haodong and Yao, Junfeng and Qian, Quan and Song, Jun},
  doi          = {10.1007/s10489-025-06301-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {NPGCL: Neighbor enhancement and embedding perturbation with graph contrastive learning for recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Composite gaussian processes flows for learning
discontinuous multimodal policies. <em>APIN</em>, <em>55</em>(6), 1–20.
(<a href="https://doi.org/10.1007/s10489-025-06302-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning control policies for real-world robotic tasks often involve challenges such as multimodality, local discontinuities, and the need for computational efficiency. These challenges arise from the complexity of robotic environments, where multiple solutions may coexist. To address these issues, we propose Composite Gaussian Processes Flows (CGP-Flows), a novel semi-parametric model for robotic policy. CGP-Flows integrate Overlapping Mixtures of Gaussian Processes (OMGPs) with the Continuous Normalizing Flows (CNFs), enabling them to model complex policies addressing multimodality and local discontinuities. This hybrid approach retains the computational efficiency of OMGPs while incorporating the flexibility of CNFs. Experiments conducted in both simulated and real-world robotic tasks demonstrate that CGP-flows significantly improve performance in modeling control policies. In a simulation task, we confirmed that CGP-Flows had a higher success rate compared to the baseline method, and the success rate of GCP-Flow was significantly different from the success rate of other baselines in chi-square tests.},
  archive      = {J_APIN},
  author       = {Wang, Shu-yuan and Sasaki, Hikaru and Matsubara, Takamitsu},
  doi          = {10.1007/s10489-025-06302-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Composite gaussian processes flows for learning discontinuous multimodal policies},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Design and analysis of a variable-parameter noise-tolerant
ZNN for solving time-variant nonlinear equations and applications.
<em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06304-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solvers considering time-varying parameters are more suitable for addressing a variety of time-varying problems, whereas traditional fixed-parameter neural networks are somewhat insufficient for efficiently and quickly solving these problems. Many existing zeroing neural networks ensure rapid convergence using the infinite-valued AFs. For solving time-varying nonlinear equations, this paper proposes a finitely-activated variable parameter noise tolerant zeroing neural network (VPNTZNN), applied to trajectory tracking of redundant robotic arms. The designed variable parameters are error-dependent, enabling adaptive adjustment to optimal values as errors fluctuate, thereby ensuring faster convergence of the proposed VPNTZNN. And the constructed variable parameters and activation functions (AFs) do not escalate infinitely over time. Affected by the above variable parameters, the proposed finitely-activated VPNTZNN achieves rapid finite-time convergence with strong noise suppression. Simulation results validate the effectiveness of our method in solving time-variant nonlinear equations and in trajectory tracking of redundant manipulators. Moreover, this approach employs a finite-valued activation function to design a variable-parameter neural network, thereby avoiding the difficulties of practical implementation.},
  archive      = {J_APIN},
  author       = {Zhang, Yu and Wang, Liming and Zhong, Guomin},
  doi          = {10.1007/s10489-025-06304-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Design and analysis of a variable-parameter noise-tolerant ZNN for solving time-variant nonlinear equations and applications},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). E-GCDT: Advanced reinforcement learning with GAN-enhanced
data for continuous excavation system. <em>APIN</em>, <em>55</em>(6),
1–22. (<a href="https://doi.org/10.1007/s10489-025-06308-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automation of excavator operations entails the development and implementation of systems that allow excavators to execute tasks autonomously, thereby significantly reducing the need for human intervention. By integrating advanced sensors and artificial intelligence algorithms, these systems aim to increase operational efficiency, safety, and precision in construction and mining. However, previously developed methods have two weaknesses. First, existing automated excavator systems struggle with adapting to diverse and complex environmental conditions and with precision in control mechanisms. Second, operating an excavator involves multiple, repeated decisions that need to be modeled, planned, and executed in real time. However, there is a significant lack of comprehensive datasets that reflect real-world excavation operations to support this process. In this paper, we present an innovative system named E-GCDT. This system integrates the DoppelGANger module, which generates action time series by emulating human-mined trajectories through a generative adversarial mechanism and replays them in a simulation environment, ultimately expanding the dataset to 155 continuous mining trajectories. Furthermore, E-GCDT integrates terrain features into the decision-making process with the contrastive language-image pre-training model (CLIP), in which the decision transformer optimizes trajectory planning for efficient and accurate continuous excavation tasks. E-GCDT uniquely integrates advanced data augmentation and terrain awareness, developing an advanced Markov decision framework (DT) for continuous excavation tasks. The experimental results of a bulldozer verify that the efficiency of E-GCDT surpasses human efficiency. This system sets a new standard for continuous autonomous mining, and this study provides a new perspective on the application of reinforcement learning in industrial environments.},
  archive      = {J_APIN},
  author       = {Zhao, Qianyou and Gao, Le and Wu, Duidi and Lei, Yihao and Wang, Lingyu and Qi, Jin and Hu, Jie},
  doi          = {10.1007/s10489-025-06308-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {E-GCDT: Advanced reinforcement learning with GAN-enhanced data for continuous excavation system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). WLKA-RVS: A retinal vessel segmentation method using
weighted large kernel attention. <em>APIN</em>, <em>55</em>(6), 1–12.
(<a href="https://doi.org/10.1007/s10489-025-06309-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel segmentation is an important task in medical image analysis and has a wide range of applications in the diagnosis and treatment of retinal diseases. However, existing segmentation methods still have some shortcomings in accurately segmenting thin vessels. Based on this observation, we propose a Retinal Vessel Segmentation method based on Weighted Large Kernel Attention (WLKA-RVS), which aims to improve the accuracy of retinal vessel segmentation to better assist physicians in clinical diagnosis and treatment. Our method consists of an encoder and a decoder. In the encoder, a convolution stem first reduces the dimension of the input image. Then, feature extraction is performed by four stages of Swin Transformer modules, each stage with a downsampling layer. In the decoder, there are four different stages of Weighted Large Kernel Attention Block (WLKAB) corresponding to the Swin Transformer modules in the encoder. Then WLKA-RVS applies the Patch Expanding module to achieve upsampling. Finally, a linear layer outputs the final results. We have performed extensive experiments comparing several recent advanced models on three public datasets. WLKA-RVS led by 0.32%, 1.24%, and 0.71% in the mAcc metric, respectively. At the same time, the inference speed of WLKA-RVS met the real-time requirements for medical diagnosis. A series of experiments demonstrated the efficiency, robustness, and applicability of WLKA-RVS.},
  archive      = {J_APIN},
  author       = {Li, Jiayao and Zeng, Min and Wu, Chenxi and Cheng, Qianxiang and Guo, Qiuyan and Li, Song},
  doi          = {10.1007/s10489-025-06309-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {WLKA-RVS: A retinal vessel segmentation method using weighted large kernel attention},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TADST: Reconstruction with spatio-temporal feature fusion
for deviation-based time series anomaly detection. <em>APIN</em>,
<em>55</em>(6), 1–23. (<a
href="https://doi.org/10.1007/s10489-025-06310-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is crucial in time series analysis for identifying abnormal events. To address the limitations of traditional methods in integrating spatiotemporal correlations and modeling normal patterns, we propose a Time Series Anomaly Detection Model Based on Spatio-Temporal Feature Fusion (TADST). First, the Spatio-Temporal Feature Fusion Network (STF) combines temporal convolutional networks and graph attention influence networks to capture temporal dynamic dependencies and attribute correlations respectively, facilitating joint spatiotemporal feature modeling. Then, the Time Series Reconstruction Network (TSR) employs a multi-layer encoder-decoder architecture to learn the normal sample distribution and amplify discrepancies between reconstructed and anomalous data. Finally, the Anomaly Detection Mechanism (ADM) identifies anomalies by fitting the tail distribution of reconstruction deviations. When the anomaly score exceeds a predefined threshold, the mechanism updates the parameters of the Generalized Pareto Distribution, keeping the detection criteria adaptive. Experiments demonstrate that the proposed TADST achieves state-of-the-art results on five publicly available datasets.},
  archive      = {J_APIN},
  author       = {Yang, Bin and Ma, Tinghuai and Rong, Huan and Huang, Xuejian and Wang, Yubo and Zhao, Bowen and Wang, Chaoming},
  doi          = {10.1007/s10489-025-06310-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {TADST: Reconstruction with spatio-temporal feature fusion for deviation-based time series anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph regularized independent latent low-rank representation
for image clustering. <em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06312-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank representation (LRR) has been proved to be effective in exploring low-dimensional subspace structure embedded in the observations. However, existing LRR algorithms often pay no attention to data redundancy, easily leading to performance decay. In addition, the LRR characterizes data global inter-connections, from which some latent similarity features should be further learned and exploited to improve the performance of clustering. Therefore, a novel method termed Graph Regularized Independent Latent Low-Rank Representation (GRI-LLRR) is presented to address the above issues. As we know, Hilbert–Schmidt Independence Criterion (HSIC) measures the independence between two distributions. In the proposed method, it is introduced and developed to another novel graph regularization independent term to remove the uncorrelation between vectors and to preserve the data local geometry. With other constraints, including the sparse, nonnegative and symmetric, the LRR is obtained from the observations. Then, the proposed method further learns the cosine features as latent representation of the LRR for final clustering. Massive experiments have been conducted on eight benchmark data sets. Experimental results show that the proposed GRI-LLRR outperforms some state-of-the-art (SOTA) approaches with improvements of 2.24%, 2.73%, and 2.65% on average for CCA, NMI, and Purity, respectively.},
  archive      = {J_APIN},
  author       = {Li, Bo and Pan, Lin-Feng},
  doi          = {10.1007/s10489-025-06312-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Graph regularized independent latent low-rank representation for image clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A code completion approach combining pointer network and
transformer-XL network. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06315-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Code completion is a crucial aspect of contemporary integrated development environments (IDEs), as it not only streamlines the software development process but also bolsters the quality of software products. By leveraging large-scale codes to learn the probability distribution among code token units, deep learning methods have demonstrated significant improvements in the accuracy of token unit recommendations. However, the efficacy of code completion employing deep learning is often compromised by information loss. To mitigate this issue, we introduce a novel code language model that incorporates both the pointer network and the Transformer-XL architecture to surpass the constraints of current approaches in code completion. Our proposed model accepts as input the original code snippet and its corresponding abstract syntax tree (AST), utilizing the Transformer-XL model as the foundational architecture for capturing long-term dependencies. Additionally, we incorporate a pointer network as an adjunct component to forecast Out-of-Vocabulary (OoV) words. Our approach has been rigorously evaluated on the authentic PY150 and JS150 datasets. The comparative experimental results demonstrate the effectiveness of our model in improving the accuracy of the code completion task at the token unit level.},
  archive      = {J_APIN},
  author       = {Zhang, Xiangping and Liu, Jianxun and Long, Teng and Hu, Haize},
  doi          = {10.1007/s10489-025-06315-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A code completion approach combining pointer network and transformer-XL network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GenKP: Generative knowledge prompts for enhancing large
language models. <em>APIN</em>, <em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06318-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) have demonstrated extensive capabilities across various natural language processing (NLP) tasks. Knowledge graphs (KGs) harbor vast amounts of facts, furnishing external knowledge for language models. The structured knowledge extracted from KGs must undergo conversion into sentences to align with the input format required by LLMs. Previous research has commonly utilized methods such as triple conversion and template-based conversion. However, sentences converted using existing methods frequently encounter issues such as semantic incoherence, ambiguity, and unnaturalness, which distort the original intent, and deviate the sentences from the facts. Meanwhile, despite the improvement that knowledge-enhanced pre-training and prompt-tuning methods have achieved in small-scale models, they are difficult to implement for LLMs in the absence of computational resources. The advanced comprehension of LLMs facilitates in-context learning (ICL), thereby enhancing their performance without the need for additional training. In this paper, we propose a knowledge prompts generation method, GenKP, which injects knowledge into LLMs by ICL. Compared to inserting triple-conversion or templated-conversion knowledge without selection, GenKP entails generating knowledge samples using LLMs in conjunction with KGs and makes a trade-off of knowledge samples through weighted verification and BM25 ranking, reducing knowledge noise. Experimental results illustrate that incorporating knowledge prompts enhances the performance of LLMs. Furthermore, LLMs augmented with GenKP exhibit superior improvements compared to the methods utilizing triple and template-based knowledge injection.},
  archive      = {J_APIN},
  author       = {Li, Xinbai and Peng, Shaowen and Yada, Shuntaro and Wakamiya, Shoko and Aramaki, Eiji},
  doi          = {10.1007/s10489-025-06318-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {GenKP: Generative knowledge prompts for enhancing large language models},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent forecasting algorithm of power industry
expansion based on time series and entropy weight method. <em>APIN</em>,
<em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06321-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To accurately predict the electricity consumption trend of individual users and even the entire industry, this paper studies an intelligent prediction algorithm for the power industry based on time series and entropy weight method. Using ARIMA model and X12 model to establish a monthly electricity consumption prediction model, the study obtains the monthly electricity consumption prediction value for the expansion of the power industry. The entropy weight method is employed to calculate the weights of two power industry expansion month electricity consumption forecasting models, thereby achieving intelligent forecasting. The experimental results demonstrate that the maximum error of the proposed method is only 1.78%, and the average time complexity and average space complexity of the proposed algorithm are both below the set threshold.},
  archive      = {J_APIN},
  author       = {Wu, Guoyao and Lan, Zhiqiang and Wu, Xiaofang and Huang, Xiaoying and Mao, Linling},
  doi          = {10.1007/s10489-025-06321-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Intelligent forecasting algorithm of power industry expansion based on time series and entropy weight method},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel data-driven model for explainable hog price
forecasting. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06323-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting hog prices is an important and challenging task for pig producers and managers as it plays a crucial role in decision-making processes. Given the significant impact of raw pork supply, public concern, animal diseases, and international markets on hog prices, this study proposes a comprehensive and explainable hybrid model for hog price forecasting by combining principal component analysis (PCA), variational mode decomposition (VMD), weighted average algorithm (WAA) algorithm, and temporal fusion transformers (TFT). To improve the quality of input variables, search engine data reflecting public concern about live pig prices are dimensionally reduced using PCA. This reduction process helps in eliminating unnecessary information and enhancing the input’s relevance. Additionally, VMD is applied to decompose raw pig futures prices, enabling the capture of their underlying trends over time. Subsequently, all the input variables, including the processed search engine data and the decomposed pig futures prices, are fed into the WAA-TFT model. WAA algorithm optimizes the parameters of the TFT model, resulting in accurate predicted values. The interpretable nature of the TFT model provides valuable decision-making insights for practitioners in the agricultural products market. The experimental results show that the proposed model achieves a mean absolute percentage error (MAPE) of only 1.76% on the Chinese hog price prediction dataset, demonstrating the excellent predictive performance of the proposed model.},
  archive      = {J_APIN},
  author       = {Wu, Binrong and Zeng, Huanze and Hu, Huanling and Wang, Lin},
  doi          = {10.1007/s10489-025-06323-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A novel data-driven model for explainable hog price forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning discriminative features for multi-hop knowledge
graph reasoning. <em>APIN</em>, <em>55</em>(6), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06327-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning (RL)-based multi-hop knowledge graph reasoning has achieved remarkable success in real-world applications and can effectively handle knowledge graph completion tasks. This approach involves a policy-based agent navigating the graph environment to extend reasoning paths and identify the target entity. However, most existing multi-hop reasoning models are typically constrained to stepwise inference, which inherently disrupts the global information of multi-hop paths. To overcome this limitation, we introduce discriminative features between valid and invalid paths as global information. Here, we propose a multi-hop path encoder specifically designed to extract these discriminative features. Firstly, a multi-hop path encoding module is employed to derive each path’s hidden features, using cross-attention mechanisms to strengthen the interaction between triple context and path features. Secondly, a discriminative feature extraction module is used to capture the differences between valid and invalid paths. Thirdly, an attention-enhanced gated fusion mechanism is implemented to integrate these discriminative features into the multi-hop inference decoder. We further evaluate our method on five standard datasets. Our method outperforms the baseline models, demonstrating the effectiveness of discriminative features in improving prediction performance, learning speed, and path interpretability.},
  archive      = {J_APIN},
  author       = {Liu, Hao and Li, Dong and Zeng, Bing and Xu, Yang},
  doi          = {10.1007/s10489-025-06327-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Learning discriminative features for multi-hop knowledge graph reasoning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Spatial-temporal clustering enhanced multi-graph
convolutional network for traffic flow prediction. <em>APIN</em>,
<em>55</em>(6), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06329-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamics and uncertainty are the fundamental reasons for the difficulty in accurately predicting traffic flow. In recent years, graph convolutional networks have been widely used in traffic flow prediction because of their excellent dynamic feature mapping ability. However, the existing models usually overlook the correlations among the nodes and the complex impact of external factors on traffic flow, which make it challenging to explore the complex spatial-temporal features. To overcome these shortcomings, we propose a novel Spatial-temporal Clustering enhanced Multi-Graph Convolutional Network (SCM-GCN) for traffic flow prediction. First, a Spatial-Temporal Clustering (STS) module based on the improved adjacency matrix DBSCAN clustering algorithm is constructed, this module divides traffic nodes into multiple highly correlated clusters, each of which consists of multi-graph features and time-varying features. Then, a Multi-Graph Spatial Feature Extraction (MGSFE) module that integrates the graph convolution operation and attention mechanism is designed to extract dynamic spatial features of multi-graph and time-varying features. Next, the Time-Varying Feature Extraction (TVFE) module based on the dilated convolution and gated attention mechanism is constructed. It integrates the output of the MGSFE module to extract dynamic temporal features of time-varying features and output the predicted values. Finally, the comparison and ablation experiments on four datasets show that the proposed model performs better than state-of-the-art models. The key source code and data are available at https://github.com/Bounger2/SCMGCN .},
  archive      = {J_APIN},
  author       = {Bao, Yinxin and Shen, Qinqin and Cao, Yang and Shi, Quan},
  doi          = {10.1007/s10489-025-06329-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Spatial-temporal clustering enhanced multi-graph convolutional network for traffic flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic fusion of multi-source heterogeneous data using MOE
mechanism for stock prediction. <em>APIN</em>, <em>55</em>(6), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06330-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock prices are influenced by numerous factors, including social media, news, and financial reports, serving as indicators of financial market dynamics. However, harnessing diverse information from different sources and structures to predict price trends remains challenging. In this paper, we propose a dual-stage deep learning model based on the Mixture-of-Expert (MoE) mechanism. In stage one, three distinct expert networks encode information about price movements, financial news, and investor sentiments through multi-source interaction attention. In stage two, a gated network dynamically fuses outputs, capturing temporal relationships in windowed data. Experimental results on the Chinese stock market demonstrate our model outperforms existing ones in forecasting tasks.},
  archive      = {J_APIN},
  author       = {Dong, Yuxin and Wu, Zirui and Hao, Yongtao},
  doi          = {10.1007/s10489-025-06330-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic fusion of multi-source heterogeneous data using MOE mechanism for stock prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature selection based on multi-perspective dynamic
neighbourhood entropy measures in a dynamic neighbourhood rough set.
<em>APIN</em>, <em>55</em>(6), 1–21. (<a
href="https://doi.org/10.1007/s10489-025-06336-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neighbourhood rough set (NRS)-based feature selection has been extensively applied in data mining. However, the effectiveness of the NRS model is limited by its reliance on the grid search method to determine the optimal neighbourhood parameter, insensitivity to data distribution under different features, and consideration of uncertainty measures from only one single perspective. To address the aforementioned issues, this study first defines a spatial function that can obtain information about the distribution of samples in space according to the change in the feature subset. On this basis, three perspectives of dynamic neighbourhoods are proposed: pessimistic, neutral, and optimistic. Next, the concept of the dynamic neighbourhood rough set (DNRS) model is developed. The most significant feature of this model is its adaptive ability to dynamically update the neighbourhood radius of samples on the basis of the information of their distribution in space, without the necessity of setting neighbourhood parameters artificially. Then, algebraic and information-theoretic views are introduced to propose multi-perspective dynamic neighbourhood entropy measures, which effectively measure the uncertainty of the data. In addition, a nonmonotonic feature selection algorithm based on mutual information is designed to overcome the limitations of feature selection algorithms that rely on monotonic evaluation functions. This algorithm utilizes multi-perspective dynamic neighbourhood entropy measures from a neutral perspective. Finally, to mitigate the high time complexity in feature selection for high-dimensional datasets, the Fisher score is introduced in an initial dimensionality reduction method. The results of the experiment show that the algorithm effectively eliminates redundant features and improves accuracy.},
  archive      = {J_APIN},
  author       = {Xu, Jiucheng and Ma, Miaoxian and Zhang, Shan and Niu, Wulin},
  doi          = {10.1007/s10489-025-06336-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Feature selection based on multi-perspective dynamic neighbourhood entropy measures in a dynamic neighbourhood rough set},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GANet: Geometry-aware network for RGB-d semantic
segmentation. <em>APIN</em>, <em>55</em>(6), 1–13. (<a
href="https://doi.org/10.1007/s10489-025-06337-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of RGB-D semantic segmentation has attracted considerable interest in recent times. The challenge is to develop an effective method for combining RGB images, which capture colour variations, with depth images, which provide robust information about object geometry regardless of lighting conditions. Treating both image types equally through the same convolution operator fails to take into account their inherent differences. Thus, in this paper, we propose a novel approach that combines a geometry-aware convolution (GAConv) module and a multiscale fusion module (MFM) with the aim of enhancing the performance of RGB-D image segmentation. The GAConv module effectively captures fine-grained geometric details from depth images, while the MFM module enables efficient integration of multi-scale features, allowing the network to utilise both spatial and semantic information. Extensive experimentation was conducted on the NYUv2 and SUN RGB-D datasets, wherein our model demonstrated consistent superiority over existing state-of-the-art methods in terms of pixel accuracy and mean intersection over union (mIoU).},
  archive      = {J_APIN},
  author       = {Tian, Chunqi and Xu, Weirong and Bai, Lizhi and Yang, Jun and Xu, Yanjun},
  doi          = {10.1007/s10489-025-06337-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {GANet: Geometry-aware network for RGB-D semantic segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature optimization based on multi-order fusion and
adaptive recursive elimination for motion classification in doppler
radar. <em>APIN</em>, <em>55</em>(6), 1–13. (<a
href="https://doi.org/10.1007/s10489-025-06342-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radar-based human motion recognition (HMR) technology has gained substantial importance across diverse domains such as security surveillance, post-disaster search and rescue operations, and the development of smart home environments. The intricate nature of human movements generates radar echo signals with pronounced non-stationary attributes, which encapsulate a wealth of target feature data. However, striking a balance between the precision of motion recognition and the requirement for real-time processing, especially in the context of extracting meaningful features from radar signals, remains a formidable challenge. This research paper introduces a novel approach to tackle this challenge. Firstly,we apply the multi-order fractional Fourier transform (m-FRFT) to radar echo signals, facilitating the extraction of micro-Doppler (m-D) frequency information. Secondly, we have developed an optimized feature selection model named MPG, which stands for m-D parameter screening based on genetic algorithm (GA) and adaptive weight particle swarm optimization (AWPSO). Thirdly, we apply the MPG model to the recursive feature elimination (RFE) algorithm to refine the representation of m-D frequency information, allowing for adaptive parameter adjustment and effective feature dimensionality reduction. The proposed method has been tested using human motion echo data collected from a Doppler radar prototype. The experimental outcomes demonstrate that our approach outperforms traditional feature extraction methods in terms of reducing feature dimensionality, computational efficiency, and classification accuracy.},
  archive      = {J_APIN},
  author       = {Sun, Tong and Ding, Yipeng and Chen, Yuxin and Ping, Lv},
  doi          = {10.1007/s10489-025-06342-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {Feature optimization based on multi-order fusion and adaptive recursive elimination for motion classification in doppler radar},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced decision framework for two-player zero-sum markov
games with diverse opponent policies. <em>APIN</em>, <em>55</em>(6),
1–21. (<a href="https://doi.org/10.1007/s10489-025-06344-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper takes into account a general two-player zero-sum Markov game scenario in which our agent faces multi-type opponents with multiple policies. To enhance our agent’s return against opponent’s diverse policies, a novel Decision-making Framework based on Opponent Distinguishing and Policy Judgment (DF-ODPJ) is proposed. On the basis of the pre-trained Nash equilibrium strategies, DF-ODPJ can distinguish the opponent’s type by sampling from the interaction trajectory. Then a fast criterion is proposed to judge the opponent’s policy which is proven to minimize the misjudgment probability with optimal threshold calculated. According to the identification results, appropriate policies are generated to enhance the return. The proposed DF-ODPJ is more flexible since it is orthogonal to existing Nash equilibrium algorithms and single-agent reinforcement learning algorithms. The experimental results on grid world, video games, and UAV aerial combat environments illustrate the effectiveness of DF-ODPJ. The code is available at https://github.com/ChenXJ295/DF-ODPJ .},
  archive      = {J_APIN},
  author       = {Zhu, Jin and Wang, Xuan and Geir E., Dullerud},
  doi          = {10.1007/s10489-025-06344-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {Enhanced decision framework for two-player zero-sum markov games with diverse opponent policies},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A large scale group decision making with expert guidance via
discrete conditional variational autoencoder. <em>APIN</em>,
<em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06345-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Large Scale Group Decision Making (LSGDM), the differences in decision-makers’ professional backgrounds and attitudes often lead to high-quality decisions being overshadowed by numerous low-quality decisions, thus affecting the accuracy of the final decision. This study proposes a new decision-making method to address this challenge. First, a few experts are invited to make decisions as cluster centers, followed by obtaining decisions from a large number of ordinary decision-makers. The ordinary decisions are then generated and modified using a Discrete Conditional Variational Autoencoder (DCVAE) to enhance decision quality while maintaining consistency with expert decisions. Finally, the normalized prediction selection rate (NPSR) and the Borda Count consensus method are integrated to obtain the final result. Experimental results demonstrate the effectiveness of this method in improving the quality of LSGDM, providing a new solution to the coexistence of high- and low-quality decisions.},
  archive      = {J_APIN},
  author       = {Zhang, Hengshan and He, Adong and Sun, Jiaze and Chen, Yanping},
  doi          = {10.1007/s10489-025-06345-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {A large scale group decision making with expert guidance via discrete conditional variational autoencoder},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional time-dependent dynamic graph neural
network for metro passenger flow prediction. <em>APIN</em>,
<em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06346-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate metro passenger flow prediction can provide data support for vehicle scheduling and personnel allocation by metro operation departments, ensuring the efficient utilization of related resources. In recent years, Graph Convolutional Networks (GCNs) have demonstrated excellent performance in spatial processing, making them an effective method for extracting spatiotemporal dependencies in metro passenger flow prediction. However, traditional GCN models focus solely on static relationships between stations, overlooking the dynamic changes in station relationships and typically concentrating on short-term temporal dependencies while neglecting longer-term temporal features. To fully consider the spatiotemporal relationships within the metro network, a Multi-Dimensional Temporal Dependency Graph Neural Network (MTDGNN) is proposed for metro passenger flow prediction. Specifically, 1D dilated convolutions are employed to initially extract multi-dimensional temporal dependencies, generating multiple spatiotemporal dependency extraction channels. Two correlation matrices combined with GCN are then proposed to extract spatial relationships between stations within the metro network. The extracted spatiotemporal features are further captured by a Gated Recurrent Unit (GRU) to enhance temporal feature extraction. Subsequently, a multi-head attention mechanism is utilized to integrate the extraction results from multiple channels to obtain the final prediction. Finally, the model is evaluated using metro ridership data from two cities in southwestern and central China. The results indicate that the proposed model exhibits superior predictive performance compared to other methods. The MAE values on the two datasets are 1.5% to 59.3% lower than those of other methods, and the RMSE values are 3.4% to 60.0% lower than those of other methods.},
  archive      = {J_APIN},
  author       = {Li, Ruisen and Zhao, Liqiang and Tang, Jinjin and Tang, Shuixiong and Hao, Zhenxing},
  doi          = {10.1007/s10489-025-06346-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Multi-dimensional time-dependent dynamic graph neural network for metro passenger flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An echo state network with adaptive improved pigeon-inspired
optimization for time series prediction. <em>APIN</em>, <em>55</em>(6),
1–32. (<a href="https://doi.org/10.1007/s10489-025-06347-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective alternative model to recurrent neural network (RNN), echo state network (ESN) has garnered more attention due to its efficiency in handling time series data. Despite the simple training process and rapid convergence speed of ESN, appropriate parameter settings and a concise network structure are crucial for optimal model performance. Therefore, many optimization algorithms have been proposed to obtain the optimal parameters of ESN. Among these methods, the Pigeon-Inspired Optimization (PIO) has gained attention due to its fast search speed, strong evolution capability, and excellent optimization ability. However, the main drawbacks of PIO are that it may easily get trapped in local optima and achieve lower precision results. To address these issues, this paper proposes a hybrid algorithm combining adaptive improved pigeon-inspired optimization with tabu search (TS-APIO) algorithm. By combining the improved PIO and the tabu search (TS), it not only enhances the global search capability but also strengthens its robustness. Additionally, the adaptive adjustment mechanism can improve the generalization ability. Through theoretical analysis and simulation examples, the TS-APIO algorithm can adaptively select the optimal ESN parameters and structure based on different scenarios. It can effectively enhance the ability to capture the dynamic features and reduce the prediction error.},
  archive      = {J_APIN},
  author       = {Yang, Xu and Wang, Lei and Chen, Qili},
  doi          = {10.1007/s10489-025-06347-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-32},
  shortjournal = {Appl. Intell.},
  title        = {An echo state network with adaptive improved pigeon-inspired optimization for time series prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised heterogeneous graph neural network based on
deep and broad neighborhood encoding. <em>APIN</em>, <em>55</em>(6),
1–23. (<a href="https://doi.org/10.1007/s10489-025-06348-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised heterogeneous graph neural networks have shown remarkable effectiveness in addressing the challenge of limited labeled data. However, current contrastive learning methods face limitations in leveraging neighborhood information for each node. Some approaches utilize the local information of the target node, ignoring useful signals from deeper neighborhoods. On the other hand, simply stacking convolutional layers to expand the neighborhood inevitably leads to over-smoothing. To address the problems, we propose HGNN-DB, a Self-supervised Heterogeneous Graph Neural Network Based on Deep and Broad Neighborhood Encoding to tackle the over-smoothing problem within heterogeneous graphs. Specifically, HGNN-DB aims to learn informative node representations by incorporating both deep and broad neighborhoods. We introduce a deep neighborhood encoder with a distance-weighted strategy to capture deep features of target nodes. Additionally, a single-layer graph convolutional network is employed for the broad neighborhood encoder to aggregate broad features of target nodes. Furthermore, we introduce a collaborative contrastive mechanism to learn the complementarity and potential invariance between the two views of neighborhood information. Experimental results on four real-world datasets and seven baselines demonstrate that our model significantly outperforms the current state-of-the-art techniques on multiple downstream tasks. The codes and datasets for this work are available at https://github.com/SSQiana/HGNN-DB.},
  archive      = {J_APIN},
  author       = {Song, Qianyu and Li, Chao and Fu, Jinhu and Zeng, Qingtian and Xie, Nengfu},
  doi          = {10.1007/s10489-025-06348-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Self-supervised heterogeneous graph neural network based on deep and broad neighborhood encoding},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NNBSVR: Neural network-based semantic vector representations
of ICD-10 codes. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06349-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatically predicting ICD-10 codes from clinical notes using machine learning models can reduce the burden of manual coding. However, existing methods often overlook the semantic relationships between ICD-10 codes, resulting in inaccurate evaluations when clinically similar codes are considered completely different. Traditional evaluation metrics, which rely on equality-based matching, fail to capture the clinical relevance of predicted codes. This study introduces NNBSVR (Neural Network-Based Semantic Vector Representations), a novel approach for generating semantic-based vector representations of ICD-10 codes. Unlike traditional approaches that rely on exact code matching, NNBSVR incorporates contextual and hierarchical information to enhance both prediction accuracy and evaluation methods. We validate NNBSVR using intrinsic and extrinsic evaluation methods. Intrinsic evaluation assesses the vectors’ ability to reconstruct the ICD-10 hierarchy and identify clinically meaningful clusters. Extrinsic evaluation compares our relevancy-based approach, which includes customized evaluation metrics, to traditional equality-based metrics on an ICD-10 code prediction task using a 9.57 million clinical notes corpus. NNBSVR demonstrates significant improvements over equality-based metrics, achieving a 9.81% gain in micro-F1 score on the training set and a 12.73% gain on the test set. A manual review by medical experts on a sample of 10,000 predictions confirms an accuracy of 92.58%, further validating our approach. This study makes two significant contributions: first, the development of semantic-based vector representations that encapsulate ICD-10 code relationships and context; second, the customization of evaluation metrics to incorporate clinical relevance. By addressing the limitations of traditional equality-based evaluation metrics, NNBSVR enhances the automated assignment of ICD-10 codes in clinical settings, demonstrating superior performance over existing methods.},
  archive      = {J_APIN},
  author       = {Hatoum, Monah Bou and Charr, Jean Claude and Ghaddar, Alia and Guyeux, Christophe and Laiymani, David},
  doi          = {10.1007/s10489-025-06349-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {NNBSVR: Neural network-based semantic vector representations of ICD-10 codes},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning sparse filters-based convolutional networks without
offline training for robust visual tracking. <em>APIN</em>,
<em>55</em>(6), 1–23. (<a
href="https://doi.org/10.1007/s10489-025-06350-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the scarcity of training samples in the visual tracking task, almost all existing Convolutional Neural Networks (CNNs) based deep tracking algorithms rely heavily on large auxiliary datasets to train the tracking model offline. However, such offline training has two inevitable disadvantages: (1) the learned generic features may be less discriminative for tracking specific objects; (2) the training process demands huge computational power provided by high-performance graphics processing units (GPUs), which is not always available in many practical applications. Therefore, learning effective generic features without offline training for robust visual tracking is a necessary and challenging task. This paper tackles this task by proposing the Sparse Filters-based Convolutional Network (SFCN), which is a fully feed-forward convolutional network with a lightweight structure including two convolutional layers. Its convolutional kernels are a set of sparse filters learned and updated online from local patches using sparse dictionary learning. Benefiting from the learned sparse filters, SFCN learns effective generic features by exploiting both the discriminative information between the foreground and background of the target region and the hierarchical layout information among the local patches inside each target candidate region. Furthermore, a dynamic model updating strategy is adopted to alleviate the drift problem. Extensive experiments on five large-scale benchmark datasets show that the proposed method performs favorably against several state-of-the-art tracking algorithms.},
  archive      = {J_APIN},
  author       = {Xu, Qi and Xu, Zhuoming and Chen, Zhe and Chen, Yun and Wang, Huabin and Tao, Liang},
  doi          = {10.1007/s10489-025-06350-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {Learning sparse filters-based convolutional networks without offline training for robust visual tracking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LGCGNet: A local-global context guided network for real-time
water surface semantic segmentation. <em>APIN</em>, <em>55</em>(6),
1–20. (<a href="https://doi.org/10.1007/s10489-025-06351-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned boats will encounter many static and dynamic obstacles during navigation, and only real-time obstacle sensing can ensure safe navigation and long endurance of unmanned boats. In this paper, LGCGNet is proposed to perform real-time water surface semantic segmentation on the images captured by the on-board camera. In order to ensure that the model adapted to obstacles with extremely variable scales, a local-global module is proposed in this paper. The local-global module consisted of residual dense dilated module and context-enhanced separable self-attention. Residual dense dilated module enabled the enhancement of local detail information and context-enhanced separable self-attention enabled model receptive field expansion. In addition, the sub-pixel downsampling module is used to avoid the loss of feature information to improve segmentation accuracy. Experiments on the MaSTr1325 dataset showed that LGCGNet apprpached the segmentation accuracy of state-of-the-art semantic segmentation models with only 689,000 parameters and 9.068G floating point operations per second, with an mIoU of 84.14%. In addition, the processing speed of LGCGNet is 34.86FPS, which meets the frame rate conditions of commercially available photovoltaic equipment. The experiments demonstrated that the LGCGNet proposed in this paper strike a good balance between achieving high accuracy, reducing model size and improving real-time performance.},
  archive      = {J_APIN},
  author       = {Liu, Ting and Luo, Peiqi and Wang, Guofeng and Zhang, Yuxin and Lu, Xiangyi and Dong, Mengyu},
  doi          = {10.1007/s10489-025-06351-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {LGCGNet: A local-global context guided network for real-time water surface semantic segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Scnet: Spectral convolutional networks for multivariate time
series classification. <em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06352-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread application of time series data, the study of classification techniques has become an important topic. Although existing multivariate time series classification (MTSC) methods have made progress, they often rely on one-dimensional (1D) time series, which limits their ability to capture complex temporal dynamics and multiscale features. To address these challenges, a Spectral Convolutional Network (SCNet) is introduced in this work. SCNet effectively transforms 1D time series data into the frequency domain using an enhanced Discrete Fourier Transform (enhanced_DFT), revealing periodicity and key frequency components while reshaping the data into a two-dimensional (2D) time series for better representation. Furthermore, it uses a Spectral Energy Prioritization method to optimize frequency domain energy distribution and a multiscale convolutional module to capture features at different scales, improving the model’s ability to analyze short-term and long-term trends. To validate the effectiveness and superiority, we conducted extensive experiments on 10 sub-datasets from the well-known UEA dataset. The results show that our proposed SCNet achieved the highest average accuracy of 74.3%, which is 2.2% higher than the current state-of-the-art models, demonstrating its potential for practical application and efficiency in MTSC task.},
  archive      = {J_APIN},
  author       = {Wu, Xing and Xing, Xinyu and Yao, Junfeng and Qian, Quan and Song, Jun},
  doi          = {10.1007/s10489-025-06352-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Scnet: Spectral convolutional networks for multivariate time series classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Precise spiking neurons for fitting any activation function
in ANN-to-SNN conversion. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06354-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are recognized for their energy efficiency due to spike-based communication. In this regard, the shift towards SNNs is driven by their ability to significantly reduce energy consumption while maintaining the performance of ANNs. Converting Artificial Neural Networks (ANNs) to SNNs is a key research focus, but existing methods often struggle with balancing conversion accuracy and latency, and are typically restricted to ReLU activations. We introduce Precision Spiking (PS) neurons, a novel dynamic spiking neuron model that can precisely fit any activation function by jointly regulating spike timing, reset voltage, and membrane potential threshold. This capability enables exact parameter optimization via iterative methods, achieving low-latency, high-accuracy ANN-to-SNN conversion. Experiments on image classification and natural language processing benchmarks confirm state-of-the-art results, with a maximum conversion loss of 0.55% and up to 0.38% accuracy improvement over the original ANN. To the best of our knowledge, this method offers a significant advancement over existing approaches by achieving high-precision fitting of arbitrary activation functions with low latency and minimal conversion loss, thus considerably expanding the range of feasible ANN-to-SNN conversions.},
  archive      = {J_APIN},
  author       = {Wang, Tianqi and Shen, Qianzi and Li, Xuhang and Zhang, Yanting and Wang, Zijian and Yan, Cairong},
  doi          = {10.1007/s10489-025-06354-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Precise spiking neurons for fitting any activation function in ANN-to-SNN conversion},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NoRD: A framework for noise-resilient self-distillation
through relative supervision. <em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06355-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) has become a pivotal technique in deep learning, facilitating model compression and regularization by transferring knowledge from one neural network to another, enhancing its capabilities for downstream tasks such as classification. However, real-world datasets often suffer from noisy label problems, significantly hindering neural network learning in supervised tasks. Recent advancements in KD aim to improve noise-robustness and regularization in deep neural networks through different learning paradigms. Yet, prevalent approaches often exhibit noise-prone behaviors as the student network heavily relies on the teacher’s learning. To address this challenge, we propose a robust knowledge transfer method, NoRD: a Noise-Resilient Self-Distillation framework. This approach leverages relative self-supervision combined with decision matching to minimize noise susceptibility during the knowledge transfer process. Our study evaluates this technique on CIFAR-10, CIFAR-100, and MNIST datasets with synthetic label noise. Results showcase that our method achieves 8-10% higher test accuracy compared to state-of-the-art noise-robust loss functions at noise rates exceeding 50%, surpassing well-known KD methods by 4-5% in top-1 test accuracy. The code is available at https://github.com/philsaurabh/NoRD_Applied-Intelligence .},
  archive      = {J_APIN},
  author       = {Sharma, Saurabh and Lodhi, Shikhar Singh and Srivastava, Vanshika and Chandra, Joydeep},
  doi          = {10.1007/s10489-025-06355-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {NoRD: A framework for noise-resilient self-distillation through relative supervision},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Lbgcn: Lightweight bilinear graph convolutional network with
attention mechanism for recommendation. <em>APIN</em>, <em>55</em>(6),
1–17. (<a href="https://doi.org/10.1007/s10489-025-06357-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Graph Convolutional Neural Network (GCN) is a powerful technique for learning and representing graph data, commonly utilized in model-based collaborative filtering recommendation algorithms. However, despite its effectiveness, the issues are data sparsity and interpretability. Most existing GCN-based models simply update the central node’s features by aggregating the features of its neighbors, typically via a weighted sum. Unfortunately, this approach fails to capture the cooperative information hidden in the neighbor interactions. To address this limitation, we propose a recommendation algorithm based on a convolution network of lightweight neighborhood interactive graphs, named the Lightweight Bilinear Graph Convolutional Network (LBGCN). Our approach employs a lightweight graph convolutional neural network as a multi-level feature aggregator, leveraging higher-order connectivity to aggregate neighborhood information into a multi-level feature of the node through the aggregator. Meanwhile, we introduce a local feature aggregator to capture the collaborative filtering signals in the interaction features of neighbors. Finally, we combine the results using an attention mechanism to obtain the embedded representation of final users and items. In addition, we demonstrate the rationality and effectiveness of our proposed model through experiments on three public datasets. The results show that our method could gain 2.52% NDCG improvement at most.},
  archive      = {J_APIN},
  author       = {Su, Yu and Wei, Pingzhu and Zhu, Linbo and Xu, Lixiang and Wang, Xianquan and Tong, He and Han, Ze},
  doi          = {10.1007/s10489-025-06357-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Lbgcn: Lightweight bilinear graph convolutional network with attention mechanism for recommendation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel ensemble bagging-logistic regression algorithm for
NoSQL database security. <em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06358-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present era, the use of the Internet has drastically increased in the sharing of digital information. In this case, the digital information is stored using cloud technology or NoSQL databases. However, there is a significant challenge in protecting and managing the cloud and NoSQL-based data and extracting required information from these sources while maintaining the actual information. The network traffic has also increased significantly, which requires more memory and sufficient systems to manage and monitor the influx of Big Data. Traditional relational databases face issues in managing and securing the cloud-based dynamic data generated from various sources. NoSQL databases have recently been used to store and manage dynamic data effectively. However, there are security and privacy issues with the NoSQL databases, which remain challenging to provide. Consequently, in the present study, we propose a novel algorithm that enhances the security of the NoSQL databases and predicts its success rate. Initially, we implemented the Fernet data masking algorithm to secure the NoSQL database. Then, the secured data is classified and predicted using an innovative proposed method called the Ensemble Bagging Classifier-Logistic Regression (EBC-LR) to validate the accuracy of the secured NoSQL database. The experimental outcomes depict that our proposed algorithm achieves 85 percent accuracy, better than traditional methods in enhancing the security of NoSQL databases. Our proposed algorithm can effectively predict secure standard databases with the highest success rate.},
  archive      = {J_APIN},
  author       = {Kanade, Anuradha and Vibhute, Amol D. and Kanade, Shantanu},
  doi          = {10.1007/s10489-025-06358-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Novel ensemble bagging-logistic regression algorithm for NoSQL database security},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mixmamba-fewshot: Mamba and attention mixer-based method
with few-shot learning for bearing fault diagnosis. <em>APIN</em>,
<em>55</em>(6), 1–22. (<a
href="https://doi.org/10.1007/s10489-025-06361-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence, particularly machine learning and deep learning has ushered in a new era of technological advancements leading to significant progress across various domains. In the field of computer vision, deep learning has made substantial contributions, impacting everything from daily life to production and industry. When machines, rotating devices, and engines operate, bearing failures are inevitable. Our task is to accurately detect or diagnose these failures. However, a key challenge lies in the lack of sufficient data on bearing faults to train a model capable of delivering highly accurate diagnostic results. To address this issue, in this paper, we propose a new approach named MixMamba-Fewshot, leveraging few-shot learning and using a feature extraction module that integrates an attention mechanism called the Priority Attention Mixer and Mamba - a novel theory that has recently gained considerable attention within the research community. Using Mamba for vision-based feature extraction in classification tasks, particularly in few-shot learning is an innovative approach, and it has shown promising results in improving the accuracy of bearing fault diagnosis. When we tested our model on the datasets provided by Case Western Reserve University (CWRU) and the Paderborn University (PU) Bearing Dataset, we compared it with previously published models. Our proposed approach demonstrated a significant improvement in diagnostic accuracy and clearly outperformed existing approaches. Our code will be available at: https://github.com/linhthan216/MixMamba-Fewshot .},
  archive      = {J_APIN},
  author       = {Than, Nhu-Linh and Nguyen, Van Quang and Truong, Gia-Bao and Pham, Van-Truong and Tran, Thi-Thao},
  doi          = {10.1007/s10489-025-06361-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Mixmamba-fewshot: Mamba and attention mixer-based method with few-shot learning for bearing fault diagnosis},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HiProIBM: Unsupervised continual learning through
hierarchical prototypical cross-level discrimination along with
information bottleneck subnetwork masking. <em>APIN</em>,
<em>55</em>(6), 1–27. (<a
href="https://doi.org/10.1007/s10489-025-06362-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Catastrophic Forgetting (CF) occurs when a machine learning model forgets the experience of previous tasks while learning new tasks due to inadequate retention mechanisms. Unsupervised continual learning (UCL) addresses this by enabling the model to adapt to new tasks using unlabeled data while retaining past knowledge. To mitigate CF in UCL, we use a parameter isolation technique to mask sub-networks dedicated to each task, thus preventing interference with previous tasks. However, relying solely on weight magnitude for constructing these sub-networks can result in the retention of irrelevant weights and the creation of redundant sub-networks. This approach also risks capacity saturation and information suppression for tasks encountered later in the sequence. To overcome this, we use masked sub-networks, inspired by the information bottleneck (IB) concept. It accumulates valuable information into essential weights to construct redundancy-free sub-networks which effectively mitigates CF and enables the new task training. The IB subnetwork masking faces challenges in balancing input compression with meaningful pattern preservation without labels. It risks overcompression and loss of crucial latent structures, which degrades model performance. We address this by learning multiple semantic hierarchies present in the data using unsupervised contrastive learning. However traditional contrastive learning techniques learn meaningful representations by contrasting similar and dissimilar data points. These approaches lack adequate representational power for modeling datasets with multiple semantic hierarchies. The inherent hierarchical semantic structures in datasets are necessary to integrate semantically related clusters into larger, coarser-grained clusters, but existing contrastive learning methods often overlook this and limit semantic understanding. We address this by constructing and updating hierarchical prototypes with cross-level group discrimination to represent semantic structures in the latent space. Our experiments on four standard datasets show performance improvements over SOTA baselines for varying task-sequences from 5 to 100, with nearly-zero forgetting.},
  archive      = {J_APIN},
  author       = {Malviya, Ankit and Kumar Maurya, Chandresh},
  doi          = {10.1007/s10489-025-06362-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {HiProIBM: Unsupervised continual learning through hierarchical prototypical cross-level discrimination along with information bottleneck subnetwork masking},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting gas flow rates of wellhead chokes based on a
cascade forwards neural network with a historically limited penetrable
visibility graph. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06365-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel hybrid model that combines the cascade forward neural network (CFNN) with a historical limited penetrable visibility graph (HLPVG) for accurate prediction of gas flow rates through wellhead chokes in shale gas production. The model addresses the challenges of complex, nonlinear relationships between multiple variables affecting gas flow, including liquid–gas ratio (LGR), upstream pressure, temperature, and choke bean size. Using 11,572 field production samples from shale gas fields in the southern Sichuan Basin, the CFNN-HLPVG model demonstrates superior predictive performance compared to the conventional methods. The HLPVG algorithm transforms time series data into a graph structure, enabling the extraction of rich temporal and topological features, whereas the CFNN captures the complex interactions between variables. The model achieves a mean absolute relative error (MARE) of 0.014, significantly outperforming traditional approaches, including the Gilbert-type correlation, support vector machine, and other neural network architectures. Sobol sensitivity analysis revealed that choke bean size has the greatest impact on gas flow prediction (37.7% first-order sensitivity), followed by upstream pressure (19.3%) and temperature (11.6%), whereas LGR has a minimal influence (0.6%). The model performs particularly well under normal operating conditions but shows decreased accuracy in extreme environments with high temperature and pressure. This research provides a novel approach to gas flow prediction in wellhead chokes, offering valuable insights for optimizing shale gas production operations while highlighting areas for future improvement in handling extreme conditions and multisource data integration.},
  archive      = {J_APIN},
  author       = {Jiang, Youshi and Hu, Jingkai and Chen, Xiyu and Mo, Weiren},
  doi          = {10.1007/s10489-025-06365-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Predicting gas flow rates of wellhead chokes based on a cascade forwards neural network with a historically limited penetrable visibility graph},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised anomalous machine sound detection model
based on spectrogram decomposition and parallel sub-network.
<em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06366-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalous Sound Detection (ASD) has research significance and application prospect industrial automation. Most existing models of ASD have limited ability to effectively utilize machine sound features, leading to reduced stability against sound anomalies and domain shift variations. To address the above issues, we propose a self-supervised ASD model based on spectrogram decomposition and parallel sub-network in this paper. Firstly, we decompose the spectrogram along the time and frequency dimensions to balance feature size and information integrity. This approach emphasizes the temporal and frequency variations in the feature map, facilitating a better understanding of the factors that affect machine sounds under domain shift conditions. Secondly, we design a pair of parallel training sub-networks. The parallel sub-networks employ self-attention mechanisms and shared gradients to effectively capture changes in features across both time and frequency dimensions. This approach improves model stability against anomalies and domain shifts. Finally, the anomaly scores of sub-network branches are fused as anomalous detection results. The performance of the proposed model is validated on DCASE2022 Task2 dataset. The Area under the Receiver Operating Characteristic Curve (AUC) and partial AUC (pAUC) of our model reached 72.89% and 64.83%. The results confirm the effectiveness of the proposed model, achieving better performance.},
  archive      = {J_APIN},
  author       = {Zhang, Tao and Kong, Lingguo and Zhao, Xin and Li, Donglei and Geng, Yanzhang and Ding, Biyun and Wang, Chao},
  doi          = {10.1007/s10489-025-06366-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A self-supervised anomalous machine sound detection model based on spectrogram decomposition and parallel sub-network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis of deep non-smooth symmetric nonnegative matrix
factorization on hierarchical clustering. <em>APIN</em>, <em>55</em>(6),
1–16. (<a href="https://doi.org/10.1007/s10489-025-06367-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep matrix factorization (deep MF) is an increasingly popular unsupervised data-mining technique that operates as a deep decomposition rooted in traditional nonnegative matrix factorization (NMF). Compared with standard NMF, deep MF has shown excellent performance in the extraction of hierarchical information from complex datasets. For cases in which the data matrices corresponding to the dataset are symmetric—such as the adjacency matrix of an undirected graph in network analysis—this paper proposes a deep MF variant called deep non-smooth nonnegative symmetric matrix factorization (DNSSNMF). The aim of this work is to enhance the extraction of complex hierarchical structures in high-dimensional datasets and achieve the clustering of structures inherent in graphical representations by improving the goodness-of-fit of the factor matrix product. Accordingly, we successfully applied DNSSNMF to post-traumatic-stress-disorder (PTSD) datasets and synthetic datasets to extract several hierarchical communities. In particular, we extracted non-disjoint communities in the partial correlation network of psychiatric symptoms in PTSD, revealing correlations between different symptoms and leading to meaningful clinical interpretations. The results of our numerical experiments indicated promising applications of DNSSNMF in fields including network analysis and medicine.},
  archive      = {J_APIN},
  author       = {Li, Shunli and Lu, Linzhang and Liu, Qilong and Chen, Zhen},
  doi          = {10.1007/s10489-025-06367-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Analysis of deep non-smooth symmetric nonnegative matrix factorization on hierarchical clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Composed image retrieval: A survey on recent research and
development. <em>APIN</em>, <em>55</em>(6), 1–35. (<a
href="https://doi.org/10.1007/s10489-025-06372-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, composed image retrieval (CIR) has gained significant attention within the research community due to its excellent research value and extensive real-world applications. CIR allows modifying query images based on user-provided text descriptions, producing search results that better match users’ intent. This paper conducts a comprehensive and up-to-date survey of CIR research and its applications. We summarise recent advancements in CIR methodologies from these perspectives by breaking down a CIR system into four key processes-feature extraction, feature alignment, feature fusion, and image retrieval. We examine feature extraction, emphasizing deep learning techniques for images and text. As deep learning evolves, feature alignment increasingly integrates with other processes, encouraging us to categorize related methods into explicit and implicit approaches. From the perspective of feature fusion, we investigate advancements in image-text feature fusion techniques, categorizing them into 6 broad categories and 17 subcategories. We also summarize different architecture types and training loss functions for image retrieval. Additionally, we review standard benchmark datasets and evaluation metrics in CIR, presenting a comparative analysis of the accuracy of crucial CIR approaches. Finally, we put forward several critical yet underexplored issues in the field.},
  archive      = {J_APIN},
  author       = {Wan, Yongquan and Zou, Guobing and Zhang, Bofeng},
  doi          = {10.1007/s10489-025-06372-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-35},
  shortjournal = {Appl. Intell.},
  title        = {Composed image retrieval: A survey on recent research and development},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchoring actions using conditional behavior trees and
genetic programming. <em>APIN</em>, <em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06373-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robotic Kitting means the creation of parts assortment to be used later. These parts are selected from one or more containers in which there are different types of them randomly distributed. The Anchoring Problem should be considered if we want to provide a general solution to robotic kitting, since users want that it works with different types of parts that are not known ’a priori’. Therefore, we are working on a human supervised approach in which Behavior Trees, robot learning and human-robot interaction are used to anchor percepts and operations to symbols during commissioning or reconfiguration phases. In this paper we explain: (1) the anchoring mechanisms in our system and how behavior trees can be used to represent an anchor, and (2) how Genetic Programming is used to generate Conditional Behavior Trees that anchor symbolic actions to robot operations.},
  archive      = {J_APIN},
  author       = {Escudero-Rodrigo, Diego and Alquezar, René and Aranda, Joan},
  doi          = {10.1007/s10489-025-06373-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Anchoring actions using conditional behavior trees and genetic programming},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADIMPL: A dynamic, real-time and robustness attack detection
model for industrial cyber-physical systems based on improved meta
pseudo labels. <em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06374-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the introduction of networking has increased the efficiency of Industrial Cyber-Physical Systems (ICPS), it has also lowered the cost for attackers, significantly increasing security risks. Current research on ICPS attack detection focuses on deep learning methods. However, the dependence on large labeled datasets often hinders these systems from adapting quickly to the dynamic changes and real-time demands of the ICPS environment. To address these issues, we present an attack detection method based on improved meta pseudo label (ADIMPL). ADIMPL innovatively combines two-layer network traffic feature extraction with the compact SqueezeNet deep neural network, achieving high performance with a minimal number of labeled samples. Additionally, the method dynamically adapts to changing attack patterns, significantly increasing detection accuracy while enhancing the robustness and real-time processing capabilities of the detection system. Extensive experiments on real-world industrial CPS datasets (CIC-IDS2017, CIC-IDS2018, and the CIC-Attack Dataset 2023) demonstrate that ADIMPL can effectively, robustly, and in real-time detect network attacks against industrial CPS. Notably, ADIMPL achieves a detection accuracy of 99.13% with an average latency of 0.098 s and maintains a minimum attack detection accuracy of 91.99% even under our proposed GAN+OPSO malicious attacks.},
  archive      = {J_APIN},
  author       = {Zhang, Bohan and Zhang, Pan and Wang, Zhiwen and Lv, Jiaqi and Miao, Wei},
  doi          = {10.1007/s10489-025-06374-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {ADIMPL: A dynamic, real-time and robustness attack detection model for industrial cyber-physical systems based on improved meta pseudo labels},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). STGFP: Information enhanced spatio-temporal graph neural
network for traffic flow prediction. <em>APIN</em>, <em>55</em>(6),
1–21. (<a href="https://doi.org/10.1007/s10489-025-06377-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow prediction is crucial for the development of intelligent transportation systems aimed at preventing and mitigating traffic issues. We present an information-enhanced spatio-temporal graph neural network model to predict traffic flow, addressing the inefficient utilization of non-Euclidean structured traffic data. Firstly, we employ a multivariate temporal attention mechanism to capture dynamic temporal correlations across different time intervals, while a second-order graph attention network identifies spatial correlations within the network. Secondly, we construct two types of traffic topology graphs that comprehensively describe traffic flow features by integrating non-Euclidean traffic flow data, regional traffic status information, and node features. Finally, a multi-graph convolution neural network is designed to extract long-range spatial features from these traffic topology graphs. The spatio-temporal feature extraction module then combines these long-range spatial features with spatio-temporal features to fuse multiple features and improve prediction accuracy. Experimental results demonstrate that the proposed approach outperforms state-of-the-art baseline methods in predicting traffic flow performance.},
  archive      = {J_APIN},
  author       = {Li, Qi and Wang, Fan and Wang, Chen},
  doi          = {10.1007/s10489-025-06377-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {STGFP: Information enhanced spatio-temporal graph neural network for traffic flow prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Non-local modeling of enhancer-promoter interactions, a
correspondence on “LOCO-EPI: Leave-one-chromosome-out (LOCO) as a
benchmarking paradigm for deep learning based prediction of
enhancer-promoter interactions.” <em>APIN</em>, <em>55</em>(6), 1–5. (<a
href="https://doi.org/10.1007/s10489-025-06378-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recent paper by Tahir et al. (Appl Intell 55:71, 2024) in Applied Intelligence reported a computational model of enhancer promoter interactions without realizing that many of their conclusions were previously published in 2018. In addition to correcting this record, the authors appear to be unaware of an additional body of previous work on enhancer-promoter interactions, which can explain why their computational model performs poorly. We describe how the weak predictive power of their model is consistent with new insights gained from substantial recent progress in the area of detecting and modeling enhancer promoter interactions constrained by DNA looping, extrusion by cohesin, and CTCF.},
  archive      = {J_APIN},
  author       = {Beer, Michael A.},
  doi          = {10.1007/s10489-025-06378-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-5},
  shortjournal = {Appl. Intell.},
  title        = {Non-local modeling of enhancer-promoter interactions, a correspondence on “LOCO-EPI: Leave-one-chromosome-out (LOCO) as a benchmarking paradigm for deep learning based prediction of enhancer-promoter interactions”},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025b). A local generation-mix cascade network for image
translation with limited data. <em>APIN</em>, <em>55</em>(6), 1–21. (<a
href="https://doi.org/10.1007/s10489-025-06379-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image translation based on deep generative models often overfits with limited data. Current methods overcome this problem through mix-based data augmentation. However, if latent features are mixed without considering semantic correspondences, augmented samples may exhibit visible artifacts and mislead model training. In this paper, we propose a Local Generation-Mix Cascade Network (LogMix), a data augmentation strategy for image translation tasks with limited data. Through cascading a local feature generation module and mixing module, LogMix enables the generation of a reference feature bank, which is mixed with the most similar local representation to form a new intermediate sample. Furthermore, we design a semantic relationship loss based on the mixed distance of latent features ensures consistency in the distribution of features between the generated and source domains. LogMix effectively mitigates the overfitting problem by learning to translate intermediate samples instead of memorizing the training data Experimental results across various tasks demonstrate that, even with limited data, LogMix data augmentation reduces image ambiguity and offers significant advantages in establishing realistic cross-domain mappings.},
  archive      = {J_APIN},
  author       = {Zhang, Yusen and Li, Min and Gou, Yao and Zhang, Xianjie and He, Yujie},
  doi          = {10.1007/s10489-025-06379-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A local generation-mix cascade network for image translation with limited data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel fuzzy knowledge graph structure for decision making
of multimodal big data. <em>APIN</em>, <em>55</em>(6), 1–21. (<a
href="https://doi.org/10.1007/s10489-025-06381-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making in the era of big data is always a challenge. Recently, various methods especially graph sampling have been presented to assist the decision more effectively. As real-world graphs are large, constantly evolving, and distributed in nature, it becomes necessary to sample their structures for many different goals. Therefore, acquiring a comprehensive and in-depth understanding of graph sampling is essential to strengthen this field. In addition, graph sampling techniques often rely on edge or vertex sampling without effective methods for rule or path sampling. In this paper, we propose a novel framework for the rule-based sampling method on fuzzy knowledge graphs. In this framework, fuzzy knowledge graphs are built on integrated databases from multiple sources. We design a purposive random sampling method based on fuzzy rules on graphs to prioritize important rules for output inference. The remaining important rules form the core structure of the fuzzy knowledge graph, known as the Fuzzy Knowledge Graph Structure (FKGS). This structure is considered as a compression mechanism to reduce computational complexity when representing and performing calculations for large-scale data problems. Experimental results based on benchmark datasets on diabetes mellitus show that the sampling method greatly reduces the calculation time while maintaining high accuracy. Moreover, the purposive random sampling method results in significantly higher accuracy than the random sampling method. Besides, the ANOVA method is also conducted to statistically validate the model. The results are significant for decision-making in the context of big data.},
  archive      = {J_APIN},
  author       = {Tan, Nguyen Hong and Long, Cu Kim and Tuan, Tran Manh and Chuan, Pham Minh and Hai, Pham Van and Khanh, Phan Hung and Son, Le Hoang},
  doi          = {10.1007/s10489-025-06381-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A novel fuzzy knowledge graph structure for decision making of multimodal big data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Instructed fine-tuning based on semantic consistency
constraint for deep multi-view stereo. <em>APIN</em>, <em>55</em>(6),
1–25. (<a href="https://doi.org/10.1007/s10489-025-06382-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing depth map-based multi-view stereo (MVS) methods typically assume that texture features remain consistent across different viewpoints. However, factors such as lighting changes, occlusions, and weakly textured regions can lead to inconsistent texture features, posing challenges for feature extraction. As a result, relying solely on texture consistency does not always yield high-quality reconstruction results in certain scenarios. In contrast, high-level semantic concepts corresponding to the same objects remain consistent across different viewpoints, which we define as semantic consistency. Since designing and training new MVS networks from scratch is both costly and labor-intensive, we propose fine-tuning existing depth map-based MVS networks during testing phase by incorporating semantic consistency constraints to improve the reconstruction quality in regions with poor results. Considering the robust open-set detection and zero-shot segmentation capabilities of Grounded-SAM, we first use Grounded-SAM to generate semantic segmentation masks for arbitrary objects in multi-view images based on text instructions. These masks are then used to fine-tune pre-trained MVS networks via aligning them from different viewpoints to the reference viewpoint and optimizing the depth maps based on the proposed semantic consistency loss function. Our method is designed as a test-time approach that is adaptable to a wide range of depth map-based MVS networks, requiring only adjustments to a small number of depth-related parameters. Comprehensive experimental evaluation across different MVS networks and large-scale scenarios demonstrates that our method effectively enhances reconstruction quality at a lower computational cost.},
  archive      = {J_APIN},
  author       = {Zhang, Yan and Yan, Hongping and Ding, Kun and Cai, Tingting and Zhou, Yueyue},
  doi          = {10.1007/s10489-025-06382-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Instructed fine-tuning based on semantic consistency constraint for deep multi-view stereo},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DropMismatch: Removing mismatched UI elements for better
pixel to code generation. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06384-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automating the generation of user interface (UI) code from design images has gained significant attention due to its potential to streamline application development. However, the effectiveness of deep learning models in this domain is often hindered by mismatches between UI images and their corresponding layout code, a common issue in image-text datasets. In this paper, we introduce a framework that locates and removes these mismatches, thereby improving the accuracy of UI code generation models. Our approach leverages a convolutional neural network to predict the alignment between UI components and layout code nodes, coupled with a tree-based heuristic algorithm to localize mismatches. Through extensive evaluation, we demonstrate that our method enhances the accuracy of UI code generation by approximately 15%, while significantly reducing the need for costly manual annotations. The proposed framework not only advances the state of automated UI code generation but also lays the foundation for creating high-quality, large-scale UI datasets, essential for future research and development in this field.},
  archive      = {J_APIN},
  author       = {Li, Ming and Lin, Tao},
  doi          = {10.1007/s10489-025-06384-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {DropMismatch: Removing mismatched UI elements for better pixel to code generation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NVS-former: A more efficient medical image segmentation
model. <em>APIN</em>, <em>55</em>(6), 1–12. (<a
href="https://doi.org/10.1007/s10489-025-06387-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the current field of medical image segmentation research, numerous Transformer-based segmentation models have emerged. However, these models often suffer from limitations in multi-scale feature extraction and struggle to capture local detail features and contextual information, thereby constraining their segmentation performance. This paper introduces a novel model for medical image segmentation, called NVS-Former, which comprises both an encoder and a decoder. The key innovation of NVS-Former lies in its redesigned core module during the encoding phase, which not only enhances feature extraction capabilities but also improves the capture of local detail information. Additionally, the decoder structure has been reengineered to further optimize the model’s class prediction abilities. NVS-Former has demonstrated superior performance in tasks involving multi-organ, pulmonary detail, and cell segmentation. In various comparative experiments, it consistently outperformed state-of-the-art methods, highlighting its efficiency and stability in medical image segmentation.},
  archive      = {J_APIN},
  author       = {Huang, Xiangdong and Huang, Junxia and Ibrahim, Noor Farizah},
  doi          = {10.1007/s10489-025-06387-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-12},
  shortjournal = {Appl. Intell.},
  title        = {NVS-former: A more efficient medical image segmentation model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A framework for solving bias in graph-based recommender
systems with a causal perspective. <em>APIN</em>, <em>55</em>(6), 1–21.
(<a href="https://doi.org/10.1007/s10489-025-06388-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems founded on graph neural networks (GNN) have been extensively employed because of their exceptional recommendation efficiency. Nevertheless, numerous recommendation biases also crop up, We have observed that delicate details such as gender and age are frequently implicitly apprehended by recommendation systems, culminating in unfair recommendations, and the associated algorithms of GNN will magnify this bias. To tackle these difficulties, this paper puts forth a method of introducing the notion of causal fairness into the issue of fairness in GNN-based recommendation systems, to accomplish counterfactual fairness of user-sensitive information and thereby attain unbiased recommendations. Specifically, given a GNN-based recommendation system model, which is implemented in our devised fairness framework, chiefly obtaining equitable effects through two facets: (1) attaining user embedding fairness through the counterfactual fairness technique; (2) mitigating the prejudiced impact caused by the GNN algorithm using the proposed central association subgraph method. The amalgamation of these two facets ultimately delivers unbiased recommendations. The effectiveness and sophistication of our proposed method for mitigating partiality problems in GNN recommendation systems from a causal perspective (MGRC) have been proven via experiments on four real-world datasets.},
  archive      = {J_APIN},
  author       = {Yang, Kewu and Li, Guogang and Wang, Linjia and Xie, Jianrong},
  doi          = {10.1007/s10489-025-06388-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {A framework for solving bias in graph-based recommender systems with a causal perspective},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PAG-unet: Multi-task dense scene understanding with
pixel-attention-guided unet. <em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06389-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task dense scene understanding is a fundamental research area in computer vision (CV). By predicting pixels, perceiving, and reasoning about multiple related tasks, it improves both accuracy and data efficiency. However, it faces the challenge that some tasks may require more independent feature representations, and excessive sharing can lead to interference between tasks. To address this issue, we propose a novel Pixel-Attention-Guided Unet (PAG-Unet). PAG-Unet incorporates a Pixel-Attention-Guided Fusion module (PAG Fusion) and a Multi-Task Self-Attention module (MTSA) to enhance task-specific feature extraction and reduce task interference. PAG Fusion leverages the relationship between shallow and deep features by using task-specific deep features to calibrate the distribution of shared shallow features. This suppresses background noise and enhances semantic features, thereby fully extracting task-specific features for different tasks and achieving feature enhancement. MTSA considers both global and local spatial interactions for each task during task interactions, capturing task-specific information and compensating for the loss of crucial details, thus improving prediction accuracy for each task. Our method achieves superior multi-task performance on the New York University Depth v2(NYUD-v2) and PASCAL Visual Object Classes Context(PASCAL-Context) datasets, with most metrics significantly outperforming previous state-of-the-art methods. The code is available at https://github.com/UPLI-123/Pag-Unet .},
  archive      = {J_APIN},
  author       = {Xu, Yi and Li, Changhao},
  doi          = {10.1007/s10489-025-06389-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {PAG-unet: Multi-task dense scene understanding with pixel-attention-guided unet},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Predicting hemodynamic parameters based on arterial blood
pressure waveform using self-supervised learning and fine-tuning.
<em>APIN</em>, <em>55</em>(6), 1–26. (<a
href="https://doi.org/10.1007/s10489-025-06391-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The arterial blood pressure waveform (ABPW) serves as a less invasive technique for evaluating hemodynamic parameters, offering a lower risk compared to the more invasive pulmonary artery catheter (PAC) thermodilution method. Various studies suggest that deep learning models can potentially predict the hemodynamic parameters of ABPW. However, the scarcity of ground truth data restricts the accuracy of these models, preventing them from gaining clinical acceptance. To mitigate this data and domain challenge, this work proposed a self-supervised generative learning model for hemodynamic parameter prediction, called SSHemo (Self-Supervised Hemodynamic model). Specifically, SSHemo suggests first to leverage large amounts of unlabeled ABPW data to learn the representative embedding and then to fine-tune for the downstream task with a small amount of hemodynamic parameters’ ground truth. To verify the effectiveness of SSHemo, we utilize the public available VitalDB data set to train the model, and evaluation was conducted on two public datasets: VitalDB and MIMIC. The experimental results reveal that SSHemo’s regression mean absolute error (MAE) improved significantly from 1.63 L/min to 1.25 L/min when predicting cardiac output (CO). The trending tracking ability for CO changes meets clinical acceptance (radial limit of agreement (LOA) is $$\pm 25.56$$ °, less than $$\pm 30$$ °). In addition, SSHemo demonstrates robust stability in various conditions and cohorts, as evidenced by subgroup analysis, varying systemic vascular resistance (SVR) range analysis, and rapid CO analysis, compared to the most widely used commercial devices, the EV1000. Computational analysis further underscores the value and potential of practical application of the model in various settings.},
  archive      = {J_APIN},
  author       = {Liao, Ke and Elibol, Armagan and Gao, Ziyan and Meng, Lingzhong and Chong, Nak Young},
  doi          = {10.1007/s10489-025-06391-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Predicting hemodynamic parameters based on arterial blood pressure waveform using self-supervised learning and fine-tuning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale contrastive learning via aggregated subgraph for
link prediction. <em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06394-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction seeks to uncover potential or future connections within a network using structural or attribute information. Recently, Graph Neural Network (GNN)-based methods have attracted considerable attention for their effectiveness in link prediction. However, most GNN-based approaches focus solely on single-scale input graphs, which limits their ability to comprehensively capture network structure information. In this paper, multi-scale subgraphs are introduced as input graphs to obtain complementary network structures from different perspectives. Simultaneously, to obtain embedding vectors with better representational capacity, contrastive loss from self-supervised learning is incorporated for link prediction. Specifically, Multi-scale Contrastive learning framework based on Aggregated Subgraph (MCAS) is proposed for predicting missing links. Firstly, we construct enclosing subgraph by extracting neighbors of target nodes. By applying aggregation operation to these subgraphs, different granularities of multi-scale subgraphs are obtained. Secondly, encoders are used to learn information from multiple scales of subgraphs separately. Next, contrastive learning is employed to achieve information balance among the multi-scale subgraphs. Finally, the minimization of the loss allows us to improve the model’s robustness. Empirical evidence indicates that our approach excels state-of-the-art methods on nine datasets, including biological and citation networks. All source code is publicly available at: https://github.com/yabingyao/MCAS4LinkPrediction .},
  archive      = {J_APIN},
  author       = {Yao, Yabing and Guo, Pingxia and Mao, Zhiheng and Ti, Ziyu and He, Yangyang and Nian, Fuzhong and Zhang, Ruisheng and Ma, Ning},
  doi          = {10.1007/s10489-025-06394-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale contrastive learning via aggregated subgraph for link prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSFL: A blockchain-based data sharing and federated learning
framework. <em>APIN</em>, <em>55</em>(6), 1–22. (<a
href="https://doi.org/10.1007/s10489-025-06400-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive amount of data generated by the proliferation of Internet of Things (IoT) devices has become one of the key factors driving the advancement of artificial intelligence (AI) technology. However, the lack of storage space and limited computational power of edge devices make it difficult to directly process large data volumes or run complex machine learning algorithms on these devices. At the same time, existing Federated Learning (FL) schemes still face a number of shortcomings, including a single point of failure, vulnerability to poisoning attacks, and a lack of incentives. To address the above issues, we propose DSFL, a blockchain-based framework for fair data sharing and FL. Specifically, we combine digital envelope technology and one-way accumulator with smart contracts to design fair, secure, and trustworthy data sharing protocols that facilitate edge devices to share data proactively, realize the value of data and reduce storage pressure. In addition, we propose blockchain extension schemes suitable for coupling with FL to improve training efficiency. Importantly, the node management mechanism and incentive algorithms are designed to effectively monitor and trace the behavior of nodes, and promote the virtuous cycle of model training and the motivation of participants. Experimental results show that DSFL is able to ensure fair data sharing and efficient model training without the involvement of trusted third parties. In particular, it is able to achieve model accuracy close to that of existing popular schemes even when 40% of the nodes are lazy, providing an excellent defense against malicious nodes.},
  archive      = {J_APIN},
  author       = {Niu, Haiqian and Zhang, Xing and Chu, Zhiguang and Shi, Wei},
  doi          = {10.1007/s10489-025-06400-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {DSFL: A blockchain-based data sharing and federated learning framework},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ROCIP: Robust continuous inertial position tracking for
complex actions emerging from the interaction of human actors and
environment. <em>APIN</em>, <em>55</em>(6), 1–10. (<a
href="https://doi.org/10.1007/s10489-025-06409-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inertial navigation is advancing rapidly due to improvements in sensor technology and tracking algorithms, with consumer-grade inertial measurement units (IMUs) becoming increasingly compact and affordable. Despite progress in pedestrian dead reckoning (PDR), IMU-based positional tracking still faces significant noise and bias issues. While traditional model-based methods and recent machine learning approaches have been employed to reduce signal drift, error accumulation remains a barrier to long-term system performance. Inertial tracking’s self-contained nature offers broad applicability but limits integration with a global reference frame. To solve this problem, a system that could “introspect its error” and “learn from the past” is proposed. It consists of a neural statistical motion model that regresses both poses and uncertainties with DenseNet, which are then fed into Rao-Blackwellised particle filter (RBPF) for calibration with a probabilistic transition map. An inertial tracking dataset with head-mounted IMUs was collected, including walking and running with different speeds while allowing participants to rotate their heads in a self-selected manner. The dataset consisted of 19 volunteers that generated 151 sequences in 4 scenarios with a total time of 929.8 min. It was shown that our proposed method (ROCIP) outperformed the leading methods in the field, with a relative trajectory error (RTE) of 4.94m and absolute trajectory error (ATE) of 4.36m. ROCIP could also solve the problem of error accumulation in dead reckoning and maintain a small and consistent error during long-term tracking.},
  archive      = {J_APIN},
  author       = {Hou, Xinyu and Bergmann, Jeroen},
  doi          = {10.1007/s10489-025-06409-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-10},
  shortjournal = {Appl. Intell.},
  title        = {ROCIP: Robust continuous inertial position tracking for complex actions emerging from the interaction of human actors and environment},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A statistical categorization-based curriculum learning
approach for multi-task classification of images. <em>APIN</em>,
<em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06270-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image classification and the detection of features within images remain significant challenges in computer vision. Several approaches, including serial task models and multi-output models, have been explored to address these challenges. This study focuses on multitasking attention mechanisms, which enable simultaneous categorization of data and tasks. By applying a statistical framework, the proposed method enhances the efficiency and accuracy of image classification and feature detection, with a focus on handling multiple tasks concurrently. To enhance the robustness of the model, a data-driven approach based on curriculum learning was proposed. The experiments were conducted using two distinct datasets. The first dataset involves forensic examinations, specifically identifying firearms and their calibers from firing pin marks. The proposed model achieved an accuracy of 95% in brand detection and 98% in caliber detection on this dataset. In the second part of the experiments, the animals with attributes 2 (AwA2) dataset, where state-of-the-art models have previously been applied, was used. The proposed model reduced classification errors by 1 to 10% compared to traditional convolutional neural network (CNN) architectures. The experimental results from both the forensic and public datasets demonstrate that the proposed model effectively handles multitask classification tasks, validating its applicability across diverse domains.},
  archive      = {J_APIN},
  author       = {Veranyurt, Ozan and Sakar, C. Okan},
  doi          = {10.1007/s10489-025-06270-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A statistical categorization-based curriculum learning approach for multi-task classification of images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adversarial network embedding with bootstrapped
representations for sparse networks. <em>APIN</em>, <em>55</em>(6),
1–22. (<a href="https://doi.org/10.1007/s10489-025-06343-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inherent sparsity of real-world networks presents challenges in learning-rich embeddings and accurately reconstructing networks. To address these challenges, a novel method termed Adversarial Network Embedding with Bootstrapped Representations (ANEBR) is proposed. Firstly, a novel network augmentation method is employed for positive sampling. ANEBR utilizes the Katz Index to extract higher-order latent information and refines it with $$\alpha $$ -entmax. The crucial information is extracted while minimizing noise generation. Secondly, ANEBR circumvents negative sampling by learning bootstrapped representations. Building on bootstrapped representations from the BYOL algorithm, ANEBR incorporates the GAN techniques to align the learned embeddings nonlinearly. Finally, ANEBR attains accurate network reconstruction by imposing a low-rank constraint on the reconstruction error through the nuclear norm. Extensive experiments with statistical and sensitivity analyses demonstrate that ANEBR outperforms state-of-the-art methods in various tasks. Specifically, ANEBR reconstructs the PPI network with a precision of 0.9992, marking a relative improvement of 6.65%. Code is available at https://github.com/wuzelong/ANEBR .},
  archive      = {J_APIN},
  author       = {Wu, Zelong and Wang, Yidan and Lin, Guoliang and Liu, Junlong},
  doi          = {10.1007/s10489-025-06343-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Adversarial network embedding with bootstrapped representations for sparse networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust hierarchical clustering algorithm for automatic
identification of clusters. <em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06376-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aggregation-based hierarchical clustering algorithms are widely used in data analysis due to their robust clustering performance. Although some existing hierarchical clustering methods can identify the number of clusters in a dataset, most are only effective for well-separated clusters and struggle to identify the number of clusters in complex datasets, particularly non-convex noisy datasets. To address these shortcomings, this paper proposes a robust hierarchical clustering algorithm for automatic identification of clusters(RHCAIC), which can identify the optimal number of clusters while providing reliable clustering results. To reduce the impact of noise in clustering, the method first calculates reverse density and designs a dynamic noise discriminator to denoise the dataset. Based on the fact that more similar points have a higher probability of being clustered into the same cluster among multiple results of hierarchical clustering, a robust solution was designed. After constructing a directed graph using the kNN algorithm, the graph merging process is performed by iteratively traversing the directed edges. During this process, the number of clusters is identified, and the clustering results of the denoised dataset are obtained. Finally, by incorporating density information into the noise clustering, the final clustering results are obtained. A series of experiments conducted on 12 synthetic datasets and 8 real datasets demonstrate that, compared to seven other benchmark algorithms, the RHCAIC algorithm not only accurately identifies the number of clusters in the dataset but also produces better clustering results.},
  archive      = {J_APIN},
  author       = {Long, Jianwu and Wang, Qiang and Liu, Luping},
  doi          = {10.1007/s10489-025-06376-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A robust hierarchical clustering algorithm for automatic identification of clusters},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating potential causes of sepsis with bayesian
network structure learning. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06405-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sepsis is a life-threatening and serious global health issue. This study combines knowledge with available hospital data to investigate the potential causes of Sepsis that can be affected by policy decisions. We investigate the underlying causal structure of this problem by combining clinical expertise with score-based, constraint-based, and hybrid structure learning algorithms. A novel approach to model averaging and knowledge-based constraints was implemented to arrive at a consensus structure for causal inference. The structure learning process highlighted the importance of exploring data-driven approaches alongside clinical expertise. This includes discovering unexpected, although reasonable, relationships from a clinical perspective. Hypothetical interventions on Chronic Obstructive Pulmonary Disease, Alcohol dependence, and Diabetes suggest that the presence of any of these risk factors in patients increases the likelihood of Sepsis. This finding, alongside measuring the effect of these risk factors on Sepsis, has potential policy implications. Recognising the importance of prediction in improving health outcomes related to Sepsis, the model is also assessed in its ability to predict Sepsis by evaluating accuracy, sensitivity, and specificity. These three indicators all had results around 70%, and the AUC was 80%, which means the causal structure of the model is reasonably accurate given that the models were trained on data available for commissioning purposes only.},
  archive      = {J_APIN},
  author       = {Petrungaro, Bruno and Kitson, Neville K. and Constantinou, Anthony C.},
  doi          = {10.1007/s10489-025-06405-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Investigating potential causes of sepsis with bayesian network structure learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual-channel graph-level anomaly detection method based on
multi-graph representation learning. <em>APIN</em>, <em>55</em>(6),
1–16. (<a href="https://doi.org/10.1007/s10489-024-05852-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-level anomaly detection plays a crucial role in anomaly identification by comparing and classifying the graph-level features of normal and anomalous graphs. Despite advancements, existing methods often suffer from low detection rates and high false-positive rates when dealing with sparse anomalous data. To address this limitation, we propose a dual-channel graph-level anomaly detection model that utilizes two graph isomorphic networks to separately learn from labeled anomalous data and unlabeled normal data. This model enhances the identification of unlabeled anomalies by learning from both types of data through separate channels. Furthermore, to enable the model to be applicable to complex graph types in graph-level anomaly detection applications, we introduce a novel multi-graph representation learning method that can transform multi-graphs into a simplified graph representation. We have rigorously evaluated the proposed model on 6 public datasets, and the experimental results demonstrate the effectiveness of the model, with significant performance improvements over 9 baseline models.},
  archive      = {J_APIN},
  author       = {Jing, Yongjun and Wang, Hao and Chen, Jiale and Chen, Xu},
  doi          = {10.1007/s10489-024-05852-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Dual-channel graph-level anomaly detection method based on multi-graph representation learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3D-FaIR: 3D facial imperfection regeneration with defects by
fully convolutional mesh autoencoder. <em>APIN</em>, <em>55</em>(6),
1–15. (<a href="https://doi.org/10.1007/s10489-024-05880-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces an effective approach using a fully convolutional mesh autoencoder model to reconstruct 3D facial features in the presence of imperfections. The method accurately simulates facial scars in a virtual environment, adapting to unique situations. This article presents the “Cir3D-FaIR” dataset, which is specifically tailored to address issues related to facial scars. Additionally, we propose a new technique called 3D facial imperfection regeneration (3D-FaIR), which focusses on reconstructing a complete face based on the remaining features of the patient’s face. To further enhance the applicability of this research, the article has developed an advanced outlier detection technique that isolates affected areas and provides appropriate models for wound coverage. The Cir3D-FaIR dataset, consisting of imperfect facial models and open-source package, is available at https://github.com/SIMOGroup/3DFaIR . Our findings demonstrate that the proposed approach can potentially aid in faster and safer patient recovery through convenient methods. We hope that this work inspires the development of new products and innovative solutions for facial scar regeneration.},
  archive      = {J_APIN},
  author       = {Nguyen, Phuong D. and Le, Thinh D. and Nguyen, Duong Q. and Nguyen, Thanh Q. and Chou, Li-Wei and Nguyen-Xuan, H.},
  doi          = {10.1007/s10489-024-05880-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {3D-FaIR: 3D facial imperfection regeneration with defects by fully convolutional mesh autoencoder},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An online self-organizing radial basis function neural
network based on gaussian membership. <em>APIN</em>, <em>55</em>(6),
1–17. (<a href="https://doi.org/10.1007/s10489-024-05989-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radial basis function neural network (RBFNN) is one of the most popular neural networks, and an appropriate selection of its structure and learning algorithms is crucial for its performance. Aiming to alleviate the sensitivity of the RBFNN to its parameters and improve the overall performance of the network, this study proposes a Gaussian Membership-based online self-organizing RBF neural network (GM-OSRBFNN). First, the Gaussian Membership is introduced to enhance network insensitivity to network parameters and used as a similarity metric to indicate the similarity between the sample to a hidden neuron and that between hidden neurons. Second, the similarity metric is used to design the neuron addition and merging rules to achieve a self-organizing network structure, and error constraints are introduced to the neuron addition rule; also, the noisy neuron deletion rule is defined to make the network structure more compact. In addition, an online fixed mini-batch gradient algorithm is used for online learning of network parameters, which can guarantee fast and stable convergence of the network. Finally, the proposed GM-OSRBFNN is tested on common nonlinear system modeling problems to verify its effectiveness. The experimental results show that compared to the existing models, the GM-OSRBFNN can achieve competitive prediction performance with a more compact network structure, faster convergence speed, and, more importantly, better insensitivity to network parameters.},
  archive      = {J_APIN},
  author       = {Jia, Lijie and Li, Wenjing and Qiao, Junfei and Zhang, Xinliang},
  doi          = {10.1007/s10489-024-05989-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {An online self-organizing radial basis function neural network based on gaussian membership},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel recurrent neural network with transformer for
anomalous trajectory detection. <em>APIN</em>, <em>55</em>(6), 1–19. (<a
href="https://doi.org/10.1007/s10489-024-06069-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomalous trajectory detection within urban road traffic networks is crucial for identifying operational vehicle fraud in intelligent transportation systems. However, most existing approaches are limited to detecting anomalous trajectories solely based on the same original point, neglecting the extraction of spatiotemporal features and contextual information embedded in trajectory data. To address these limitations, a Parallel Recurrent Neural Network with Transformer (PRNNT) model is proposed for anomalous trajectory detection. Specifically, the position embedding and a transformer encoder module are utilized to train trajectory embeddings, allowing the model to learn sequential features and contextual information of trajectories. Moreover, a parallel recurrent neural network is employed to extract hidden trajectory features, capturing the differences between normal and anomalous trajectories. Finally, a linear layer is applied to fuse the spatiotemporal features and output the probability of an anomalous trajectory, enhancing the detection of vehicle trajectory anomalies. Experimental results on Beijing and Porto datasets demonstrate that the proposed PRNNT model significantly outperforms the iBAT (Isolation-Based Anomalous Trajectory), ATDC (Anomalous Trajectory Detection and Classification), ATD-RNN (Anomalous Trajectory Detection using Recurrent Neural Network), XGBoost (Extreme Gradient Boosting), GM-VSAE (Gaussian Mixture Variational Sequence AutoEncoder), and UA-OATD (Deep Unified Attention-based Sequence Modeling for Online Anomalous Trajectory Detection) models, achieving at least a 3.8%, 22.7%, 3.8%, 22.7%, 15%, and 16.7% improvement in F1-score, respectively.},
  archive      = {J_APIN},
  author       = {Xia, Dawen and Li, Yunsong and Ao, Yuce and Wei, Xiaoduo and Chen, Yan and Hu, Yang and Li, Yantao and Li, Huaqing},
  doi          = {10.1007/s10489-024-06069-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Parallel recurrent neural network with transformer for anomalous trajectory detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction to: Implicit regularization of a deep augmented
neural network model for human motion prediction. <em>APIN</em>,
<em>55</em>(6), 1. (<a
href="https://doi.org/10.1007/s10489-024-06148-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_APIN},
  author       = {Yadav, Gaurav Kumar and Abdel-Nasser, Mohamed and Rashwan, Hatem A. and Puig, Domenec and Nandi, G. C.},
  doi          = {10.1007/s10489-024-06148-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1},
  shortjournal = {Appl. Intell.},
  title        = {Correction to: Implicit regularization of a deep augmented neural network model for human motion prediction},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention-based spatial-temporal synchronous graph
convolution networks for traffic flow forecasting. <em>APIN</em>,
<em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06341-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic flow forecasting is crucial for urban traffic control, planning, and detection. Most existing spatial-temporal modeling methods overlook the hidden dynamic correlations between road network nodes and the time series nonstationarity while synchronously capturing complex long- and short-term spatial-temporal dependencies. To this end, this paper proposes an Attention-based Spatial-Temporal Synchronous Graph Convolutional Network (AST-SGCN) to capture complex spatial-temporal correlations over long and short terms. Specifically, we design a self-attention mechanism that utilizes spatial-temporal synchronous computation to efficiently mine dynamic spatial-temporal correlations with changes in traffic and enhance computational efficiency. Then, we construct a residual adaptive adjacency matrix, which includes historical data and node vectors, to stimulate the information transfer of spatial-temporal graph nodes and mine the hidden spatial-temporal dependencies through the graph convolution layer. Next, we establish a Fourier transform layer (FTL) to handle the nonstationary data. Finally, we develop a spatial-temporal hybrid stacking module for capturing complex long-term spatial-temporal correlations, within which two layers of graph convolution and one layer of self-attention are deployed. Extensive experimental results on three real-world traffic flow datasets demonstrate that our AST-SGCN model outperforms the comparable models.},
  archive      = {J_APIN},
  author       = {Wei, Xiaoduo and Xia, Dawen and Li, Yunsong and Ao, Yuce and Chen, Yan and Hu, Yang and Li, Yantao and Li, Huaqing},
  doi          = {10.1007/s10489-025-06341-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Attention-based spatial-temporal synchronous graph convolution networks for traffic flow forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DARTS-EAST: An edge-adaptive selection with topology first
differentiable architecture selection method. <em>APIN</em>,
<em>55</em>(6), 1–13. (<a
href="https://doi.org/10.1007/s10489-025-06353-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DARTS+PT is a well-known differentiable neural architecture search (NAS) method that evaluates the contribution of operations to the performance of the super-network, ultimately deriving the final architecture. However, DARTS+PT introduces randomness into the edge discretization process by selecting edges randomly, which leads to performance instability. Moreover, the method assesses the impact of each candidate operation by iteratively removing them and measuring the resulting drop in super-network performance, leading to a high search cost. To address these issues, this paper identifies the root cause of instability and proposes a novel edge selection criterion to establish an adaptive edge discretization order, improving stability. Additionally, we introduce a topology-first discretization scheme that prioritizes topology selection over operation selection, significantly reducing the search cost. We name this approach DARTS-EAST (Edge-Adaptive Selection with Topology-First Differentiable Architecture Selection). Extensive experiments on widely used benchmarks demonstrate that DARTS-EAST not only achieves competitive performance but also offers significant improvements in both stability and search efficiency.},
  archive      = {J_APIN},
  author       = {Fang, Xuwei and Xie, Weisheng and Li, Hui and Zhou, Wenbin and Hang, Chen and Gao, Xiangxiang},
  doi          = {10.1007/s10489-025-06353-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-13},
  shortjournal = {Appl. Intell.},
  title        = {DARTS-EAST: An edge-adaptive selection with topology first differentiable architecture selection method},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TANGAN: Solving tangram puzzles using generative adversarial
network. <em>APIN</em>, <em>55</em>(6), 1–27. (<a
href="https://doi.org/10.1007/s10489-025-06364-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While humans show remarkable proficiency in solving visual puzzles, machines often fall short due to the complex combinatorial nature of such tasks. Consequently, there is a growing interest in developing computational methods for the automatic solution of different puzzles, especially through deep learning approaches. The Tangram, an ancient Chinese puzzle, challenges players to arrange seven polygonal pieces to construct different patterns. Despite its apparent simplicity, solving the Tangram is considered an NP-complete problem, being a challenge even for the most sophisticated algorithms. Moreover, ensuring the generality and adaptability of machine learning models across different Tangram arrangements and complexities is an ongoing research problem. In this paper, we introduce a generative model specifically designed to solve the Tangram. Our model competes favorably with previous methods regarding accuracy while delivering fast inferences. It incorporates a novel loss function that integrates pixel-based information with geometric features, promoting a deeper understanding of the spatial relationships between pieces. Unlike previous approaches, our model takes advantage of the geometric properties of the Tangram to formulate a solving strategy, exploiting its inherent properties only through exposure to training data rather than through direct instruction. Extending the proposed loss function, we present a novel evaluation metric as a better fitting measure for assessing Tangram solutions than previous metrics. We further provide a new dataset containing more samples than others reported in the literature. Our findings highlight the potential of deep learning approaches in geometric problem domains.},
  archive      = {J_APIN},
  author       = {Yamada, Fernanda Miyuki and Batagelo, Harlen Costa and Gois, João Paulo and Takahashi, Hiroki},
  doi          = {10.1007/s10489-025-06364-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-27},
  shortjournal = {Appl. Intell.},
  title        = {TANGAN: Solving tangram puzzles using generative adversarial network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Batch process quality prediction based on denoising
autoencoder-spatial temporal convolutional attention mechanism fusion
network. <em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06368-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In batch processes, the accurate prediction of quality variables plays a crucial role in smooth production and quality control. However, various sources of noise in the production environment cause abnormal data fluctuations that deviate from the real value. Coupled with the dynamic nonlinearity of batch processing and the complex spatiotemporal relationship of variables, which greatly increase the difficulty of prediction and pose a severe challenge to prediction performance. Therefore, a denoising autoencoder-Spatial Temporal Convolution Attention Fusion Network (DAE-STCAFN) prediction method is proposed. Firstly, combining DAE and maximum information coefficient (MIC), multi-level data features are extracted to prepare high-quality input data for the quality prediction model. DAE is used to denoise the original data, and relevant variables are selected through MIC. Then, an augmented matrix is constructed to eliminate the autocorrelation of the selected variables in the time series. Secondly, a spatial temporal convolutional attention fusion mechanism is created to extract the spatial temporal fusion features between the input and output variable sequences. Thirdly, to further enhance the learning ability of the model, a batch attention module is constructed to automatically learn the relationship among sample in small batch. Finally, experiments were carried out on the simulation platform of penicillin fermentation and hot tandem rolling process. In the prediction process of penicillin concentration, RMSE and MAE of the proposed method were 0.0099 and 0.0077, respectively. In the prediction of strip thickness, the RMSE and MAE are 0.0008 and 0.0003 respectively. The results show that the proposed method is effective both in simulation experiment and in actual industrial production in terms of prediction accuracy, stability and generalization ability.},
  archive      = {J_APIN},
  author       = {Zhang, Yan and Cao, Jie and Zhao, Xiaoqiang and Hui, Yongyong},
  doi          = {10.1007/s10489-025-06368-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Batch process quality prediction based on denoising autoencoder-spatial temporal convolutional attention mechanism fusion network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). High-order consensus graph learning for incomplete
multi-view clustering. <em>APIN</em>, <em>55</em>(6), 1–25. (<a
href="https://doi.org/10.1007/s10489-025-06375-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete Multi-View Clustering (IMVC) aims to partition data with missing samples into distinct groups. However, most IMVC methods rarely consider the high-order neighborhood information of samples, which represents complex underlying interactions, and often neglect the weights of different views. To address these issues, we propose a High-order Consensus Graph Learning (HoCGL) model. Specifically, we integrate a reconstruction term to recover the incomplete multi-view data. High-order proximity matrices are constructed, and the self-representation similarity matrices and multiple high-order proximity matrices are learned mutually, allowing the similarity matrices to incorporate complex high-order information. Finally, the consensus graph representation is derived from the similarity matrices through a self-weighted strategy. An efficient algorithm is designed to solve the proposed model. The excellent clustering performance of the proposed model is validated by comparing it with eight state-of-the-art models across nine datasets.},
  archive      = {J_APIN},
  author       = {Guo, Wei and Che, Hangjun and Leung, Man-Fai},
  doi          = {10.1007/s10489-025-06375-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {High-order consensus graph learning for incomplete multi-view clustering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). StackMFF: End-to-end multi-focus image stack fusion network.
<em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06383-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing end-to-end multi-focus image fusion (MFF) networks demonstrate excellent performance when fusing image pairs. However, when image stacks are processed, the necessity for iterative fusion leads to error accumulation, resulting in various types and degrees of image degradation, which ultimately limits the algorithms’ practical applications. To address this challenge and expand the application scenarios of multi-focus fusion algorithms, we propose a relatively simple yet effective approach: utilizing 3D convolutional neural networks to directly model and fuse entire multi-focus image stacks in an end-to-end manner. To obtain large-scale training data, we developed a refocusing pipeline based on monocular depth estimation technology that can synthesize a multi-focus image stack from any all-in-focus image. Furthermore, we extended the attention mechanisms commonly used in image pair fusion networks from two dimensions to three dimensions and proposed a comprehensive loss function group, effectively enhancing the fusion quality. Extensive experimental results demonstrate that the proposed method achieves state-of-the-art performance in both fusion quality and processing speed while avoiding image degradation issues, establishing a simple yet powerful baseline for the multi-focus image stack fusion task. The codes are available at https://github.com/Xinzhe99/StackMFF .},
  archive      = {J_APIN},
  author       = {Xie, Xinzhe and Qingyan, Jiang and Chen, Dong and Guo, Buyu and Li, Peiliang and Zhou, Sangjun},
  doi          = {10.1007/s10489-025-06383-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {StackMFF: End-to-end multi-focus image stack fusion network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructive sample partition-based parameter-free sampling
for class-overlapped imbalanced data classification. <em>APIN</em>,
<em>55</em>(6), 1–29. (<a
href="https://doi.org/10.1007/s10489-025-06385-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data widely exists in real applications ranging from medical diagnosis to economic fraud detection, etc. Data level method is one of the prevalent methods to deal with imbalanced data by re-balancing the distribution between different classes. Recent researches reveal that handling the class-overlapping of imbalanced data when designing data-level approach can effectively improve the performance of imbalanced learning. However, most existing data-level methods rely on specific parameters to obtain desired performance, making them hard to generalize to other scenarios. And the intractable data difficulty factors, i.e., the most frequent class-overlapping problem, makes them confront additional challenges. Designing efficient, flexible method that considers the parameter-free designing and the class-overlapping handling simultaneously remains a challenge. This paper proposes to deal with the class-overlapped imbalanced data with parameter-free adaptive method. To be specific, we first propose a parameter-free constructive sample partition (CSP) method, and then design an adaptive parameter-free CSP-based undersampling method (CSPUS) and an adaptive parameter-free CSP-based hybrid sampling method (CSPHS) to balance the class distribution by handling the class-overlap of the original data. Numerical experiments on 18 representative high-overlap imbalanced datasets from KEEL repository and 23 state-of-the-art comparison methods demonstrate the effectiveness of CSPUS and CSPHS. The source code of our proposed methods is available at https://github.com/ytyancp/CSPS.},
  archive      = {J_APIN},
  author       = {Wang, Weiqing and Yan, Yuanting and Zhou, Peng and Zhao, Shu and Zhang, Yiwen},
  doi          = {10.1007/s10489-025-06385-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-29},
  shortjournal = {Appl. Intell.},
  title        = {Constructive sample partition-based parameter-free sampling for class-overlapped imbalanced data classification},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evaluation of traditional machine learning algorithms for
featuring educational exercises. <em>APIN</em>, <em>55</em>(6), 1–25.
(<a href="https://doi.org/10.1007/s10489-025-06386-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) algorithms are important in educational environments, and the use of machine learning algorithms to evaluate and improve the quality of education. Previous studies have individually analyzed algorithms to estimate item characteristics, such as grade, number of attempts, and time from student interactions. By contrast, this study integrated all three characteristics to discern the relationships between attempts, time, and performance in educational exercises. We analyzed 15 educational assessments using different machine learning algorithms, specifically 12 for regression and eight for classification, with different hyperparameters. This study used real student interaction data from Zenodo.org, encompassing over 150 interactions per exercise, to predict grades and to improve our understanding of student performance. The results show that, in regression, the Bayesian ridge regression and random forest regression algorithms obtained the best results, and for the classification algorithms, Random Forest and Nearest Neighbors stood out. Most exercises in both scenarios involved more than 150 student interactions. Furthermore, the absence of a pattern in the variables contributes to suboptimal outcomes in some exercises. The information provided makes it more efficient to enhance the design of educational exercises.},
  archive      = {J_APIN},
  author       = {Jiménez-Macías, Alberto and Muñoz-Merino, Pedro J. and Moreno-Marcos, Pedro Manuel and Kloos, Carlos Delgado},
  doi          = {10.1007/s10489-025-06386-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {Evaluation of traditional machine learning algorithms for featuring educational exercises},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Prediction of reservoir water levels via an improved
attention mechanism based on CNN − LSTM. <em>APIN</em>, <em>55</em>(6),
1–20. (<a href="https://doi.org/10.1007/s10489-025-06393-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water level prediction is crucial for flood control scheduling and water resource management. The application of various deep learning methods to water level prediction in reservoirs is limited. Accurate water level prediction aids in optimizing reservoir operation strategies, ensuring flood safety downstream and meeting water supply demands. To achieve accurate predictions, a new structure based on a convolutional neural network − long short-term memory (CNN − LSTM) model is proposed, which incorporates a self-attention mechanism and a local attention mechanism in an SL − CNN − LSTM coupled model. Using the Three Gorges Reservoir head area in China as a case study, hydrometeorological data from three points in the reservoir&#39;s head area and upstream water level characteristics are used as input variables. Data collected every six hours from 2008 to 2021 were used, with the model trained and tested at an 8:2 ratio. The study revealed that a two-layer CNN configuration performed best in most models. The SL − CNN − LSTM-2 model achieved the best performance across all the metrics, with an R2 of 0.9988, an MAE of 0.2767, an RMSE of 0.3404, and a MAPE of 0.1717, particularly for extreme water level predictions with minimal residuals, validating its strong ability to balance long- and short-term dependencies. Additionally, the model effectively extracts features and captures critical information in time series data, balancing learning capacity and computational efficiency. The research results are highly important for water resource management in large reservoirs, providing reliable technical support for flood control scheduling and water resource optimization.},
  archive      = {J_APIN},
  author       = {Li, Haoran and Zhang, Lili and Yao, Yunsheng and Zhang, Yaowen},
  doi          = {10.1007/s10489-025-06393-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Prediction of reservoir water levels via an improved attention mechanism based on CNN − LSTM},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A personalized consensus-reaching method for large-group
decision-making in social networks combining self-confidence and trust
relationships. <em>APIN</em>, <em>55</em>(6), 1–24. (<a
href="https://doi.org/10.1007/s10489-025-06395-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, large-scale group decision-making (LSGDM) in social network environments considering experts’ psychological behaviors has received increasing attention. Moreover, existing studies have shown that whether it is internal self-confidence or external trust relationships of experts, they play a crucial role in reaching consensus. Therefore, this paper integrates self-confidence and trust relationships, and proposes a personalized consensus-reaching method for LSGDM from the perspective of adjustment willingness. Firstly, we explored the promoting effect of opinion similarity on the efficiency of trust propagation and proposed a method to evaluate unknown trust relationships among experts, integrating the objectivity of trust relationships and the subjectivity of self-confidence to determine the experts’ weights. Secondly, a hierarchical fuzzy clustering algorithm based on the chi-square test is proposed for effective subgroup division, which avoids the impact of setting initial clustering parameters on the clustering results. Afterwards, the adjustment willingness of the subgroups is determined by combining the experts’ self-confidence and the trust relationships between them. In addition to this, a personalized consensus feedback adjustment mechanism that synthesizes the adjustment willingness and trust relationship is constructed to reach consensus, which can better preserve the original information. Finally, the effectiveness of the proposed method is verified through a numerical example. In addition, the advantages of the proposed method are demonstrated by comparing with other methods.},
  archive      = {J_APIN},
  author       = {Liu, Zhengmin and Ding, Ruxue and Wang, Wenxin and Liu, Peide and Gao, Shanshan},
  doi          = {10.1007/s10489-025-06395-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {A personalized consensus-reaching method for large-group decision-making in social networks combining self-confidence and trust relationships},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Pursuit-evasion game with online planning using deep
reinforcement learning. <em>APIN</em>, <em>55</em>(6), 1–17. (<a
href="https://doi.org/10.1007/s10489-025-06396-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pursuit-evasion with round-up is a problem where multiple pursuers aim to capture a moving target within a specific encirclement to prevent its escape. In this paper, multi-UAV pursuit-evasion algorithms in obstacle environments are investigated and deployed on real-world micro quadcopters. In order to guide pursuers in quickly avoiding obstacles and swiftly approaching the evader, an end-to-end distributed reinforcement learning framework is proposed, and a two-stage reward function is designed. Building upon this, a MADDPG framework based on a trajectory prediction network is constructed to assist pursuers in completing round-up more quickly. Furthermore, unlike most reinforcement learning algorithms, the proposed algorithm is deployed onto a micro quadcopter controller, and a pursuit-evasion game is conducted in a real-world scenario. The results of simulations and physical experiments show that the proposed algorithm can complete round-up more quickly and can be successfully transferred to the real world.},
  archive      = {J_APIN},
  author       = {Chen, Yong and Shi, Yu and Dai, Xunhua and Meng, Qing and Yu, Tao},
  doi          = {10.1007/s10489-025-06396-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {Pursuit-evasion game with online planning using deep reinforcement learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The improved mountain gazelle optimizer for spatiotemporal
support vector regression: A novel method for railway subgrade
settlement prediction integrating multi-source information.
<em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06397-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uneven settlement of railway subgrades not only affects the comfort of train operations but, in extreme cases, may compromise operational safety. As a result, accurately predicting subgrade settlement is crucial for maintaining both safety and operational efficiency. This study introduces an Improved Mountain Gazelle Optimizer for the Spatiotemporal Support Vector Regression (IMGO-STSVR) model, which effectively predicts railway subgrade settlement. Data are collected using Permanent Scatterer Interferometric Synthetic Aperture Radar (PS-InSAR) technology in combination with a multi-source environmental monitoring system. The proposed improvement to the Mountain Gazelle Optimizer (IMGO) enhances the model’s optimization capabilities, while the Support Vector Regression model is improved by the constructed spatiotemporal kernel function (STSVR). Experimental results demonstrate that the IMGO-STSVR model achieves high accuracy and stability across various experimental sites. This method provides valuable insights for predicting subgrade settlement in the railway industry, aiding in the early identification of potential risks, optimizing maintenance strategies, and ensuring the safe and efficient operation of rail transport.},
  archive      = {J_APIN},
  author       = {Chen, Guangwu and Zhao, Shilin and Li, Peng and Wang, Shilin and Zhou, Xin and Potekhin, Vyacheslav},
  doi          = {10.1007/s10489-025-06397-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {The improved mountain gazelle optimizer for spatiotemporal support vector regression: A novel method for railway subgrade settlement prediction integrating multi-source information},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention ensemble mixture: A novel offline reinforcement
learning algorithm for autonomous vehicles. <em>APIN</em>,
<em>55</em>(6), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06403-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline Reinforcement Learning (RL), which optimizes policies from previously collected datasets, is a promising approach for tackling tasks where direct interaction with the environment is infeasible due to high risk or cost of errors, such as autonomous vehicle (AV) applications. However, offline RL faces a critical challenge: extrapolation errors arising from out-of-distribution (OOD) data. In this paper, we propose Attention Ensemble Mixture (AEM), a novel offline RL algorithm that leverages ensemble learning and an attention mechanism. Ensemble learning enhances the confidence of Q-function predictions, while the attention mechanism evaluates the uncertainty of selected actions. By assigning appropriate attention weights to each Q-head, AEM effectively down-weights OOD actions and up-weights in-distribution actions. We further introduce three key improvements to enhance the robustness and generality of AEM: attention-weighted Bellman backups, KL divergence regularization, and delayed attention updates. Extensive comparative experiments demonstrate that AEM outperforms several state-of-the-art ensemble offline RL algorithms, while ablation studies underscore the significance of the proposed enhancements. In AV tasks, AEM exhibits superior performance compared to other methods, excelling in both offline and online evaluations.},
  archive      = {J_APIN},
  author       = {Han, Xinchen and Afifi, Hossam and Moungla, Hassine and Marot, Michel},
  doi          = {10.1007/s10489-025-06403-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Attention ensemble mixture: A novel offline reinforcement learning algorithm for autonomous vehicles},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning missing instances in intact and projection spaces
for incomplete multi-view unsupervised feature selection. <em>APIN</em>,
<em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06406-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view unsupervised feature selection has achieved great success in identifying a subset of prominent features from multi-view data to produce compact and meaningful representations. However, most existing methods assume that all data views are complete, which is often not the case in real-world scenarios. Multi-view data is frequently incomplete, with some instances missing in certain views. To address this issue, we propose an incomplete multi-view unsupervised feature selection model based on multiple space learning, termed Learning Missing Instances in Intact and Projection Spaces for Incomplete Multi-view Unsupervised Feature Selection (LIPS). This model integrates intact latent space learning, projection space learning, missing instance imputation, and correlation structure learning into a joint framework. Specifically, LIPS employs intact latent space learning to generate intact representations that capture the full information of multi-view data. Using these representations, LIPS calculates correlations between data through a constrained self-expression strategy, generating a sparse correlation matrix where each row contains few non-zero entries, signifying that each data point can be linearly reconstructed using only a small subset of related neighbors. Subsequently, LIPS projects data into low-dimensional spaces to retain the neighborhood correlations. Finally, it leverages complementary information to impute the missing instances from a cross-view perspective based on intact representations and utilizes neighborhood information to generate neighborhood-smooth imputations for missing instances from view-specific perspectives. Additionally, an effective algorithm is developed to resolve the optimization problem. Extensive experiments conducted on six public datasets of different types, including image datasets (MSRC-v1, Caltech101-7, and CIFAR-10), text datasets (BBCSport and WebKB), and a face dataset (Yale), measured by Acc and NMI, demonstrate that the proposed LIPS outperforms state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Wu, Jian-Sheng and Yu, Hong-Wei and Li, Yanlan and Min, Weidong},
  doi          = {10.1007/s10489-025-06406-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Learning missing instances in intact and projection spaces for incomplete multi-view unsupervised feature selection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-like synthetic sperm video generation from learned
behaviors. <em>APIN</em>, <em>55</em>(6), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06407-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-assisted sperm analysis is an open research problem, and a main challenge is how to test its performance. Deep learning techniques have boosted computer vision tasks to human-level accuracy, when sufficiently large labeled datasets were provided. However, when it comes to sperm (either human or not) there is lack of sufficient large datasets for training and testing deep learning systems. In this paper we propose a solution that provides access to countless fully annotated and realistic synthetic video sequences of sperm. Specifically, we introduce a parametric model of a spermatozoon, which is animated along a video sequence using a denoising diffusion probabilistic model. The resulting videos are then rendered with a photo-realistic appearance via a style transfer procedure using a CycleGAN. We validate our synthetic dataset by training a deep object detection model on it, achieving state-of-the-art performance once validated on real data. Additionally, an evaluation of the generated sequences revealed that the behavior of the synthetically generated spermatozoa closely resembles that of real ones.},
  archive      = {J_APIN},
  author       = {Hernández-García, Sergio and Cuesta-Infante, Alfredo and Makris, Dimitrios and S. Montemayor, Antonio},
  doi          = {10.1007/s10489-025-06407-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Real-like synthetic sperm video generation from learned behaviors},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dense image-mask attention-guided transformer network for
jaw lesions classification and segmentation in dental cone-beam computed
tomography images. <em>APIN</em>, <em>55</em>(6), 1–26. (<a
href="https://doi.org/10.1007/s10489-025-06408-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation and classification of jaw lesions from cone-beam computed tomography (CBCT) images are crucial in computer-assisted diagnosis and treatment planning for oral and maxillofacial (OMF) surgery. However, the evolutionary nature of jaw lesions and their morphological diversity pose significant challenges to both segmentation and classification tasks. Although existing deep learning-based works have achieved promising results on segmentation and classification of other types of lesions, they often consider the two tasks separately, thereby overlooking the strong guidance that lesion masks can provide in determining lesion categories. In this manuscript, we propose a dense image-mask attention-guided transformer network for end-to-end jaw lesions classification and segmentation in 3D CBCT images based on a multi-task learning (MTL) architecture. Specifically, we design multi-dimension attention (MDA) and multi-scale attention (MSA) modules to incorporate dense features from different dimensions and scales, explicitly enhancing the guidance of lesion segmentation for classification decisions. Furthermore, to effectively encode long-term contextual information, we employ a transformer as the classification decoder and design a 3D positional embedding method to preserve the 3D positional information of sequential feature inputs for the transformer. Finally, we design a task merge module that employs a per-lesion inference strategy to assign a category to each lesion instance. A large in-house dataset consisting of 358 CBCT scans with five types of jaw lesions is constructed to evaluate the proposed method. The experimental results show a binary segmentation DICE score of 90%, a mean classification accuracy of 89.23%, and a multi-class segmentation DICE score of 79.06%, surpassing many state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Li, Xiang and Liu, Wei and Tang, Wei and Guo, Jixiang},
  doi          = {10.1007/s10489-025-06408-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-26},
  shortjournal = {Appl. Intell.},
  title        = {Dense image-mask attention-guided transformer network for jaw lesions classification and segmentation in dental cone-beam computed tomography images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NTFNet: Narrowing-then-fusing network for RGB-TIR semantic
segmentation. <em>APIN</em>, <em>55</em>(6), 1–24. (<a
href="https://doi.org/10.1007/s10489-025-06411-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the task of understanding scenes in visible (RGB) and thermal-infrared (TIR) images has garnered increasing interest in the field of computer vision. However, most existing methods employ simplistic fusion strategies to merge features from different modalities. These strategies often overlook the differences in shallow-level features between modalities, thereby reducing the discriminability of the fused features and resulting in suboptimal segmentation performance. To address this issue, we present a novel RGB-TIR semantic segmentation framework, named NTFNet. This framework exploits the potential consistency of semantic-level features to rectify shallow-level features and reduce discrepancies between modalities prior to integration. Specifically, auxiliary encoders are employed at each layer to capture semantically consistent information. To obtain rich multi-modal semantic features, we designed a High-Level Feature Fusion Module (HFFM) that enhances feature representation in both channel and spatial dimensions. Subsequently, the Shallow Feature Difference Rectification Module (SFDRM) is introduced to rectify the difference in shallow-level features. To address the loss of detailed information during the rectification process, the SFDRM incorporates a Detail Attention Mechanism (DAM) to preserve the original detail information, thereby further optimizing the final segmentation results. In the end, a Multi-Scale Feature Fusion module (Multi-Scale FFM) is designed to combine the rectified features. Comprehensive experiments on two public RGB-TIR datasets show that our method significantly outperforms other state-of-the-art approaches in terms of performance.},
  archive      = {J_APIN},
  author       = {Liu, Yichen and Ye, Junjie and He, Wangpeng and Qu, Zhiqiang and Xu, Ruoxuan},
  doi          = {10.1007/s10489-025-06411-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {NTFNet: Narrowing-then-fusing network for RGB-TIR semantic segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic graph-based graph attention network for anomaly
detection in industrial multivariate time series data. <em>APIN</em>,
<em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06412-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For industrial big data, anomaly detection for multivariate time series data is of critical strategic significance. However, the complexity of industrial equipment and production processes, combined with the high dimensionality of production data, makes it challenging for traditional anomaly detection methods to effectively capture the complex interdependencies and dynamic evolutionary relationships among multiple variables. Additionally, issues such as unstable data distributions, variability, and data drift exacerbate the challenges faced by anomaly detection methods in industrial data analysis and decision-making. This study presents a dynamic graph-based graph attention network for anomaly detection in a multivariate time series data (D-GATAD) model, introducing an innovative approach to dynamic graph construction. The proposed method seamlessly integrates node content features with graph topological structure information, enabling adaptive construction of dynamic graphs based on the current sensor network structure. This design allows for precise modeling of the complex temporal dependencies between variables. Furthermore, the method incorporates an optimized prediction-based model design that organically combines embedding vectors with node data, thereby significantly enhancing the interpretability of the analytical results. Experimental evaluations demonstrate that the proposed method outperforms existing state-of-the-art models across multiple public benchmark datasets. Notably, on the highly complex WADI dataset, it achieves a 5.12% improvement in the AUC score, underscoring its robustness and effectiveness in industrial anomaly detection. This research offers an innovative and widely applicable solution for industrial data analysis and anomaly detection, with significant implications for practical deployment.},
  archive      = {J_APIN},
  author       = {Gao, Cong and Ma, Hongye and Pei, Qingqi and Chen, Yanping},
  doi          = {10.1007/s10489-025-06412-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Dynamic graph-based graph attention network for anomaly detection in industrial multivariate time series data},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved data-driven model-free adaptive control method for
an upper extremity power-assist exoskeleton. <em>APIN</em>,
<em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06415-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread application of power-assist exoskeletons in physical labor and daily activities has increased the demand for robust control strategies to address challenges in human-exoskeleton interaction. Factors such as collisions and friction introduce uncertain disturbances, making it difficult to establish an accurate human-exoskeleton interaction model, thereby limiting the applicability of current model-based control methods. To overcome these problems, this study proposes an improved data-driven model-free adaptive control method (IMFAC) for the upper extremity power-assist exoskeleton. The stability and convergence of the closed-loop system are rigorously proven. To optimize the initial conditions of IMFAC, we propose an improved snake optimizer (ISO) algorithm incorporating opposition-based learning. The proposed ISO-IMFAC method is evaluated in two scenarios: a nonlinear Hammerstein model benchmark and a physical exoskeleton platform. Experimental results demonstrate that ISO-IMFAC outperforms other popular data-driven control methods across six metrics: integrated absolute error (4.756), mean integral of time-weighted absolute error (0.457), maximum error (1.167), minimum error (0), mean error (0.032), and error standard deviation (0.169). Additionally, the ISO-IMFAC method effectively drives the exoskeleton without relying on its dynamic model. In two load-bearing experiments conducted with five subjects wearing the exoskeleton, the proposed method reduces average muscle exertion per unit time by over 50% and extended working time by more than 180%. These findings highlight the significant potential of the proposed method to enhance user endurance and reduce physical strain, paving the way for practical applications in diverse real-world scenarios. The code is released at https://github.com/Shurun-Wang/ISO-IMFAC .},
  archive      = {J_APIN},
  author       = {Wang, Shurun and Tang, Hao and Ping, Zhaowu and Tan, Qi and Wang, Bin},
  doi          = {10.1007/s10489-025-06415-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Improved data-driven model-free adaptive control method for an upper extremity power-assist exoskeleton},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automated echocardiogram image quality assessment with YOLO
and resnet in the left ventricular myocardium of A4C views.
<em>APIN</em>, <em>55</em>(6), 1–31. (<a
href="https://doi.org/10.1007/s10489-025-06419-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image quality of echocardiography is an important factor to affect cardiovascular disease diagnosis. Currently, the deep learning (DL) used in cardiac echocardiogram image quality assess model focus more on evaluating the whole dynamic video, but the outputs revealed less local anatomical details in judging the image quality in heart chambers. This study was aimed to achieve the local part image quality assess, specifically for the five locals in the left ventricle of A4C section for myocardium. The object detection model, YOLOv8 (You Only Look Once), were used to crop five local parts in the left ventricle myocardium of A4C section. Then, the ResNet-18 model was used to evaluate the image quality of each cropped part, that output from score 0 to 3, four quality levels. The YOLOv8 model demonstrated exceptional performance metrics with Precision of 98.77%, Recall of 98.84%, mAP50 of 98.95%, and mAP50-90 of 81.33%. Additionally, the model exhibited an average Inference Time of 215ms per frame. Comparatively, the ResNet-18 model achieved Accuracy scores of 79.34%, 82.41%, 77.82%, 82.33%, and 78.13%, which correspond to the assessment of the left ventricular myocardium in all five local A4C views. The aggregate performance of the ResNet-18 model was characterized by average Macro Precision of 66.77%, Recall of 59.89%, and F1 Score of 59.49%. Furthermore, the model displayed average Micro Precision of 67.42%, Recall of 70.00%, and F1 Score of 69.98%. This study determined the effectiveness of YOLOv8 to find the bounding box of local myocardium and ResNet-18 for real-time automatic quality assessment, and had the potential to improve the efficiency of diagnosis for the doctor using echocardiogram.},
  archive      = {J_APIN},
  author       = {Liu, Weiyang and Wang, Qiushuang and Zhang, Peifang and Deng, Yujiao and Zhao, Yawei and Zhang, Yongming and Xu, Hongli and Qiu, Xiaowan and Chen, Xu and Xu, Jiayu and He, Kunlun},
  doi          = {10.1007/s10489-025-06419-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-31},
  shortjournal = {Appl. Intell.},
  title        = {Automated echocardiogram image quality assessment with YOLO and resnet in the left ventricular myocardium of A4C views},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Real-time AI-driven quality control for laboratory
automation: A novel computer vision solution for the opentrons OT-2
liquid handling robot. <em>APIN</em>, <em>55</em>(6), 1–14. (<a
href="https://doi.org/10.1007/s10489-025-06334-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of robotics and automated solutions in life sciences R&amp;D has accelerated in recent years, driven by the need to process increasing sample volumes, protect laboratory staff from hazardous substances, and manage financial pressures. Various automation systems, each with distinct levels of sample processing, transportation tasks, and data management, are available to meet specific application requirements, with liquid handling robots taking pivotal positions in these systems. However, current liquid handling robots, such as the Opentrons OT-2, lack integrated vision-based quality control, which limits their accuracy and reliability. This study presents an AI-driven computer vision model designed to enhance quality control in laboratory automation. By integrating the YOLOv8 object detection model with the OT-2, our model enables precise detection of pipette tips and liquid volumes, providing real-time feedback on errors, such as missing tips and incorrect liquid levels. Our results demonstrate the model&#39;s effectiveness and accessibility, presenting an affordable solution for improving automation in academic and research laboratories. This closed-loop system transforms the OT-2 into a robust tool for automated laboratory tasks, making it an accessible and cost-effective approach for enhancing quality control in laboratory automation and addressing a critical gap in available tools for resource-limited settings.},
  archive      = {J_APIN},
  author       = {Khan, Sana Ullah and Møller, Vilhelm Krarup and Frandsen, Rasmus John Normand and Mansourvar, Marjan},
  doi          = {10.1007/s10489-025-06334-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Real-time AI-driven quality control for laboratory automation: A novel computer vision solution for the opentrons OT-2 liquid handling robot},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anomaly detection in crowd scenes via cross trajectories.
<em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06338-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel finite-time braid entropy (FTBE) theorem to extract feature vectors to detect abnormal events occurring globally and locally in crowds. Detecting abnormal events or behavior in crowd movements is a key research topic regarding community security and management. A trajectory- based method depending on the FTBE theorem and the distribution of motion vectors is presented to determine abnormal events. The FTBE theory determines the complexity of the pattern occurring during the movement of the trajectories describing the behavior. In most studies in the literature, the image is divided into equal regions and the solution is produced by separating every behavior into more than one zone. However, this may result in incorrect results. Our study separated the behavior within a certain time interval into location-independent motion clusters. Each cluster indicated a behavior, which was represented by a feature vector derived from the distribution of FTBE and motion vectors. The learning model and fully connected deep neural network were used to detect which cluster was behaving abnormally in the local area. In addition, abnormal events were determined globally by the step braid entropy score (SBES) value calculated for the current scene. The method was tested using the UMN, UCSD and UCF-Crime databases. The experimental results of the method showed an alternative approach to the detection of abnormal behavior.},
  archive      = {J_APIN},
  author       = {Akpulat, Murat and Ekinci, Murat},
  doi          = {10.1007/s10489-025-06338-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Anomaly detection in crowd scenes via cross trajectories},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional neural networks for advanced adhesive joints
application patterns. <em>APIN</em>, <em>55</em>(6), 1–22. (<a
href="https://doi.org/10.1007/s10489-025-06340-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adhesive bonding is a widely used joining technique across various industries. Achieving uniform adhesive coverage over the entire surface without the formation of air pockets is crucial for creating strong and durable joints. Simultaneously, it is essential to minimise waste caused by material leakage at the edges. However, generating an optimal adhesive pattern to achieve the desired adhesive distribution after compression remains a challenge, as fluids tend to spread in a circular manner, while industry-relevant target geometries are typically non-circular. This paper investigates the application of Convolutional Neural Networks (CNNs) to optimise adhesive application patterns by utilising a simplified simulation model known as the Partially Filled Gaps Model (PFGM) to generate extensive training data. The CNN is trained to predict fluid distribution outcomes based on initial adhesive application patterns and addresses the inverse problem of determining an optimal application pattern to achieve a desired target distribution after compression. Two training approaches are introduced: a basic inverse model that utilizes a straightforward input–output data exchange, and a more advanced strategy that incorporates a forward model to improve accuracy. The forward model predicts the final distribution, enabling better refinement of the initial application patterns. The results demonstrate that the CNN-based approach is highly effective in generating optimal application patterns for adhesive bonds. Its primary advantage, compared to alternative methods, lies in its ability to achieve precise results within a short computation time. However, a significant drawback is the limited flexibility in accommodating variations in parameters.},
  archive      = {J_APIN},
  author       = {Scholtes, Kiro and Flaig, Florian and Kaufmann, Marvin and Lehne, Frank Guido and Vallée, Till and Fricke, Holger and Müller, Michael},
  doi          = {10.1007/s10489-025-06340-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Convolutional neural networks for advanced adhesive joints application patterns},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffusionLight: A multi-agent reinforcement learning
approach for traffic signal control based on shortcut-diffusion model.
<em>APIN</em>, <em>55</em>(6), 1–25. (<a
href="https://doi.org/10.1007/s10489-025-06359-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous researches have shown that the Reinforcement Learning(RL) is an effective solution to solve large-scale traffic signal control(TSC) problems. However, facing multi-scenario and emergencies, cooperative control of traffic signals at multi-intersection becomes a challenging multi-agent reinforcement learning(MARL) process. In order to solve real-world problems, this paper proposes a MARL algorithm called DiffusionLight, which combines Shortcut-Diffusion Model(SDM) and Soft Actor-Critic(SAC), and a fast Diffusion model to solve the traffic signal cooperative control problem of multi-scenario and multi-intersection. DiffusionLight has the stable characteristics and powerful expression ability of the SDM as the strategy network to solve the action space, while SAC is used as the value network to better explore the solution space. Experimental results show that DiffusionLight exhibits better stability compared to the baseline algorithm in the face of multi-scenario TSC and burst data anomalies, and as well as excellent performance on multiple public datasets of grid and arterial traffic networks.},
  archive      = {J_APIN},
  author       = {Yu, JiLin and Wang, Zhiwen and Zhang, Ruonan},
  doi          = {10.1007/s10489-025-06359-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-25},
  shortjournal = {Appl. Intell.},
  title        = {DiffusionLight: A multi-agent reinforcement learning approach for traffic signal control based on shortcut-diffusion model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TsDa-ASAM: Balancing efficiency and accuracy in coke image
particle size segmentation via two-stage distillation-aware adaptive
segment anything model. <em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06427-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coke image segmentation is a crucial step in coke particle size control of the sintering process. However, due to the complexity of model architecture and the dense distribution of coke particles in the images, existing segmentation methods fail to satisfy the efficiency and accuracy requirements for coke image segmentation in industrial scenarios. To address these challenges, this paper proposes a two-stage distillation-aware adaptive segment anything model to balance efficiency and accuracy in coke image particle size segmentation, referred to as TsDa-ASAM. In the first stage, knowledge distillation methods are employed to distill the Segment Anything Model (SAM) into a lightweight model, explicitly focusing on enhancing segmentation efficiency. In the second stage, a domain knowledge injection strategy is formulated, which incorporates domain knowledge into the distillation model to effectively enhance the accuracy. Moreover, an adaptive prompt point selection algorithm is introduced to address the redundancy issue of prompt points in SAM, improving the efficiency of TsDa-ASAM. The effectiveness of TsDa-ASAM is validated through extensive experiments on the publicly available dataset SA-1B and the coke image dataset from industrial sites. After distillation and fine-tuning, the segmentation accuracy of the proposed model improved by 10%, and the segmentation efficiency of TsDa-ASAM was enhanced by 2 to 3 times with the integration of the adaptive prompt point selection algorithm. The experimental results have effectively demonstrated the potential of the proposed model in balancing accuracy and efficiency.},
  archive      = {J_APIN},
  author       = {Wang, Yalin and Peng, Yubin and Tan, Xujie and Pan, Yuqing and Liu, Chenliang},
  doi          = {10.1007/s10489-025-06427-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {TsDa-ASAM: Balancing efficiency and accuracy in coke image particle size segmentation via two-stage distillation-aware adaptive segment anything model},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025a). Entropy guidance hierarchical rich-scale feature network
for remote sensing image semantic segmentation of high resolution.
<em>APIN</em>, <em>55</em>(6), 1–22. (<a
href="https://doi.org/10.1007/s10489-025-06433-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation of high-resolution remote sensing images (HRRSIs) is crucial for a wide range of applications, such as urban planning and disaster management. However, in HRRSIs, existing multiscale feature extraction and fusion methods often fail to achieve the desired accuracy because of the challenges posed by densely distributed small objects and large-scale variations. Therefore, we propose a hierarchical rich-sale feature network with entropy guidance (HRFNet), which introduces an entropy-based weighting and feature mining strategy to enhance feature extraction and fusion. Specifically, image entropy is employed as a quantifiable index to characterize the object distribution within remote sensing images, enabling an adaptive image division strategy. The image entropy is further used as weights during network training to emphasize regions with high entropy, which often correspond to edges and densely populated small objects. Additionally, the proposed feature mining strategy effectively integrates both global and local contextual information across multilayer feature maps. Extensive experiments show that HRFNet achieves mIoU scores of 81.31%, 86.47%, and 51.5% on the Vaihingen, Potsdam, and LoveDA datasets, respectively, outperforming existing methods by 1.0–3.0% mIoU.},
  archive      = {J_APIN},
  author       = {Zhang, Haoxue and Li, Linjuan and Xie, Xinlin and He, Yun and Ren, Jinchang and Xie, Gang},
  doi          = {10.1007/s10489-025-06433-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {Entropy guidance hierarchical rich-scale feature network for remote sensing image semantic segmentation of high resolution},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Uncertainty weighted policy optimization based on bayesian
approximation. <em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06303-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient exploration remains a major challenge in the field of reinforcement learning (RL). Bayesian methods have been widely investigated within the RL paradigm and are used to implement intelligent exploration strategies. However, most of these methods inevitably introduce some complexity within the Bayesian neural networks (BNNs) or are difficult to optimize elegantly. In this work, a novel algorithm called uncertainty weighted policy optimization (UWPO) based on Bayesian approximation, is introduced. UWPO theoretically analyzes the uncertainty of the policy space using the Dirichlet distribution and Monte Carlo (MC) dropout for both discrete and continuous spaces, eliminating the need for an explicit distribution representation in BNNs. The algorithm also proposes an implicit distributional training method for the value function, which is compatible with Bayesian inference. Moreover, an uncertainty-weighted update principle is adopted to adaptively adjust the contribution of each training instance to the objective. Finally, comparing UWPO with other prevailing deep reinforcement learning (DRL) algorithms on the Atari, MuJoCo, and Box2D platforms. The experimental results demonstrate that the algorithm improves the average reward score by nearly 15% while reducing computational costs by 20% compared to current state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Li, Tianyi and Yang, Genke and Chu, Jian},
  doi          = {10.1007/s10489-025-06303-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Uncertainty weighted policy optimization based on bayesian approximation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SFP: Temporal knowledge graph completion based on
sequence-focus patterns representation learning. <em>APIN</em>,
<em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06306-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extrapolation task in the temporal knowledge graph has received increasing attention from scholars due to its wide range of practical application scenarios. At present, recurrent neural networks are currently widely used in temporal knowledge graph completion techniques. These networks are employed to depict the sequential pattern of entities and relations. However, as the sequence lengthens, some critical early information may become diluted. Prediction errors ensue in the completion task as a result. Furthermore, it is observed that existing temporal knowledge graph completion methods fail to account for the topological structure of relations, which leads to relation representations with essentially little distinction across different timestamps. In order to tackle the previously mentioned concern, our research introduces a Temporal Knowledge Graph Completion Method utilizing Sequence-Focus Patterns Representation Learning (SFP). This method contains two patterns: the Focus pattern and the Sequential pattern. In the SFP model, we developed a novel graph attention network called ConvGAT. This network efficiently distinguishes and extracts complex relation information, thereby enhancing the accuracy of entity representations that are aggregated in the Focus pattern and Sequential pattern. Furthermore we proposed RelGAT, a graph attention network that simulates the topological structure of relations. This enhances the precision of relation representations and facilitates the differentiation between relation embeddings generated at various timestamps in the Focus pattern. Utilizing a time-aware attention mechanism, the Focus pattern extracts vital information at particular timestamps in order to amplify the data that the Sequential pattern dilutes. On five distinct benchmark datasets, SFP significantly outperforms the baseline, according to a comprehensive series of experiments.},
  archive      = {J_APIN},
  author       = {Wang, Jingbin and Ke, XiFan and Zhang, FuYuan and Wu, YuWei and Zhang, SiRui and Guo, Kun},
  doi          = {10.1007/s10489-025-06306-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {SFP: Temporal knowledge graph completion based on sequence-focus patterns representation learning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AI-computing, deep reinforcement learning-based predictive
human-robot neuromechanical simulation for wearable robots.
<em>APIN</em>, <em>55</em>(6), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06360-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-robot interaction (HRI) is widely used in robotics to assist humans, with wearable robots enhancing mobility for both able-bodied individuals and those with impairments. Traditionally, characterizing human biomechanical responses to these robots requires extensive human testing, which is time-consuming, costly, and potentially risky. Developing computational HRI simulations for wearable robots offers a promising solution. However, modeling the high-fidelity human-exoskeleton interaction in simulations presents significant challenges that remain underexplored. These include creating a high-fidelity autonomous human motion control agent, accounting for the non-passive nature of human responses, and incorporating closed-loop control within the robotic system. In this paper, we propose an AI-computing, deep reinforcement learning-based HRI simulation to predict complex and realistic human biomechanical responses to exoskeleton assistance. The multi-neural network training process develops an end-to-end, autonomous control policy that reduces human muscle effort by utilizing current human kinematic states. This approach processes state information from both the human musculoskeletal and exoskeleton control neural network, generating control policies for robust human walking movement and reducing muscle effort. Numerical experiments demonstrated the framework’s ability to simulate human motion control, showing reductions in hip joint torque (13.04 $$\%$$ ), rectus femoris (RF) muscle activation (7.31 $$\%$$ ), and biceps femoris (BF) muscle activation (12.21 $$\%$$ ) with exoskeleton use. Validation through real-world experiments further confirmed a decrease in RF and BF muscle activations by 22.12 $$\%$$ and 11.45 $$\%$$ , respectively. These results highlight the effectiveness of our proposed AI computing-based simulation method in replicating and optimizing human biomechanics during exoskeleton-assisted movement. This AI computing-based human-exoskeleton predictive simulation may offer a general, high-fidelity platform for studying human biomechanical responses and enabling autonomous control for assistive devices without requiring intensive human testing in the rehabilitation field.},
  archive      = {J_APIN},
  author       = {Wang, Mingyi and Luo, Shuzhen},
  doi          = {10.1007/s10489-025-06360-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {AI-computing, deep reinforcement learning-based predictive human-robot neuromechanical simulation for wearable robots},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Performance of machine learning methods for cattle
identification and recognition from retinal images. <em>APIN</em>,
<em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06398-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Animal identification is a critical issue in terms of security, traceability, and animal health, especially in large-scale livestock enterprises. Traditional methods (such as ear tags and branding) both negatively affect animal welfare and may lead to security vulnerabilities. This study aims to develop a biometric system based on retinal vascular patterns for the identification and recognition of cattle. This system aims to provide a safer and animal welfare-friendly alternative by using image processing techniques instead of traditional device-based methods. In the study, preprocessing, segmentation, feature extraction, and performance evaluation steps were applied for the biometric identification and recognition process using retinal images taken from both eyes. Techniques such as green channel extraction, contrast-limited adaptive histogram equalization, morphological operations, noise filtering, and threshold determination were used in the preprocessing stage. Fuzzy C-means, K-means, and Level-set methods were applied for segmentation, and feature extraction was performed using SIFT, SURF, BRISK, FAST, and HARRIS methods. At the end of the study, the highest accuracy rate was obtained as 95.6% for identification and 87.9% for recognition. In addition, the obtained dataset was shared publicly, thus creating a reusable resource that researchers from different disciplines can use. It was concluded that this study made a significant contribution to the field of biometric-based animal identification and recognition and offered a practically usable solution in terms of animal welfare and safety.},
  archive      = {J_APIN},
  author       = {Cihan, Pınar and Saygılı, Ahmet and Akyüzlü, Muhammed and Özmen, Nihat Eren and Ermutlu, Celal Şahin and Aydın, Uğur and Yılmaz, Alican and Aksoy, Özgür},
  doi          = {10.1007/s10489-025-06398-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Performance of machine learning methods for cattle identification and recognition from retinal images},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Effect of continuous s-shaped rectified linear function on
deep convolutional neural network. <em>APIN</em>, <em>55</em>(6), 1–24.
(<a href="https://doi.org/10.1007/s10489-025-06399-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vanishing gradient issue in convolutional neural networks (CNNs) is often addressed by improving activation functions, such as the S-shaped rectified linear activation unit (SReLU). However, SReLU can pose challenges in updating training parameters effectively. To mitigate this, we propose applying the Aggregation Fischer–Burmeister (AFB) function to SReLU, which smooths the secant line slope of the function from both sides. However, direct application of AFB to SReLU can intensify the vanishing gradient issue due to irregular function behavior. To address this concern, we introduce a regulated version of AFB (ReAFB) that ensures proper gradient and mean activation output conditions when applied to SReLU (ReAFBSReLU). We evaluate the performance of CNNs using ReAFBSReLU on three benchmark datasets: MNIST, CIFAR-10 (with and without data augmentation), and CIFAR-100. Specifically, we implement Network in Network (NIN) for MNIST and CIFAR-10, and LeNet for CIFAR-100 dataset. Additionally, we utilize SqueezeNet exclusively to compare the performance of CNNs using the proposed ReAFBSReLU activation function against state-of-the-art activation functions. Our results demonstrate that ReAFBSReLU outperforms other activation functions tested in this study, indicating its efficacy in enhancing training parameter updates and subsequently improving accuracy.},
  archive      = {J_APIN},
  author       = {Ghazvini, Anahita and Abdullah, Siti Norul Huda Sheikh and Ayob, Masri},
  doi          = {10.1007/s10489-025-06399-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Effect of continuous S-shaped rectified linear function on deep convolutional neural network},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Use of artificial intelligence techniques in
characterization of vibration signals for application in agri-food
engineering. <em>APIN</em>, <em>55</em>(6), 1–24. (<a
href="https://doi.org/10.1007/s10489-025-06424-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bottling machinery is a critical component in agri-food industries, where maintaining operational efficiency is key to ensuring productivity and minimizing economic losses. Early detection of faulty conditions in this equipment can significantly improve maintenance procedures and overall system performance. This research focuses on health monitoring of gripping pliers in bottling plants, a crucial task that has traditionally relied on analyzing raw vibration signals or using narrowly defined, application-specific features. However, these methods often face challenges related to limited robustness, high computational costs, and sensitivity to noise. To address these limitations, we propose a novel approach based on generic features extracted through basic signal processing techniques applied to vibration signals. These features are then classified using a random forest algorithm, enabling an effective analysis of health states. The proposed method is evaluated against traditional approaches and demonstrates clear advantages, including higher accuracy in detecting and classifying faulty conditions, greater robustness against random perturbations, and a reduced computational cost. Additionally, the method requires fewer training instances to achieve reliable performance. This study highlights the potential of artificial intelligence and signal processing techniques in predictive maintenance, offering a scalable and efficient solution for fault detection in manufacturing processes, particularly within the agri-food sector.},
  archive      = {J_APIN},
  author       = {Luque, Amalia and Campos Olivares, Daniel and Mazzoleni, Mirko and Ferramosca, Antonio and Previdi, Fabio and Carrasco, Alejandro},
  doi          = {10.1007/s10489-025-06424-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-24},
  shortjournal = {Appl. Intell.},
  title        = {Use of artificial intelligence techniques in characterization of vibration signals for application in agri-food engineering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparison study of several strategies in multivariate
time series clustering based on graph community detection.
<em>APIN</em>, <em>55</em>(6), 1–23. (<a
href="https://doi.org/10.1007/s10489-025-06444-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data analysis, especially forecasting, classification, imputation, and anomaly detection, has gained a lot of research attention in recent years due to its prevalence and wide application. Compared to classification, clustering is an unsupervised task and thus more applicable for analyzing massive time series without labels. One latest way is based on the idea of graph community detection: first transforming a time series set into a graph (or a network), in which a node represents a time series instance and an edge denotes that the two connected nodes (thus the represented time series) are more similar to each other; then, running a community detection algorithm on the graph to discover a community structure, that gives out a clustering result. Recently, there are several works based on the graph community detection idea to cluster multivariate time series. However, such works focus only on specific methods in each step, and a performance comparison of combinations of methods in different steps is lacking. This paper outlines the process of graph-based multivariate time clustering as four phases (referred to as framework), namely representation learning, similarity computing, relation network construction, and clustering, lists typical methods in each phase, and makes a comparison study of combinations of each phase methods (called strategies in this paper). Recent time series deep neural network models are introduced to the framework as time series representation learning methods as well. In addition, $$\varvec{\varepsilon } \varvec{k}$$ NN, an improvement of $$\varvec{k}$$ NN by filtering out unnecessary low similarity connections during network construction, is proposed. A great number of experiments are conducted on eight real-world multivariate time series with various properties to verify the performance of different strategy combinations. The results suggest that proper deep neural network is a promising way for learning time series vector representations to compute similarities, and strategies including $$\varvec{\varepsilon } \varvec{k}$$ NN for network construction, average for multi-layer network merging and Louvain for clustering are more effective from a statistical perspective.},
  archive      = {J_APIN},
  author       = {Sun, Hanlin and Jie, Wei and Chen, Yanping and Wang, Zhongmin},
  doi          = {10.1007/s10489-025-06444-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-23},
  shortjournal = {Appl. Intell.},
  title        = {A comparison study of several strategies in multivariate time series clustering based on graph community detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). QuinNet: Quintuple u-shape networks for scale- and
shape-variant lesion segmentation. <em>APIN</em>, <em>55</em>(6), 1–15.
(<a href="https://doi.org/10.1007/s10489-025-06448-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning approaches have demonstrated remarkable efficacy in medical image segmentation. However, they continue to struggle with challenges such as the loss of global context information, inadequate aggregation of multi-scale context, and insufficient attention to lesion regions characterized by diverse shapes and sizes. To address these challenges, we propose a new medical image segmentation network, which consists of one main U-shape network (MU) and four auxiliary U-shape sub-networks (AU), leading to Quintuple U-shape networks in total, thus abbreviated as QuinNet hereafter. MU devises special attention-based blocks to prioritize important regions in the feature map. It also contains a multi-scale interactive aggregation module to aggregate multi-scale contextual information. To maintain global contextual information, AU encoders extract multi-scale features from the input images, then fuse them into feature maps of the same level in MU, while the decoders of AU refine features for the segmentation task and co-supervise the learning process with MU. Overall, the dual supervision of MU and AU is very beneficial for improving the segmentation performance on lesion regions of diverse shapes and sizes. We validate our method on four benchmark datasets, showing that it achieves significantly better segmentation performance than the competitors. Source codes of QuinNet are available at https://github.com/Truman0o0/QuinNet .},
  archive      = {J_APIN},
  author       = {Fan, Gaojuan and Wang, Jie and Xia, Ruixue and Zhou, Funa and Zhang, Chongsheng},
  doi          = {10.1007/s10489-025-06448-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {QuinNet: Quintuple u-shape networks for scale- and shape-variant lesion segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A reinforcement learning malware detection model based on
heterogeneous information network path representation. <em>APIN</em>,
<em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06417-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the significant increase of Android malware, the APP privacy data leakage incidents occur frequently, which poses a great threat to user property and information security. Specifically, the new malware has the characteristics of high evolution rate and diverse variants, leading to the fact that the current malware detection methods still have three key problems: (1) Difficulty in acquiring Android sample structural features; (2) Weakly in representing malware behavior structure; (3) Poor robustness of the detection model. To address the above limitations, we propose a new malware detection framework MPRLDroid with reinforcement learning. First of all, the MPRLDroid model extracts the Android APP structural features and constructs the heterogeneous information network data based on the semantic call structure between APP, API and permission. Subsequently, the model utilizes reinforcement learning to adaptively generate a meta-path for each sample and combines it with a graph attention network to effectively represent the graph of nodes. Finally, the low-dimensional graph node vector data is brought into the downstream detection task for classification, where the performance change of the classification result is used as a reward function for reinforcement learning. The experimental results demonstrate that the MPRLDroid model, when integrated with reinforcement learning, outperforms the baseline models in terms of performance, and its detection model exhibits greater robustness compared to other models.},
  archive      = {J_APIN},
  author       = {Yang, Kang and Cai, Lizhi and Wu, Jianhua and Liu, Zhenyu and Zhang, Meng},
  doi          = {10.1007/s10489-025-06417-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {A reinforcement learning malware detection model based on heterogeneous information network path representation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSF-SegFormer: A feature fusion algorithm for magnetic
leakage image segmentation. <em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06453-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional segmentation networks have low segmentation accuracy for flux leakage images, often leading to missed or false detections of small defects, which significantly affect the evaluation of defect severity. Based on the SegFormer network, a high-accuracy decoder based on multi-scale feature fusion is proposed, which is more suitable for the segmentation of small defects in flux leakage and replaces the multi-layer perceptron (MLP) decoder of the original network. The new network model is called MSF-SegFormer. MSF-SegFormer introduces a feature fusion network MSF that integrates high-resolution and low-resolution features and introduces feature pyramid fusion, which can merge output features at different levels across different scales. A cascaded attention module is proposed, combining two local attention mechanisms in a cascade and using a residual network to enhance the local feature representation of flux leakage images, improving the accuracy and stability of the task. In the application of flux leakage defect data, compared with benchmark models such as CNN and SegFormer, this model can accurately segment target edges with fewer parameters, maintain high accuracy, reduce false detection probability, and improve the Miou value of the traditional MLP decoder from 88.21% to 90.44%.},
  archive      = {J_APIN},
  author       = {Wang, Zhujun and Ni, Rongtai and Sun, Tianhe and Jiang, Yulong and Liu, Bin},
  doi          = {10.1007/s10489-025-06453-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {MSF-SegFormer: A feature fusion algorithm for magnetic leakage image segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FA3-net: Feature aggregation and augmentation with attention
network for sound event localization and detection. <em>APIN</em>,
<em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06437-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sound event localization and detection (SELD) aims to identify the category and duration of sound events (SED) while also estimating their respective direction of arrival (DOA). This multi-task problem presents unique challenges, as the features required for SED and DOA tasks are not entirely aligned. Consequently, incomplete feature extraction and suboptimal feature fusion often hinder performance. To address these issues, we propose a feature aggregation and augmentation with attention network (FA3-Net). FA3-Net consists of two main components: the feature aggregation and augmentation with attention (FA3) module and the Conformer module. The FA3 module plays a critical role in fusing and enhancing high-level features, which is specifically designed to efficiently handle the distinct requirements of SED and DOA tasks. It ensures that task-specific features are extracted effectively, while also improving feature discriminability and reducing confusion. The feature aggregation residual block (FAResBlock), a component of the FA3 module, handles task-specific feature aggregation, while the feature augmentation with attention block (FAA block) enhances feature representation across multiple dimensions. The Conformer module is employed to model the temporal sequence, as it excels in capturing both local and global dependencies, making it ideal for comprehensive time sequence analysis. Finally, to overcome data limitations, audio channel swapping (ACS) is employed. Experiments on the STARSS23 dataset, DCASE2021 dataset and L3DAS22 dataset show that FA3-Net significantly outperforms other models in both feature aggregation and augmentation, while also being more efficient and lightweight. The code is available in: https://github.com/wangchuan11111111/FA3-NET},
  archive      = {J_APIN},
  author       = {Wang, Chuan and Huang, Qinghua},
  doi          = {10.1007/s10489-025-06437-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {FA3-net: Feature aggregation and augmentation with attention network for sound event localization and detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improved DAB-DETR model for irregular traffic obstacles
detection in vision based driving environment perception scenario.
<em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06440-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine vision based irregular traffic obstacles recognition plays a pivotal role in the autonomous driving and Advanced Driver Assistance Systems (ADAS) by providing the necessary environment perception capabilities. Traditional models for recognizing irregular traffic obstacles suffer from challenges with small target detection, poor performance in diverse environmental conditions and computational complexity. This work addresses the critical issue of recognizing irregular traffic obstacles in roadway environments. We present an enhanced target detection model based on the Dynamic Anchor Boxes-recognition Transformer (DAB-DETR). The original model’s structure was limited in expressing relative positional information between features due to the reliance on absolute position encoding. To overcome this limitation, the improved DAB-DETR incorporates relative position encoding within the multi-headed self-attention mechanism of the Transformer encoder. Additionally, we propose a novel Average Precision (AP) loss function that unifies classification and localization losses into a single parameterized formula, addressing performance degradation observed in the original model. Experimental results demonstrate significant improvements in detection accuracy for irregular traffic objects, showcasing the effectiveness of the proposed enhancements. According to the testing results, the improved DAB-DETR model’s detection accuracy is 82.00% with Intersection over Union (IoU) equals to 0.5, which is 3.3% better than the original model and 6.20% and 7.71% better than the conventional models, YOLOv5 and Faster R-CNN, respectively.},
  archive      = {J_APIN},
  author       = {Yang, Junchao and Zhang, Hui and Zhou, Yuting and Guo, Zhiwei and Lin, Feng},
  doi          = {10.1007/s10489-025-06440-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Improved DAB-DETR model for irregular traffic obstacles detection in vision based driving environment perception scenario},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ship pipeline defect detection method based on deep learning
and transfer fusion of ultrasonic guided wave signals. <em>APIN</em>,
<em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-025-06390-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultrasonic guided waves (UGW) hold great promise for structural health monitoring (SHM) of pipeline structures. However, the inherent complexity of pipeline defect features within the UGW makes the intuitive and accurate identification of defects based only on UGW signals challenging. In addition, the existing neural network-based UGW signal recognition methods require a large number of defect waveform samples, which limits their applicability. This study proposes a signal recognition method based on deep learning and sample transfer fusion for the identification of UGW signals in ship pipelines, allowing to accurately detect their potential defects. A time–frequency imaging algorithm for ship pipeline UGW signals is first introduced using the continuous wavelet transform (CWT) to capture their time–frequency characteristics. Leveraging transfer learning, UGW signal samples from various operational scenarios onshore oil pipelines are then fused to pre-train the GoogLeNet convolutional neural network (CNN) model. Finally, the pre-trained GoogLeNet model is fine-tuned with ship pipeline UGW signal samples, which allows to accurately detect the underlying defects. The experimental results demonstrate that the proposed method significantly increases the classification accuracy of ship pipeline defects compared with non-transfer learning methods and time-domain imaging. More precisely, the accuracy increases from 63.3% to 97.3%. Furthermore, the obtained results show that the proposed method has high robustness.},
  archive      = {J_APIN},
  author       = {Tang, Ruoli and Li, Yongzhe and Zhang, Shangyu},
  doi          = {10.1007/s10489-025-06390-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Ship pipeline defect detection method based on deep learning and transfer fusion of ultrasonic guided wave signals},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning-based road surveillance system in
distributed CCTV environment: Pedestrian fall recognition using
spatio-temporal attention networks. <em>APIN</em>, <em>55</em>(6), 1–16.
(<a href="https://doi.org/10.1007/s10489-025-06451-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intelligent CCTV systems are highly effective in monitoring pedestrian and vehicular traffic and identifying anomalies in the roadside environment. In particular, it is necessary to develop an effective recognition system to address the problem of pedestrian falls, which is a major cause of injury in road traffic environments. However, the existing systems have challenges such as communication constraints and performance instability. In this paper, we propose a novel fall recognition system based on Federated Learning (FL) to solve these challenges. The proposed system utilizes a GAT combined with LSTM and attention layers to extract spatio-temporal features, which can more accurately identify pedestrian falls. Each road CCTV works as an independent client to generate local data, and the server aggregates these models to learn a global model. This ensures robust operation in different views and environments, and solves the bottleneck of data communication and security challenges. We validated the feasibility and applicability of the FL-based fall recognition method by implementing the prototype and applying it to the UP-FALL benchmark dataset, which is widely used for fall recognition. Code has been made available at: https://github.com/Kim-Byeong-Hun/Fed-PFR .},
  archive      = {J_APIN},
  author       = {Kim, Byeonghun and Im, Jaegyun and Noh, Byeongjoon},
  doi          = {10.1007/s10489-025-06451-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Federated learning-based road surveillance system in distributed CCTV environment: Pedestrian fall recognition using spatio-temporal attention networks},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional requirements for reinforcement
recommendation reasoning. <em>APIN</em>, <em>55</em>(6), 1–16. (<a
href="https://doi.org/10.1007/s10489-024-05854-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation systems not only need to improve the accuracy of recommendations, but also need to focus on the variety and novelty of recommendations to improve user satisfaction. Currently, most of the existing recommendation systems focus on improving the accuracy and diversity of recommendation items, however, they usually do not consider the original user needs, and the potential relationship between diversity and novelty is not deeply explored. In addition to accuracy and diversity, we also consider novelty, and analyze the relationship between diversity and novelty (same place and different place), and propose an explainable recommendation system that integrates multiple (multidimensional) requirements such as accuracy, diversity, and novelty. The model combines semantic relations of knowledge graphs and multi-hop inference so as to analyze and consider the diversity and novelty requirements of users. Meanwhile, a recurrent neural network is used to construct a temporal multi-label classification network to predict users’ multidimensional demands and capture the dependencies between diversity and novelty demands. Finally, a composite reward function, including accuracy reward, diversity reward and novelty reward, is designed to implement a multi-demand, multi-decision recommendation method. Experiments are conducted on three real-world datasets, and the experimental results show that the model can guarantee the accuracy while improving the diversity and novelty of recommended items.},
  archive      = {J_APIN},
  author       = {Li, Yinggang and Tong, Xiangrong and Lv, Zhongming},
  doi          = {10.1007/s10489-024-05854-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Multi-dimensional requirements for reinforcement recommendation reasoning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ISL-net: Dual-stream interaction network with task-optimized
modules for more accurate, complete iris segmentation and localization.
<em>APIN</em>, <em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-024-05862-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Iris images captured in uncooperative and unconstrained environments pose significant challenges for iris segmentation and localization owing to factors including high occlusions, specular reflections, motion blur, iris rotation, and off-angle images. To address this challenge, this paper proposes ISL-Net, a multitask segmentation network with a task-optimization module based on deep learning for joint iris segmentation and localization. We developed a dual-stream interactive module (DSIM) that combines dual-stream decoders to facilitate information exchange between tasks without interference. To optimize the iris-segmentation and iris-localization performance, we incorporated a balanced attention module (BAM) and a boundary-enhancement module (BEM) in the skip connections of the respective task stream decoders. The BEM recovers missing boundaries in iris localization, while the BAM focuses on uncertain areas in iris segmentation, enhancing the model’s ability to handle these regions. These modules complement each other, improving overall system performance without interference. The proposed model was evaluated on three challenging iris datasets, outperforming most existing models by achieving e1 index scores of 0.34, 0.79, and 0.61% and average normalized Hausdorff distances (HDs) of 0.7221, 1.1914, and 1.0396%. The results indicate that ISL-Net can generate normalized iris images with simple post-processing, making it suitable for direct application in existing iris-recognition systems.},
  archive      = {J_APIN},
  author       = {He, Lei and Yang, Xiaokai and Zheng, Jian and Liu, Zhaobang and Yang, Xiaoguo},
  doi          = {10.1007/s10489-024-05862-8},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {ISL-net: Dual-stream interaction network with task-optimized modules for more accurate, complete iris segmentation and localization},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SDDP: Sensitive data detection method for user-controlled
data pricing. <em>APIN</em>, <em>55</em>(6), 1–15. (<a
href="https://doi.org/10.1007/s10489-025-06229-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, there is an urgent need for data sharing, in which data pricing is a crucial issue, because a reasonable price can not only enhance the willingness of users to share data but also promote the progress of data sharing. However, current research is mostly approached from the perspective of data sharing platforms, treating all data equally without sufficient evaluation of sensitive data within shared datasets and personalized perception of privacy from the users themselves. To address this problem, we detected sensitive data in each piece of data and then defined the pricing function based on information entropy and the user’s perception of sensitive information. To enhance the accuracy of sensitive data detection, we integrated an attention mechanism into a pre-trained model to comprehensively represent the samples. Subsequently, on the basis of automatically generating label correlation vectors to calculate the correlation matrix, a graph convolutional neural network was employed to mine the correlation between labels. Furthermore, based on the detection results, information entropy and user ratings are reasonably mapped to prices. Pricing based on user ratings is more suitable for pricing personal data rather than government or institutional data. The experimental results on the dataset of Twitter text sent by users have demonstrated that the average precision of our sensitive data detection model has improved by up to 9.26% compared to comparison models, and SDDP can provide reasonable pricing for samples containing sensitive data and fair compensation for users.},
  archive      = {J_APIN},
  author       = {Hu, Yuchuan and Hu, Bitao and Guo, Bing and Dai, Cheng and Shen, Yan},
  doi          = {10.1007/s10489-025-06229-3},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {SDDP: Sensitive data detection method for user-controlled data pricing},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-scale dual-stream visual feature extraction and graph
reasoning for visual question answering. <em>APIN</em>, <em>55</em>(6),
1–18. (<a href="https://doi.org/10.1007/s10489-025-06325-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in deep learning algorithms have significantly expanded the capabilities of systems to handle vision-to-language (V2L) tasks. Visual question answering (VQA) presents challenges that require a deep understanding of visual and language content to perform complex reasoning tasks. The existing VQA models often rely on grid-based or region-based visual features, which capture global context and object-specific details, respectively. However, balancing the complementary strengths of each feature type while minimizing fusion noise remains a significant challenge. This study propose a multi-scale dual-stream visual feature extraction method that combines grid and region features to enhance both global and local visual feature representations. Also, a visual graph relational reasoning (VGRR) approach is proposed to further improve reasoning by constructing a graph that models spatial and semantic relationships between visual objects, using Graph Attention Networks (GATs) for relational reasoning. To enhance the interaction between visual and textual modalities, we further propose a cross-modal self-attention fusion strategy, which enables the model to focus selectively on the most relevant parts of both the image and the question. The proposed model is evaluated on the VQA 2.0 and GQA benchmark datasets, demonstrating competitive performance with significant accuracy improvements compared to state-of-the-art methods. Ablation studies confirm the effectiveness of each module in enhancing visual-textual understanding and answer prediction.},
  archive      = {J_APIN},
  author       = {Yusuf, Abdulganiyu Abdu and Feng, Chong and Mao, Xianling and Li, Xinyan and Haruna, Yunusa and Duma, Ramadhani Ally},
  doi          = {10.1007/s10489-025-06325-4},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Multi-scale dual-stream visual feature extraction and graph reasoning for visual question answering},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Locomotion mode prediction in real-life walking with and
without ankle–foot exoskeleton assistance. <em>APIN</em>,
<em>55</em>(6), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06416-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exoskeletons can assist human locomotion in real-life scenarios, but existing tools for decoding locomotion modes (LMs) focus on recognition rather than prediction, which can lead to delayed assistance. This study proposes a long short-term memory (LSTM) neural network to predict five LMs (level-walking, ramp ascent/descent, stair ascent/descent) with greater lead time compared to state-of-the-art methods. We examined the optimal sequence length (SL) for LSTM-based LM prediction, using data from inertial sensors placed on the lower limbs and the lower back, along with a waist-mounted infrared laser. Ten subjects walked in real-life scenarios, both with and without an ankle–foot exoskeleton. Results show that a 1-s SL provides the most advanced and accurate LM prediction, outperforming SLs of 0.6, 0.8, and 1.2 s. The proposed LSTM model achieved an accuracy of 98 ± 0.31%, predicting LMs 0.66 s in advance (for an average stride time of 1.98 ± 0.83 s). Level-walking presented more misclassifications, and the model primarily relied on inertial data over laser input. Overall, these findings demonstrate the LSTM’s strong predictive capability for both assisted and non-assisted walking and independent of which limb executes the transition, supporting its applicability for exoskeleton-assisted locomotion.},
  archive      = {J_APIN},
  author       = {Carvalho, Simão P. and Figueiredo, Joana and Cerqueira, João J. and Santos, Cristina P.},
  doi          = {10.1007/s10489-025-06416-2},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Locomotion mode prediction in real-life walking with and without ankle–foot exoskeleton assistance},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A scale-cross non-local network with higher-level semantics
guidance for smoke segmentation. <em>APIN</em>, <em>55</em>(6), 1–17.
(<a href="https://doi.org/10.1007/s10489-025-06420-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoke semantic segmentation (SSS) is particularly challenging task due to the various patterns of the target itself, which are caused by the characteristics of smoke, like, non-rigid, translucent, fuzzy, environment-sensitive, and so forth. This paper tailor-makes the Scale-Cross Non-Local Network (SCNN) for Smoke Segmentation, aiming to accurately locate the position of smoke in complex scenes. While non-local enjoys the bonus of the excellent competence in modeling long-range contextual dependencies acquired by self-attention, the constraint on single-scale input and the suitability for low-resolution feature erode its capability in information representation. To address these issues, we bespoke a Scale-Cross Non-Local (SCNL) module to better integrate local features with global dependencies. In practical scenes, diverse non-smoke objects sharing similarity with smoke pose great obstacles to accurate location of smoke. As a solution, we design a Pyramid Irregular Convolution (PIC) module containing rich high-level semantic to further refine the feature representation of segmentation task. By supervising classification task, the high-level semantics obtained can guide the segmentation feature to correct semantic errors at the image level and alleviate the issue of between-class similarity. To assess its generalization ability, we empirically evaluate our SCNN on extensive synthetic and real data. Experimental results demonstrate that SCNN achieves state-of-the-art performance, exhibiting enhanced smoke localization, accuracy in boundary detection, and a significant reduction in the false segmentation rate for smoke-like objects.},
  archive      = {J_APIN},
  author       = {Zhang, Lin and Wu, Jing and Zhao, Yun and Yuan, Feiniu},
  doi          = {10.1007/s10489-025-06420-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-17},
  shortjournal = {Appl. Intell.},
  title        = {A scale-cross non-local network with higher-level semantics guidance for smoke segmentation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HKGAT: Heterogeneous knowledge graph attention network for
explainable recommendation system. <em>APIN</em>, <em>55</em>(6), 1–19.
(<a href="https://doi.org/10.1007/s10489-025-06446-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the Heterogeneous Knowledge Graph Attention Network (HKGAT) for recommendation systems. As recommendation technology evolves, systems now emphasize diversity, fairness, and explainability alongside accuracy. Traditional methods encounter issues integrating knowledge graphs and lack explainability. HKGAT addresses these by leveraging heterogeneous knowledge graphs. It consists of a heterogeneous information aggregation layer, an attention-aware heterogeneous relation fusion layer, and a prediction layer. First, recommendation data forms a user-item knowledge graph. Then, the aggregation layer collects relation information, followed by the fusion layer integrating it for higher-order feature representations. The prediction layer combines link prediction and recommendation score prediction. Additionally, paths of top-ten results are analyzed and quantified for explainability to optimize ranking. Experiments on self-constructed and Amazon-book datasets show HKGAT outperforms baselines like HetGCN, with significant improvements in Precision, Recall, F1 score, and NDCG@10, and a notable 1.9% gain in NDCG@10 from explainable ranking optimization.},
  archive      = {J_APIN},
  author       = {Zhang, Yongchuan and Tian, Jiahong and Sun, Jing and Chan, Huirong and Qiu, Agen and Liu, Cailin},
  doi          = {10.1007/s10489-025-06446-w},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {HKGAT: Heterogeneous knowledge graph attention network for explainable recommendation system},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging CQT-VMD and pre-trained AlexNet architecture for
accurate pulmonary disease classification from lung sound signals.
<em>APIN</em>, <em>55</em>(6), 1–19. (<a
href="https://doi.org/10.1007/s10489-025-06452-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel algorithm for classifying pulmonary diseases using lung sound signals by integrating Variational Mode Decomposition (VMD) and the Constant-Q Transform (CQT) within a pre-trained AlexNet convolutional neural network. Breathing sounds from the ICBHI and KAUHS databases are analyzed, where three key intrinsic mode functions (IMFs) are extracted using VMD and subsequently converted into CQT-based time-frequency representations. These images are then processed by the AlexNet model, achieving an impressive classification accuracy of 93.30%. This approach not only demonstrates the innovative synergy of CQT-VMD for lung sound analysis but also underscores its potential to enhance computerized decision support systems (CDSS) for pulmonary disease diagnosis. The results, showing high accuracy, a sensitivity of 91.21%, and a specificity of 94.9%, highlight the robustness and effectiveness of the proposed method, paving the way for its clinical adoption and the development of lightweight deep-learning algorithms for portable diagnostic tools. Overview of the proposed methodology for pulmonary disease classification using CQT-VMD and pre-trained AlexNet architecture applied to lung sound signals},
  archive      = {J_APIN},
  author       = {Neili, Zakaria and Sundaraj, Kenneth},
  doi          = {10.1007/s10489-025-06452-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-19},
  shortjournal = {Appl. Intell.},
  title        = {Leveraging CQT-VMD and pre-trained AlexNet architecture for accurate pulmonary disease classification from lung sound signals},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). OTMKGRL: A universal multimodal knowledge graph
representation learning framework using optimal transport and
cross-modal relation. <em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06459-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The demand for integrating multimodal information, such as text and images, has grown significantly as it enables richer and more comprehensive knowledge representations. Most existing multimodal knowledge graph representation learning (KGRL) methods focus primarily on fusing multimodal entity information, directly applying multimodal entities and single-modal relations to downstream tasks. However, these methods face challenges related to the heterogeneity of multi-source entity data, which amplifies the differences in feature distributions between entity and relation representations. To address these challenges, we propose a universal multimodal KGRL framework, OTMKGRL, which seamlessly incorporates multimodal information into three types of single-modal KGRL methods. First, OTMKGRL employs Tucker decomposition to project entity text and image data into a shared space, thereby generating multimodal entity representations. It then uses optimal transport to integrate multimodal entity information into the original single-modal entity representations. Second, OTMKGRL introduces a cross-modal relation attention mechanism that fuses effective multimodal entity features into the original single-modal relations, yielding cross-modal relation representations. Extensive experiments across three multimodal datasets demonstrate the effectiveness and versatility of our approach. The OTMKGRL framework significantly enhances the performance of existing single-modal KGRL models in multimodal settings.},
  archive      = {J_APIN},
  author       = {Wang, Tao and Shen, Bo},
  doi          = {10.1007/s10489-025-06459-5},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {OTMKGRL: A universal multimodal knowledge graph representation learning framework using optimal transport and cross-modal relation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Vision-based attention deep q-network with prior-based
knowledge. <em>APIN</em>, <em>55</em>(6), 1–14. (<a
href="https://doi.org/10.1007/s10489-024-05850-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision-based reinforcement learning (RL) is a potent algorithm for addressing tasks related to visual behavioural decision-making; nevertheless, it operates as a black-box, directly training models with images as input in the end-to-end fashion. Therefore, to elucidate the underlying mechanisms of the model and the agent’s focus on different features during the decision-making process, a vision-based attention (VA) mechanism is introduced into vision-based RL in this paper. A prior-based mechanism is introduced to address the issue of instability in the attention maps observed by the agent when attention mechanisms are directly integrated into network updates that results in an increase in single-step errors and larger cumulative errors. Thus, a vision-based attention deep Q-network (VADQN) method with a prior-based mechanism is proposed. Specifically, prior attention maps are obtained using a learnable Gaussian filtering and a spectral residual method. Next, the attention maps are fine-tuned using a self-attention (SA) mechanism to enhance their performance. During training, both the attention maps and the parameters of the policy network are concurrently trained to ensure explanations of the regions of interest during online training. Finally, a series of ablation experiments are conducted on Atari games to compare the proposed method with humans, convolutional neural networks, and other approaches. The results demonstrate that the proposed method not only reveals the regions of interest attended to by DRL during the decision-making process but also enhances DRL performance in certain scenarios. This approach provides valuable insights for understanding and improving the performance of DRL in visual decision-making tasks.},
  archive      = {J_APIN},
  author       = {Ma, Jialin and Li, Ce and Hong, Liang and Wei, Kailun and Zhao, Shutian and Jiang, Hangfei and Qu, Yanyun},
  doi          = {10.1007/s10489-024-05850-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Vision-based attention deep q-network with prior-based knowledge},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised text classification method based on
three-way decision with evidence theory. <em>APIN</em>, <em>55</em>(6),
1–15. (<a href="https://doi.org/10.1007/s10489-024-06129-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning methods play a crucial role in text classification tasks. However, due to limitation of scarce labeled training data, the uncertainty of pseudo labels is still an unavoidable problem in semi-supervised text classification. To address this issue, this paper introduces three-way decision theory into semi-supervised text classification model, which divides the model output pseudo-labeled samples into different regions and adopts different processing strategies. The accurate and effective pseudo-labeled samples are selected as much as possible to expand the original training set. For the pseudo-labeled outputs by the model, we use evidence theory to fuse the probability outputs of the samples to improve the stability and credibility of pseudo labels. Experimental results demonstrate that the method introduced in this paper effectively enhances the accuracy of semi-supervised text classification while exhibiting high stability.},
  archive      = {J_APIN},
  author       = {Yang, Ziping and Jiang, Chunmao and Huang, Chunmei},
  doi          = {10.1007/s10489-024-06129-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-15},
  shortjournal = {Appl. Intell.},
  title        = {Semi-supervised text classification method based on three-way decision with evidence theory},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse pinball universum nonparallel support vector machine
and its safe screening rule. <em>APIN</em>, <em>55</em>(6), 1–33. (<a
href="https://doi.org/10.1007/s10489-025-06356-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparallel support vector machine (NPSVM) is an effective and popular classification technique, which introduces the $$\epsilon $$ -insensitive loss function instead of the quadratic loss function in twin support vector machine (TSVM), making the model have the same sparsity and kernel strategy as support vector machine (SVM). However, NPSVM is sensitive to noise points and does not utilize the prior knowledge embedded in the unlabeled samples. Therefore, to improve its generalization ability and robustness, a sparse pinball Universum nonparallel support vector machine (SPUNPSVM) is first proposed in this paper. On the one hand, the sparse pinball loss is employed to enhance the robustness. On the other hand, it exploits the Universum data, which do not belong to any class, to embed prior knowledge into the model. Numerical experiments have verified its effectiveness. Furthermore, to further speed up SPUNPSVM, we propose a safe screening rule (SSR-SPUNPSVM) based on its sparsity, which achieves acceleration without sacrificing accuracy. Numerical experiments and statistical tests demonstrate the superiority of our SSR-SPUNPSVM.},
  archive      = {J_APIN},
  author       = {Wang, Hongmei and Li, Ping and Zheng, Yuyan and Jiang, Kun and Xu, Yitian},
  doi          = {10.1007/s10489-025-06356-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-33},
  shortjournal = {Appl. Intell.},
  title        = {Sparse pinball universum nonparallel support vector machine and its safe screening rule},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3DGCformer: 3-dimensional graph convolutional transformer
for multi-step origin–destination matrix forecasting. <em>APIN</em>,
<em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06371-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting Human mobility is of great significance in the simulation and control of infectious diseases like COVID-19. To get a clear picture of potential future outbreaks, it is necessary to forecast multi-step Origin–Destination (OD) matrices for a relatively long period in the future. However, multi-step Origin–Destination Matrix Forecasting (ODMF) is a non-trivial problem. First, previous ODMF models only forecast the OD matrix for the next time-step, and they cannot perform well on long-term multi-step forecasts due to error accumulation. Second, many ODMF methods capture spatial and temporal dependencies with separate modules, which is insufficient to model spatio-temporal correlations in the time-varying OD matrix sequence. To address the challenges in multi-step ODMF, we propose 3-Dimensional Graph Convolutional Transformer (3DGCformer). As an enhancement of the original 3DGCN, we propose a novel Origin–Destination Feature Propagation (ODFP) rule between 3DGCN layers and integrate 2 3DGCNs with different spatio-temporal graphs and corresponding feature propagation rules to model the formation of OD flows in a more comprehensive way. For multi-step forecasts, 3DGCformer uses Transformer to capture long-term global temporal dependency, and adapt its decoder using labeled tokens to avoid error accumulation and improve time efficiency. To avoid information loss as the number of regions increases, we propose a patch embedding approach to convert data from 3DGCNs to the Transformer module. We perform extensive experiments on 4 real-world human mobility datasets, and the results show that our proposed model outperforms the state-of-the-art methods.},
  archive      = {J_APIN},
  author       = {Huang, Yiou and Deng, Hao and Zhao, Shengjie},
  doi          = {10.1007/s10489-025-06371-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {3DGCformer: 3-dimensional graph convolutional transformer for multi-step origin–destination matrix forecasting},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HRMG-EA: Heterogeneous graph neural network recommendation
with multi-level guidance based on enhanced-attributes. <em>APIN</em>,
<em>55</em>(6), 1–22. (<a
href="https://doi.org/10.1007/s10489-025-06428-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Graph Neural Networks are an efficient and powerful tool for modeling graph structure data in recommendation systems. However, existing heterogeneous graph neural networks often fail to model the dependencies between user and item attribute preferences, limiting graph structure optimization and consequently reducing the accuracy of recommendations. To overcome these issues, we propose a Heterogeneous graph neural network Recommendation with Multi-level Guidance based on Enhanced-Attributes (HRMG-EA). First, we design an attribute enhanced gated network to model user-item interaction attribute scenarios and obtain enhanced-attributes by capturing complex attribute dependencies. It effectively avoids the expansion of the graph scale in attribute graph scenarios and further covers personalized attribute relationship distribution characteristics of users and items. Then, we propose a novel multi-level graph structure guidance strategy based on enhanced-attributes. It guides graph structure learning from three optimization levels, optimizing from two perspectives: explicit (heterogeneity and homogeneity) and implicit (contrast enhancement). The former can screen higher-quality heterogeneous neighbor nodes in a direct interaction environment, and filter out redundant or erroneous edges under different similar semantic interest paths to improve the quality of the neighborhood environment. The latter aligns representation embeddings of enhanced-attributes and graph structure in a latent space, explores their potential commonalities, and obtains more comprehensive, fine-grained semantic and beneficial structural information. Finally, on two real-world datasets, HRMG-EA significantly outperforms the state-of-the-art baseline algorithms in both recall and normalized discounted cumulative gain. A large number of ablation experiments and analytical verifications also verify its effectiveness.},
  archive      = {J_APIN},
  author       = {Wang, Longtao and Yuan, Guiyuan and Li, Chao and Zhao, Yufei and Duan, Hua and Zeng, Qingtian},
  doi          = {10.1007/s10489-025-06428-y},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-22},
  shortjournal = {Appl. Intell.},
  title        = {HRMG-EA: Heterogeneous graph neural network recommendation with multi-level guidance based on enhanced-attributes},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Separable n-soft sets: A tool for multinary descriptions
with large-scale parameter sets. <em>APIN</em>, <em>55</em>(6), 1–37.
(<a href="https://doi.org/10.1007/s10489-025-06435-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft set theory builds on the idea of a parameterized family of subsets of a universal set, where for each pertinent characteristic, any specific member of the universe either satisfies it or not. The concept of an N-soft set sharpens this model with the aid of multinary parameterized descriptions; that is, N-soft sets categorize the options in terms of multiple classifications of the characteristics. The aim of this research is fourfold. First, this research focuses on daily-life decision-making problems that involve both positive and negative attributes that can be naturally distributed among classes. Each comparable group of attributes produces an N-soft set, and we can represent all these N-soft sets using separable N-soft sets. We show that this structure facilitates decision-making in the presence of large numbers of attributes. Second, to develop tools that provide a mechanism for the selection of an alternative in this new model, we first develop a complement operator for N-soft sets to uniformize the data, and then, we propose strategies for taking advantage of the qualities of the attributes. Aggregation operators are employed to aggregate the data into a resultant N-soft set, a fuzzy N-soft set, or a hesitant N-soft set. Several algorithmic procedures are proposed to define these methods. Third, we define the novel notion of a multihesitant N-soft set. This loosely defined concept is helpful for representing data with multiple and repetitive entries while avoiding information loss. Finally, we provide solutions to several real-life decision-making problems to illustrate the versatility of our approaches. We apply this theory to construct a new method for ranking countries participating in the Olympic Games. Our motivation is that the existing lexicographic procedure is unable to distinguish among gold, silver, and bronze medals won at sports with very different characteristics.},
  archive      = {J_APIN},
  author       = {Khan, Muhammad Jabir and Alcantud, Jose Carlos R. and Akram, Muhammad and Ding, Weiping},
  doi          = {10.1007/s10489-025-06435-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-37},
  shortjournal = {Appl. Intell.},
  title        = {Separable N-soft sets: A tool for multinary descriptions with large-scale parameter sets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dark-ControlNet: An enhanced dehazing universal plug-in
based on the dark channel prior. <em>APIN</em>, <em>55</em>(6), 1–16.
(<a href="https://doi.org/10.1007/s10489-025-06439-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing dehazing models have excellent performance in synthetic scenes but still face the challenge of low robustness in real scenes. In this paper, we propose Dark-ControlNet, a generalized and enhanced dehazing plug-in that uses the dark channel prior as a control condition, which can be deployed on existing dehazing models and can be simply fine-tuned to enhance their robustness in real scenes while improving their dehazing performance. We first freeze the backbone network to preserve its encoding and decoding capabilities and input the dark channel prior with high robustness as conditional information to the plug-in network to obtain prior knowledge. Then, we fuse the dark channel prior features into the backbone network in the form of mean-variance alignment via the Haze&amp;Dark(HD) module and guide the backbone network to decode clear images by fine-tuning the plug-in network. The experimental results show that the existing dehazing model enhanced by Dark-ControlNet performs well on synthetic datasets and real datasets.},
  archive      = {J_APIN},
  author       = {Yang, Yu and Yin, Xuesong and Wang, Yigang},
  doi          = {10.1007/s10489-025-06439-9},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-16},
  shortjournal = {Appl. Intell.},
  title        = {Dark-ControlNet: An enhanced dehazing universal plug-in based on the dark channel prior},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency-enhanced and decomposed transformer for
multivariate time series anomaly detection. <em>APIN</em>,
<em>55</em>(6), 1–18. (<a
href="https://doi.org/10.1007/s10489-025-06441-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread adoption of the Internet of Things (IoT), vast amounts of multivariate time series data are generated, which reflect the operational status of systems. Accurate and efficient anomaly detection in these data is crucial for maintaining system stability. However, data from unstable environments often exhibit high volatility, data drift, and complex patterns of anomalies. Unsupervised anomaly detection models are typically designed for stable data and lack generalizability, leading to a high rate of false positives when applied to unstable data. This paper introduces the frequency-enhanced and decomposed transformer for anomaly detection (FDTAD), which is a novel anomaly detection model based on a transformer that is enhanced with frequency and time series decomposition. FDTAD addresses data drift by decomposing time series and leverages both time-domain and frequency-domain information to improve the generalization ability of the model. The model preserves major amplitudes in the frequency domain to extract primary periodic patterns, uses spectral residuals to capture detailed variations, and incorporates a frequency-domain correlation attention mechanism to extract dependencies in frequency-domain data in a sparse representation. Additionally, a spatiotemporal module is designed to extract the temporal correlations in the data and spatial correlations among the data with different attributes. FDTAD combines a data periodic pattern reconstructor and a data detailed pattern reconstructor through an adversarial mechanism to achieve maximum accuracy in reconstructing normal data. Extensive experiments on 10 public datasets demonstrate that FDTAD outperforms state-of-the-art baseline methods, with a 4.1% improvement in the F1 score and a 4.7% improvement in precision.},
  archive      = {J_APIN},
  author       = {Li, Shijiang and Wang, Zhihai and Wang, Xiaokang and Yin, Zihao and Yao, Muyun},
  doi          = {10.1007/s10489-025-06441-1},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-18},
  shortjournal = {Appl. Intell.},
  title        = {Frequency-enhanced and decomposed transformer for multivariate time series anomaly detection},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing graph representation learning via type-aware
decoupling and node influence allocation. <em>APIN</em>, <em>55</em>(6),
1–14. (<a href="https://doi.org/10.1007/s10489-025-06443-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional graph representation methods can fit the information of graph with low-dimensional vectors, but they cannot interpret their composition, resulting in insufficient security. Graph decoupling, as a method of graph representation, can analyze the latent factors composing the graph representation vectors. However, in current graph decoupling methods, the number of factors is a hyperparameter, and enforce uniform decoupling vector dimensions which leads to information loss or redundancy. To address these issues, we propose a type-aware graph decoupling based on influence called Variational Graph Decoupling Auto-Encoder (VGDAE). It uses node labels as interpretable and objectively existing natural semantics for decoupling and allocates embedding space based on node influence, addressing the issues of manually setting the number of factors in traditional graph decoupling and the mismatch between node information size and embedding space. On the Cora, Citeseer, and fb-CMU datasets, VGDAE shows the impact of different node classes as decoupling targets on classification tasks. Furthermore, we perform visualization of the representations, VGDAE exhibits performance improvements of 2% in classification tasks and 12% in clustering tasks when compared with baseline models.},
  archive      = {J_APIN},
  author       = {Zhu, Guochang and Hu, Jun and Liu, Li and Zhang, Qinghua and Wang, Guoyin},
  doi          = {10.1007/s10489-025-06443-z},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-14},
  shortjournal = {Appl. Intell.},
  title        = {Enhancing graph representation learning via type-aware decoupling and node influence allocation},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). REFD: Recurrent encoder and fusion decoder for temporal
knowledge graph reasoning. <em>APIN</em>, <em>55</em>(6), 1–21. (<a
href="https://doi.org/10.1007/s10489-025-06445-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reasoning over Temporal Knowledge Graphs (TKGs) presents challenges in modeling the dynamic relationships and evolving behaviors of entities and relations over time. Traditional approaches often treat entities and relations separately, which limits their ability to capture their joint temporal evolution and interactions. To overcome these limitations, REFD (Recurrent Encoder and Fusion Decoder) is proposed, a novel framework designed to improve TKG reasoning. The REFD framework consists of two primary components: a recurrent encoder and a fusion decoder. The recurrent encoder incorporates three key modules: (1) the full-domain multi-scale temporal recurrent encoder, which effectively captures temporal dependencies across varying time scales, (2) the entity-relation symbiotic temporal feature deep fusion engine, which integrates temporal features of both entities and relations, and (3) the intelligent temporal feature priority dynamic adjustment mechanism, which adaptively adjusts the importance of different features over time. The fusion decoder, particularly the entity-relation feature Fusion Decoder, combines the temporal features of entities and relations to model their joint evolution, overcoming the limitations of previous methods that model them separately. By jointly capturing the evolving dynamics of entities and relations over time, REFD significantly enhances the accuracy of temporal reasoning tasks. Experimental results show that REFD outperforms existing approaches, offering superior prediction accuracy and better handling of the complexities in TKGs.},
  archive      = {J_APIN},
  author       = {Liu, Qian and Feng, Siling and Huang, MengXing and Bhatti, Uzair Aslam},
  doi          = {10.1007/s10489-025-06445-x},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {REFD: Recurrent encoder and fusion decoder for temporal knowledge graph reasoning},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Mastering table tennis with hierarchy: A reinforcement
learning approach with progressive self-play training. <em>APIN</em>,
<em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06450-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical Reinforcement Learning (HRL) is widely applied in various complex task scenarios. In complex tasks where simple model-free reinforcement learning struggles, hierarchical design allows for more efficient utilization of interactive data, significantly reducing training costs and improving training success rates. This study delves into the use of HRL based on the model-free policy layer to learn complex strategies for a robotic arm playing table tennis. Through processes such as pre-training, self-play training, and self-play training with top-level winning strategies, the robustness of the lower-level hitting strategies has been enhanced. Furthermore, a novel decay reward mechanism has been employed in the training of the higher-level agent to improve the win rate in adversarial matches against other methods. After pre-training and adversarial training, we achieved an average of 52 rally cycles for the forehand strategy and 48 rally cycles for the backhand strategy in testing. The high-level strategy training based on the decay reward mechanism resulted in an advantageous score when competing against other strategies.},
  archive      = {J_APIN},
  author       = {Ma, Hongxu and Fan, Jianyin and Xu, Haoran and Wang, Qiang},
  doi          = {10.1007/s10489-025-06450-0},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {Mastering table tennis with hierarchy: A reinforcement learning approach with progressive self-play training},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new deep learning-based approach for predicting the
geothermal heat pump’s thermal power of a real bioclimatic house.
<em>APIN</em>, <em>55</em>(6), 1–20. (<a
href="https://doi.org/10.1007/s10489-025-06457-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, growing concern about climate change and the need to reduce greenhouse gas emissions have highlighted the role of energy efficiency and sustainability on the global agenda. Energy policies are decisive in establishing regulatory frameworks and incentives to address these challenges, leading to an inclusive and more resilient energy transition. In this context, geothermal energy is an essential source of renewable, low-emission energy, capable of providing heat and electricity sustainably. The present research focuses on a bioclimatic house’s geothermal energy system based on a heating pump and a horizontal heat exchanger. The main aim is to predict the generated thermal power of the heat pump using historical data from several sensors. In particular, two approaches were proposed with both uni-variate and multi-variate scenarios. Several deep learning techniques were applied: LSTM, GRU, 1D-CNN, CNN-LSTM, and CNN-GRU, obtaining satisfactory results over the whole dataset, which comprised one year of data acquisition. Specifically, promising results have been achieved using hybrid methods combining recurrent-based and convolutional neural networks.},
  archive      = {J_APIN},
  author       = {Zayas-Gato, Francisco and Díaz-Longueira, Antonio and Arcano-Bea, Paula and Michelena, Álvaro and Calvo-Rolle, Jose Luis and Jove, Esteban},
  doi          = {10.1007/s10489-025-06457-7},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-20},
  shortjournal = {Appl. Intell.},
  title        = {A new deep learning-based approach for predicting the geothermal heat pump’s thermal power of a real bioclimatic house},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An approach to software defect prediction for small-sized
datasets. <em>APIN</em>, <em>55</em>(6), 1–21. (<a
href="https://doi.org/10.1007/s10489-025-06458-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction (SDP) is an active research subject in the software engineering domain. The earlier works on SDP use the same project’s data for prediction in future releases, called within-project defect prediction (WPDP). WPDP may not perform well when the data available for training is small in size. In this work, to address the issue of small-size data, we suggest enhancing the data by borrowing data from other software projects. For better prediction accuracy of learning models, both train and test data must follow the same distribution. However, this may not be true in the case of data being transferred from the other project. Data from different projects may follow different distributions. So, to handle this issue, we have proposed a data preprocessing method, namely data transfer-based WPDP (DT-WPDP). Next, we have shown the use of the deep neural network (DNN) for WPDP and compared it with other classical machine learning (ML) models such as k nearest neighbor, decision tree, logistic regression, and Naive Bayes classifiers. Further, we have performed experimental analysis to assess the effect of the proposed DT-WPDP data preprocessing method with DNN and other ML models. Experimental results show that the proposed approach significantly improves the accuracies of different models. Among different models, the DNN model performed best for all datasets. In the case of very small-sized datasets, which is our main concern in this work, the accuracy of the DNN model is improved by 7% after using the proposed approach.},
  archive      = {J_APIN},
  author       = {Bal, Pravas Ranjan and Shukla, Suyash and Kumar, Sandeep},
  doi          = {10.1007/s10489-025-06458-6},
  journal      = {Applied Intelligence},
  month        = {4},
  number       = {6},
  pages        = {1-21},
  shortjournal = {Appl. Intell.},
  title        = {An approach to software defect prediction for small-sized datasets},
  volume       = {55},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
