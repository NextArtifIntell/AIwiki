<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NPL_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="npl---22">NPL - 22</h2>
<ul>
<li><details>
<summary>
(2025). HGBL: A fine granular hierarchical multi-label text
classification model. <em>NPL</em>, <em>57</em>(1), 1–28. (<a
href="https://doi.org/10.1007/s11063-024-11713-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical multi-label text classification is vital for natural language processing (NLP). However, existing research rarely makes full use of the interaction between labels and text features that are crucial to hierarchical multi-label text classification. To address this issue, a novel model named hierarchy-guided BiLSTM guided contrastive learning classification (HGBL) is proposed, which successfully enhances the interaction between labels and text features by incorporating global context and embedding the idea of contrastive learning into this model. During modeling, Graphormer is adopted to model the dependencies between labels, and the bidirectional recurrent network (BiLSTM) is used to integrate global context including label features. Afterwards, the contrastive learning module embeds hierarchical awareness into the fine-tuned bidirectional encoder representations from transformers (BERT) by training the value of the loss. Experimental results on NYT, WOS and RCV1-V2 datasets show that HGBL exhibits significant competitive advantages compared with 19 competitors in terms of several indicators and can be used effectively for hierarchical multi-label text classification problems.},
  archive      = {J_NPL},
  author       = {Zhang, Chaoqun and Dai, Linlin and Liu, Chengxing and Zhang, Longhao},
  doi          = {10.1007/s11063-024-11713-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Neural Process. Lett.},
  title        = {HGBL: A fine granular hierarchical multi-label text classification model},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Continual learning in medicine: A systematic literature
review. <em>NPL</em>, <em>57</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s11063-024-11709-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual Learning (CL) is a novel AI paradigm in which tasks and data are made available over time; thus, the trained model is computed on the basis of a stream of data. CL-based approaches are able to learn new skills and knowledge without forgetting the previous ones, with no guaranteed access to previously encountered data, and mitigating the so-called “catastrophic forgetting” phenomenon. Interestingly, by making AI systems able to learn and improve over time without the need for large amounts of new data or computational resources, CL can help at reducing the impact of computationally-expensive and energy-intensive activities; hence, CL can play a key role in the path towards more green AIs, enabling more efficient and sustainable uses of resources. In this work, we describe different methods proposed in the literature to solve CL tasks; we survey different applications, highlighting strengths and weaknesses, with a particular focus on the biomedical context. Furthermore, we discuss how to make the methods more robust and suitable for a wider range of applications.},
  archive      = {J_NPL},
  author       = {Bruno, Pierangela and Quarta, Alessandro and Calimeri, Francesco},
  doi          = {10.1007/s11063-024-11709-7},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {Continual learning in medicine: A systematic literature review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LPM-net: A data-driven resource-efficient predictive motion
planner for mobile robots. <em>NPL</em>, <em>57</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s11063-024-11671-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A data-driven predictive motion planner for mobile robots, referred to as LPM-Net, has been proposed in this paper. Conventional predictive motion planners are computationally expensive, often resulting in insufficient throughput on mobile robot hardware. LPM-Net is an imitation learning-assisted local predictive non-holonomic motion planner that is capable of learning from conventional motion planners regarded as paradigm models and replicating their behavior while satisfying the same kinodynamic constraints. In addition, LPM-Net is compatible with GPU and TPU hardware, allowing for faster and more efficient processing. LPM-Net uses convolutional and recurrent long short-term memory deep neural networks to predict steering commands. This has improved computational efficiency which allows autonomous vehicles to be equipped with more cost-effective computers. In the present study, LPM-Net was tuned to mimic the behavior of a model predictive controller paradigm model. Measurements in this study demonstrate that the proposed mimic planner, LPM-Net, consumes approximately half the processing power of the conventional predictive planner, albeit with a slight increase in hesitation when reaching goals.},
  archive      = {J_NPL},
  author       = {Amirhosseini, Fakhreddin and Nilforoushan, Zahra and Leili Mirtaheri, Seyedeh},
  doi          = {10.1007/s11063-024-11671-4},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Neural Process. Lett.},
  title        = {LPM-net: A data-driven resource-efficient predictive motion planner for mobile robots},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LieCConv: An image classification algorithm based on lie
group convolutional neural network. <em>NPL</em>, <em>57</em>(1), 1–21.
(<a href="https://doi.org/10.1007/s11063-024-11691-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Lie group convolutional neural networks (LG-CNNs), the calculation and storage of Lie group distances have quadratic space complexity. In order to improve the memory utilization efficiency of LG-CNNs, a novel Lie group convolutional neural network called LieCConv is proposed. LieCConv utilizes an innovative sampling algorithm and a linear space complexity calculation and storage approach for Lie group distances, substantially enhancing network memory efficiency. Firstly, LieCConv employs a novel sampling algorithm called array-neighborhood sampling (ANS) in the downsampling stage. ANS only requires neighborhood information to obtain an excellent sample set with a low threshold of use. The sample set generated by ANS reflects the distribution of the original set. Then, LieCConv adopts a batch calculation and storage scheme for Lie group distances, which effectively declines the space complexity of calculating and storing Lie group distances from quadratic complexity to linear complexity, reducing the memory consumption during training. Finally, the contrast between ANS and farthest point sampling was presented, demonstrating that ANS better captures the distribution characteristics of the original dataset. The memory usage of LieCConv and LieConv was compared, revealing that LieCConv reduces the memory usage for calculating and storing Lie group distances to less than 500 MB. And the performance of LieCConv was evaluated on RotMNIST, RotFashionMNIST and TT100K, validating that LieCConv is universal and effective.},
  archive      = {J_NPL},
  author       = {Zhang, Yunjie and Luo, Xizhao and Tao, Chongben and Qin, Bo and Yang, Anjia and Cao, Feng},
  doi          = {10.1007/s11063-024-11691-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Neural Process. Lett.},
  title        = {LieCConv: An image classification algorithm based on lie group convolutional neural network},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Harborfront anomaly detection. <em>NPL</em>, <em>57</em>(1),
1–16. (<a href="https://doi.org/10.1007/s11063-024-11696-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Creating high-quality datasets for the task of video anomaly detection is challenging due to a subjective anomaly definition and the rarity of anomalies, which oust the possibility of obtaining statistically significant data. This results in datasets where anomalies are placed in a single category, and are often considered less relevant from a security standpoint. Instead, we propose to create video anomaly datasets based on a framework utilizing object annotations to ease the annotation process and allow users to decide on the anomaly definition. Furthermore, this allows for a fine-grained evaluation w.r.t. anomaly types, which represents a novelty in the area of video anomaly detection. The framework is demonstrated using the existing thermal long-term drift (LTD) dataset, identifying and evaluating five different types of anomalies (appearance, motion, localization, density, and tampering) on six test sets. State-of-the-art anomaly detection methods are evaluated and found to underperform on the thermal anomaly detection dataset, which emphasizes a need for an adjustable anomaly definition in order to produce better anomaly datasets and models that generalize towards practical use. We share the code of the proposed framework to extract anomaly types along with object annotations for the LTD dataset at https://github.com/jagob/harborfront-vad .},
  archive      = {J_NPL},
  author       = {Dueholm, Jacob V. and Siemon, Mia and Ionescu, Radu T. and Moeslund, Thomas B. and Nasrollahi, Kamal},
  doi          = {10.1007/s11063-024-11696-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Harborfront anomaly detection},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring dual coupledness for effective pruning in object
detection. <em>NPL</em>, <em>57</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s11063-024-11697-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pruning offers an efficient approach to compressing models deployed on resource-constrained devices. In this paper, we introduce a novel method called Dual-Coupledness Object Detection Pruning (DCODP), specifically designed for object detection models. Taking into account the complexity of model coupling, our algorithm utilizes a depth-first search approach to identify interlayer coupling within the model. It then groups sublayers with the same parent layer together. Filters corresponding to feature maps with strong coupling are pruned within the layer, and the same pruning operation is applied to the corresponding indices in other coupled layers. In order to prove the validity of our method, extensive experiments are conducted on PASCAL VOC2007, PASCAL VOC2012 and MS COCO2017. The results show that our DCODP achieves a significant reduction of 50% in parameters and an average of more than 70% impressive score.},
  archive      = {J_NPL},
  author       = {Xiaohui, Guan and Wenzhuo, Huang and Yaguan, Qian and Xinxin, Sun},
  doi          = {10.1007/s11063-024-11697-8},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Exploring dual coupledness for effective pruning in object detection},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed-time synchronization of caputo/conformable
fractional-order inertial cohen-grossberg neural networks via
event-triggered one/two-phase hybrid impulsive control. <em>NPL</em>,
<em>57</em>(1), 1–57. (<a
href="https://doi.org/10.1007/s11063-024-11703-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the fixed-time synchronization (FXS) problems of Caputo/conformable fractional-order inertial Cohen-Grossberg neural networks (FOICGNNs) by one/two-phase hybrid impulsive control (HIC) through event-triggered update strategies. By utilizing the properties of fractional calculus, several novel inequalities regarding the fixed-time convergence of hybrid impulsive systems (HIS) are obtained. We especially discuss and compare the cases of Caputo and conformable fractional order to gain deep insight into fractional calculus. By applying the Lyapunov stability theory, two hybrid controllers, which consist of event-triggered continuous controllers and impulsive controllers, are designed to realize the FXS of FOICGNNs. It’s worth pointing out that, we unprecedentedly study and compare the differences of the one-phase HIC and two-phase HIC, where a novel nonlinear impulsive controller is proposed and designed to obtain fixed-time convergence in the impulsive control phase. In addition, the exclusion of Zeno behavior is proved for the designed event-triggered strategy. Finally, several numerical examples are provided to illustrate the feasibility of the proposed control approach and the correctness of the theoretical results.},
  archive      = {J_NPL},
  author       = {Xiong, Yao and Li, Yesheng and Lv, Haifei and Wu, Wei and Xie, Songhua and Chen, Mengwei and Hu, Changkui and Li, Min},
  doi          = {10.1007/s11063-024-11703-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-57},
  shortjournal = {Neural Process. Lett.},
  title        = {Fixed-time synchronization of Caputo/Conformable fractional-order inertial cohen-grossberg neural networks via event-triggered One/Two-phase hybrid impulsive control},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network clustering for multi-task learning. <em>NPL</em>,
<em>57</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s11063-024-11712-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Multi-Task Learning (MTL) technique has been widely studied by worldwide researchers. The majority of current MTL studies adopt the hard parameter sharing structure, where hard layers tend to learn general representations over all tasks and specific layers are prone to learn specific representations for each task. Since the specific layers directly follow the hard layers, the MTL model needs to estimate this direct change (from general to specific) as well. To alleviate this problem, we introduce the novel cluster layer, which groups tasks into clusters during training procedures. In a cluster layer, the tasks in the same cluster are further required to share the same network. By this way, the cluster layer produces the general presentation for the same cluster, while produces relatively specific presentations for different clusters. The cluster layers are used as transitions between the hard layers and the specific layers. Thus, the MTL model can learn general representations to specific representations gradually. We evaluate our model with MTL document classification, and the results demonstrate the cluster layer is quite efficient in MTL.},
  archive      = {J_NPL},
  author       = {Mu, Zhiying and Gao, Dehong and Guo, Sensen},
  doi          = {10.1007/s11063-024-11712-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Neural Process. Lett.},
  title        = {Network clustering for multi-task learning},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Jointly learning type-aware relations and inter-aspect with
graph convolutional networks for aspect sentiment analysis.
<em>NPL</em>, <em>57</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s11063-024-11715-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel approach for aspect-level sentiment analysis by leveraging the relationships between dependent types and aspects. The proposed method involves simplifying the type-aware graph convolutional network and designing a graph convolution module specifically for extracting relations between aspect words. The process begins with constructing an ordinary dependency graph for each sentence using a dependency tree. This graph is then refined by considering syntactic dependencies between context words and aspect-specific words, resulting in an aspect-focused graph. The aspect-focused graph, along with the corresponding embedding matrices, is fed into the aspect-focused GCN to capture the essential aspects and context words. Moreover, an inter-aspect GCN is employed to extract the dependencies between aspect words and other aspect words, utilizing the representations learned by the focused aspect GCN based on the inter-aspect graph. The L-layer of the GCN incorporates a bidirectional attentional mechanism to extract interrelationships, thus enhancing sentiment polarity judgment. Through interactive learning of aspect-specific affective features, the model acquires an understanding of the relationships between important text and aspect words, as well as the relationships among aspect words. Experimental results on five benchmark datasets demonstrate the superior performance of our proposed method compared to state-of-the-art approaches, exhibiting a significant improvement over the regular GCN model.},
  archive      = {J_NPL},
  author       = {Zong, Liansong and Hu, Dongfeng and Gui, Qingchi and Zhang, Pengfei and Wang, Jie},
  doi          = {10.1007/s11063-024-11715-9},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Jointly learning type-aware relations and inter-aspect with graph convolutional networks for aspect sentiment analysis},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic evaluation of english translation based on
multi-granularity interaction fusion. <em>NPL</em>, <em>57</em>(1),
1–17. (<a href="https://doi.org/10.1007/s11063-025-11716-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The latest neural machine translation automatic evaluation method uses pre-trained context word vectors to extract semantic features and directly concatenates them into the neural network to predict translation quality. However, the direct operation can easily lead to a lack of interaction between features, and the layer-by-layer prediction is prone to losing fine-grained matching information. To address these issues, we propose a multi-granularity interactive fusion English translation automatic evaluation, which introduces middle and late information fusion methods. First, we use a bilinear attention distribution to capture high-order cross language feature interactions. By stacking multiple high-order interaction blocks and equipping them with an index linear unit without parameters for middle fusion in a parameter-free manner. Second, we use fine-grained accurate matching sentence shift distance and sentence-level cosine similarity for late fusion. The experimental results on the WMT’21 Metrics Task benchmark dataset show that the proposed method can effectively improve its correlation with human evaluation and achieve comparable performance with the best participating system.},
  archive      = {J_NPL},
  author       = {Chen, Xibo and Yang, Yonghe and Hu, Haize},
  doi          = {10.1007/s11063-025-11716-2},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Automatic evaluation of english translation based on multi-granularity interaction fusion},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature enhancement-based few-shot bearing surface defect
image classification method. <em>NPL</em>, <em>57</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s11063-025-11720-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of intelligent bearing surface defect classification based on deep neural networks remains challenging in real factories, due to the scarcity of defect samples. Under real-working conditions, with less training samples, the paper proposes a few-shot bearing defect image classification network which can recognize different bearing surface defects image, including notch, reddish rust, scratching, incising, conformity, pitting and mill scale. Based on general metric learning neural network framework, a local feature extraction layer is designed, which calculates the auto-correlation vector of global feature in a sliding region to enhance detail features. Additionally, a similar feature attention module emphasizes the the regions of similarity between the query set and the class prototype center to overcome the influence of background noise on classification. To validate the effectiveness of the proposed network, comparative experiments were conducted using the benchmark dataset miniImageNet, achieving classification accuracies of 59% in the 5-way 1-shot setting and 76% in the 5-way 5-shot setting respectively. Furthermore, to assess its performance in a real-factory condition, a self-made dataset of bearing defects from a factory was employed. The proposed network achieved a remarkable classification accuracy of 88% in the 5-way 5-shot setting. These experimental results confirm the practical application value of our few-shot bearing surface defect image classification network, demonstrating its ability to accurately recognize various bearing defects with limited training samples.},
  archive      = {J_NPL},
  author       = {Cang, Yan and Zhang, Xuanshang},
  doi          = {10.1007/s11063-025-11720-6},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {Feature enhancement-based few-shot bearing surface defect image classification method},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-dimensional feature interaction for conversational
aspect-based quadruple sentiment analysis. <em>NPL</em>, <em>57</em>(1),
1–19. (<a href="https://doi.org/10.1007/s11063-025-11721-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational aspect-level quadruple sentiment analysis (DiaASQ) is proposed as a new task that aims to extract target-aspect-opinion-sentiment quadruples in dialogues. However, this task faces the problem of complex context matching and multiple utterance feature modeling, which creates difficulties in extracting quadruples from multiple intersecting utterances. To address this problem, this paper proposes a Multi-dimensional Dialogue Feature Interaction (MDFI) approach. This method models dialogue features through an interactive network structure to capture interactions between utterance features. The approach adds two layers of ResNet to achieve deep association fusion based on multi-head self-attention. It superimposes the associated features of replies, speakers, and dialogue threads layer by layer and enhances the capability of conversation representation through linear augmentation. Our model outperforms the DiaASQ benchmark model in global utterance, intra-utterance, and cross-utterance quadruple extraction. In particular, the ZH dataset shows an improvement of 7.42 in global utterance and 9.66 in cross-utterance.},
  archive      = {J_NPL},
  author       = {Zhao, Zhongyang and Zhang, Long and Zheng, Qiusheng and Zhang, Junshuai},
  doi          = {10.1007/s11063-025-11721-5},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Neural Process. Lett.},
  title        = {Multi-dimensional feature interaction for conversational aspect-based quadruple sentiment analysis},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Value creation for healthcare ecosystems through artificial
intelligence applied to physician-to-physician communication: A
systematic review. <em>NPL</em>, <em>57</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s11063-025-11725-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study reviews the role of artificial intelligence (AI) in enhancing healthcare through an analysis of physician-to-physician communication. It seeks to identify the best practices for extracting value from professional medical chats (PMCs) and assess the impact of AI on patient outcomes and healthcare systems, emphasizing the integration of ethical and responsible AI practices. We conducted an extensive systematic literature review using the Web of Science Core Collection. Searches encompassed English-language articles published between January 2019 and July 2023 using keywords related to AI, machine learning, natural language processing, and physician communication. Of the 247 articles screened, 13 met the inclusion criteria given their in-depth analysis of AI in healthcare communication, methodological soundness, and relevance to clinical outcomes. The review provides insights into interprofessional communication dynamics, the advancement of NLP and deep learning in medical dialogues, and strategies for effective human-machine collaboration. Ethical considerations and the need for transparency in AI applications are key to these central findings. This study highlights the untapped potential of physician-generated real-world data in creating value for healthcare ecosystems. It advocates for a multidisciplinary strategy encompassing communication, education, and collaboration to advance AI in healthcare responsibly. Moreover, it suggests that by combining existing techniques in the AI discipline, including neural networks, generative AI, and genetic algorithms, as well as keeping a “physician in the loop” when building AI systems, we can have a significant impact on healthcare delivery and medical research.},
  archive      = {J_NPL},
  author       = {Rubinstein, Beny and Matos, Sergio},
  doi          = {10.1007/s11063-025-11725-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Neural Process. Lett.},
  title        = {Value creation for healthcare ecosystems through artificial intelligence applied to physician-to-physician communication: A systematic review},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AUMEs: AU detection-based dual-stream multi-task 3DCNN for
micro-expression recognition. <em>NPL</em>, <em>57</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s11063-025-11726-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expressions are brief, involuntary facial movements that can reveal real emotions. However, their short duration and low intensity pose a challenge for feature extraction and learning of neural networks. To overcome this challenge, we propose AUMEs, a 3DCNN-based multi-task learning framework that utilizes deep learning-based Lagrangian motion magnification and optical flow computation methods to enhance spatio-temporal features of micro-expressions, thus solving the problem of weak micro-expression motion intensity. AUMEs also use AU detection as a parallel task to improve the accuracy of micro-expression recognition by transferring knowledge from the AU detection task, and focal loss is utilized in model training to handle category imbalance in the micro-expression dataset. AUMEs achieve competitive results compared with existing SOTA methods on the CASMEII and SAMM datasets, achieving accuracy (Acc.) of 81.05% and 79.85%, UF1 score reaches 0.8880 and 0.7450 on the five-category task, and on the three-category UAR reached 89.02% and 75.86% and 0.8880 and 0.7450 for UF1. Furthermore, in both dataset analyses, the multi-task approach surpassed the single-task method across both the five-category and three-category classifications.},
  archive      = {J_NPL},
  author       = {Shi, Hu and Wang, Yanxia and Wang , Renjie and Liu, Dan},
  doi          = {10.1007/s11063-025-11726-0},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Neural Process. Lett.},
  title        = {AUMEs: AU detection-based dual-stream multi-task 3DCNN for micro-expression recognition},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Few-shot object detection based on global domain adaptation
strategy. <em>NPL</em>, <em>57</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s11063-025-11727-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming to detect novel objects from only a few annotated samples, few-shot object detection (FSOD) has undergone remarkable development. Previous works rarely pay attention to the perspective of gradient propagation to optimize existing methods, therefore failing to make full use of information for novel objects in gradient propagation. We propose a method to solve this problem based on two-stage fine-tuning. A domain adaptation module with multi-constraints is used to promote the spread of gradients, a classification promotion network is used to improve the effect of classification, and a multi-path mask head is added to enrich RoI features. Experiments on PASCAL VOC and COCO datasets show that our model significantly raises the performance compared with previous methods (up to 1–5 $$\%$$ in average).},
  archive      = {J_NPL},
  author       = {Gong, Xiaolin and Cai, Youpeng and Wang, Jian and Liu, Daqing and Ma, Yongtao},
  doi          = {10.1007/s11063-025-11727-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Few-shot object detection based on global domain adaptation strategy},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GrapHisto: A robust representation of graph-structured data
for graph convolutional networks. <em>NPL</em>, <em>57</em>(1), 1–27.
(<a href="https://doi.org/10.1007/s11063-025-11728-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning from graphs is an established branch of AI research motivated by the relevance of applications that involve graph-structured data. The most popular instance is the graph neural network (GNN). On the other hand, due to the promising results of deep learning models in the most diverse fields of application, several efforts have been made to replicate these successes when dealing with graphical data. A prominent specimen of the kind is the graph convolutional network (GCN). Along these lines, the paper propose a novel approach for processing graphs that exploits the capabilities of convolutional neural networks (CNNs) to learn from images. This is achieved by means of a new representation of graphs, called GrapHisto, that portrays graphs in the form of characteristic “pictures”. The GrapHisto is in the form of graph-specific, unique tensors encapsulating the graph topology and its features (i.e., the labels associated with vertexes and edges). This representation is fed to a CNN, and the resulting machine is termed GrapHisto-CNN. The paper provides some theoretical investigations of the properties of the approach, and proposes solutions to some practical issues. An experimental evaluation of the GrapHisto-CNN is reported, revolving around two setups: classification of synthetically-generated graphs, and molecule classification form the dataset QM9. The results show that the approach is effective and robust, and that it compares favorably with GNNs and GCNs.},
  archive      = {J_NPL},
  author       = {Benini, Marco and Bongini, Pietro and Trentin, Edmondo},
  doi          = {10.1007/s11063-025-11728-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Neural Process. Lett.},
  title        = {GrapHisto: A robust representation of graph-structured data for graph convolutional networks},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ECTTLNER: An effective cross-task transferring learning
method for low-resource named entity recognition. <em>NPL</em>,
<em>57</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s11063-025-11729-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition is a fundamental task in natural language processing that significantly impacts the performance of its downstream tasks. Cross-task transfer learning methods are more naturally suited for low-resource named entity recognition compared to cross-language and cross-domain transfer learning methods. Existing cross-task transfer learning methods improve the performance of the low-resource named entity recognition by leveraging relevant information from other auxiliary tasks, such as sentence-level and token-level information. However, these methods do not fully exploit token-level information of entities, leaving room for improvement in low-resource named entity recognition. To futher improve the performance of the low-resource named entity recognition, this paper proposes a simple and effective cross-task transfer learning method called ECTTLNER, which introduces Sentence Contains Entities, Sentence Entity Number, Token Is Entity, and Token Boundary Label prediction tasks into named entity recognition and performs multi-task learning together with the main sequence labeling task. Experimental results on three NER datasets demonstrate that ECTTLNER outperforms a set of state-of-the-art baseline models, and achieves more than a 2.6% improvement in F1-score over these baseline models, particularly in low-resource scenarios.},
  archive      = {J_NPL},
  author       = {Xu, Yiwu and Chen, Yun},
  doi          = {10.1007/s11063-025-11729-x},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Neural Process. Lett.},
  title        = {ECTTLNER: An effective cross-task transferring learning method for low-resource named entity recognition},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Power analysis attacks on NVM crossbar-based neuromorphic
systems. <em>NPL</em>, <em>57</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s11063-025-11730-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new adversarial attack strategy against neuromorphic systems using analysis of power consumption. Specifically, we show that neuromorphic designs based on non-volatile memory crossbars can leak important information about loss sensitivity in their power profile. Adversaries can use this information to craft evasion attacks even if they don’t know the dataset that the model was trained on. In our experiments, we show that these types of attacks are effective against both single-layer and multilayer neuromorphic implementations of neural networks, and they can be made query-efficient through Bayesian optimization. We also provide theoretical insights into the relationship between the loss sensitivity and the power consumption measurements, showing that, for single-layer networks, the correlation coefficient of these two metrics scales inversely with the square root of the input size. Finally, this paper proposes that low bitwidth quantization could be an effective defense strategy against the class of attacks discussed herein.},
  archive      = {J_NPL},
  author       = {Merkel, Cory and Su, Allen},
  doi          = {10.1007/s11063-025-11730-4},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Neural Process. Lett.},
  title        = {Power analysis attacks on NVM crossbar-based neuromorphic systems},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Recent emerging techniques in explainable artificial
intelligence to enhance the interpretable and understanding of AI models
for human. <em>NPL</em>, <em>57</em>(1), 1–32. (<a
href="https://doi.org/10.1007/s11063-025-11732-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in Explainable Artificial Intelligence (XAI) aim to bridge the gap between complex artificial intelligence (AI) models and human understanding, fostering trust and usability in AI systems. However, challenges persist in comprehensively interpreting these models, hindering their widespread adoption. This study addresses these challenges by exploring recently emerging techniques in XAI. The primary problem addressed is the lack of transparency and interpretability in AI models to humanity for institution-wide use, which undermines user trust and inhibits their integration into critical decision-making processes. Through an in-depth review, this study identifies the objectives of enhancing the interpretability of AI models and improving human understanding of their decision-making processes. Various methodological approaches, including post-hoc explanations, model transparency methods, and interactive visualization techniques, are investigated to elucidate AI model behaviours. We further present techniques and methods to make AI models more interpretable and understandable to humans including their strengths and weaknesses to demonstrate promising advancements in model interpretability, facilitating better comprehension of complex AI systems by humans. In addition, we provide the application of XAI in local use cases. Challenges, solutions, and open research directions were highlighted to clarify these compelling XAI utilization challenges. The implications of this research are profound, as enhanced interpretability fosters trust in AI systems across diverse applications, from healthcare to finance. By empowering users to understand and scrutinize AI decisions, these techniques pave the way for more responsible and accountable AI deployment.},
  archive      = {J_NPL},
  author       = {Mathew, Daniel Enemona and Ebem, Deborah Uzoamaka and Ikegwu, Anayo Chukwu and Ukeoma, Pamela Eberechukwu and Dibiaezue, Ngozi Fidelia},
  doi          = {10.1007/s11063-025-11732-2},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Neural Process. Lett.},
  title        = {Recent emerging techniques in explainable artificial intelligence to enhance the interpretable and understanding of AI models for human},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Master–slave finite-time synchronization of chaotic
fractional-order neural networks under hybrid sampled-data control: An
LMI approach. <em>NPL</em>, <em>57</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s11063-025-11733-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid controller with a sampled data control is investigated to achieve finite-time master–slave synchronization of delayed fractional-order neural networks (DFONNs). A Lyapunov-Krasovskii functional is constructed to obtain the sufficient conditions that incorporate delay information. For the first time, the asymptotic stability of the error system is guaranteed in a finite-time using the inequality technique and a sampled-data hybrid controller. The obtained conditions are expressed via linear matrix inequality. Notably, the proposed approach outperforms existing methods, demonstrating improved results in a comparative analysis. An explicit formula is utilized to calculate the settling time, which is significantly influenced by the fractional order $$0&lt;\beta \le 1$$ . The superior performance of the proposed control method is evident, showcasing its effectiveness through numerical simulations and addressing the synchronization problem in DFONNs.},
  archive      = {J_NPL},
  author       = {Kiruthika, R. and Manivannan, A.},
  doi          = {10.1007/s11063-025-11733-1},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Neural Process. Lett.},
  title        = {Master–Slave finite-time synchronization of chaotic fractional-order neural networks under hybrid sampled-data control: An LMI approach},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parkinsons detection from gait time series classification
using modified metaheuristic optimized long short term memory.
<em>NPL</em>, <em>57</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s11063-025-11735-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurodegenerative conditions are defined by the progressive deterioration and death of nerve cells in the core neural system. Most neurodegenerative conditions are not curable. While there have been significant improvements and techniques used to treat these diseases early diagnosis continues to play a crucial role in the entire approach. Conditions are often diagnosed only once they start negatively impacting the daily life of those affected. Early detection and timely preventative treatment can help improve patient subjective well-being. This study examines the application of a non-invasive gait analysis technique for the detection of Parkinson’s disease. Publicly available data collected from patients suffering from Parkinson’s along with control groups is utilized and combined with long-short-term neural networks to construct models capable of detecting signs on Parkinson’s disorder. However, because of the significant reliance of models on appropriate parameters selection, metaheuristic algorithms are used to fine tune the selection process, and a modified variation of the strongly founded PSO algorithm was proposed. Several contemporary optimizers are compared based on their ability to optimize model performance. This suggested approach achieved the superior outcomes with an accuracy of 89.92%. The constructed models have been evaluated to determine feature importance using game theory based methods.},
  archive      = {J_NPL},
  author       = {Markovic, Filip and Jovanovic, Luka and Spalevic, Petar and Kaljevic, Jelena and Zivkovic, Miodrag and Simic, Vladimir and Shaker, Hotefa and Bacanin, Nebojsa},
  doi          = {10.1007/s11063-025-11735-z},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Neural Process. Lett.},
  title        = {Parkinsons detection from gait time series classification using modified metaheuristic optimized long short term memory},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correction: LPM-net: A data-driven resource-efficient
predictive motion planner for mobile robots. <em>NPL</em>,
<em>57</em>(1), 1. (<a
href="https://doi.org/10.1007/s11063-025-11736-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NPL},
  author       = {Amirhosseini, Fakhreddin and Nilforoushan, Zahra and Mirtaheri, Seyedeh Leili},
  doi          = {10.1007/s11063-025-11736-y},
  journal      = {Neural Processing Letters},
  month        = {2},
  number       = {1},
  pages        = {1},
  shortjournal = {Neural Process. Lett.},
  title        = {Correction: LPM-net: a data-driven resource-efficient predictive motion planner for mobile robots},
  volume       = {57},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
