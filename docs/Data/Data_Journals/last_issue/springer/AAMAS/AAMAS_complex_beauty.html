<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AAMAS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aamas---22">AAMAS - 22</h2>
<ul>
<li><details>
<summary>
(2025). Epistemic selection of costly alternatives: The case of
participatory budgeting. <em>AAMAS</em>, <em>39</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10458-024-09677-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We initiate the study of voting rules for participatory budgeting using the so-called epistemic approach, where one interprets votes as noisy reflections of some ground truth regarding the objectively best set of projects to fund. Using this approach, we first show that both the most studied rules in the literature and the most widely used rule in practice cannot be justified on epistemic grounds: they cannot be interpreted as maximum likelihood estimators, whatever assumptions we make about the accuracy of voters. Focusing then on welfare-maximising rules, we obtain both positive and negative results regarding epistemic guarantees.},
  archive      = {J_AAMAS},
  author       = {Rey, Simon and Endriss, Ulle},
  doi          = {10.1007/s10458-024-09677-2},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Epistemic selection of costly alternatives: The case of participatory budgeting},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ability and knowledge: From epistemic transition systems to
labelled stit models. <em>AAMAS</em>, <em>39</em>(1), 1–41. (<a
href="https://doi.org/10.1007/s10458-024-09661-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is possible to know that one can guarantee a certain result and yet not know how to guarantee it. In such cases one has the ability to guarantee something in a causal sense, but not in an epistemic sense. In this paper we focus on two formalisms used to model both conceptions of ability: one formalism based on epistemic transition systems and the other on labelled stit models. We show a strong correspondence between the two formalisms by providing mappings from the former to the latter for both the languages and the structures. Moreover, we demonstrate that our extension of labelled stit logic is more expressive than the logic of epistemic transition systems.},
  archive      = {J_AAMAS},
  author       = {Kuncová, Alexandra and Broersen, Jan and Duijf, Hein and Ramírez Abarca, Aldo Iván},
  doi          = {10.1007/s10458-024-09661-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-41},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Ability and knowledge: From epistemic transition systems to labelled stit models},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information gathering in POMDPs using active inference.
<em>AAMAS</em>, <em>39</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s10458-024-09683-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gathering information about the environment state is the main goal in several planning tasks for autonomous agents, such as surveillance, inspection and tracking of objects. Such planning tasks are typically modeled using a Partially Observable Markov Decision Process (POMDP), and in the literature several approaches have emerged to consider information gathering during planning and execution. Similar developments can be seen in the field of active inference, which focuses on active information collection in order to be able to reach a goal. Both fields use POMDPs to model the environment, but the underlying principles for action selection are different. In this paper we create a bridge between both research fields by discussing how they relate to each other and how they can be used for information gathering. Our contribution is a tailored approach to model information gathering tasks directly in the active inference framework. A series of experiments demonstrates that our approach enables agents to gather information about the environment state. As a result, active inference becomes an alternative to common POMDP approaches for information gathering, which opens the door towards more cross cutting research at the intersection of both fields. This is advantageous, because recent advancements in POMDP solvers may be used to accelerate active inference, and the principled active inference framework may be used to model POMDP agents that operate in a neurobiologically plausible fashion.},
  archive      = {J_AAMAS},
  author       = {Walraven, Erwin and Sijs, Joris and Burghouts, Gertjan J.},
  doi          = {10.1007/s10458-024-09683-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Information gathering in POMDPs using active inference},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aggregating bipolar opinions through bipolar
assumption-based argumentation. <em>AAMAS</em>, <em>39</em>(1), 1–34.
(<a href="https://doi.org/10.1007/s10458-024-09684-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a novel method to aggregate bipolar argumentation frameworks expressing opinions of different parties in debates. We use Bipolar Assumption-based Argumentation (ABA) as an all-encompassing formalism for bipolar argumentation under different semantics. By leveraging on recent results on judgement aggregation in social choice theory, we prove several preservation results for relevant properties of bipolar ABA using quota and oligarchic rules. Specifically, we prove (positive and negative) results about the preservation of conflict-free, closed, admissible, preferred, complete, set-stable, well-founded and ideal extensions in bipolar ABA, as well as the preservation of acceptability, acyclicity and coherence for individual assumptions. Finally, we illustrate our methodology and results in the context of a case study on opinion aggregation for the treatment of long COVID patients.},
  archive      = {J_AAMAS},
  author       = {Dickie, Charles and Lauren, Stefan and Belardinelli, Francesco and Rago, Antonio and Toni, Francesca},
  doi          = {10.1007/s10458-024-09684-3},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Aggregating bipolar opinions through bipolar assumption-based argumentation},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). La VIDA: Towards a motivated goal reasoning agent.
<em>AAMAS</em>, <em>39</em>(1), 1–36. (<a
href="https://doi.org/10.1007/s10458-024-09685-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An autonomous agent deployed to operate over extended horizons in uncertain environments will encounter situations for which it was not designed. A class of these situations involves an invalidation of agent goals and limited guidance in establishing a new set of goals to pursue. An agent will benefit from some mechanism that will allow it to pursue new goals under these circumstances such that the goals are broadly useful in its environment and take advantage of its existing skills while aligning with societal norms. We propose augmenting a goal reasoning agent, i.e., an agent that can deliberate on and self-select its goals, with a motivation system that can be used to both constrain and motivate agent behavior. A human-like motivation system coupled with a goal-self concordant selection technique allows the approach to be framed as an optimization problem in which the agent selects goals that have high utility while simultaneously in harmony with its motivations. Over the agent’s operational lifespan its motivation system adjusts incrementally to more closely reflect the reality of its goal reasoning and goal pursuit experiences. Experiments performed with an ablation testing technique comparing the average utility of goals achieved in the presence and absence of a motivation system suggest that the motivated version of the system leads to pursuing more useful goals than the baseline.},
  archive      = {J_AAMAS},
  author       = {Addison, Ursula},
  doi          = {10.1007/s10458-024-09685-2},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {La VIDA: Towards a motivated goal reasoning agent},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Budget-feasible egalitarian allocation of conflicting jobs.
<em>AAMAS</em>, <em>39</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s10458-024-09686-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Allocating conflicting jobs among individuals while respecting a budget constraint for each individual is an optimization problem that arises in various real-world scenarios. In this paper, we consider the situation where each individual derives some satisfaction from each job. We focus on finding a feasible allocation of conflicting jobs that maximize egalitarian cost, i.e., the satisfaction of the individual who is worst-off. To the best of our knowledge, this is the first paper to combine egalitarianism, budget-feasibility, and conflict-freeness in allocations. We provide a systematic study of the computational complexity of finding budget-feasible conflict-free egalitarian allocation and show that our problem generalizes a large number of classical optimization problems. Therefore, unsurprisingly, our problem is NP-hard even for two individuals and when there is no conflict between any jobs. We show that the problem admits algorithms when studied in the realm of approximation algorithms and parameterized algorithms with a host of natural parameters that match and in some cases improve upon the running time of known algorithms.},
  archive      = {J_AAMAS},
  author       = {Gupta, Sushmita and Jain, Pallavi and Mohanapriya, A. and Tripathi, Vikash},
  doi          = {10.1007/s10458-024-09686-1},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Budget-feasible egalitarian allocation of conflicting jobs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reflexive anticipatory reasoning by BDI agents.
<em>AAMAS</em>, <em>39</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s10458-025-09687-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates how predictions about the future behaviour of an agent can be exploited to improve its decision-making in the present. Future states are foreseen by a simulation technique, which is based on models of both the environment and the agent. Although the environment model is usually taken into account for prediction in artificial intelligence (e.g., in automated planning), the agent model receives less attention. We leverage the agent model to speed up the simulation and as a source of alternative decisions. Our proposal bases the agent model on the practical knowledge the developer has given to the agent, especially in the case of BDI agents. This knowledge is thus exploited in the proposed future-concerned reasoning mechanisms. We present a prototype implementation of our approach as well as the results from its evaluation on static and dynamic environments. This allows us to better understand the relation between the improvement in agent decisions and the quality of the knowledge provided by the developer.},
  archive      = {J_AAMAS},
  author       = {Hübner, Jomi Fred and Burattini, Samuele and Ricci, Alessandro and Mayer, Simon},
  doi          = {10.1007/s10458-025-09687-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Reflexive anticipatory reasoning by BDI agents},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disagree and commit: Degrees of argumentation-based
agreements. <em>AAMAS</em>, <em>39</em>(1), 1–38. (<a
href="https://doi.org/10.1007/s10458-025-09688-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cooperative human decision-making, agreements are often not total; a partial degree of agreement is sufficient to commit to a decision and move on, as long as one is somewhat confident that the involved parties are likely to stand by their commitment in the future, given no drastic unexpected changes. In this paper, we introduce the notion of agreement scenarios that allow artificial autonomous agents to reach such agreements, using formal models of argumentation, in particular abstract argumentation and value-based argumentation. We introduce the notions of degrees of satisfaction and (minimum, mean, and median) agreement, as well as a measure of the impact a value in a value-based argumentation framework has on these notions. We then analyze how degrees of agreement are affected when agreement scenarios are expanded with new information, to shed light on the reliability of partial agreements in dynamic scenarios. An implementation of the introduced concepts is provided as part of an argumentation-based reasoning software library.},
  archive      = {J_AAMAS},
  author       = {Kampik, Timotheus and Nieves, Juan Carlos},
  doi          = {10.1007/s10458-025-09688-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Disagree and commit: Degrees of argumentation-based agreements},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multi-level explainability framework for engineering and
understanding BDI agents. <em>AAMAS</em>, <em>39</em>(1), 1–42. (<a
href="https://doi.org/10.1007/s10458-025-09689-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the complexity of software systems rises, explainability - i.e. the ability of systems to provide explanations of their behaviour - becomes a crucial property. This is true for any AI-based systems, including autonomous systems that exhibit decisionmaking capabilities such as multi-agent systems. Although explainabil- ity is generally considered useful to increase the level of trust for end-users, we argue it is also an interesting property for software engineers, developers, and designers to debug and validate the system’s behaviour. In this paper, we propose a multi-level explainability framework for BDI agents to generate explanations of a running system from logs at different levels of abstraction, tailored to different users and their needs. We describe the mapping from logs to explanations, and present a prototype tool based on the JaCaMo platform which implements the framework.},
  archive      = {J_AAMAS},
  author       = {Yan, Elena and Burattini, Samuele and Hübner, Jomi Fred and Ricci, Alessandro},
  doi          = {10.1007/s10458-025-09689-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-42},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A multi-level explainability framework for engineering and understanding BDI agents},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A formal testing method for multi-agent systems using
colored petri nets. <em>AAMAS</em>, <em>39</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s10458-025-09690-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomy in software, a system’s ability to make decisions and take actions independently without human intervention, is a fundamental characteristic of multi-agent systems. Testing, a crucial phase of software validation, is particularly challenging in multi-agent systems due to its complexity, as the interaction between autonomous agents can result in emergent behaviors and collective intelligence, leading to system properties not found in individual agents. A multi-agent system operates on at least three main dimensions: the individual level, the social level, and the communication interfaces. An organizational model formally defines a multi-agent system’s structure, roles, relationships, and interactions. It represents the social layer, capturing agents’ collective dynamics and dependencies, facilitating coherent and efficient collaboration to achieve individual and collective goals. During the literature review, a gap was identified when testing the social layer of multi-agent systems. This paper presents a testing approach by formally introducing steps to map an organizational model, here $$\mathcal {M}$$ oise $$^+$$ , into a colored Petri net. This mapping aims to generate a formal system model, which is used to generate and count test cases based on a coverage criterion. Finally, a use case called Inspector was presented to demonstrate the method by generating test cases, executing the test, and identifying execution errors.},
  archive      = {J_AAMAS},
  author       = {Machado, Ricardo Arend and Cardoso, Arthur da Silva Zelindro and Farias, Giovani Parente and Gonçalves, Eder Mateus Nunes and Adamatti, Diana Francisca},
  doi          = {10.1007/s10458-025-09690-z},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A formal testing method for multi-agent systems using colored petri nets},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An introduction to computational argumentation research from
a human argumentation perspective. <em>AAMAS</em>, <em>39</em>(1), 1–59.
(<a href="https://doi.org/10.1007/s10458-025-09692-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational Argumentation studies how human argumentative reasoning can be approached from a computational viewpoint. Human argumentation is a complex process that has been studied from different perspectives (e.g., philosophical or linguistic) and that involves many different aspects beyond pure reasoning, such as the role of emotions, values, social contexts, and practical constraints, which are often overlooked in computational approaches to argumentation. The heterogeneity of human argumentation is present in Computational Argumentation research, in the form of various tasks that approach the main phases of argumentation individually. With the increasing interest of researchers in Artificial Intelligence, we consider that it is of great importance to provide guidance on the Computational Argumentation research area. Thus, in this paper, we present a general overview of Computational Argumentation, from the perspective of how humans argue. For that purpose, the following contributions are produced: (i) a consistent structure for Computational Argumentation research mapped with the human argumentation process; (ii) a collective understanding of the tasks approached by Computational Argumentation and their synergies; (iii) a thorough review of important advances in each of these tasks; and (iv) an analysis and a classification of the future trends in Computational Argumentation research and relevant open challenges in the area.},
  archive      = {J_AAMAS},
  author       = {Ruiz-Dolz, Ramon and Heras, Stella and García-Fornes, Ana},
  doi          = {10.1007/s10458-025-09692-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-59},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {An introduction to computational argumentation research from a human argumentation perspective},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Low variance trust region optimization with independent
actors and sequential updates in cooperative multi-agent reinforcement
learning. <em>AAMAS</em>, <em>39</em>(1), 1–34. (<a
href="https://doi.org/10.1007/s10458-025-09695-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative multi-agent reinforcement learning assumes each agent shares the same reward function and can be trained effectively using the Trust Region framework of single-agent. Instead of relying on other agents’ actions, the independent actors setting considers each agent to act based only on its local information, thus having more flexible applications. However, in the sequential update framework, it is required to re-estimate the joint advantage function after each individual agent’s policy step. Despite the practical success of importance sampling, the updated advantage function suffers from exponentially high variance problems, which likely results in unstable convergence. In this work, we first analyze the high variance advantage both empirically and theoretically. To overcome this limitation, we introduce a clipping objective to control the upper bounds of the advantage fluctuation in sequential updates. With the proposed objective, we provide a monotonic bound with sub-linear convergence to $$\varepsilon$$ -Nash Equilibria. We further derive two new practical algorithms using our clipping objective. The experiment results on three popular multi-agent reinforcement learning benchmarks show that our proposed method outperforms the tested baselines in most environments. By carefully analyzing different training settings, our proposed method is highlighted with both stable convergence properties and the desired low advantage variance estimation. For reproducibility purposes, our source code is publicly available at https://github.com/giangbang/Low-Variance-Trust-Region-MARL .},
  archive      = {J_AAMAS},
  author       = {Le, Bang Giang and Ta, Viet Cuong},
  doi          = {10.1007/s10458-025-09695-8},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-34},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Low variance trust region optimization with independent actors and sequential updates in cooperative multi-agent reinforcement learning},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Solving multi-agent games on networks. <em>AAMAS</em>,
<em>39</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10458-025-09696-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent games on networks (GoNs) have nodes that represent agents and edges that represent interactions among agents. A special class of GoNs is composed of 2-players games on each of their edges. General GoNs have games that are played by all agents in each neighborhood. Solutions to games on networks are stable states (i.e., pure Nash equilibria), and in general one is interested in efficient solutions (of high global social welfare). This study addresses the multi-agent aspect of games on networks—a system of multiple agents that compose a game and seek a solution by performing a multi-agent (distributed) algorithm. The agents playing the game are assumed to be strategic and an iterative distributed algorithm is proposed, that lets the agents interact (i.e., negotiate) in neighborhoods in a process that guarantees the convergence of any multi-agent game on network to a globally stable state. The proposed algorithm—the TECon algorithm—iterates, one neighborhood at a time, performing a repeated social choice action. A truth-enforcing mechanism is integrated into the algorithm, collecting the valuations of agents in each neighborhood and computing incentives while eliminating strategic behavior. The proposed method is proven to converge to globally stable states that are at least as efficient as the initial state, for any game on network. A specific version of the algorithm is given for the class of Public Goods Games, where the main properties of the algorithm are guaranteed even when the strategic agents playing the game consider their possible future valuations when interacting. An extensive experimental evaluation on randomly generated games on networks demonstrates that the TECon algorithm converges very rapidly. On general forms of public goods games, the proposed algorithm outperforms former solving methods, where former methods are applicable.},
  archive      = {J_AAMAS},
  author       = {Vaknin, Yair and Meisels, Amnon},
  doi          = {10.1007/s10458-025-09696-7},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Solving multi-agent games on networks},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A game-theoretic approach for hierarchical epidemic control.
<em>AAMAS</em>, <em>39</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10458-025-09697-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We design and analyze a multi-level game-theoretic model of hierarchical policy interventions for epidemic control, such as those in response to the COVID-19 pandemic. Our model captures the potentially mismatched priorities among a hierarchy of policy-makers (e.g., federal, state, and local governments) with respect to two cost components that have opposite dependence on the policy strength—post-intervention infection rates and the socio-economic cost of policy implementation. Additionally, our model includes a crucial third factor in decisions: a cost of non-compliance with the policy-maker immediately above in the hierarchy, such as non-compliance of counties with state-level policies. We propose two novel algorithms for approximating solutions to such games. The first is based on best response dynamics (BRD) and exploits the tree structure of the game. The second combines quadratic integer programming (QIP), which enables us to collapse the two lowest levels of the game, with the best response dynamics. We experimentally characterize the scalability and equilibrium approximation quality of our two approaches against model parameters. Finally, we conduct experiments in simulations based on both synthetic and real-world data under various parameter configurations and analyze the resulting (approximate) equilibria to gain insight into the impact of decentralization on overall welfare (measured as the negative sum of costs) as well as emergent properties like social welfare, free-riding, and fairness in cost distribution among policy-makers.},
  archive      = {J_AAMAS},
  author       = {Jia, Feiran and Mate, Aditya and Li, Zun and Jabbari, Shahin and Chakraborty, Mithun and Tambe, Milind and Wellman, Michael P. and Vorobeychik, Yevgeniy},
  doi          = {10.1007/s10458-025-09697-6},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {A game-theoretic approach for hierarchical epidemic control},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Emergent language: A survey and taxonomy. <em>AAMAS</em>,
<em>39</em>(1), 1–73. (<a
href="https://doi.org/10.1007/s10458-025-09691-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The field of emergent language represents a novel area of research within the domain of artificial intelligence, particularly within the context of multi-agent reinforcement learning. Although the concept of studying language emergence is not new, early approaches were primarily concerned with explaining human language formation, with little consideration given to its potential utility for artificial agents. In contrast, studies based on reinforcement learning aim to develop communicative capabilities in agents that are comparable to or even superior to human language. Thus, they extend beyond the learned statistical representations that are common in natural language processing research. This gives rise to a number of fundamental questions, from the prerequisites for language emergence to the criteria for measuring its success. This paper addresses these questions by providing a comprehensive review of relevant scientific publications on emergent language in artificial intelligence. Its objective is to serve as a reference for researchers interested in or proficient in the field. Consequently, the main contributions are the definition and overview of the prevailing terminology, the analysis of existing evaluation methods and metrics, and the description of the identified research gaps.},
  archive      = {J_AAMAS},
  author       = {Peters, Jannik and Waubert de Puiseau, Constantin and Tercan, Hasan and Gopikrishnan, Arya and Lucas de Carvalho, Gustavo Adolpho and Bitter, Christian and Meisen, Tobias},
  doi          = {10.1007/s10458-025-09691-y},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-73},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Emergent language: A survey and taxonomy},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimal matchings with one-sided preferences: Fixed and
cost-based quotas. <em>AAMAS</em>, <em>39</em>(1), 1–36. (<a
href="https://doi.org/10.1007/s10458-025-09693-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the well-studied many-to-one bipartite matching problem of assigning applicants $${\varvec{\mathcal {A}}}$$ to posts $${\varvec{\mathcal {P}}}$$ where applicants rank posts in the order of preference. This setting models many important real-world allocation problems like assigning students to courses, applicants to jobs, amongst many others. In such scenarios, it is natural to ask for an allocation that satisfies guarantees of the form “match at least 80% of applicants to one of their top three choices” or “it is unacceptable to leave more than 10% of applicants unassigned”. The well-studied notions of rank-maximality and fairness fail to capture such requirements due to their property of optimizing extreme ends of the signature of a matching. We, therefore, propose a novel optimality criterion, which we call the “weak dominance ” of ranks. We investigate the computational complexity of the new notion of optimality in the setting where posts have associated fixed quotas. We prove that under the fixed quota setting, the problem turns out to be NP-hard under natural restrictions. We provide randomized algorithms in the fixed quota setting when the number of ranks is constant. We also study the problem under a cost-based quota setting and show that a matching that weakly dominates the input signature and has minimum total cost can be computed efficiently. Apart from circumventing the hardness, the cost-based quota setting is motivated by real-world applications like course allocation or school choice where the capacities or quotas need not be rigid. We also show that when the objective is to minimize the maximum cost, the problem under the cost-based quota setting turns out to be NP-hard. To complement the hardness, we provide a randomized algorithm when the number of ranks is constant. We also provide an approximation algorithm which is an asymptotic faster alternative to the randomized algorithm.},
  archive      = {J_AAMAS},
  author       = {Santhini, K. A. and Sankar, Govind S. and Nasre, Meghana},
  doi          = {10.1007/s10458-025-09693-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Optimal matchings with one-sided preferences: Fixed and cost-based quotas},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Investigating the impact of direct punishment on the
emergence of cooperation in multi-agent reinforcement learning systems.
<em>AAMAS</em>, <em>39</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s10458-025-09698-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving the problem of cooperation is fundamentally important for the creation and maintenance of functional societies. Problems of cooperation are omnipresent within human society, with examples ranging from navigating busy road junctions to negotiating treaties. As the use of AI becomes more pervasive throughout society, the need for socially intelligent agents capable of navigating these complex cooperative dilemmas is becoming increasingly evident. Direct punishment is a ubiquitous social mechanism that has been shown to foster the emergence of cooperation in both humans and non-humans. In the natural world, direct punishment is often strongly coupled with partner selection and reputation and used in conjunction with third-party punishment. The interactions between these mechanisms could potentially enhance the emergence of cooperation within populations. However, no previous work has evaluated the learning dynamics and outcomes emerging from multi-agent reinforcement learning populations that combine these mechanisms. This paper addresses this gap. It presents a comprehensive analysis and evaluation of the behaviors and learning dynamics associated with direct punishment, third-party punishment, partner selection, and reputation. Finally, we discuss the implications of using these mechanisms on the design of cooperative AI systems.},
  archive      = {J_AAMAS},
  author       = {Dasgupta, Nayana and Musolesi, Mirco},
  doi          = {10.1007/s10458-025-09698-5},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Investigating the impact of direct punishment on the emergence of cooperation in multi-agent reinforcement learning systems},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Relationship design for socially-aware behavior in static
games. <em>AAMAS</em>, <em>39</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10458-025-09699-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous agents can adopt socially-aware behaviors to reduce social costs, mimicking the way animals interact in nature and humans in society. We present a new approach to model socially-aware decision-making that includes two key elements: bounded rationality and inter-agent relationships. We capture the inter-agent relationships by introducing a novel model called a relationship game and encode agents’ bounded rationality using quantal response equilibria. For each relationship game, we define a social cost function and formulate a mechanism design problem to optimize weights for relationships that minimize social cost at the equilibrium. We address the multiplicity of equilibria by presenting the problem in two forms: Min-Max and Min-Min, aimed respectively at minimization of the highest and lowest social costs in the equilibria. We compute the quantal response equilibrium by solving a least-squares problem defined with its Karush-Kuhn-Tucker conditions, and propose two projected gradient descent algorithms to solve the mechanism design problems. Numerical results, including two-lane congestion and congestion with an ambulance, confirm that these algorithms consistently reach the equilibrium with the intended social costs.},
  archive      = {J_AAMAS},
  author       = {Chen, Shenghui and Bayiz, Yigit E. and Fridovich-Keil, David and Topcu, Ufuk},
  doi          = {10.1007/s10458-025-09699-4},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Relationship design for socially-aware behavior in static games},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Double mixing networks based monotonic value function
decomposition algorithm for swarm intelligence in UAVs. <em>AAMAS</em>,
<em>39</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s10458-025-09700-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-agent systems, particularly when facing challenges of partial observability, reinforcement learning demonstrates significant autonomous decision-making capabilities. Aiming at addressing resource allocation and collaboration issues in drone swarms operating in dynamic and unknown environments, we propose a novel deep reinforcement learning algorithm, DQMIX. We employ a framework of centralized training with decentralized execution and incorporate a partially observable Markov game model to describe the complex game environment of drone swarms. The core innovation of the DQMIX algorithm lies in its dual-mixing network structure and soft-switching mechanism. Two independent mixing networks handle local Q-values and synthesize them into a global Q-value. This structure enhances decision accuracy and system adaptability under different scenarios and data conditions. The soft-switching module allows the system to transition smoothly between the two networks, selecting the output of the network with smaller TD-errors to enhance decision stability and coherence. Simultaneously, we introduce Hindsight Experience Replay to learn from failed experiences. Experimental results using JSBSim demonstrate that DQMIX provides an effective solution for drone swarm game problems, especially in resource allocation and adversarial environments.},
  archive      = {J_AAMAS},
  author       = {Qu, Pingping and He, Chenglong and Wu, Xiaotong and Wang, Ershen and Xu, Song and Liu, Huan and Sun, Xinhui},
  doi          = {10.1007/s10458-025-09700-0},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Double mixing networks based monotonic value function decomposition algorithm for swarm intelligence in UAVs},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). “Provably fair” algorithms may perpetuate racial and gender
bias: A study of salary dispute resolution. <em>AAMAS</em>,
<em>39</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10458-025-09703-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prior work suggests automated dispute resolution tools using “provably fair” algorithms can address disparities between demographic groups. These methods use multi-criteria elicited preferences from all disputants and satisfy constraints to generate “fair” solutions. However, we analyze the potential for inequity to permeate proposals through the preference elicitation stage. This possibility arises if differences in dispositional attitudes differ between demographics, and those dispositions affect elicited preferences. Specifically, risk aversion plays a prominent role in predicting preferences. Risk aversion predicts a weaker relative preference for salary and a softer within-issue utility for each issue; this leads to worse compensation packages for risk-averse groups. These results raise important questions in AI-value alignment about whether an AI mediator should take explicit preferences at face value.},
  archive      = {J_AAMAS},
  author       = {Hale, James and Kim, Peter H. and Gratch, Jonathan},
  doi          = {10.1007/s10458-025-09703-x},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {“Provably fair” algorithms may perpetuate racial and gender bias: A study of salary dispute resolution},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On fair and efficient solutions for budget apportionment.
<em>AAMAS</em>, <em>39</em>(1), 1–31. (<a
href="https://doi.org/10.1007/s10458-025-09694-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article deals with an apportionment problem involving n agents and a common budget B. Each agent submits some demands which are indivisible portions of the budget, and a central authority has to decide which demands to accept. The utility of an agent corresponds to the total amount of her accepted demands. In this context, it is desirable to be fair among the agents and efficient by not wasting the budget. An ideal solution would be to spend exactly B/n for every agent but this is rarely possible because of the indivisibility of the demands. Since combining fairness with efficiency is highly desirable but often impossible, we explore relaxed notions of fairness and efficiency, in order to determine if they go together. Our approach is also constructive because polynomial algorithms that build fair and efficient solutions are also given. The fairness criteria under consideration are the maximization of the minimum agent utility (max–min), proportionality, a customized notion of envy-freeness called jealousy-freeness, and the relaxations up to one or any demand of the previous two concepts. Efficiency in this work is either the maximization of the utilitarian social welfare or Pareto optimality. First we consider fairness and efficiency separately. The existence and computation of solutions that are either fair or efficient are studied. A complete picture of the relations that connect the fairness and efficiency concepts is provided. Second, we determine when fairness and efficiency can be combined for every possible instance. We prove that Pareto optimality is compatible with two notions of fairness, namely max–min and proportionality up to any demand. In contrast, none of the fairness concepts under consideration can be paired with the maximization of utilitarian social welfare. Therefore, we finally conduct a thorough analysis of the price of fairness which bounds the loss of efficiency caused by imposing fairness or one of its relaxations.},
  archive      = {J_AAMAS},
  author       = {Cardi, Pierre and Gourvès, Laurent and Lesca, Julien},
  doi          = {10.1007/s10458-025-09694-9},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-31},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {On fair and efficient solutions for budget apportionment},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptation procedure in misinformation games.
<em>AAMAS</em>, <em>39</em>(1), 1–47. (<a
href="https://doi.org/10.1007/s10458-025-09704-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study interactions between agents in multi-agent systems, in which the agents are misinformed with regards to the game that they play, essentially having a subjective and incorrect understanding of the setting, without being aware of it. For that, we introduce a new game-theoretic concept, called misinformation games, that provides the necessary toolkit to study this situation. Subsequently, we enhance this framework by developing a time-discrete procedure (called the Adaptation Procedure) that captures iterative interactions in the above context. During the Adaptation Procedure, the agents update their information and reassess their behaviour in each step. We demonstrate our ideas through an implementation, which is used to study the efficiency and characteristics of the Adaptation Procedure.},
  archive      = {J_AAMAS},
  author       = {Varsos, Konstantinos and Papamichail, Merkouris and Flouris, Giorgos and Bitsaki, Marina},
  doi          = {10.1007/s10458-025-09704-w},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  month        = {6},
  number       = {1},
  pages        = {1-47},
  shortjournal = {Auton. Agent. Multi-Agent. Syst.},
  title        = {Adaptation procedure in misinformation games},
  volume       = {39},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
