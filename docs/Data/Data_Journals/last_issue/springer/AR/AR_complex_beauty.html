<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ar---9">AR - 9</h2>
<ul>
<li><details>
<summary>
(2025). Mori-zwanzig approach for belief abstraction with
application to belief space planning. <em>AR</em>, <em>49</em>(1), 1–23.
(<a href="https://doi.org/10.1007/s10514-024-10185-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a learning-based method to extract symbolic representations of the belief state and its dynamics in order to solve planning problems in a continuous-state partially observable Markov decision processes (POMDP) problem. While existing approaches typically parameterize the continuous-state POMDP into a finite-dimensional Markovian model, they are unable to preserve fidelity of the abstracted model. To improve accuracy of the abstracted representation, we introduce a memory-dependent abstraction approach to mitigate the modeling error. The first major contribution of this paper is we propose a Neural Network based method to learn the non-Markovian transition model based on the Mori-Zwanzig (M-Z) formalism. Different from existing work in applying M-Z formalism to autonomous time-invariant systems, our approach is the first work generalizing the M-Z formalism to robotics, by addressing the non-Markovian modeling of the belief dynamics that is dependent on historical observations and actions. The second major contribution is we theoretically show that modeling the non-Markovian memory effect in the abstracted belief dynamics improves the modeling accuracy, which is the key benefit of the proposed algorithm. Simulation experiment of a belief space planning problem is provided to validate the performance of the proposed belief abstraction algorithms.},
  archive      = {J_AR},
  author       = {Hou, Mengxue and Lin, Tony X. and Zhou, Enlu and Zhang, Fumin},
  doi          = {10.1007/s10514-024-10185-1},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Auton. Robot.},
  title        = {Mori-zwanzig approach for belief abstraction with application to belief space planning},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrative biomechanics of a human–robot carrying task:
Implications for future collaborative work. <em>AR</em>, <em>49</em>(1),
1–12. (<a href="https://doi.org/10.1007/s10514-024-10184-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patients with sarcopenia, who face difficulties in carrying heavy loads, may benefit from collaborative robotic assistance that is modeled after human–human interaction. The objective of this study is to describe the kinematics and spatio-temporal parameters during a collaborative carrying task involving both human and robotic partners. Fourteen subjects carried a table while moving forward with a human and a robotic partner. The movements were recorded using a three-dimensional motion capture system. The subjects successfully completed the task of carrying the table with the robot. No significant differences were found in the shoulder and elbow flexion/extension angles. In human–human dyads, the center of mass naturally oscillated vertically with an amplitude of approximately 2 cm. The here presented results of the human–human interaction serve as a model for the development of future robotic systems, designed for collaborative manipulation.},
  archive      = {J_AR},
  author       = {Schuengel, Verena and Braunstein, Bjoern and Goell, Fabian and Braun, Daniel and Reißner, Nadine and Safronov, Kirill and Weiser, Christian and Heieis, Jule and Albracht, Kirsten},
  doi          = {10.1007/s10514-024-10184-2},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Auton. Robot.},
  title        = {Integrative biomechanics of a human–robot carrying task: Implications for future collaborative work},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Safe and stable teleoperation of quadrotor UAVs under haptic
shared autonomy. <em>AR</em>, <em>49</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10514-024-10186-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel approach that aims to address both safety and stability of a haptic teleoperation system within a framework of Haptic Shared Autonomy (HSA). We use Control Barrier Functions (CBFs) to generate the control input that follows the user’s input as closely as possible while guaranteeing safety. In the context of stability of the human-in-the-loop system, we limit the force feedback perceived by the user via a small $$\mathcal {L}_2$$ -gain, which is achieved by limiting the control and the force feedback via a differential constraint. Specifically, with the property of HSA, we propose two pathways to design the control and the force feedback: Sequential Control Force (SCF) and Joint Control Force (JCF). Both designs can achieve safety and stability but with different responses to the user’s commands. We conducted experimental simulations to evaluate and investigate the properties of the designed methods. We also tested the proposed method on a physical quadrotor UAV and a haptic interface.},
  archive      = {J_AR},
  author       = {Zhang, Dawei and Tron, Roberto},
  doi          = {10.1007/s10514-024-10186-0},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Auton. Robot.},
  title        = {Safe and stable teleoperation of quadrotor UAVs under haptic shared autonomy},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synthesizing compact behavior trees for probabilistic
robotics domains. <em>AR</em>, <em>49</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10514-024-10187-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex robotics domains (e.g., remote exploration applications and scenarios involving interactions with humans) require encoding high-level mission specifications that consider uncertainty. Most current fielded systems in practice require humans to manually encode mission specifications in ways that require amounts of time and expertise that can become infeasible and limit mission scope. Therefore, we propose a method of automating the process of encoding mission specifications as behavior trees. In particular, we present an algorithm for synthesizing behavior trees that represent the optimal policy for a user-defined specification of a domain and problem in the Probabilistic Planning Domain Definition Language (PPDDL). Our algorithm provides access to behavior tree advantages including compactness and modularity, while alleviating the need for the time-intensive manual design of behavior trees, which requires substantial expert knowledge. Our method converts the PPDDL specification into solvable MDP matrices, simplifies the solution, i.e. policy, using Boolean algebra simplification, and converts this simplified policy to a compact behavior tree that can be executed by a robot. We present simulated experiments for a marine target search and response scenario and an infant-robot interaction for mobility domain. Our results demonstrate that the synthesized, simplified behavior trees have approximately between 15 x and 26 x fewer nodes and an average of between 8 x and 13 x fewer active conditions for selecting the active action than they would without simplification. These compactness and activity results suggest an increase in the interpretability and execution efficiency of the behavior trees synthesized by the proposed method. Additionally, our results demonstrate that this synthesis method is robust to a variety of user input mistakes, and we empirically confirm that the synthesized behavior trees perform equivalently to the optimal policy that they are constructed to logically represent.},
  archive      = {J_AR},
  author       = {Scheide, Emily and Best, Graeme and Hollinger, Geoffrey A.},
  doi          = {10.1007/s10514-024-10187-z},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Auton. Robot.},
  title        = {Synthesizing compact behavior trees for probabilistic robotics domains},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). View: Visual imitation learning with waypoints. <em>AR</em>,
<em>49</em>(1), 1–26. (<a
href="https://doi.org/10.1007/s10514-024-10188-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots can use visual imitation learning (VIL) to learn manipulation tasks from video demonstrations. However, translating visual observations into actionable robot policies is challenging due to the high-dimensional nature of video data. This challenge is further exacerbated by the morphological differences between humans and robots, especially when the video demonstrations feature humans performing tasks. To address these problems we introduce Visual Imitation lEarning with Waypoints (VIEW), an algorithm that significantly enhances the sample efficiency of human-to-robot VIL. VIEW achieves this efficiency using a multi-pronged approach: extracting a condensed prior trajectory that captures the demonstrator’s intent, employing an agent-agnostic reward function for feedback on the robot’s actions, and utilizing an exploration algorithm that efficiently samples around waypoints in the extracted trajectory. VIEW also segments the human trajectory into grasp and task phases to further accelerate learning efficiency. Through comprehensive simulations and real-world experiments, VIEW demonstrates improved performance compared to current state-of-the-art VIL methods. VIEW enables robots to learn manipulation tasks involving multiple objects from arbitrarily long video demonstrations. Additionally, it can learn standard manipulation tasks such as pushing or moving objects from a single video demonstration in under 30 min, with fewer than 20 real-world rollouts. Code and videos here: https://collab.me.vt.edu/view/},
  archive      = {J_AR},
  author       = {Jonnavittula, Ananth and Parekh, Sagar and P. Losey, Dylan},
  doi          = {10.1007/s10514-024-10188-y},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-26},
  shortjournal = {Auton. Robot.},
  title        = {View: Visual imitation learning with waypoints},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Eigen-factors a bilevel optimization for plane SLAM of 3D
point clouds. <em>AR</em>, <em>49</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10514-025-10189-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern depth sensors can generate a huge number of 3D points in few seconds to be later processed by Localization and Mapping algorithms. Ideally, these algorithms should handle efficiently large sizes of Point Clouds (PC) under the assumption that using more points implies more information available. The Eigen Factors (EF) is a new algorithm that solves PC SLAM by using planes as the main geometric primitive. To do so, EF exhaustively calculates the error of all points at complexity O(1), thanks to the Summation matrix S of homogeneous points. The solution of EF is a bilevel optimization where the lower-level problem estimates the plane variables in closed-form, and the upper-level non-linear problem uses second order optimization to estimate sensor poses (trajectory). We provide a direct analytical solution for the gradient and Hessian based on the homogeneous point-plane constraint. In addition, two variants of the EF are proposed: one pure analytical derivation and a second one approximating the problem to an alternating optimization showing better convergence properties. We evaluate the optimization processes (back-end) of EF and other state-of-the-art plane SLAM algorithms in a synthetic environment, and extended to ICL dataset (RGBD) and LiDAR KITTI datasets. EF demonstrates superior robustness and accuracy of the estimated trajectory and improved map metrics. Code is publicly available at https://github.com/prime-slam/EF-plane-SLAM with python bindings and pip package.},
  archive      = {J_AR},
  author       = {Ferrer, Gonzalo and Iarosh, Dmitrii and Kornilova, Anastasiia},
  doi          = {10.1007/s10514-025-10189-5},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Auton. Robot.},
  title        = {Eigen-factors a bilevel optimization for plane SLAM of 3D point clouds},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Isolated kalman filtering: Theory and decoupled estimator
design. <em>AR</em>, <em>49</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s10514-025-10191-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a state decoupling strategy for Kalman filtering problems, when the dynamics of individual estimates are decoupled and their outputs are sparsely coupled. The algorithm is termed Isolated Kalman Filtering (IsoKF) and exploits the sparsity in the output coupling by applying approximations that mitigate the need for non-involved estimates. We prove that the approximations made during the isolated coupling of estimates are based on an implicit maximum determinant completion of the incomplete a priori covariance matrix. The steady state behavior is studied on eleven different observation graphs and a buffering scheme to support delayed (i.e. out-of-order) measurements is proposed. We discussed handling of delayed measurements in both, an optimal or a suboptimal way. The credibility of the isolated estimates are evaluated on a linear and nonlinear toy example in Monte Carlo simulations. The presented paradigm is made available online to the community within a generic C++ estimation framework supporting both, modular sensor fusion and collaborative state estimation.},
  archive      = {J_AR},
  author       = {Jung, Roland and Luft, Lukas and Weiss, Stephan},
  doi          = {10.1007/s10514-025-10191-x},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Auton. Robot.},
  title        = {Isolated kalman filtering: Theory and decoupled estimator design},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Between reality and delusion: Challenges of applying large
language models to companion robots for open-domain dialogues with older
adults. <em>AR</em>, <em>49</em>(1), 1–41. (<a
href="https://doi.org/10.1007/s10514-025-10190-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Throughout our lives, we interact daily in conversations with our friends and family, covering a wide range of topics, known as open-domain dialogue. As we age, these interactions may diminish due to changes in social and personal relationships, leading to loneliness in older adults. Conversational companion robots can alleviate this issue by providing daily social support. Large language models (LLMs) offer flexibility for enabling open-domain dialogue in these robots. However, LLMs are typically trained and evaluated on textual data, while robots introduce additional complexity through multi-modal interactions, which has not been explored in prior studies. Moreover, it is crucial to involve older adults in the development of robots to ensure alignment with their needs and expectations. Correspondingly, using iterative participatory design approaches, this paper exposes the challenges of integrating LLMs into conversational robots, deriving from 34 Swedish-speaking older adults’ (one-to-one) interactions with a personalized companion robot, built on Furhat robot with GPT $$-$$ 3.5. These challenges encompass disruptions in conversations, including frequent interruptions, slow, repetitive, superficial, incoherent, and disengaging responses, language barriers, hallucinations, and outdated information, leading to frustration, confusion, and worry among older adults. Drawing on insights from these challenges, we offer recommendations to enhance the integration of LLMs into conversational robots, encompassing both general suggestions and those tailored to companion robots for older adults.},
  archive      = {J_AR},
  author       = {Irfan, Bahar and Kuoppamäki, Sanna and Hosseini, Aida and Skantze, Gabriel},
  doi          = {10.1007/s10514-025-10190-y},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-41},
  shortjournal = {Auton. Robot.},
  title        = {Between reality and delusion: Challenges of applying large language models to companion robots for open-domain dialogues with older adults},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ASAP-MPC: An asynchronous update scheme for online motion
planning with nonlinear model predictive control. <em>AR</em>,
<em>49</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10514-025-10192-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a Nonlinear Model Predictive Control (NMPC) update scheme targeted at motion planning for mechatronic motion systems, such as drones and mobile platforms. NMPC-based motion planning typically requires low computation times to be able to provide control inputs at the required rate for system stability, disturbance rejection, and overall performance. To achieve online NMPC updates in complex situations, works in literature typically rely on one of two approaches: attempting to reduce the solution times in NMPC by sacrificing feasibility guarantees, or allowing more time to the motion planning algorithm, which requires additional strategies to ensure robust tracking of the planned motion, e.g., state feedback. Following this second paradigm, this paper presents As-Soon-As-Possible MPC (ASAP-MPC), an asynchronous update scheme for online motion planning with optimal control that abandons the idea of having to satisfy restrictive real-time update rates and that solves the optimal control problem to full convergence. ASAP-MPC combines trajectory generation through optimal control with additional tracking control for improved robustness against disturbances and plant-model mismatch. The scheme seamlessly connects trajectories, resulting from subsequent NMPC solutions, providing a smooth and continuous overall trajectory for the motion system. This framework’s applicability to embedded applications is shown on two different experiment setups where a state-of-the-art method fails to successfully navigate through a given environment: a quadcopter flying through a cluttered environment with hardware-in-the-loop simulation and a scale model truck-trailer manoeuvring in a structured physical lab environment.},
  archive      = {J_AR},
  author       = {Dirckx, Dries and Bos, Mathias and Vandewal, Bastiaan and Vanroye, Lander and Swevers, Jan and Decré, Wilm},
  doi          = {10.1007/s10514-025-10192-w},
  journal      = {Autonomous Robots},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Auton. Robot.},
  title        = {ASAP-MPC: An asynchronous update scheme for online motion planning with nonlinear model predictive control},
  volume       = {49},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
