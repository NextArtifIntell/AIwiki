<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AMAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="amai---14">AMAI - 14</h2>
<ul>
<li><details>
<summary>
(2025). Single MCMC chain parallelisation on decision trees.
<em>AMAI</em>, <em>93</em>(1), 219–232. (<a
href="https://doi.org/10.1007/s10472-023-09876-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision trees (DT) are highly famous in machine learning and usually acquire state-of-the-art performance. Despite that, well-known variants like CART, ID3, random forest, and boosted trees miss a probabilistic version that encodes prior assumptions about tree structures and shares statistical strength between node parameters. Existing work on Bayesian DT depends on Markov Chain Monte Carlo (MCMC), which can be computationally slow, especially on high dimensional data and expensive proposals. In this study, we propose a method to parallelise a single MCMC DT chain on an average laptop or personal computer that enables us to reduce its run-time through multi-core processing while the results are statistically identical to conventional sequential implementation. We also calculate the theoretical and practical reduction in run time, which can be obtained utilising our method on multi-processor architectures. Experiments showed that we could achieve 18 times faster running time provided that the serial and the parallel implementation are statistically identical.},
  archive      = {J_AMAI},
  author       = {Drousiotis, Efthyvoulos and Spirakis, Paul},
  doi          = {10.1007/s10472-023-09876-9},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {219-232},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Single MCMC chain parallelisation on decision trees},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Two parameter-tuned multi-objective evolutionary-based
algorithms for zoning management in marine spatial planning.
<em>AMAI</em>, <em>93</em>(1), 187–218. (<a
href="https://doi.org/10.1007/s10472-023-09853-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Strategic spatial planning is becoming more popular around the world as a decision-making way to build a unified vision for directing the medium- to long-term development of land/marine areas. Recently, the study of marine areas in terms of spatial planning such as Marine Spatial Planning (MSP) has received much attention. One of the challenging issues in MSP is to make a balance between determining the ideal zone for a new activity while also considering the locations of existing activities. This spatial zoning problem for multi-uses with multiple objectives could be formulated as optimization models. This paper presents and compares the results of two multi-objective evolutionary-based algorithms (MOEAs), Synchronous Hypervolume-based non-dominated sorting genetic algorithm-II (SH-NSGA-II) which is an extension of NSGA-II and a memetic algorithm (MA) in which SH-NSGA-II is enhanced with a local search. These proposed algorithms are used to solve the multi-objective spatial zoning optimization problem, which seeks to maximize the zone interest value assigned to the new activity while simultaneously maximizing its spatial compactness. We introduce several innovations in these proposed algorithms to address the problem constraints and to improve the robustness of the traditional NSGA-II and MA approaches. Unlike traditional ones, a different stop condition, multiple crossover, mutation, and repairing operators, and also a local search operator are developed. A comparative study is presented between the results obtained using both algorithms. To guarantee robust results for both algorithms, their parameters are calibrated and tuned using the Multi-Response Surface Methodology (MRSM) method. The effective and non-effective components, as well as the validity of the regression models, are determined using analysis of variance (ANOVA). Although SH-NSGA-II has revealed a good efficiency, its performance is still improved using a local search scheme within SH-NSGA-II, which is specially tailored to the problem characteristics. The two methods are designed for raster data.},
  archive      = {J_AMAI},
  author       = {Basirati, Mohadese and Billot, Romain and Meyer, Patrick},
  doi          = {10.1007/s10472-023-09853-2},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {187-218},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Two parameter-tuned multi-objective evolutionary-based algorithms for zoning management in marine spatial planning},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Clique detection with a given reliability. <em>AMAI</em>,
<em>93</em>(1), 173–186. (<a
href="https://doi.org/10.1007/s10472-024-09928-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a new notion of a clique reliability. The clique reliability is understood as the ratio of the number of statistically significant links in a clique to the number of edges of the clique. This notion relies on a recently proposed original technique for separating inferences about pairwise connections between vertices of a network into significant and admissible ones. In this paper, we propose an extension of this technique to the problem of clique detection. We propose a method of step-by-step construction of a clique with a given reliability. The results of constructing cliques with a given reliability using data on the returns of stocks included in the Dow Jones index are presented.},
  archive      = {J_AMAI},
  author       = {Semenov, Dmitry and Koldanov, Alexander and Koldanov, Petr and Pardalos, Panos},
  doi          = {10.1007/s10472-024-09928-8},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {173-186},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Clique detection with a given reliability},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing doubly stochastic matrices for average consensus
through swarm and evolutionary algorithms. <em>AMAI</em>,
<em>93</em>(1), 151–171. (<a
href="https://doi.org/10.1007/s10472-023-09912-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Doubly-stochastic matrices play a vital role in modern applications of complex networks such as tracking and decentralized state estimation, coordination and control of autonomous agents. A central theme in all of the above is consensus, that is, nodes reaching agreement about the value of an underlying variable (e.g. the state of the environment). Despite the fact that complex networks have been studied thoroughly, the communication graphs are usually described by symmetric matrices due to their advantageous theoretical properties. We do not yet have methods for optimizing generic doubly-stochastic matrices. In this paper, we propose a novel formulation and framework, EvoDSM, for achieving fast linear distributed averaging by: (a) optimizing the weights of a fixed graph topology, and (b) optimizing for the topology itself. We are concerned with graphs that can be described by positive doubly-stochastic matrices. Our method relies on swarm and evolutionary optimization algorithms and our experimental results and analysis showcase that our method (1) achieves comparable performance with traditional methods for symmetric graphs, (2) is applicable to non-symmetric network structures and edge weights, and (3) is scalable and can operate effectively with moderately large graphs without engineering overhead.},
  archive      = {J_AMAI},
  author       = {Syriopoulos, Panos K. and Chatzilygeroudis, Konstantinos I. and Kalampalikis, Nektarios G. and Vrahatis, Michael N.},
  doi          = {10.1007/s10472-023-09912-8},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {151-171},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Optimizing doubly stochastic matrices for average consensus through swarm and evolutionary algorithms},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel method for solving universum twin bounded support
vector machine in the primal space. <em>AMAI</em>, <em>93</em>(1),
131–150. (<a href="https://doi.org/10.1007/s10472-023-09896-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In supervised learning, the Universum, a third class that is not a part of either class in the classification task, has proven to be useful. In this study we propose (N $$ \mathfrak {U} $$ TBSVM), a Newton-based approach for solving in the primal space the optimization problems related to Twin Bounded Support Vector Machines with Universum data ( $$ \mathfrak {U} $$ TBSVM). In the N $$ \mathfrak {U} $$ TBSVM, the constrained programming problems of $$ \mathfrak {U} $$ TBSVM are converted into unconstrained optimization problems, and a generalization of Newton’s method for solving the unconstrained problems is introduced. Numerical experiments on synthetic, UCI, and NDC data sets show the ability and effectiveness of the proposed N $$ \mathfrak {U} $$ TBSVM. We apply the suggested method for gender detection from face images, and compare it with other methods.},
  archive      = {J_AMAI},
  author       = {Moosaei, Hossein and Khosravi, Saeed and Bazikar, Fatemeh and Hladík, Milan and Rosario Guarracino, Mario},
  doi          = {10.1007/s10472-023-09896-5},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {131-150},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {A novel method for solving universum twin bounded support vector machine in the primal space},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Realtime gray-box algorithm configuration using
cost-sensitive classification. <em>AMAI</em>, <em>93</em>(1), 109–130.
(<a href="https://doi.org/10.1007/s10472-023-09890-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A solver’s runtime and the quality of the solutions it generates are strongly influenced by its parameter settings. Finding good parameter configurations is a formidable challenge, even for fixed problem instance distributions. However, when the instance distribution can change over time, a once effective configuration may no longer provide adequate performance. Realtime algorithm configuration (RAC) offers assistance in finding high-quality configurations for such distributions by automatically adjusting the configurations it recommends based on instances seen so far. Existing RAC methods treat the solver as a black box, meaning the solver is given a configuration as input, and it outputs either a solution or runtime as an objective function for the configurator. However, analyzing intermediate output from the solver can enable configurators to avoid wasting time on poorly performing configurations. We propose a gray-box approach that utilizes intermediate output during evaluation and implement it within the RAC method Contextual Preselection with Plackett-Luce (CPPL blue). We apply cost-sensitive machine learning with pairwise comparisons to determine whether ongoing evaluations can be terminated to free resources. We compare our approach to a black-box equivalent on several experimental settings and show that our approach reduces the total solving time in several scenarios and improves solution quality in an additional scenario.},
  archive      = {J_AMAI},
  author       = {Weiss, Dimitri and Tierney, Kevin},
  doi          = {10.1007/s10472-023-09890-x},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {109-130},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Realtime gray-box algorithm configuration using cost-sensitive classification},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel SVM-based classification approaches for evaluating
pancreatic carcinoma. <em>AMAI</em>, <em>93</em>(1), 93–108. (<a
href="https://doi.org/10.1007/s10472-023-09888-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop two SVM-based classifiers named stable nested one-class support vector machines (SN-1SVMs) and decoupled margin-moment based SVMs (DMMB-SVMs), to predict the specific type of pancreatic carcinoma using quantitative histopathological signatures of images. For each patient, the diagnosis can produce hundreds of images, which can be used to classify the pancreatic tissues into three classes: chronic pancreatitis, intraductal papillary mucinous neoplasms, and pancreatic carcinoma. The proposed two approaches tackle the classification problems from two different perspectives: the SN-1SVM treats each image as a classification point in a nested fashion to predict malignancy of the tissues, while the DMMB-SVM treats each patient as a classification point by assembling information across images. One attractive feature of the DMMB-SVM is that, in addition to utilizing the mean information, it also takes into account the covariance of features extracted from images for each patient. We conduct numerical experiments to evaluate and compare performance of the two methods. It is observed that the SN-1SVM can take advantage of the data structure more effectively, while the DMMB-SVM demonstrates better computational efficiency and classification accuracy. To further improve interpretability of the final classifier, we also consider the $$\ell _1$$ -norm in the DMMB-SVM to handle feature selection.},
  archive      = {J_AMAI},
  author       = {Washburn, Ammon and Fan, Neng and Zhang, Hao Helen},
  doi          = {10.1007/s10472-023-09888-5},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {93-108},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Novel SVM-based classification approaches for evaluating pancreatic carcinoma},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bayesian optimization over the probability simplex.
<em>AMAI</em>, <em>93</em>(1), 77–91. (<a
href="https://doi.org/10.1007/s10472-023-09883-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian Process based Bayesian Optimization is largely adopted for solving problems where the inputs are in Euclidean spaces. In this paper we associate the inputs to discrete probability distributions which are elements of the probability simplex. To search in the new design space, we need a distance between distributions. The optimal transport distance (aka Wasserstein distance) is chosen due to its mathematical structure and the computational strategies enabled by it. Both the GP and the acquisition function is generalized to an acquisition functional over the probability simplex. To optimize this functional two methods are proposed, one based on auto differentiation and the other based on proximal-point algorithm and the gradient flow. Finally, we report a preliminary set of computational results on a class of problems whose dimension ranges from 5 to 100. These results show that embedding the Bayesian optimization process in the probability simplex enables an effective algorithm whose performance over standard Bayesian optimization improves with the increase of problem dimensionality.},
  archive      = {J_AMAI},
  author       = {Candelieri, Antonio and Ponti, Andrea and Archetti, Francesco},
  doi          = {10.1007/s10472-023-09883-w},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {77-91},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Bayesian optimization over the probability simplex},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KNN classification: A review. <em>AMAI</em>, <em>93</em>(1),
43–75. (<a href="https://doi.org/10.1007/s10472-023-09882-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k-nearest neighbors (k/NN) algorithm is a simple yet powerful non-parametric classifier that is robust to noisy data and easy to implement. However, with the growing literature on k/NN methods, it is increasingly challenging for new researchers and practitioners to navigate the field. This review paper aims to provide a comprehensive overview of the latest developments in the k/NN algorithm, including its strengths and weaknesses, applications, benchmarks, and available software with corresponding publications and citation analysis. The review also discusses the potential of k/NN in various data science tasks, such as anomaly detection, dimensionality reduction and missing value imputation. By offering an in-depth analysis of k/NN, this paper serves as a valuable resource for researchers and practitioners to make informed decisions and identify the best k/NN implementation for a given application.},
  archive      = {J_AMAI},
  author       = {Syriopoulos, Panos K. and Kalampalikis, Nektarios G. and Kotsiantis, Sotiris B. and Vrahatis, Michael N.},
  doi          = {10.1007/s10472-023-09882-x},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {43-75},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {KNN classification: A review},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved multi-task least squares twin support vector
machine. <em>AMAI</em>, <em>93</em>(1), 21–41. (<a
href="https://doi.org/10.1007/s10472-023-09877-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, multi-task learning (MTL) has become a popular field in machine learning and has a key role in various domains. Sharing knowledge across tasks in MTL can improve the performance of learning algorithms and enhance their generalization capability. A new approach called the multi-task least squares twin support vector machine (MTLS-TSVM) was recently proposed as a least squares variant of the direct multi-task twin support vector machine (DMTSVM). Unlike DMTSVM, which solves two quadratic programming problems, MTLS-TSVM solves two linear systems of equations, resulting in a reduced computational time. In this paper, we propose an enhanced version of MTLS-TSVM called the improved multi-task least squares twin support vector machine (IMTLS-TSVM). IMTLS-TSVM offers a significant advantage over MTLS-TSVM by operating based on the empirical risk minimization principle, which allows for better generalization performance. The model achieves this by including regularization terms in its objective function, which helps control the model’s complexity and prevent overfitting. We demonstrate the effectiveness of IMTLS-TSVM by comparing it to several single-task and multi-task learning algorithms on various real-world data sets. Our results highlight the superior performance of IMTLS-TSVM in addressing multi-task learning problems.},
  archive      = {J_AMAI},
  author       = {Moosaei, Hossein and Bazikar, Fatemeh and Pardalos, Panos M.},
  doi          = {10.1007/s10472-023-09877-8},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {21-41},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {An improved multi-task least squares twin support vector machine},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guest editorial: Revised selected papers from the LION 16
conference. <em>AMAI</em>, <em>93</em>(1), 19–20. (<a
href="https://doi.org/10.1007/s10472-024-09958-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AMAI},
  author       = {Kotsireas, Ilias S. and Pardalos, Panos M.},
  doi          = {10.1007/s10472-024-09958-2},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {19-20},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Guest editorial: Revised selected papers from the LION 16 conference},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep data density estimation through donsker-varadhan
representation. <em>AMAI</em>, <em>93</em>(1), 7–17. (<a
href="https://doi.org/10.1007/s10472-024-09943-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Estimating the data density is one of the challenging problem topics in the deep learning society. In this paper, we present a simple yet effective methodology for estimating the data density using the Donsker-Varadhan variational lower bound on the KL divergence and the modeling based on the deep neural network. We demonstrate that the optimal critic function associated with the Donsker-Varadhan representation on the KL divergence between the data and the uniform distribution can estimate the data density. Also, we present the deep neural network-based modeling and its stochastic learning procedure. The experimental results and possible applications of the proposed method demonstrate that it is competitive with the previous methods for data density estimation and has a lot of possibilities for various applications.},
  archive      = {J_AMAI},
  author       = {Park, Seonho and Pardalos, Panos M.},
  doi          = {10.1007/s10472-024-09943-9},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {7-17},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {Deep data density estimation through donsker-varadhan representation},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The future starts now. <em>AMAI</em>, <em>93</em>(1), 5–6.
(<a href="https://doi.org/10.1007/s10472-025-09970-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AMAI},
  author       = {Dix, Jürgen and Fisher, Michael},
  doi          = {10.1007/s10472-025-09970-0},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {5-6},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {The future starts now},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 35 years of math and AI. <em>AMAI</em>, <em>93</em>(1), 1–3.
(<a href="https://doi.org/10.1007/s10472-025-09969-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AMAI},
  author       = {Golumbic, Martin Charles},
  doi          = {10.1007/s10472-025-09969-7},
  journal      = {Annals of Mathematics and Artificial Intelligence},
  month        = {2},
  number       = {1},
  pages        = {1-3},
  shortjournal = {Ann. Math. Artif. Intell.},
  title        = {35 years of math and AI},
  volume       = {93},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
