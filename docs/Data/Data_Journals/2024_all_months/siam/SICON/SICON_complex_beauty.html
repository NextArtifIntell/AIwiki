<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SICON_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sicon---134">SICON - 134</h2>
<ul>
<li><details>
<summary>
(2024). Learning decentralized linear quadratic regulators with
<span class="math inline">${\sqrt{T}}$</span> regret. <em>SICON</em>,
<em>62</em>(6), 3341–3368. (<a
href="https://doi.org/10.1137/23M161714X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose an online learning algorithm that adaptively designs a decentralized linear quadratic regulator when the system model is unknown a priori and new data samples from a single system trajectory become progressively available. The algorithm uses a disturbance-feedback representation of state-feedback controllers coupled with online convex optimization with memory and delayed feedback. Under the assumption that the system is stable or given a known stabilizing controller, we show that our controller enjoys an expected regret that scales as with the time horizon for the case of partially nested information pattern. For more general information patterns, the optimal controller is unknown even if the system model is known. In this case, the regret of our controller is shown with respect to a linear suboptimal controller.},
  archive      = {J_SICON},
  author       = {Lintao Ye and Ming Chi and Ruiquan Liao and Vijay Gupta},
  doi          = {10.1137/23M161714X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3341-3368},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Learning decentralized linear quadratic regulators with \({\sqrt{T}}\) regret},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Trajectory stabilization of nonlocal continuity equations by
localized controls. <em>SICON</em>, <em>62</em>(6), 3315–3340. (<a
href="https://doi.org/10.1137/24M1644274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We discuss stabilization around trajectories of the continuity equation with nonlocal vector fields, where the control is localized, i.e., it acts on a fixed subset of the configuration space. We first show that the correct definition of stabilization is the following: given an initial error of order , measured in Wasserstein distance, one can improve the final error to an order with . We then prove the main result: assuming that the trajectory crosses the subset of control action, stabilization can be achieved. The key problem lies in regularity issues: the reference trajectory needs to be absolutely continuous, while the initial state to be stabilized needs to be realized by a small Lipschitz perturbation or by being in a very small neighborhood of it.},
  archive      = {J_SICON},
  author       = {Nikolay Pogodaev and Francesco Rossi},
  doi          = {10.1137/24M1644274},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3315-3340},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Trajectory stabilization of nonlocal continuity equations by localized controls},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic modified flows for riemannian stochastic gradient
descent. <em>SICON</em>, <em>62</em>(6), 3288–3314. (<a
href="https://doi.org/10.1137/24M163863X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We give quantitative estimates for the rate of convergence of Riemannian stochastic gradient descent (RSGD) to Riemannian gradient flow and to a diffusion process, the so-called Riemannian stochastic modified flow (RSMF). Using tools from stochastic differential geometry, we show that, in the small learning rate regime, RSGD can be approximated by the solution to the RSMF driven by an infinite-dimensional Wiener process. The RSMF accounts for the random fluctuations of RSGD and, thereby, increases the order of approximation compared to the deterministic Riemannian gradient flow. The RSGD is built using the concept of a retraction map, that is, a cost-efficient approximation of the exponential map, and we prove quantitative bounds for the weak error of the diffusion approximation under assumptions on the retraction map, the geometry of the manifold, and the random estimators of the gradient.},
  archive      = {J_SICON},
  author       = {Benjamin Gess and Sebastian Kassing and Nimit Rana},
  doi          = {10.1137/24M163863X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3288-3314},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stochastic modified flows for riemannian stochastic gradient descent},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential mixing of constrained random dynamical systems
via controllability conditions. <em>SICON</em>, <em>62</em>(6),
3266–3287. (<a href="https://doi.org/10.1137/24M164999X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We provide deterministic controllability conditions that imply exponential mixing properties for randomly forced constrained dynamical systems with possibly unbounded state space. As an application, new ergodicity results are obtained for nonsmooth models in elasto-plasticity driven by various types of noise, including white noise. It is thereby illustrated how tools from control theory can be utilized to tackle regularity issues that commonly arise in the qualitative study of constrained systems.},
  archive      = {J_SICON},
  author       = {Laurent Mertz and Vahagn Nersesyan and Manuel Rissel},
  doi          = {10.1137/24M164999X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3266-3287},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Exponential mixing of constrained random dynamical systems via controllability conditions},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multidimensional indefinite stochastic riccati equations and
zero-sum stochastic linear-quadratic differential games with
non-markovian regime switching. <em>SICON</em>, <em>62</em>(6),
3239–3265. (<a href="https://doi.org/10.1137/23M1581984">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is concerned with zero-sum stochastic linear-quadratic differential games in a regime-switching model. The coefficients of the games depend on the underlying noises, so it is a non-Markovian regime-switching model. Based on the solutions of a new kind of multidimensional indefinite stochastic Riccati equation (SRE) and a multidimensional linear backward stochastic differential equation (BSDE) with unbounded coefficients, we provide closed-loop optimal feedback control-strategy pairs for the two players. The main contribution of this paper, which is of great importance in its own right from the BSDE theory point of view, is to prove the existence and uniqueness of the solution to the new kind of SRE. Notably, the first component of the solution (as a process) is capable of taking positive and negative values simultaneously. For homogeneous systems, we obtain the optimal feedback control-strategy pairs under general closed convex cone control constraints. Finally, these results are applied to portfolio selection games with full or partial no-shorting constraint in a regime-switching market with random coefficients.},
  archive      = {J_SICON},
  author       = {Panpan Zhang and Zuo Quan Xu},
  doi          = {10.1137/23M1581984},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3239-3265},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Multidimensional indefinite stochastic riccati equations and zero-sum stochastic linear-quadratic differential games with non-markovian regime switching},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Equilibria for time-inconsistent singular control problems.
<em>SICON</em>, <em>62</em>(6), 3213–3238. (<a
href="https://doi.org/10.1137/23M1609701">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study a time-inconsistent singular control problem originating from irreversible reinsurance decisions with nonexponential discount. A novel definition of equilibrium for time-inconsistent singular control problems is introduced. For the problem with nonexponential discount, both sufficient and necessary conditions are derived, providing a thorough mathematical characterization of the equilibrium. Specifically, the equilibrium can be characterized by an extended HJB system, which is a coupled system of nonlocal parabolic equations with free boundaries. Finally, by showing the existence of classical solutions to the extended HJB system, the existence of equilibria is established under some additional assumptions.},
  archive      = {J_SICON},
  author       = {Zongxia Liang and Xiaodong Luo and Fengyi Yuan},
  doi          = {10.1137/23M1609701},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3213-3238},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Equilibria for time-inconsistent singular control problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation of time optimal controls for ginzburg–landau
equations with disturbance coefficients. <em>SICON</em>, <em>62</em>(6),
3195–3212. (<a href="https://doi.org/10.1137/24M1646868">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper shows the existence of time optimal controls for a class of linear complex Ginzburg–Landau equations with homogeneous Dirichlet boundary conditions and arbitrarily located internal controller. Meanwhile, the bang-bang property of time optimal controls is obtained by Pontryagin’s maximum principle and properties of nontrivial solutions of controlled systems. We mainly prove that the optimal time and the associated optimal control for the Ginzburg–Landau equation, where the principal coefficient has a perturbation, are close to those of the original problem for a parabolic equation. The key is to establish the connections between time and norm optimal control problems.},
  archive      = {J_SICON},
  author       = {Shu Luan and Xiuxiang Zhou},
  doi          = {10.1137/24M1646868},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3195-3212},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Approximation of time optimal controls for Ginzburg–Landau equations with disturbance coefficients},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Blackwell optimality and policy stability for long-run
risk-sensitive stochastic control. <em>SICON</em>, <em>62</em>(6),
3172–3194. (<a href="https://doi.org/10.1137/24M1671335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper analyzes the stability of optimal policies in the long-run stochastic control framework with an averaged risk-sensitive criterion for discrete-time MDPs on finite state-action space. In particular, we study the robustness of optimal controls when perturbations to the risk-aversion parameter are applied and investigate the Blackwell property, together with its link to the risk-sensitive vanishing discount approximation framework. Finally, we present examples that help to better understand the intricacies of the risk-sensitive control framework.},
  archive      = {J_SICON},
  author       = {Nicole Bäuerle and Marcin Pitera and Łukasz Stettner},
  doi          = {10.1137/24M1671335},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3172-3194},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Blackwell optimality and policy stability for long-run risk-sensitive stochastic control},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Occupancy information ratio: Infinite-horizon,
information-directed, parameterized policy search. <em>SICON</em>,
<em>62</em>(6), 3145–3171. (<a
href="https://doi.org/10.1137/22M1536650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we propose an information-directed objective for infinite-horizon reinforcement learning (RL), called the occupancy information ratio (OIR), inspired by the information ratio objectives used in previous information-directed sampling schemes for multi-armed bandits and Markov decision processes as well as recent advances in general utility RL. The OIR, composed of a ratio between the average cost of a policy and the entropy of its induced state occupancy measure, enjoys rich underlying structure and presents an objective to which scalable, model-free policy search methods naturally apply. Specifically, we show by leveraging connections between quasiconvex optimization and the linear programming theory for Markov decision processes that the OIR problem can be transformed and solved via convex optimization methods when the underlying model is known. Since model knowledge is typically lacking in practice, we lay the foundations for model-free OIR policy search methods by establishing a corresponding policy gradient theorem. Building on this result, we subsequently derive REINFORCE- and actor-critic-style algorithms for solving the OIR problem in policy parameter space. Crucially, exploiting the powerful hidden quasiconvexity property implied by our transformation of the OIR problem, we establish finite-time convergence of the REINFORCE-style scheme to global optimality and asymptotic convergence of the actor-critic-style scheme to (near) global optimality under suitable conditions. Finally, we experimentally illustrate the utility of OIR-based methods over vanilla methods in sparse-reward settings, supporting the OIR as an alternative to existing RL objectives.},
  archive      = {J_SICON},
  author       = {Wesley A. Suttle and Alec Koppel and Ji Liu},
  doi          = {10.1137/22M1536650},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3145-3171},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Occupancy information ratio: Infinite-horizon, information-directed, parameterized policy search},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Large deviation principle in discrete time nonlinear
filtering. <em>SICON</em>, <em>62</em>(6), 3121–3144. (<a
href="https://doi.org/10.1137/23M1589979">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we study the behavior of discrete time nonlinear filters when the signal and observations are small. It will be shown that if these noises are of the same order, then there is a nontrivial limiting behavior of the corresponding conditional distribution. In addition, we establish a large deviation principle for the conditional distribution. The proof is via the weak convergence approach. However, the main hurdle in the proof is the difficulty in uniquely characterizing the limiting conditional distribution, as we can only identify the support of the limiting conditional distribution. This uniquely identifies the limit only in the case when the support is a singleton set. Therefore, we construct an appropriately equivalent problem where the aforementioned support is a singleton set. After establishing the large deviation principle, we immediately infer the large deviation principle of the original problem from the equivalence.},
  archive      = {J_SICON},
  author       = {Sumith Reddy Anugu},
  doi          = {10.1137/23M1589979},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3121-3144},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Large deviation principle in discrete time nonlinear filtering},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Perturbed bayesian best response dynamic in continuum games.
<em>SICON</em>, <em>62</em>(6), 3091–3120. (<a
href="https://doi.org/10.1137/23M1591931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The notion of perturbed Bayesian best response dynamic for continuum strategy Bayesian population games is introduced. Fundamental properties of the dynamic such as existence of perturbed equilibrium, convergence of the perturbed equilibrium to the Bayesian equilibrium of the underlying game, as well as existence, uniqueness, and continuity of solutions from arbitrary initial conditions is established. As applications to the theory, convergence of solutions to the perturbed equilibria is shown to hold for two classes of games, namely, Bayesian potential games and Bayesian negative semidefinite games.},
  archive      = {J_SICON},
  author       = {Sayan Mukherjee and Souvik Roy},
  doi          = {10.1137/23M1591931},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3091-3120},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Perturbed bayesian best response dynamic in continuum games},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence analysis of the semismooth newton method for
sparse control problems governed by semilinear elliptic equations.
<em>SICON</em>, <em>62</em>(6), 3076–3090. (<a
href="https://doi.org/10.1137/23M1585945">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that a second order sufficient condition for local optimality, along with a strict complementarity condition, is enough to get the superlinear convergence of the semismooth Newton method for an optimal control problem governed by a semilinear elliptic equation. The objective functional may include a sparsity promoting term and we allow for box control constraints.},
  archive      = {J_SICON},
  author       = {Eduardo Casas and Mariano Mateos},
  doi          = {10.1137/23M1585945},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3076-3090},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Convergence analysis of the semismooth newton method for sparse control problems governed by semilinear elliptic equations},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A mixed passivity/small-gain theorem for sobolev
input-output stability. <em>SICON</em>, <em>62</em>(6), 3042–3075. (<a
href="https://doi.org/10.1137/24M1643128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A stability theorem for the feedback connection of two (possibly infinite-dimensional) time-invariant linear systems is presented. The theorem is formulated in the frequency domain and is in the spirit of combined passivity/small-gain results. It places a mixture of positive realness and small-gain assumptions on the two transfer functions to ensure a certain notion of input-output stability, called Sobolev stability (which includes the classical -stability concept as a special case). The result is more general than the classical passivity and small-gain theorems; strong positive realness of either the plant or controller is not required, and the small-gain condition only needs to hold on a suitable subset of the open right-half plane. We show that the “mixed” stability theorem is applicable in settings where -stability of the feedback connection is not possible, such as output regulation and disturbance rejection of certain periodic signals by so-called repetitive control.},
  archive      = {J_SICON},
  author       = {Chris Guiver and Hartmut Logemann and Mark R. Opmeer},
  doi          = {10.1137/24M1643128},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3042-3075},
  shortjournal = {SIAM J. Control Optim.},
  title        = {A mixed Passivity/Small-gain theorem for sobolev input-output stability},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reciprocity of nonlinear systems. <em>SICON</em>,
<em>62</em>(6), 3019–3041. (<a
href="https://doi.org/10.1137/24M1629250">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Reciprocity of linear input-output systems is defined as symmetry of its impulse response or transfer matrix. In the famous 1972 paper by Willems [Dissipative dynamical systems, part II: Linear systems with quadratic supply rates, Arch. Ration. Mech. Anal., 45, pp. 352–393] it was shown how reciprocity can be reflected in the state space realization. Furthermore, it was shown how to combine reciprocity with passivity in order to obtain state space realizations with physically motivated properties, including relaxation systems. The current paper is concerned with the extension of this theory to the nonlinear case. Emphasis is on nonlinear reciprocal systems with a Hessian pseudo-Riemannian metric. The combination of reciprocity with passivity is elucidated from a port-Hamiltonian perspective.},
  archive      = {J_SICON},
  author       = {Arjan van der Schaft},
  doi          = {10.1137/24M1629250},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {3019-3041},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Reciprocity of nonlinear systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Backstepping control of a class of space-time-varying linear
parabolic PDEs via time invariant kernel functions. <em>SICON</em>,
<em>62</em>(6), 2992–3018. (<a
href="https://doi.org/10.1137/23M1556836">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper aims at addressing the problem of exponential stabilization and continuous dependence of solutions on initial data for a class of 1-D linear parabolic PDEs with space-time-varying coefficients under backstepping boundary control. More precisely, in order to stabilize the system without involving a Gevrey-like condition or the event-triggered scheme, a boundary feedback controller is designed via a time invariant kernel function. Thus, the complexity of control design and implementation can be significantly reduced. The well-posedness of the closed-loop system is assessed by using Schauder’s theory and the theory of parabolic PDEs. By using the approximative Lyapunov method and a priori estimates of certain linear operators associated with Volterra integral transformations, the exponential stability of the closed-loop system is established in the spatial norm whenever . Then, based on the obtained exponential stability, it is shown that the solution to the considered system depends continuously on the spatial norm of the initial data. Numerical simulations are conducted to illustrate the effectiveness of the proposed scheme.},
  archive      = {J_SICON},
  author       = {Qiaoling Chen and Jun Zheng and Guchuan Zhu},
  doi          = {10.1137/23M1556836},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {2992-3018},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Backstepping control of a class of space-time-varying linear parabolic PDEs via time invariant kernel functions},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multilevel fast marching method for the minimum time
problem. <em>SICON</em>, <em>62</em>(6), 2963–2991. (<a
href="https://doi.org/10.1137/23M1563657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a new numerical method to approximate the solutions of a class of stationary Hamilton–Jacobi (HJ) partial differential equations arising from minimum time optimal control problems. We rely on nested grid approximations and look for the optimal trajectories by using the coarse grid approximations to reduce the search space in fine grids. This provides an infinitesimal version of the “highway hierarchy” method which has been developed to solve shortest path problems (with discrete time and discrete state). We obtain, for each level, an approximate value function on a subdomain of the state space. We show that the sequence obtained in this way does converge to the viscosity solution of the HJ equation. Moreover, for our multilevel algorithm, if is the convergence rate of the classical numerical scheme, then the number of arithmetic operations needed to obtain an error in is in , with , to be compared with for ordinary grid-based methods. Here is the dimension of the problem, depends on and on the “stiffness” of the value function around optimal trajectories, and the notation ignores logarithmic factors. In particular, in typical smooth cases, one has and .},
  archive      = {J_SICON},
  author       = {Marianne Akian and Stéphane Gaubert and Shanqing Liu},
  doi          = {10.1137/23M1563657},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {2963-2991},
  shortjournal = {SIAM J. Control Optim.},
  title        = {A multilevel fast marching method for the minimum time problem},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability and passivity for a class of distributed
port-hamiltonian networks. <em>SICON</em>, <em>62</em>(6), 2936–2962.
(<a href="https://doi.org/10.1137/22M1539174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of infinite dimensional (distributed) dissipative port-Hamiltonian systems whose dynamics is generated by a block operator in a Hilbert space that has a bounded dissipative diagonal and a possibly unbounded skew-adjoint off-diagonal. Sufficient conditions for the strong and exponential stability of the underlying semigroup generators are provided along with the derivation of a power-balance equation for classical solutions of the associated boundary control system. Furthermore, we consider interconnections of several such distributed pH systems and show that Kirchhoff-type interconnections preserve the underlying structure of the considered block operators. The results are illustrated for a power network connecting several prosumers via distributed transmission lines that are modeled based on the telegraph equations.},
  archive      = {J_SICON},
  author       = {Hannes Gernandt and Dorothea Hinsen},
  doi          = {10.1137/22M1539174},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {2936-2962},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stability and passivity for a class of distributed port-hamiltonian networks},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximation of feedback gains using spectral projections:
Application to the oseen system. <em>SICON</em>, <em>62</em>(6),
2910–2935. (<a href="https://doi.org/10.1137/23M1609695">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a parabolic controlled system (called ) in a Hilbert space and a family of approximate parabolic controlled systems (called ) in a Hilbert space . We are in the case of nonconforming approximations, that is, when . We assume that both and are Hilbert subspaces of another Hilbert space . We assume that and satisfy approximation errors, is exponentially stabilizable, and is uniformly parabolic. We define a reduced order model, called (resp., ), based on spectral projections for (resp., ). We construct a Riccati based feedback for which exponentially stabilizes both and , and we construct an associated Riccati based feedback for which exponentially stabilizes both and . We prove convergence rates for , and we prove that, for all , where is small enough, also exponentially stabilizes . We apply these results to the boundary feedback stabilization of the Oseen system (the linearized Navier–Stokes system around an unstable stationary solution) and to its numerical approximation by a finite element method (F.E.M.). In that case , where is the meshsize of the F.E.M.},
  archive      = {J_SICON},
  author       = {Mehdi Badra and Jean-Pierre Raymond},
  doi          = {10.1137/23M1609695},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {2910-2935},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Approximation of feedback gains using spectral projections: Application to the oseen system},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse parameter identification for stochastic systems based
on <span class="math inline"><em>L</em><sub><em>γ</em></sub></span>
regularization. <em>SICON</em>, <em>62</em>(6), 2884–2909. (<a
href="https://doi.org/10.1137/23M1599513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is concerned with the reconstruction of the zero and nonzero elements of the sparse parameter vector of stochastic systems with general observation sequences. A sparse parameter identification algorithm based on the penalty with and the residual sum of squares is proposed. Without requiring independently and identically distributed (i.i.d.) and stationary conditions on the observation sequences, the proposed algorithm is proved that not only the contributing variable corresponding to the nonzero parameters can be selected out with probability converging to one but also the estimates of the nonzero parameters have the asymptotic normality property. In order to improve the performance of the regularization method, a two-step algorithm based on the adaptively weighted penalty with is designed whose set and parameter almost sure convergence are established with non-i.i.d. and nonstationary observation sequences. The proposed methods are applied to the structure selection of the nonlinear autoregressive models with exogenous variables and the sparse parameter identification of the linear feedback control systems. Finally, three numerical examples are given to verify the efficiency of the theoretical results.},
  archive      = {J_SICON},
  author       = {Jian Guo and Ying Wang and Yanlong Zhao and Ji-Feng Zhang},
  doi          = {10.1137/23M1599513},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {2884-2909},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Sparse parameter identification for stochastic systems based on \({L_\gamma}\) regularization},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Average cost optimality of partially observed MDPs:
Contraction of nonlinear filters and existence of optimal solutions and
approximations. <em>SICON</em>, <em>62</em>(6), 2859–2883. (<a
href="https://doi.org/10.1137/24M1643736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The average cost optimality is known to be a challenging problem for partially observable stochastic control, with few results available beyond the finite state, action, and measurement setup, for which somewhat restrictive conditions are available. In this paper, we present explicit and easily testable conditions for the existence of solutions to the average cost optimality equation where the state space is compact. In particular, we present a novel contraction based analysis, which, to the best of our knowledge, is new to the literature, building on recent regularity results for nonlinear filters. Beyond establishing existence, we also present several implications of our analysis that also are new to the literature: (i) robustness to incorrect priors, (ii) near optimality of policies based on quantized approximations, (iii) near optimality of policies with finite memory, and (iv) convergence in Q-learning. In addition to our main theorem, each of these represents a novel contribution for average cost criteria.},
  archive      = {J_SICON},
  author       = {Yunus Emre Demirci and Ali Devran Kara and Serdar Yüksel},
  doi          = {10.1137/24M1643736},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {12},
  number       = {6},
  pages        = {2859-2883},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Average cost optimality of partially observed MDPs: Contraction of nonlinear filters and existence of optimal solutions and approximations},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential selection and feedback stabilization of
invariant subspaces of quantum trajectories. <em>SICON</em>,
<em>62</em>(5), 2834–2857. (<a
href="https://doi.org/10.1137/23M1607453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We show that quantum trajectories become exponentially fast supported by one of their minimal invariant subspaces. The exponential convergence is established in expectation by using Lyapunov techniques and carrying out an in-depth study of the identifiability of the different subspaces. Additionally, we introduce a feedback control strategy that enables targeted convergence to a desired subspace. This convergence is also achieved at exponential speed.},
  archive      = {J_SICON},
  author       = {Nina H. Amini and Maël Bompais and Clément Pellegrini},
  doi          = {10.1137/23M1607453},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2834-2857},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Exponential selection and feedback stabilization of invariant subspaces of quantum trajectories},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An asymptotic weak maximum principle. <em>SICON</em>,
<em>62</em>(5), 2807–2833. (<a
href="https://doi.org/10.1137/23M1595771">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. As far as numerical methods for optimization problems are concerned, in practice it is a matter of generating sequences of solutions and associated multipliers which are expected to obey, asymptotically, (at least) the first-order necessary optimality conditions. In mathematical programming, this procedure is theoretically validated by means of the so-called asymptotic KKT conditions. In optimal control theory, there is a lack of necessary optimality conditions of this kind. In this paper, we propose a new set of necessary optimality conditions for mixed-constrained optimal control problems in the form of an asymptotic (weak) maximum principle. We also propose, inspired by the augmented Lagrangian method for nonlinear programming, a method of multipliers for numerically solving mixed-constrained optimal control problems in which the generated sequences of solutions and multipliers satisfy the conditions of the asymptotic weak maximum principle. We discuss its convergence properties in terms of optimality and feasibility. To demonstrate the practical viability of the proposed theory, we provide some numerical results.},
  archive      = {J_SICON},
  author       = {Rodrigo B. Moreira and Valeriano A. de Oliveira},
  doi          = {10.1137/23M1595771},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2807-2833},
  shortjournal = {SIAM J. Control Optim.},
  title        = {An asymptotic weak maximum principle},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Infinite horizon average cost optimality criteria for
mean-field control. <em>SICON</em>, <em>62</em>(5), 2776–2806. (<a
href="https://doi.org/10.1137/23M1603649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study mean-field control problems in discrete time under the infinite horizon average cost optimality criteria. We focus on both the finite population and the infinite population setups. We show the existence of a solution to the average cost optimality equation (ACOE) and the existence of optimal stationary Markov policies for finite population problems under (i) a minorization condition that provides geometric ergodicity on the collective state process of the agents, and (ii) under standard Lipschitz continuity assumptions on the stagewise cost and transition function of the agents when the Lipschitz constant of the transition function satisfies a certain bound. For the infinite population problem, we establish the existence of a solution to the ACOE, and the existence of optimal policies under the continuity assumptions on the cost and the transition functions. Finally, we relate the finite population and infinite population control problems: (i) we prove that the optimal value of the finite population problem converges to the optimal value of the infinite population problem as the number of agents grows to infinity; (ii) we show that the accumulation points of the finite population optimal solution corresponds to an optimal solution for the infinite population problem; and finally (iii) we show that one can use the solution of the infinite population problem for the finite population problem symmetrically across the agents to achieve near optimal performance when the population is sufficiently large.},
  archive      = {J_SICON},
  author       = {Erhan Bayraktar and Ali Devran Kara},
  doi          = {10.1137/23M1603649},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2776-2806},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Infinite horizon average cost optimality criteria for mean-field control},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Infinite horizon backward stochastic difference equations
and related stochastic recursive control problems. <em>SICON</em>,
<em>62</em>(5), 2750–2775. (<a
href="https://doi.org/10.1137/23M160270X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is concerned with the discrete-time infinite horizon backward stochastic differential equation, i.e., the infinite horizon backward stochastic difference equation. We first prove the existence and uniqueness of the solution of this equation. Then the discrete-time stochastic recursive control problem is studied, in which the cost functional is set to be the solution of the infinite horizon backward stochastic difference equation. By introducing a proper discrete-time infinite horizon dual equation, we prove the stochastic maximum principle and the verification theorem for this recursive control problem. Finally we apply the derived stochastic maximum principle to the optimal consumption problem arising from a type of long-term trust fund.},
  archive      = {J_SICON},
  author       = {Yuanyuan Ji and Qi Zhang},
  doi          = {10.1137/23M160270X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2750-2775},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Infinite horizon backward stochastic difference equations and related stochastic recursive control problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the gain of entrainment in a class of weakly contractive
bilinear control systems. <em>SICON</em>, <em>62</em>(5), 2723–2749. (<a
href="https://doi.org/10.1137/23M1585714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of bilinear weakly contractive systems that entrain to periodic excitations. Entrainment is important in many natural and artificial processes. For example, in order to function properly synchronous generators must entrain to the frequency of the electrical grid, and biological organisms must entrain to the 24h solar day. A dynamical system has a positive gain of entrainment (GOE) if entrainment also yields a larger output, on average. This property is important in many applications from the periodic operation of bioreactors to the periodic production of proteins during the cell cycle division process. We derive a closed-form formula for the GOE to first-order in the control perturbation. This is used to show that in the class of systems that we consider the GOE is always a higher-order phenomenon. We demonstrate the theoretical results using two applications: the master equation and a model from systems biology called the ribosome flow model, both with time-varying and periodic transition rates.},
  archive      = {J_SICON},
  author       = {Rami Katz and Thomas Kriecherbauer and Lars Grüne and Michael Margaliot},
  doi          = {10.1137/23M1585714},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2723-2749},
  shortjournal = {SIAM J. Control Optim.},
  title        = {On the gain of entrainment in a class of weakly contractive bilinear control systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multiple lyapunov functions and memory: A symbolic dynamics
approach to systems and control. <em>SICON</em>, <em>62</em>(5),
2695–2722. (<a href="https://doi.org/10.1137/23M1589244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a novel framework for the Lyapunov analysis of an important class of hybrid systems, inspired by the theory of symbolic dynamics and earlier results on the restricted class of switched systems. This new framework allows us to leverage language theory tools in order to provide a universal characterization of Lyapunov stability for this class of systems. We establish, in particular, a formal connection between multiple Lyapunov functions and techniques based on memorization and/or prediction of the discrete part of the state. This allows us to provide an equivalent (single) Lyapunov function, for any given multiple-Lyapunov criterion. By leveraging our language-theoretic formalism, a new class of stability conditions is then obtained when considering both memory and future values of the state in a joint fashion, providing new numerical schemes that outperform existing technique. Our techniques are then illustrated on numerical examples.},
  archive      = {J_SICON},
  author       = {Matteo Della Rossa and Raphaël M. Jungers},
  doi          = {10.1137/23M1589244},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2695-2722},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Multiple lyapunov functions and memory: A symbolic dynamics approach to systems and control},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Unbiased parameter estimation for partially observed
diffusions. <em>SICON</em>, <em>62</em>(5), 2664–2694. (<a
href="https://doi.org/10.1137/23M160298X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this article we consider the estimation of static parameters for a partially observed diffusion process with discrete-time observations over a fixed time interval. In particular, we assume that one must time-discretize the partially observed diffusion process and work with the model with bias and consider maximizing the resulting log-likelihood. Using a novel double randomization scheme, based upon Markovian stochastic approximation we develop a new method to, in principle, unbiasedly estimate the static parameters, that is, to obtain the maximum likelihood estimator with no time discretization bias. Under appropriate mathematical assumptions we prove that our estimator is unbiased and investigate the method in several numerical examples, showing that it can empirically outperform the unbiased method in [J. Heng, J. Houssineau, and A. Jasra, J. Mach. Learn. Res., 25 (2024)].},
  archive      = {J_SICON},
  author       = {Elsiddig Awadelkarim and Ajay Jasra and Hamza Ruzayqat},
  doi          = {10.1137/23M160298X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2664-2694},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Unbiased parameter estimation for partially observed diffusions},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Average submodularity of maximizing anticoordination in
network games. <em>SICON</em>, <em>62</em>(5), 2639–2663. (<a
href="https://doi.org/10.1137/22M1506614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the control of decentralized learning dynamics for agents in an anticoordination network game. In the anticoordination network game, there is a preferred action in the absence of neighbors’ actions, and the utility an agent receives from the preferred action decreases as more of its neighbors select the preferred action, potentially causing the agent to select a less desirable action. The decentralized dynamics that are based on the synchronous best-response dynamics converge for the considered payoffs. Given a convergent action profile, we measure anticoordination by the number of edges in the underlying graph that have at least one agent in either end of the edge not taking the preferred action. A designer wants to find an optimal set of agents to control under a finite budget in order to achieve maximum anticoordination (MAC) on game convergence as a result of the dynamics. We show that the MAC is submodular in expectation over all realizations of the payoff interaction constants in bipartite networks. The proof relies on characterizing well-behavedness of MAC instances for bipartite networks, and designing a coupling between the dynamics and another distribution preserving selection protocol, for which we can show the diminishing returns property. Utilizing this result, we obtain a performance guarantee for the greedy optimization of MAC. Finally, we provide a computational study to show the effectiveness of greedy node selection strategies to solve MAC on general bipartite networks.},
  archive      = {J_SICON},
  author       = {Soham Das and Ceyhun Eksin},
  doi          = {10.1137/22M1506614},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2639-2663},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Average submodularity of maximizing anticoordination in network games},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controlled martingale problems and their markov mimics.
<em>SICON</em>, <em>62</em>(5), 2621–2638. (<a
href="https://doi.org/10.1137/23M1598428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this article we prove under suitable assumptions that the marginals of any solution to a relaxed controlled martingale problem on a Polish space can be mimicked by a Markovian solution of a Markov-relaxed controlled martingale problem. We also show how such ‘`Markov mimics’’ can be obtained by relative entropy minimization. We provide many examples where the above results can be applied.},
  archive      = {J_SICON},
  author       = {Siva Athreya and Vivek S. Borkar and Nitya Gadhiwala},
  doi          = {10.1137/23M1598428},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2621-2638},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Controlled martingale problems and their markov mimics},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal ratcheting of dividend payout under brownian motion
surplus. <em>SICON</em>, <em>62</em>(5), 2590–2620. (<a
href="https://doi.org/10.1137/23M159250X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is concerned with a long-standing optimal dividend payout problem subject to the so-called ratcheting constraint, that is, the dividend payout rate shall be nondecreasing over time and is thus self-path-dependent. The surplus process is modeled by a drifted Brownian motion process and the aim is to find the optimal dividend ratcheting strategy to maximize the expectation of the total discounted dividend payouts until the ruin time. Due to the self-path-dependent control constraint, the standard control theory cannot be directly applied to tackle the problem. The related Hamilton–Jacobi–Bellman (HJB) equation is a new type of variational inequality. In the literature, it is only shown to have a viscosity solution, which is not strong enough to guarantee the existence of an optimal dividend ratcheting strategy. This paper proposes a novel partial differential equation method to study the HJB equation. We not only prove the existence and uniqueness of the solution in some stronger functional space, but also prove the strict monotonicity, boundedness, and -smoothness of the dividend ratcheting free boundary. Based on these results, we eventually derive an optimal dividend ratcheting strategy, and thus solve the open problem completely. Economically speaking, we find that if the surplus volatility is above an explicit threshold, then one should pay dividends at the maximum rate, regardless of the surplus level. Otherwise, by contrast, the optimal dividend ratcheting strategy relies on the surplus level and one should only ratchet up the dividend payout rate when the surplus level touches the dividend ratcheting free boundary. Moreover, our numerical results suggest that one should invest in those companies with stable dividend payout strategies since their income rates should be higher and volatility rates smaller.},
  archive      = {J_SICON},
  author       = {Chonghu Guan and Zuo Quan Xu},
  doi          = {10.1137/23M159250X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2590-2620},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Optimal ratcheting of dividend payout under brownian motion surplus},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Backward stochastic differential equations with conditional
reflection and related recursive optimal control problems.
<em>SICON</em>, <em>62</em>(5), 2557–2589. (<a
href="https://doi.org/10.1137/22M1534985">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a new type of reflected backward stochastic differential equations (BSDEs) for which the reflection constraint is imposed on its main solution component, denoted as by convention, but in terms of its conditional expectation on a general subfiltration . We thus term such a equation as conditionally reflected BSDE (for short, conditional RBSDE). Conditional RBSDE subsumes classical RBSDE with a pointwise reflection barrier and the recently developed BSDE with a mean reflection constraint as its two special and extreme cases: they exactly correspond to being the full filtration to represent complete information and the degenerated filtration to deterministic scenario, respectively. For conditional RBSDE, we obtain its existence and uniqueness under mild conditions by combining the Snell envelope method with the Skorokhod lemma. We also discuss its connection, in the case of a linear driver, to a class of optimal stopping problems in the presence of partial information. As a by-product, a new version of the comparison theorem is obtained. With the help of this connection, we study weak formulations of a class of optimal control problems with reflected recursive functionals by characterizing the related optimal solution and value. Moreover, in the special case of recursive functionals being RBSDE with pointwise reflections, we study the strong formulations of related stochastic backward recursive control and zero-sum games, both in a non-Markovian framework, that are of their own interests and have not been fully explored by existing literature yet.},
  archive      = {J_SICON},
  author       = {Ying Hu and Jianhui Huang and Wenqiang Li},
  doi          = {10.1137/22M1534985},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2557-2589},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Backward stochastic differential equations with conditional reflection and related recursive optimal control problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Logarithmic regret bounds for continuous-time average-reward
markov decision processes. <em>SICON</em>, <em>62</em>(5), 2529–2556.
(<a href="https://doi.org/10.1137/23M1584101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider reinforcement learning for continuous-time Markov decision processes (MDPs) in the infinite-horizon, average-reward setting. In contrast to discrete-time MDPs, a continuous-time process moves to a state and stays there for a random holding time after an action is taken. With unknown transition probabilities and rates of exponential holding times, we derive instance-dependent regret lower bounds that are logarithmic in the time horizon. Moreover, we design a learning algorithm and establish a finite-time regret bound that achieves the logarithmic growth rate. Our analysis builds upon upper confidence reinforcement learning, a delicate estimation of the mean holding times, and stochastic comparison of point processes.},
  archive      = {J_SICON},
  author       = {Xuefeng Gao and Xun Yu Zhou},
  doi          = {10.1137/23M1584101},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2529-2556},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Logarithmic regret bounds for continuous-time average-reward markov decision processes},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An optimal spectral inequality for degenerate operators.
<em>SICON</em>, <em>62</em>(5), 2506–2528. (<a
href="https://doi.org/10.1137/23M1605211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we establish a Lebeau–Robbiano spectral inequality for a degenerate one-dimensional elliptic operator, with an optimal dependency with the frequency parameter. The proof relies on a combination of uniform local Carleman estimates away from the degeneracy and a moment method adapted for a degenerate elliptic operator. We also provide an application to the null-controllability on a measurable set in time for the associated degenerate heat equation.},
  archive      = {J_SICON},
  author       = {Rémi Buffe and Kim Dang Phung and Amine Slimani},
  doi          = {10.1137/23M1605211},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2506-2528},
  shortjournal = {SIAM J. Control Optim.},
  title        = {An optimal spectral inequality for degenerate operators},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A tikhonov theorem for McKean–vlasov two-scale systems and a
new application to mean field optimal control problems. <em>SICON</em>,
<em>62</em>(5), 2475–2505. (<a
href="https://doi.org/10.1137/22M1543070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We provide a new version of the Tikhonov theorem for both two-scale forward systems and also two-scale forward-backward systems of stochastic differential equations, which also covers the McKean–Vlasov case. Differently from what is usually done in the literature, we prove a type of convergence for the “fast” variable, which allows the limiting process to be discontinuous. This is relevant for the second part of the paper, where we present a new application of this theory to the approximation of the solution of mean field control problems. Towards this aim, we construct a two-scale system whose “fast” component converges to the optimal control process, while the “slow” component converges to the optimal state process. The interest in such a procedure is that it allows one to approximate the solution of the control problem, avoiding the usual step of the minimization of the Hamiltonian.},
  archive      = {J_SICON},
  author       = {Matteo Burzoni and Alekos Cecchin and Andrea Cosso},
  doi          = {10.1137/22M1543070},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2475-2505},
  shortjournal = {SIAM J. Control Optim.},
  title        = {A tikhonov theorem for McKean–Vlasov two-scale systems and a new application to mean field optimal control problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Null internal controllability for a kirchhoff–love plate
with a comb-like shaped structure. <em>SICON</em>, <em>62</em>(5),
2456–2474. (<a href="https://doi.org/10.1137/24M1647825">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is devoted to studying the null internal controllability of a Kirchoff–Love thin plate with a middle surface having a comb-like shaped structure with a large number of thin fingers described by a small positive parameter . It is often impossible to directly approach such a problem numerically, due to the large number of thin fingers. So an asymptotic analysis is needed. In this paper, we first prove that the problem is null controllable at each level . We then prove that the sequence of the respective controls with minimal norm converges, as vanishes, to a limit control function ensuring the optimal null controllability of a degenerate limit problem set in a domain without fingers.},
  archive      = {J_SICON},
  author       = {Umberto De Maio and Antonio Gaudiello and Cătălin-George Lefter},
  doi          = {10.1137/24M1647825},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2456-2474},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Null internal controllability for a Kirchhoff–Love plate with a comb-like shaped structure},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Stochastic maximum principle for fully coupled
forward-backward stochastic differential equations driven by
subdiffusion. <em>SICON</em>, <em>62</em>(5), 2433–2455. (<a
href="https://doi.org/10.1137/23M1620168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study optimal stochastic control problems for fully coupled forward-backward stochastic differential equations driven by anomalous subdiffusion, which have nontrivial mixed features of deterministic and stochastic controls. Both the stochastic maximum principle (SMP) and sufficient SMP are obtained by using a convex variational method. The paper ends with an application of the main results of this paper to a linear quadratic problem in the subdiffusive setting, which is solved explicitly.},
  archive      = {J_SICON},
  author       = {Shuaiqi Zhang and Zhen-Qing Chen},
  doi          = {10.1137/23M1620168},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {10},
  number       = {5},
  pages        = {2433-2455},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stochastic maximum principle for fully coupled forward-backward stochastic differential equations driven by subdiffusion},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The hybrid maximum principle for optimal control problems
with spatially heterogeneous dynamics is a consequence of a pontryagin
maximum principle for <span
class="math inline">L<sub><strong>▫</strong></sub><sup><strong>1</strong></sup></span>-local
solutions. <em>SICON</em>, <em>62</em>(4), 2412–2432. (<a
href="https://doi.org/10.1137/23M155311X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The title of the present work is a nod to the paper “The hybrid maximum principle is a consequence of Pontryagin maximum principle” by Dmitruk and Kaganovich [Systems Control Lett., 57 (2008), pp. 964–970]. We investigate a similar framework of hybrid optimal control problems that is also different from Dmitruk and Kaganovich’s. Precisely, we consider a general control system that is described by a differential equation involving a spatially heterogeneous dynamics. In that context, the sequence of dynamics followed by the trajectory and the corresponding switching times are fully constrained by the state position. We prove with an explicit counterexample that the augmentation technique used by Dmitruk and Kaganovich cannot be fully applied to our setting, but we show that it can be adapted by introducing a new notion of local solution to classical optimal control problems and by establishing a corresponding Pontryagin maximum principle. Thanks to this method, we derive a hybrid maximum principle adapted to our setting, with a simple proof that does not require any technical tools (such as implicit function arguments) to handle the dynamical discontinuities.},
  archive      = {J_SICON},
  author       = {Térence Bayen and Anas Bouali and Loïc Bourdin},
  doi          = {10.1137/23M155311X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2412-2432},
  shortjournal = {SIAM J. Control Optim.},
  title        = {The hybrid maximum principle for optimal control problems with spatially heterogeneous dynamics is a consequence of a pontryagin maximum principle for \(\boldsymbol{\textrm{L}}^{\boldsymbol{1}}_{\boldsymbol{\square }}\)-local solutions},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Chain controllability of linear control systems.
<em>SICON</em>, <em>62</em>(4), 2387–2411. (<a
href="https://doi.org/10.1137/23M1626347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For linear control systems with bounded control range, chain controllability properties are analyzed. It is shown that there exists a unique chain control set and that it equals the sum of the control set around the origin and the center Lyapunov space of the homogeneous part. For the proof, the linear control system is extended to a bilinear control system on an augmented state space. This system induces a control system on projective space. For the associated control flow, attractor-repeller decompositions are used to show that the control system on projective space has a unique chain control set that is not contained in the equator. It is given by the image of the chain control set of the original linear control system.},
  archive      = {J_SICON},
  author       = {Fritz Colonius and Alexandre J. Santana and Eduardo C. Viscovini},
  doi          = {10.1137/23M1626347},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2387-2411},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Chain controllability of linear control systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On borkar and young relaxed control topologies and
continuous dependence of invariant measures on control policy.
<em>SICON</em>, <em>62</em>(4), 2367–2386. (<a
href="https://doi.org/10.1137/23M1571940">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In deterministic and stochastic control theory, relaxed or randomized control policies allow for versatile mathematical analysis (on continuity, compactness, convexity, and approximations) to be applicable with no artificial restrictions on the classes of control policies considered, leading to very general existence results on optimal measurable policies under various setups and information structures. On relaxed controls, two studied topologies are the Young and Borkar (weak) topologies on spaces of functions from a state/measurement space to the space of probability measures on control action spaces; the former via a weak convergence topology on probability measures on a product space with a fixed marginal on the input (state) space, and the latter via a weak topology on randomized policies viewed as maps from states/measurements to the space of signed measures with bounded variation. We establish implication and equivalence conditions between the Young and Borkar topologies on control policies. We then show that, under some conditions, for a controlled Markov chain with standard Borel spaces the invariant measure is weakly continuous on the space of stationary control policies defined by either of these topologies. An implication is near-optimality of quantized stationary policies in state and actions or continuous stationary and deterministic policies for average cost control under two sets of continuity conditions (with either weak continuity in the state-action pair or strong continuity in the action for each state) on transition kernels.},
  archive      = {J_SICON},
  author       = {Serdar Yüksel},
  doi          = {10.1137/23M1571940},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2367-2386},
  shortjournal = {SIAM J. Control Optim.},
  title        = {On borkar and young relaxed control topologies and continuous dependence of invariant measures on control policy},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constituting an extension of lyapunov’s direct method.
<em>SICON</em>, <em>62</em>(4), 2346–2366. (<a
href="https://doi.org/10.1137/23M1595242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates new sufficient conditions for the stability, asymptotic stability, and global asymptotic stability of nonlinear autonomous systems, specifically in cases where the first derivative of the Lyapunov function candidate may have both positive and negative values on its domain. The main contribution of this approach is the introduction of a new auxiliary function that relaxes the stability conditions, allowing the first derivative of the Lyapunov function candidate to be less than or equal to a nonnegative function. The suggested auxiliary function should be integrable within our first theorem. Meanwhile, our first corollary presents a technique that simplifies the task by establishing specific conditions related to differential inequalities. This weaker condition in the proposed results enables the establishment of stability properties in cases where the Lyapunov function candidate is not well chosen or finding a Lyapunov function is not straightforward. Additionally, it is proven that the original Lyapunov method for autonomous systems is a special case of our first theorem. Furthermore, it is demonstrated that assumptions in previous studies, such as Matrosov’s theorem or results on higher-order derivatives of the Lyapunov function, guarantee the existence of our auxiliary function. Finally, lemmas are provided to construct these auxiliary functions, and examples are presented to demonstrate the effectiveness of this approach. This work will contribute to the development of stability analysis techniques for nonlinear autonomous systems.},
  archive      = {J_SICON},
  author       = {M. Akbarian and N. Pariz and A. Heydari},
  doi          = {10.1137/23M1595242},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2346-2366},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Constituting an extension of lyapunov’s direct method},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sharp equilibria for time-inconsistent mean-field stopping
games. <em>SICON</em>, <em>62</em>(4), 2319–2345. (<a
href="https://doi.org/10.1137/23M1625512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We investigate time-inconsistent mean-field stopping games under nonexponential discounting in discrete time. At the intrapersonal level, each player plays against her future selves as a result of the time inconsistency caused by nonexponential discounting. At the interpersonal level, she plays against other players due to players’ interaction via the proportion of players that have stopped. We look for sharp mean-field equilibria (MFEs), such that given other players’ stopping policies, the representative player’s strategy not only is an intrapersonal equilibrium, but also an optimal one among all such intrapersonal equilibria. We analyze two classes of examples. The first one is on time-inconsistent bank-run models, and we construct an (optimal) sharp MFE by a monotone iteration scheme. The second one has a Markovian setup and no common noise, and we show the existence of a sharp MFE based on the Tikhonov fixed-point theorem.},
  archive      = {J_SICON},
  author       = {Ziyuan Wang and Zhou Zhou},
  doi          = {10.1137/23M1625512},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2319-2345},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Sharp equilibria for time-inconsistent mean-field stopping games},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The unconditional consensus control through leadership for
the delayed hegselmann–krause model. <em>SICON</em>, <em>62</em>(4),
2297–2318. (<a href="https://doi.org/10.1137/23M1588858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the Hegselmann–Krause opinion formation model with leadership and time delay, which is a generalization of the model studied by Wongkaew, Caponigro, and Borzi [Math. Models Methods Appl. Sci., 25 (2015), pp. 565–585], dealing with the control strategies without time delay effect. Numerical simulations suggest that the consensus can still emerge asymptotically in the opinion evolution flow under the leader’s control even when the time delay is large. However, rigorous theoretical analysis for such consensus dynamics still lacks a complete understanding. In this paper, we present an iterated framework for the consensus control behavior for the delayed Hegselmann–Krause model with leadership, without any restriction on the length of the time delay. After that, we design a simple control strategy which can steer all agents to any target opinion and give a theoretical proof of its validity. Numerical simulations are performed to confirm theoretical results.},
  archive      = {J_SICON},
  author       = {Linglong Du and Jianwen Zhu and Feng Xie},
  doi          = {10.1137/23M1588858},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2297-2318},
  shortjournal = {SIAM J. Control Optim.},
  title        = {The unconditional consensus control through leadership for the delayed Hegselmann–Krause model},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An observer for pipeline flow with hydrogen blending in gas
networks: Exponential synchronization. <em>SICON</em>, <em>62</em>(4),
2273–2296. (<a href="https://doi.org/10.1137/23M1563840">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a state estimation problem for gas flows in pipeline networks where hydrogen is blended into the natural gas. The flow is modeled by the quasi-linear isothermal Euler equations coupled to an advection equation on a graph. The flow through the vertices where the pipes are connected is governed by algebraic node conditions. The state is approximated by an observer system that uses nodal measurements. We prove that the state of the observer system converges to the original system state exponentially fast in the -norm if the measurements are exact. If measurement errors are present we show that the observer state approximates the original system state up to an error that is proportional to the maximal measurement error. The proof of the synchronization result uses Lyapunov functions with exponential weights.},
  archive      = {J_SICON},
  author       = {Martin Gugat and Jan Giesselmann},
  doi          = {10.1137/23M1563840},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2273-2296},
  shortjournal = {SIAM J. Control Optim.},
  title        = {An observer for pipeline flow with hydrogen blending in gas networks: Exponential synchronization},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dual-gain function based prescribed-time output feedback
control nonlinear time-delay systems. <em>SICON</em>, <em>62</em>(4),
2254–2272. (<a href="https://doi.org/10.1137/23M1556496">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates the prescribed-time output feedback stabilization problem for a class of nonlinear time-delay systems. First, a novel dual-gain function is put forward by exploiting the dynamic gain and the time-varying gain function to design the reduced-order observer for reconstructing unavailable states. Then, by utilizing the Lyapunov–Krasovskii functional and state variables of the reduced-order observer, a new prescribed-time controller is presented based on the nonscaling design framework. Since no state scaling is required in controller design process under this framework, our control strategy is simpler and can greatly reduce the computational burden. Further, compared with the previous prescribed-time stabilization results, our designed controller acts on the entire time domain, not just a limited time interval. Based on our proposed stability criterion, it is proved that the controller can render that all system state variables converge to the origin within the prescribed time. Finally, a numerical example is provided to illustrate the effectiveness of the proposed control strategy.},
  archive      = {J_SICON},
  author       = {Pengju Ning and Sergey N. Dashkovskiy and Changchun Hua and Kuo Li},
  doi          = {10.1137/23M1556496},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2254-2272},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Dual-gain function based prescribed-time output feedback control nonlinear time-delay systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep relaxation of controlled stochastic gradient descent
via singular perturbations. <em>SICON</em>, <em>62</em>(4), 2229–2253.
(<a href="https://doi.org/10.1137/23M1544878">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a singularly perturbed system of stochastic differential equations proposed by Chaudhari et al. (Res. Math. Sci. 2018) to approximate the entropic gradient descent in the optimization of deep neural networks via homogenization. We embed it in a much larger class of two-scale stochastic control problems and rely on convergence results for Hamilton–Jacobi–Bellman equations with unbounded data proved recently by ourselves (ESAIM Control Optim. Calc. Var. 2023). We show that the limit of the value functions is itself the value function of an effective control problem with extended controls and that the trajectories of the perturbed system converge in a suitable sense to the trajectories of the limiting effective control system. These rigorous results improve the understanding of the convergence of the algorithms used by Chaudhari et al., as well as of their possible extensions where some tuning parameters are modeled as dynamic controls.},
  archive      = {J_SICON},
  author       = {Martino Bardi and Hicham Kouhkouh},
  doi          = {10.1137/23M1544878},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2229-2253},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Deep relaxation of controlled stochastic gradient descent via singular perturbations},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Zero-sum stopper versus singular-controller games with
constrained control directions. <em>SICON</em>, <em>62</em>(4),
2203–2228. (<a href="https://doi.org/10.1137/23M1579558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of zero-sum stopper versus singular-controller games in which the controller can only act on a subset of the coordinates of a controlled diffusion. Due to the constraint on the control directions these games fall outside the framework of recently studied variational methods. In this paper we develop an approximation procedure, based on -stability estimates for the controlled diffusion process and almost sure convergence of suitable stopping times. That allows us to prove existence of the game’s value and to obtain an optimal strategy for the stopper under continuity and growth conditions on the payoff functions. This class of games is a natural extension of (single-agent) singular control problems, studied in the literature, with similar constraints on the admissible controls.},
  archive      = {J_SICON},
  author       = {Andrea Bovo and Tiziano De Angelis and Jan Palczewski},
  doi          = {10.1137/23M1579558},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2203-2228},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Zero-sum stopper versus singular-controller games with constrained control directions},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph-structured tensor optimization for nonlinear density
control and mean field games. <em>SICON</em>, <em>62</em>(4), 2176–2202.
(<a href="https://doi.org/10.1137/23M1571587">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work we develop a numerical method for solving a type of convex graph-structured tensor optimization problem. This type of problem, which can be seen as a generalization of multimarginal optimal transport problems with graph-structured costs, appears in many applications. Examples are unbalanced optimal transport and multispecies potential mean field games, where the latter is a class of nonlinear density control problems. The method we develop is based on coordinate ascent in a Lagrangian dual, and under mild assumptions we prove that the algorithm converges globally. Moreover, under a set of stricter assumptions, the algorithm converges R-linearly. To perform the coordinate ascent steps one has to compute projections of the tensor, and doing so by brute force is in general not computationally feasible. Nevertheless, for certain graph structures it is possible to derive efficient methods for computing these projections, and here we specifically consider the graph structure that occurs in multispecies potential mean field games. We also illustrate the methodology on a numerical example from this problem class.},
  archive      = {J_SICON},
  author       = {Axel Ringh and Isabel Haasler and Yongxin Chen and Johan Karlsson},
  doi          = {10.1137/23M1571587},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2176-2202},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Graph-structured tensor optimization for nonlinear density control and mean field games},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On markov perfect equilibria in discounted stochastic ARAT
games. <em>SICON</em>, <em>62</em>(4), 2148–2175. (<a
href="https://doi.org/10.1137/23M1592365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we study discounted stochastic games with an additive rewards and transitions structure. We assume that the transition probabilities are dominated by some probability measures on a countably generated measurable state space and are norm continuous in actions of the players. We prove the existence of Markov perfect equilibria in which the players can use randomization on two pure actions in each state. When the state space is countable, then we show that there exists a pure Markov perfect equilibrium. Assuming additionally that the transition probabilities have no conditional atoms, we establish some existence results on pure Markov perfect equilibria for games with uncountable state space using a version of Lyapunov’s theorem for conditional expectation of correspondences due to Dynkin and Evstigneev. We also include a wide-ranging discussion on equilibria for discounted stochastic games with a general state space.},
  archive      = {J_SICON},
  author       = {Anna Jaśkiewicz and Andrzej S. Nowak},
  doi          = {10.1137/23M1592365},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2148-2175},
  shortjournal = {SIAM J. Control Optim.},
  title        = {On markov perfect equilibria in discounted stochastic ARAT games},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Risk-sensitive average markov decision processes in general
spaces. <em>SICON</em>, <em>62</em>(4), 2115–2147. (<a
href="https://doi.org/10.1137/23M156118X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we study discrete-time Markov decision processes with Borel state and action spaces under the risk-sensitive average cost criterion. The cost function can be unbounded. We introduce a new kernel and prove the quasi-compactness of the kernel from which the multiplicative Poisson equation is derived. Moreover, we develop a new approach to show the existence of a solution to the risk-sensitive average cost optimality equation and obtain the existence of an optimal deterministic stationary policy. Furthermore, we give two examples to illustrate our results.},
  archive      = {J_SICON},
  author       = {Xian Chen and Qingda Wei},
  doi          = {10.1137/23M156118X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2115-2147},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Risk-sensitive average markov decision processes in general spaces},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Existence of optimal pairs for optimal control problems with
states constrained to riemannian manifolds. <em>SICON</em>,
<em>62</em>(4), 2098–2114. (<a
href="https://doi.org/10.1137/23M1584095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we investigate the existence of optimal pairs for optimal control problems with their states constrained pointwise to Riemannian manifolds. For this purpose, by means of the Riemannian geometric tool, we introduce a crucial Cesari-type property, which is an extension of the classical Cesari property (see Definition 3.3, p. 51 in [L. D. Berkovitz, Optimal Control Theory, Appl. Math. Sci. 12, Springer-Verlag, New York, Heidelberg, 1974]) from the setting of Euclidean spaces to that of Riemannian manifolds. Moreover, we show the efficiency of our result by a concrete example.},
  archive      = {J_SICON},
  author       = {Li Deng and Xu Zhang},
  doi          = {10.1137/23M1584095},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2098-2114},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Existence of optimal pairs for optimal control problems with states constrained to riemannian manifolds},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust funnel model predictive control for output tracking
with prescribed performance. <em>SICON</em>, <em>62</em>(4), 2071–2097.
(<a href="https://doi.org/10.1137/23M1551195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a novel robust Model Predictive Control (MPC) scheme for nonlinear multi-input multi-output systems of relative degree one with stable internal dynamics. The proposed algorithm is a combination of funnel MPC, i.e., MPC with a particular stage cost, and the model-free adaptive funnel controller. The new robust funnel MPC scheme guarantees output tracking of reference signals within prescribed performance bounds—even in the presence of unknown disturbances and a structural model-plant mismatch. We show initial and recursive feasibility of the proposed control scheme without imposing terminal conditions or any requirements on the prediction horizon. Moreover, we allow for model updates at runtime. To this end, we propose a proper initialization strategy, which ensures that recursive feasibility is preserved. Finally, we validate the performance of the proposed robust MPC scheme by simulations.},
  archive      = {J_SICON},
  author       = {Thomas Berger and Dario Dennstädt and Lukas Lanza and Karl Worthmann},
  doi          = {10.1137/23M1551195},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2071-2097},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Robust funnel model predictive control for output tracking with prescribed performance},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gradient flows for regularized stochastic control problems.
<em>SICON</em>, <em>62</em>(4), 2036–2070. (<a
href="https://doi.org/10.1137/20M1373645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies stochastic control problems with the action space taken to be probability measures, with the objective penalized by the relative entropy. We identify a suitable metric space on which we construct a gradient flow for the measure-valued control process, in the set of admissible controls, along which the cost functional is guaranteed to decrease. It is shown that any invariant measure of this gradient flow satisfies the Pontryagin optimality principle. If the problem we work with is sufficiently convex, the gradient flow converges exponentially fast. Furthermore, the optimal measure-valued control process admits a Bayesian interpretation, which means that one can incorporate prior knowledge when solving such stochastic control problems. This work is motivated by a desire to extend the theoretical underpinning for the convergence of stochastic gradient type algorithms widely employed in the reinforcement learning community to solve control problems.},
  archive      = {J_SICON},
  author       = {David Šiška and Łukasz Szpruch},
  doi          = {10.1137/20M1373645},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2036-2070},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Gradient flows for regularized stochastic control problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal impulsive control for time delay systems.
<em>SICON</em>, <em>62</em>(4), 2012–2035. (<a
href="https://doi.org/10.1137/24M1632450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce discontinuous solutions to nonlinear impulsive control systems with state time delays in the dynamics and derive necessary optimality conditions in the form of a maximum principle for associated optimal control problems. In the case without delays, if the measure control is scalar valued, the corresponding discontinuous state trajectory, understood as a limit of classical state trajectories for absolutely continuous controls approximating the measure, is unique. For vector-valued measure controls, however, the limiting trajectory is not unique and a full description of the control must include additional “attached” controls affecting instantaneous state evolution at a discontinuity. For impulsive control systems with time delays we reveal a new phenomenon, namely, that the limiting state trajectory resulting from different approximations of a given measure control needs not to be unique, even in the scalar case. Correspondingly, our framework allows for additional attached controls, even though the measure control is scalar valued.},
  archive      = {J_SICON},
  author       = {Giovanni Fusco and Monica Motta and Richard Vinter},
  doi          = {10.1137/24M1632450},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {2012-2035},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Optimal impulsive control for time delay systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Controlling a vlasov–poisson plasma by a particle-in-cell
method based on a monte carlo framework. <em>SICON</em>, <em>62</em>(4),
1977–2011. (<a href="https://doi.org/10.1137/23M1563852">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Vlasov–Poisson system describes the time evolution of a plasma in the so-called collisionless regime. The investigation of a high-temperature plasma that is influenced by an exterior magnetic field is one of the most significant aspects of thermonuclear fusion research. In this paper, we formulate and analyze a kinetic optimal control problem for the Vlasov–Poisson system where the control is represented by an external magnetic field. The main goal of such optimal control problems is to confine the plasma to a certain region in phase space. We first investigate the optimal control problem in terms of mathematical analysis, i.e., we show the existence of at least one global minimizer and rigorously derive a first-order necessary optimality condition for local minimizers by the adjoint approach. Then we build a Monte Carlo framework to solve the state equations as well as the adjoint equations by means of a particle-in-cell method, and we apply a nonlinear conjugate gradient method to solve the optimization problem. Eventually, we present numerical experiments that successfully validate our optimization framework.},
  archive      = {J_SICON},
  author       = {Jan Bartsch and Patrik Knopf and Stefania Scheurer and Jörg Weber},
  doi          = {10.1137/23M1563852},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {1977-2011},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Controlling a Vlasov–Poisson plasma by a particle-in-cell method based on a monte carlo framework},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the exact boundary controllability of semilinear wave
equations. <em>SICON</em>, <em>62</em>(4), 1953–1976. (<a
href="https://doi.org/10.1137/23M1586598">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We address the exact boundary controllability of the semilinear wave equation posed over a bounded domain of . Assuming that is continuous and satisfies the condition for some small enough and some in , we apply the Schauder fixed point theorem to prove the uniform controllability for initial data in . Then, assuming that is in and satisfies the condition , we apply the Banach fixed point theorem and exhibit a strongly convergent sequence to a state-control pair for the semilinear equation.},
  archive      = {J_SICON},
  author       = {Sue Claret and Jérôme Lemoine and Arnaud Münch},
  doi          = {10.1137/23M1586598},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {1953-1976},
  shortjournal = {SIAM J. Control Optim.},
  title        = {On the exact boundary controllability of semilinear wave equations},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Further on pinning synchronization of dynamical networks
with coupling delay. <em>SICON</em>, <em>62</em>(4), 1933–1952. (<a
href="https://doi.org/10.1137/23M1578085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Though extensively studied, the longstanding pinning synchronization problem of dynamical networks with coupling delay has not been well solved until now. In this paper, we further investigate this problem. By proposing a system of functional differential inequalities, we derive synchronization criteria for dynamical networks with coupling delay under linear pinning control, where the threshold of the admissible delay and the control gain threshold are estimated. Since the estimated control gain threshold could be very large when the delay draws close to the delay threshold, we also use the adaptive pinning control scheme to avoid control gain estimation. Pinning synchronization criteria of networks under adaptive control are derived and the delay threshold is given. This is the first time that general coupling delay has been addressed in the field of pinning control. Finally, two numerical examples are presented to validate the theoretical results.},
  archive      = {J_SICON},
  author       = {Shuaibing Zhu and Jinhu Lü},
  doi          = {10.1137/23M1578085},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {8},
  number       = {4},
  pages        = {1933-1952},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Further on pinning synchronization of dynamical networks with coupling delay},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). RBFNN adaptive sampled-data control for nonlinear plants: A
validity analysis. <em>SICON</em>, <em>62</em>(3), 1908–1932. (<a
href="https://doi.org/10.1137/23M1595035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates adaptive sampled-data control for strict-feedback nonlinear plants with unmatched uncertainties by means of radial basis function neural networks (RBFNNs). First, the continuous-time plant is locally discretized as a disturbed strict-feedback model by using the approximate Euler model approach. Then, as a basis of rigorous stability analysis, the concept of validity is proposed, which, considering the locality of the universal approximation capacity in RBFNNs, requires that the argument of each RBFNN be inside the corresponding compact set all the time. Meanwhile, to address the noncausality issue, delayed signals are utilized in the backstepping method for discrete-time plants. Subsequently, the validity and stability are proved rigorously; meanwhile, a practical output tracking problem is solved under a time-varying reference signal, the order of whose continuous derivatives is the same as the plants. This is the first time the interdependence on the design of sampling periods and RBFNNs in different design steps has been shown. Finally, simulation results are provided to illustrate the efficiency and feasibility of the obtained results.},
  archive      = {J_SICON},
  author       = {Hao Yu and Tongwen Chen},
  doi          = {10.1137/23M1595035},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1908-1932},
  shortjournal = {SIAM J. Control Optim.},
  title        = {RBFNN adaptive sampled-data control for nonlinear plants: A validity analysis},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Average cost minimization problems subject to state
constraints. <em>SICON</em>, <em>62</em>(3), 1884–1907. (<a
href="https://doi.org/10.1137/23M1558124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider pathwise state constraint optimal control problems in which unknown parameters intervene in the dynamics, the cost, the endpoint constraint, and the state constraint. The cost criteria to minimize take an integral form of a given endpoint cost function with respect to a reference probability measure that is defined on the set of the unknown parameters. For this class of problems we derive necessary optimality conditions.},
  archive      = {J_SICON},
  author       = {Piernicola Bettiol and Nathalie Khalil},
  doi          = {10.1137/23M1558124},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1884-1907},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Average cost minimization problems subject to state constraints},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On tracking and antidisturbance ability of PID controllers.
<em>SICON</em>, <em>62</em>(3), 1857–1883. (<a
href="https://doi.org/10.1137/22M1522498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we are concerned with the tracking performance and antidisturbance ability of the widely used proportional-integral-derivative (PID) controllers in practice. Towards this end, we consider a basic class of second-order nonlinear stochastic control systems subject to model uncertainties and external disturbances, and focus on the ability of the classical PID controller to track time-varying reference signals. First, under some suitable conditions on the system nonlinear functions, reference signals, and external disturbances, we show that such control systems can be stabilized in the mean square sense, provided that the three PID gains are selected from a stability region constructed in the paper. Besides, it is shown that the steady-state tracking error has an upper bound proportional to the sum of the varying rates of reference signals, the varying rates of external disturbances, and the intensity of random noises. Meanwhile, its proportional coefficient depends on the selection of PID gains, which can be made arbitrarily small by choosing suitably large PID gains. Finally, by introducing a desired transient process which is shaped from the reference signal, a new PID tuning rule is presented, which can guarantee both the expected steady state and transient tracking performance.},
  archive      = {J_SICON},
  author       = {Cheng Zhao and Shuo Yuan},
  doi          = {10.1137/22M1522498},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1857-1883},
  shortjournal = {SIAM J. Control Optim.},
  title        = {On tracking and antidisturbance ability of PID controllers},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quickest real-time detection of multiple brownian drifts.
<em>SICON</em>, <em>62</em>(3), 1832–1856. (<a
href="https://doi.org/10.1137/23M1587750">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Consider the motion of a Brownian particle in dimensions, whose coordinate processes are standard Brownian motions with zero drift initially, and then at some random/unobservable time, exactly of the coordinate processes get a (known) nonzero drift permanently. Given that the position of the Brownian particle is being observed in real time, the problem is to detect the time at which the coordinate processes get the drift as accurately as possible. We solve this problem in the most uncertain scenario when the random/unobservable time is (i) exponentially distributed and (ii) independent from the initial motion without drift. The solution is expressed in terms of a stopping time that minimizes the probability of a false early detection and the expected delay of a missed late detection. The elliptic case has been settled in [4] where the hypoelliptic case resolved in the present paper was left open (the case reduces to the classic case having a known solution). We also show that the methodology developed solves the problem in the general case where exactly is relaxed to any number of the coordinate processes getting the drift. To our knowledge this is the first time that such a multidimensional hypoelliptic problem has been solved exactly in the literature.},
  archive      = {J_SICON},
  author       = {P. A. Ernst and H. Mei and G. Peskir},
  doi          = {10.1137/23M1587750},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1832-1856},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Quickest real-time detection of multiple brownian drifts},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimal control placement of networked reaction-diffusion
systems based on turing model. <em>SICON</em>, <em>62</em>(3),
1809–1831. (<a href="https://doi.org/10.1137/23M1616856">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider the problem of placing a minimal number of controls to achieve controllability for a class of networked control systems that are based on the original Turing reaction-diffusion model, which is governed by a set of ordinary differential equations with interactions defined by a ring graph. Turing model considers two morphogens reacting and diffusing over the spatial domain and has been widely accepted as one of the most fundamental models to explain pattern formation in a developing embryo. It is of great importance to understand the mechanism behind the various reaction kinetics that generate such a wide range of patterns. As a first step towards this goal, in this paper we study controllability of Turing model for the case of cells connected as a square grid in which controls can be applied to the boundary cells. We first investigate the minimal control placement problem for the diffusion only system. The eigenvalues of the diffusion matrix are classified by their geometric multiplicity, and the properties of the corresponding eigenspaces are studied. The symmetric control sets are designed to categorize control candidates by symmetry of the network topology. Then the necessary and sufficient condition is provided for placing the minimal control to guarantee controllability for the diffusion system. Furthermore, we show that the necessary condition can be extended to Turing model by a natural expansion of the symmetric control sets. Under certain circumstances, we prove that it is also sufficient to ensure controllability of Turing model.},
  archive      = {J_SICON},
  author       = {Yuexin Cao and Yibei Li and Lirong Zheng and Xiaoming Hu},
  doi          = {10.1137/23M1616856},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1809-1831},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Minimal control placement of networked reaction-diffusion systems based on turing model},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonconservative stability criteria for semi-markovian
impulsive switched systems. <em>SICON</em>, <em>62</em>(3), 1783–1808.
(<a href="https://doi.org/10.1137/23M1564833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper proposes criteria for establishing the asymptotic moment stability of semi-Markovian impulsive switched systems. Under some mild assumptions, we formulate an auxiliary linear time-delayed system based on the Lyapunov characterizations of the subsystems and impulses, as well as the properties of the underlying semi-Markovian impulsive switching signal. Our main result provides an upper bound on the moment, which is directly related to a solution of the aforementioned linear time-delayed system. Specifically, the semi-Markovian impulsive switched system is asymptotically moment stable if the auxiliary linear time-delayed system is asymptotically stable. In situations where the mode-dependent sojourn time distributions of the underlying impulsive switching signals are all exponential, uniform, or trigonometric, we deduce explicit formulae for the auxiliary linear time-delayed systems. To prove the main result, we compute the expected gain function, which requires formulating a generalized renewal equation. Finally, we test our stability criteria on a numerical example in different scenarios and show that our stability results are nonconservative compared to the statistically obtained average of state-norms and state-norm-squares.},
  archive      = {J_SICON},
  author       = {Shenyu Liu and Penghui Wen},
  doi          = {10.1137/23M1564833},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1783-1808},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Nonconservative stability criteria for semi-markovian impulsive switched systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Flatness approach for the boundary controllability of a
system of heat equations. <em>SICON</em>, <em>62</em>(3), 1766–1782. (<a
href="https://doi.org/10.1137/23M1577833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the boundary controllability of system of heat equations by using a flatness approach. According to the relation between the diffusion coefficients of the heat equation, it is known that the system can be neither null-controllable nor null-controllable for any , where . Here we recover this result in the case that by using the flatness method, and we obtain an explicit formula for the control and for the corresponding solutions. In particular, the state and the control have Gevrey regularity in time and in space.},
  archive      = {J_SICON},
  author       = {Blaise Colle and Jérôme Lohéac and Takéo Takahashi},
  doi          = {10.1137/23M1577833},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1766-1782},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Flatness approach for the boundary controllability of a system of heat equations},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mean field games in a stackelberg problem with an informed
major player. <em>SICON</em>, <em>62</em>(3), 1737–1765. (<a
href="https://doi.org/10.1137/23M1615188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We investigate a stochastic differential game in which a major player has private information (the knowledge of a random variable), which she discloses through her control to a population of small players playing in a Nash mean field game equilibrium. The major player’s cost depends on the distribution of the population, while the cost of the population depends on the random variable known by the major player. We show that the game has a relaxed solution and that the optimal control of the major player is approximatively optimal in games with a large but finite number of small players.},
  archive      = {J_SICON},
  author       = {Philippe Bergault and Pierre Cardaliaguet and Catherine Rainer},
  doi          = {10.1137/23M1615188},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1737-1765},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Mean field games in a stackelberg problem with an informed major player},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global uniform finite-time output feedback stabilization for
disturbed nonlinear uncertain systems: Backstepping-like observer and
nonseparation principle design. <em>SICON</em>, <em>62</em>(3),
1717–1736. (<a href="https://doi.org/10.1137/22M1519365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates the problem of global uniform finite-time output feedback stabilization for a class of generalized disturbed high-order nonlinear uncertain systems. The presence of nonlinear uncertainties and unknown disturbances makes it challenging to design a state observer and an output feedback controller. To address this problem, a new technique of output feedback design is proposed. Firstly, based on a backstepping-like method, a finite-time extended state observer (FT-ESO) is constructed to estimate the unmeasured states and unknown disturbances of the system. Then, utilizing the nonseparation principle and disturbance-estimation–compensation method, a continuous output–based finite-time active anti-disturbance control (FT-AADC) method is developed by integrating the finite-time state feedback controller with the proposed FT-ESO. The global uniform finite-time stability of the entire observer-control system is proven using Lyapunov theory. Simulation results are provided to demonstrate the effectiveness of the proposed method.},
  archive      = {J_SICON},
  author       = {Wenwu Zhu and Haibo Du},
  doi          = {10.1137/22M1519365},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1717-1736},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Global uniform finite-time output feedback stabilization for disturbed nonlinear uncertain systems: Backstepping-like observer and nonseparation principle design},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Distributed global consensus of LTI mass with heterogeneous
actuator saturation and communication noises. <em>SICON</em>,
<em>62</em>(3), 1690–1716. (<a
href="https://doi.org/10.1137/23M1584678">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we focus on a general linear time-invariant multiagent system with heterogeneous actuator saturation to answer the main question: how to achieve global consensus under the premise of asymptotically null controllable with bounded controls of each agent so as to make breakthroughs from the perspectives of global consensus, heterogeneous actuator saturation, communication noises, and distributed characteristic preservation. We introduce a distributed control algorithm that incorporates a redesigned saturation function featuring a decentralized dynamic saturation level to achieve these objectives. Each component of the dynamic saturation level self-updates according to an adaptive strategy. The proposed method effectively eliminates heterogeneous actuator saturation by carefully selecting both the constant and time-varying saturation parameters in the adaptive strategy of the dynamic saturation level. Our approach achieves both state feedback–based and output feedback–based global consensus, with the latter utilizing a special coordinate decomposition. Numerical simulations demonstrate the efficacy of our method.},
  archive      = {J_SICON},
  author       = {Xiaoling Wang and Juan Qian and Housheng Su and Xiujuan Lu and James Lam},
  doi          = {10.1137/23M1584678},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1690-1716},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Distributed global consensus of LTI mass with heterogeneous actuator saturation and communication noises},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability and genericity of bang-bang controls in affine
problems. <em>SICON</em>, <em>62</em>(3), 1669–1689. (<a
href="https://doi.org/10.1137/23M1586446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We analyze the role of the bang-bang property in affine optimal control problems. We show that many essential stability properties of affine problems are only satisfied when minimizers are bang-bang. We employ Stegall’s variational principle to prove that almost any linear perturbation leads to a bang-bang strict global minimizer. Examples are given to show the applicability of our results to specific optimal control problems.},
  archive      = {J_SICON},
  author       = {Alberto Domínguez Corella and Gerd Wachsmuth},
  doi          = {10.1137/23M1586446},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1669-1689},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stability and genericity of bang-bang controls in affine problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The occupation kernel method for nonlinear system
identification. <em>SICON</em>, <em>62</em>(3), 1643–1668. (<a
href="https://doi.org/10.1137/19M127029X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This manuscript presents a novel approach to nonlinear system identification leveraging densely defined Liouville operators and a new “kernel” function that represents an integration functional over a reproducing kernel Hilbert space (RKHS) dubbed an occupation kernel. The manuscript thoroughly explores the concept of occupation kernels in the contexts of RKHSs of continuous functions and establishes Liouville operators over RKHS, where several dense domains are found for specific examples of this unbounded operator. The combination of these two concepts allows for the embedding of a dynamical system into an RKHS, where function-theoretic tools may be leveraged for the examination of such systems. This framework allows for trajectories of a nonlinear dynamical system to be treated as a fundamental unit of data for a nonlinear system identification routine. The approach to nonlinear system identification is demonstrated to identify parameters of a dynamical system accurately while also exhibiting a certain robustness to noise.},
  archive      = {J_SICON},
  author       = {Joel A. Rosenfeld and Benjamin P. Russo and Rushikesh Kamalapurkar and Taylor T. Johnson},
  doi          = {10.1137/19M127029X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1643-1668},
  shortjournal = {SIAM J. Control Optim.},
  title        = {The occupation kernel method for nonlinear system identification},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Mean viability theorems and second-order hamilton–jacobi
equations. <em>SICON</em>, <em>62</em>(3), 1615–1642. (<a
href="https://doi.org/10.1137/23M1550438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce the notion of mean viability for controlled stochastic differential equations and establish counterparts of Nagumo’s classical viability theorems (necessary and sufficient conditions for mean viability). As an application, we provide a purely probabilistic proof of a comparison principle and of existence for contingent and viscosity solutions of second-order fully nonlinear path-dependent Hamilton–Jacobi–Bellman equations. We do not use compactness and optimal stopping arguments, which are usually employed in the literature on viscosity solutions for second-order path-dependent PDEs.},
  archive      = {J_SICON},
  author       = {Christian Keller},
  doi          = {10.1137/23M1550438},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1615-1642},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Mean viability theorems and second-order Hamilton–Jacobi equations},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Randomized optimal stopping problem in continuous time and
reinforcement learning algorithm. <em>SICON</em>, <em>62</em>(3),
1590–1614. (<a href="https://doi.org/10.1137/22M1516725">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we study the optimal stopping problem in the so-called exploratory framework, in which the agent takes actions randomly conditioning on the current state and a regularization term is added to the reward functional. Such a transformation reduces the optimal stopping problem to a standard optimal control problem. For the American put option model, we derive the related HJB equation and prove its solvability. Furthermore, we give a convergence rate of policy iteration and compare our solution to the classical American put option problem. Our results indicate a trade-off between the convergence rate and bias in the choice of the temperature constant. Based on the theoretical analysis, a reinforcement learning algorithm is designed and numerical results are demonstrated for several models.},
  archive      = {J_SICON},
  author       = {Yuchao Dong},
  doi          = {10.1137/22M1516725},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1590-1614},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Randomized optimal stopping problem in continuous time and reinforcement learning algorithm},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Invariance principles for <span
class="math inline"><em>G</em></span>-brownian-motion-driven stochastic
differential equations and their applications to <span
class="math inline"><em>G</em></span>-stochastic control.
<em>SICON</em>, <em>62</em>(3), 1569–1589. (<a
href="https://doi.org/10.1137/23M1564936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The G-Brownian-motion-driven stochastic differential equations (G-SDEs) as well as the G-expectation, which were seminally proposed by Peng and his colleagues, have been extensively applied to describing a particular kind of uncertainty arising in real-world systems modeling. Mathematically depicting long-time and limit behaviors of the solution produced by G-SDEs is beneficial to understanding the mechanisms of system’s evolution. Here, we develop a new G-semimartingale convergence theorem and further establish a new invariance principle for investigating the long-time behaviors emergent in G-SDEs. We also validate the uniqueness and the global existence of the solution of G-SDEs whose vector fields are only locally Lipschitzian with a linear upper bound. To demonstrate the broad applicability of our analytically established results, we investigate its application to achieving G-stochastic control in a few representative dynamical systems.},
  archive      = {J_SICON},
  author       = {Xiaoxiao Peng and Shijie Zhou and Wei Lin and Xuerong Mao},
  doi          = {10.1137/23M1564936},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1569-1589},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Invariance principles for \(G\)-brownian-motion-driven stochastic differential equations and their applications to \(G\)-stochastic control},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shape optimization of hemolysis for shear thinning flows in
moving domains. <em>SICON</em>, <em>62</em>(3), 1546–1568. (<a
href="https://doi.org/10.1137/23M1595485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the three-dimensional problem of shape optimization of blood flows in moving domains. Such a geometry is adopted to take into account the modeling of rotating systems and blood pumps, for instance. The blood flow is described by generalized Navier–Stokes equations, in the particular case of shear-thinning flows. For a sequence of converging moving domains, we show that a sequence of associated solutions to blood equations converges to a solution of the problem written on the limit moving domain. Thus, we extended the result given in [J. Sokołowski and J. Stebel, Evol. Equ. Control Theory, 3 (2014), pp. 331–348] for , to the range , where is the exponent of the rheological law. This shape continuity property allows us to show the existence of minimal shapes for a class of functionals depending on the blood velocity field and its gradient. This allows one to consider in particular the problem of hemolysis minimization in blood flows, namely the minimization of red blood cells damage.},
  archive      = {J_SICON},
  author       = {Valentin Calisti and Šárka Nečasová},
  doi          = {10.1137/23M1595485},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1546-1568},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Shape optimization of hemolysis for shear thinning flows in moving domains},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Concentration in gossip opinion dynamics over random graphs.
<em>SICON</em>, <em>62</em>(3), 1521–1545. (<a
href="https://doi.org/10.1137/23M1545823">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study concentration inequalities in gossip opinion dynamics over random graphs. In the model, a network is generated from a random graph model with independent edges, and agents interact pairwise randomly over the network. During the process, regular agents average neighbors’ opinions and then update, whereas stubborn agents do not change opinions. To approximate the original process, we introduce a gossip model over an expected graph, obtained by averaging all possible networks generated from the random graph model. Using concentration inequalities, we derive high-probability bounds for the distance between the expected final opinion vectors over the random graph and over the expected graph. Leveraging matrix perturbation results, we show how such concentration can help study the effect of network structure on the expected final opinions in two cases: (i) When the influence of stubborn agents is large, the expected final opinions polarize and are close to stubborn agents’ opinions. (ii) When the influence of stubborn agents is small, the expected final opinions are close to each other. With the help of concentration inequalities for Markov chains, we obtain high-probability bounds for the distance between time-averaged opinions and the expected final opinions over the expected graph. In simulation, we validate the theoretical findings and study a gossip model over a stochastic block model that has community structure.},
  archive      = {J_SICON},
  author       = {Yu Xing and Karl H. Johansson},
  doi          = {10.1137/23M1545823},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1521-1545},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Concentration in gossip opinion dynamics over random graphs},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal control of stochastic delay differential equations
and applications to path-dependent financial and economic models.
<em>SICON</em>, <em>62</em>(3), 1490–1520. (<a
href="https://doi.org/10.1137/23M1553960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this manuscript we consider a class of optimal control problems of stochastic differential delay equations. First, we rewrite the problem in a suitable infinite-dimensional Hilbert space. Then, using the dynamic programming approach, we characterize the value function of the problem as the unique viscosity solution of the associated infinite-dimensional Hamilton-Jacobi-Bellman equation. Finally, we prove a -partial regularity of the value function. We apply these results to path dependent financial and economic problems (Merton-like portfolio problem and optimal advertising).},
  archive      = {J_SICON},
  author       = {Filippo De Feo and Salvatore Federico and Andrzej Święch},
  doi          = {10.1137/23M1553960},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1490-1520},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Optimal control of stochastic delay differential equations and applications to path-dependent financial and economic models},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The role of correlation in diffusion control ranking games.
<em>SICON</em>, <em>62</em>(3), 1465–1489. (<a
href="https://doi.org/10.1137/23M1574336">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies two-player stochastic differential games with diffusion control on finite time horizons. The players’ state processes are described in terms of controlled martingale problems, and we allow for correlation between the players’ states, described by some correlation coefficient. We consider zero-sum ranking games in the sense that the criterion to optimize only depends on the difference of the two players’ state processes at the finite time horizon. We explicitly compute saddle points of the game depending on the correlation coefficient. In particular, for correlation coefficients smaller than some explicit threshold, the game has a value and a saddle point (in strict controls). For correlation coefficients exceeding the threshold, we introduce the larger class of relaxed controls that can be interpreted as mixed strategies. We show that the game has a value and a saddle point in relaxed controls for all correlation coefficients.},
  archive      = {J_SICON},
  author       = {Stefan Ankirchner and Nabil Kazi-Tani and Julian Wendt},
  doi          = {10.1137/23M1574336},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1465-1489},
  shortjournal = {SIAM J. Control Optim.},
  title        = {The role of correlation in diffusion control ranking games},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nash equilibria for exchangeable team-against-team games,
their mean-field limit, and the role of common randomness.
<em>SICON</em>, <em>62</em>(3), 1437–1464. (<a
href="https://doi.org/10.1137/22M1534055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study stochastic exchangeable games among a finite number of teams consisting of a large but finite number of decision makers as well as their mean-field limit with infinite number of decision makers in each team. For this class of games within static and dynamic settings, we introduce sets of randomized policies under various decentralized information structures with privately independent or common randomness for decision makers within each team. (i) For a general class of exchangeable stochastic games with a finite number of decision makers, we first establish the existence of a Nash equilibrium under randomized policies (with common randomness) within each team that are exchangeable (but not necessarily symmetric, i.e., identical) among decision makers within each team. (ii) As the number of decision makers within each team goes to infinity (that is, for the mean-field limit game among teams), we show that a Nash equilibrium exists under randomized policies within each team that are independently randomized and symmetric among decision makers within each team (that is, there is no common randomness). (iii) Finally, we establish that a Nash equilibrium for a class of mean-field games among teams under independently randomized symmetric policies constitutes an approximate Nash equilibrium for the corresponding prelimit (exchangeable) game among teams with finite but large numbers of decision makers. (iv) We thus establish a rigorous connection between agent-based-modeling and team-against-team games, via the representative agents defining the game played in equilibrium, and we furthermore show that common randomness is not necessary for large team-against-team games, unlike the case with small-sized ones.},
  archive      = {J_SICON},
  author       = {Sina Sanjari and Naci Saldi and Serdar Yüksel},
  doi          = {10.1137/22M1534055},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1437-1464},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Nash equilibria for exchangeable team-against-team games, their mean-field limit, and the role of common randomness},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Feedback and open-loop nash equilibria for LQ
infinite-horizon discrete-time dynamic games. <em>SICON</em>,
<em>62</em>(3), 1417–1436. (<a
href="https://doi.org/10.1137/23M1579960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider dynamic games defined over an infinite horizon, characterized by linear, discrete-time dynamics and quadratic cost functionals. Considering such linear-quadratic dynamic games, we focus on their solutions in terms of Nash equilibrium strategies. Both feedback (F-NE) and open-loop (OL-NE) Nash equilibrium solutions are considered. The contributions of the paper are threefold. First, our detailed study reveals some interesting structural insights in relation to F-NE solutions. Second, as a stepping stone toward our consideration of OL-NE strategies, we consider a specific infinite-horizon discrete-time (single-player) optimal control problem, wherein the dynamics are influenced by a known exogenous input and draw connections between its solution obtained via dynamic programming and Pontryagin’s minimum principle. Finally, we exploit the latter result to provide a characterization of OL-NE strategies of the class of infinite-horizon dynamic games. The results and key observations made throughout the paper are illustrated via a numerical example.},
  archive      = {J_SICON},
  author       = {Andrea Monti and Benita Nortmann and Thulasi Mylvaganam and Mario Sassano},
  doi          = {10.1137/23M1579960},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1417-1436},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Feedback and open-loop nash equilibria for LQ infinite-horizon discrete-time dynamic games},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal moral-hazard-free reinsurance under extended
distortion premium principles. <em>SICON</em>, <em>62</em>(3),
1390–1416. (<a href="https://doi.org/10.1137/23M1556046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study an optimal reinsurance problem under a diffusion risk model for an insurer who aims to minimize the probability of lifetime ruin. To rule out moral hazard issues, we only consider moral-hazard-free reinsurance contracts by imposing the incentive compatibility constraint on indemnity functions. The reinsurance premium is calculated under an extended distortion premium principle, in which the distortion function is not necessarily concave or continuous. We first show that an optimal reinsurance contract always exists and then derive two sufficient and necessary conditions to characterize it. Due to the presence of the incentive compatibility constraint and the nonconcavity of the distortion, the optimal contract is obtained as a solution to a double obstacle problem. At last, we apply the general result to study four examples and obtain the optimal contract in (semi-)closed form.},
  archive      = {J_SICON},
  author       = {Zhuo Jin and Zuo Quan Xu and Bin Zou},
  doi          = {10.1137/23M1556046},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1390-1416},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Optimal moral-hazard-free reinsurance under extended distortion premium principles},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Input-to-state stability for bilinear feedback systems.
<em>SICON</em>, <em>62</em>(3), 1369–1389. (<a
href="https://doi.org/10.1137/23M155788X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Input-to-state stability estimates with respect to small initial conditions and input functions for infinite-dimensional systems with bilinear feedback are shown. We apply the obtained results to controlled versions of a viscous Burger equation with Dirichlet boundary conditions, a Schrödinger equation, a Navier–Stokes system, and a semilinear wave equation.},
  archive      = {J_SICON},
  author       = {René Hosfeld and Birgit Jacob and Felix L. Schwenninger and Marius Tucsnak},
  doi          = {10.1137/23M155788X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1369-1389},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Input-to-state stability for bilinear feedback systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Gauss–newton oriented greedy algorithms for the
reconstruction of operators in nonlinear dynamics. <em>SICON</em>,
<em>62</em>(3), 1343–1368. (<a
href="https://doi.org/10.1137/23M1552929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is devoted to the development and convergence analysis of greedy reconstruction algorithms based on the strategy presented in [Y. Maday and J. Salomon, Joint Proceedings of the 48th IEEE Conference on Decision and Control and the 28th Chinese Control Conference, 2009, pp. 375–379]. These procedures allow the design of a sequence of control functions that ease the identification of unknown operators in nonlinear dynamical systems. The original strategy of greedy reconstruction algorithms is based on an offline/online decomposition of the reconstruction process and an ansatz for the unknown operator obtained by an a priori chosen set of linearly independent matrices. In the previous work [S. Buchwald, G. Ciaramella, and J. Salomon, SIAM J. Control Optim., 59 (2021), pp. 4511–4537], convergence results were obtained in the case of linear identification problems. We tackle here the more general case of nonlinear systems. More precisely, we introduce a new greedy algorithm based on the linearized system. We show that the controls obtained with this new algorithm lead to the local convergence of the classical Gauss–Newton method applied to the online nonlinear identification problem. We then extend this result to the controls obtained on nonlinear systems where a local convergence result is also proved. The main convergence results are obtained for dynamical systems with linear and bilinear control structures.},
  archive      = {J_SICON},
  author       = {Simon Buchwald and Gabriele Ciaramella and Julien Salomon},
  doi          = {10.1137/23M1552929},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1343-1368},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Gauss–Newton oriented greedy algorithms for the reconstruction of operators in nonlinear dynamics},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive stabilization of noncooperative stochastic
differential games. <em>SICON</em>, <em>62</em>(3), 1317–1342. (<a
href="https://doi.org/10.1137/22M1530549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider the adaptive stabilization problem for a basic class of linear-quadratic noncooperative stochastic differential games when the systems matrices are unknown to the regulator and the players. This is a typical problem of game-based control systems (GBCS) introduced and studied recently, which have a hierarchical decision-making structure: there is a controller at the upper level acting as a global regulator which makes its decision first, and the players at the lower level are assumed to play a typical zero-sum differential games. The main purpose of the paper is to study how the adaptive regulator can be designed to make the GBCS globally stable and at the same time to ensure a Nash equilibrium reached by the players, where the adaptive strategies of the players are assumed to be constructed based on the standard least squares estimators. The design of the global regulator is an integration of the weighted least squares parameter estimator, random regularization and diminishing excitation methods. Under the assumption that the system matrix pair is controllable and there exists a stabilizing solution for the corresponding algebraic Riccati equation, it is shown that the closed-loop adaptive GBCS will be globally stable, and at the same time reach a Nash equilibrium by the players.},
  archive      = {J_SICON},
  author       = {Nian Liu and Lei Guo},
  doi          = {10.1137/22M1530549},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {6},
  number       = {3},
  pages        = {1317-1342},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Adaptive stabilization of noncooperative stochastic differential games},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal control of bistable traveling waves: Looking for the
best spatial distribution of a killing action to block a pest invasion.
<em>SICON</em>, <em>62</em>(2), 1291–1315. (<a
href="https://doi.org/10.1137/22M1528410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Some pests and vectors of many vector-borne diseases (like mosquitoes for malaria and dengue) are known to invade any homogeneous and favorable territory, following a traveling wave type dynamic. The density of individuals in the field is commonly modeled as the solution of a bistable reaction-diffusion equation on an unbounded domain. In this work, we are interested in finding an optimal strategy to block such a solution by means of a population elimination action in a prescribed subdomain (modeling, for instance, the effect of a mechanical action or an insecticide applied in a certain region to reduce the number of individuals in the population). We propose a complete description of the solutions of this problem, based on the precise analysis of the optimality conditions and on arguments for comparison between the possible strategies.},
  archive      = {J_SICON},
  author       = {Luis Almeida and Alexis Léculier and Grégoire Nadin and Yannick Privat},
  doi          = {10.1137/22M1528410},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1291-1315},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Optimal control of bistable traveling waves: Looking for the best spatial distribution of a killing action to block a pest invasion},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local time pushed mixed equilibrium strategies for
time-inconsistent stopping problems. <em>SICON</em>, <em>62</em>(2),
1261–1290. (<a href="https://doi.org/10.1137/22M1506651">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the game-theoretic approach to time-inconsistent stopping of a one-dimensional diffusion where the time-inconsistency is due to the presence of a nonexponential (weighted) discount function. In particular, we study (weak) equilibria for this problem in a novel class of mixed (i.e., randomized) stopping times based on a local time construction of the stopping intensity. For a general formulation of the problem we provide a verification theorem giving sufficient conditions for mixed (and pure) equilibria in terms of a set of variational inequalities, including a smooth fit condition. We apply the theory to prove the existence of (mixed) equilibria in a recently studied real options problem in which no pure equilibria exist.},
  archive      = {J_SICON},
  author       = {Andi Bodnariu and Sören Christensen and Kristoffer Lindensjö},
  doi          = {10.1137/22M1506651},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1261-1290},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Local time pushed mixed equilibrium strategies for time-inconsistent stopping problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A phase theory of multi-input multi-output linear
time-invariant systems. <em>SICON</em>, <em>62</em>(2), 1235–1260. (<a
href="https://doi.org/10.1137/22M148968X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we define the phase response for a class of multi-input multi-output (MIMO) linear time-invariant (LTI) systems whose frequency responses are (semi-)sectorial at all frequencies. The newly defined phase subsumes the well-known notion of positive real systems and is closely related to the notion of negative imaginary systems. We formulate a small phase theorem for feedback stability, which complements the small gain theorem. The small phase theorem lays the foundation of a phase theory of MIMO systems. We also discuss time-domain interpretations of phase-bounded systems via both energy signal analysis and power signal analysis.},
  archive      = {J_SICON},
  author       = {Wei Chen and Dan Wang and Sei Zhen Khong and Li Qiu},
  doi          = {10.1137/22M148968X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1235-1260},
  shortjournal = {SIAM J. Control Optim.},
  title        = {A phase theory of multi-input multi-output linear time-invariant systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reversible investment problem with capacity and demand in
finite horizon: Free boundary analysis. <em>SICON</em>, <em>62</em>(2),
1207–1234. (<a href="https://doi.org/10.1137/22M1469547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates a reversible investment problem with finite horizon, in which a social planner aims to determine the project’s capacity level to minimize the expected total costs. These costs depend on the demand for the good, the supply in terms of production capacity, and the proportional costs. The issue of irreversible investment has been examined by Han and Yi [Commun. Nonlinear Sci. Numer. Simul., 109 (2022), 106302]. Mathematically, the reversible investment problem can be formulated as a singular stochastic control problem. The value function satisfies a two-dimensional parabolic variational inequality subject to gradient constraint, which leads to two time-dependent free boundaries representing optimal investment and disinvestment strategies. We employ a partial differential equation approach to characterize the continuity, monotonicity, and horizontal asymptotes of free boundaries, as well as establish the regularity of the value function. To the best of our knowledge, the approach to analyze the behavior of free boundaries is novel in the literature.},
  archive      = {J_SICON},
  author       = {Xiaoru Han and Fahuai Yi and Jianbo Zhang},
  doi          = {10.1137/22M1469547},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1207-1234},
  shortjournal = {SIAM J. Control Optim.},
  title        = {A reversible investment problem with capacity and demand in finite horizon: Free boundary analysis},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dynamic programming in probability spaces via optimal
transport. <em>SICON</em>, <em>62</em>(2), 1183–1206. (<a
href="https://doi.org/10.1137/23M1560902">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study discrete-time finite-horizon optimal control problems in probability spaces, whereby the state of the system is a probability measure. We show that, in many instances, the solution of dynamic programming in probability spaces results from two ingredients: (i) the solution of dynamic programming in the “ground space” (i.e., the space on which the probability measures live) and (ii) the solution of an optimal transport problem. From a multi-agent control perspective, a separation principle holds: “low-level control of the agents of the fleet” (how does one reach the destination?) and “fleet-level control” (who goes where?) are decoupled.},
  archive      = {J_SICON},
  author       = {Antonio Terpin and Nicolas Lanzetti and Florian Dörfler},
  doi          = {10.1137/23M1560902},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1183-1206},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Dynamic programming in probability spaces via optimal transport},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exponential stability for a class of discrete-time switched
systems and its applications to multiagent systems. <em>SICON</em>,
<em>62</em>(2), 1165–1182. (<a
href="https://doi.org/10.1137/23M1546762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies the exponential stabilization problem for a class of discrete-time linear switched systems arising from establishing the output-based distributed observer and the output-based adaptive distributed observer for discrete-time linear leader systems over jointly connected switching networks. The existing results on distributed observers and adaptive distributed observers are state-based in the sense that they need to make use of the full state of the leader system, which is quite restrictive since, in many applications, only the output of the leader system is available. As an application, the output-based distributed observer is used to solve a leader-following consensus problem for discrete-time linear multiagent systems by distributed output feedback control.},
  archive      = {J_SICON},
  author       = {Tao Liu and Jie Huang},
  doi          = {10.1137/23M1546762},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1165-1182},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Exponential stability for a class of discrete-time switched systems and its applications to multiagent systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Markov chain approximation for hamilton–jacobi–bellman
equation with absorbing boundary. <em>SICON</em>, <em>62</em>(2),
1152–1164. (<a href="https://doi.org/10.1137/23M1565723">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the infinite horizon optimal control problems of the controlled Markov process. We verify the relationship between the controlled Markov process and its fluid limit by the viscosity solution approach. More precisely, we show that the value function of the controlled Markov process converges to one of its limit processes which is the viscosity solution of the associated Hamilton–Jacobi–Bellman equation.},
  archive      = {J_SICON},
  author       = {Itsuki Watanabe},
  doi          = {10.1137/23M1565723},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1152-1164},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Markov chain approximation for Hamilton–Jacobi–Bellman equation with absorbing boundary},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global output-feedback control by exploiting high-gain
dynamic-compensation mechanisms. <em>SICON</em>, <em>62</em>(2),
1122–1151. (<a href="https://doi.org/10.1137/22M1536303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Currently, output-feedback control still necessitates severe constraints on systems, e.g., system nonlinearities cannot exceed certain degree and uncertainties should belong to specific types. In this paper, by exploiting dynamic-compensation mechanisms, we essentially extend system nonlinearities and uncertainties. Specifically, the nonlinearities heavily rely on unmeasured states and particularly have unknown arbitrary function-of-output growth rates. Unknown control coefficients whether with known or unknown bounds are admitted, which have been excluded before in the context of such inclusive nonlinearities. The key to our novel solution lies in realizing the potential of filter-based observers, dynamic high gains, design/analysis parameter designation, and composite Lyapunov functions. In detail, two dynamic-high-gain filters are worked out to provide available states for controller design. The filter states, after weighted by the unknown control coefficient, also make up the estimated states which lead to control-free and tractable error dynamics. Two dynamic high gains with new dynamics are put forward to counteract the nonlinearities and uncertainties and, meanwhile, to enable the adaptive controller to own a concise structure. During the controller design, crucial design parameters can no longer be expressed explicitly due to unknown control coefficients, but rather need to be pursued through a recursive algorithm. With a set of analysis parameters, important (dynamic-high-gain) input-to-state stable properties of some vital variables are uncovered, and exhaustive Lyapunov analysis is performed for the closed-loop boundedness and convergence.},
  archive      = {J_SICON},
  author       = {Yuan Wang and Yungang Liu},
  doi          = {10.1137/22M1536303},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1122-1151},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Global output-feedback control by exploiting high-gain dynamic-compensation mechanisms},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus-based optimization for saddle point problems.
<em>SICON</em>, <em>62</em>(2), 1093–1121. (<a
href="https://doi.org/10.1137/22M1543367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose consensus-based optimization for saddle point problems (CBO-SP), a novel multi-particle metaheuristic derivative-free optimization method capable of provably finding global Nash equilibria. Following the idea of swarm intelligence, the method employs two groups of interacting particles, one which performs a minimization over one variable while the other performs a maximization over the other variable. The two groups constantly exchange information through a suitably weighted average. This paradigm permits a passage to the mean-field limit, which makes the method amenable to theoretical analysis, and it allows to obtain rigorous convergence guarantees under reasonable assumptions about the initialization and the objective function, which most notably include nonconvex-nonconcave objectives. We further provide numerical evidence for the success of the algorithm.},
  archive      = {J_SICON},
  author       = {Hui Huang and Jinniao Qiu and Konstantin Riedl},
  doi          = {10.1137/22M1543367},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1093-1121},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Consensus-based optimization for saddle point problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Convergence of policy gradient methods for finite-horizon
exploratory linear-quadratic control problems. <em>SICON</em>,
<em>62</em>(2), 1060–1092. (<a
href="https://doi.org/10.1137/22M1533517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the global linear convergence of policy gradient (PG) methods for finite-horizon continuous-time exploratory linear-quadratic control (LQC) problems. The setting includes stochastic LQC problems with indefinite costs and allows additional entropy regularizers in the objective. We consider a continuous-time Gaussian policy whose mean is linear in the state variable and whose covariance is state-independent. Contrary to discrete-time problems, the cost is noncoercive in the policy and not all descent directions lead to bounded iterates. We propose geometry-aware gradient descents for the mean and covariance of the policy using the Fisher geometry and the Bures–Wasserstein geometry, respectively. The policy iterates are shown to satisfy an a priori bound, and converge globally to the optimal policy with a linear rate. We further propose a novel PG method with discrete-time policies. The algorithm leverages the continuous-time analysis, and achieves a robust linear convergence across different action frequencies. A numerical experiment confirms the convergence and robustness of the proposed algorithm.},
  archive      = {J_SICON},
  author       = {Michael Giegrich and Christoph Reisinger and Yufei Zhang},
  doi          = {10.1137/22M1533517},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1060-1092},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Convergence of policy gradient methods for finite-horizon exploratory linear-quadratic control problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Control of a linearized viscous liquid–tank system with
surface tension. <em>SICON</em>, <em>62</em>(2), 1034–1059. (<a
href="https://doi.org/10.1137/23M158749X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies the linearization of the viscous tank–liquid system. The linearization of the tank–liquid system gives a high-order partial differential equation, which is a combination of a wave equation with Kelvin–Voigt damping and a Euler–Bernoulli beam equation. The single input appears in two of the boundary conditions (boundary input). The paper provides results both for the open-loop system (existence/uniqueness of solutions and stability properties of the open-loop system) as well as results for the construction of feedback stabilizers. More specifically, the feedback design methodology is based on control Lyapunov functionals (CLFs). The proposed CLFs are modifications and augmentations of the total energy functionals for the tank–liquid system so that the dissipative effects of viscosity, friction, and surface tension are captured. By focusing on the linearized water–tank system, we are able to provide results that are not provided in the nonlinear case: (1) existence and uniqueness of solutions, (2) simultaneous presence of friction and surface tension, and (3) stabilization in a stronger norm, using a different CLF.},
  archive      = {J_SICON},
  author       = {Iasson Karafyllis and Miroslav Krstic},
  doi          = {10.1137/23M158749X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1034-1059},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Control of a linearized viscous Liquid–Tank system with surface tension},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stabilization of continuous-time probabilistic logical
networks under sampling dwell time constraints. <em>SICON</em>,
<em>62</em>(2), 1006–1033. (<a
href="https://doi.org/10.1137/23M1566388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper investigates the sampled-data stabilization of continuous-time probabilistic logical control networks (CT-PLCNs). CT-PLCNs can provide quantitative and accurate descriptions for the transient kinetics in comparing discrete-time probabilistic logical control networks (DT-PLCNs). First, CT-PLCNs are transformed into switched continuous-time probabilistic logical networks by regarding the control input as a switching signal. In this setup, CT-PLCNs can be classified into two types: one with stable modes and the other with only unstable modes. Then the concept of average -sample dwell time is proposed to describe the scenario, where the dwell time of each mode is an integral multiple of the sampling period . Based on this, the stabilization conditions for CT-PLCNs are established by restricting the sampling dwell time of controller modes. Furthermore, a copositive Lyapunov function is constructed for the case with stable modes and is discretized for the case without stable modes, providing a new framework for studying the stabilization of CT-PLCNs. Finally, a chemical model generated by GINsim is provided to demonstrate the feasibility of the obtained theoretical results. Overall, this paper provides new insights into the stabilization of CT-PLCNs and presents practical applications for chemical models.},
  archive      = {J_SICON},
  author       = {Lin Lin and James Lam and Min Meng and Xiaochen Xie and Panshuo Li and Daotong Zhang and Peng Shi},
  doi          = {10.1137/23M1566388},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {1006-1033},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stabilization of continuous-time probabilistic logical networks under sampling dwell time constraints},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Minimal kullback–leibler divergence for constrained lévy–itô
processes. <em>SICON</em>, <em>62</em>(2), 982–1005. (<a
href="https://doi.org/10.1137/23M1555697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Given an -dimensional stochastic process driven by -Brownian motions and Poisson random measures, we search for a probability measure , with minimal relative entropy to , such that the -expectations of some terminal and running costs are constrained. We prove existence and uniqueness of the optimal probability measure, derive the explicit form of the measure change, and characterize the optimal drift and compensator adjustments under the optimal measure. We provide an analytical solution for Value-at-Risk (quantile) constraints, discuss how to perturb a Brownian motion to have arbitrary variance, and show that pinned measures arise as a limiting case of optimal measures. The results are illustrated in a risk management setting—including an algorithm to simulate under the optimal measure—and explore an example where an agent seeks to answer the question what dynamics are induced by a perturbation of the Value-at-Risk and the average time spent below a barrier on the reference process?},
  archive      = {J_SICON},
  author       = {Sebastian Jaimungal and Silvana M. Pesenti and Leandro Sánchez-Betancourt},
  doi          = {10.1137/23M1555697},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {982-1005},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Minimal Kullback–Leibler divergence for constrained Lévy–Itô processes},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Stochastic maximum principle for subdiffusions and its
applications. <em>SICON</em>, <em>62</em>(2), 953–981. (<a
href="https://doi.org/10.1137/23M157168X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we study optimal stochastic control problems for stochastic systems driven by non-Markov subdiffusion , which have mixed features of deterministic and stochastic controls. Here is the standard Brownian motion on , and is the inverse of a subordinator with drift that is independent of . We obtain stochastic maximum principles (SMPs) for these systems using both convex and spiking variational methods, depending on whether or not the domain is convex. To derive SMPs, we first establish a martingale representation theorem for subdiffusions , and then use it to derive the existence and uniqueness result for the solutions of backward stochastic differential equations (BSDEs) driven by subdiffusions, which may be of independent interest. We also derive sufficient SMPs. Application to a linear quadratic system is given to illustrate the main results of this paper.},
  archive      = {J_SICON},
  author       = {Shuaiqi Zhang and Zhen-Qing Chen},
  doi          = {10.1137/23M157168X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {953-981},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stochastic maximum principle for subdiffusions and its applications},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability analysis for nonlinear neutral stochastic
functional differential equations. <em>SICON</em>, <em>62</em>(2),
924–952. (<a href="https://doi.org/10.1137/22M1523066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper provides some sufficient conditions for the existence and uniqueness and the stochastic stability of the global solution for nonlinear neutral stochastic functional differential equations. When the drift term and the diffusion term satisfy a locally Lipschitz condition, and the Lyapunov monotonicity condition has a sign-changed time-varying coefficient, the existence and uniqueness of the global solution for such equations will be studied by using the Lyapunov–Krasovskii function approach and the theory of stochastic analysis. The stability in th-moment, the asymptotical stability in th-moment, and the exponential stability in th-moment will be investigated. Different characterizations for these three kinds of stochastic stability in moment will be established, which are presented with respect to integration conditions. These results have seldom been reported in the existing literature. The almost surely exponential stability for the global solution of such equations is also discussed. Some discussions and comparisons are provided. Two examples are given to check the effectiveness of the theoretical results obtained.},
  archive      = {J_SICON},
  author       = {Huabin Chen and Chenggui Yuan},
  doi          = {10.1137/22M1523066},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {924-952},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stability analysis for nonlinear neutral stochastic functional differential equations},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Viscosity solutions for McKean–vlasov control on a torus.
<em>SICON</em>, <em>62</em>(2), 903–923. (<a
href="https://doi.org/10.1137/22M1543732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. An optimal control problem in the space of probability measures and the viscosity solutions of the corresponding dynamic programming equations defined using the intrinsic linear derivative are studied. The value function is shown to be Lipschitz continuous with respect to a smooth Fourier–Wasserstein metric. A comparison result between the Lipschitz viscosity sub- and supersolutions of the dynamic programming equation is proved using this metric, characterizing the value function as the unique Lipschitz viscosity solution.},
  archive      = {J_SICON},
  author       = {H. Mete Soner and Qinxin Yan},
  doi          = {10.1137/22M1543732},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {903-923},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Viscosity solutions for McKean–Vlasov control on a torus},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Verification methods for the lyapunov–krasovskii functional
inequalities. <em>SICON</em>, <em>62</em>(2), 877–902. (<a
href="https://doi.org/10.1137/22M1542167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study parameterizations of Lyapunov–Krasovskii functionals (LKFs) to analyze the stability of linear time-delay systems. We discuss the solution to the delay Lyapunov matrix, which constructs an LKF associated with a prescribed time derivative, and relate it to the approaches commonly used in the numerical computation of LKFs. We then compare two approaches for the stability analysis of time-delay systems based on semidefinite programming, namely the method based on integral inequalities and the method based on sum-of-squares programming, which have recently emerged as optimization-based methods to compute LKFs. We discuss their main assumptions and establish connections between both methods. Finally, we formulate a projection-based method allowing us to use general sets of functions to parameterize LKFs, thus encompassing the sets of polynomial functions in the literature. The solutions of the proposed stability conditions and the construction of the corresponding LKFs as stability certificates are illustrated with numerical examples.},
  archive      = {J_SICON},
  author       = {Ali Diab and Giorgio Valmorbida and William Pasillas-Lépine},
  doi          = {10.1137/22M1542167},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {877-902},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Verification methods for the Lyapunov–Krasovskii functional inequalities},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Long-run impulse control with generalized discounting.
<em>SICON</em>, <em>62</em>(2), 853–876. (<a
href="https://doi.org/10.1137/23M1582539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we investigate the effects of applying generalized (nonexponential) discounting on a long-run impulse control problem for a Feller–Markov process. We show that the optimal value of the discounted problem is the same as the optimal value of its undiscounted version. Next, we prove that an optimal strategy for the undiscounted discrete-time functional is also optimal for the discrete-time discounted criterion and nearly optimal for the continuous-time discounted one. This shows that the discounted problem, being time-inconsistent in nature, admits a time-consistent solution. Also, instead of a complex time-dependent Bellman equation, one may consider its simpler time-independent version.},
  archive      = {J_SICON},
  author       = {Damian Jelito and Łukasz Stettner},
  doi          = {10.1137/23M1582539},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {853-876},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Long-run impulse control with generalized discounting},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On global approximate controllability of a quantum particle
in a box by moving walls. <em>SICON</em>, <em>62</em>(2), 826–852. (<a
href="https://doi.org/10.1137/22M1518980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study a system composed of a free quantum particle trapped in a box whose walls can change their position. We prove the global approximate controllability of the system: any initial pure state can be driven arbitrarily close to any target pure state in the Hilbert space of the free particle with a predetermined final position of the box. To this purpose we consider weak solutions of the Schrödinger equation and use a stability theorem for the time-dependent Schrödinger equation.},
  archive      = {J_SICON},
  author       = {Aitor Balmaseda and Davide Lonigro and Juan Manuel Pérez-Pardo},
  doi          = {10.1137/22M1518980},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {826-852},
  shortjournal = {SIAM J. Control Optim.},
  title        = {On global approximate controllability of a quantum particle in a box by moving walls},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning stationary nash equilibrium policies in <span
class="math inline"><em>n</em></span>-player stochastic games with
independent chains. <em>SICON</em>, <em>62</em>(2), 799–825. (<a
href="https://doi.org/10.1137/22M1512880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a subclass of -player stochastic games, in which players have their own internal state/action spaces while they are coupled through their payoff functions. It is assumed that players’ internal chains are driven by independent transition probabilities. Moreover, players can receive only realizations of their payoffs, not the actual functions, and cannot observe each others’ states/actions. For this class of games, we first show that finding a stationary Nash equilibrium (NE) policy without any assumption on the reward functions is intractable. However, for general reward functions, we develop polynomial-time learning algorithms based on dual averaging and dual mirror descent, which converge in terms of the averaged Nikaido–Isoda distance to the set of -NE policies almost surely or in expectation. In particular, under extra assumptions on the reward functions such as social concavity, we derive polynomial upper bounds on the number of iterates to achieve an -NE policy with high probability. Finally, we evaluate the effectiveness of the proposed algorithms in learning -NE policies using numerical experiments for energy management in smart grids.},
  archive      = {J_SICON},
  author       = {S. Rasoul Etesami},
  doi          = {10.1137/22M1512880},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {4},
  number       = {2},
  pages        = {799-825},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Learning stationary nash equilibrium policies in \(n\)-player stochastic games with independent chains},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spectral factorization of rank-deficient rational densities.
<em>SICON</em>, <em>62</em>(1), 776–798. (<a
href="https://doi.org/10.1137/23M1546622">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Though there are hundreds of papers on rational spectral factorization, most of them are concerned with full-rank spectral densities. In this paper we propose a novel approach for spectral factorization of a rank-deficient spectral density, leading to a minimum-phase full-rank spectral factor, in both the discrete-time and continuous-time cases. Compared with several approaches to low-rank spectral factorization, our approach exploits a deterministic relation inside the factor, leading to high computational efficiency. In addition, we show that this method is easily used in identification of low-rank processes and in Wiener filtering.},
  archive      = {J_SICON},
  author       = {Wenqi Cao and Anders Lindquist},
  doi          = {10.1137/23M1546622},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {776-798},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Spectral factorization of rank-deficient rational densities},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Turnpike properties for mean-field linear-quadratic optimal
control problems. <em>SICON</em>, <em>62</em>(1), 752–775. (<a
href="https://doi.org/10.1137/22M1524187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is concerned with an optimal control problem for a mean-field linear stochastic differential equation with a quadratic functional in the infinite time horizon. Under suitable conditions, including the stabilizability, the (strong) exponential, integral, and mean-square turnpike properties for the optimal pair are established. The keys are to correctly formulate the corresponding static optimization problem and find the equations determining the correction processes. These have revealed the main feature of the stochastic problems which are significantly different from the deterministic version of the theory.},
  archive      = {J_SICON},
  author       = {Jingrui Sun and Jiongmin Yong},
  doi          = {10.1137/22M1524187},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {752-775},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Turnpike properties for mean-field linear-quadratic optimal control problems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leader-following rendezvous control for generalized
cucker-smale model on riemannian manifolds. <em>SICON</em>,
<em>62</em>(1), 724–751. (<a
href="https://doi.org/10.1137/23M1545811">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies a leader-following rendezvous problem for the generalized Cucker–Smale model, a double-integrator multiagent system, on some Riemannian manifolds. By using intrinsic properties of the covariant derivative, logarithmic map, and parallel transport on the Riemannian manifolds, we design a feedback control law and prove that this feedback control law enables all followers to track the trajectory of the moving leader when the Riemannian manifold is compact or flat. As concrete examples, we consider the leader-following rendezvous problem on the unit sphere, in Euclidean space, on the unit circle, and infinite cylinder and present the corresponding feedback control laws. Meanwhile, numerical examples are given for the aforementioned Riemannian manifolds to illustrate and verify the theoretical results.},
  archive      = {J_SICON},
  author       = {Xiaoyu Li and Yuhu Wu and Lining Ru},
  doi          = {10.1137/23M1545811},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {724-751},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Leader-following rendezvous control for generalized cucker-smale model on riemannian manifolds},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the modeling of impulse control with random effects for
continuous markov processes. <em>SICON</em>, <em>62</em>(1), 699–723.
(<a href="https://doi.org/10.1137/19M1286967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The use of coordinate processes for the modeling of impulse control for general Markov processes typically involves the construction of a probability measure on a countable product of copies of the path space. In addition, admissibility of an impulse control policy requires that the random times of the interventions be stopping times with respect to different filtrations arising from the different component coordinate processes. When the underlying Markov process has continuous paths, however, a simpler model can be developed which takes the single path space as its probability space and uses the natural filtration with respect to which the intervention times must be stopping times. Moreover, this model construction allows for impulse control with random effects whereby the decision maker selects a distribution of the new state. This paper gives the construction of the probability measure on the path space for an admissible intervention policy subject to a randomized impulse mechanism. In addition, a class of polices is defined for which the paths between interventions are independent and a further subclass for which the cycles following the initial cycle are identically distributed. A benefit of this smaller subclass of policies is that one is allowed to use classical renewal arguments to analyze long-term average control problems. Further, the paper defines a class of stationary impulse policies for which the family of models gives a Markov family. The decision to use an ordering policy in inventory management provides an example of an impulse policy for which the process has independent and identically distributed cycles and the family of models forms a Markov family.},
  archive      = {J_SICON},
  author       = {Kurt L. Helmes and Richard H. Stockbridge and Chao Zhu},
  doi          = {10.1137/19M1286967},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {699-723},
  shortjournal = {SIAM J. Control Optim.},
  title        = {On the modeling of impulse control with random effects for continuous markov processes},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal control duality and the douglas–rachford algorithm.
<em>SICON</em>, <em>62</em>(1), 680–698. (<a
href="https://doi.org/10.1137/23M1558549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We explore the relationship between the dual of a weighted minimum-energy control problem, a special case of linear-quadratic optimal control problems, and the Douglas–Rachford (DR) algorithm. We obtain an expression for the fixed point of the DR operator as applied to solving the optimal control problem, which in turn devises a certificate of optimality that can be employed for numerical verification. The fixed point and the optimality check are illustrated in two example optimal control problems.},
  archive      = {J_SICON},
  author       = {Regina S. Burachik and Bethany I. Caldwell and C. Yalçin Kaya and Walaa M. Moursi},
  doi          = {10.1137/23M1558549},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {680-698},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Optimal control duality and the Douglas–Rachford algorithm},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Primal-dual regression approach for markov decision
processes with general state and action spaces. <em>SICON</em>,
<em>62</em>(1), 650–679. (<a
href="https://doi.org/10.1137/22M1526010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a regression-based primal-dual martingale approach for solving discrete time, finite-horizon MDPs. The state and action spaces may be finite or infinite (but regular enough) subsets of Euclidean space. Consequently, our method allows for the construction of tight upper and lower-biased approximations of the value functions, providing precise estimates of the optimal policy. Importantly, we prove error bounds for the estimated duality gap featuring polynomial dependence on the time horizon. Additionally, we observe sublinear dependence of the stochastic part of the error on the cardinality/dimension of the state and action spaces. From a computational perspective, our proposed method is efficient. Unlike typical duality-based methods for optimal control problems in the literature, the Monte Carlo procedures involved here do not require nested simulations.},
  archive      = {J_SICON},
  author       = {Denis Belomestny and John Schoenmakers},
  doi          = {10.1137/22M1526010},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {650-679},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Primal-dual regression approach for markov decision processes with general state and action spaces},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A stability result for a degenerate beam equation.
<em>SICON</em>, <em>62</em>(1), 630–649. (<a
href="https://doi.org/10.1137/23M1565668">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a beam equation in presence of a leading degenerate operator which is not in divergence form. We impose clamped conditions where the degeneracy occurs and dissipative conditions at the other endpoint. We provide some conditions for the uniform exponential decay of solutions for the associated problem. (This article has been updated.)},
  archive      = {J_SICON},
  author       = {Alessandro Camasta and Genni Fragnelli},
  doi          = {10.1137/23M1565668},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {630-649},
  shortjournal = {SIAM J. Control Optim.},
  title        = {A stability result for a degenerate beam equation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal control and signaling strategies of control-coding
capacity of general decision models: Applications to gaussian models and
decentralized strategies. <em>SICON</em>, <em>62</em>(1), 600–629. (<a
href="https://doi.org/10.1137/22M1518700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We investigate the control-coding (CC) capacity of general dynamical decision models (DMs) that involve nonlinear filtering, which is absent in the specific DMs investigated in [C. K. Kourtellaris and C. D. Charalambous, IEEE Trans. Inform. Theory, 64 (2018), pp. 4962–4992]. We derive characterizations of CC capacity and we show their equivalence to extremum problems of maximizing the information theoretic measure of directed information from the input process to the output process of the DM over randomized strategies. Due to the generality of the DMs, the CC capacity is shown to be equivalent to partially observable Markov decision problems, contrary to the DMs in the above mentioned paper, which give rise to fully observable Markov decision problems. Subsequently, the CC capacity is transformed, using nonlinear filtering theory, to fully observable Markov decision problems. For the application example of a Gaussian DM with past dependence on inputs and outputs, we prove a decentralized separation principle that states optimal inputs are Gaussian and consist of (i) a control, (ii) an estimation, and (iii) an information transmission part, which interact in a specific order. The optimal control and estimation parts are related to linear-quadratic Gaussian stochastic optimal control problems with partial information. Various degenerated cases are discussed, including examples from the above mentioned paper, which do not involve estimation.},
  archive      = {J_SICON},
  author       = {Charalambos D. Charalambous and Christos K. Kourtellaris and Ioannis Tzortzis},
  doi          = {10.1137/22M1518700},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {600-629},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Optimal control and signaling strategies of control-coding capacity of general decision models: Applications to gaussian models and decentralized strategies},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability of abstract interconnected systems with a possibly
unstable component. <em>SICON</em>, <em>62</em>(1), 581–599. (<a
href="https://doi.org/10.1137/23M1572350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider an interconnection of a one-dimensional ODE and an infinite dimensional abstract differential equation in view of the asymptotic stability. Sufficient stability conditions are obtained under the assumption that the whole system is positive with respect to the Minkowski cone. The decoupled ODE subsystem is not required to be stable. We illustrate our results by means of examples demonstrating the advantages of the developed approach over the existing results. As well we compare our results with the known small-gain theory.},
  archive      = {J_SICON},
  author       = {Ivan Atamas and Sergey Dashkovskiy and Vitalii Slynko},
  doi          = {10.1137/23M1572350},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {581-599},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stability of abstract interconnected systems with a possibly unstable component},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact controllability for a refined stochastic wave
equation. <em>SICON</em>, <em>62</em>(1), 563–580. (<a
href="https://doi.org/10.1137/22M1537680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we obtain the exact controllability for a refined stochastic wave equation with three controls by establishing a novel Carleman estimate for a backward hyperbolic-like operator. Compared with the known result [Q. Lü and X Zhang, Mathematical Control Theory for Stochastic Partial Differential Equations, Springer, Cham, Switzerland, 2021], the novelty of this paper is twofold: (1) Our model contains the effects in the drift terms when we put controls directly in the diffusion terms, which is more sensible for practical applications; (2) We provide an explicit description of the waiting time which is sharp in the case of dimension one and is independent of the coefficents of lower terms.},
  archive      = {J_SICON},
  author       = {Zhonghua Liao and Qi Lü},
  doi          = {10.1137/22M1537680},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {563-580},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Exact controllability for a refined stochastic wave equation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact controllability and stabilization for linear
dispersive PDE’s on the two-dimensional torus. <em>SICON</em>,
<em>62</em>(1), 539–562. (<a
href="https://doi.org/10.1137/22M1529361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The moment method is used to prove the exact controllability of a wide class of bidimensional linear dispersive PDE’s posed on the two-dimensional torus . The control function is considered to be acting on a small vertical and horizontal strip of the torus. Our results apply to several well-known models including some bidimesional extensions of the Benajamin–Ono and Korteweg–de Vries equations. As a by product, the exponential stabilizability with any given decay rate is also established in the Sobolev space , with , by constructing an appropriated feedback control law.},
  archive      = {J_SICON},
  author       = {Francisco J. Vielma-Leal and Ademir Pastor},
  doi          = {10.1137/22M1529361},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {539-562},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Exact controllability and stabilization for linear dispersive PDE’s on the two-dimensional torus},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The global maximum principle for optimal control of
partially observed stochastic systems driven by fractional brownian
motion. <em>SICON</em>, <em>62</em>(1), 509–538. (<a
href="https://doi.org/10.1137/22M1543203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we study the stochastic control problem of a partially observed (multidimensional) stochastic system driven by both Brownian motions and fractional Brownian motions. In the absence of the powerful tool of Girsanov transformation, we introduce and study new stochastic processes which are used to transform the original problem to a “classical one”. The adjoint backward stochastic differential equations and the necessary condition satisfied by the optimal control (maximum principle) are obtained.},
  archive      = {J_SICON},
  author       = {Yueyang Zheng and Yaozhong Hu},
  doi          = {10.1137/22M1543203},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {509-538},
  shortjournal = {SIAM J. Control Optim.},
  title        = {The global maximum principle for optimal control of partially observed stochastic systems driven by fractional brownian motion},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The nonlocal kelvin principle and the dual approach to
nonlocal control in the conduction coefficients. <em>SICON</em>,
<em>62</em>(1), 487–508. (<a
href="https://doi.org/10.1137/22M1522127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We explore the dual approach to nonlocal optimal control in the coefficients, specifically for a classical min-max problem which in this study is associated with a nonlocal scalar diffusion equation. We reformulate the optimal control problem utilizing a dual variational principle, which is expressed in terms of nonlocal two-point fluxes. We introduce the proper functional space framework to deal with this formulation and establish its well-posedness. The key ingredient is the inf-sup (Ladyzhenskaya–Babuška–Brezzi) condition, which holds uniformly with respect to small nonlocal horizons. As a by-product of this fact, we are able to prove convergence of nonlocal optimal control problems toward their local counterparts in a straightforward fashion.},
  archive      = {J_SICON},
  author       = {Anton Evgrafov and José C. Bellido},
  doi          = {10.1137/22M1522127},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {487-508},
  shortjournal = {SIAM J. Control Optim.},
  title        = {The nonlocal kelvin principle and the dual approach to nonlocal control in the conduction coefficients},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Admissibility and observability of jeffreys type of
overdamped second order linear systems. <em>SICON</em>, <em>62</em>(1),
466–486. (<a href="https://doi.org/10.1137/22M1511680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study Jeffreys-type overdamped second order linear systems with observed outputs in the setting of Hilbert spaces. The state equation comes from an overdamped second order linear partial differential equation which is wave-like but was proposed to describe heat conduction. It results from adopting the Jeffreys law of constitutive relation for heat flux, rather than the usual Fourier law. Sufficient conditions for infinite-time admissibility of the system observation operator and system observability are obtained. In the general case, we obtain the infinite-time admissibility from that of the first order Cauchy system, which is done by employing the Hardy space approach. In the special case when the operator in the state equation is negative definite, we derive the infinite-time admissibility and system observability using a semigroup approach. Illustrative examples are given.},
  archive      = {J_SICON},
  author       = {Jian-Hua Chen and Xian-Feng Zhao and Hua-Cheng Zhou},
  doi          = {10.1137/22M1511680},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {466-486},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Admissibility and observability of jeffreys type of overdamped second order linear systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stabilization for wave equation with localized kelvin–voigt
damping on cuboidal domain: A degenerate case. <em>SICON</em>,
<em>62</em>(1), 441–465. (<a
href="https://doi.org/10.1137/22M153210X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we study the stabilization issue for a multidimensional wave equation with localized Kelvin–Voigt damping on a cuboidal domain, in which the damping region does not satisfy the geometric control condition (GCC). The variable damping coefficient is assumed to be degenerate near the interface. We prove that the system is polynomially stable with a decay rate depending on the degree of the degeneration . A relationship between the decay order and is identified. In particular, this decay rate is consistent with the optimal one for the corresponding system with constant damping coefficient (i.e., ) obtained in [K. Yu and Z.-J. Han, SIAM J. Control Optim., 59 (2021), pp. 1973–1988]. Moreover, it is the first result on the decay rates of the solutions to multidimensional wave equations with localized degenerate Kelvin–Voigt damping when GCC is not satisfied.},
  archive      = {J_SICON},
  author       = {Zhong-Jie Han and Zhuangyi Liu and Kai Yu},
  doi          = {10.1137/22M153210X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {441-465},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stabilization for wave equation with localized Kelvin–Voigt damping on cuboidal domain: A degenerate case},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A viscous ergodic problem with unbounded and measurable
ingredients, part 1: HJB equation. <em>SICON</em>, <em>62</em>(1),
415–440. (<a href="https://doi.org/10.1137/22M1478069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We address the problem of existence and uniqueness of solutions to ergodic Hamilton–Jacobi–Bellman (HJB) equations of the form in the whole space with unbounded and merely measurable data and where is a Bellman Hamiltonian. The method we use is different from classical approaches. It relies on duality theory and optimization in abstract Banach spaces together with maximal dissipativity of the diffusion operator.},
  archive      = {J_SICON},
  author       = {Hicham Kouhkouh},
  doi          = {10.1137/22M1478069},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {415-440},
  shortjournal = {SIAM J. Control Optim.},
  title        = {A viscous ergodic problem with unbounded and measurable ingredients, part 1: HJB equation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). A stability dichotomy for discrete-time linear switching
systems in dimension two. <em>SICON</em>, <em>62</em>(1), 400–414. (<a
href="https://doi.org/10.1137/23M1551225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We prove that, for every discrete-time linear switching system in two complex variables and with finitely many switching states, either the system is Lyapunov stable or there exists a trajectory which escapes to infinity with at least linear speed. We also give a checkable algebraic criterion to distinguish these two cases. This dichotomy was previously known to hold for systems in two real variables but is known to be false in higher dimensions and for systems with infinitely many switching states.},
  archive      = {J_SICON},
  author       = {Ian D. Morris},
  doi          = {10.1137/23M1551225},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {400-414},
  shortjournal = {SIAM J. Control Optim.},
  title        = {A stability dichotomy for discrete-time linear switching systems in dimension two},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear consensus+innovations under correlated
heavy-tailed noises: Mean square convergence rate and asymptotics.
<em>SICON</em>, <em>62</em>(1), 376–399. (<a
href="https://doi.org/10.1137/22M1543197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider distributed recursive estimation of consensus+innovations type in the presence of heavy-tailed sensing and communication noises. We allow that the sensing and communication noises are mutually correlated while independent and identically distributed in time, and that they may both have infinite moments of order higher than one (hence having infinite variances). Such heavy-tailed, infinite-variance noises are highly relevant in practice and are shown to occur, e.g., in dense internet of things deployments. We develop a consensus+innovations distributed estimator that employs a general nonlinearity in both consensus and innovations steps to combat the noise. We establish the estimator’s almost sure convergence, asymptotic normality, and mean squared error (MSE) convergence. Moreover, we establish and explicitly quantify for the estimator a sublinear MSE convergence rate. We then quantify through analytical examples the effects of the nonlinearity choices and the noises correlation on the system performance. Finally, numerical examples corroborate our findings and verify that the proposed method works in the simultaneous heavy-tail communication-sensing noise setting, while existing methods fail under the same noise conditions.},
  archive      = {J_SICON},
  author       = {Manojlo Vukovic and Dusan Jakovetic and Dragana Bajovic and Soummya Kar},
  doi          = {10.1137/22M1543197},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {376-399},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Nonlinear Consensus+Innovations under correlated heavy-tailed noises: Mean square convergence rate and asymptotics},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning optimal policies in potential mean field games:
Smoothed policy iteration algorithms. <em>SICON</em>, <em>62</em>(1),
351–375. (<a href="https://doi.org/10.1137/22M1539861">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce two smoothed policy iteration algorithms (SPIs) as rules for learning policies and methods for computing Nash equilibria in second order potential mean field games (MFGs). Global convergence is proved if the coupling term in the MFG system satisfies the Lasry–Lions monotonicity condition. Local convergence to a stable solution is proved for a system which may have multiple solutions. The convergence analysis shows close connections between SPIs and the fictitious play algorithm, which has been widely studied in the MFG literature. Numerical simulation results based on finite difference schemes are presented to supplement the theoretical analysis.},
  archive      = {J_SICON},
  author       = {Qing Tang and Jiahao Song},
  doi          = {10.1137/22M1539861},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {351-375},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Learning optimal policies in potential mean field games: Smoothed policy iteration algorithms},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Discrete-time approximation of stochastic optimal control
with partial observation. <em>SICON</em>, <em>62</em>(1), 326–350. (<a
href="https://doi.org/10.1137/23M1549018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a class of stochastic optimal control problems with partial observation, and study their approximation by discrete-time control problems. We establish a convergence result by using the weak convergence technique of Kushner and Dupuis [Numerical Methods for Stochastic Control Problems in Continuous Time, Springer, New York], together with the notion of relaxed control rule introduced by El Karoui, Huù Nguyen and Jeanblanc-Picqué [SIAM J. Control Optim., 26 (1988), pp. 1025–1061]. In particular, with a well chosen discrete-time control system, we obtain a first implementable numerical algorithm (with convergence) for the partially observed control problem. Moreover, our discrete-time approximation result would open the door to study convergence of more general numerical approximation methods, such as machine learning based methods. Finally, we illustrate our convergence result by numerical experiments on a partially observed control problem in a linear quadratic setting.},
  archive      = {J_SICON},
  author       = {Yunzhang Li and Xiaolu Tan and Shanjian Tang},
  doi          = {10.1137/23M1549018},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {326-350},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Discrete-time approximation of stochastic optimal control with partial observation},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sampled-data finite-dimensional observer-based control of 1D
stochastic parabolic PDEs. <em>SICON</em>, <em>62</em>(1), 297–325. (<a
href="https://doi.org/10.1137/22M1538247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Sampled-data control of PDEs has become an active research area; however, existing results are confined to deterministic PDEs. Sampled-data controller design of stochastic PDEs is a challenging open problem. In this paper we suggest a solution to this problem for 1D stochastic diffusion-reaction equations under discrete-time nonlocal measurement via the modal decomposition method, where both the considered system and the measurement are subject to nonlinear multiplicative noise. We present two methods: a direct one with sampled-data controller implemented via zero-order hold device, and a dynamic-extension-based one with sampled-data controller implemented via a generalized hold device. For both methods, we provide mean-square exponential stability analysis of the full-order closed-loop system. We construct a Lyapunov functional that depends on both the deterministic and stochastic parts of the finite-dimensional part of the closed-loop system. We employ corresponding Itô’s formulas for stochastic ODEs and PDEs, respectively, and further combine with Halanay’s inequality with respect to the expected value of to compensate for sampling in the infinite-dimensional tail. We provide linear matrix inequalities (LMIs) for finding the observer dimension and upper bounds on sampling intervals and noise intensities that preserve the mean-square exponential stability. We prove that the LMIs are always feasible for large enough observer dimension and small enough bounds on sampling intervals and noise intensities. A numerical example demonstrates the efficiency of our methods. The example shows that for the same bounds on noise intensities, the dynamic-extension-based controller allows larger sampling intervals, but this is due to its complexity (generalized hold device for sample-data implementation compared to zero-order hold for the direct method).},
  archive      = {J_SICON},
  author       = {Pengfei Wang and Emilia Fridman},
  doi          = {10.1137/22M1538247},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {297-325},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Sampled-data finite-dimensional observer-based control of 1D stochastic parabolic PDEs},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Maximum principles for optimal control problems with
differential inclusions. <em>SICON</em>, <em>62</em>(1), 271–296. (<a
href="https://doi.org/10.1137/22M1540740">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. There are three different forms of adjoint inclusions that appear in the most advanced necessary optimality conditions for optimal control problems involving differential inclusions: Euler–Lagrange inclusion (with partial convexification) [A. D. Ioffe, J. Optim. Theory Appl., 182 (2019), pp. 285–309], fully convexified Hamiltonian inclusion [F. H. Clarke, Mem. Amer. Math. Soc., 173 (2005), 816], and partially convexified Hamiltonian inclusion [P. D. Loewen and R. T. Rockafellar, SIAM J. Control Optim., 34 (1996), pp. 1496–1511], [A. D. Ioffe, Trans. Amer. Math. Soc., 349 (1997), pp. 2871–2900], [R. B. Vinter, SIAM J. Control Optim., 52 (2014), pp. 1237–1250] (for convex-valued differential inclusions in the first two references). This paper addresses all three types of necessary conditions for problems with (in general) nonconvex-valued differential inclusions. The first of the two main theorems, with the Euler–Lagrange inclusion, is equivalent to the main result of [A. D. Ioffe, J. Optim. Theory Appl., 182 (2019), pp. 285–309] but proved in a substantially different and much more direct way. The second theorem contains conditions that guarantee necessity of both types of Hamiltonian conditions. It seems to be the first result of such a sort that covers differential inclusions with possibly unbounded values and contains the most recent results of [F. H. Clarke, Mem. Amer. Math. Soc., 173 (2005), 816] and [R. B. Vinter, SIAM J. Control Optim., 52 (2014), pp. 1237–1250] as particular cases. And again, the proof of the theorem is based on a substantially different approach.},
  archive      = {J_SICON},
  author       = {A. D. Ioffe},
  doi          = {10.1137/22M1540740},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {271-296},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Maximum principles for optimal control problems with differential inclusions},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MF-OMO: An optimization formulation of mean-field games.
<em>SICON</em>, <em>62</em>(1), 243–270. (<a
href="https://doi.org/10.1137/22M1524084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper proposes a new mathematical paradigm to analyze discrete-time mean-field games. It is shown that finding Nash equilibrium solutions for a general class of discrete-time mean-field games is equivalent to solving an optimization problem with bounded variables and simple convex constraints, called MF-OMO. This equivalence framework enables finding multiple (and possibly all) Nash equilibrium solutions of mean-field games by standard algorithms. For instance, projected gradient descent is shown to be capable of retrieving all possible Nash equilibrium solutions when there are finitely many of them, with proper initializations. Moreover, analyzing mean-field games with linear rewards and mean-field independent dynamics is reduced to solving a finite number of linear programs, hence solvable in finite time. This framework does not rely on the contractive and the monotone assumptions and the uniqueness of the Nash equilibrium.},
  archive      = {J_SICON},
  author       = {Xin Guo and Anran Hu and Junzi Zhang},
  doi          = {10.1137/22M1524084},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {243-270},
  shortjournal = {SIAM J. Control Optim.},
  title        = {MF-OMO: An optimization formulation of mean-field games},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of RHC for stabilization of nonautonomous parabolic
equations under uncertainty. <em>SICON</em>, <em>62</em>(1), 220–242.
(<a href="https://doi.org/10.1137/23M1550876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Stabilization of a class of time-varying parabolic equations with uncertain input data using receding horizon control (RHC) is investigated. The diffusion coefficient and the initial function are prescribed as random fields. We consider both cases: uniform and log-normal distributions of the diffusion coefficient. The controls are chosen to be finite-dimensional and enter into the system as a linear combination of finitely many indicator functions (actuators) supported in open subsets of the spatial domain. Under suitable regularity assumptions, we study the expected (averaged) stabilizability of the RHC-controlled system with respect to the number of actuators. An upper bound is also obtained for the failure probability of RHC in relation to the choice of the number of actuators and parameters in the equation.},
  archive      = {J_SICON},
  author       = {Behzad Azmi and Lukas Herrmann and Karl Kunisch},
  doi          = {10.1137/23M1550876},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {220-242},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Analysis of RHC for stabilization of nonautonomous parabolic equations under uncertainty},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stochastic fixed-point iterations for nonexpansive maps:
Convergence and error bounds. <em>SICON</em>, <em>62</em>(1), 191–219.
(<a href="https://doi.org/10.1137/22M1515550">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study a stochastically perturbed version of the well-known Krasnoselskii–Mann iteration for computing fixed points of nonexpansive maps in finite dimensional normed spaces. We discuss sufficient conditions on the stochastic noise and stepsizes that guarantee almost sure convergence of the iterates towards a fixed point and derive nonasymptotic error bounds and convergence rates for the fixed-point residuals. Our main results concern the case of a martingale difference noise with variances that can possibly grow unbounded. This supports an application to reinforcement learning for average reward Markov decision processes, for which we establish convergence and asymptotic rates. We also analyze in depth the case where the noise has uniformly bounded variance, obtaining error bounds with explicit computable constants.},
  archive      = {J_SICON},
  author       = {Mario Bravo and Roberto Cominetti},
  doi          = {10.1137/22M1515550},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {191-219},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Stochastic fixed-point iterations for nonexpansive maps: Convergence and error bounds},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). State estimation with event sensors: Observability analysis
and multi-sensor fusion. <em>SICON</em>, <em>62</em>(1), 167–190. (<a
href="https://doi.org/10.1137/22M1539204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work investigates a state estimation problem for linear time-invariant systems based on polarized measurement information from event sensors. To enable estimator design, a new notion of observability, namely, -observability is defined with the precision parameter which relates to the worst-case performance of inferring the initial state, based on which a criterion is developed to test the -observability of discrete-time linear systems. Utilizing multisensor polarity data from event sensors and the implicit information hidden in event-triggering conditions at no-event instants, an iterative event-triggered state estimator is designed to evaluate a set containing all possible values of the state. The proposed estimator is built by outer approximation of intersecting ellipsoids that are predicted from previous state estimates and the ellipsoids inferred from received polarity information of event sensors as well as the event-triggering protocol; the estimated regions of the state derived from multisensor event measurements are fused together, the sizes of which are proved to be asymptotically bounded. Distributed implementation of the estimation algorithm utilizing a two-layer processor network of hierarchy architecture is discussed, and the temporal computational complexity of the algorithm implemented in centralized and distributed ways is analyzed. The efficiency of the proposed event-triggered state estimator is verified by numerical experiments.},
  archive      = {J_SICON},
  author       = {Xinhui Liu and Kaikai Zheng and Dawei Shi and Tongwen Chen},
  doi          = {10.1137/22M1539204},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {167-190},
  shortjournal = {SIAM J. Control Optim.},
  title        = {State estimation with event sensors: Observability analysis and multi-sensor fusion},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimal scheduling of entropy regularizer for
continuous-time linear-quadratic reinforcement learning. <em>SICON</em>,
<em>62</em>(1), 135–166. (<a
href="https://doi.org/10.1137/22M1515744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work uses the entropy-regularized relaxed stochastic control perspective as a principled framework for designing reinforcement learning (RL) algorithms. Herein, an agent interacts with the environment by generating noisy controls distributed according to the optimal relaxed policy. The noisy policies, on the one hand, explore the space and hence facilitate learning, but, on the other hand, they introduce bias by assigning a positive probability to nonoptimal actions. This exploration-exploitation trade-off is determined by the strength of entropy regularization. We study algorithms resulting from two entropy regularization formulations: the exploratory control approach, where entropy is added to the cost objective, and the proximal policy update approach, where entropy penalizes policy divergence between consecutive episodes. We focus on the finite horizon continuous-time linear-quadratic (LQ) RL problem, where a linear dynamics with unknown drift coefficients is controlled subject to quadratic costs. In this setting, both algorithms yield a Gaussian relaxed policy. We quantify the precise difference between the value functions of a Gaussian policy and its noisy evaluation and show that the execution noise must be independent across time. By tuning the frequency of sampling from relaxed policies and the parameter governing the strength of entropy regularization, we prove that the regret, for both learning algorithms, is of the order (up to a logarithmic factor) over episodes, matching the best known result from the literature.},
  archive      = {J_SICON},
  author       = {Lukasz Szpruch and Tanut Treetanthiploet and Yufei Zhang},
  doi          = {10.1137/22M1515744},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {135-166},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Optimal scheduling of entropy regularizer for continuous-time linear-quadratic reinforcement learning},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On converse lyapunov theorem for fixed-time input-to-state
stability. <em>SICON</em>, <em>62</em>(1), 118–134. (<a
href="https://doi.org/10.1137/22M1497596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Input-to-state stability is one of the most utilizable robust stability properties for nonlinear dynamical systems, while (nearly) fixed-time convergence is a kind of decay for trajectories of disturbance-free systems that is independent in initial conditions. The presence of both these features for a system can be checked by the existence of a proper Lyapunov function. The objective of this work is to provide the conditions for a converse result that (nearly) fixed-time input-to-state stable systems admit a respective Lyapunov function. Similar auxiliary results for uniform finite-time stability and uniform (nearly) fixed-time stability are obtained.},
  archive      = {J_SICON},
  author       = {Denis Efimov and Andrey Polyakov},
  doi          = {10.1137/22M1497596},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {118-134},
  shortjournal = {SIAM J. Control Optim.},
  title        = {On converse lyapunov theorem for fixed-time input-to-state stability},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The maximality principle in singular control with absorption
and its applications to the dividend problem. <em>SICON</em>,
<em>62</em>(1), 91–117. (<a
href="https://doi.org/10.1137/22M152791X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Motivated by a new formulation of the classical dividend problem, we show that Peskir’s maximality principle can be transferred to singular stochastic control problems with two-dimensional degenerate dynamics and absorption along the diagonal of the state space. We construct an optimal control as a Skorokhod reflection along a moving barrier, where the barrier can be computed analytically as the smallest solution to a certain nonlinear ODE. Contrarily to the classical one-dimensional formulation of the dividend problem, our framework produces a nontrivial solution when the firm’s (predividend) equity capital evolves as a geometric Brownian motion. Such a solution is also qualitatively different from the one traditionally obtained for the arithmetic Brownian motion.},
  archive      = {J_SICON},
  author       = {Tiziano De Angelis and Erik Ekström and Marcus Olofsson},
  doi          = {10.1137/22M152791X},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {91-117},
  shortjournal = {SIAM J. Control Optim.},
  title        = {The maximality principle in singular control with absorption and its applications to the dividend problem},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Extreme occupation measures in markov decision processes
with an absorbing state. <em>SICON</em>, <em>62</em>(1), 65–90. (<a
href="https://doi.org/10.1137/23M1572398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider a Markov decision process (MDP) with a Borel state space , where is an absorbing state (cemetery), and a Borel action space . We consider the space of finite occupation measures restricted on and the extreme points in it. It is possible that some strategies have infinite occupation measures. Nevertheless, we prove that every finite extreme occupation measure is generated by a deterministic stationary strategy. Then, for this MDP, we consider a constrained problem with total undiscounted criteria and constraints, where the cost functions are nonnegative. By assumption, the strategies inducing infinite occupation measures are not optimal. Then our second main result is that, under mild conditions, the solution to this constrained MDP is given by a mixture of no more than occupation measures generated by deterministic stationary strategies.},
  archive      = {J_SICON},
  author       = {Alexey Piunovskiy and Yi Zhang},
  doi          = {10.1137/23M1572398},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {65-90},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Extreme occupation measures in markov decision processes with an absorbing state},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). An irreducible linear switching system whose unique
barabanov norm is not strictly convex. <em>SICON</em>, <em>62</em>(1),
42–64. (<a href="https://doi.org/10.1137/23M1551213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We construct a marginally stable linear switching system in continuous time, in four dimensions, and with three switching states, which is exponentially stable with respect to constant switching laws and which has a unique Barabanov norm, but such that the Barabanov norm fails to be strictly convex. This resolves a question of Chitour, Gaye, and Mason.},
  archive      = {J_SICON},
  author       = {Ian D. Morris},
  doi          = {10.1137/23M1551213},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {42-64},
  shortjournal = {SIAM J. Control Optim.},
  title        = {An irreducible linear switching system whose unique barabanov norm is not strictly convex},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On BIBO stability of infinite-dimensional linear state-space
systems. <em>SICON</em>, <em>62</em>(1), 22–41. (<a
href="https://doi.org/10.1137/23M1563098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider bounded-input-bounded-output (BIBO) stability of systems described by infinite-dimensional linear state-space representations, filling the so far unattended gap of a formal definition and characterization of BIBO stability in this general case. Furthermore, we provide several sufficient conditions guaranteeing BIBO stability of a particular system and discuss to which extent this property is preserved under additive and multiplicative perturbations of the system.},
  archive      = {J_SICON},
  author       = {Felix L. Schwenninger and Alexander A. Wierzba and Hans Zwart},
  doi          = {10.1137/23M1563098},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {22-41},
  shortjournal = {SIAM J. Control Optim.},
  title        = {On BIBO stability of infinite-dimensional linear state-space systems},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Relaxed excitation conditions for robust identification and
adaptive control using estimation with memory. <em>SICON</em>,
<em>62</em>(1), 1–21. (<a
href="https://doi.org/10.1137/22M1506183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, adaptive controllers are designed to track a given trajectory for linear and nonlinear systems. No condition on the tracked trajectory, other than continuity and boundedness, is needed to simultaneously ensure exponential convergence to the tracking reference, exponential convergence to the identification of the plant, and robustness to nonparametric uncertainties. To achieve this, the formulation of the excitation condition associated with the identification part of the adaptive scheme is proposed without employing closed-loop signals, allowing the use of a transient enrichment of the reference. The effect of this transient modification is attenuated by using relaxed requirements for the identification, obtained through a generalization of several estimation algorithms found in recent literature that use memory mechanisms. Consequently, no spectral content of the tracked trajectory—a classic requirement in adaptive theory—is needed to guarantee the mentioned features when the proposed scheme is used. A numerical example is given to illustrate the design aspects involved and the distinctive features of the proposed strategy.},
  archive      = {J_SICON},
  author       = {Javier Gallegos and Norelys Aguila-Camacho},
  doi          = {10.1137/22M1506183},
  journal      = {SIAM Journal on Control and Optimization},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {SIAM J. Control Optim.},
  title        = {Relaxed excitation conditions for robust identification and adaptive control using estimation with memory},
  volume       = {62},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
