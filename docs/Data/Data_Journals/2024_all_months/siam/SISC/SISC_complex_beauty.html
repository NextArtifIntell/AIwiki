<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>SISC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="sisc---259">SISC - 259</h2>
<ul>
<li><details>
<summary>
(2024). WAN discretization of PDEs: Best approximation,
stabilization, and essential boundary conditions. <em>SISC</em>,
<em>46</em>(6), C688–C715. (<a
href="https://doi.org/10.1137/23M1588196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we provide a theoretical analysis of the recently introduced weakly adversarial networks (WAN) method, used to approximate partial differential equations in high dimensions. We address the existence and stability of the solution, as well as approximation bounds. We also propose two new stabilized WAN-based formulas that avoid the need for direct normalization. Furthermore, we analyze the method’s effectiveness for the Dirichlet boundary problem that employs the implicit representation of the geometry. We also devise a pseudotime XNODE neural network for static PDE problems, yielding significantly faster convergence results than the classical deep neural networks.},
  archive      = {J_SISC},
  author       = {Silvia Bertoluzza and Erik Burman and Cuiyu He},
  doi          = {10.1137/23M1588196},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {C688-C715},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {WAN discretization of PDEs: Best approximation, stabilization, and essential boundary conditions},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The ADMM-PINNs algorithmic framework for nonsmooth
PDE-constrained optimization: A deep learning approach. <em>SISC</em>,
<em>46</em>(6), C659–C687. (<a
href="https://doi.org/10.1137/23M1566935">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the combination of the alternating direction method of multipliers (ADMM) with physics-informed neural networks (PINNs) for a general class of nonsmooth partial differential equation (PDE)-constrained optimization problems, where additional regularization can be employed for constraints on the control or design variables. The resulting ADMM-PINNs algorithmic framework substantially enlarges the applicable range of PINNs to nonsmooth cases of PDE-constrained optimization problems. The application of the ADMM makes it possible to separate the PDE constraints and the nonsmooth regularization terms for iterations. Accordingly, at each iteration, one of the resulting subproblems is a smooth PDE-constrained optimization which can be efficiently solved by PINNs, and another is a simple nonsmooth optimization problem, which usually has a closed-form solution or can be efficiently solved by various standard optimization algorithms or pretrained neural networks. The ADMM-PINNs algorithmic framework does not require one to solve PDEs repeatedly, and it is mesh-free, easy to implement, and scalable to different PDE settings. We validate the efficiency of the ADMM-PINNs algorithmic framework by different prototypical applications, including inverse potential problems, source identification in elliptic equations, control constrained optimal control of the Burgers equation, and sparse optimal control of parabolic equations.},
  archive      = {J_SISC},
  author       = {Yongcun Song and Xiaoming Yuan and Hangrui Yue},
  doi          = {10.1137/23M1566935},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {C659-C687},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The ADMM-PINNs algorithmic framework for nonsmooth PDE-constrained optimization: A deep learning approach},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust radial basis function interpolation based on geodesic
distance for the numerical coupling of multiphysics problems.
<em>SISC</em>, <em>46</em>(6), B981–B1002. (<a
href="https://doi.org/10.1137/24M1643888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Multiphysics simulations frequently require transferring solution fields between subproblems with nonmatching spatial discretizations, typically using interpolation techniques. Standard methods are usually based on measuring the closeness between points by means of the Euclidean distance, which does not account for curvature, cuts, cavities, or other nontrivial geometrical or topological features of the domain. This may lead to spurious oscillations in the interpolant in proximity to these features. To overcome this issue, we propose a modification to rescaled localized radial basis function (RL-RBF) interpolation to account for the geometry of the interpolation domain, by yielding conformity and fidelity to geometrical and topological features. The proposed method, referred to as RL-RBF-G, relies on measuring the geodesic distance between data points. RL-RBF-G removes spurious oscillations appearing in the RL-RBF interpolant, resulting in increased accuracy in domains with complex geometries. We demonstrate the effectiveness of RL-RBF-G interpolation through a convergence study in an idealized setting. Furthermore, we discuss the algorithmic aspects and the implementation of RL-RBF-G interpolation in a distributed-memory parallel framework, and present the results of a strong scalability test yielding nearly ideal results. Finally, we show the effectiveness of RL-RBF-G interpolation in multiphysics simulations by considering an application to a whole-heart cardiac electromechanics model.},
  archive      = {J_SISC},
  author       = {Michele Bucelli and Francesco Regazzoni and Luca Dede’ and Alfio Quarteroni},
  doi          = {10.1137/24M1643888},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {B981-B1002},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Robust radial basis function interpolation based on geodesic distance for the numerical coupling of multiphysics problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cell electropermeabilization modeling via multiple traces
formulation and time semi-implicit multistep coupling. <em>SISC</em>,
<em>46</em>(6), B953–B980. (<a
href="https://doi.org/10.1137/23M1570260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We simulate the electrical response of multiple disjoint biological three-dimensional cells undergoing an electropermeabilization process. Instead of solving the boundary value problem in the unbounded volume, we reduce it to a system of boundary integrals equations—the local multiple traces formulation—coupled with nonlinear dynamics on the cell membranes. Though in time the model is highly nonlinear and poorly regular, the smooth geometry allows for boundary unknowns to be spatially approximated by spherical harmonics. This leads to spectral convergence rates in space. In time, we use a multistep semi-implicit scheme. To ensure stability, the time step needs to be bounded by the smallest characteristic time of the system. Numerical results are provided to validate our claims, and future enhancements are pointed out.},
  archive      = {J_SISC},
  author       = {Isabel A. Martínez Ávila and Carlos Jerez-Hanckes and Irina Pettersson},
  doi          = {10.1137/23M1570260},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {B953-B980},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Cell electropermeabilization modeling via multiple traces formulation and time semi-implicit multistep coupling},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An SVD-based fast algorithm for 3D maxwell’s equations with
perfect electric conductor and quasi-periodic boundary conditions.
<em>SISC</em>, <em>46</em>(6), B925–B952. (<a
href="https://doi.org/10.1137/23M1611038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper presents a fast algorithm, FAME, to calculate the band structures of three-dimensional (3D) photonic crystals with supercell structures and perfect electric conductor and quasi-periodic mixed boundary conditions. The oblique Yee finite difference method is used to discretize the frequency-domain source-free Maxwell’s equations uniformly with different Bravais lattices. We derive the explicit singular value decomposition (SVD) of the discrete curl operator by leveraging the SVD of the discrete differential operator in each direction, in which the FFT structure is implied. With the help of the explicit basis of the range space of the discrete curl operator embedded in its SVD, we transform the Maxwell eigenvalue problem into a null space–free generalized eigenvalue problem, which can be readily solved by the conjugate gradient method. The discrete cosine/sine transform operations induced by the perfect electric conductor boundary conditions in each matrix-vector multiplication operation are accelerated by the FFT with complexity, as well as the quasi-periodic boundary conditions. Numerical experiments are conducted to demonstrate the efficacy and effectiveness of FAME, and surface state phenomena of 3D photonic crystals with gyroid supercell structures are realized.},
  archive      = {J_SISC},
  author       = {Xing-Long Lyu and Tiexiang Li and Jia-Wei Lin and Wen-Wei Lin},
  doi          = {10.1137/23M1611038},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {B925-B952},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An SVD-based fast algorithm for 3D maxwell’s equations with perfect electric conductor and quasi-periodic boundary conditions},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An a posteriori error estimate for a 0D-2D coupled model.
<em>SISC</em>, <em>46</em>(6), B903–B924. (<a
href="https://doi.org/10.1137/22M161651X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work is motivated by the need of efficient numerical simulations of gas flows in the serpentine channels used in proton-exchange membrane fuel cells. In particular, we consider the Poisson problem in a 2D domain composed of several long straight rectangular sections and of several bended corners. In order to speed up the resolution, we propose a 0D model in the rectangular parts of the channel and a finite element resolution in the bends. To find a good compromise between precision and time consuming, the challenge is double: how to choose a suitable position of the interface between the 0D and the 2D models and how to control the discretization error in the bends. We shall present an a posteriori error estimator based on an equilibrated flux reconstruction in the subdomains where the finite element method is applied. The estimates give a global upper bound on the error measured in the energy norm of the difference between the exact and approximate solutions on the whole domain. They are guaranteed, meaning that they feature no undetermined constants. (Global) lower bounds for the error are also derived. An adaptive algorithm is proposed to use smartly the estimator for the aforementioned double challenge. A numerical validation of the estimator and the algorithm completes the work.},
  archive      = {J_SISC},
  author       = {Hussein Albazzal and Alexei Lozinski and Roberta Tittarelli},
  doi          = {10.1137/22M161651X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {B903-B924},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An a posteriori error estimate for a 0D-2D coupled model},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reinforced inverse scattering. <em>SISC</em>,
<em>46</em>(6), B884–B902. (<a
href="https://doi.org/10.1137/22M153207X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Inverse wave scattering aims at determining the properties of an object using data on how the object scatters incoming waves. To gather this information, sensors are positioned to transmit and receive waves. The effectiveness of reconstructing scatterer properties depends significantly on the placement of these sensors and the frequencies of the incident waves. This paper presents a reinforcement learning framework to enhance user-specified strategies like uniformly placing sensors by adaptively determining optimal sensor locations and wave frequencies tailored to different scatterers. This approach leads to a notable enhancement in reconstruction quality, even with limited imaging resources. Extensive numerical results will be provided to demonstrate that the usage of a reinforcement learning framework is beneficial.},
  archive      = {J_SISC},
  author       = {Hanyang Jiang and Yuehaw Khoo and Haizhao Yang},
  doi          = {10.1137/22M153207X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {B884-B902},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Reinforced inverse scattering},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multigrid reduction framework for domains with symmetries.
<em>SISC</em>, <em>46</em>(6), B860–B883. (<a
href="https://doi.org/10.1137/24M1638513">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Divergence constraints are present in the governing equations of numerous physical phenomena, and they usually lead to a Poisson equation whose solution represents a bottleneck in many simulation codes. Algebraic multigrid (AMG) is arguably the most powerful preconditioner for Poisson’s equation, and its effectiveness results from the complementary roles played by the smoother, responsible for damping high-frequency error components, and the coarse-grid correction, which in turn reduces low-frequency modes. This work presents several strategies to make AMG more compute-intensive by leveraging reflection, translational, and rotational symmetries. AMGR, our final proposal, does not require boundary conditions to be symmetric, therefore applying to a broad range of academic and industrial configurations. It is based on a multigrid reduction framework that introduces an aggressive coarsening to the multigrid hierarchy, reducing the memory footprint, setup, and application costs of the top-level smoother. While preserving AMG’s excellent convergence, AMGR allows one to replace the standard sparse matrix-vector product with the more compute-intensive sparse matrix-matrix product, yielding significant accelerations. Numerical experiments on industrial CFD applications demonstrated up to 70 speed-ups when solving Poisson’s equation with AMGR instead of AMG. Additionally, strong and weak scalability analyses revealed no significant degradation.},
  archive      = {J_SISC},
  author       = {Àdel Alsalti-Baldellou and Carlo Janna and Xavier Álvarez-Farré and F. Xavier Trias},
  doi          = {10.1137/24M1638513},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {B860-B883},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A multigrid reduction framework for domains with symmetries},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient n-to-m checkpointing algorithm for finite element
simulations. <em>SISC</em>, <em>46</em>(6), B830–B859. (<a
href="https://doi.org/10.1137/23M1613724">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we introduce a new algorithm for N-to-M checkpointing in finite element simulations. This new algorithm allows efficient saving/loading of functions representing physical quantities associated with the mesh representing the physical domain. Specifically, the algorithm allows for using different numbers of parallel processes for saving and loading, allowing for restarting and postprocessing on the process count appropriate to the given phase of the simulation and other conditions. For demonstration, we implemented this algorithm in PETSc, the Portable, Extensible Toolkit for Scientific Computation, and added a convenient high-level interface into Firedrake, a system for solving partial differential equations using finite element methods. We evaluated our new implementation by saving and loading data involving 8.2 billion finite element degrees of freedom using 8,192 parallel processes on ARCHER2, the UK National Supercomputing Service. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://zenodo.org/records/7675345.},
  archive      = {J_SISC},
  author       = {David A. Ham and Vaclav Hapla and Matthew G. Knepley and Lawrence Mitchell and Koki Sagiyama},
  doi          = {10.1137/23M1613724},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {B830-B859},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient N-to-M checkpointing algorithm for finite element simulations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simulation method for the wetting dynamics of liquid
droplets on deformable membranes. <em>SISC</em>, <em>46</em>(6),
B806–B829. (<a href="https://doi.org/10.1137/24M1641142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Biological cells utilize membranes and liquid-like droplets, known as biomolecular condensates, to structure their interior. The interaction of droplets and membranes, despite being involved in several key biological processes, is so far little understood. Here, we present a first numerical method to simulate the continuum dynamics of droplets interacting with deformable membranes via wetting. The method combines the advantages of the phase-field method for multiphase flow simulation and the arbitrary Lagrangian-Eulerian method for an explicit description of the elastic surface. The model is thermodynamically consistent, coupling bulk hydrodynamics with capillary forces, as well as bending, tension, and stretching of a thin membrane. The method is validated by comparing simulations for single droplets to theoretical results of shape equations, and its capabilities are illustrated in two- and three-dimensional axisymmetric scenarios.},
  archive      = {J_SISC},
  author       = {Marcel Mokbel and Dominic Mokbel and Susanne Liese and Christoph Weber and Sebastian Aland},
  doi          = {10.1137/24M1641142},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {B806-B829},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A simulation method for the wetting dynamics of liquid droplets on deformable membranes},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). MCMS-RBM: Multicomponent multistate reduced basis method
toward rapid generation of phase diagrams for the lifshitz–petrich
model. <em>SISC</em>, <em>46</em>(6), B785–B805. (<a
href="https://doi.org/10.1137/23M1596831">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Due to quasicrystals having long-range orientational order but without translational symmetry, traditional numerical methods usually suffer when applied as is. In the past decade, the projection method has emerged as a prominent solver for quasiperiodic problems. Transforming them into higher-dimensional but periodic ones, the projection method facilitates the application of the fast Fourier transform. However, the computational complexity inevitably becomes high, which significantly impedes, e.g., the generation of the phase diagram since a high-fidelity simulation of a problem whose dimension is doubled must be performed for numerous times. To address the computational challenge of quasiperiodic problems based on the projection method, this paper proposes a multicomponent multistate reduced basis method (MCMS-RBM). Featuring multiple components with each providing reduction functionality for one branch of the problem induced by one part of the parameter domain, the MCMS-RBM does not resort to the parameter domain configurations (e.g., phase diagrams) a priori. It enriches each component in a greedy fashion via a phase transition guided exploration of the multiple states inherent to the problem. Adopting the empirical interpolation method, the resulting online-efficient method vastly accelerates the generation of a delicate phase diagram to a matter of minutes for a parametrized two-turn-four dimensional Lifshitz–Petrich model with two length scales. Moreover, it furnishes surrogate and equally accurate field variables anywhere in the parameter domain.},
  archive      = {J_SISC},
  author       = {Yajie Ji and Lijie Ji and Yanlai Chen and Zhenli Xu},
  doi          = {10.1137/23M1596831},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {B785-B805},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {MCMS-RBM: Multicomponent multistate reduced basis method toward rapid generation of phase diagrams for the Lifshitz–Petrich model},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A meshfree RBF-FD constant along normal method for solving
PDEs on surfaces. <em>SISC</em>, <em>46</em>(6), A3897–A3921. (<a
href="https://doi.org/10.1137/23M1621265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper introduces a novel meshfree methodology based on radial basis function–finite difference (RBF-FD) approximations for the numerical solution of partial differential equations (PDEs) on surfaces of codimension 1 embedded in . The method is built upon the principles of the closest point method, without the use of a grid or a closest point mapping. We show that the combination of local embedded stencils with these principles can be employed to approximate surface derivatives using polyharmonic spline kernels and polynomials (PHS + Poly) RBF-FD. Specifically, we show that it is enough to consider a constant extension along the normal direction only at a single node to overcome the rank deficiency of the polynomial basis. An extensive parameter analysis is presented to test the dependence of the approach. We demonstrate high-order convergence rates on problems involving surface advection and surface diffusion, and solve Turing pattern formations on surfaces defined either implicitly or by point clouds. Moreover, a simple coupling approach with a particle tracking method demonstrates the potential of the proposed method in solving PDEs on evolving surfaces in the normal direction. Our numerical results confirm the stability, flexibility, and high-order algebraic convergence of the approach. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://gitlab.com/apetras/surfacepdes_public_code.git and in the supplementary materials (surfacepdes_public_code-master.zip [2.83KB]).},
  archive      = {J_SISC},
  author       = {Víctor Bayona and Argyrios Petras and Cécile Piret and Steven J. Ruuth},
  doi          = {10.1137/23M1621265},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3897-A3921},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A meshfree RBF-FD constant along normal method for solving PDEs on surfaces},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-stable and mesh-preserving parametric FEM for mean
curvature flow of surfaces. <em>SISC</em>, <em>46</em>(6), A3873–A3896.
(<a href="https://doi.org/10.1137/24M1647813">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Harmonic maps serve as reliable approximations to conformal maps. Building upon this concept, we introduce a family of novel parametric finite element schemes for solving the mean curvature flow of surfaces in this paper. The key idea involves coupling the normal component of the original equation with a modified harmonic map heat flow. This heat flow induces a map from a given reference surface to the unknown surface to be solved, resulting in a new system that effectively preserves the mesh quality. We employ the linearized Euler scheme and the BDF2 scheme in the temporal direction, with the existence and uniqueness of solutions being rigorously proven. We prove that the Euler scheme is energy-stable, and it becomes energy-diminishing when the current obtained numerical surface is selected as the reference surface for computing the numerical solution at the subsequent time level. Numerical experiments, including several benchmark examples, demonstrate the advantages of our approach in preserving mesh quality and capturing the evolution of surfaces when they approach a singularity.},
  archive      = {J_SISC},
  author       = {Beiping Duan},
  doi          = {10.1137/24M1647813},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3873-A3896},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Energy-stable and mesh-preserving parametric FEM for mean curvature flow of surfaces},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A highly accurate PML-BIE solver for the electromagnetic
scattering problem in a multilayered medium. <em>SISC</em>,
<em>46</em>(6), A3849–A3872. (<a
href="https://doi.org/10.1137/24M1650703">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper proposes a new boundary integral equation (BIE) methodology based on the perfectly matched layer (PML) truncation technique for solving the electromagnetic scattering problems in a multilayered medium. Instead of using the original PML stretched fields, modified fields which are also equivalent to the solutions in the physical region are introduced. This significantly simplifies the study of the proposed methodology for solving the PML problem. Then some PML transformed layer potentials and the associated boundary integral operators are defined and the corresponding jump relations are shown. Under the assumption that the fields vanish on the PML boundary, the solution representations, as well as the related BIEs and regularization of the hypersingular operators, in terms of the current density functions on the truncated interface, are derived. Numerical experiments are presented to demonstrate the efficiency and accuracy of the method.},
  archive      = {J_SISC},
  author       = {Gang Bao and Wangtao Lu and Tao Yin and Lu Zhang},
  doi          = {10.1137/24M1650703},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3849-A3872},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A highly accurate PML-BIE solver for the electromagnetic scattering problem in a multilayered medium},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accurate solution of the nonlinear schrödinger equation via
conservative multiple-relaxation ImEx methods. <em>SISC</em>,
<em>46</em>(6), A3827–A3848. (<a
href="https://doi.org/10.1137/23M1598118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The nonlinear Schrödinger (NLS) equation possesses an infinite hierarchy of conserved densities, and the numerical preservation of some of these quantities is critical for accurate long-time simulations. We propose a discretization that conserves one or two of these conserved quantities by combining higher-order implicit-explicit (ImEx) Runge–Kutta time integrators with the relaxation technique and adaptive step size control and only requires the solution of one or two algebraic equations at the end of each step. We show through numerical tests that our mass-conserving method is much more efficient and accurate than the widely used second-order time-splitting pseudospectral approach. Compared to higher-order operator splitting, it gives similar results in general and significantly better results near the semiclassical limit. Furthermore, for some problems adaptive time stepping provides a dramatic reduction in cost without sacrificing accuracy. We also propose a full discretization that conserves both mass and energy by using a conservative finite element spatial discretization and multiple relaxation in time. Our results suggest that this method provides a qualitative improvement in long-time error growth for multi-soliton solutions. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/abhibsws/Multiple_Relaxation_NLS and in the supplementary materials (Multiple_Relaxation_NSL-main.zip [1.82MB]).},
  archive      = {J_SISC},
  author       = {Abhijit Biswas and David I. Ketcheson},
  doi          = {10.1137/23M1598118},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3827-A3848},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Accurate solution of the nonlinear schrödinger equation via conservative multiple-relaxation ImEx methods},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A faster multipole legendre–chebyshev transform.
<em>SISC</em>, <em>46</em>(6), A3803–A3826. (<a
href="https://doi.org/10.1137/24M1659352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper describes a fast algorithm for transforming Legendre coefficients into Chebyshev coefficients, and vice versa. The algorithm is based on the fast multipole method and is similar to the approach described by Alpert and Rokhlin [SIAM J. Sci. Comput., 12 (1991), pp. 158–179]. The main difference is that we utilize a modal Galerkin approach with Chebyshev basis functions instead of a nodal approach with a Lagrange basis. Part of the algorithm is a novel method that facilitates faster spreading of intermediate results through neighboring levels of hierarchical matrices. This enhancement leads to a method that is approximately 20 percent faster to execute, due to fewer floating point operations. We also describe an efficient initialization algorithm that for the Lagrange basis is roughly 5 times faster than the original method for large input arrays. The described method has both a planning and an execution stage that asymptotically require O(N) flops. The algorithm is simple enough that it can be implemented in 100 lines of vectorized Python code. Moreover, its efficiency is such that a single-threaded C implementation can transform 1,000,000 coefficients in approximately 20 milliseconds on a new MacBook Pro M3, representing about 3 times the execution time of a well-planned (single-threaded) type 2 discrete cosine transform from FFTW (www.fftw.org). Planning for these coefficients requires approximately 50 milliseconds. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/mikaem/SISC-Legendre-to-Chebyshev and in the supplementary materials (SISC-Legendre-to-Chebyshev-main.zip [559KB]). The method is already in use in the spectral Galerkin framework Shenfun [11].},
  archive      = {J_SISC},
  author       = {Mikael Mortensen},
  doi          = {10.1137/24M1659352},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3803-A3826},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A faster multipole Legendre–Chebyshev transform},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A high-order meshless linearly implicit energy-preserving
method for nonlinear wave equations on riemannian manifolds.
<em>SISC</em>, <em>46</em>(6), A3779–A3802. (<a
href="https://doi.org/10.1137/24M1654245">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a kernel-based meshless energy-preserving method for solving nonlinear wave equations on closed, compact, and smooth Riemannian manifolds. Our method employs the scalar auxiliary variable approach to transform the nonlinear term into a quadratic form, enabling a linearly implicit scheme that reduces computational time and has good energy conservation properties. Spatial discretization is achieved through a meshless Galerkin approximation in a finite-dimensional space spanned by Lagrange basis functions constructed from positive definite functions. The method demonstrates a high order of convergence without requiring an underlying mesh. Numerical experiments validate the theoretical analysis, confirming the convergence order and energy-preserving properties of the proposed method.},
  archive      = {J_SISC},
  author       = {Zhengjie Sun and Leevan Ling},
  doi          = {10.1137/24M1654245},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3779-A3802},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A high-order meshless linearly implicit energy-preserving method for nonlinear wave equations on riemannian manifolds},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing singular and near-singular integrals over curved
boundary elements: The strongly singular case. <em>SISC</em>,
<em>46</em>(6), A3756–A3778. (<a
href="https://doi.org/10.1137/23M1605594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present algorithms for computing strongly singular and near-singular surface integrals over curved triangular patches, based on singularity subtraction, the continuation approach, and transplanted Gauss quadrature. We demonstrate the accuracy and robustness of our method for quadratic basis functions and quadratic triangles by integrating it into a boundary element code and solving several scattering problems in three dimensions. We also give numerical evidence that the utilization of curved boundary elements enhances computational efficiency compared to conventional planar elements.},
  archive      = {J_SISC},
  author       = {Hadrien Montanelli and Francis Collino and Houssem Haddar},
  doi          = {10.1137/23M1605594},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3756-A3778},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Computing singular and near-singular integrals over curved boundary elements: The strongly singular case},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rational kernel-based interpolation for complex-valued
frequency response functions. <em>SISC</em>, <em>46</em>(6),
A3727–A3755. (<a href="https://doi.org/10.1137/23M1588901">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work is concerned with the kernel-based approximation of a complex-valued function from data, where the response function of a partial differential equation in the frequency domain is of particular interest. In this setting, kernel methods are employed more and more frequently; however, standard kernels do not perform well. Moreover, the role and mathematical implications of the underlying pair of kernels, which arise naturally in the complex-valued case, remain to be addressed. We introduce new reproducing kernel Hilbert spaces of complex-valued functions and formulate the problem of complex-valued interpolation with a kernel pair as minimum-norm interpolation in these spaces. Moreover, we combine the interpolant with a low-order rational function, where the order is adaptively selected based on a new model selection criterion. Numerical results on examples from different fields, including electromagnetics and acoustics examples, illustrate the performance of the method in comparison to available rational approximation methods. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://zenodo.org/records/12601365 and in the supplementary materials (M158890_SuppMat.pdf [401KB]).},
  archive      = {J_SISC},
  author       = {Julien Bect and Niklas Georg and Ulrich Römer and Sebastian Schöps},
  doi          = {10.1137/23M1588901},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3727-A3755},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Rational kernel-based interpolation for complex-valued frequency response functions},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shape optimization under a constraint on the worst-case
scenario. <em>SISC</em>, <em>46</em>(6), A3703–A3726. (<a
href="https://doi.org/10.1137/24M1648818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work falls within the general framework of robust shape optimization under constraints, where a physical parameter of the problem is poorly known. In particular, we study problems where one of the constraints concerns the maximal possible value that a given shape functional can assume when the uncertain parameter varies within an admissible range. Two different approaches are considered: the first one based on the approximation of the set of admissible uncertain parameters by a convex polyhedron, and the second one relying on the notion of subdifferential in the sense of Clarke. The main contributions of this work consist in the theoretical proof of convergence of the first approach under suitable hypotheses of convexity of the set of admissible parameters and of the constraint, and the adaptation of Clarke’s subdifferential in the context of robust shape optimization. The two techniques are compared numerically in three examples, with the objective of minimizing the volume of elastic structures under a constraint on the worst-case scenario for the mechanical compliance and the von Mises stress.},
  archive      = {J_SISC},
  author       = {Fabien Caubet and Marc Dambrine and Giulio Gargantini and Jérôme Maynadier},
  doi          = {10.1137/24M1648818},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3703-A3726},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Shape optimization under a constraint on the worst-case scenario},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). Two-level overlapping schwarz preconditioners with
universal coarse spaces for <span
class="math inline"><strong>2</strong><strong>m</strong></span>th-order
elliptic problems. <em>SISC</em>, <em>46</em>(6), A3681–A3702. (<a
href="https://doi.org/10.1137/24M1650247">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a novel universal construction of two-level overlapping Schwarz preconditioners for th-order elliptic boundary value problems, where is a positive integer. The word “universal” here signifies that the coarse space construction can be applied to any finite element discretization for any that satisfies some common assumptions. We present numerical results for conforming, nonconforming, and discontinuous Galerkin-type finite element discretizations for high-order problems to demonstrate the scalability of the proposed two-level overlapping Schwarz preconditioners.},
  archive      = {J_SISC},
  author       = {Jongho Park},
  doi          = {10.1137/24M1650247},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3681-A3702},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Two-level overlapping schwarz preconditioners with universal coarse spaces for \(\boldsymbol{2m}\)th-order elliptic problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse discrete empirical interpolation method: State
estimation from few sensors. <em>SISC</em>, <em>46</em>(6), A3658–A3680.
(<a href="https://doi.org/10.1137/24M1636344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The discrete empirical interpolation method (DEIM) estimates a function from its incomplete pointwise measurements. Unfortunately, DEIM suffers large interpolation errors when few measurements are available. Here, we introduce Sparse DEIM (S-DEIM) for accurately estimating a function even when very few measurements are available. To this end, S-DEIM leverages a kernel vector which has been neglected in previous DEIM-based methods. We derive theoretical error estimates for S-DEIM, showing its relatively small error when an optimal kernel vector is used. When the function is generated by a continuous-time dynamical system, we propose a data assimilation algorithm which approximates the optimal kernel vector using sparse observational time series. We prove that, under certain conditions, data assimilated S-DEIM converges exponentially fast towards the true state. We demonstrate the efficacy of our method on two numerical examples.},
  archive      = {J_SISC},
  author       = {Mohammad Farazmand},
  doi          = {10.1137/24M1636344},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3658-A3680},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Sparse discrete empirical interpolation method: State estimation from few sensors},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stability theory of TASE–runge–kutta methods with inexact
jacobian. <em>SISC</em>, <em>46</em>(6), A3628–A3657. (<a
href="https://doi.org/10.1137/24M1631869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper analyzes the stability of the class of time-accurate and highly-stable explicit Runge–Kutta (TASE-RK) methods, introduced in 2021 by Bassenne, Fu, and Mani [J. Comput. Phys., 424 (2021), 109847] for the numerical solution of stiff Initial value problems. Such numerical methods are easy to implement and require the solution of a limited number of linear systems per step, whose coefficient matrices involve the exact Jacobian of the problem. To significantly reduce the computational cost of TASE-RK methods without altering their consistency properties, it is possible to replace with a matrix (not necessarily tied to ) in their formulation, for instance, fixed for a certain number of consecutive steps or even constant. However, the stability properties of TASE-RK methods strongly depend on this choice, and so far have been studied assuming . In this manuscript, we theoretically investigate the conditional and unconditional stability of TASE-RK methods by considering arbitrary . To this end, we first split the Jacobian as . Then, through the use of stability diagrams and their connections with the field of values, we analyze both the case in which and are simultaneously diagonalizable and the case in which they are not necessarily simultaneously diagonalizable. Numerical experiments, conducted on partial differential equations arising from applications, show the correctness and utility of the theoretical results derived in the paper, as well as the good stability and efficiency of TASE-RK methods when is suitably chosen.},
  archive      = {J_SISC},
  author       = {Dajana Conte and Jesus Martin-Vaquero and Giovanni Pagano and Beatrice Paternoster},
  doi          = {10.1137/24M1631869},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3628-A3657},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Stability theory of TASE–Runge–Kutta methods with inexact jacobian},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A shape-newton method for free-boundary problems subject to
the bernoulli boundary condition. <em>SISC</em>, <em>46</em>(6),
A3599–A3627. (<a href="https://doi.org/10.1137/23M1590263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a shape-Newton method for solving generic free-boundary problems where one of the free-boundary conditions is governed by the nonlinear Bernoulli equation. The method is a Newton-like scheme that employs shape derivatives of the governing equations. In particular, we derive the shape derivative of the Bernoulli equation, which turns out to depend on the curvature in a nontrivial manner. The resulting shape-Newton method allows one to update the position of the free boundary by solving a special linear boundary-value problem at each iteration. We prove solvability of the linearized problem under certain conditions of the data. We verify the effectiveness of the shape-Newton approach applied to free-surface flow over a submerged triangular obstacle using a finite element method on a deforming mesh. We observe superlinear convergence behavior for our shape-Newton method as opposed to the unfavorable linear rate of traditional methods.},
  archive      = {J_SISC},
  author       = {Yiyun Fan and John Billingham and Kristoffer G. van der Zee},
  doi          = {10.1137/23M1590263},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3599-A3627},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A shape-newton method for free-boundary problems subject to the bernoulli boundary condition},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive stepsize algorithms for langevin dynamics.
<em>SISC</em>, <em>46</em>(6), A3574–A3598. (<a
href="https://doi.org/10.1137/24M1658590">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We discuss the design of an invariant measure-preserving transformation for the numerical treatment of Langevin dynamics based on a rescaling of time, with the goal of sampling from an invariant measure. Given an appropriate monitor function which characterizes the numerical difficulty of the problem as a function of the state of the system, this method allows stepsizes to be reduced only when necessary, facilitating efficient recovery of long-time behavior. We study both overdamped and underdamped Langevin dynamics. We investigate how an appropriate correction term that ensures preservation of the invariant measure should be incorporated into a numerical splitting scheme. Finally, we demonstrate the use of the technique on several model systems, including a Bayesian sampling problem with a steep prior. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://zenodo.org/records/11192969.},
  archive      = {J_SISC},
  author       = {A. Leroy and B. Leimkuhler and J. Latz and D. J. Higham},
  doi          = {10.1137/24M1658590},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3574-A3598},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Adaptive stepsize algorithms for langevin dynamics},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A rational filtering algorithm for sequences of shifted
symmetric linear systems with applications to frequency response
analysis. <em>SISC</em>, <em>46</em>(6), A3552–A3573. (<a
href="https://doi.org/10.1137/23M1578474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a numerical algorithm for the solution of a large number of shifted linear systems for which the system pencil is symmetric and definite and the shifts lie inside a given real interval. Extending an earlier method due to Meerbergen and Bai [SIAM J. Matrix Anal. Appl., 31 (2010), pp. 1642–1662], the algorithm uses a rational filter with poles at Chebyshev points to compute and deflate the components of the solution in the direction of eigenvectors of the system pencil corresponding to eigenvalues within the interval. It then solves the deflated systems for the remaining components using a Krylov subspace method with a preconditioner constructed by interpolating the factorizations at the filter poles. The algorithm parallelizes naturally. We demonstrate its effectiveness using matrix pencils from both model and real-world problems and discuss applications to frequency response analysis.},
  archive      = {J_SISC},
  author       = {Anthony P. Austin and Lior Horesh and Vassilis Kalantzis},
  doi          = {10.1137/23M1578474},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3552-A3573},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A rational filtering algorithm for sequences of shifted symmetric linear systems with applications to frequency response analysis},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Optimized schwarz waveform relaxation methods for the
telegrapher equation. <em>SISC</em>, <em>46</em>(6), A3528–A3551. (<a
href="https://doi.org/10.1137/24M1642962">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Schwarz waveform relaxation (SWR) methods are popular domain decomposition methods for solving time-dependent problems. Optimized SWR (OSWR) algorithms are a modern class of SWR algorithms using transmission conditions that exchange more information and involve parameters that can be used to optimize the convergence rate of OSWR. We present here an analysis of overlapping and nonoverlapping SWR and OSWR applied to the telegrapher equation. We derive explicit asymptotic expressions for the optimized parameters, and show their great impact on the convergence of OSWR. We also explain how closely the telegrapher equation is related to RLCG transmission line circuits, and construct new discretization schemes based on this relation, with stability and convergence analyses. We illustrate our theoretical results with numerical experiments.},
  archive      = {J_SISC},
  author       = {Mohammad D. Al-Khaleel and Martin J. Gander and Pratik M. Kumbhar},
  doi          = {10.1137/24M1642962},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3528-A3551},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Optimized schwarz waveform relaxation methods for the telegrapher equation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A BDF-spectral method for a class of nonlocal partial
differential equations with long time delay. <em>SISC</em>,
<em>46</em>(6), A3503–A3527. (<a
href="https://doi.org/10.1137/24M1629535">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we design a numerical method for a class of nonlocal partial differential equations with long time delay. The system involves a variable on , in which case for , a -dimensional problem is to be solved numerically, which is challenging, especially for or . We propose an effective numerical method: backward differentiation formula schemes and the Fourier spectral method are applied for time and space discretization, respectively, and the long time delay term is treated by the Laguerre spectral method. The unique solvability of the numerical schemes is proved, and the energy upper bound of the numerical solution for the long time is given by energy estimation. By applying the generalized Laguerre orthogonal projection, the error estimate is obtained within finite final time for the full discretization. Numerical experiments are applied to verify the energy bound and convergence order. Also, examples are given to show how the solutions evolve and approach the global attractor.},
  archive      = {J_SISC},
  author       = {Shuxun Shi and Xinyi Du and Wenbin Chen},
  doi          = {10.1137/24M1629535},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3503-A3527},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A BDF-spectral method for a class of nonlocal partial differential equations with long time delay},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy-dissipative spectral renormalization exponential
integrator method for gradient flow problems. <em>SISC</em>,
<em>46</em>(6), A3477–A3502. (<a
href="https://doi.org/10.1137/23M158190X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present a novel spectral renormalization exponential integrator method for solving gradient flow problems. Our method is specifically designed to simultaneously satisfy discrete analogues of the energy-dissipation laws and achieve high-order accuracy in time. To accomplish this, our method first incorporates the energy-dissipation law into the target gradient flow equation by introducing a time-dependent spectral renormalization (TDSR) factor. Then, the coupled equations are discretized using the spectral approximation in space and the exponential time differencing in time. Finally, the resulting fully discrete nonlinear system is decoupled and solved using the Picard iteration at each time step. Furthermore, we introduce an extra enforcing term into the system for updating the TDSR factor, which greatly relaxes the time-step size restriction of the proposed method and enhances its computational efficiency. Extensive numerical tests with various gradient flows are also presented to demonstrate the accuracy and effectiveness of our method as well as its high efficiency when combined with an adaptive time-stepping strategy for long-term simulations.},
  archive      = {J_SISC},
  author       = {Dianming Hou and Lili Ju and Zhonghua Qiao},
  doi          = {10.1137/23M158190X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3477-A3502},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Energy-dissipative spectral renormalization exponential integrator method for gradient flow problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Building hierarchies of semiclassical jacobi polynomials for
spectral methods in annuli. <em>SISC</em>, <em>46</em>(6), A3448–A3476.
(<a href="https://doi.org/10.1137/23M160846X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We discuss computing with hierarchies of families of (potentially weighted) semiclassical Jacobi polynomials which arise in the construction of multivariate orthogonal polynomials. In particular, we outline how to build connection and differentiation matrices with optimal complexity and compute analysis and synthesis operations in quasi-optimal complexity. We investigate a particular application of these results to constructing orthogonal polynomials in annuli, called the generalized Zernike annular polynomials, which lead to sparse discretizations of partial differential equations (PDEs). We compare against a scaled-and-shifted Chebyshev–Fourier series showing that in general the annular polynomials converge faster when approximating smooth functions and have better conditioning. We also construct a sparse spectral element method by combining disk and annulus cells, which is highly effective for solving PDEs with radially discontinuous variable coefficients and data. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://doi.org/10.5281/zenodo.8430270.},
  archive      = {J_SISC},
  author       = {Ioannis P. A. Papadopoulos and Timon S. Gutleb and Richard M. Slevinsky and Sheehan Olver},
  doi          = {10.1137/23M160846X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3448-A3476},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Building hierarchies of semiclassical jacobi polynomials for spectral methods in annuli},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Faster randomized partial trace estimation. <em>SISC</em>,
<em>46</em>(6), A3427–A3447. (<a
href="https://doi.org/10.1137/23M1620399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop randomized matrix-free algorithms for estimating partial traces, a generalization of the trace arising in quantum physics and chemistry. Our algorithm improves on the typicality-based approach used in [T. Chen and Y-C. Cheng, J. Chem. Phys., 157 (2022), 064106] by deflating important subspaces (e.g., corresponding to the low-energy eigenstates) explicitly. This results in a significant variance reduction, leading to several order-of-magnitude speedups over the previous state of the art. We then apply our algorithm to the study of the thermodynamics of several Heisenberg spin systems, particularly the entanglement spectrum and ergotropy.},
  archive      = {J_SISC},
  author       = {Tyler Chen and Robert Chen and Kevin Li and Skai Nzeuton and Yilu Pan and Yixin Wang},
  doi          = {10.1137/23M1620399},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3427-A3447},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Faster randomized partial trace estimation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multivariate rational approximation of functions with curves
of singularities. <em>SISC</em>, <em>46</em>(6), A3401–A3426. (<a
href="https://doi.org/10.1137/23M1626414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Functions with singularities are notoriously difficult to approximate with conventional approximation schemes. In computational applications, they are often resolved with low-order piecewise polynomials, multilevel schemes, or other types of grading strategies. Rational functions are an exception to this rule: for univariate functions with point singularities, such as branch points, rational approximations exist with root-exponential convergence in the rational degree. This is typically enabled by the clustering of poles near the singularity. Both the theory and computational practice of rational functions for function approximation have focused on the univariate case, with extensions to two dimensions via identification with the complex plane. Multivariate rational functions, i.e., quotients of polynomials of several variables, are relatively unexplored in comparison. Yet, apart from a steep increase in theoretical complexity, they also offer a wealth of opportunities. A first observation is that singularities of multivariate rational functions may be continuous curves of poles, rather than isolated ones. By generalizing the clustering of poles from points to curves, we explore constructions of multivariate rational approximations to functions with curves of singularities. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/NBoulle/MultivariateRational and in the supplementary materials (MultivariateRational.zip [57.5KB]).},
  archive      = {J_SISC},
  author       = {Nicolas Boullé and Astrid Herremans and Daan Huybrechs},
  doi          = {10.1137/23M1626414},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3401-A3426},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multivariate rational approximation of functions with curves of singularities},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new approach for designing well-balanced schemes for the
shallow water equations: A combination of conservative and primitive
formulations. <em>SISC</em>, <em>46</em>(6), A3375–A3400. (<a
href="https://doi.org/10.1137/23M1624610">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we introduce a novel approach for constructing robust, fully well-balanced numerical methods for the one-dimensional Saint-Venant system, both with and without the Manning friction term. Inspired by the method presented in [R. Abgrall, Commun. Appl. Math. Comput., 5 (2023), pp. 370–402], we first combine the conservative and primitive formulations of the studied hyperbolic system in a natural way. The solution is globally continuous and described by a combination of point and average values. The point and average values will then be evolved by two different forms of the studied Saint-Venant system, and we will show how to deal with the yield conservative and primitive forms in a well-balanced manner. The developed schemes are capable of exactly preserving both the still-water and the moving-water equilibria. We demonstrate the behavior of the proposed new scheme on several challenging examples.},
  archive      = {J_SISC},
  author       = {Rémi Abgrall and Yongle Liu},
  doi          = {10.1137/23M1624610},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3375-A3400},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A new approach for designing well-balanced schemes for the shallow water equations: A combination of conservative and primitive formulations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An entropy stable discontinuous galerkin method for the
spherical thermal shallow water equations. <em>SISC</em>,
<em>46</em>(6), A3353–A3374. (<a
href="https://doi.org/10.1137/24M1638938">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a novel discontinuous Galerkin finite element method for numerical simulations of the rotating thermal shallow water equations in complex geometries using curvilinear meshes, with arbitrary accuracy. We derive the buoyancy variance which is convex and defines an entropy functional, and which must be preserved in order to preserve model stability at the discrete level. Our spatial discretization is provably entropy and energy stable, and the fully discrete method conserves mass, buoyancy, and vorticity. This is achieved by using novel entropy stable numerical fluxes, the summation-by-parts principle, and splitting the pressure and convection operators so that we can circumvent the use of chain rule at the discrete level. Numerical simulations on a cubed sphere mesh are presented to verify the theoretical results. The numerical experiments demonstrate the robustness of the method for a regime of well developed turbulence, where it can be run stably without any dissipation. The entropy stable fluxes are sufficient to control the grid scale noise generated by geostrophic turbulence, eliminating the need for artificial stabilization. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and Data Available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/kieranricardo/dg-tswe-paper.git and in the supplementary materials (M163893_SM.zip [ 76.9KB]).},
  archive      = {J_SISC},
  author       = {Kieran Ricardo and Kenneth Duru and David Lee},
  doi          = {10.1137/24M1638938},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {12},
  number       = {6},
  pages        = {A3353-A3374},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An entropy stable discontinuous galerkin method for the spherical thermal shallow water equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special section: 2023 copper mountain conference.
<em>SISC</em>, <em>46</em>(5), Siii. (<a
href="https://doi.org/10.1137/24M1681707">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SISC},
  author       = {Eric C. Cyr and Scott MacLachlan},
  doi          = {10.1137/24M1681707},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {Siii},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Special section: 2023 copper mountain conference},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Diagonalization-based preconditioners and generalized
convergence bounds for ParaOpt. <em>SISC</em>, <em>46</em>(5),
S317–S345. (<a href="https://doi.org/10.1137/23M1571423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The ParaOpt algorithm was recently introduced as a time-parallel solver for optimal-control problems with a terminal-cost objective, and convergence results have been presented for the linear diffusive case with implicit-Euler time integrators. We reformulate ParaOpt for tracking problems and provide generalized convergence analyses for both objectives. We focus on linear diffusive equations and prove convergence bounds that are generic in the time integrators used. For large problem dimensions, ParaOpt’s performance depends crucially on having a good preconditioner to solve the arising linear systems. For the case where ParaOpt’s cheap, coarse-grained propagator is linear, we introduce diagonalization-based preconditioners inspired by recent advances in the ParaDiag family of methods. These preconditioners not only lead to a weakly scalable ParaOpt version, but are themselves invertible in parallel, making maximal use of available concurrency. They have proven convergence properties in the linear diffusive case that are generic in the time discretization used, similarly to our ParaOpt results. Numerical results confirm that the iteration count of the iterative solvers used for ParaOpt’s linear systems becomes constant in the limit of an increasing processor count. The paper is accompanied by a sequential MATLAB implementation. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://gitlab.kuleuven.be/numa/public/pintopt and in the supplementary materials (pintopt-master.zip [32.2KB]).},
  archive      = {J_SISC},
  author       = {Arne Bouillon and Giovanni Samaey and Karl Meerbergen},
  doi          = {10.1137/23M1571423},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S317-S345},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Diagonalization-based preconditioners and generalized convergence bounds for ParaOpt},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reducing operator complexity of galerkin coarse-grid
operators with machine learning. <em>SISC</em>, <em>46</em>(5),
S296–S316. (<a href="https://doi.org/10.1137/23M1583533">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a data-driven and machine-learning-based approach to compute non-Galerkin coarse-grid operators in multigrid (MG) methods, addressing the well-known issue of increasing operator complexity. Guided by the MG theory on spectrally equivalent coarse-grid operators, we have developed novel machine learning algorithms that utilize neural networks combined with smooth test vectors from multigrid eigenvalue problems. The proposed method demonstrates promise in reducing the complexity of coarse-grid operators while maintaining overall MG convergence for solving parametric partial differential equation problems. Numerical experiments on anisotropic rotated Laplacian and linear elasticity problems are provided to showcase the performance and comparison with existing methods for computing non-Galerkin coarse-grid operators. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/liruipeng/SparseCoarseOperator.},
  archive      = {J_SISC},
  author       = {Ru Huang and Kai Chang and Huan He and Ruipeng Li and Yuanzhe Xi},
  doi          = {10.1137/23M1583533},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S296-S316},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Reducing operator complexity of galerkin coarse-grid operators with machine learning},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multigrid preconditioning for regularized least-squares
problems. <em>SISC</em>, <em>46</em>(5), S271–S295. (<a
href="https://doi.org/10.1137/23M1583417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we are concerned with efficiently solving the sequences of regularized linear least-squares problems associated with employing Tikhonov-type regularization with regularization operators designed to enforce edge recovery. An optimal regularization parameter, which balances the fidelity to the data with the edge-enforcing constraint term, is typically not known a priori. This adds to the total number of regularized linear least-squares problems that must be solved before the final image can be recovered. Therefore, in this paper, we determine effective multigrid preconditioners for these sequences of systems. We focus our approach on the sequences that arise as a result of the edge-preserving method introduced in [S. Gazzola et al., Inverse Problems, 36 (2020), 124004], where we can exploit an interpretation of the regularization term as a diffusion operator; however, our methods are also applicable in other edge-preserving settings, such as iteratively reweighted least-squares problems. Particular attention is paid to the selection of components of the multigrid preconditioner in order to achieve robustness for different ranges of the regularization parameter value. In addition, we present a parameter trimming approach that, when used with the L-curve heuristic, reduces the total number of solves required. We demonstrate our preconditioning and parameter trimming routines on examples in computed tomography and image deblurring.},
  archive      = {J_SISC},
  author       = {Matthias Bolten and Misha E. Kilmer and Scott MacLachlan},
  doi          = {10.1137/23M1583417},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S271-S295},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multigrid preconditioning for regularized least-squares problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient GMRES+AMG on GPUs: Composite smoothers and mixed
<span class="math inline"><strong>V</strong></span>-cycles.
<em>SISC</em>, <em>46</em>(5), S246–S270. (<a
href="https://doi.org/10.1137/23M1578632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this study, we introduce algorithms optimized for GPU architectures, aimed at efficiently solving large sparse linear systems, a central challenge in Navier–Stokes pressure projection problems. Our approach includes an adaptation of the GMRES algorithm, drawing inspiration from the merged vector operations first proposed by Bielich et al. [Parallel Comput., 112 (2022), 102940]. This adaptation increases computational intensity on GPU platforms through optimized vector update strategies. The algorithm incorporates modified and classical Gram–Schmidt methods with an algebraic multigrid (AMG) preconditioner, each tailored for GPU performance. A key innovation in our work is the development of a Gram–Schmidt projector employing a rank-1 perturbation of the identity matrix. Designed to maximize the high memory bandwidth utilization of the AMD MI-250X GPU, this approach includes a strategy for treating the unit diagonal that minimizes memory reads, leading to a 25% increase in computational efficiency. The application of perturbation theory further ensures that orthogonality loss is limited to , where is the number of iterations. Additionally, we introduce a mixed AMG -cycle strategy combining ILU(0) and -Jacobi smoothers, which achieves a 30–50% reduction in GPU compute times compared to conventional methods, while maintaining low backward error. This strategy, alongside our novel treatment of the diagonal in triangular matrices, marks a substantial increase in AMG efficicency for GPU systems. We believe that these contributions represent a significant advance in optimizing GMRES+AMG algorithms for GPU computations. The empirical results demonstrate notable speed increments and maintain rigorous backward error bounds, underscoring the potential of our methods to substantially increase computational efficiency in large-scale scientific applications.},
  archive      = {J_SISC},
  author       = {Stephen Thomas and Allison H. Baker},
  doi          = {10.1137/23M1578632},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S246-S270},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient GMRES+AMG on GPUs: Composite smoothers and mixed \(\boldsymbol{V}\)-cycles},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A first-order reduced model for a highly oscillating
differential equation with application in penning traps. <em>SISC</em>,
<em>46</em>(5), S225–S245. (<a
href="https://doi.org/10.1137/23M158351X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We derive a reduced first-order model from a two-scale asymptotic expansion in a small parameter in order to approximate the solution of a stiff differential equation. The problem of interest is a multiscale Newton–Lorentz equation modeling the dynamics of a charged particle under the influence of a linear electric field and of a perturbed strong magnetic field. First, we show that in short times, the first-order model provides a much better approximation than the zero-order one, since it contains terms evolving at slow time scales. Then, thanks to the source-free property of the equations, we propose a volume-preserving method using a particular splitting technique to solve numerically the first-order model. Finally, it turns out that the first-order model does not systematically provide a satisfactory approximation in long times. To overcome this issue, we implement a recent strategy based on the Parareal algorithm, in which the first-order approximation is used for the coarse solver. This approach allows one to perform efficient and accurate long-time simulations for any small parameter. Numerical results for two realistic Penning traps are provided to support these statements.},
  archive      = {J_SISC},
  author       = {Sever A. Hirstoaga},
  doi          = {10.1137/23M158351X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S225-S245},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A first-order reduced model for a highly oscillating differential equation with application in penning traps},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multigrid methods using block floating point arithmetic.
<em>SISC</em>, <em>46</em>(5), S202–S224. (<a
href="https://doi.org/10.1137/23M1581819">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Block floating point (BFP) arithmetic is currently seeing a resurgence in interest because it requires less power and less chip area and is less complicated to implement in hardware than standard floating point arithmetic. This paper explores the application of BFP to mixed- and progressive-precision multigrid methods, enabling the solution of linear elliptic partial differential equations (PDEs) in energy- and hardware-efficient integer arithmetic. While most existing applications of BFP arithmetic tend to use small block sizes, the block size here is chosen to be maximal such that matrices and vectors share a single exponent for all entries. This is sometimes also referred to as a scaled fixed point format. We provide algorithms for BLAS-like routines for BFP arithmetic that ensure exact vector-vector and matrix-vector computations up to a specified precision. Using these algorithms, we study the asymptotic precision requirements for achieving discretization-error-accuracy. We demonstrate that some computations can be performed using only 4-bit integers, while the number of bits required to attain a certain target accuracy is similar to that of standard floating point arithmetic. Finally, we present a heuristic for full multigrid in BFP arithmetic based on saturation and truncation that still achieves discretization-error-accuracy without the need for expensive normalization steps of intermediate results.},
  archive      = {J_SISC},
  author       = {Nils Kohl and Stephen F. McCormick and Rasmus Tamstorf},
  doi          = {10.1137/23M1581819},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S202-S224},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multigrid methods using block floating point arithmetic},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable multiphysics block preconditioning for low mach
number compressible resistive MHD with application to magnetic
confinement fusion. <em>SISC</em>, <em>46</em>(5), S170–S201. (<a
href="https://doi.org/10.1137/23M1582667">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This study investigates multiphysics block preconditioners that are critical in devising scalable Newton–Krylov iterative solvers for longer time-scale fully implicit fluid plasma models. The specific model of interest is the visco-resistive, low Mach number, compressible magnetohydrodynamics (MHD) model. This model describes the dynamics of conducting fluids in the presence of electromagnetic fields and can be used to study aspects of astrophysical phenomena, important science and technology applications, and basic plasma physics. The specific application of interest that motivates this study is the macroscopic simulation of longer time-scale stability and disruptions of magnetic confinement fusion devices, specifically the ITER Tokamak. The computational solution of the governing balance equations for mass, momentum, heat transfer, and magnetic induction for resistive MHD systems can be extremely challenging. These difficulties arise from both the strong nonlinear, nonsymmetric coupling of fluid and electromagnetic phenomena as well as the significant range of time and length scales that the interactions of these physical mechanisms produce. To handle the range of time and spatial scales of interest, a fully implicit unstructured variational multiscale finite element formulation is employed. For the scalable solution of the Newton linearized systems, fully coupled block preconditioners are designed to leverage algebraic multigrid subsolves. Results are presented for the strong and weak scaling of the method as well as the robustness of these techniques for a large range of Lundquist numbers.},
  archive      = {J_SISC},
  author       = {Peter Ohm and Jesus Bonilla and Edward Phillips and John N. Shadid and Michael Crockatt and Ray S. Tuminaro and Jonathan Hu and Xian-Zhu Tang},
  doi          = {10.1137/23M1582667},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S170-S201},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Scalable multiphysics block preconditioning for low mach number compressible resistive MHD with application to magnetic confinement fusion},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Fault-tolerant parallel multigrid method on unstructured
adaptive mesh. <em>SISC</em>, <em>46</em>(5), S145–S169. (<a
href="https://doi.org/10.1137/23M1582904">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. As the generation of exascale high-performance clusters begins, it has become evident that numerical algorithms will greatly benefit from built-in resilience features that can handle system faults. Prior studies of fault-tolerant multigrid methods have focused on structured grids. In this work, however, we study the resilience of multigrid solvers on unstructured grids with adaptive refinement. The challenge lies in the fact that unstructured grids distributed across multiple processors may manifest as local hierarchical grids with unaligned boundaries. Our numerical experiments highlight that this disparity can result in divergence when employing standard local multigrid for fault recovery. We analyze this phenomenon by using an energy control condition. To tackle the divergence issue, we propose a simple variation of the multigrid V-cycle that scales the coarse problem. We present a convergence proof for the new algorithm. By implementing this new method for local recovery, our numerical experiments confirm that convergence can be recovered on unstructured grids while the algorithm agrees with the standard multigrid V-cycle on grids with aligned boundaries. More importantly, the impact of a fault can be mitigated and delays in the global multigrid iterations can be reduced. Finally, we investigate how local regions within the adaptive mesh, associated with different faulty processors, affect the effectiveness of fault recovery.},
  archive      = {J_SISC},
  author       = {Frederick Fung and Linda Stals and Quanling Deng},
  doi          = {10.1137/23M1582904},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S145-S169},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Fault-tolerant parallel multigrid method on unstructured adaptive mesh},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multigrid-augmented deep learning preconditioners for the
helmholtz equation using compact implicit layers. <em>SISC</em>,
<em>46</em>(5), S123–S144. (<a
href="https://doi.org/10.1137/23M1583302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a deep learning–based iterative approach to solve the discrete heterogeneous Helmholtz equation for high wavenumbers. Combining classical iterative multigrid solvers and convolutional neural networks (CNNs) via preconditioning, we obtain a faster, learned neural solver that scales better than a standard multigrid solver. Our approach offers three main contributions over previous neural methods of this kind. First, we construct a multilevel U-Net-like encoder-solver CNN with an implicit layer on the coarsest grid of the U-Net, where convolution kernels are inverted. This alleviates the field of view problem in CNNs and allows better scalability. Second, we improve upon the previous CNN preconditioner in terms of the number of parameters, computation time, and convergence rates. Third, we propose a multiscale training approach that enables the network to scale to problems of previously unseen dimensions while still maintaining a reasonable training procedure. Our encoder-solver architecture can be used to generalize over different slowness models of various difficulties and is efficient at solving for many right-hand sides per slowness model. We demonstrate the benefits of our novel architecture with numerical experiments on various heterogeneous two-dimensional problems at high wavenumbers.},
  archive      = {J_SISC},
  author       = {Bar Lerer and Ido Ben-Yair and Eran Treister},
  doi          = {10.1137/23M1583302},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S123-S144},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multigrid-augmented deep learning preconditioners for the helmholtz equation using compact implicit layers},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Constrained local approximate ideal restriction for
advection-diffusion problems. <em>SISC</em>, <em>46</em>(5), S96–S122.
(<a href="https://doi.org/10.1137/23M1583442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper focuses on developing a reduction-based algebraic multigrid (AMG) method that is suitable for solving general (non)symmetric linear systems and is naturally robust from pure advection to pure diffusion. Initial motivation comes from a new reduction-based AMG approach, (local approximate ideal restriction), that was developed for solving advection-dominated problems. Though this new solver is very effective in the advection-dominated regime, its performance degrades in cases where diffusion becomes dominant. This is consistent with the fact that in general, reduction-based AMG methods tend to suffer from growth in complexity and/or convergence rates as the problem size is increased, especially for diffusion-dominated problems in two or three dimensions. Motivated by the success of in the advective regime, our aim in this paper is to generalize the AIR framework with the goal of improving the performance of the solver in diffusion-dominated regimes. To do so, we propose a novel way to combine mode constraints as used commonly in energy-minimization AMG methods with the local approximation of ideal operators used in . The resulting constrained algorithm is able to achieve fast scalable convergence on advective and diffusive problems. In addition, it is able to achieve standard low complexity hierarchies in the diffusive regime through aggressive coarsening, something that was previously difficult for reduction-based methods.},
  archive      = {J_SISC},
  author       = {Ahsan Ali and James J. Brannick and Karsten Kahl and Oliver A. Krzysik and Jacob B. Schroder and Ben S. Southworth},
  doi          = {10.1137/23M1583442},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S96-S122},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Constrained local approximate ideal restriction for advection-diffusion problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rounding-error analysis of multigrid <span
class="math inline"><em>V</em></span>-cycles. <em>SISC</em>,
<em>46</em>(5), S88–S95. (<a
href="https://doi.org/10.1137/23M1582898">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Earlier work on rounding-error analysis of multigrid was restricted to cycles that used one relaxation step before coarsening and none afterwards. The present paper extends this analysis to two-grid methods that use one relaxation step both before and after coarsening. The analysis is based on floating point arithmetic and focuses on a two-grid scheme that is perturbed on the coarse grid to allow for an approximate coarse-grid solve. Leveraging previously published results, this two-grid theory can then be extended to general -cycles, as well as full multigrid. It can also be extended to mixed-precision iterative refinement based on these cycles. An added benefit of the theory here over previous work is that it is obtained in a more organized, transparent, and simpler way.},
  archive      = {J_SISC},
  author       = {Stephen F. McCormick and Rasmus Tamstorf},
  doi          = {10.1137/23M1582898},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S88-S95},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Rounding-error analysis of multigrid \({V}\)-cycles},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A reduced conjugate gradient basis method for fractional
diffusion. <em>SISC</em>, <em>46</em>(5), S68–S87. (<a
href="https://doi.org/10.1137/23M1575913">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work is on a fast and accurate reduced basis method for solving discretized fractional elliptic partial differential equations (PDEs) of the form by rational approximation. A direct computation of the action of such an approximation would require solving multiple (2030) large-scale sparse linear systems. Our method constructs the reduced basis using the first few directions obtained from the preconditioned conjugate gradient method applied to one of the linear systems. As shown in the theory and experiments, only a small number of directions (510) are needed to approximately solve all large-scale systems on the reduced basis subspace. This reduces the computational cost dramatically because: (1) We only use one of the large-scale problems to construct the basis; and (2) all large-scale problems restricted to the subspace have much smaller sizes. We test our algorithms for fractional PDEs on a 3d Euclidean domain, a 2d surface, and random combinatorial graphs. We also use a novel approach to construct the rational approximation for the fractional power function by the orthogonal greedy algorithm (OGA). Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/yuwenli925/RCGBM and in the supplementary materials (RCGBM-main.zip [19.8KB]).},
  archive      = {J_SISC},
  author       = {Yuwen Li and Ludmil Zikatanov and Cheng Zuo},
  doi          = {10.1137/23M1575913},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S68-S87},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A reduced conjugate gradient basis method for fractional diffusion},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Enhancing training of physics-informed neural networks using
domain decomposition–based preconditioning strategies. <em>SISC</em>,
<em>46</em>(5), S46–S67. (<a
href="https://doi.org/10.1137/23M1583375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose to enhance the training of physics-informed neural networks. To this aim, we introduce nonlinear additive and multiplicative preconditioning strategies for the widely used L-BFGS optimizer. The nonlinear preconditioners are constructed by utilizing the Schwarz domain decomposition framework, where the parameters of the network are decomposed in a layerwise manner. Through a series of numerical experiments, we demonstrate that both additive and multiplicative preconditioners significantly improve the convergence of the standard L-BFGS optimizer while providing more accurate solutions of the underlying PDEs. Moreover, the additive preconditioner is inherently parallel, thus giving rise to a novel approach to model parallelism.},
  archive      = {J_SISC},
  author       = {Alena Kopaničáková and Hardik Kothari and George E. Karniadakis and Rolf Krause},
  doi          = {10.1137/23M1583375},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S46-S67},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Enhancing training of physics-informed neural networks using domain Decomposition–Based preconditioning strategies},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the convergence of monolithic multigrid for implicit
runge–kutta time stepping of finite element problems. <em>SISC</em>,
<em>46</em>(5), S22–S45. (<a
href="https://doi.org/10.1137/23M1569344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Finite element discretizations of time-dependent problems also require effective time-stepping schemes. While implicit Runge–Kutta methods provide favorable accuracy and stability properties, they give rise to large and complicated systems of equations to solve for each time step. These algebraic systems couple all Runge–Kutta stages together, giving a much larger system than for single-stage methods. We consider an approach to these systems based on monolithic smoothing. If stage-coupled smoothers possess a certain kind of structure, then the question of convergence of a two-grid or multigrid iteration reduces to convergence of a related strategy for a single-stage system with a complex-valued time step. In addition to providing a general theoretical approach to the convergence of monolithic multigrid methods, several numerical examples are given to illustrate the theory and show how higher-order Runge–Kutta methods can be made effective in practice. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and Data Available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/rckirby/CodeForMMGPaper as well as in the supplemental material.},
  archive      = {J_SISC},
  author       = {Robert C. Kirby},
  doi          = {10.1137/23M1569344},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S22-S45},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On the convergence of monolithic multigrid for implicit Runge–Kutta time stepping of finite element problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). LFA-tuned matrix-free multigrid method for the elastic
helmholtz equation. <em>SISC</em>, <em>46</em>(5), S1–S21. (<a
href="https://doi.org/10.1137/23M1583466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present an efficient matrix-free geometric multigrid method for the elastic Helmholtz equation, and a suitable discretization. Many discretization methods had been considered in the literature for the Helmholtz equations, as well as many solvers and preconditioners, some of which are adapted for the elastic version of the equation. However, there is very little work considering the reciprocity of discretization and a solver. In this work, we aim to bridge this gap. By choosing an appropriate stencil for rediscretization of the equation on the coarse grid, we develop a multigrid method that can be easily implemented as matrix-free, relying on stencils rather than sparse matrices. This is crucial for efficient implementation on modern hardware. Using two-grid local Fourier analysis, we validate the compatibility of our discretization with our solver, and tune a choice of weights for the stencil for which the convergence rate of the multigrid cycle is optimal. It results in a scalable multigrid preconditioner that can tackle large real-world three-dimensional scenarios.},
  archive      = {J_SISC},
  author       = {Rachel Yovel and Eran Treister},
  doi          = {10.1137/23M1583466},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {S1-S21},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {LFA-tuned matrix-free multigrid method for the elastic helmholtz equation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An accurate and efficient continuity-preserved method based
on randomized neural networks for elliptic interface problems.
<em>SISC</em>, <em>46</em>(5), C633–C657. (<a
href="https://doi.org/10.1137/24M1632309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, based on the extreme learning machine idea and randomized neural networks, a new continuity-preserved method is proposed to efficiently and accurately solve linear and nonlinear elliptic interface problems. For linear interface problems, an error estimate including an approximation error and a statistical error is established for shallow randomized neural networks with the activation function . Especially, the approximation error under the norm is given for the first time to the best of the authors’ knowledge. For nonlinear cases, a novel multilevel method is further proposed to significantly improve efficiency. Various numerical tests on different examples are carried out to verify the proposed method, not only showing it can outperform classical numerical methods in terms of accuracy, but also illustrating its effectiveness, especially the improvements of the multilevel method in terms of computational costs.},
  archive      = {J_SISC},
  author       = {Jinyong Ying and Jingying Hu and Zuoshunhua Shi and Jiao Li},
  doi          = {10.1137/24M1632309},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {C633-C657},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An accurate and efficient continuity-preserved method based on randomized neural networks for elliptic interface problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning in-between imagery dynamics via physical latent
spaces. <em>SISC</em>, <em>46</em>(5), C608–C632. (<a
href="https://doi.org/10.1137/23M1609440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a framework designed to learn the underlying dynamics between two images observed at consecutive time steps. The complex nature of image data and the lack of temporal information pose significant challenges in capturing the unique evolving patterns. Our proposed method focuses on estimating the intermediary stages of image evolution, allowing for interpretability through latent dynamics while preserving spatial correlations with the image. By incorporating a latent variable that follows a physical model expressed in partial differential equations, our approach ensures the interpretability of the learned model and provides insight into corresponding image dynamics. We demonstrate the robustness and effectiveness of our learning framework through a series of numerical tests using geoscientific imagery data.},
  archive      = {J_SISC},
  author       = {Jihun Han and Yoonsang Lee and Anne Gelb},
  doi          = {10.1137/23M1609440},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {C608-C632},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Learning in-between imagery dynamics via physical latent spaces},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinear embeddings for conserving hamiltonians and other
quantities with neural galerkin schemes. <em>SISC</em>, <em>46</em>(5),
C583–C607. (<a href="https://doi.org/10.1137/23M1607799">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work focuses on the conservation of quantities such as Hamiltonians, mass, and momentum when solution fields of partial differential equations are approximated with nonlinear parametrizations such as deep networks. The proposed approach builds on Neural Galerkin schemes that are based on the Dirac–Frenkel variational principle to train nonlinear parametrizations sequentially in time. We first show that only adding constraints that aim to conserve quantities in continuous time can be insufficient because the nonlinear dependence on the parameters implies that even quantities that are linear in the solution fields become nonlinear in the parameters and thus are challenging to discretize in time. Instead, we propose Neural Galerkin schemes that compute at each time step an explicit embedding onto the manifold of nonlinearly parametrized solution fields to guarantee conservation of quantities. The embeddings can be combined with standard explicit and implicit time integration schemes. Numerical experiments demonstrate that the proposed approach conserves quantities up to machine precision.},
  archive      = {J_SISC},
  author       = {Paul Schwerdtner and Philipp Schulze and Jules Berman and Benjamin Peherstorfer},
  doi          = {10.1137/23M1607799},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {C583-C607},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Nonlinear embeddings for conserving hamiltonians and other quantities with neural galerkin schemes},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A domain decomposition–based CNN-DNN architecture for model
parallel training applied to image recognition problems. <em>SISC</em>,
<em>46</em>(5), C557–C582. (<a
href="https://doi.org/10.1137/23M1562202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Deep neural networks (DNNs) and, in particular, convolutional neural networks (CNNs) have brought significant advances in a wide range of modern computer application problems. However, the increasing availability of large numbers of datasets and the increasing available computational power of modern computers have led to steady growth in the complexity and size of DNN and CNN models, respectively, and thus, to longer training times. Hence, various methods and attempts have been developed to accelerate and parallelize the training of complex network architectures. In this work, a novel CNN-DNN architecture is proposed that naturally supports a model parallel training strategy and that is loosely inspired by two-level domain decomposition methods (DDMs). First, local CNN models, that is, subnetworks, are defined that operate on overlapping or nonoverlapping parts of the input data, for example, subimages. The subnetworks can be trained completely in parallel and independently of each other. Each subnetwork then outputs a local decision for the given machine learning problem which is exclusively based on the respective local input data. Subsequently, in a second step, an additional DNN model is trained which evaluates the local decisions of the local subnetworks and generates a final, global decision. With respect to the analogy to DDMs, the DNN models can be loosely interpreted as a coarse problem and hence, the new approach can be interpreted as a two-level domain decomposition. In this paper, we apply the proposed architecture to image classification problems using CNNs. Experimental results for different two-dimensional image classification problems are provided, as well as a face recognition problem and a classification problem for three-dimensional computed tomography (CT) scans. Therefore, classical Residual Network (ResNet) and VGG architectures are considered. More modern architectures, such as, e.g., MobileNet2, are left for future work. The results show that the proposed approach can significantly accelerate the required training time compared to the global model and, additionally, can also help to improve the accuracy of the underlying classification problem.},
  archive      = {J_SISC},
  author       = {Axel Klawonn and Martin Lanser and Janine Weber},
  doi          = {10.1137/23M1562202},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {C557-C582},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A domain Decomposition–Based CNN-DNN architecture for model parallel training applied to image recognition problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A neural network approach for stochastic optimal control.
<em>SISC</em>, <em>46</em>(5), C535–C556. (<a
href="https://doi.org/10.1137/23M155832X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a neural network approach for approximating the value function of high-dimensional stochastic control problems. Our training process simultaneously updates our value function estimate and identifies the part of the state space likely to be visited by optimal trajectories. Our approach leverages insights from optimal control theory and the fundamental relation between semilinear parabolic partial differential equations and forward-backward stochastic differential equations. To focus the sampling on relevant states during neural network training, we use the stochastic Pontryagin maximum principle (PMP) to obtain the optimal controls for the current value function estimate. By design, our approach coincides with the method of characteristics for the nonviscous Hamilton–Jacobi–Bellman equation arising in deterministic control problems. Our training loss consists of a weighted sum of the objective functional of the control problem and penalty terms that enforce the HJB equations along the sampled trajectories. Importantly, training is unsupervised in that it does not require solutions of the control problem. Our numerical experiments highlight our scheme’s ability to identify the relevant parts of the state space and produce meaningful value estimates. Using a two-dimensional model problem, we demonstrate the importance of the stochastic PMP to inform the sampling and compare it to a finite element approach. With a nonlinear control affine quadcopter example, we illustrate that our approach can handle complicated dynamics. For a 100-dimensional benchmark problem, we demonstrate that our approach improves accuracy and time-to-solution, and, via a modification, we show the wider applicability of our scheme. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/EmoryMLIP/NeuralSOC and in the supplementary material (NeuralSOC-main.zip [ 29.9MB]).},
  archive      = {J_SISC},
  author       = {Xingjian Li and Deepanshu Verma and Lars Ruthotto},
  doi          = {10.1137/23M155832X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {C535-C556},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A neural network approach for stochastic optimal control},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A linearly implicit spectral scheme for the
three-dimensional hall-MHD system. <em>SISC</em>, <em>46</em>(5),
B752–B783. (<a href="https://doi.org/10.1137/23M1553844">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The inclusion of a Hall term brings many more challenges in the establishment of a numerical scheme for the Hall magnetohydrodynamics (Hall-MHD) system, compared to the classical MHD equations. For the incompressible Hall-MHD system in a three-dimensional domain, we aim at constructing an efficient numerical scheme with properties of linearity, adaptive variation of time-stepping, second-order time accuracy, decoupling, and unconditional energy stability. For this purpose, the Legendre–Galerkin spectral method is applied for spatial approximation. By introducing an artificial auxiliary variable, we employ the Crank–Nicolson scheme for temporal discretization with the explicit treatment of nonlinear terms. In addition, the second-order incremental pressure-correction method is utilized in the Stokes solver to reduce the cost of computation. Based on the energy dissipation rate of the Hall-MHD system, we design an adaptive time-stepping strategy to enhance efficiency. The unconditional energy stability of the fully discrete scheme is strictly proved, where the decoupled Stokes solver needs to be analyzed in detail. We also show that the scheme is divergence-free for magnetic fields if the corresponding initial condition is divergence-free. Numerical experiments are carried out to illustrate the accuracy, efficiency, and robustness of the proposed scheme. As for applications of our scheme, numerical simulations on the O- and X-points appearing in fast magnetic reconnection and on whistler waves are presented within the Hall-MHD regime.},
  archive      = {J_SISC},
  author       = {Shimin Guo and Liquan Mei and Wenjing Yan},
  doi          = {10.1137/23M1553844},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {B752-B783},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A linearly implicit spectral scheme for the three-dimensional hall-MHD system},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Scalable approximation and solvers for ionic
electrodiffusion in cellular geometries. <em>SISC</em>, <em>46</em>(5),
B725–B751. (<a href="https://doi.org/10.1137/24M1644717">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The activity and dynamics of excitable cells are fundamentally regulated and moderated by extracellular and intracellular ion concentrations and their electric potentials. The increasing availability of dense reconstructions of excitable tissue at extreme geometric detail pose a new and clear scientific computing challenge for computational modeling of ion dynamics and transport. In this paper, we design, develop and evaluate a scalable numerical algorithm for solving the time-dependent and nonlinear KNP-EMI (Kirchhoff–Nernst–Planck extracellular-membrane-intracellular) equations describing ionic electrodiffusion for excitable cells with an explicit geometric representation of intracellular and extracellular compartments and interior interfaces. We also introduce and specify a set of model scenarios of increasing complexity suitable for benchmarking. Our solution strategy is based on an implicit-explicit discretization and linearization in time; a mixed finite element discretization of ion concentrations and electric potentials in intracellular and extracellular domains; and an algebraic multigrid-based, inexact block-diagonal preconditioner for GMRES. Numerical experiments with up to unknowns per time step and up to 256 cores demonstrate that this solution strategy is robust and scalable with respect to the problem size, time discretization, and number of cores. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://zenodo.org/records/10790439.},
  archive      = {J_SISC},
  author       = {Pietro Benedusi and Ada Johanne Ellingsrud and Halvor Herlyng and Marie E. Rognes},
  doi          = {10.1137/24M1644717},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {B725-B751},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Scalable approximation and solvers for ionic electrodiffusion in cellular geometries},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Jet: Multilevel graph partitioning on graphics processing
units. <em>SISC</em>, <em>46</em>(5), B700–B724. (<a
href="https://doi.org/10.1137/23M1559129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The multilevel heuristic is the dominant strategy for high-quality sequential and parallel graph partitioning. Partition refinement is a key step of multilevel graph partitioning. In this work, we present Jet, a new parallel algorithm for partition refinement specifically designed for graphics processing units (GPUs). We combine Jet with GPU-aware coarsening to develop a -way graph partitioner, the Jet partitioner. The new partitioner achieves superior quality when compared to state-of-the-art shared memory partitioners on a large collection of test graphs. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available”, as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available in https://scholarsphere.psu.edu/resources/cc9dcf42-f5eb-42f1-80ec-5d50a402fc22 as well as in the supplementary material files Jet_Multilevel_Graph_Partitioning_on_Graphics_Processing_Units_Supplementary_Material.pdf [267KB and Jet-Partitioner.zip [47.9KB].},
  archive      = {J_SISC},
  author       = {Michael S. Gilbert and Kamesh Madduri and Erik G. Boman and Siva Rajamanickam},
  doi          = {10.1137/23M1559129},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {B700-B724},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Jet: Multilevel graph partitioning on graphics processing units},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterative methods of linearized moment equations for
rarefied gases. <em>SISC</em>, <em>46</em>(5), B669–B699. (<a
href="https://doi.org/10.1137/24M1634242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study the iterative methods for large moment systems derived from the linearized Boltzmann equation. By Fourier analysis, it is shown that the direct application of the block symmetric Gauss–Seidel (BSGS) method has slower convergence for smaller Knudsen numbers. Better convergence rates for dense flows are then achieved by coupling the BSGS method with the micro-macro decomposition, which treats the moment equations as a coupled system with a microscopic part and a macroscopic part. Since the macroscopic part contains only a small number of equations, it can be solved accurately during the iteration with a relatively small computational cost, which accelerates the overall iteration. The method is further generalized to the multiscale decomposition which splits the moment system into many subsystems with different orders of magnitude. Both one- and two-dimensional numerical tests are carried out to examine the performances of these methods. Possible issues regarding the efficiency and convergence are discussed in the conclusion.},
  archive      = {J_SISC},
  author       = {Xiaoyu Dong and Zhenning Cai},
  doi          = {10.1137/24M1634242},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {B669-B699},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Iterative methods of linearized moment equations for rarefied gases},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the optimal linear contraction order of tree tensor
networks, and beyond. <em>SISC</em>, <em>46</em>(5), B647–B668. (<a
href="https://doi.org/10.1137/23M161286X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The contraction cost of a tensor network depends on the contraction order. However, the optimal contraction ordering problem is known to be NP-hard. We show that the linear contraction ordering problem for tree tensor networks admits a polynomial-time algorithm, by drawing connections to database join ordering. The result relies on the adjacent sequence interchange property of the contraction cost, which enables a global decision of the contraction order based on local comparisons. Based on that, we specify a modified version of the IKKBZ database join ordering algorithm to find the optimal tree tensor network linear contraction order. Finally, we extend our algorithm as a heuristic to general contraction orders and arbitrary tensor network topologies. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/stoianmihail/netzwerk and in the supplementary materials (Netzwerk-main.zip [352KB]).},
  archive      = {J_SISC},
  author       = {Mihail Stoian and Richard M. Milbradt and Christian B. Mendl},
  doi          = {10.1137/23M161286X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {B647-B668},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On the optimal linear contraction order of tree tensor networks, and beyond},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A dual grid geometric electromagnetic particle in cell
method. <em>SISC</em>, <em>46</em>(5), B621–B646. (<a
href="https://doi.org/10.1137/23M1618910">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Geometric particle-in-cell discretizations have been derived based on a discretization of the fields that is conforming with the de Rham structure of the Maxwell’s equations and a standard particle-in-cell ansatz for the fields by deriving the equations of motion from a discrete action principle. While earlier work has focused on finite-element discretization of the fields based on the theory of finite-element exterior calculus, we propose in this article an alternative formulation of the field equations that is based on the ideas conveyed by mimetic finite differences, the needed duality being expressed by the use of staggered grids. We construct a finite-difference formulation based on degrees of freedom defined as point values, edge, face, and volume integrals on a primal and its dual grid. Compared to the finite-element formulation, no mass matrix inversion is involved in the formulation of the Maxwell solver. In numerical experiments, we verify the conservation properties of the novel method and study the influence of the various parameters in the discretization.},
  archive      = {J_SISC},
  author       = {Katharina Kormann and Eric Sonnendrücker},
  doi          = {10.1137/23M1618910},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {B621-B646},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A dual grid geometric electromagnetic particle in cell method},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Interpolating parametrized quantum circuits using blackbox
queries. <em>SISC</em>, <em>46</em>(5), B600–B620. (<a
href="https://doi.org/10.1137/23M1609543">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This article focuses on developing classical surrogates for parametrized quantum circuits using interpolation via (trigonometric) polynomials. We develop two algorithms for the construction of such surrogates and prove performance guarantees. The constructions are based on circuit evaluations which are blackbox in the sense that no structural specifics of the circuits are exploited. While acknowledging the limitations of the blackbox approach compared to whitebox evaluations, which exploit specific circuit properties, we demonstrate scenarios in which the blackbox approach might prove beneficial. Sample applications include but are not restricted to the approximation of variational quantum eigensolvers and the alleviaton of the barren plateau problem.},
  archive      = {J_SISC},
  author       = {Lars Simon and Holger Eble and Hagen-Henrik Kowalski and Manuel Radons},
  doi          = {10.1137/23M1609543},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {B600-B620},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Interpolating parametrized quantum circuits using blackbox queries},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bounds on nonlinear errors for variance computation with
stochastic rounding. <em>SISC</em>, <em>46</em>(5), B579–B599. (<a
href="https://doi.org/10.1137/23M1563001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The main objective of this work is to investigate nonlinear errors and pairwise summation using stochastic rounding (SR) in variance computation algorithms. We estimate the forward error of computations under SR through two methods: the first is based on a bound of the variance and the Bienaymé–Chebyshev inequality, while the second is based on martingales and the Azuma–Hoeffding inequality. The study shows that for pairwise summation, using SR results in a probabilistic bound of the forward error proportional to rather than the deterministic bound in when using the default rounding mode. We examine two algorithms that compute the variance, one called “textbook” and the other “two-pass,” which both exhibit nonlinear errors. Using the two methods mentioned above, we show that the forward errors of these algorithms have probabilistic bounds under SR in instead of for the deterministic bounds. We show that this advantage holds using pairwise summation for both textbook and two-pass, with probabilistic bounds of the forward error proportional to . Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow the reader to reproduce the results in this paper are available at https://github.com/verificarlo/sr-non-linear-bounds and in the supplementary material (sr-non-linear-bounds-main.zip [8.62KB]).},
  archive      = {J_SISC},
  author       = {E-M. El Arar and D. Sohier and P. de Oliveira Castro and E. Petit},
  doi          = {10.1137/23M1563001},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {B579-B599},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Bounds on nonlinear errors for variance computation with stochastic rounding},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An <span
class="math inline"><em>L</em><em>D</em><em>L</em><sup>T</sup></span>
trust-region quasi-newton method. <em>SISC</em>, <em>46</em>(5),
A3330–A3351. (<a href="https://doi.org/10.1137/23M1623380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For quasi-Newton methods in unconstrained minimization, it is valuable to develop methods that are robust, i.e., methods that converge on a large number of problems. Trust-region algorithms are often regarded to be more robust than line-search methods; however, because trust-region methods are computationally more expensive, the most popular quasi-Newton implementations use line-search methods. To fill this gap, we develop a trust-region method that updates an factorization, scales quadratically with the size of the problem, and is competitive with a conventional line-search method.},
  archive      = {J_SISC},
  author       = {Johannes J. Brust and Philip E. Gill},
  doi          = {10.1137/23M1623380},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3330-A3351},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An \({LDL}^{\textrm{T}}\) trust-region quasi-newton method},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nested sampling for uncertainty quantification and rare
event estimation. <em>SISC</em>, <em>46</em>(5), A3305–A3329. (<a
href="https://doi.org/10.1137/23M1607842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Nested sampling is a method for computing the Bayesian evidence, also called the marginal likelihood, which is the integral of the likelihood with respect to the prior. More generally, it is a numerical probabilistic quadrature rule. The main idea of nested sampling is to replace a high-dimensional likelihood integral over parameter space with an integral over the unit line by employing a push-forward with respect to a suitable transformation. Practically, a set of active samples ascends the level sets of the integrand function, with the measure contraction of the superlevel sets being statistically estimated. We justify the validity of this approach for integrands with nonnegligible plateaus and demonstrate nested sampling’s practical effectiveness in estimating the (log-)probability of rare events.},
  archive      = {J_SISC},
  author       = {Jonas Latz and Doris Schneider and Philipp Wacker},
  doi          = {10.1137/23M1607842},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3305-A3329},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Nested sampling for uncertainty quantification and rare event estimation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Boundary treatment for high-order IMEX runge–kutta local
discontinuous galerkin schemes for multidimensional nonlinear parabolic
PDEs. <em>SISC</em>, <em>46</em>(5), A3282–A3304. (<a
href="https://doi.org/10.1137/23M1612184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this article, we propose novel boundary treatment algorithms to avoid order reduction when implicit-explicit Runge–Kutta time discretization is used for solving convection-diffusion-reaction problems with time-dependent Dirichlet boundary conditions. We consider Cartesian meshes and PDEs with stiff terms coming from the diffusive parts of the PDE. The algorithms treat boundary values at the implicit-explicit internal stages in the same way as the interior points. The boundary treatment strategy is designed to work with multidimensional problems with possible nonlinear advection and source terms. The proposed methods recover the designed order of convergence by numerical verification. For the spatial discretization, in this work, we consider local discontinuous Galerkin methods, although the developed boundary treatment algorithms can operate with other discretization schemes in space, such as finite differences, finite elements, or finite volumes.},
  archive      = {J_SISC},
  author       = {Víctor González-Tabernero and José Germán López-Salas and Manuel Jesús Castro-Díaz and José Antonio García-Rodríguez},
  doi          = {10.1137/23M1612184},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3282-A3304},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Boundary treatment for high-order IMEX Runge–Kutta local discontinuous galerkin schemes for multidimensional nonlinear parabolic PDEs},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modifying the asynchronous jacobi method for data corruption
resilience. <em>SISC</em>, <em>46</em>(5), A3258–A3281. (<a
href="https://doi.org/10.1137/23M1605648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Moving scientific computation from high-performance computing (HPC) and cloud computing (CC) environments to devices on the edge, i.e., physically near instruments of interest, has received tremendous interest in recent years. Such edge computing environments can operate on data in situ, offering enticing benefits over data aggregation to HPC and CC facilities that include avoiding costs of transmission, increased data privacy, and real-time data analysis. Because of the inherent unreliability of edge computing environments, new fault-tolerant approaches must be developed before the benefits of edge computing can be realized. Motivated by algorithm-based fault tolerance, a variant of the asynchronous Jacobi (ASJ) method is developed that achieves resilience to data corruption by rejecting solution approximations from neighbor devices according to a bound derived from convergence theory. Numerical results on a two-dimensional Poisson problem show that the new rejection criterion, along with a novel approximation to the shortest path length on which the criterion depends, restores convergence for the ASJ variant in the presence of certain types data corruption. Numerical results are obtained for when the singular values in the analytic bound are approximated. Additional linear systems are also explored, one with a more dense sparsity pattern and one that includes advection. All results indicate that successful resilience to data corruption depends on whether the bound tightens fast enough to reject corrupted data before the iteration evolution deviates significantly from that predicted by the convergence theory defining the bound. This observation generalizes to future work on algorithm-based fault tolerance for other asynchronous algorithms, including upcoming approaches that leverage Krylov subspaces.},
  archive      = {J_SISC},
  author       = {Christopher J. Vogl and Zachary R. Atkins and Alyson Fox and Agnieszka Miȩdlar and Colin Ponce},
  doi          = {10.1137/23M1605648},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3258-A3281},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Modifying the asynchronous jacobi method for data corruption resilience},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Operator-splitting/finite element methods for the minkowski
problem. <em>SISC</em>, <em>46</em>(5), A3230–A3257. (<a
href="https://doi.org/10.1137/23M1590779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The classical Minkowski problem for convex bodies has deeply influenced the development of differential geometry. During the past several decades, abundant mathematical theories have been developed for studying the solutions of the Minkowski problem; however, the numerical solution of this problem has been largely left behind, with only a few methods available to achieve that goal. In this article, focusing on the two-dimensional Minkowski problem with Dirichlet boundary conditions, we introduce two solution methods, both based on operator-splitting. One of these two methods deals directly with the Dirichlet condition, while the other one uses an approximation à la Robin of this Dirichlet condition. The relaxation of the Dirichlet condition makes the second method better suited than the first one to treat those situations where the Minkowski equation (of Monge–Ampère type) and the Dirichlet condition are not compatible. Both methods are generalizations of the solution method for the canonical Monge–Ampère equation discussed by Glowinski et al. [J. Sci. Comput., 81 (2019), pp. 2271–2302]; as such they take advantage of a divergence formulation of the Minkowski problem, which makes it well suited to both a mixed finite-element approximation and the time-discretization via an operator-splitting scheme of an associated initial value problem. Our methodology can be easily implemented on convex domains of rather general shape (with curved boundaries, possibly). The numerical experiments validate both methods, showing that if one uses continuous piecewise affine finite-element approximations of the solution of the Minkowski problem and of its three second order derivatives, these two methods provide nearly second-order accuracy for the and norms of the approximation error, where the Minkowski–Dirichlet problem is assumed to have a smooth solution. One can easily extend the methods discussed in this article to address the solution of three-dimensional Minkowski problems.},
  archive      = {J_SISC},
  author       = {Hao Liu and Shingyu Leung and Jianliang Qian},
  doi          = {10.1137/23M1590779},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3230-A3257},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Operator-Splitting/Finite element methods for the minkowski problem},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Model order reduction of an ultraweak and optimally stable
variational formulation for parametrized reactive transport problems.
<em>SISC</em>, <em>46</em>(5), A3205–A3229. (<a
href="https://doi.org/10.1137/23M1613402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This contribution introduces a model order reduction approach for an advection-reaction problem with a parametrized reaction function. The underlying discretization uses an ultraweak formulation with an -like trial space and an “optimal” test space as introduced by Demkowicz et al. This ensures the stability of the discretization and in addition allows for a symmetric reformulation of the problem in terms of a dual solution which can also be interpreted as the normal equations of an adjoint least-squares problem. Classic model order reduction techniques can then be applied to the space of dual solutions which also immediately gives a reduced primal space. We show that the necessary computations do not require the reconstruction of any primal solutions and can instead be performed entirely on the space of dual solutions. We prove exponential convergence of the Kolmogorov -width and show that a greedy algorithm produces quasi-optimal approximation spaces for both the primal and the dual solution spaces. Numerical experiments based on the benchmark problem of a catalytic filter confirm the applicability of the proposed method. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://www.doi.org/10.5281/zenodo.10048126.},
  archive      = {J_SISC},
  author       = {Christian Engwer and Mario Ohlberger and Lukas Renelt},
  doi          = {10.1137/23M1613402},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3205-A3229},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Model order reduction of an ultraweak and optimally stable variational formulation for parametrized reactive transport problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A registration method for reduced basis problems using
linear optimal transport. <em>SISC</em>, <em>46</em>(5), A3177–A3204.
(<a href="https://doi.org/10.1137/23M1570715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a registration method for model reduction of parametric partial differential equations with dominating advection effects and moving features. Registration refers to the use of a parameter-dependent mapping to make the set of solutions to these equations better suited for approximation using classical reduced basis methods. The proposed approach utilizes concepts from optimal transport theory, as we utilize Monge embeddings to construct these mappings in a purely data-driven way. We discuss how our approach relates to existing works that combine model order reduction and optimal transport theory. Numerical results are provided to demonstrate the effect of the registration. This includes a model problem where the solution is itself a probability density and one where it is not. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/ToBlick/OptimalMappings and in the supplementary materials (OptimalMappings.jl-main.zip [30KB] and M157071_SuppMat.pdf [308KB]).},
  archive      = {J_SISC},
  author       = {Tobias Blickhan},
  doi          = {10.1137/23M1570715},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3177-A3204},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A registration method for reduced basis problems using linear optimal transport},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A robust two-level overlapping preconditioner for darcy flow
in high-contrast media. <em>SISC</em>, <em>46</em>(5), A3151–A3176. (<a
href="https://doi.org/10.1137/23M1558987">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this article, a two-level overlapping domain decomposition preconditioner is developed for solving linear algebraic systems obtained from simulating Darcy flow in high-contrast media. Our preconditioner starts at a mixed finite element method for discretizing the partial differential equation by Darcy’s law with the no-flux boundary condition and is then followed by a velocity elimination technique to yield a linear algebraic system with only unknowns of pressure. Then, our main objective is to design a robust and efficient domain decomposition preconditioner for this system, which is accomplished by engineering a multiscale coarse space that is capable of characterizing high-contrast features of the permeability field. A generalized eigenvalue problem is solved in each nonoverlapping coarse element in a communication-free manner to form the global solver, which is accompanied by local solvers originated from additive Schwarz methods but with a non-Galerkin discretization to derive the two-level preconditioner. We provide a rigorous analysis that indicates that the condition number of the preconditioned system could be bounded above with several assumptions. Extensive numerical experiments with various types of three-dimensional high-contrast models are exhibited. In particular, we study the robustness against the contrast of the media as well as the influences of numbers of eigenfunctions, oversampling sizes, and subdomain partitions on the efficiency of the proposed preconditioner. Strong and weak scalability performances are also examined.},
  archive      = {J_SISC},
  author       = {Changqing Ye and Shubin Fu and Eric T. Chung and Jizu Huang},
  doi          = {10.1137/23M1558987},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3151-A3176},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A robust two-level overlapping preconditioner for darcy flow in high-contrast media},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A distributions-based approach for data-consistent
inversion. <em>SISC</em>, <em>46</em>(5), A3124–A3150. (<a
href="https://doi.org/10.1137/24M1641646">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We formulate a novel approach to solve a class of stochastic problems, referred to as data-consistent inverse (DCI) problems, which involve the characterization of a probability measure on the parameters of a computational model whose subsequent push-forward matches an observed probability measure on specified quantities of interest (QoI) typically associated with the outputs from the computational model. Whereas prior DCI solution methodologies focused on either constructing nonparametric estimates of the densities or the probabilities of events associated with the preimage of the QoI map, we develop and analyze a constrained quadratic optimization approach based on estimating push-forward measures using weighted empirical distribution functions. The method proposed here is more suitable for low-data regimes or high-dimensional problems than the density-based method, as well as for problems where the probability measure does not admit a density. Numerical examples are included to demonstrate the performance of the method and to compare with the density-based approach where applicable. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://zenodo.org/doi/10.5281/zenodo.10676816.},
  archive      = {J_SISC},
  author       = {Kirana O. Bergstrom and Troy D. Butler and Timothy M. Wildey},
  doi          = {10.1137/24M1641646},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3124-A3150},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A distributions-based approach for data-consistent inversion},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Reflectionless discrete perfectly matched layers for
higher-order finite difference schemes. <em>SISC</em>, <em>46</em>(5),
A3094–A3123. (<a href="https://doi.org/10.1137/23M1581558">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper introduces discrete holomorphic perfectly matched layers (PMLs) specifically designed for high-order finite difference (FD) discretizations of the scalar wave equation. In contrast to standard PDE-based PMLs, the proposed method achieves the remarkable outcome of completely eliminating numerical reflections at the PML interface, in practice achieving errors at the level of machine precision. Our approach builds upon the ideas put forth in a recent publication [A. Chern, J. Comput. Phys., 381 (2019), pp. 91–109] expanding the scope from the standard second-order FD method to arbitrarily high-order schemes. This generalization uses additional localized PML variables to accommodate the larger stencils employed. We establish that the numerical solutions generated by our proposed schemes exhibit a geometric decay rate as they propagate within the PML domain. To showcase the effectiveness of our method, we present a variety of numerical examples, including waveguide problems. These examples highlight the importance of employing high-order schemes to effectively address and minimize undesired numerical dispersion errors, emphasizing the practical advantages and applicability of our approach.},
  archive      = {J_SISC},
  author       = {Vicente A. Hojas and Carlos Pérez-Arancibia and Manuel A. Sánchez},
  doi          = {10.1137/23M1581558},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3094-A3123},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Reflectionless discrete perfectly matched layers for higher-order finite difference schemes},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A scalable two-level domain decomposition eigensolver for
periodic schrödinger eigenstates in anisotropically expanding domains.
<em>SISC</em>, <em>46</em>(5), A3067–A3093. (<a
href="https://doi.org/10.1137/23M161848X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Accelerating iterative eigenvalue algorithms is often achieved by employing a spectral shifting strategy. Unfortunately, improved shifting typically leads to a smaller eigenvalue for the resulting shifted operator, which in turn results in a high condition number of the underlying solution matrix, posing a major challenge for iterative linear solvers. This paper introduces a two-level domain decomposition preconditioner that addresses this issue for the linear Schrödinger eigenvalue problem, even in the presence of a vanishing eigenvalue gap in nonuniform, expanding domains. Since the quasi-optimal shift, which is already available as the solution to a spectral cell problem, is required for the eigenvalue solver, it is logical to also use its associated eigenfunction as a generator to construct a coarse space. We analyze the resulting two-level additive Schwarz preconditioner and obtain a condition number bound that is independent of the domain’s anisotropy, despite the need for only one basis function per subdomain for the coarse solver. Several numerical examples are presented to illustrate its flexibility and efficiency. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://doi.org/10.5281/zenodo.11072863.},
  archive      = {J_SISC},
  author       = {Lambert Theisen and Benjamin Stamm},
  doi          = {10.1137/23M161848X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3067-A3093},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A scalable two-level domain decomposition eigensolver for periodic schrödinger eigenstates in anisotropically expanding domains},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shape optimization by constrained first-order system least
mean approximation. <em>SISC</em>, <em>46</em>(5), A3044–A3066. (<a
href="https://doi.org/10.1137/23M1605570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, the problem of shape optimization, subject to PDE constraints, is reformulated as an best approximation problem under divergence constraints to the shape tensor introduced by Laurain and Sturm [ESAIM Math. Model. Numer. Anal., 50 (2016), pp. 1241–1267]. More precisely, the main result of this paper states that the distance of the above approximation problem is equal to the dual norm of the shape derivative considered as a functional on (where ). This implies that for any given shape, one can evaluate its distance from being stationary with respect to the shape derivative by simply solving the associated -type least mean approximation problem. Moreover, the Lagrange multiplier for the divergence constraint turns out to be the shape deformation of steepest descent. This provides, as an alternative to the approach by Deckelnick, Herbert, and Hinze, a way to compute shape gradients in for . The discretization of the least mean approximation problem is done with (lowest-order) matrix-valued Raviart–Thomas finite element spaces leading to piecewise constant approximations of the shape deformation acting as a Lagrange multiplier. Admissible deformations in to be used in a shape gradient iteration are reconstructed locally. Our computational results confirm that the distance of the best approximation does indeed measure the distance of the considered shape to optimality. Also confirmed by our computational tests is the observation of Deckelnick, Herbert, and Hinze [ESAIM Control Optim. Calc. Var., 28 (2022), 2] that choosing (much) larger than 2 (which means that must be close to 1 in our best approximation problem) decreases the chance of encountering mesh degeneracy during the shape gradient iteration. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available in the supplemental material (2DshapeclmSISC160557R2.zip [34.6KB]).},
  archive      = {J_SISC},
  author       = {Gerhard Starke},
  doi          = {10.1137/23M1605570},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3044-A3066},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Shape optimization by constrained first-order system least mean approximation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Randomized sketching of nonlinear eigenvalue problems.
<em>SISC</em>, <em>46</em>(5), A3022–A3043. (<a
href="https://doi.org/10.1137/22M153656X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Rational approximation is a powerful tool to obtain accurate surrogates for nonlinear functions that are easy to evaluate and linearize. The interpolatory adaptive Antoulas–Anderson (AAA) method is one approach to construct such approximants numerically. For large-scale vector- and matrix-valued functions, however, the direct application of the set-valued variant of AAA becomes inefficient. We propose and analyze a new sketching approach for such functions called sketchAAA that, with high probability, leads to much better approximants than previously suggested approaches while retaining efficiency. The sketching approach works in a black-box fashion where only evaluations of the nonlinear function at sampling points are needed. Numerical tests with nonlinear eigenvalue problems illustrate the efficacy of our approach, with speedups over 200 for sampling large-scale black-box functions without sacrificing accuracy. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://zenodo.org/doi/10.5281/zenodo.11634528.},
  archive      = {J_SISC},
  author       = {Stefan Güttel and Daniel Kressner and Bart Vandereycken},
  doi          = {10.1137/22M153656X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A3022-A3043},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Randomized sketching of nonlinear eigenvalue problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Conditional quasi-monte carlo with constrained active
subspaces. <em>SISC</em>, <em>46</em>(5), A2999–A3021. (<a
href="https://doi.org/10.1137/23M1548918">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Conditional Monte Carlo or pre-integration is a powerful tool for reducing variance and improving the regularity of integrands when using Monte Carlo and quasi-Monte Carlo (QMC) methods. To select the variable to pre-integrate, one must consider both the variable’s importance and the tractability of the conditional expectation. For integrals over a Gaussian distribution, any linear combination of variables can potentially be pre-integrated. Liu and Owen [SIAM J. Numer. Anal., 61 (2023), pp. 495–514] propose to select the linear combination based on an active subspace decomposition of the integrand. However, pre-integrating the selected direction might be intractable. In this work, we address this issue by finding the active subspace subject to constraints such that pre-integration can be easily carried out. The proposed algorithm also provides a computationally efficient alternative to dimension reduction for pre-integrated functions. The method is applied to examples from computational finance, density estimation, and computational chemistry and is shown to achieve smaller errors than previous methods.},
  archive      = {J_SISC},
  author       = {Sifan Liu},
  doi          = {10.1137/23M1548918},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A2999-A3021},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Conditional quasi-monte carlo with constrained active subspaces},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite element approximation for the delayed generalized
burgers–huxley equation with weakly singular kernel: Part II
nonconforming and DG approximation. <em>SISC</em>, <em>46</em>(5),
A2972–A2998. (<a href="https://doi.org/10.1137/23M1612196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, the numerical approximation of the generalized Burgers–Huxley equation (GBHE) with weakly singular kernels using nonconforming methods will be presented. Specifically, we discuss two new formulations. The first formulation is based on the nonconforming finite element method. The other formulation is based on discontinuous Galerkin finite element methods. The wellposedness results for both formulations are proved. Then, a priori error estimates for both the semidiscrete and fully discrete schemes are derived. Specific numerical examples, including some applications for the GBHE with a weakly singular model, are discussed to validate the theoretical results.},
  archive      = {J_SISC},
  author       = {Sumit Mahahjan and Arbaz Khan},
  doi          = {10.1137/23M1612196},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A2972-A2998},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Finite element approximation for the delayed generalized Burgers–Huxley equation with weakly singular kernel: Part II nonconforming and DG approximation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Robust iterative method for symmetric quantum signal
processing in all parameter regimes. <em>SISC</em>, <em>46</em>(5),
A2951–A2971. (<a href="https://doi.org/10.1137/23M1598192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper addresses the problem of solving nonlinear systems in the context of symmetric quantum signal processing (QSP), a powerful technique for implementing matrix functions on quantum computers. Symmetric QSP focuses on representing target polynomials as products of matrices in SU(2) that possess symmetry properties. We present a novel Newton’s method tailored for efficiently solving the nonlinear system involved in determining the phase factors within the symmetric QSP framework. Our method demonstrates rapid and robust convergence in all parameter regimes, including the challenging scenario with ill-conditioned Jacobian matrices, using standard double precision arithmetic operations. For instance, solving symmetric QSP for a highly oscillatory target function (polynomial degree ) takes 6 iterations to converge to machine precision when , and the number of iterations only increases to 18 iterations when with a highly ill-conditioned Jacobian matrix. Leveraging the matrix product state structure of symmetric QSP, the computation of the Jacobian matrix incurs a computational cost comparable to a single function evaluation. Moreover, we introduce a reformulation of symmetric QSP using real-number arithmetics, further enhancing the method’s efficiency. Extensive numerical tests validate the effectiveness and robustness of our approach, which has been implemented in the QSPPACK software package.},
  archive      = {J_SISC},
  author       = {Yulong Dong and Lin Lin and Hongkang Ni and Jiasu Wang},
  doi          = {10.1137/23M1598192},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A2951-A2971},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Robust iterative method for symmetric quantum signal processing in all parameter regimes},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The sparse-grid-based adaptive spectral koopman method.
<em>SISC</em>, <em>46</em>(5), A2925–A2950. (<a
href="https://doi.org/10.1137/23M1578292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The adaptive spectral Koopman (ASK) method was introduced to numerically solve autonomous dynamical systems that laid the foundation for numerous applications across different fields in science and engineering. Although ASK achieves high accuracy, it is computationally more expensive for multidimensional systems compared with conventional time integration schemes like Runge–Kutta. In this work, we combine the sparse grid and ASK to accelerate the computation for multidimensional systems. This sparse-grid-based ASK (SASK) method uses the Smolyak structure to construct multidimensional collocation points as well as associated polynomials that are used to approximate eigenfunctions of the Koopman operator of the system. In this way, the number of collocation points is reduced compared with using the tensor product rule. We demonstrate that SASK can be used to solve ordinary differential equations (ODEs) and partial differential equations (PDEs) based on their semidiscrete forms. Numerical experiments are illustrated to compare the performance of SASK and state-of-the-art ODE solvers.},
  archive      = {J_SISC},
  author       = {Bian Li and Yue Yu and Xiu Yang},
  doi          = {10.1137/23M1578292},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A2925-A2950},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The sparse-grid-based adaptive spectral koopman method},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bound-preserving framework for central-upwind schemes for
general hyperbolic conservation laws. <em>SISC</em>, <em>46</em>(5),
A2899–A2924. (<a href="https://doi.org/10.1137/23M1628024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Central-upwind (CU) schemes are Riemann-problem-solver-free finite-volume methods widely applied to a variety of hyperbolic systems of PDEs. Exact solutions of these systems typically satisfy certain bounds, and it is highly desirable and even crucial for the numerical schemes to preserve these bounds. In this paper, we develop and analyze bound-preserving (BP) CU schemes for general hyperbolic systems of conservation laws. Unlike many other Godunov-type methods, CU schemes cannot, in general, be recast as convex combinations of first-order BP schemes. Consequently, standard BP analysis techniques are invalidated. We address these challenges by establishing a novel framework for analyzing the BP property of CU schemes. To this end, we discover that the CU schemes can be decomposed as a convex combination of several intermediate solution states. Thanks to this key finding, the goal of designing BPCU schemes is simplified to the enforcement of four more accessible BP conditions, each of which can be achieved with the help of a minor modification of the CU schemes. We employ the proposed approach to construct provably BPCU schemes for the Euler equations of gas dynamics. The robustness and effectiveness of the BPCU schemes are validated by several demanding numerical examples, including high-speed jet problems, flow past a forward-facing step, and a shock diffraction problem.},
  archive      = {J_SISC},
  author       = {Shumo Cui and Alexander Kurganov and Kailiang Wu},
  doi          = {10.1137/23M1628024},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A2899-A2924},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Bound-preserving framework for central-upwind schemes for general hyperbolic conservation laws},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable backward differentiation formula time discretization
of BGN-based parametric finite element methods for geometric flows.
<em>SISC</em>, <em>46</em>(5), A2874–A2898. (<a
href="https://doi.org/10.1137/23M1625597">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a novel class of temporal high-order parametric finite element methods for solving a wide range of geometric flows of curves and surfaces. By incorporating the backward differentiation formula (BDF) for time discretization into the BGN formulation, originally proposed by Barrett, Garcke, and Nürnberg (J. Comput. Phys., 222 (2007), pp. 441–467), we successfully develop high-order BGN/BDF schemes. The proposed BGN/BDF schemes not only retain almost all the advantages of the classical first-order BGN scheme such as computational efficiency and good mesh quality, but also exhibit the desired th-order temporal accuracy in terms of shape metrics, ranging from second-order to fourth-order accuracy. Furthermore, we validate the performance of our proposed BGN/BDF schemes through extensive numerical examples, demonstrating their high-order temporal accuracy for various types of geometric flows while maintaining good mesh quality throughout the evolution.},
  archive      = {J_SISC},
  author       = {Wei Jiang and Chunmei Su and Ganghui Zhang},
  doi          = {10.1137/23M1625597},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A2874-A2898},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Stable backward differentiation formula time discretization of BGN-based parametric finite element methods for geometric flows},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new provably stable weighted state redistribution
algorithm. <em>SISC</em>, <em>46</em>(5), A2848–A2873. (<a
href="https://doi.org/10.1137/23M1597484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a practical finite volume method on cut cells using state redistribution. Our algorithm is provably monotone, total variation diminishing, and GKS (Gustafsson, Kreiss, Sundström) stable in many situations, and shuts off continuously as the cut cell size approaches a target value. Our analysis reveals why original state redistribution works so well: it results in a monotone scheme for most configurations, though at times subject to a slightly smaller CFL condition. Our analysis also explains why a premerging step is beneficial. We show computational experiments in two and three dimensions.},
  archive      = {J_SISC},
  author       = {Marsha Berger and Andrew Giuliani},
  doi          = {10.1137/23M1597484},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A2848-A2873},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A new provably stable weighted state redistribution algorithm},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Generalizing lloyd’s algorithm for graph clustering.
<em>SISC</em>, <em>46</em>(5), A2819–A2847. (<a
href="https://doi.org/10.1137/23M1556800">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Clustering is a commonplace problem in many areas of data science, with applications in biology and bioinformatics, understanding chemical structure, image segmentation, building recommender systems, and many more fields. While there are many different clustering variants (based on given distance or graph structure, probability distributions, or data density), we consider here the problem of clustering nodes in a graph, motivated by the problem of aggregating discrete degrees of freedom in multigrid and domain decomposition methods for solving sparse linear systems. Specifically, we consider the challenge of forming balanced clusters in the graph of a sparse matrix for use in algebraic multigrid, although the algorithm has general applicability. Based on an extension of the Bellman–Ford algorithm, we generalize Lloyd’s algorithm for partitioning subsets of to balance the number of nodes in each cluster; this is accompanied by a rebalancing algorithm that reduces the overall energy in the system. The algorithm provides control over the number of clusters and leads to “well centered” partitions of the graph. Theoretical results are provided to establish linear complexity and numerical results in the context of algebraic multigrid highlight the benefits of improved clustering. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/lukeolson/paper-lloyd-data and in the supplementary materials (paper-lloyd-data.zip [88.1MB]).},
  archive      = {J_SISC},
  author       = {Tareq Zaman and Nicolas Nytko and Ali Taghibakhshi and Scott MacLachlan and Luke Olson and Matthew West},
  doi          = {10.1137/23M1556800},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A2819-A2847},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Generalizing lloyd’s algorithm for graph clustering},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Inverse source problem of the biharmonic equation from
multifrequency phaseless data. <em>SISC</em>, <em>46</em>(5),
A2799–A2818. (<a href="https://doi.org/10.1137/24M162889X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work deals with an inverse source problem for the biharmonic wave equation. A two-stage numerical method is proposed to identify the unknown source from the multifrequency phaseless data. In the first stage, we introduce some artificial auxiliary point sources to the inverse source system and establish a phase retrieval formula. Theoretically, we point out that the phase can be uniquely determined and estimate the stability of this phase retrieval approach. Once the phase information is retrieved, the Fourier method is adopted to reconstruct the source function from the phased multifrequency data. The proposed method is easy to implement and there is no forward solver involved in the reconstruction. Numerical experiments are conducted to verify the performance of the proposed method.},
  archive      = {J_SISC},
  author       = {Yan Chang and Yukun Guo and Yue Zhao},
  doi          = {10.1137/24M162889X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {10},
  number       = {5},
  pages        = {A2799-A2818},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Inverse source problem of the biharmonic equation from multifrequency phaseless data},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A pseudoreversible normalizing flow for stochastic dynamical
systems with various initial distributions. <em>SISC</em>,
<em>46</em>(4), C508–C533. (<a
href="https://doi.org/10.1137/23M1585635">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a pseudoreversible normalizing flow method for efficiently generating samples of the state of a stochastic differential equation (SDE) with various initial distributions. The primary objective is to construct an accurate and efficient sampler that can be used as a surrogate model for computationally expensive numerical integration of SDEs, such as those employed in particle simulation. After training, the normalizing flow model can directly generate samples of the SDE’s final state without simulating trajectories. The existing normalizing flow model for SDEs depends on the initial distribution, meaning the model needs to be retrained when the initial distribution changes. The main novelty of our normalizing flow model is that it can learn the conditional distribution of the state, i.e., the distribution of the final state conditional on any initial state, such that the model only needs to be trained once and the trained model can be used to handle various initial distributions. This feature can provide a significant computational saving in studies of how the final state varies with the initial distribution. Additionally, we propose to use a pseudoreversible network architecture to define the normalizing flow model, which has sufficient expressive power and training efficiency for a variety of SDEs in science and engineering, e.g., in particle physics. We provide a rigorous convergence analysis of the pseudoreversible normalizing flow model to the target probability density function in the Kullback–Leibler divergence metric. Numerical experiments are provided to demonstrate the effectiveness of the proposed normalizing flow model. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/mlmathphy/PRNF and in the supplementary materials (PRNF-main.zip [27.4MB]).},
  archive      = {J_SISC},
  author       = {Minglei Yang and Pengjun Wang and Diego del-Castillo-Negrete and Yanzhao Cao and Guannan Zhang},
  doi          = {10.1137/23M1585635},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C508-C533},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A pseudoreversible normalizing flow for stochastic dynamical systems with various initial distributions},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A meshless solver for blood flow simulations in elastic
vessels using a physics-informed neural network. <em>SISC</em>,
<em>46</em>(4), C479–C507. (<a
href="https://doi.org/10.1137/23M1622696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Investigating blood flow in the cardiovascular system is crucial for assessing cardiovascular health. Computational approaches offer some noninvasive alternatives to measure blood flow dynamics. Numerical simulations based on traditional methods such as finite-element and other numerical discretizations have been extensively studied and have yielded excellent results. However, adapting these methods to real-life simulations remains a complex task. In this paper, we propose a method that offers flexibility and can efficiently handle real-life simulations. We suggest utilizing the physics-informed neural network to solve the Navier–Stokes equation in a deformable domain, specifically addressing the simulation of blood flow in elastic vessels. Our approach models blood flow using an incompressible, viscous Navier–Stokes equation in an arbitrary Lagrangian–Eulerian form. The mechanical model for the vessel wall structure is formulated by an equation of Newton’s second law of momentum and linear elasticity to the force exerted by the fluid flow. Our method is a mesh-free approach that eliminates the need for discretization and meshing of the computational domain. This makes it highly efficient in solving simulations involving complex geometries. Additionally, with the availability of well-developed open-source machine learning framework packages and parallel modules, our method can easily be accelerated through GPU computing and parallel computing. To evaluate our approach, we conducted experiments on regular cylinder vessels as well as vessels with plaque on their walls. We compared our results to a solution calculated by finite element methods using a dense grid and small time steps, which we considered as the ground truth solution. We report the relative error and the time consumed to solve the problem, highlighting the advantages of our method.},
  archive      = {J_SISC},
  author       = {Han Zhang and Raymond H. Chan and Xue-Cheng Tai},
  doi          = {10.1137/23M1622696},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C479-C507},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A meshless solver for blood flow simulations in elastic vessels using a physics-informed neural network},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Least-squares neural network (LSNN) method for linear
advection-reaction equation: Discontinuity interface. <em>SISC</em>,
<em>46</em>(4), C448–C478. (<a
href="https://doi.org/10.1137/23M1568107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We studied the least-squares ReLU neural network (LSNN) method for solving a linear advection-reaction equation with discontinuous solution in [Z. Cai et al., J. Comput. Phys., 443 (2021), 110514]. The method is based on a least-squares formulation and uses a new class of approximating functions: ReLU neural network (NN) functions. A critical and additional component of the LSNN method, differing from other NN-based methods, is the introduction of a properly designed and physics preserved discrete differential operator. In this paper, we study the LSNN method for problems with discontinuity interfaces. First, we show that ReLU NN functions with depth can approximate any -dimensional step function on a discontinuity interface generated by a vector field as streamlines with any prescribed accuracy. By decomposing the solution into continuous and discontinuous parts, we prove theoretically that the discretization error of the LSNN method using ReLU NN functions with depth is mainly determined by the continuous part of the solution provided that the solution jump is constant. Numerical results for both two- and three-dimensional test problems with various discontinuity interfaces show that the LSNN method with enough layers is accurate and does not exhibit the common Gibbs phenomena along discontinuity interfaces.},
  archive      = {J_SISC},
  author       = {Zhiqiang Cai and Junpyo Choi and Min Liu},
  doi          = {10.1137/23M1568107},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C448-C478},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Least-squares neural network (LSNN) method for linear advection-reaction equation: Discontinuity interface},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An alternating flux learning method for multidimensional
nonlinear conservation laws. <em>SISC</em>, <em>46</em>(4), C421–C447.
(<a href="https://doi.org/10.1137/23M1556605">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In a recent work [Q. Li and S. Evje, Netw. Heterog. Media, 18 (2023), pp. 48–79], it was explored how to identify the unknown flux function in a one-dimensional scalar conservation law. Key ingredients are symbolic neural networks to represent the candidate flux functions, entropy-satisfying numerical schemes, and a proper combination of initial data. The purpose of this work is to extend this methodology to a two-dimensional scalar conservation law . Straightforward extension of the method from the 1D to the 2D problem results in poor identification of the unknown and . Relying on ideas from joint and alternating equations training, a learning strategy is designed that enables accurate identification of the flux functions, even when 2D observations are sparse. It involves an alternating flux training approach where a first set of candidate flux functions obtained from joint training is improved through an alternating direction-dependent training strategy. Numerical investigations demonstrate that the method can effectively identify the true underlying flux functions and in the general case when they are nonconvex and unequal.},
  archive      = {J_SISC},
  author       = {Qing Li and Steinar Evje},
  doi          = {10.1137/23M1556605},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C421-C447},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An alternating flux learning method for multidimensional nonlinear conservation laws},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Graph neural reaction diffusion models. <em>SISC</em>,
<em>46</em>(4), C399–C420. (<a
href="https://doi.org/10.1137/23M1576700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The integration of graph neural networks (GNNs) and neural ordinary and partial differential equations has been extensively studied in recent years. GNN architectures powered by neural differential equations allow us to reason about their behavior, and develop GNNs with desired properties such as controlled smoothing or energy conservation. In this paper we take inspiration from Turing instabilities in a reaction diffusion (RD) system of partial differential equations, and propose a novel family of GNNs based on neural RD systems, called RDGNN. We show that our RDGNN is powerful for the modeling of various data types, from homophilic, to heterophilic, and spatiotemporal datasets. We discuss the theoretical properties of our RDGNN, its implementation, and show that it improves or offers competitive performance to state-of-the-art methods.},
  archive      = {J_SISC},
  author       = {Moshe Eliasof and Eldad Haber and Eran Treister},
  doi          = {10.1137/23M1576700},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C399-C420},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Graph neural reaction diffusion models},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving poisson problems in polygonal domains with
singularity enriched physics informed neural networks. <em>SISC</em>,
<em>46</em>(4), C369–C398. (<a
href="https://doi.org/10.1137/23M1601195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Physics-informed neural networks (PINNs) are a powerful class of numerical solvers for partial differential equations, employing deep neural networks with successful applications across a diverse set of problems. However, their effectiveness is somewhat diminished when addressing issues involving singularities, such as point sources or geometric irregularities, where the approximations they provide often suffer from reduced accuracy due to the limited regularity of the exact solution. In this work, we investigate PINNs for solving Poisson equations in polygonal domains with geometric singularities and mixed boundary conditions. We propose a novel singularity enriched PINN, by explicitly incorporating the singularity behavior of the analytic solution, e.g., corner singularity, mixed boundary condition, and edge singularities, into the ansatz space, and present a convergence analysis of the scheme. We present extensive numerical simulations in two and three dimensions to illustrate the efficiency of the method, and also a comparative study with several existing neural network based approaches. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/hhjc-web/SEPINN.git and in the supplementary materials (M160119_SuppMat.pdf [399KB]).},
  archive      = {J_SISC},
  author       = {Tianhao Hu and Bangti Jin and Zhi Zhou},
  doi          = {10.1137/23M1601195},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C369-C398},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Solving poisson problems in polygonal domains with singularity enriched physics informed neural networks},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Temporal difference learning for high-dimensional PIDEs with
jumps. <em>SISC</em>, <em>46</em>(4), C349–C368. (<a
href="https://doi.org/10.1137/23M1584538">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a deep learning framework for solving high-dimensional partial integro-differential equations (PIDEs) based on the temporal difference learning. We introduce a set of Lévy processes and construct a corresponding reinforcement learning model. To simulate the entire process, we use deep neural networks to represent the solutions and nonlocal terms of the equations. Subsequently, we train the networks using the temporal difference error, the termination condition, and properties of the nonlocal terms as the loss function. The relative error of the method reaches in 100-dimensional experiments and in one-dimensional pure jump problems. Additionally, our method demonstrates the advantages of low computational cost and robustness, making it well-suited for addressing problems with different forms and intensities of jumps.},
  archive      = {J_SISC},
  author       = {Liwei Lu and Hailong Guo and Xu Yang and Yi Zhu},
  doi          = {10.1137/23M1584538},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C349-C368},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Temporal difference learning for high-dimensional PIDEs with jumps},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Render unto numerics: Orthogonal polynomial neural operator
for PDEs with nonperiodic boundary conditions. <em>SISC</em>,
<em>46</em>(4), C323–C348. (<a
href="https://doi.org/10.1137/23M1556320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. By learning the mappings between infinite function spaces using carefully designed neural networks, the operator learning methodology has exhibited significantly more efficiency than traditional methods in solving differential equations, but faces concerns about their accuracy and reliability. To overcome these limitations through robustly enforcing boundary conditions (BCs), a general neural architecture named spectral operator learning is introduced by combining with the structures of the spectral numerical method. One variant called the orthogonal polynomial neural operator (OPNO) is proposed later, aiming at PDEs with Dirichlet, Neumann, and Robin BCs. The strict BC satisfaction properties and the universal approximation capacity of the OPNO are theoretically proven. A variety of numerical experiments with physical backgrounds demonstrate that the OPNO outperforms other existing deep learning methodologies, showcasing potential of comparable accuracy with the traditional second-order finite difference method that employs a considerably fine mesh (with relative errors on the order of ), and is up to almost 5 magnitudes faster over the traditional method. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/liu-ziyuan-math/spectral_operator_learning/tree/main/OPNO/Reproduce and in the supplementary materials (spectral_operator_learning-main.zip [669KB]).},
  archive      = {J_SISC},
  author       = {Ziyuan Liu and Haifeng Wang and Hong Zhang and Kaijun Bao and Xu Qian and Songhe Song},
  doi          = {10.1137/23M1556320},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C323-C348},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Render unto numerics: Orthogonal polynomial neural operator for PDEs with nonperiodic boundary conditions},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Slow invariant manifolds of singularly perturbed systems via
physics-informed machine learning. <em>SISC</em>, <em>46</em>(4),
C297–C322. (<a href="https://doi.org/10.1137/23M1602991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a physics-informed machine learning (PIML) approach for the approximation of slow invariant manifolds of singularly perturbed systems, providing functionals in an explicit form that facilitates the construction and numerical integration of reduced-order models (ROMs). The proposed scheme solves the partial differential equation corresponding to the invariance equation (IE) within the geometric singular perturbation theory (GSPT) framework. For the solution of the IE, we used two neural network structures, namely, feedforward neural networks and random projection neural networks, with symbolic differentiation for the computation of the gradients required for the learning process. The efficiency of our PIML method is assessed via three benchmark problems, namely, the Michaelis–Menten, the target-mediated drug disposition reaction mechanism, and the 3D Sel’kov model. We show that the proposed PIML scheme provides approximations of equivalent or even higher accuracy than those provided by other traditional GSPT-based methods, and importantly, for any practical purposes, it is not affected by the magnitude of the perturbation parameter. This is of particular importance because there are many systems for which the gap between the fast and slow timescales is not that big, but still, ROMs can be constructed. A comparison of the computational costs between symbolic, automatic, and numerical approximation of the required derivatives in the learning process is also provided. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://epubs.siam.org/doi/suppl/10.1137/23M1602991/suppl_file/131735_1_supp_551502_s5k7wy_sc.pdf and https://epubs.siam.org/doi/suppl/10.1137/23M1602991/suppl_file/SISC_PIML_SIMs_SP-main.zip.},
  archive      = {J_SISC},
  author       = {Dimitrios Patsatzis and Gianluca Fabiani and Lucia Russo and Constantinos Siettos},
  doi          = {10.1137/23M1602991},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C297-C322},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Slow invariant manifolds of singularly perturbed systems via physics-informed machine learning},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On the training and generalization of deep operator
networks. <em>SISC</em>, <em>46</em>(4), C273–C296. (<a
href="https://doi.org/10.1137/23M1598751">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a novel training method for deep operator networks (DeepONets), one of the most popular neural network models for operators. DeepONets are constructed by two subnetworks, namely the branch and trunk networks. Typically, the two subnetworks are trained simultaneously, which amounts to solving a complex optimization problem in a high dimensional space. In addition, the nonconvex and nonlinear nature makes training very challenging. To tackle such a challenge, we propose a two-step training method that trains the trunk network first and then sequentially trains the branch network. The core mechanism is motivated by the divide-and-conquer paradigm and is the decomposition of the entire complex training task into two subtasks with reduced complexity. Therein the Gram–Schmidt orthonormalization process is introduced which significantly improves stability and generalization ability. On the theoretical side, we establish a generalization error estimate in terms of the number of training data, the width of DeepONets, and the number of input and output sensors. Numerical examples are presented to demonstrate the effectiveness of the two-step training method, including Darcy flow in heterogeneous porous media.},
  archive      = {J_SISC},
  author       = {Sanghyun Lee and Yeonjong Shin},
  doi          = {10.1137/23M1598751},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {C273-C296},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On the training and generalization of deep operator networks},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implicit adaptive mesh refinement for dispersive tsunami
propagation. <em>SISC</em>, <em>46</em>(4), B554–B578. (<a
href="https://doi.org/10.1137/23M1585210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present an algorithm to solve the dispersive depth-averaged Serre–Green–Naghdi equations using patch-based adaptive mesh refinement. These equations require adding additional higher derivative terms to the nonlinear shallow water equations. This has been implemented as a new component of the open source GeoClaw software that is widely used for modeling tsunamis, storm surge, and related hazards, improving its accuracy on shorter wavelength phenomena. We use a formulation that requires solving an elliptic system of equations at each time step, making the method implicit. The adaptive algorithm allows different time steps on different refinement levels and solves the implicit equations level by level. Computational examples are presented to illustrate the stability and accuracy on a radially symmetric test case and two realistic tsunami modeling problems, including a hypothetical asteroid impact creating a short wavelength tsunami for which dispersive terms are necessary. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/rjleveque/ImplicitAMR-paper and in the supplementary materials (ImplicitAMR-paper.zip [174KB]).},
  archive      = {J_SISC},
  author       = {Marsha J. Berger and Randall J. LeVeque},
  doi          = {10.1137/23M1585210},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {B554-B578},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Implicit adaptive mesh refinement for dispersive tsunami propagation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Cut finite element discretizations of cell-by-cell EMI
electrophysiology models. <em>SISC</em>, <em>46</em>(4), B527–B553. (<a
href="https://doi.org/10.1137/23M1580632">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The EMI (extracellular-membrane-intracellular) model describes electrical activity in excitable tissue, where the extracellular and intracellular spaces and cellular membrane are explicitly represented. The model couples a system of partial differential equations (PDEs) in the intracellular and extracellular spaces with a system of ordinary differential equations (ODEs) on the membrane. A key challenge for the EMI model is the generation of high-quality meshes conforming to the complex geometries of brain cells. To overcome this challenge, we propose a novel cut finite element method (CutFEM) where the membrane geometry can be represented independently of a structured and easy-to-generate background mesh for the remaining computational domain. Starting from a Godunov splitting scheme, the EMI model is split into separate PDE and ODE parts. The resulting PDE part is a nonstandard elliptic interface problem, for which we devise two different CutFEM formulations: one single-dimensional formulation with the intra/extracellular electrical potentials as unknowns, and a multi-dimensional formulation that also introduces the electrical current over the membrane as an additional unknown leading to a penalized saddle point problem. Both formulations are augmented by suitably designed ghost penalties to ensure stability and convergence properties that are insensitive to how the membrane surface mesh cuts the background mesh. For the ODE part, we introduce a new unfitted discretization to solve the membrane bound ODEs on a membrane interface that is not aligned with the background mesh. Finally, we perform extensive numerical experiments to demonstrate that CutFEM is a promising approach to efficiently simulate electrical activity in geometrically resolved brain cells. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://zenodo.org/record/8068506.},
  archive      = {J_SISC},
  author       = {Nanna Berre and Marie E. Rognes and André Massing},
  doi          = {10.1137/23M1580632},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {B527-B553},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Cut finite element discretizations of cell-by-cell EMI electrophysiology models},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rounding error using low precision approximate random
variables. <em>SISC</em>, <em>46</em>(4), B502–B526. (<a
href="https://doi.org/10.1137/23M1552814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For numerical approximations to stochastic differential equations using the Euler–Maruyama scheme, we propose incorporating approximate random variables computed using low precisions, such as single and half precision. We propose and justify a model for the rounding error incurred, and produce an average case error bound for two and four way differences, appropriate for regular and nested multilevel Monte Carlo estimations. Our rounding error model recovers and extends the statistical model by Arciniega and Allen [Stoch. Anal. Appl., 21 (2003), pp. 281–300], while bounding the size that systematic and biased rounding errors are permitted to be. By considering the variance structure of multilevel Monte Carlo correction terms in various precisions with and without a Kahan compensated summation, we compute the potential speed ups offered from the various precisions. We find single precision offers the potential for approximate speed improvements by a factor of 7 across a wide span of discretization levels. Half precision offers comparable improvements for several levels of coarse simulations, and even offers improvements by a factor of 10–12 for the very coarsest few levels, which are likely to dominate higher order methods such as the Milstein scheme.},
  archive      = {J_SISC},
  author       = {Michael B. Giles and Oliver Sheridan-Methven},
  doi          = {10.1137/23M1552814},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {B502-B526},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Rounding error using low precision approximate random variables},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). S-OPT: A points selection algorithm for hyper-reduction in
reduced order models. <em>SISC</em>, <em>46</em>(4), B474–B501. (<a
href="https://doi.org/10.1137/22M1484018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. While projection-based reduced order models can reduce the dimension of full order solutions, the resulting reduced models may still contain terms that scale with the full order dimension. Hyper-reduction techniques are sampling-based methods that further reduce this computational complexity by approximating such terms with a much smaller dimension. The goal of this work is to introduce the points selection algorithm developed by Shin and Xiu [SIAM J. Sci. Comput., 38 (2016), pp. A385–A411] as a hyper-reduction method. The selection algorithm was originally proposed as a stochastic collocation method for uncertainty quantification. Since the algorithm aims at maximizing a quantity that measures both the column orthogonality and the determinant, we refer to the algorithm as S-OPT. Numerical examples are provided to demonstrate the performance of S-OPT and to compare its performance with a gappy proper orthogonal decomposition (POD) algorithm. We found that using the S-OPT algorithm is shown to predict the full order solutions with higher accuracy than gappy POD especially when the number of sampling points is small, although we note that S-OPT shows slow asymptotic convergence with respect to the number of samples for some applications, e.g., Lagrangian hydrodynamics.},
  archive      = {J_SISC},
  author       = {Jessica T. Lauzon and Siu Wun Cheung and Yeonjong Shin and Youngsoo Choi and Dylan M. Copeland and Kevin Huynh},
  doi          = {10.1137/22M1484018},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {B474-B501},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {S-OPT: A points selection algorithm for hyper-reduction in reduced order models},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Integrated nested laplace approximations for large-scale
spatiotemporal bayesian modeling. <em>SISC</em>, <em>46</em>(4),
B448–B473. (<a href="https://doi.org/10.1137/23M1561531">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Bayesian inference tasks continue to pose a computational challenge. This especially holds for spatiotemporal modeling, where high-dimensional latent parameter spaces are ubiquitous. The methodology of integrated nested Laplace approximations (INLA) provides a framework for performing Bayesian inference applicable to a large subclass of additive Bayesian hierarchical models. In combination with the stochastic partial differential equation (SPDE) approach, it gives rise to an efficient method for spatiotemporal modeling. In this work, we build on the INLA-SPDE approach by putting forward a performant distributed memory variant, INLADIST, for large-scale applications. To perform the arising computational kernel operations, consisting of Cholesky factorizations, solving linear systems, and selected matrix inversions, we present two numerical solver options: a sparse CPU-based library and a novel blocked GPU-accelerated approach which we propose. We leverage the recurring nonzero block structure in the arising precision (inverse covariance) matrices, which allows us to employ dense subroutines within a sparse setting. Both versions of INLADIST are highly scalable, capable of performing inference on models with millions of latent parameters. We demonstrate their accuracy and performance on synthetic as well as real-world climate dataset applications.},
  archive      = {J_SISC},
  author       = {Lisa Gaedke-Merzhäuser and Elias Krainski and Radim Janalik and Håvard Rue and Olaf Schenk},
  doi          = {10.1137/23M1561531},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {B448-B473},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Integrated nested laplace approximations for large-scale spatiotemporal bayesian modeling},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian parameter identification in impedance boundary
conditions for helmholtz problems. <em>SISC</em>, <em>46</em>(4),
B422–B447. (<a href="https://doi.org/10.1137/23M1591517">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the problem of identifying the acoustic impedance of a wall surface from noisy pressure measurements in a closed room using a Bayesian approach. The room acoustics are modeled by the interior Helmholtz equation with impedance boundary conditions. The aim is to compute moments of the acoustic impedance to estimate a suitable density function of the impedance coefficient. For the computation of moments we use ratio estimators and Monte Carlo sampling. We consider two different experimental scenarios. In the first scenario, the noisy measurements correspond to a wall modeled by impedance boundary conditions. In this case, the Bayesian algorithm uses a model that is (up to the noise) consistent with the measurements and our algorithm is able to identify acoustic impedance with high accuracy. In the second scenario, the noisy measurements come from a coupled acoustic-structural problem, modeling a wall made of glass, whereas the Bayesian algorithm still uses a model with impedance boundary conditions. In this case, the parameter identification model is inconsistent with the measurements and therefore is not capable to represent them well. Nonetheless, for particular frequency bands the Bayesian algorithm identifies estimates with high likelihood. Outside these frequency bands the algorithm fails. We discuss the results of both examples and possible reasons for the failure of the latter case for particular frequency values.},
  archive      = {J_SISC},
  author       = {Nick Wulbusch and Reinhild Roden and Matthias Blau and Alexey Chernov},
  doi          = {10.1137/23M1591517},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {B422-B447},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Bayesian parameter identification in impedance boundary conditions for helmholtz problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Quantum simulation for quantum dynamics with artificial
boundary conditions. <em>SISC</em>, <em>46</em>(4), B403–B421. (<a
href="https://doi.org/10.1137/23M1563451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Quantum dynamics, typically expressed in the form of a time-dependent Schrödinger equation with a Hermitian Hamiltonian, is a natural application for quantum computing. However, when simulating quantum dynamics that involves the emission of electrons, it is necessary to use artificial boundary conditions (ABCs) to confine the computation within a fixed domain. The introduction of ABCs alters the Hamiltonian structure of the dynamics, and existing quantum algorithms cannot be directly applied since the evolution is no longer unitary. The current paper utilizes a recently introduced Schrödingerization method that converts non-Hermitian dynamics into a Schrödinger form for the artificial boundary problems [S. Jin, N. Liu, and Y. Yu, Quantum Simulation of Partial Differential Equations via Schrödingerisation, preprint, arXiv:2212.13969, 2022], [S. Jin, N. Liu, and Y. Yu, Phys. Rev. A, 108 (2023), 032603]. We implement this method for three types of ABCs, including the complex absorbing potential technique, perfectly matched layer methods, and Dirichlet-to-Neumann approach. We analyze the query complexity of these algorithms and perform numerical experiments to demonstrate the validity of this approach. This helps to bridge the gap between available quantum algorithms and computational models for quantum dynamics in unbounded domains.},
  archive      = {J_SISC},
  author       = {Shi Jin and Xiantao Li and Nana Liu and Yue Yu},
  doi          = {10.1137/23M1563451},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {B403-B421},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Quantum simulation for quantum dynamics with artificial boundary conditions},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Shape optimization of optical microscale inclusions.
<em>SISC</em>, <em>46</em>(4), B377–B402. (<a
href="https://doi.org/10.1137/23M158262X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper describes a class of shape optimization problems for optical metamaterials comprised of periodic microscale inclusions composed of a dielectric, low-dimensional material suspended in a nonmagnetic bulk dielectric. The shape optimization approach is based on a homogenization theory for time-harmonic Maxwell’s equations that describes effective material parameters for the propagation of electromagnetic waves through the metamaterial. The control parameter of the optimization is a deformation field representing the deviation of the microscale geometry from a reference configuration of the cell problem. This allows for describing the homogenized effective permittivity tensor as a function of the deformation field. We show that the underlying deformed cell problem is well-posed and regular. This, in turn, proves that the shape optimization problem is well-posed. In addition, a numerical scheme is formulated that utilizes an adjoint formulation with either gradient descent or BFGS as optimization algorithms. The developed algorithm is tested numerically on a number of prototypical shape optimization problems with a prescribed effective permittivity tensor as the target. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://zenodo.org/records/10459309.},
  archive      = {J_SISC},
  author       = {Manaswinee Bezbaruah and Matthias Maier and Winnifried Wollner},
  doi          = {10.1137/23M158262X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {B377-B402},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Shape optimization of optical microscale inclusions},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A sketch-and-select arnoldi process. <em>SISC</em>,
<em>46</em>(4), A2774–A2797. (<a
href="https://doi.org/10.1137/23M1588007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A sketch-and-select Arnoldi process to generate a well-conditioned basis of a Krylov space at low cost is proposed. At each iteration the procedure utilizes randomized sketching to select a limited number of previously computed basis vectors to project out of the current basis vector. The computational cost grows linearly with the dimension of the Krylov space. The subset selection problem for the projection step is approximately solved with a number of heuristic algorithms and greedy methods used in statistical learning and compressive sensing. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/simunec/sketch-select-arnoldi and in the supplementary materials (sketch-select-arnoldi-main.zip [2.21MB]).},
  archive      = {J_SISC},
  author       = {Stefan Güttel and Igor Simunec},
  doi          = {10.1137/23M1588007},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2774-A2797},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A sketch-and-select arnoldi process},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast iterative PDE-based algorithm for feedback controls
of nonsmooth mean-field control problems. <em>SISC</em>, <em>46</em>(4),
A2737–A2773. (<a href="https://doi.org/10.1137/21M1441158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a PDE-based accelerated gradient algorithm for optimal feedback controls of McKean–Vlasov dynamics that involve mean-field interactions both in the state and action. The method exploits a forward-backward splitting approach and iteratively refines the approximate controls based on the gradients of smooth costs, the proximal maps of nonsmooth costs, and dynamically updated momentum parameters. At each step, the state dynamics is approximated via a particle system, and the required gradient is evaluated through a coupled system of nonlocal linear PDEs. The latter is solved by finite difference approximation or neural network-based residual approximation, depending on the state dimension. We present exhaustive numerical experiments for low- and high-dimensional mean-field control problems, including sparse stabilization of stochastic Cucker–Smale models, which reveal that our algorithm captures important structures of the optimal feedback control and achieves a robust performance with respect to parameter perturbation.},
  archive      = {J_SISC},
  author       = {Christoph Reisinger and Wolfgang Stockinger and Yufei Zhang},
  doi          = {10.1137/21M1441158},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2737-A2773},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A fast iterative PDE-based algorithm for feedback controls of nonsmooth mean-field control problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multilevel parareal algorithm with averaging for oscillatory
problems. <em>SISC</em>, <em>46</em>(4), A2709–A2736. (<a
href="https://doi.org/10.1137/23M1547123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The present study is an extension of the work done by Peddle, Haut, and Wingate [SIAM J. Sci. Comput., 41 (2019), pp. A3476–A3497] and Haut and Wingate [SIAM J. Sci. Comput., 36 (2014), pp. A693–A713], where a two-level Parareal method with mapping and averaging is examined. The method proposed in this paper is a multilevel Parareal method with arbitrarily many levels, which is not restricted to the two-level case. We give an asymptotic error estimate which reduces to the two-level estimate for the case when only two levels are considered. Introducing more than two levels has important consequences for the averaging procedure, as we choose separate averaging windows for each of the different levels, which is an additional new feature of the present study. The different averaging windows make the proposed method especially appropriate for nonlinear multiscale problems, because we can introduce a level for each intrinsic scale of the problem and adapt the averaging procedure such that we reproduce the behavior of the model on the particular scale resolved by the level. The method is applied to nonlinear differential equations. The nonlinearities can generate a range of frequencies in the problem. The computational cost of the new method is investigated and studied on several examples.},
  archive      = {J_SISC},
  author       = {Juliane Rosemeier and Terry Haut and Beth Wingate},
  doi          = {10.1137/23M1547123},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2709-A2736},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multilevel parareal algorithm with averaging for oscillatory problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptivity in local kernel based methods for approximating
the action of linear operators. <em>SISC</em>, <em>46</em>(4),
A2683–A2708. (<a href="https://doi.org/10.1137/23M1598052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Building on the successes of local kernel methods for approximating the solutions to partial differential equations (PDEs) and the evaluation of definite integrals (quadrature/cubature), a local estimate of the error in such approximations is developed. This estimate is useful for determining locations in the solution domain where increased node density (equivalently, reduction in the spacing between nodes) can decrease the error in the solution. An adaptive procedure for adding nodes to the domain for both the approximation of derivatives and the approximate evaluation of definite integrals is described. This method efficiently computes the error estimate at a set of prescribed points and adds new nodes for approximation where the error is too large. Computational experiments demonstrate close agreement between the error estimate and actual absolute error in the approximation. Such methods are necessary or desirable when approximating solutions to PDEs (or in the case of quadrature/cubature), where the initial data and subsequent solution (or integrand) exhibit localized features that require significant refinement to resolve and where uniform increases in the density of nodes across the entire computational domain is not possible or too burdensome.},
  archive      = {J_SISC},
  author       = {Jonah A. Reeger},
  doi          = {10.1137/23M1598052},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2683-A2708},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Adaptivity in local kernel based methods for approximating the action of linear operators},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Implicit-explicit schemes for incompressible flow problems
with variable viscosity. <em>SISC</em>, <em>46</em>(4), A2660–A2682. (<a
href="https://doi.org/10.1137/23M1606526">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This article investigates different implicit-explicit (IMEX) methods for incompressible flows with variable viscosity. The viscosity field may depend on space and time alone or, for example, on velocity gradients. Unlike most previous works on IMEX schemes, which focus on the convective term, we propose also treating parts of the diffusive term explicitly, which can reduce the coupling between the velocity components. We present different IMEX alternatives for the variable-viscosity Navier–Stokes system, analyzing their theoretical and algorithmic properties. Temporal stability is proven for all the methods presented, including monolithic and fractional-step variants. These results are unconditional except for one of the fractional-step discretizations, whose stability is shown for time-step sizes under an upper bound that depends solely on the problem data. The key finding of this work is a class of IMEX schemes whose steps decouple the velocity components and are fully linearized (even if the viscosity depends nonlinearly on the velocity) without requiring any CFL condition for stability. Moreover, in the presence of Neumann boundaries, some of our formulations lead naturally to conditions involving normal pseudotractions. This generalizes to the variable-viscosity case what happens for the standard Laplacian form with constant viscosity. Our analysis is supported by a series of numerical experiments.},
  archive      = {J_SISC},
  author       = {Gabriel Barrenechea and Ernesto Castillo and Douglas Pacheco},
  doi          = {10.1137/23M1606526},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2660-A2682},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Implicit-explicit schemes for incompressible flow problems with variable viscosity},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The effect of approximate coarsest-level solves on the
convergence of multigrid v-cycle methods. <em>SISC</em>, <em>46</em>(4),
A2634–A2659. (<a href="https://doi.org/10.1137/23M1578255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The multigrid V-cycle method is a popular method for solving systems of linear equations. It computes an approximate solution by using smoothing on fine levels and solving a system of linear equations on the coarsest level. Solving on the coarsest level depends on the size and difficulty of the problem. If the size permits, it is typical to use a direct method based on LU or Cholesky decomposition. In settings with large coarsest-level problems, approximate solvers such as iterative Krylov subspace methods, or direct methods based on low-rank approximation, are often used. The accuracy of the coarsest-level solver is typically determined based on the experience of the users with the concrete problems and methods. In this paper, we present an approach to analyzing the effects of approximate coarsest-level solves on the convergence of the V-cycle method for symmetric positive definite problems. Using these results, we derive coarsest-level stopping criterion through which we may control the difference between the approximation computed by a V-cycle method with approximate coarsest-level solver and the approximation which would be computed if the coarsest-level problems were solved exactly. The coarsest-level stopping criterion may thus be set up such that the V-cycle method converges to a chosen finest-level accuracy in (nearly) the same number of V-cycle iterations as the V-cycle method with exact coarsest-level solver. We also utilize the theoretical results to discuss how the convergence of the V-cycle method may be affected by the choice of a tolerance in a coarsest-level stopping criterion based on the relative residual norm. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://doi.org/10.5281/zenodo.11178544.},
  archive      = {J_SISC},
  author       = {Petr Vacek and Erin Carson and Kirk M. Soodhalter},
  doi          = {10.1137/23M1578255},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2634-A2659},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The effect of approximate coarsest-level solves on the convergence of multigrid V-cycle methods},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A preconditioned krylov subspace method for linear inverse
problems with general-form tikhonov regularization. <em>SISC</em>,
<em>46</em>(4), A2607–A2633. (<a
href="https://doi.org/10.1137/23M1593802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Tikhonov regularization is a widely used technique in solving inverse problems that can enforce prior properties on the desired solution. In this paper, we propose a Krylov subspace based iterative method for solving linear inverse problems with general-form Tikhonov regularization term , where is a positive semidefinite matrix. An iterative process called the preconditioned Golub–Kahan bidiagonalization (pGKB) is designed, which implicitly utilizes a proper preconditioner to generate a series of solution subspaces with desirable properties encoded by the regularizer . Based on the pGKB process, we propose an iterative regularization algorithm via projecting the original problem onto small dimensional solution subspaces. We analyze the regularization properties of this algorithm, including the incorporation of prior properties of the desired solution into the solution subspace and the semiconvergence behavior of the regularized solution. To overcome instabilities caused by semiconvergence, we further propose two pGKB based hybrid regularization algorithms. All the proposed algorithms are tested on both small-scale and large-scale linear inverse problems. Numerical results demonstrate that these iterative algorithms exhibit excellent performance, outperforming other state-of-the-art algorithms in some cases.},
  archive      = {J_SISC},
  author       = {Haibo Li},
  doi          = {10.1137/23M1593802},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2607-A2633},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A preconditioned krylov subspace method for linear inverse problems with general-form tikhonov regularization},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A high-order fast direct solver for surface PDEs.
<em>SISC</em>, <em>46</em>(4), A2582–A2606. (<a
href="https://doi.org/10.1137/22M1525259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a fast direct solver for variable-coefficient elliptic PDEs on surfaces based on the hierarchical Poincaré–Steklov method. The method takes as input an unstructured, high-order quadrilateral mesh of a surface and discretizes surface differential operators on each element using a high-order spectral collocation scheme. Elemental solution operators and Dirichlet-to-Neumann maps tangent to the surface are precomputed and merged in a pairwise fashion to yield a hierarchy of solution operators that may be applied in operations for a mesh with degrees of freedom. The resulting fast direct solver may be used to accelerate high-order implicit time-stepping schemes, as the precomputed operators can be reused for fast elliptic solves on surfaces. On a standard laptop, precomputation for a 12th-order surface mesh with over 1 million degrees of freedom takes 10 seconds, while subsequent solves take only 0.25 seconds. We apply the method to a range of problems on both smooth surfaces and surfaces with sharp corners and edges, including the static Laplace–Beltrami problem, the Hodge decomposition of a tangential vector field, and some time-dependent nonlinear reaction-diffusion systems. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available”, as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/danfortunato/surface-hps-sisc.},
  archive      = {J_SISC},
  author       = {Daniel Fortunato},
  doi          = {10.1137/22M1525259},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2582-A2606},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A high-order fast direct solver for surface PDEs},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A levenberg–marquardt method for nonsmooth regularized least
squares. <em>SISC</em>, <em>46</em>(4), A2557–A2581. (<a
href="https://doi.org/10.1137/22M1538971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a Levenberg–Marquardt method for minimizing the sum of a smooth nonlinear least-squares term and a nonsmooth term . Both and may be nonconvex. Steps are computed by minimizing the sum of a regularized linear least-squares model and a model of using a first-order method such as the proximal gradient method. We establish global convergence to a first-order stationary point under the assumptions that and its Jacobian are Lipschitz continuous and is proper and lower semicontinuous. In the worst case, our method performs iterations to bring a measure of stationarity below . We also derive a trust-region variant that enjoys similar asymptotic worst-case iteration complexity as a special case of the trust-region algorithm of Aravkin, Baraldi, and Orban [SIAM J. Optim., 32 (2022), pp. 900–929]. We report numerical results on three examples: a group-lasso basis-pursuit denoise example, a nonlinear support vector machine, and parameter estimation in a neuroscience application. To implement those examples, we describe in detail how to evaluate proximal operators for separable and for the group lasso with trust-region constraint. In all cases, the Levenberg–Marquardt methods perform fewer outer iterations than either a proximal gradient method with adaptive step length or a quasi-Newton trust-region method, neither of which exploit the least-squares structure of the problem. Our results also highlight the need for more sophisticated subproblem solvers than simple first-order methods.},
  archive      = {J_SISC},
  author       = {Aleksandr Y. Aravkin and Robert Baraldi and Dominique Orban},
  doi          = {10.1137/22M1538971},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2557-A2581},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A Levenberg–Marquardt method for nonsmooth regularized least squares},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energetic variational neural network discretizations of
gradient flows. <em>SISC</em>, <em>46</em>(4), A2528–A2556. (<a
href="https://doi.org/10.1137/22M1529427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a structure-preserving Eulerian algorithm for solving -gradient flows and a structure-preserving Lagrangian algorithm for solving generalized diffusions. Both algorithms employ neural networks as tools for spatial discretization. Unlike most existing methods that construct numerical discretizations based on the strong or weak form of the underlying PDE, the proposed schemes are constructed based on the energy-dissipation law directly. This guarantees the monotonic decay of the system’s free energy, which avoids unphysical states of solutions and is crucial for the long-term stability of numerical computations. To address challenges arising from nonlinear neural network discretization, we perform temporal discretizations on these variational systems before spatial discretizations. This approach is computationally memory-efficient when implementing neural network-based algorithms. The proposed neural network-based schemes are mesh-free, allowing us to solve gradient flows in high dimensions. Various numerical experiments are presented to demonstrate the accuracy and energy stability of the proposed numerical schemes.},
  archive      = {J_SISC},
  author       = {Ziqing Hu and Chun Liu and Yiwei Wang and Zhiliang Xu},
  doi          = {10.1137/22M1529427},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2528-A2556},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Energetic variational neural network discretizations of gradient flows},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi-implicit fully exactly well-balanced relaxation
scheme for the shallow water system. <em>SISC</em>, <em>46</em>(4),
A2503–A2527. (<a href="https://doi.org/10.1137/23M1621289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This article focuses on the design of semi-implicit schemes that are fully well-balanced for the one-dimensional shallow water equations, that is, schemes that preserve all smooth steady states of the system and not just water-at-rest equilibria. The proposed methods outperform standard explicit schemes in the low-Froude regime, where the celerity is much larger than the fluid velocity, eliminating the need for a large number of iterations on large time intervals. In this work, splitting and relaxation techniques are combined in order to obtain fully well-balanced semi-implicit first and second order schemes. In contrast to recent Lagrangian-based approaches, this one allows the preservation of all the steady states while avoiding the complexities associated with Lagrangian formalism.},
  archive      = {J_SISC},
  author       = {Celia Caballero-Cárdenas and Manuel Jesús Castro and Christophe Chalons and Tomás Morales de Luna and María Luz Muñoz-Ruiz},
  doi          = {10.1137/23M1621289},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2503-A2527},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A semi-implicit fully exactly well-balanced relaxation scheme for the shallow water system},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multilevel particle filters for a class of partially
observed piecewise deterministic markov processes. <em>SISC</em>,
<em>46</em>(4), A2475–A2502. (<a
href="https://doi.org/10.1137/23M1600505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we consider the filtering of a class of partially observed piecewise deterministic Markov processes. In particular, we assume that an ordinary differential equation (ODE) drives the deterministic element and can only be solved numerically via a time discretization. We develop, based upon the approach in Lemaire, Thieullen, and Thomas [Adv. Appl. Probab., 52 (2020), pp. 138–172], a new particle and multilevel particle filter (MLPF) in order to approximate the filter associated to the discretized ODE. We provide a bound on the mean square error associated to the MLPF which provides guidance on setting the simulation parameters of the algorithm and implies that significant computational gains can be obtained versus using a particle filter. Our theoretical claims are confirmed in several numerical examples.},
  archive      = {J_SISC},
  author       = {Ajay Jasra and Kengo Kamatani and Mohamed Maama},
  doi          = {10.1137/23M1600505},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2475-A2502},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multilevel particle filters for a class of partially observed piecewise deterministic markov processes},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Domain decomposition learning methods for solving elliptic
problems. <em>SISC</em>, <em>46</em>(4), A2445–A2474. (<a
href="https://doi.org/10.1137/22M1515392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. With the aid of hardware and software developments, there has been a surge of interest in solving PDEs by deep learning techniques, and the integration with domain decomposition strategies has recently attracted considerable attention due to its enhanced representation and parallelization capacity of the network solution. While there are already several works that substitute the numerical solver of overlapping Schwarz methods with the deep learning approach, the nonoverlapping counterpart has not been thoroughly studied yet because of the inevitable interface overfitting problem that would propagate the errors to neighboring subdomains and eventually hamper the convergence of outer iteration. In this work, a novel learning approach, i.e., the compensated deep Ritz method using neural network extension operators, is proposed to enable the flux transmission across subregion interfaces with guaranteed accuracy, thereby allowing us to construct effective learning algorithms for realizing the more general nonoverlapping domain decomposition methods in the presence of overfitted interface conditions. Numerical experiments on a series of elliptic boundary value problems, including the regular and irregular interfaces, low and high dimensions, and smooth and high-contrast coefficients on multidomains, are carried out to validate the effectiveness of our proposed domain decomposition learning algorithms. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available&quot; as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available in https://github.com/AI4SC-TJU or in the supplementary materials.},
  archive      = {J_SISC},
  author       = {Qi Sun and Xuejun Xu and Haotian Yi},
  doi          = {10.1137/22M1515392},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2445-A2474},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Domain decomposition learning methods for solving elliptic problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A full approximation scheme multilevel method for nonlinear
variational inequalities. <em>SISC</em>, <em>46</em>(4), A2421–A2444.
(<a href="https://doi.org/10.1137/23M1594200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present the full approximation scheme constraint decomposition (FASCD) multilevel method for solving variational inequalities (VIs). FASCD is a joint extension of both the full approximation scheme multigrid technique for nonlinear partial differential equations, due to A. Brandt, and the constraint decomposition (CD) method introduced by X.-C. Tai for VIs arising in optimization. We extend the CD idea by exploiting the telescoping nature of certain subset decompositions arising from multilevel mesh hierarchies. When a reduced-space (active set) Newton method is applied as a smoother, with work proportional to the number of unknowns on a given mesh level, FASCD V-cycles exhibit nearly mesh-independent convergence rates. The full multigrid cycle version is an optimal solver. The example problems include differential operators which are symmetric linear, nonsymmetric linear, and nonlinear, in unilateral and bilateral VI problems. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://bitbucket.org/pefarrell/fascd/, where the software used to produce the results in section 8 is archived at tag v1.0, and at https://doi.org/10.5281/zenodo.10476845 or in the supplementary materials (pefarrell-fascd-6407e9f547d6.zip [225KB]). The authors used Firedrake master revision c5e939dde.},
  archive      = {J_SISC},
  author       = {Ed Bueler and Patrick E. Farrell},
  doi          = {10.1137/23M1594200},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2421-A2444},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A full approximation scheme multilevel method for nonlinear variational inequalities},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing <span
class="math inline"><strong>H</strong><sup><strong>2</strong></sup></span>-conforming
finite element approximations without having to implement <span
class="math inline"><strong>C</strong><sup><strong>1</strong></sup></span>-elements.
<em>SISC</em>, <em>46</em>(4), A2398–A2420. (<a
href="https://doi.org/10.1137/23M1615486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a method to compute the -conforming finite element approximation to planar fourth order elliptic problems without having to implement elements. The algorithm consists of replacing the original -conforming scheme with preprocessing and postprocessing steps that require only an -conforming Poisson type solve and an inner Stokes-like problem that again only requires at most -conformity. We then demonstrate the method applied to the Morgan–Scott elements with three numerical examples. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://doi.org/10.5281/zenodo.10070565.},
  archive      = {J_SISC},
  author       = {Mark Ainsworth and Charles Parker},
  doi          = {10.1137/23M1615486},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2398-A2420},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Computing \(\boldsymbol{H}^{\boldsymbol{2}}\)-conforming finite element approximations without having to implement \(\boldsymbol{C}^{\boldsymbol{1}}\)-elements},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Super-localized orthogonal decomposition for high-frequency
helmholtz problems. <em>SISC</em>, <em>46</em>(4), A2377–A2397. (<a
href="https://doi.org/10.1137/21M1465950">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a novel variant of the Localized Orthogonal Decomposition (LOD) method for time-harmonic scattering problems of Helmholtz type with high wavenumber . On a coarse mesh of width , the proposed method identifies local finite element source terms that yield rapidly decaying responses under the solution operator. They can be constructed to high accuracy from independent local snapshot solutions on patches of width and are used as problem-adapted basis functions in the method. In contrast to the classical LOD and other state-of-the-art multiscale methods, two- and three-dimensional numerical computations show that the localization error decays super-exponentially as the oversampling parameter is increased. This suggests that optimal convergence is observed under the substantially relaxed oversampling condition with denoting the spatial dimension. Numerical experiments demonstrate the significantly improved offline and online performance of the method also in the case of heterogeneous media and perfectly matched layers.},
  archive      = {J_SISC},
  author       = {Philip Freese and Moritz Hauck and Daniel Peterseim},
  doi          = {10.1137/21M1465950},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2377-A2397},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Super-localized orthogonal decomposition for high-frequency helmholtz problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive factorized nyström preconditioner for
regularized kernel matrices. <em>SISC</em>, <em>46</em>(4), A2351–A2376.
(<a href="https://doi.org/10.1137/23M1565139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The spectrum of a kernel matrix significantly depends on the parameter values of the kernel function used to define the kernel matrix. This makes it challenging to design a preconditioner for a regularized kernel matrix that is robust across different parameter values. This paper proposes the adaptive factorized Nyström (AFN) preconditioner. The preconditioner is designed for the case where the rank of the Nyström approximation is large, i.e., for kernel function parameters that lead to kernel matrices with eigenvalues that decay slowly. AFN deliberately chooses a well-conditioned submatrix to solve with and corrects a Nyström approximation with a factorized sparse approximate matrix inverse. This makes AFN efficient for kernel matrices with large numerical ranks. AFN also adaptively chooses the size of this submatrix to balance accuracy and cost. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/scalable-matrix/H2Pack/tree/AFN_precond and in the supplementary materials (H2Pack.zip [3.99MB]).},
  archive      = {J_SISC},
  author       = {Shifan Zhao and Tianshi Xu and Hua Huang and Edmond Chow and Yuanzhe Xi},
  doi          = {10.1137/23M1565139},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2351-A2376},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An adaptive factorized nyström preconditioner for regularized kernel matrices},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient frequency-independent numerical method for
computing the far-field pattern induced by polygonal obstacles.
<em>SISC</em>, <em>46</em>(4), A2324–A2350. (<a
href="https://doi.org/10.1137/23M1612160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For problems of time-harmonic scattering by rational polygonal obstacles, embedding formulae express the far-field pattern induced by any incident plane wave in terms of the far-field patterns for a relatively small (frequency-independent) set of canonical incident angles. Although these remarkable formulae are exact in theory, here we demonstrate that (i) they are highly sensitive to numerical errors in practice, and (ii) direct calculation of the coefficients in these formulae may be impossible for particular sets of canonical incident angles, even in exact arithmetic. Only by overcoming these practical issues can embedding formulae provide a highly efficient approach to computing the far-field pattern induced by a large number of incident angles. Here we address challenges (i) and (ii), supporting our theory with numerical experiments. Challenge (i) is solved using techniques from computational complex analysis: we reformulate the embedding formula as a complex contour integral and prove that this is much less sensitive to numerical errors. In practice, this contour integral can be efficiently evaluated by residue calculus. Challenge (ii) is addressed using techniques from numerical linear algebra: we oversample, considering more canonical incident angles than are necessary, thus expanding the set of valid coefficient vectors. The coefficient vector can then be selected using either a least squares approach or column subset selection.},
  archive      = {J_SISC},
  author       = {Andrew Gibbs and Stephen Langdon},
  doi          = {10.1137/23M1612160},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2324-A2350},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An efficient frequency-independent numerical method for computing the far-field pattern induced by polygonal obstacles},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024b). On generalized preconditioners for time-parallel parabolic
optimal control. <em>SISC</em>, <em>46</em>(4), A2298–A2323. (<a
href="https://doi.org/10.1137/23M1553194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The ParaDiag family of algorithms solves differential equations by using preconditioners that can be inverted in parallel through diagonalization. In the context of optimal control of linear parabolic PDEs, the state-of-the-art ParaDiag method is limited to solving self-adjoint problems with a tracking objective. We propose three improvements to the ParaDiag method: the use of alpha-circulant matrices to construct an alternative preconditioner, a generalization of the algorithm for solving non-self-adjoint equations, and the formulation of an algorithm for terminal-cost objectives. We present novel analytic results about the eigenvalues of the preconditioned systems for all discussed ParaDiag algorithms in the case of self-adjoint equations, which proves the favorable properties of the alpha-circulant preconditioner. We use these results to perform a theoretical parallel-scaling analysis of ParaDiag for self-adjoint problems. Numerical tests confirm our findings and suggest that the self-adjoint behavior, which is backed by theory, generalizes to the non-self-adjoint case. We provide a sequential, open-source reference solver in MATLAB for all discussed algorithms. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available,” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://gitlab.kuleuven.be/numa/public/pintopt or in the supplementary materials (repro-generalized-paradiag.zip [86.4KB]).},
  archive      = {J_SISC},
  author       = {Arne Bouillon and Giovanni Samaey and Karl Meerbergen},
  doi          = {10.1137/23M1553194},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2298-A2323},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On generalized preconditioners for time-parallel parabolic optimal control},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient tensor-product spectral-element operators with the
summation-by-parts property on curved triangles and tetrahedra.
<em>SISC</em>, <em>46</em>(4), A2270–A2297. (<a
href="https://doi.org/10.1137/23M1573963">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present an extension of the summation-by-parts (SBP) framework to tensor-product spectral-element operators in collapsed coordinates. The proposed approach enables the construction of provably stable discretizations of arbitrary order which combine the geometric flexibility of unstructured triangular and tetrahedral meshes with the efficiency of sum-factorization algorithms. Specifically, a methodology is developed for constructing triangular and tetrahedral spectral-element operators of any order which possess the SBP property (i.e., satisfying a discrete analogue of integration by parts) as well as a tensor-product decomposition. Such operators are then employed within the context of discontinuous spectral-element methods based on nodal expansions collocated at the tensor-product quadrature nodes as well as modal expansions employing Proriol–Koornwinder–Dubiner polynomials, the latter approach resolving the time step limitation associated with the singularity of the collapsed coordinate transformation. Energy-stable formulations for curvilinear meshes are obtained using a skew-symmetric splitting of the metric terms, and a weight-adjusted approximation is used to efficiently invert the curvilinear modal mass matrix. The proposed schemes are compared to those using nontensorial multidimensional SBP operators and are found to offer comparable accuracy to such schemes in the context of smooth linear advection problems on curved meshes, but at a reduced computational cost for higher polynomial degrees. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and Data Available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/tristanmontoya/ReproduceSBPSimplex and in the supplementary materials (reproducibility_repository.zip [35.7MB]).},
  archive      = {J_SISC},
  author       = {Tristan Montoya and David W. Zingg},
  doi          = {10.1137/23M1573963},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2270-A2297},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient tensor-product spectral-element operators with the summation-by-parts property on curved triangles and tetrahedra},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local structure-preserving relaxation method for equilibrium
of charged systems on unstructured meshes. <em>SISC</em>,
<em>46</em>(4), A2248–A2269. (<a
href="https://doi.org/10.1137/23M1607234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work considers charged systems described by the modified Poisson–Nernst–Planck (PNP) equations, which incorporate ionic steric effects and the Born solvation energy for dielectric inhomogeneity. Solving the equilibrium of modified PNP equations poses numerical challenges due to the emergence of sharp boundary layers caused by small Debye lengths, particularly when local ionic concentrations reach saturation. To address this, we first reformulate the problem as a constraint optimization, where the ionic concentrations on unstructured Delaunay nodes are treated as fractional particles moving along edges between nodes. The electric fields are then updated to minimize the objective free energy while satisfying the discrete Gauss law. We develop a local relaxation method on unstructured meshes that inherently respects the discrete Gauss law, ensuring curl-free electric fields. Numerical analysis demonstrates that the optimal mass of the moving fractional particles guarantees the positivity of both ionic and solvent concentrations. Additionally, the free energy of the charged system consistently decreases during successive updates of ionic concentrations and electric fields. We conduct numerical tests to validate the expected numerical accuracy, positivity, free-energy dissipation, and robustness of our method in simulating charged systems with sharp boundary layers.},
  archive      = {J_SISC},
  author       = {Zhonghua Qiao and Zhenli Xu and Qian Yin and Shenggao Zhou},
  doi          = {10.1137/23M1607234},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2248-A2269},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Local structure-preserving relaxation method for equilibrium of charged systems on unstructured meshes},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new thermodynamically compatible finite volume scheme for
lagrangian gas dynamics. <em>SISC</em>, <em>46</em>(4), A2224–A2247. (<a
href="https://doi.org/10.1137/23M1580863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The equations of Lagrangian gas dynamics fall into the larger class of overdetermined hyperbolic and thermodynamically compatible (HTC) systems of partial differential equations. They satisfy an entropy inequality (second principle of thermodynamics) and conserve total energy (first principle of thermodynamics). The aim of this work is to construct a novel thermodynamically compatible cell-centered Lagrangian finite volume scheme on unstructured meshes. Unlike in existing schemes, we choose to directly discretize the entropy inequality, hence obtaining total energy conservation as a consequence of the new thermodynamically compatible discretization of the other equations. First, the governing equations are written in fluctuation form. Next, the noncompatible centered numerical fluxes are corrected according to the approach recently introduced by Abgrall et al. using a scalar correction factor that is defined at the nodes of the grid. This perfectly fits into the formalism of nodal solvers which is typically adopted in cell-centered Lagrangian finite volume methods. Semidiscrete entropy conservative and entropy stable Lagrangian schemes are devised, and they are adequately blended together via a convex combination based on either a priori or a posteriori detectors of discontinuous solutions. The nonlinear stability in the energy norm is rigorously demonstrated, and the new schemes are provably positivity preserving for density and pressure. Furthermore, they exhibit zero numerical diffusion for isentropic flows while still being nonlinearly stable. The new schemes are tested against classical benchmarks for Lagrangian hydrodynamics, assessing their convergence and robustness and comparing their numerical dissipation with classical Lagrangian finite volume methods.},
  archive      = {J_SISC},
  author       = {Walter Boscheri and Michael Dumbser and Pierre-Henri Maire},
  doi          = {10.1137/23M1580863},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2224-A2247},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A new thermodynamically compatible finite volume scheme for lagrangian gas dynamics},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modeling diffusion in one dimensional discontinuous media
under generalized permeable interface conditions: Theory and algorithms.
<em>SISC</em>, <em>46</em>(4), A2202–A2223. (<a
href="https://doi.org/10.1137/23M1590846">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Diffusive transport in media with discontinuous properties is a challenging problem that arises in many applications. This paper focuses on one dimensional discontinuous media with generalized permeable boundary conditions at the discontinuity interface. It presents novel analytical expressions from the method of images to simulate diffusive processes, such as mass or thermal transport. The analytical expressions are used to formulate a generalization of the existing Skew Brownian Motion, HYMLA, and Uffink’s method, here named as GSBM, GHYMLA, and GUM, respectively, to handle generic interface conditions. The algorithms rely upon the random walk method and are tested by simulating transport in a bimaterial and in a multilayered medium with piecewise constant properties. The results indicate that the GUM algorithm provides the best performance in terms of accuracy and computational cost. The methods proposed can be applied for simulation of a wide range of differential problems.},
  archive      = {J_SISC},
  author       = {Elisa Baioni and Antoine Lejay and Géraldine Pichot and Giovanni Michele Porta},
  doi          = {10.1137/23M1590846},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2202-A2223},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Modeling diffusion in one dimensional discontinuous media under generalized permeable interface conditions: Theory and algorithms},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Transformed model reduction for partial differential
equations with sharp inner layers. <em>SISC</em>, <em>46</em>(4),
A2178–A2201. (<a href="https://doi.org/10.1137/23M1589980">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Small parameters in partial differential equations can give rise to solutions with sharp inner layers that evolve over time. However, the standard model reduction method becomes inefficient when applied to these problems due to the slow decaying Kolmogorov -width of the solution manifold. To address this issue, a natural approach is to transform the equation in such a way that the transformed solution manifold exhibits a fast decaying Kolmogorov -width. In this paper, we focus on the Allen–Cahn equation as a model problem. We employ asymptotic analysis to identify slow variables and perform a transformation of the partial differential equations accordingly. Subsequently, we apply the proper orthogonal decomposition method and a QR discrete empirical interpolation method (qDEIM) technique to the transformed equation with the slow variables. Numerical experiments demonstrate that the new model reduction method yields significantly improved results compared to direct model reduction applied to the original equation. Furthermore, this approach can be extended to other equations, such as the convection equation and the Burgers equation. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/toreanony/TransformedModelReduction and in the supplementary materials (TransformedModelReduction-master.zip [19.1KB]).},
  archive      = {J_SISC},
  author       = {Tianyou Tang and Xianmin Xu},
  doi          = {10.1137/23M1589980},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2178-A2201},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Transformed model reduction for partial differential equations with sharp inner layers},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A highly efficient and accurate divergence-free spectral
method for the curl-curl equation in two and three dimensions.
<em>SISC</em>, <em>46</em>(4), A2150–A2177. (<a
href="https://doi.org/10.1137/23M1587038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present a fast divergence-free spectral algorithm for the curl-curl problem. Divergence-free bases in two and three dimensions are constructed by using the generalized Jacobi polynomials. An accurate spectral method with exact preservation of the divergence-free constraint pointwisely is then proposed, and its corresponding error estimate is established. We then present a highly efficient solution algorithm based on a combination of the matrix-free preconditioned Krylov subspace iterative method and a fully diagonalizable auxiliary problem, which is derived from the spectral discretizations of generalized eigenvalue problems of Laplace and biharmonic operators. We rigorously prove that the dimensions of the invariant subspace of the preconditioned linear system resulting from the divergence-free spectral method with respect to the dominant eigenvalue 1 are and for two- and three-dimensional problems with and unknowns, respectively. Thus, the proposed method usually takes only several iterations to converge, and, astonishingly, as the problem size (polynomial order) increases, the number of iterations will decrease, even for highly indefinite system and oscillatory solutions. As a result, the computational cost of the solution algorithm is only a small multiple of and floating number operations for two- and three-dimensional problems, respectively. Plenty of numerical examples for solving the curl-curl problem with both constant and variable coefficients in two and three dimensions are presented to demonstrate the accuracy and efficiency of the proposed method.},
  archive      = {J_SISC},
  author       = {Lechang Qin and Changtao Sheng and Zhiguo Yang},
  doi          = {10.1137/23M1587038},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2150-A2177},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A highly efficient and accurate divergence-free spectral method for the curl-curl equation in two and three dimensions},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Global minimization of polynomial integral functionals.
<em>SISC</em>, <em>46</em>(4), A2123–A2149. (<a
href="https://doi.org/10.1137/23M1592584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We describe a “discretize-then-relax” strategy to globally minimize integral functionals over functions in a Sobolev space subject to Dirichlet boundary conditions. The strategy applies whenever the integral functional depends polynomially on and its derivatives, even if it is nonconvex. The “discretize” step uses a bounded finite element scheme to approximate the integral minimization problem with a convergent hierarchy of polynomial optimization problems over a compact feasible set, indexed by the decreasing size of the finite element mesh. The “relax” step employs sparse moment-sum-of-squares relaxations to approximate each polynomial optimization problem with a hierarchy of convex semidefinite programs, indexed by an increasing relaxation order . We prove that, as and , solutions of such semidefinite programs provide approximate minimizers that converge in a suitable sense (including in certain norms) to the global minimizer of the original integral functional if it is unique. We also report computational experiments showing that our numerical strategy works well even when technical conditions required by our theoretical analysis are not satisfied.},
  archive      = {J_SISC},
  author       = {Giovanni Fantuzzi and Federico Fuentes},
  doi          = {10.1137/23M1592584},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {8},
  number       = {4},
  pages        = {A2123-A2149},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Global minimization of polynomial integral functionals},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Observability and effective region of partial differential
equations with application to data assimilation. <em>SISC</em>,
<em>46</em>(3), C249–C271. (<a
href="https://doi.org/10.1137/23M1586690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we introduce a new definition of observability for dynamical systems, formulated on the principles of dynamic optimization. This definition gives rise to the concept of an effective region, specifically designed for partial differential equations (PDEs). The usefulness of these concepts is demonstrated through examples of state estimation using observational information for PDEs in a limited area. The findings empower a more efficient analysis of PDE observability. By confining computations to an effective region significantly smaller than the overall region in which the PDE is defined, we demonstrate a substantial reduction in computational demand of evaluating observability. As an application of observability and effective region, we propose a learning-based surrogate data assimilation (DA) model for efficient state estimation in a limited area. Our model employs a feedforward neural network for online computation, eliminating the need for integrating high-dimensional limited-area models. This approach offers significant computational advantages over traditional DA algorithms. Furthermore, our method avoids the requirement of lateral boundary conditions for the limited-area model in both online and offline computations.},
  archive      = {J_SISC},
  author       = {Wei Kang and Liang Xu and Hong Zhou},
  doi          = {10.1137/23M1586690},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {C249-C271},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Observability and effective region of partial differential equations with application to data assimilation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Randomized kaczmarz in adversarial distributed setting.
<em>SISC</em>, <em>46</em>(3), B354–B376. (<a
href="https://doi.org/10.1137/23M1554357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Developing large-scale distributed methods that are robust to the presence of adversarial or corrupted workers is an important part of making such methods practical for real-world problems. In this paper, we propose an iterative approach that is adversary-tolerant for convex optimization problems. By leveraging simple statistics, our method ensures convergence and is capable of adapting to adversarial distributions. Additionally, the efficiency of the proposed methods for solving convex problems is shown in simulations with the presence of adversaries. Through simulations, we demonstrate the efficiency of our approach in the presence of adversaries and its ability to identify adversarial workers with high accuracy and tolerate varying levels of adversary rates.},
  archive      = {J_SISC},
  author       = {Longxiu Huang and Xia Li and Deanna Needell},
  doi          = {10.1137/23M1554357},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {B354-B376},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Randomized kaczmarz in adversarial distributed setting},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An operator-splitting optimization approach for phase-field
simulation of equilibrium shapes of crystals. <em>SISC</em>,
<em>46</em>(3), B331–B353. (<a
href="https://doi.org/10.1137/23M161183X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Computing equilibrium shapes of crystals (ESCs) is a challenging problem in materials science that involves minimizing an orientation-dependent (i.e., anisotropic) surface energy functional subject to a prescribed mass constraint. The highly nonlinear and singular anisotropic terms in the problem make it very challenging from both analytical and numerical aspects. Especially when the strength of anisotropy is very strong (i.e., strongly anisotropic cases), the ESCs will form some singular, sharp corners even if the surface energy function is smooth. Traditional numerical approaches, such as the gradient flow, are unable to produce true sharp corners due to the necessary addition of a high-order regularization term that penalizes sharp corners and rounds them off. In this paper, we propose a new numerical method based on the Davis–Yin splitting (DYS) optimization algorithm to predict the ESCs instead of using gradient flow approaches. We discretize the infinite-dimensional phase-field energy functional in the absence of regularization terms and transform it into a finite-dimensional constraint minimization problem. The resulting optimization problem is solved using the DYS method, which automatically guarantees the mass-conservation and bound-preserving properties. We also prove the global convergence of the proposed algorithm. These desired properties are numerically observed. In particular, the proposed method can produce real sharp corners with satisfactory accuracy. Finally, we present numerous numerical results to demonstrate that the ESCs can be well simulated under different types of anisotropic surface energies, which also confirms the effectiveness and efficiency of the proposed method.},
  archive      = {J_SISC},
  author       = {Zeyu Zhou and Wen Huang and Wei Jiang and Zhen Zhang},
  doi          = {10.1137/23M161183X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {B331-B353},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An operator-splitting optimization approach for phase-field simulation of equilibrium shapes of crystals},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive space-time domain decomposition for multiphase flow
in porous media with bound constraints. <em>SISC</em>, <em>46</em>(3),
B306–B330. (<a href="https://doi.org/10.1137/23M1578139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper proposes an adaptive space-time algorithm based on domain decomposition for the large-scale simulation of a recently developed thermodynamically consistent reservoir problem. In the approach, the bound constraints are represented by means of a minimum-type complementarity function to enforce the positivity of the reservoir model, and a space-time mixed finite element method is applied for the parallel-in-time monolithic discretization. In particular, we propose a time-adaptive strategy using the improved backward differencing formula of second order, to take full advantage of the high degree of space-time parallelism. Moreover, the complicated dynamics with higher nonlinearity of space-time discretization require some innovative nonlinear and linear solution strategies. Therefore, we present a class of modified semismooth Newton algorithms to enhance the convergence rate of nonlinear iterations. Multilevel space-time restricted additive Schwarz algorithms, whose subdomains cover both space and time variables, are also studied for domain decomposition-based preconditioning. Numerical experiments demonstrate the robustness and parallel scalability of the proposed adaptive space-time algorithm on a supercomputer with tens of thousands of processor cores.},
  archive      = {J_SISC},
  author       = {Tianpei Cheng and Haijian Yang and Jizu Huang and Chao Yang},
  doi          = {10.1137/23M1578139},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {B306-B330},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Adaptive space-time domain decomposition for multiphase flow in porous media with bound constraints},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Finite time horizon mixed control of vibrational systems.
<em>SISC</em>, <em>46</em>(3), B280–B305. (<a
href="https://doi.org/10.1137/22M1488648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider a vibrational system control problem over a finite time horizon. The performance measure of the system is taken to be a -mixed norm which generalizes the standard norm. We present an algorithm for efficient calculation of this norm in the case when the system is parameter dependent and the number of inputs or outputs of the system is significantly smaller than the order of the system. Our approach is based on a novel procedure which is not based on solving Lyapunov equations and which takes into account the structure of the system. We use a characterization of the norm given in terms of integrals which we solve using adaptive quadrature rules. This enables us to use recycling strategies as well as parallelization. The efficiency of the new algorithm allows for an analysis of the influence of various system parameters and different finite time horizons on the value of the -mixed norm. We illustrate our approach by numerical examples concerning an -mass oscillator with one damper.},
  archive      = {J_SISC},
  author       = {Ivica Nakić and Marinela Pilj Vidaković and Zoran Tomljanović},
  doi          = {10.1137/22M1488648},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {B280-B305},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Finite time horizon mixed control of vibrational systems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A bound-preserving and positivity-preserving high-order
arbitrary lagrangian-eulerian discontinuous galerkin method for
compressible multi-medium flows. <em>SISC</em>, <em>46</em>(3),
B254–B279. (<a href="https://doi.org/10.1137/23M1588810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work presents a novel bound-preserving and positivity-preserving direct arbitrary Lagrangian–Eulerian discontinuous Galerkin (ALE-DG) method for compressible multimedium flows by solving the five-equation transport model. The proposed method satisfies the discrete geometric conservation law (D-GCL) which indicates that uniform flow is precisely preserved during the simulation. More importantly, based on the D-GCL condition, we present a theoretical analysis on designing an efficient bound-preserving and positivity-preserving limiting strategy, which is able to maintain the boundedness of the volume fraction and the positivity of the partial density and internal energy, with the aim of avoiding the occurrence of inadmissible solutions and meanwhile improving the computational robustness. The accuracy and robustness of the proposed method are demonstrated by various one- and two-dimensional benchmark test cases. The numerical results verify the well capacity of the proposed high-order ALE-DG method for compressible multimedium flows with both the ideal and stiffened gas equation of state.},
  archive      = {J_SISC},
  author       = {Fan Zhang and Jian Cheng},
  doi          = {10.1137/23M1588810},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {B254-B279},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A bound-preserving and positivity-preserving high-order arbitrary lagrangian-eulerian discontinuous galerkin method for compressible multi-medium flows},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A framework for implementing general virtual element spaces.
<em>SISC</em>, <em>46</em>(3), B229–B253. (<a
href="https://doi.org/10.1137/23M1573653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we present a framework for the construction and implementation of general virtual element spaces based on projections built from constrained least squares problems. Building on the triples used for finite element spaces, we introduce the concept of a virtual element method (VEM) tuple which encodes the necessary building blocks to construct these projections. Using this approach, a wide range of virtual element spaces can be defined. We discuss -conforming spaces for as well as divergence and curl free spaces. This general framework has the advantage of being easily integrated into any existing finite element package, and we demonstrate this within the open source software package Dune. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://gitlab.dune-project.org/dune-fem/dune-vem-paper and in the supplementary materials (128492_2_supp_546442_s3hsrj.zip [22KB]).},
  archive      = {J_SISC},
  author       = {Andreas Dedner and Alice Hodson},
  doi          = {10.1137/23M1573653},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {B229-B253},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A framework for implementing general virtual element spaces},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A parallel rank-adaptive integrator for dynamical low-rank
approximation. <em>SISC</em>, <em>46</em>(3), B205–B228. (<a
href="https://doi.org/10.1137/23M1565103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work introduces a parallel and rank-adaptive matrix integrator for dynamical low-rank approximation. The method is related to the previously proposed rank-adaptive basis update and Galerkin (BUG) integrator but differs significantly in that all arising differential equations, both for the basis and the Galerkin coefficients, are solved in parallel. Moreover, this approach eliminates the need for a potentially costly coefficient update with augmented basis matrices. The integrator also incorporates a new step rejection strategy that enhances the robustness of both the parallel integrator and the BUG integrator. By construction, the parallel integrator inherits the robust error bound of the BUG and projector-splitting integrators. Comparisons of the parallel and BUG integrators are presented by a series of numerical experiments which demonstrate the efficiency of the proposed method, for problems from radiative transfer and radiation therapy.},
  archive      = {J_SISC},
  author       = {Gianluca Ceruti and Jonas Kusch and Christian Lubich},
  doi          = {10.1137/23M1565103},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {B205-B228},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A parallel rank-adaptive integrator for dynamical low-rank approximation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matrix-free high-performance saddle-point solvers for
high-order problems in <span
class="math inline"><strong>H</strong>(𝐝𝐢𝐯 )</span>. <em>SISC</em>,
<em>46</em>(3), B179–B204. (<a
href="https://doi.org/10.1137/23M1568806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work describes the development of matrix-free GPU-accelerated solvers for high-order finite element problems in . The solvers are applicable to grad-div and Darcy problems in saddle-point formulation, and have applications in radiation diffusion and porous media flow problems, among others. Using the interpolation–histopolation basis (cf. [W. Pazner, T. Kolev, and C. R. Dohrmann, SIAM J. Sci. Comput., 45 (2023), pp. A675–A702]), efficient matrix-free preconditioners can be constructed for the -block and Schur complement of the block system. With these approximations, block-preconditioned MINRES converges in a number of iterations that is independent of the mesh size and polynomial degree. The approximate Schur complement takes the form of an M-matrix graph Laplacian and therefore can be well-preconditioned by highly scalable algebraic multigrid methods. High-performance GPU-accelerated algorithms for all components of the solution algorithm are developed, discussed, and benchmarked. Numerical results are presented on a number of challenging test cases, including the “crooked pipe” grad-div problem, the SPE10 reservoir modeling benchmark problem, and a nonlinear radiation diffusion test case.},
  archive      = {J_SISC},
  author       = {Will Pazner and Tzanio Kolev and Panayot S. Vassilevski},
  doi          = {10.1137/23M1568806},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {B179-B204},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Matrix-free high-performance saddle-point solvers for high-order problems in \(\boldsymbol{H}(\operatorname{\textbf{div}})\)},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid dealiasing of complex convolutions. <em>SISC</em>,
<em>46</em>(3), B159–B178. (<a
href="https://doi.org/10.1137/23M1552073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Efficient algorithms based on the fast Fourier transform are developed for computing linear convolutions. A hybrid approach is described that combines the conventional practice of explicit dealiasing (explicitly padding the input data with zeros) and implicit dealiasing (mathematically accounting for these zero values). The new approach generalizes implicit dealiasing to arbitrary padding ratios and includes explicit dealiasing as a special case. Unlike existing implementations of implicit dealiasing, hybrid dealiasing tailors its subtransform sizes to the convolution geometry. Multidimensional convolutions are implemented with hybrid dealiasing by decomposing them into lower-dimensional convolutions. Convolutions of complex-valued and Hermitian inputs of equal length are illustrated with pseudocode and implemented in the open-source FFTW++ library. Hybrid dealiasing is shown to outperform explicit dealiasing in one, two, and three dimensions. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and Data Available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available from https://github.com/dealias/fftwpp and in the supplementary materials.},
  archive      = {J_SISC},
  author       = {Noel Murasko and John C. Bowman},
  doi          = {10.1137/23M1552073},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {B159-B178},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Hybrid dealiasing of complex convolutions},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). EnKSGD: A class of preconditioned black box optimization and
inversion algorithms. <em>SISC</em>, <em>46</em>(3), A2101–A2122. (<a
href="https://doi.org/10.1137/23M1561142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we introduce the ensemble Kalman–Stein gradient descent (EnKSGD) class of algorithms. The EnKSGD class of algorithms builds on the ensemble Kalman filter (EnKF) line of work, applying techniques from sequential data assimilation to unconstrained optimization and parameter estimation problems. An essential idea is to exploit the EnKF as a black box (i.e., derivative-free, zeroth order) optimization tool if iterated to convergence. In this paper, we return to the foundations of the EnKF as a sequential data assimilation technique, including its continuous-time and mean-field limits, with the goal of developing faster optimization algorithms suited to noisy black box optimization and inverse problems. The resulting EnKSGD class of algorithms can be designed to both maintain the desirable property of affine-invariance and employ the well-known backtracking line search. Furthermore, EnKSGD algorithms are designed to not necessitate the subspace restriction property and to avoid the variance collapse property of previous iterated EnKF approaches to optimization, as both these properties can be undesirable in an optimization context. EnKSGD also generalizes beyond the loss and is thus applicable to a wider class of problems than the standard EnKF. Numerical experiments with empirical risk minimization type problems, including both linear and nonlinear least squares problems, as well as maximum likelihood estimation, demonstrate the faster empirical convergence of EnKSGD relative to alternative EnKF approaches to optimization. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and Data Available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/0x4249/EnKSGD and in the supplementary material (M156114_Supplementary_Materials.zip [106KB]).},
  archive      = {J_SISC},
  author       = {Brian Irwin and Sebastian Reich},
  doi          = {10.1137/23M1561142},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A2101-A2122},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {EnKSGD: A class of preconditioned black box optimization and inversion algorithms},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient and parallel solution of high-order continuous
time galerkin for dissipative and wave propagation problems.
<em>SISC</em>, <em>46</em>(3), A2073–A2100. (<a
href="https://doi.org/10.1137/23M1572787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose efficient and parallel algorithms for the implementation of the high-order continuous time Galerkin method for dissipative and wave propagation problems. By using Legendre polynomials as shape functions, we obtain a special structure of the stiffness matrix that allows us to extend the diagonal Padé approximation to solve ordinary differential equations with source terms. The unconditional stability, error estimates, and superconvergence at the nodes of the continuous time Galerkin method are proved. Numerical examples confirm our theoretical results.},
  archive      = {J_SISC},
  author       = {Zhiming Chen and Yong Liu},
  doi          = {10.1137/23M1572787},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A2073-A2100},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient and parallel solution of high-order continuous time galerkin for dissipative and wave propagation problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spectral analysis of implicit <span
class="math inline"><strong>S</strong></span>-stage block runge–kutta
preconditioners. <em>SISC</em>, <em>46</em>(3), A2047–A2072. (<a
href="https://doi.org/10.1137/23M1604266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We analyze the recently introduced family of preconditioners in [M. M. Rana et al., SIAM J. Sci. Comput., 43 (2021), pp. S475–S495] for the stage equations of implicit Runge–Kutta methods for -stage methods. We simplify the formulas for the eigenvalues and eigenvectors of the preconditioned systems for a general -stage method and use these to obtain convergence rate estimates for preconditioned GMRES for some common choices of the implicit Runge–Kutta methods. This analysis is based on understanding the inherent matrix structure of these problems and exploiting it to qualitatively predict and explain the main observed features of the GMRES convergence behavior, using tools from approximation and potential theory based on Schwarz–Christoffel maps for curves and close, connected domains in the complex plane. We illustrate our analysis with numerical experiments showing very close correspondence of the estimates and the observed behavior, suggesting the analysis reliably captures the essence of these preconditioners.},
  archive      = {J_SISC},
  author       = {Martin J. Gander and Michal Outrata},
  doi          = {10.1137/23M1604266},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A2047-A2072},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Spectral analysis of implicit \(\boldsymbol{S}\)-stage block Runge–Kutta preconditioners},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A riemannian dimension-reduced second-order method with
application in sensor network localization. <em>SISC</em>,
<em>46</em>(3), A2025–A2046. (<a
href="https://doi.org/10.1137/23M1567229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a cubic-regularized Riemannian optimization method (RDRSOM), which partially exploits the second-order information and achieves the iteration complexity of . In order to reduce the per-iteration computational cost, we further propose a practical version of RDRSOM which is an extension of the well-known Barzilai–Borwein method, which enjoys the worst-case iteration complexity of . Moreover, under more stringent conditions, RDRSOM achieves the iteration complexity of . We apply our method to solve a nonlinear formulation of the wireless sensor network localization problem whose feasible set is a Riemannian manifold that has not been considered in the literature before. Numerical experiments are conducted to verify the high efficiency of our algorithm compared to state-of-the-art Riemannian optimization methods and other nonlinear solvers.},
  archive      = {J_SISC},
  author       = {Tianyun Tang and Kim-Chuan Toh and Nachuan Xiao and Yinyu Ye},
  doi          = {10.1137/23M1567229},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A2025-A2046},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A riemannian dimension-reduced second-order method with application in sensor network localization},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new locally divergence-free path-conservative
central-upwind scheme for ideal and shallow water magnetohydrodynamics.
<em>SISC</em>, <em>46</em>(3), A1998–A2024. (<a
href="https://doi.org/10.1137/22M1539009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a new second-order unstaggered semidiscrete path-conservative central-upwind (PCCU) scheme for ideal and shallow water magnetohydrodynamics (MHD) equations. The new scheme possesses several important properties: it locally preserves the divergence-free constraint, it does not rely on any (approximate) Riemann problem solver, and it robustly produces high-resolution and nonoscillatory results. The derivation of the scheme is based on the Godunov–Powell nonconservative modifications of the studied MHD systems. The local divergence-free property is enforced by augmenting the modified systems with the evolution equations for the corresponding derivatives of the magnetic field components. These derivatives are then used to design a special piecewise linear reconstruction of the magnetic field, which guarantees a nonoscillatory nature of the resulting scheme. In addition, the proposed PCCU discretization accounts for the jump of the nonconservative product terms across cell interfaces, thereby ensuring stability. We test the proposed PCCU scheme on several benchmarks for both ideal and shallow water MHD systems. The obtained numerical results illustrate the performance of the new scheme, its robustness, and its ability not only to achieve high resolution, but also to preserve the positivity of computed quantities such as density, pressure, and water depth.},
  archive      = {J_SISC},
  author       = {Alina Chertock and Alexander Kurganov and Michael Redle and Kailiang Wu},
  doi          = {10.1137/22M1539009},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1998-A2024},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A new locally divergence-free path-conservative central-upwind scheme for ideal and shallow water magnetohydrodynamics},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The numerical flow iteration for the vlasov–poisson
equation. <em>SISC</em>, <em>46</em>(3), A1972–A1997. (<a
href="https://doi.org/10.1137/23M154710X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present the numerical flow iteration (NuFI) for solving the Vlasov–Poisson equation. In a certain sense specified later herein, NuFI provides infinite resolution of the distribution function. NuFI exactly preserves positivity, all -norms, charge, and entropy. Numerical experiments show no energy drift. Furthermore NuFI requires several orders of magnitude less memory than conventional approaches, and can very efficiently be parallelized on GPU clusters. Low fidelity simulations provide good qualitative results for extended periods of time and can be computed on low-cost workstations.},
  archive      = {J_SISC},
  author       = {Matthias Kirchhart and R. Paul Wilhelm},
  doi          = {10.1137/23M154710X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1972-A1997},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The numerical flow iteration for the Vlasov–Poisson equation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An adaptive covariance parameterization technique for the
ensemble gaussian mixture filter. <em>SISC</em>, <em>46</em>(3),
A1949–A1971. (<a href="https://doi.org/10.1137/22M1544312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The ensemble Gaussian mixture filter (EnGMF) combines the simplicity and power of Gaussian mixture models with the provable convergence and power of particle filters. The quality of the EnGMF heavily depends on the choice of covariance matrix in each Gaussian mixture. This work extends the EnGMF to an adaptive choice of covariance based on the parameterized estimates of the sample covariance matrix. Through the use of the expectation maximization algorithm, optimal choices of the covariance matrix parameters are computed in an online fashion. Numerical experiments on the Lorenz ’63 equations show that the proposed methodology converges to classical results known in particle filtering. Further numerical results with more advanced choices of covariance parameterization and the medium-size Lorenz ’96 equations show that the proposed approach can perform significantly better than the standard EnGMF and other classical data assimilation algorithms.},
  archive      = {J_SISC},
  author       = {Andrey A. Popov and Renato Zanetti},
  doi          = {10.1137/22M1544312},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1949-A1971},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An adaptive covariance parameterization technique for the ensemble gaussian mixture filter},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A simple and efficient convex optimization based
bound-preserving high order accurate limiter for
cahn–hilliard–navier–stokes system. <em>SISC</em>, <em>46</em>(3),
A1923–A1948. (<a href="https://doi.org/10.1137/23M1587853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For time-dependent PDEs, the numerical schemes can be rendered bound-preserving without losing conservation and accuracy by a postprocessing procedure of solving a constrained minimization in each time step. Such a constrained optimization can be formulated as a nonsmooth convex minimization, which can be efficiently solved by first order optimization methods, if using the optimal algorithm parameters. By analyzing the asymptotic linear convergence rate of the generalized Douglas–Rachford splitting method, optimal algorithm parameters can be approximately expressed as a simple function of the number of out-of-bounds cells. We demonstrate the efficiency of this simple choice of algorithm parameters by applying such a limiter to cell averages of a discontinuous Galerkin scheme solving phase field equations for 3D demanding problems. Numerical tests on a sophisticated 3D Cahn–Hilliard–Navier–Stokes system indicate that the limiter is high order accurate, very efficient, and well suited for large-scale simulations. For each time step, it takes at most 20 iterations for the Douglas–Rachford splitting to enforce bounds and conservation up to the round-off error, for which the computational cost is at most with being the total number of cells.},
  archive      = {J_SISC},
  author       = {Chen Liu and Beatrice Riviere and Jie Shen and Xiangxiong Zhang},
  doi          = {10.1137/23M1587853},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1923-A1948},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A simple and efficient convex optimization based bound-preserving high order accurate limiter for Cahn–Hilliard–Navier–Stokes system},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hermitian preconditioning for a class of non-hermitian
linear systems. <em>SISC</em>, <em>46</em>(3), A1903–A1922. (<a
href="https://doi.org/10.1137/23M1559026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This work considers the convergence of GMRES for nonsingular problems. GMRES is interpreted as the generalized conjugate residual method which allows for simple proofs of the convergence estimates. Preconditioning and weighted norms within GMRES are considered. The objective is to provide a way of choosing the preconditioner and GMRES norm that ensures fast convergence. The main focus of the article is on Hermitian preconditioning (even for non-Hermitian problems). It is proposed to choose a Hermitian preconditioner and to apply GMRES in the inner product induced by . If, moreover, the problem matrix is positive definite, then a new convergence bound is proved that depends only on how well preconditions the Hermitian part of , and on how non-Hermitian is. In particular, if a scalable preconditioner is known for the Hermitian part of , then the proposed method is also scalable. This result is illustrated numerically.},
  archive      = {J_SISC},
  author       = {Nicole Spillane},
  doi          = {10.1137/23M1559026},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1903-A1922},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Hermitian preconditioning for a class of non-hermitian linear systems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rank-minimizing and structured model inference.
<em>SISC</em>, <em>46</em>(3), A1879–A1902. (<a
href="https://doi.org/10.1137/23M1554308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. While extracting information from data with machine learning plays an increasingly important role, physical laws and other first principles continue to provide critical insights about systems and processes of interest in science and engineering. This work introduces a method that infers models from data with physical insights encoded in the form of structure and that minimizes the model order so that the training data are fitted well while redundant degrees of freedom without conditions and sufficient data to fix them are automatically eliminated. The models are formulated via solution matrices of specific instances of generalized Sylvester equations that enforce interpolation of the training data and relate the model order to the rank of the solution matrices. The proposed method numerically solves the Sylvester equations for minimal-rank solutions and so obtains models of low order. Numerical experiments demonstrate that the combination of structure preservation and rank minimization leads to accurate models with orders of magnitude fewer degrees of freedom than models of comparable prediction quality that are learned with structure preservation alone.},
  archive      = {J_SISC},
  author       = {Pawan Goyal and Benjamin Peherstorfer and Peter Benner},
  doi          = {10.1137/23M1554308},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1879-A1902},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Rank-minimizing and structured model inference},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Tensorial parametric model order reduction of nonlinear
dynamical systems. <em>SISC</em>, <em>46</em>(3), A1850–A1878. (<a
href="https://doi.org/10.1137/23M1553789">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. For a nonlinear dynamical system that depends on parameters, this paper introduces a novel tensorial reduced-order model (TROM). The reduced model is projection-based, and for systems with no parameters involved, it resembles proper orthogonal decomposition (POD) combined with the discrete empirical interpolation method (DEIM). For parametric systems, TROM employs low-rank tensor approximations in place of truncated SVD, a key dimension-reduction technique in POD with DEIM. Three popular low-rank tensor compression formats are considered for this purpose: canonical polyadic, Tucker, and tensor train. The use of multilinear algebra tools allows the incorporation of information about the parameter dependence of the system into the reduced model and leads to a POD-DEIM type ROM that (i) is parameter-specific (localized) and predicts the system dynamics for out-of-training set (unseen) parameter values, (ii) mitigates the adverse effects of high parameter space dimension, (iii) has online computational costs that depend only on tensor compression ranks but not on the full-order model size, and (iv) achieves lower reduced space dimensions compared to the conventional POD-DEIM ROM. This paper explains the method, analyzes its prediction power, and assesses its performance for two specific parameter-dependent nonlinear dynamical systems.},
  archive      = {J_SISC},
  author       = {Alexander V. Mamonov and Maxim A. Olshanskii},
  doi          = {10.1137/23M1553789},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1850-A1878},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Tensorial parametric model order reduction of nonlinear dynamical systems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast algebraic multigrid solver and accurate
discretization for highly anisotropic heat flux i: Open field lines.
<em>SISC</em>, <em>46</em>(3), A1821–A1849. (<a
href="https://doi.org/10.1137/23M155918X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a novel solver technique for the anisotropic heat flux equation, aimed at the high level of anisotropy seen in magnetic confinement fusion plasmas. Such problems pose two major challenges: (i) discretization accuracy and (ii) efficient implicit linear solvers. We simultaneously address each of these challenges by constructing a new finite element discretization with excellent accuracy properties, tailored to a novel solver approach based on algebraic multigrid (AMG) methods designed for advective operators. We pose the problem in a mixed formulation, introducing the directional temperature gradient as an auxiliary variable. The temperature and auxiliary fields are discretized in a scalar discontinuous Galerkin space with upwinding principles used for discretizations of advection. We demonstrate the proposed discretization’s superior accuracy over other discretizations of anisotropic heat flux, achieving error smaller for anisotropy ratio of , for closed field lines. The block matrix system is reordered and solved in an approach where the two advection operators are inverted using AMG solvers based on approximate ideal restriction, which is particularly efficient for upwind discontinuous Galerkin discretizations of advection. To ensure that the advection operators are nonsingular, in this paper we restrict ourselves to considering open (acyclic) magnetic field lines for the linear solvers. We demonstrate fast convergence of the proposed iterative solver in highly anisotropic regimes where other diffusion-based AMG methods fail.},
  archive      = {J_SISC},
  author       = {Golo A. Wimmer and Ben S. Southworth and Thomas J. Gregory and Xian-Zhu Tang},
  doi          = {10.1137/23M155918X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1821-A1849},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A fast algebraic multigrid solver and accurate discretization for highly anisotropic heat flux i: Open field lines},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A divergence preserving cut finite element method for darcy
flow. <em>SISC</em>, <em>46</em>(3), A1793–A1820. (<a
href="https://doi.org/10.1137/22M149702X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We study cut finite element discretizations of a Darcy interface problem based on the mixed finite element pairs , . Here is the space of discontinuous polynomial functions of degree less than or equal to and is the Raviart–Thomas space. We show that the standard ghost penalty stabilization, often added in the weak forms of cut finite element methods for stability and control of the condition number of the resulting linear system matrix, destroys the divergence-free property of the considered element pairs. Therefore, we propose new stabilization terms for the pressure and show that we recover the optimal approximation of the divergence without losing control of the condition number of the linear system matrix. We prove that with the new stabilization term the proposed cut finite element discretization results in pointwise divergence-free approximations of solenoidal velocity fields. We derive a priori error estimates for the proposed unfitted finite element discretization based on , . In addition, by decomposing the computational mesh into macroelements and applying ghost penalty terms only on interior edges of macroelements, stabilization is applied very restrictively and active only where needed. Numerical experiments with element pairs , and (where is the Brezzi–Douglas–Marini space) indicate that with the new method we have (1) optimal rates of convergence of the approximate velocity and pressure; (2) well-posed linear systems where the condition number of the system matrix scales as it does for fitted finite element discretizations; (3) optimal rates of convergence of the approximate divergence with pointwise divergence-free approximations of solenoidal velocity fields. All three properties hold independently of how the interface is positioned relative to the computational mesh. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/CutFEM/CutFEM-Library and in the supplementary materials (CutFEM-Library-master.zip [30.5MB]).},
  archive      = {J_SISC},
  author       = {Thomas Frachon and Peter Hansbo and Erik Nilsson and Sara Zahedi},
  doi          = {10.1137/22M149702X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1793-A1820},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A divergence preserving cut finite element method for darcy flow},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new preconditioned nonlinear conjugate gradient method in
real arithmetic for computing the ground states of rotational
bose–einstein condensate. <em>SISC</em>, <em>46</em>(3), A1764–A1792.
(<a href="https://doi.org/10.1137/23M1590317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a new nonlinear preconditioned conjugate gradient (PCG) method in real arithmetic for computing the ground states of rotational Bose–Einstein condensate, modeled by the Gross–Pitaevskii equation. Our algorithm presents a few improvements of the PCG method in complex arithmetic studied by Antoine, Levitt, and Tang [J. Comput. Phys., 343 (2017), pp. 92–109]. We show that the special structure of the energy functional and its gradient with respect to can be fully exploited in real arithmetic to evaluate them more efficiently. We propose a simple approach for fast evaluation of the energy functional, which enables exact line search. Most importantly, we derive the discrete Hessian operator of the energy functional and propose a shifted Hessian preconditioner for PCG, with which the ideal preconditioned Hessian has favorable eigenvalue distributions independent of the mesh size. This suggests that PCG with our ideal Hessian preconditioner is expected to exhibit mesh size-independent asymptomatic convergence behavior. In practice, our preconditioner is constructed by incomplete Cholesky factorization of the shifted discrete Hessian operator based on high-order finite difference discretizations. Numerical experiments in two-dimensional (2D) and three-dimensional (3D) domains show the efficiency of fast energy evaluation, the robustness of exact line search, and the improved convergence of PCG with our new preconditioner in iteration counts and runtime, notably for more challenging rotational BEC problems with high nonlinearity and rotational speed.},
  archive      = {J_SISC},
  author       = {Tianqi Zhang and Fei Xue},
  doi          = {10.1137/23M1590317},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1764-A1792},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A new preconditioned nonlinear conjugate gradient method in real arithmetic for computing the ground states of rotational Bose–Einstein condensate},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Linear-complexity black-box randomized compression of
rank-structured matrices. <em>SISC</em>, <em>46</em>(3), A1747–A1763.
(<a href="https://doi.org/10.1137/22M1528574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A randomized algorithm for computing a compressed representation of a given rank-structured matrix is presented. The algorithm interacts with only through its action on vectors. Specifically, it draws two tall thin matrices from a suitable distribution, and then reconstructs from the information contained in the set . For the specific case of a “Hierarchically Block Separable (HBS)” matrix (a.k.a. Hierarchically Semi-Separable matrix) of block rank , the number of samples required satisfies , with being representative. While a number of randomized algorithms for compressing rank-structured matrices have previously been published, the current algorithm appears to be the first that is both of truly linear complexity (no factors in the complexity bound) and fully “black box” in the sense that no matrix entry evaluation is required. Further, all samples can be extracted in parallel, enabling the algorithm to work in a “streaming” or “single view” mode.},
  archive      = {J_SISC},
  author       = {James Levitt and Per-Gunnar Martinsson},
  doi          = {10.1137/22M1528574},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1747-A1763},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Linear-complexity black-box randomized compression of rank-structured matrices},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Randomized tensor wheel decomposition. <em>SISC</em>,
<em>46</em>(3), A1714–A1746. (<a
href="https://doi.org/10.1137/23M1583934">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Tensor wheel (TW) decomposition is an elegant compromise of the popular tensor ring decomposition and fully connected tensor network decomposition, and it has many applications. In this work, we investigate the computation of this decomposition. Three randomized algorithms based on random sampling or random projection are proposed. Specifically, by defining a new tensor product called the subwheel product, the structures of the coefficient matrices of the alternating least squares subproblems from the minimization problem of TW decomposition are first figured out. Then, using the structures and the properties of the subwheel product, a random sampling algorithm based on leverage sampling and two random projection algorithms respectively based on Kronecker subsampled randomized Fourier transform and TensorSketch are derived. These algorithms can implement the sampling and projection on TW factors and hence can avoid forming the full coefficient matrices of subproblems. We present the complexity analysis and numerical performance on synthetic data, real data, and image reconstruction for our algorithms. Experimental results show that, compared with the deterministic algorithm in the literature, they need much less computing time while achieving similar accuracy and reconstruction effect. We also apply the proposed algorithms to tensor completion and find that the sampling-based algorithm always has excellent performance and the projection-based algorithms behave well when the sampling rate is higher than 50%.},
  archive      = {J_SISC},
  author       = {Mengyu Wang and Yajie Yu and Hanyu Li},
  doi          = {10.1137/23M1583934},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1714-A1746},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Randomized tensor wheel decomposition},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Spectral deferred correction methods for second-order
problems. <em>SISC</em>, <em>46</em>(3), A1690–A1713. (<a
href="https://doi.org/10.1137/23M1592596">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Spectral deferred corrections (SDC) are a class of iterative methods for the numerical solution of ordinary differential equations. SDC can be interpreted as a Picard iteration to solve a fully implicit collocation problem, preconditioned with a low-order method. It has been widely studied for first-order problems, using explicit, implicit, or implicit-explicit Euler and other low-order methods as preconditioner. For first-order problems, SDC achieves arbitrary order of accuracy and possesses good stability properties. While numerical results for SDC applied to the second-order Lorentz equations exist, no theoretical results are available for SDC applied to second-order problems. We present an analysis of the convergence and stability properties of SDC using velocity-Verlet as the base method for general second-order initial value problems. Our analysis proves that the order of convergence depends on whether the force in the system depends on the velocity. We also demonstrate that the SDC iteration is stable under certain conditions. Finally, we show that SDC can be computationally more efficient than a simple Picard iteration or a fourth-order Runge–Kutta–Nyström method. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available,” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/Parallel-in-Time/pySDC/tree/master/pySDC/projects/Second_orderSDC.},
  archive      = {J_SISC},
  author       = {Ikrom Akramov and Sebastian Götschel and Michael Minion and Daniel Ruprecht and Robert Speck},
  doi          = {10.1137/23M1592596},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1690-A1713},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Spectral deferred correction methods for second-order problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Point spread function approximation of high-rank hessians
with locally supported nonnegative integral kernels. <em>SISC</em>,
<em>46</em>(3), A1658–A1689. (<a
href="https://doi.org/10.1137/23M1584745">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present an efficient matrix-free point spread function (PSF) method for approximating operators that have locally supported nonnegative integral kernels. The PSF-based method computes impulse responses of the operator at scattered points and interpolates these impulse responses to approximate entries of the integral kernel. To compute impulse responses efficiently, we apply the operator to Dirac combs associated with batches of point sources, which are chosen by solving an ellipsoid packing problem. The ability to rapidly evaluate kernel entries allows us to construct a hierarchical matrix (H-matrix) approximation of the operator. Further matrix computations are then performed with fast H-matrix methods. This end-to-end procedure is illustrated on a blur problem. We demonstrate the PSF-based method’s effectiveness by using it to build preconditioners for the Hessian operator arising in two inverse problems governed by PDEs: inversion for the basal friction coefficient in an ice sheet flow problem and for the initial condition in an advective-diffusive transport problem. While for many ill-posed inverse problems the Hessian of the data misfit term exhibits a low-rank structure, and hence a low-rank approximation is suitable, for many problems of practical interest, the numerical rank of the Hessian is still large. The Hessian impulse responses, on the other hand, typically become more local as the numerical rank increases, which benefits the PSF-based method. Numerical results reveal that the preconditioner clusters the spectrum of the preconditioned Hessian near one, yielding roughly – reductions in the required number of PDE solves, as compared to classical regularization-based preconditioning and no preconditioning. We also present a comprehensive numerical study for the influence of various parameters (that control the shape of the impulse responses and the rank of the Hessian) on the effectiveness of the advection-diffusion Hessian approximation. The results show that the PSF-based method is able to form good approximations of high-rank Hessians using only a small number of operator applications.},
  archive      = {J_SISC},
  author       = {Nick Alger and Tucker Hartland and Noemi Petra and Omar Ghattas},
  doi          = {10.1137/23M1584745},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1658-A1689},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Point spread function approximation of high-rank hessians with locally supported nonnegative integral kernels},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multiscale hybrid method. <em>SISC</em>, <em>46</em>(3),
A1628–A1657. (<a href="https://doi.org/10.1137/22M1542556">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work we propose, analyze, and test a new multiscale finite element method called Multiscale Hybrid (MH) method. The method is built as a close relative to the Multiscale Hybrid Mixed (MHM) method, but with the fundamental difference that a novel definition of the Lagrange multiplier is introduced. The practical implication of this is that both the local problems to compute the basis functions, as well as the global problem, are elliptic, as opposed to the MHM method (and also other previous methods) where a mixed global problem is solved and constrained local problems are solved to compute the local basis functions. The error analysis of the method is based on a hybrid formulation, and a static condensation process is done at the discrete level, so the final global system only involves the Lagrange multipliers. We tested the performance of the method by means of numerical experiments for problems with multiscale coefficients, and we carried out comparisons with the MHM method in terms of performance, accuracy, and memory requirements.},
  archive      = {J_SISC},
  author       = {Gabriel R. Barrenechea and Antonio Tadeu A. Gomes and Diego Paredes},
  doi          = {10.1137/22M1542556},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1628-A1657},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A multiscale hybrid method},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Matrix-free monolithic multigrid methods for stokes and
generalized stokes problems. <em>SISC</em>, <em>46</em>(3), A1599–A1627.
(<a href="https://doi.org/10.1137/22M1504184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the widely used continuous - quadrilateral or hexahedral Taylor–Hood elements for the finite element discretization of the Stokes and generalized Stokes systems in two and three spatial dimensions. For the fast solution of the corresponding symmetric, but indefinite system of finite element equations, we propose and analyze matrix-free monolithic geometric multigrid solvers that are based on appropriately scaled Chebyshev–Jacobi smoothers. The analysis is based on results by Schöberl and Zulehner (2003). We present and discuss several numerical results for typical benchmark problems.},
  archive      = {J_SISC},
  author       = {Daniel Jodlbauer and Ulrich Langer and Thomas Wick and Walter Zulehner},
  doi          = {10.1137/22M1504184},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1599-A1627},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Matrix-free monolithic multigrid methods for stokes and generalized stokes problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Modified lawson methods for vlasov equations. <em>SISC</em>,
<em>46</em>(3), A1574–A1598. (<a
href="https://doi.org/10.1137/22M154301X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, Lawson type numerical methods are studied to solve Vlasov type equations on a phase space grid. These time integrators are known to satisfy enhanced stability properties in this context since they do not suffer from the stability condition induced from the linear part. We introduce here a class of modified Lawson integrators in which the linear part is approximated in such a way that some geometric properties of the underlying model are preserved, which has important consequences for the analysis of the scheme. Several Vlasov–Maxwell examples are presented to illustrate the good behavior of the approach.},
  archive      = {J_SISC},
  author       = {Benjamin Boutin and Anaïs Crestetto and Nicolas Crouseilles and Josselin Massot},
  doi          = {10.1137/22M154301X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1574-A1598},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Modified lawson methods for vlasov equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multigrid solvers for the de rham complex with optimal
complexity in polynomial degree. <em>SISC</em>, <em>46</em>(3),
A1549–A1573. (<a href="https://doi.org/10.1137/22M1537370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Riesz maps of the de Rham complex frequently arise as subproblems in the construction of fast preconditioners for more complicated problems. In this work, we present multigrid solvers for high-order finite-element discretizations of these Riesz maps with the same time and space complexity as sum-factorized operator application, i.e., with optimal complexity in polynomial degree in the context of Krylov methods. The key idea of our approach is to build new finite elements for each space in the de Rham complex with orthogonality properties in both the - and -inner products ( on the reference hexahedron. The resulting sparsity enables the fast solution of the patch problems arising in the Pavarino, Arnold–Falk–Winther, and Hiptmair space decompositions in the separable case. In the nonseparable case, the method can be applied to an auxiliary operator that is sparse by construction. With exact Cholesky factorizations of the sparse patch problems, the application complexity is optimal, but the setup costs and storage are not. We overcome this with the finer Hiptmair space decomposition and the use of incomplete Cholesky factorizations imposing the sparsity pattern arising from static condensation, which applies whether static condensation is used for the solver or not. This yields multigrid relaxations with time and space complexity that are both optimal in the polynomial degree. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://doi.org/10.5281/zenodo.7358044 and in the supplementary materials (pmg_de_rham.zip [61.2KB]).},
  archive      = {J_SISC},
  author       = {Pablo D. Brubeck and Patrick E. Farrell},
  doi          = {10.1137/22M1537370},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1549-A1573},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multigrid solvers for the de rham complex with optimal complexity in polynomial degree},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multilevel monte carlo with numerical smoothing for robust
and efficient computation of probabilities and densities. <em>SISC</em>,
<em>46</em>(3), A1514–A1548. (<a
href="https://doi.org/10.1137/22M1495718">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The multilevel Monte Carlo (MLMC) method is highly efficient for estimating expectations of a functional of a solution to a stochastic differential equation (SDE). However, MLMC estimators may be unstable and have a poor (noncanonical) complexity in the case of low regularity of the functional. To overcome this issue, we extend our previously introduced idea of numerical smoothing in [Quant. Finance, 23 (2023), pp. 209–227], in the context of deterministic quadrature methods to the MLMC setting. The numerical smoothing technique is based on root-finding methods combined with one-dimensional numerical integration with respect to a single well-chosen variable. This study is motivated by the computation of probabilities of events, pricing options with a discontinuous payoff, and density estimation problems for dynamics where the discretization of the underlying stochastic processes is necessary. The analysis and numerical experiments reveal that the numerical smoothing significantly improves the strong convergence and, consequently, the complexity and robustness (by making the kurtosis at deep levels bounded) of the MLMC method. In particular, we show that numerical smoothing enables recovering the MLMC complexities obtained for Lipschitz functionals due to the optimal variance decay rate when using the Euler–Maruyama scheme. For the Milstein scheme, numerical smoothing recovers the canonical MLMC complexity, even for the nonsmooth integrand mentioned above. Finally, our approach efficiently estimates univariate and multivariate density functions.},
  archive      = {J_SISC},
  author       = {Christian Bayer and Chiheb Ben Hammouda and Raúl Tempone},
  doi          = {10.1137/22M1495718},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1514-A1548},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multilevel monte carlo with numerical smoothing for robust and efficient computation of probabilities and densities},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Consensus-based rare event estimation. <em>SISC</em>,
<em>46</em>(3), A1487–A1513. (<a
href="https://doi.org/10.1137/23M1565966">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we introduce a new algorithm for rare event estimation based on adaptive importance sampling. We consider a smoothed version of the optimal importance sampling density, which is approximated by an ensemble of interacting particles. The particle dynamics is governed by a McKean–Vlasov stochastic differential equation, which was introduced and analyzed in [Carrillo et al., Stud. Appl. Math., 148 (2022), pp. 1069–1140] for consensus-based sampling and optimization of posterior distributions arising in the context of Bayesian inverse problems. We develop automatic updates for the internal parameters of our algorithm. This includes a novel time step size controller for the exponential Euler method, which discretizes the particle dynamics. The behavior of all parameter updates depends on easy to interpret accuracy criteria specified by the user. We show in numerical experiments that our method is competitive to state-of-the-art adaptive importance sampling algorithms for rare event estimation, namely a sequential importance sampling method and the ensemble Kalman filter for rare event estimation. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/AlthausKonstantin/rareeventestimation/tree/master/docs/figures_paper and in the supplementary materials (rareeventestimation-0.3.0.zip [9.66MB]).},
  archive      = {J_SISC},
  author       = {Konstantin Althaus and Iason Papaioannou and Elisabeth Ullmann},
  doi          = {10.1137/23M1565966},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1487-A1513},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Consensus-based rare event estimation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Algebraic multigrid methods for metric-perturbed coupled
problems. <em>SISC</em>, <em>46</em>(3), A1461–A1486. (<a
href="https://doi.org/10.1137/23M1572076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop multilevel methods for interface-driven multiphysics problems that can be coupled across dimensions and where complexity and strength of the interface coupling deteriorates the performance of standard methods. We focus on aggregation-based algebraic multigrid methods with custom smoothers that preserve the coupling information on each coarse level. We prove that, with the proper choice of subspace splitting, we obtain uniform convergence in discretization and physical parameters in the two-level setting. Additionally, we show parameter robustness and scalability with regard to the number of the degrees of freedom of the system on several numerical examples related to the biophysical processes in the brain, namely, the electric signaling in excitable tissue modeled by bidomain, the extracellular-membrane-intracellular (EMI) model, and reduced EMI equations. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/anabudisa/metric-amg-examples and in the supplementary materials (metric-amg-examples-master.zip [30KB]).},
  archive      = {J_SISC},
  author       = {Ana Budiša and Xiaozhe Hu and Miroslav Kuchta and Kent-Andre Mardal and Ludmil Zikatanov},
  doi          = {10.1137/23M1572076},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1461-A1486},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Algebraic multigrid methods for metric-perturbed coupled problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Exact simulation of the multifactor ornstein–uhlenbeck
driven stochastic volatility model. <em>SISC</em>, <em>46</em>(3),
A1441–A1460. (<a href="https://doi.org/10.1137/23M1595102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The classic exact simulation scheme for the Ornstein–Uhlenbeck driven stochastic volatility model is designed for the single volatility factor case. Extension to the multifactor case results in a cumbersome procedure requiring multiple numerical inversions of Laplace transforms and subsequent random sampling through numerical methods, resulting in it being perceptively slow to run. Moreover, for each volatility factor, the error is controlled by two parameters, ensuring difficult control of the bias. In this paper, we propose a new exact simulation scheme for the multifactor Ornstein–Uhlenbeck driven stochastic volatility model that is easier to implement, faster to run, and allows for an improved control of the error, which, in contrast to the existing method, is controlled by only one parameter, regardless of the number of volatility factors. Numerical results show that the proposed approach is three times faster than the original approach when one volatility factor is considered and 11 times faster when four volatility factors are considered, while still being theoretically exact.},
  archive      = {J_SISC},
  author       = {Riccardo Brignone},
  doi          = {10.1137/23M1595102},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1441-A1460},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Exact simulation of the multifactor Ornstein–Uhlenbeck driven stochastic volatility model},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A matrix-free exact newton method. <em>SISC</em>,
<em>46</em>(3), A1423–A1440. (<a
href="https://doi.org/10.1137/23M157017X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A modification of Newton’s method for solving systems of nonlinear equations is presented. The new matrix-free method is exact as opposed to a range of inexact Newton methods in the sense that both the Jacobians and the solutions to the linear Newton systems are computed without truncation. It relies on a given decomposition of a structurally dense invertible Jacobian of the residual into a product of structurally sparse invertible elemental Jacobians according to the chain rule of differentiation. Inspired by the adjoint mode of algorithmic differentiation, explicit accumulation of the Jacobian of the residual is avoided. Prospective, generally applicable implementations of the new method can be based on similar ideas. Sparsity is exploited for the direct solution of the linear Newton systems. Optimal exploitation of sparsity yields various well-known computationally intractable combinatorial optimization problems in sparse linear algebra such as Bandwidth or Directed Elimination Ordering. The method is motivated in the context of a decomposition into elemental Jacobians with bandwidth for . In the likely scenario of , the computational cost of the standard Newton algorithm is dominated by the cost of accumulating the Jacobian of the residual. It can be estimated as , thus exceeding the cost of for the direct solution of the linear Newton system. The new method reduces this cost to , yielding a potential improvement by a factor of . Supporting run time measurements are presented for the tridiagonal case showing a reduction of the computational cost by . Generalization yields the combinatorial Matrix-Free Exact Newton Step problem. We prove NP-completeness, and we present algorithmic components for building methods for the approximate solution. Potential applications of the matrix-free exact Newton method in machine learning of surrogates for computationally expensive nonlinear residuals are touched on briefly as part of various conclusions to be drawn.},
  archive      = {J_SISC},
  author       = {Uwe Naumann},
  doi          = {10.1137/23M157017X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1423-A1440},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A matrix-free exact newton method},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient preconditioners for solving dynamical optimal
transport via interior point methods. <em>SISC</em>, <em>46</em>(3),
A1397–A1422. (<a href="https://doi.org/10.1137/23M1570430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we address the numerical solution of the quadratic optimal transport problem in its dynamical form, the so-called Benamou-Brenier formulation. When solved using interior point methods, the main computational bottleneck is the solution of large saddle point linear systems arising from the associated Newton-Raphson scheme. The main purpose of this paper is to design efficient preconditioners to solve these linear systems via iterative methods. Among the proposed preconditioners, we introduce one based on the partial commutation of the operators that compose the dual Schur complement of these saddle point linear systems, which we refer to as the -preconditioner. A series of numerical tests show that the -preconditioner is the most efficient among those presented, despite a performance deterioration in the last steps of the interior point method. It is in fact the only one having a CPU time that scales only slightly worse than linearly with respect to the number of unknowns used to discretize the problem.},
  archive      = {J_SISC},
  author       = {Enrico Facca and Gabriele Todeschi and Andrea Natale and Michele Benzi},
  doi          = {10.1137/23M1570430},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1397-A1422},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient preconditioners for solving dynamical optimal transport via interior point methods},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024a). Additive schwarz methods for semilinear elliptic problems
with convex energy functionals: Convergence rate independent of
nonlinearity. <em>SISC</em>, <em>46</em>(3), A1373–A1396. (<a
href="https://doi.org/10.1137/23M159545X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We investigate additive Schwarz methods for semilinear elliptic problems with convex energy functionals, which have wide scientific applications. A key observation is that the convergence rates of both one- and two-level additive Schwarz methods have bounds independent of the nonlinear term in the problem. That is, the convergence rates do not deteriorate by the presence of nonlinearity, so that solving a semilinear problem requires no more iterations than a linear problem. Moreover, the two-level method is scalable in the sense that the convergence rate of the method depends on and only, where and are the typical diameters of an element and a subdomain, respectively, and measures the overlap among the subdomains. Numerical results are provided to support our theoretical findings.},
  archive      = {J_SISC},
  author       = {Jongho Park},
  doi          = {10.1137/23M159545X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {6},
  number       = {3},
  pages        = {A1373-A1396},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Additive schwarz methods for semilinear elliptic problems with convex energy functionals: Convergence rate independent of nonlinearity},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Special section: 2022 copper mountain conference on
iterative methods. <em>SISC</em>, <em>46</em>(2), Si. (<a
href="https://doi.org/10.1137/23M1614110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SISC},
  author       = {Andreas Stathopoulos},
  doi          = {10.1137/23M1614110},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {Si},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Special section: 2022 copper mountain conference on iterative methods},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). PISTA: Preconditioned iterative soft thresholding algorithm
for graphical lasso. <em>SISC</em>, <em>46</em>(2), S445–S466. (<a
href="https://doi.org/10.1137/22M1496128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a novel quasi-Newton method for solving the sparse inverse covariance estimation problem also known as the graphical least absolute shrinkage and selection operator (GLASSO). This problem is often solved using a second-order quadratic approximation. However, in such algorithms the Hessian term is complex and computationally expensive to handle. Therefore, our method uses the inverse of the Hessian as a preconditioner to simplify and approximate the quadratic element at the cost of a more complex element. The variables of the resulting preconditioned problem are coupled only by the subderivative of each other, which can be guessed with minimal cost using the gradient itself, allowing the algorithm to be parallelized and implemented efficiently on GPU hardware accelerators. Numerical results on synthetic and real data demonstrate that our method is competitive with other state-of-the-art approaches.},
  archive      = {J_SISC},
  author       = {Gal Shalom and Eran Treister and Irad Yavneh},
  doi          = {10.1137/22M1496128},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S445-S466},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {PISTA: Preconditioned iterative soft thresholding algorithm for graphical lasso},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Locally conservative and flux consistent iterative methods.
<em>SISC</em>, <em>46</em>(2), S424–S444. (<a
href="https://doi.org/10.1137/22M1503348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Conservation and consistency are fundamental properties of discretizations of conservation laws, necessary to ensure physically meaningful solutions. In the context of systems of nonlinear hyperbolic conservation laws, conservation and consistency additionally play an important role in convergence theory via the Lax–Wendroff theorem. Here, these concepts are extended to the realm of iterative methods by formally defining locally conservative and flux consistent iterations. These concepts are used to prove an extension of the Lax–Wendroff theorem incorporating pseudotime iterations with explicit Runge–Kutta methods. This result reveals that lack of flux consistency implies convergence towards weak solutions of a time dilated system of conservation laws, where each equation is modified by a particular scalar factor multiplying the spatial flux terms. Local conservation is further established for Krylov subspace methods with and without restarts, and for Newton’s method under certain assumptions on the discretization. It is thus shown that Newton–Krylov methods are locally conservative, although not necessarily flux consistent. Numerical experiments with the 2 dimensional compressible Euler equations corroborate the theoretical results. A simple technique for enforcing flux consistency of Newton–Krylov methods is presented. Experiments indicate that its efficacy is case dependent, and diminishes as the number of iterations grow.},
  archive      = {J_SISC},
  author       = {Viktor Linders and Philipp Birken},
  doi          = {10.1137/22M1503348},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S424-S444},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Locally conservative and flux consistent iterative methods},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A restricted SVD type CUR decomposition for matrix triplets.
<em>SISC</em>, <em>46</em>(2), S401–S423. (<a
href="https://doi.org/10.1137/22M1500666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a new restricted SVD-based CUR (RSVD-CUR) factorization for matrix triplets that aims to extract meaningful information by providing a low-rank approximation of the three matrices using a subset of their rows and columns. The proposed method utilizes the discrete empirical interpolation method (DEIM) to select the subset of rows and columns from the orthogonal and nonsingular matrices obtained through an RSVD of the matrix triplet. We explore the relationships between a DEIM type RSVD-CUR factorization, a DEIM type CUR factorization, and a DEIM type generalized CUR decomposition and provide an error analysis that establishes the accuracy of the RSVD-CUR decomposition within a factor of the approximation error of the RSVD of the given matrices. The RSVD-CUR factorization can be used in applications that require approximating one data matrix relative to two other given matrices. We discuss two such applications, namely multiview dimension reduction and data perturbation problems where a correlated noise matrix is added to the input data matrix. Our numerical experiments demonstrate the advantages of the proposed method over the standard CUR approximation in these scenarios.},
  archive      = {J_SISC},
  author       = {Perfect Y. Gidisu and Michiel E. Hochstenbach},
  doi          = {10.1137/22M1500666},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S401-S423},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A restricted SVD type CUR decomposition for matrix triplets},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving graph laplacians via multilevel sparsifiers.
<em>SISC</em>, <em>46</em>(2), S378–S400. (<a
href="https://doi.org/10.1137/22M1503932">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider effective preconditioners for solving Laplacians of general weighted graphs. Theoretically, spectral sparsifiers (SSs) provide preconditioners of optimal computational complexity. However, they are not easy to use for real-world applications due to implementation complications. Multigrid methods, on the contrary, are computationally efficient but lack theoretical justification. To bridge the gap between theory and practice, we adopt ideas of multigrid and SS methods and proposed preconditioners that can be used in practice with theoretical guarantees. We expand the original graph based on a multilevel structure to obtain an equivalent expanded graph. Although the expanded graph has a low diameter, a favorable property for constructing SSs, it has negatively weighted edges, which is an unfavorable property for SSs. We design an algorithm to properly eliminate the negatively weighted edges and prove that the resulting expanded graph with positively weighted edges is spectrally equivalent to the expanded graph and, thus, the original graph. Due to the low-diameter property of the positively weighted expanded graph preconditioner (PEGP), existing algorithms for finding SSs can be easily applied. To demonstrate the advantage of working with PEGP, we propose a type of SS, the multilevel graph sparsifier preconditioner (MGSP), that can be constructed in an easy and deterministic manner. We provide some preliminary numerical experiments to verify our theoretical findings and illustrate the practical effectiveness of PEGP and MGSP in real-world applications.},
  archive      = {J_SISC},
  author       = {Xiaozhe Hu and Junyuan Lin},
  doi          = {10.1137/22M1503932},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S378-S400},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Solving graph laplacians via multilevel sparsifiers},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient multiscale preconditioner for large-scale
highly heterogeneous flow. <em>SISC</em>, <em>46</em>(2), S352–S377. (<a
href="https://doi.org/10.1137/22M1502859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose an efficient and robust multiscale preconditioner for large-scale incompressible flow in highly heterogeneous porous media. We start from the discretization of the first-order form for the single phase incompressible flow and apply a velocity elimination strategy to obtain an equation with pressure as the only unknown. Then an efficient preconditioner is designed to solve this equation. The key component of the preconditioner is the adoption of a nonstandard coarse space that contains the media’s heterogeneity information. We solve a carefully constructed spectral problem in each coarse element to form the nonstandard coarse space. Then a rigorous convergence analysis for the proposed two-grid algorithm is carried out where the key ingredients lie in the smoothing property of the ILU(0) smoother and the approximation property. In particular, our analysis shows that our preconditioner is robust and efficient thanks to this newly constructed coarse space. Rich numerical tests with several types of large-scale, three-dimensional, highly heterogeneous permeability fields with resolutions up to are presented. The experimental results show that our generalized multiscale space–based preconditioner is robust with respect to the contrast, size, and geometry of the permeability fields. Moreover, the complexity of the preconditioner is close to . We also successfully apply this preconditioner for multiphase flow simulation and transport problems arising from reservoir simulation.},
  archive      = {J_SISC},
  author       = {Shubin Fu and Eric Chung and Lina Zhao},
  doi          = {10.1137/22M1502859},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S352-S377},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An efficient multiscale preconditioner for large-scale highly heterogeneous flow},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A parallel algorithm for computing partial spectral
factorizations of matrix pencils via chebyshev approximation.
<em>SISC</em>, <em>46</em>(2), S324–S351. (<a
href="https://doi.org/10.1137/22M1501155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a distributed-memory parallel algorithm for computing some of the algebraically smallest eigenvalues (and corresponding eigenvectors) of a large, sparse, real symmetric positive definite matrix pencil that lie within a target interval. The algorithm is based on Chebyshev interpolation of the eigenvalues of the Schur complement (over the interface variables) of a domain decomposition reordering of the pencil and accordingly exposes two dimensions of parallelism: one derived from the reordering and one from the independence of the interpolation nodes. The new method demonstrates excellent parallel scalability, comparing favorably with PARPACK, and does not require factorization of the mass matrix, which significantly reduces memory consumption, especially for 3D problems. Our implementation is publicly available on GitHub.},
  archive      = {J_SISC},
  author       = {Tianshi Xu and Anthony Austin and Vasileios Kalantzis and Yousef Saad},
  doi          = {10.1137/22M1501155},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S324-S351},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A parallel algorithm for computing partial spectral factorizations of matrix pencils via chebyshev approximation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Improving control based importance sampling strategies for
metastable diffusions via adapted metadynamics. <em>SISC</em>,
<em>46</em>(2), S298–S323. (<a
href="https://doi.org/10.1137/22M1503464">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Sampling rare events in metastable dynamical systems is often a computationally expensive task and one needs to resort to enhanced sampling methods such as importance sampling. Since we can formulate the problem of finding optimal importance sampling controls as a stochastic optimization problem, this then brings additional numerical challenges and the convergence of corresponding algorithms might suffer from metastabilty. In this article, we address this issue by combining systematic control approaches with the heuristic adaptive metadynamics method. Crucially, we approximate the importance sampling control by a neural network, which makes the algorithm in principle feasible for high-dimensional applications. We can numerically demonstrate in relevant metastable problems that our algorithm is more effective than previous attempts and that only the combination of the two approaches leads to a satisfying convergence and therefore to an efficient sampling in certain metastable settings.},
  archive      = {J_SISC},
  author       = {Enric Ribera Borrell and Jannes Quer and Lorenz Richter and Christof Schütte},
  doi          = {10.1137/22M1503464},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S298-S323},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Improving control based importance sampling strategies for metastable diffusions via adapted metadynamics},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterative schemes for probabilistic domain decomposition.
<em>SISC</em>, <em>46</em>(2), S280–S297. (<a
href="https://doi.org/10.1137/22M1503580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Probabilistic domain decomposition (PDD) is an alternative paradigm for solving boundary value problems (BVPs) in parallel with excellent scalability properties, thanks to its reliance on stochastic representations of the BVP. However, there are cases when the latter is less numerically convenient, or unknown. Semilinear elliptic BVPs and the Helmholtz equation are prominent examples of either class. In this paper, we overcome this issue by designing suitable iterative schemes for either problem. These schemes not only retain the desirable properties of PDD but also are optimally suited for pathwise variance reduction, resulting in a systematic, nearly cost-free reduction of the statistical error through the iterations. Numerical tests carried out on the supercomputer Marconi100 are presented.},
  archive      = {J_SISC},
  author       = {Jorge Morón-Vidal and Francisco Bernal and Renato Spigler},
  doi          = {10.1137/22M1503580},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S280-S297},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Iterative schemes for probabilistic domain decomposition},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Iterated gauss–seidel GMRES. <em>SISC</em>, <em>46</em>(2),
S254–S279. (<a href="https://doi.org/10.1137/22M1491241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The GMRES algorithm of Saad and Schultz [SIAM J. Sci. Stat. Comput., 7 (1986), pp. 856–869] is an iterative method for approximately solving linear systems , with initial guess and residual . The algorithm employs the Arnoldi process to generate the Krylov basis vectors (the columns of ). It is well known that this process can be viewed as a factorization of the matrix at each iteration. Despite an loss of orthogonality, for unit roundoff and condition number , the modified Gram–Schmidt formulation was shown to be backward stable in the seminal paper by Paige et al. [SIAM J. Matrix Anal. Appl., 28 (2006), pp. 264–284]. We present an iterated Gauss–Seidel formulation of the GMRES algorithm (IGS-GMRES) based on the ideas of Ruhe [Linear Algebra Appl., 52 (1983), pp. 591–601] and Świrydowicz et al. [Numer. Linear Algebra Appl., 28 (2020), pp. 1–20]. IGS-GMRES maintains orthogonality to the level or , depending on the choice of one or two iterations; for two Gauss–Seidel iterations, the computed Krylov basis vectors remain orthogonal to working accuracy and the smallest singular value of remains close to one. The resulting GMRES method is thus backward stable. We show that IGS-GMRES can be implemented with only a single synchronization point per iteration, making it relevant to large-scale parallel computing environments. We also demonstrate that, unlike MGS-GMRES, in IGS-GMRES the relative Arnoldi residual corresponding to the computed approximate solution no longer stagnates above machine precision even for highly nonnormal systems.},
  archive      = {J_SISC},
  author       = {Stephen Thomas and Erin Carson and Miroslav Rozložník and Arielle Carr and Katarzyna Świrydowicz},
  doi          = {10.1137/22M1491241},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S254-S279},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Iterated Gauss–Seidel GMRES},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Krylov subspace residual and restarting for certain second
order differential equations. <em>SISC</em>, <em>46</em>(2), S223–S253.
(<a href="https://doi.org/10.1137/22M1503300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose algorithms for efficient time integration of large systems of oscillatory second order ordinary differential equations (ODEs) whose solutions can be expressed in terms of trigonometric matrix functions. Our algorithms are based on a residual notion for second order ODEs, which allows us to extend the “residual-time restarting” Krylov subspace framework—which was recently introduced for exponential and -functions occurring in time integration of first order ODEs—to our setting. We then show that the computational cost can be further reduced in many cases by using our restarting in the Gautschi cosine scheme. We analyze residual convergence in terms of Faber and Chebyshev series and supplement these theoretical results by numerical experiments illustrating the efficiency of the proposed methods.},
  archive      = {J_SISC},
  author       = {Mike A. Botchev and Leonid Knizhnerman and Marcel Schweitzer},
  doi          = {10.1137/22M1503300},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S223-S253},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Krylov subspace residual and restarting for certain second order differential equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient high-order solver for diffusion equations with
strong anisotropy on non-anisotropy-aligned meshes. <em>SISC</em>,
<em>46</em>(2), S199–S222. (<a
href="https://doi.org/10.1137/22M1500162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper concerns numerical solution of the diffusion equation with strong anisotropy on meshes not aligned with the anisotropic vector field. In order to resolve the numerical pollution for simulations on a non-anisotropy-aligned mesh and reduce the associated high computational cost we propose an effective preconditioner, extending our previous work [D. Green et al., Comput. Phys. Commun., 9 (2022), 108333]. Similar to the anisotropy-aligned mesh case, we apply the auxiliary space preconditioning framework to design a preconditioner where a continuous finite element space is used as the auxiliary space for the discontinuous finite element space. The key component is an effective line smoother that can mitigate the high-frequency errors perpendicular to the magnetic field. We design a graph-based approach to find such a line smoother that is approximately perpendicular to the vector fields when the mesh does not align with the anisotropy. Numerical experiments for several benchmark problems are presented, demonstrating the effectiveness and robustness of the proposed preconditioner when applied to Krylov iterative methods.},
  archive      = {J_SISC},
  author       = {David Green and Xiaozhe Hu and Jeremy Lore and Lin Mu and Mark L. Stowell},
  doi          = {10.1137/22M1500162},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S199-S222},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An efficient high-order solver for diffusion equations with strong anisotropy on non-anisotropy-aligned meshes},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient algorithms for bayesian inverse problems with
whittle–matérn priors. <em>SISC</em>, <em>46</em>(2), S176–S198. (<a
href="https://doi.org/10.1137/22M1494397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper tackles efficient methods for Bayesian inverse problems with priors based on Whittle–Matérn Gaussian random fields. The Whittle–Matérn prior is characterized by a mean function and a covariance operator that is taken as a negative power of an elliptic differential operator. This approach is flexible in that it can incorporate a wide range of prior information including nonstationary effects, but it is currently computationally advantageous only for integer values of the exponent. In this paper, we derive an efficient method for handling all admissible noninteger values of the exponent. The method first discretizes the covariance operator using finite elements and quadrature, and uses preconditioned Krylov subspace solvers for shifted linear systems to efficiently apply the resulting covariance matrix to a vector. This approach can be used for generating samples from the distribution in two different ways: by solving a stochastic partial differential equation, and by using a truncated Karhunen–Loève expansion. We show how to incorporate this prior representation into the infinite-dimensional Bayesian formulation, and show how to efficiently compute the maximum a posteriori estimate, and approximate the posterior variance. Although the focus of this paper is on Bayesian inverse problems, the techniques developed here are applicable to solving systems with fractional Laplacians and Gaussian random fields. Numerical experiments demonstrate the performance and scalability of the solvers and their applicability to model and real-data inverse problems in tomography and a time-dependent heat equation.},
  archive      = {J_SISC},
  author       = {Harbir Antil and Arvind K. Saibaba},
  doi          = {10.1137/22M1494397},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S176-S198},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient algorithms for bayesian inverse problems with Whittle–Matérn priors},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Variational data assimilation and its decoupled iterative
numerical algorithms for stokes–darcy model. <em>SISC</em>,
<em>46</em>(2), S142–S175. (<a
href="https://doi.org/10.1137/22M1492994">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper we develop and analyze a variational data assimilation method with efficient decoupled iterative numerical algorithms for the Stokes–Darcy equations with the Beavers–Joseph interface condition. By using Tikhonov regularization and formulating the variational data assimilation into an optimization problem, we establish the existence, uniqueness, and stability of the optimal solution. Based on the weak formulation of the Stokes–Darcy equations, the Lagrange multiplier rule is utilized to derive the first order optimality system for both the continuous and discrete variational data assimilation problems, where the discrete data assimilation is based on a finite element discretization in space and the backward Euler scheme in time. By rescaling the optimality system and then analyzing its corresponding bilinear forms, we prove the optimal finite element convergence rate with special attention paid to recovering uncertainties missed in the optimality system. To solve the discrete optimality system efficiently, three decoupled iterative algorithms are proposed to address the computational cost for both well-conditioned and ill-conditioned variational data assimilation problems, respectively. Finally, numerical results are provided to validate the proposed methods.},
  archive      = {J_SISC},
  author       = {Xuejian Li and Wei Gong and Xiaoming He and Tao Lin},
  doi          = {10.1137/22M1492994},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S142-S175},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Variational data assimilation and its decoupled iterative numerical algorithms for Stokes–Darcy model},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Preconditioned infinite GMRES for parameterized linear
systems. <em>SISC</em>, <em>46</em>(2), S120–S141. (<a
href="https://doi.org/10.1137/22M1502380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We are interested in obtaining solutions to parameterized linear systems of the form for many values of the parameter . Here is large, sparse, and nonsingular with a nonlinear, analytic dependence on . Our approach approximates the solution to a linearized system in a flexible GMRES setting [Y. Saad, SIAM J. Sci. Comput., 14 (1993), pp. 461–469], where the linearization is based on a companion matrix similar to the operator in the infinite Arnoldi method [E. Jarlebring, W. Michiels, and K. Meerbergen, Numer. Math., 122 (2012), pp. 169–195]. This novel approach applies the action of a preconditioner inexactly, providing performance improvement over the method infinite GMRES [Jarlebring and Correnty, SIAM J. Matrix Anal. Appl., 43 (2022), pp. 1382–1405] without a loss of accuracy in general. The method returns a function which is cheap to evaluate for different . We show that the error of our method is estimated based on the magnitude of the parameter , the inexactness of the preconditioning, and the spectrum of the companion matrix. Numerical examples from a finite element discretization of a Helmholtz equation with a parameterized material coefficient illustrate the competitiveness of our approach. The software used in the simulations is publicly available online, and all the experiments are reproducible.},
  archive      = {J_SISC},
  author       = {Siobhán Correnty and Elias Jarlebring and Kirk M. Soodhalter},
  doi          = {10.1137/22M1502380},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S120-S141},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Preconditioned infinite GMRES for parameterized linear systems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Hybrid projection methods for solution decomposition in
large-scale bayesian inverse problems. <em>SISC</em>, <em>46</em>(2),
S97–S119. (<a href="https://doi.org/10.1137/22M1502197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop hybrid projection methods for computing solutions to large-scale inverse problems, where the solution represents a sum of different stochastic components. Such scenarios arise in many imaging applications (e.g., anomaly detection in atmospheric emissions tomography) where the reconstructed solution can be represented as a combination of two or more components and each component contains different smoothness or stochastic properties. In a deterministic inversion or inverse modeling framework, these assumptions correspond to different regularization terms for each solution in the sum. Although various prior assumptions can be included in our framework, we focus on the scenario where the solution is a sum of a sparse solution and a smooth solution. For computing solution estimates, we develop hybrid projection methods for solution decomposition that are based on a combined flexible and generalized Golub–Kahan process. This approach integrates techniques from the generalized Golub–Kahan bidiagonalization and the flexible Krylov methods. The benefits of the proposed methods are that the decomposition of the solution can be done iteratively, and the regularization terms and regularization parameters are adaptively chosen at each iteration. Numerical results from photoacoustic tomography and atmospheric inverse modeling demonstrate the potential for these methods to be used for anomaly detection.},
  archive      = {J_SISC},
  author       = {Julianne Chung and Jiahua Jiang and Scot M. Miller and Arvind K. Saibaba},
  doi          = {10.1137/22M1502197},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S97-S119},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Hybrid projection methods for solution decomposition in large-scale bayesian inverse problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stage-parallel fully implicit runge–kutta implementations
with optimal multilevel preconditioners at the scaling limit.
<em>SISC</em>, <em>46</em>(2), S71–S96. (<a
href="https://doi.org/10.1137/22M1503270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present an implementation of a stage-parallel preconditioner for Radau IIA type fully implicit Runge–Kutta methods, which approximates the inverse of the Runge–Kutta matrix from the Butcher tableau by the lower triangular matrix resulting from an LU decomposition and diagonalizes the system with as many blocks as stages. For the transformed system, we employ a block preconditioner where each block is distributed and solved by a subgroup of processes in parallel. For combination of partial results, we use either a communication pattern resembling Cannon’s algorithm or shared memory. A performance model and a large set of performance studies (including strong-scaling runs with up to 150k processes on 3k compute nodes) conducted for a time-dependent heat problem, using matrix-free finite element methods, indicate that the stage-parallel implementation can reach higher throughputs near the scaling limit. The achievable speedup increases linearly with the number of stages and is bounded by the number of stages. Furthermore, we show that the presented stage-parallel concepts are also applicable to the case that is directly diagonalized, which requires either complex arithmetic or solutions of two-by-two blocks, both exposing about half the parallelism. Alternatively to distributing stages and assigning them to distinct processes, we discuss the possibility of batching operations from different stages together.},
  archive      = {J_SISC},
  author       = {Peter Munch and Ivo Dravins and Martin Kronbichler and Maya Neytcheva},
  doi          = {10.1137/22M1503270},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S71-S96},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Stage-parallel fully implicit Runge–Kutta implementations with optimal multilevel preconditioners at the scaling limit},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving linear systems of the form <span
class="math inline"><strong>(</strong><strong>A</strong> <strong>+</strong> <strong>γ</strong><strong>U</strong><strong>U</strong><sup><strong>T</strong></sup><strong>)</strong> <strong>x</strong> <strong>=</strong> <strong>b</strong></span>
by preconditioned iterative methods. <em>SISC</em>, <em>46</em>(2),
S51–S70. (<a href="https://doi.org/10.1137/22M1505529">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the iterative solution of large linear systems of equations in which the coefficient matrix is the sum of two terms, a sparse matrix and a possibly dense, rank deficient matrix of the form , where is a parameter which in some applications may be taken to be 1. The matrix itself can be singular, but we assume that the symmetric part of is positive semidefinite and that is nonsingular. Linear systems of this form arise frequently in fields like optimization, fluid mechanics, computational statistics, and others. We investigate preconditioning strategies based on an alternating splitting approach combined with the use of the Sherman–Morrison–Woodbury matrix identity. The potential of the proposed approach is demonstrated by means of numerical experiments on linear systems from different application areas.},
  archive      = {J_SISC},
  author       = {Michele Benzi and Chiara Faccio},
  doi          = {10.1137/22M1505529},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S51-S70},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Solving linear systems of the form \({\boldsymbol{(A + \gamma UU^T)\, {x} = {b}}}\) by preconditioned iterative methods},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven construction of hierarchical matrices with
nested bases. <em>SISC</em>, <em>46</em>(2), S24–S50. (<a
href="https://doi.org/10.1137/22M1500848">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Hierarchical matrices provide a powerful representation for significantly reducing the computational complexity associated with dense kernel matrices. For example, the fast multipole method (FMM) and its variants are highly efficient when the kernel function is related to fundamental solutions of classical elliptic PDEs. For general kernel functions, interpolation-based methods are widely used for the efficient construction of hierarchical matrices. In this paper, we present a fast hierarchical data reduction (HiDR) procedure with complexity for the memory-efficient construction of hierarchical matrices with nested bases where is the number of data points. HiDR aims to reduce the given data in a hierarchical way so as to obtain representations for all nearfield and farfield interactions. Based on HiDR, a linear complexity matrix construction algorithm is proposed. The use of data-driven methods enables better efficiency than other general-purpose methods and flexible computation without accessing the kernel function. Experiments demonstrate significantly improved memory efficiency of the proposed data-driven method compared to interpolation-based methods over a wide range of kernels. For the Coulomb kernel, the proposed general-purpose algorithm offers competitive performance compared to FMM and its variants, such as PVFMM. The data-driven approach not only works for general kernels but also leads to much smaller precomputation costs compared to PVFMM.},
  archive      = {J_SISC},
  author       = {Difeng Cai and Hua Huang and Edmond Chow and Yuanzhe Xi},
  doi          = {10.1137/22M1500848},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S24-S50},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Data-driven construction of hierarchical matrices with nested bases},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A one-dimensional coarse preconditioner for
three-dimensional unsteady incompressible navier–stokes flows in
patient-specific arteries. <em>SISC</em>, <em>46</em>(2), S1–S23. (<a
href="https://doi.org/10.1137/22M1496773">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Numerical simulation of blood flows in patient-specific arteries is becoming an important tool in understanding vascular diseases and surgery planning. Depending on the branching geometry and the patient parameters, the flow can be quite complicated with local vortex structures and rotations, but the principal component of the flow is always along the centerline of the artery. Based on this observation, we introduce a new two-level domain decomposition method for unsteady incompressible Navier–Stokes equations in three-dimensional complex patient-specific arteries, and the key component of the preconditioner is a parameterized one-dimensional unsteady Navier–Stokes or Stokes coarse problem defined along the centerline of the artery. The one-dimensional preconditioner and some overlapping three-dimensional subdomain preconditioners are combined additively to form the two-level method via interpolations using radial basis functions. The most important feature of the method is that the cost of solving the coarse problem is nearly negligible compared with the subdomain solver. The blood flow is modeled by the unsteady incompressible Navier–Stokes equations with resistance outflow boundary conditions discretized by a stabilized finite element method on fully unstructured meshes and the second-order backward differentiation formula in time. Numerical experiments indicate that the proposed method is highly effective and robust for complex arteries with many branches, in other words, the number of linear and nonlinear iterations changes very little when the mesh is refined or the number of subdomains is increased or the number of arterial branches is increased.},
  archive      = {J_SISC},
  author       = {Yingzhi Liu and Fenfen Qi and Xiao-Chuan Cai},
  doi          = {10.1137/22M1496773},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {S1-S23},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A one-dimensional coarse preconditioner for three-dimensional unsteady incompressible Navier–Stokes flows in patient-specific arteries},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Leveraging multitime hamilton–jacobi PDEs for certain
scientific machine learning problems. <em>SISC</em>, <em>46</em>(2),
C216–C248. (<a href="https://doi.org/10.1137/23M1561397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Hamilton–Jacobi partial differential equations (HJ PDEs) have deep connections with a wide range of fields, including optimal control, differential games, and imaging sciences. By considering the time variable to be a higher dimensional quantity, HJ PDEs can be extended to the multitime case. In this paper, we establish a novel theoretical connection between specific optimization problems arising in machine learning and the multitime Hopf formula, which corresponds to a representation of the solution to certain multitime HJ PDEs. Through this connection, we increase the interpretability of the training process of certain machine learning applications by showing that when we solve these learning problems, we also solve a multitime HJ PDE and, by extension, its corresponding optimal control problem. As a first exploration of this connection, we develop the relation between the regularized linear regression problem and the linear quadratic regulator (LQR). We then leverage our theoretical connection to adapt standard LQR solvers (namely, those based on the Riccati ordinary differential equations) to design new training approaches for machine learning. Finally, we provide some numerical examples that demonstrate the versatility and possible computational advantages of our Riccati-based approach in the context of continual learning, posttraining calibration, transfer learning, and sparse dynamics identification.},
  archive      = {J_SISC},
  author       = {Paula Chen and Tingwei Meng and Zongren Zou and Jérôme Darbon and George Em Karniadakis},
  doi          = {10.1137/23M1561397},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {C216-C248},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Leveraging multitime Hamilton–Jacobi PDEs for certain scientific machine learning problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Solving the boltzmann equation with a neural sparse
representation. <em>SISC</em>, <em>46</em>(2), C186–C215. (<a
href="https://doi.org/10.1137/23M1558227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the neural sparse representation to solve the Boltzmann equation with BGK and quadratic collision models, where a network-based ansatz that can approximate the distribution function with extremely high efficiency is proposed. Precisely, fully connected neural networks are employed in the time and physical space so as to avoid the discretization in space and time. Different low-rank representations are utilized in the microscopic velocity for the BGK and quadratic collision models, resulting in a significant reduction in the degree of freedom. We approximate the discrete velocity distribution in the BGK model using the canonical polyadic decomposition. For the quadratic collision model, a data-driven, SVD-based linear basis is built based on the BGK solution. All of these will significantly improve the efficiency of the network when solving the Boltzmann equation. Moreover, the specially designed adaptive-weight loss function is proposed with the strategies as multiscale input and Maxwellian splitting applied to further enhance the approximation efficiency and speed up the learning process. Several numerical experiments, including 1D wave and Sod tube problems and a 2D wave problem, demonstrate the effectiveness of these neural sparse representation methods.},
  archive      = {J_SISC},
  author       = {Zhengyi Li and Yanli Wang and Hongsheng Liu and Zidong Wang and Bin Dong},
  doi          = {10.1137/23M1558227},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {C186-C215},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Solving the boltzmann equation with a neural sparse representation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Neural control of parametric solutions for high-dimensional
evolution PDEs. <em>SISC</em>, <em>46</em>(2), C155–C185. (<a
href="https://doi.org/10.1137/23M1549870">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop a novel computational framework to approximate solution operators of evolution partial differential equations (PDEs). By employing a general nonlinear reduced-order model, such as a deep neural network, to approximate the solution of a given PDE, we realize that the evolution of the model parameters is a control problem in the parameter space. Based on this observation, we propose to approximate the solution operator of the PDE by learning the control vector field in the parameter space. From any initial value, this control field can steer the parameter to generate a trajectory such that the corresponding reduced-order model solves the PDE. This allows for substantially reduced computational cost to solve the evolution PDE with arbitrary initial conditions. We also develop comprehensive error analysis for the proposed method when solving a large class of semilinear parabolic PDEs. Numerical experiments on different high-dimensional evolution PDEs with various initial conditions demonstrate the promising results of the proposed method.},
  archive      = {J_SISC},
  author       = {Nathan Gaby and Xiaojing Ye and Haomin Zhou},
  doi          = {10.1137/23M1549870},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {C155-C185},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Neural control of parametric solutions for high-dimensional evolution PDEs},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Energy stable and conservative dynamical low-rank
approximation for the su–olson problem. <em>SISC</em>, <em>46</em>(2),
B137–B158. (<a href="https://doi.org/10.1137/23M1586215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Computational methods for thermal radiative transfer problems exhibit high computational costs and a prohibitive memory footprint when the spatial and directional domains are finely resolved. A strategy to reduce such computational costs is dynamical low-rank approximation (DLRA), which represents and evolves the solution on a low-rank manifold, thereby significantly decreasing computational and memory requirements. Efficient discretizations for the DLRA evolution equations need to be carefully constructed to guarantee stability while enabling mass conservation. In this work, we focus on the Su–Olson closure leading to a linearized internal energy model and derive a stable discretization through an implicit coupling of internal energy and particle density. Moreover, we propose a rank-adaptive strategy to preserve local mass conservation. Numerical results are presented which showcase the accuracy and efficiency of the proposed low-rank method compared to the solution of the full system.},
  archive      = {J_SISC},
  author       = {Lena Baumann and Lukas Einkemmer and Christian Klingenberg and Jonas Kusch},
  doi          = {10.1137/23M1586215},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {B137-B158},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Energy stable and conservative dynamical low-rank approximation for the Su–Olson problem},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Overcoming the numerical sign problem in the wigner dynamics
via adaptive particle annihilation. <em>SISC</em>, <em>46</em>(2),
B107–B136. (<a href="https://doi.org/10.1137/22M1498279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The infamous numerical sign problem poses a fundamental obstacle to particle-based stochastic Wigner simulations in high-dimensional phase space. Although the existing particle annihilation (PA) via uniform mesh significantly alleviates the sign problem when dimensionality D 4, the mesh size grows dramatically when D 6 due to the curse of dimensionality and consequently makes the annihilation very inefficient. In this paper, we propose an adaptive PA algorithm, termed sequential-clustering particle annihilation via discrepancy estimation (SPADE), to overcome the sign problem. SPADE follows a divide-and-conquer strategy: adaptive clustering of particles via controlling their number-theoretic discrepancies and independent random matching in each cluster. The target is to alleviate the oversampling problem induced by the overpartitioning of phase space and to capture the nonclassicality of the Wigner function simultaneously. Combining SPADE with the variance reduction technique based on the stationary phase approximation, we attempt to simulate the proton-electron couplings in six- and 12-dimensional phase space. A thorough performance benchmark of SPADE is provided with the reference solutions in six-dimensional phase space produced by a characteristic-spectral-mixed scheme under a uniform grid, which fully explores the limit of grid-based deterministic Wigner solvers.},
  archive      = {J_SISC},
  author       = {Yunfeng Xiong and Sihong Shao},
  doi          = {10.1137/22M1498279},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {B107-B136},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Overcoming the numerical sign problem in the wigner dynamics via adaptive particle annihilation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified framework of the SAV-ZEC method for a
mass-conserved allen–cahn type two-phase ferrofluid flow model.
<em>SISC</em>, <em>46</em>(2), B77–B106. (<a
href="https://doi.org/10.1137/23M1569125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This article presents a mass-conserved Allen–Cahn type two-phase ferrofluid flow model and establishes its corresponding energy law. The model is a highly coupled, nonlinear saddle point system consisting of the mass-conserved Allen–Cahn equation, the Navier–Stokes equation, the magnetostatic equation, and the magnetization equation. We develop a unified framework of the scalar auxiliary variable (SAV) method and the zero energy contribution (ZEC) approach, which constructs a mass-conserved, fully decoupled, second-order accurate in time, and unconditionally energy-stable linear scheme. We incorporate several distinct numerical techniques, including reformulations of the equations to remove the linear couplings and implicit nonlocal integration, the projection method to decouple the velocity and pressure, a symmetric implicit-explicit format for symmetric positive definite nonlinearity, and the continuous finite element method discretization. We also analyze the mass-conserved property, unconditional energy stability, and well-posedness of the scheme. To demonstrate the effectiveness, stability, and accuracy of the developed model and numerical algorithm, we implemented several numerical examples, involving a ferrofluid hedgehog in 2D and a ferromagnetic droplet in 3D. It is worth mentioning that the proposed unified framework of the SAV-ZEC method is also applicable to designing efficient schemes for other coupled-type fluid flow phase-field systems.},
  archive      = {J_SISC},
  author       = {Guo-Dong Zhang and Xiaoming He and Xiaofeng Yang},
  doi          = {10.1137/23M1569125},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {B77-B106},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A unified framework of the SAV-ZEC method for a mass-conserved Allen–Cahn type two-phase ferrofluid flow model},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel two-stage reduction to hessenberg-triangular form.
<em>SISC</em>, <em>46</em>(2), B56–B76. (<a
href="https://doi.org/10.1137/23M1547093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a two-stage algorithm for the parallel reduction of a pencil to Hessenberg-triangular form. Traditionally, two-stage Hessenberg-triangular reduction algorithms achieve high performance in the first stage but struggle to achieve high performance in the second stage. Our algorithm extends techniques described by Karlsson et al. [Parallel Comput., 37 (2011), pp. 771–782] to also achieve high performance in the second stage. Experiments in a shared memory environment demonstrate that the algorithm can outperform state-of-the-art sequential algorithms using parallel BLAS. Future work will need to determine whether our algorithm can also outperform parallelized versions of these algorithms.},
  archive      = {J_SISC},
  author       = {Thijs Steel and Raf Vandebril},
  doi          = {10.1137/23M1547093},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {B56-B76},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Parallel two-stage reduction to hessenberg-triangular form},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A semi-lagrangian discontinuous galerkin method for
drift-kinetic simulations on GPUs. <em>SISC</em>, <em>46</em>(2),
B33–B55. (<a href="https://doi.org/10.1137/23M1559658">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we demonstrate the efficiency of using semi-Lagrangian discontinuous Galerkin methods to solve the drift-kinetic equation using graphic processing units (GPUs). In this setting we propose a second order splitting scheme and a two-dimensional semi-Lagrangian scheme in the poloidal plane. The resulting method is able to conserve mass up to machine precision, allows us to take large time steps due to the absence of a CFL condition, and provides local data dependency which is essential to obtain good performance on state-of-the-art high-performance computing systems. We report simulations of a drift-kinetic ion temperature gradient instability and show that our implementation achieves a performance of up to 600 GB/s on an A100 GPU.},
  archive      = {J_SISC},
  author       = {Lukas Einkemmer and Alexander Moriggl},
  doi          = {10.1137/23M1559658},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {B33-B55},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A semi-lagrangian discontinuous galerkin method for drift-kinetic simulations on GPUs},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Local characteristic decomposition–free high-order finite
difference WENO schemes for hyperbolic systems endowed with a coordinate
system of riemann invariants. <em>SISC</em>, <em>46</em>(2),
A1352–A1372. (<a href="https://doi.org/10.1137/22M1536479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The weighted essentially nonoscillatory (WENO) schemes are popular high-order numerical methods for hyperbolic conservation laws. When dealing with hyperbolic systems, WENO schemes are usually used in cooperation with the local characteristic decomposition, as the componentwise WENO reconstruction/interpolation procedure often produces oscillatory approximations near shocks. In this paper, we investigate local characteristic decomposition–free WENO schemes for a special class of hyperbolic systems endowed with a coordinate system of Riemann invariants. We apply the WENO procedure to the coordinate system of Riemann invariants instead of the local characteristic fields to save the expensive computational cost on local characteristic decomposition but meanwhile maintain the essentially nonoscillatory performance. Due to the nonlinear algebraic relation between the Riemann invariants and conserved variables, it is difficult to obtain the cell averages of Riemann invariants directly from those of conserved variables and vice versa; thus, we do not use the finite volume WENO schemes in this work. The same difficulty is also faced in the traditional Shu–Osher lemma [C.-W. Shu and S. Osher, J. Comput. Phys., 83 (1989), pp. 32–78]–based finite difference schemes, as the computation of fluxes is based on reconstruction as well. Therefore, we adopt the alternative formulation of the finite difference WENO scheme [Y. Jiang, C.-W. Shu, and M. Zhang, SIAM J. Sci. Comput., 35 (2013), pp. A1137–A1160, C.-W. Shu and S. Osher, J. Comput. Phys., 77 (1988), pp. 439–471] in this paper, which is based on interpolation for nodal values. The efficiency and good performance of our method are demonstrated by extensive numerical tests which indicate that the coordinate system of Riemann invariants is a good alternative of local characteristic fields for the WENO procedure.},
  archive      = {J_SISC},
  author       = {Ziyao Xu and Chi-Wang Shu},
  doi          = {10.1137/22M1536479},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1352-A1372},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Local characteristic Decomposition–Free high-order finite difference WENO schemes for hyperbolic systems endowed with a coordinate system of riemann invariants},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). The runge–kutta discontinuous galerkin method with compact
stencils for hyperbolic conservation laws. <em>SISC</em>,
<em>46</em>(2), A1327–A1351. (<a
href="https://doi.org/10.1137/23M158629X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we develop a new type of Runge–Kutta (RK) discontinuous Galerkin (DG) method for solving hyperbolic conservation laws. Compared with the original RKDG method, the new method features improved compactness and allows simple boundary treatment. The key idea is to hybridize two different spatial operators in an explicit RK scheme, utilizing local projected derivatives for inner RK stages and the usual DG spatial discretization for the final stage only. Limiters are applied only at the final stage for the control of spurious oscillations. We also explore the connections between our method and Lax–Wendroff DG schemes and ADER-DG schemes. Numerical examples are given to confirm that the new RKDG method is as accurate as the original RKDG method, while being more compact, for problems including two-dimensional Euler equations for compressible gas dynamics.},
  archive      = {J_SISC},
  author       = {Qifan Chen and Zheng Sun and Yulong Xing},
  doi          = {10.1137/23M158629X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1327-A1351},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {The Runge–Kutta discontinuous galerkin method with compact stencils for hyperbolic conservation laws},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Direct/iterative hybrid solver for scattering by
inhomogeneous media. <em>SISC</em>, <em>46</em>(2), A1298–A1326. (<a
href="https://doi.org/10.1137/22M1521547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper presents a fast high-order method for the solution of two-dimensional problems of scattering by penetrable inhomogeneous media, with application to high-frequency configurations containing (possibly) discontinuous refractivities. The method relies on a hybrid direct/iterative combination of (1) a differential volumetric formulation (which is based on the use of appropriate Chebyshev differentiation matrices enacting the Laplace operator) and (2) a second-kind boundary integral formulation (which, once again, utilizes Chebyshev discretization, but, in this case, in the boundary integral context). The approach enjoys low dispersion and high-order accuracy for smooth refractivities, as well as second-order accuracy (while maintaining low dispersion) in the discontinuous refractivity case. The solution approach proceeds by application of impedance-to-impedance (ItI) maps to couple the volumetric and boundary discretizations. The volumetric linear algebra solutions are obtained by means of a multifrontal solver, and the coupling with the boundary integral formulation is achieved via an application of the iterative linear algebra solver GMRES. In particular, the existence and uniqueness theory presented in the present paper provides an affirmative answer to an open question concerning the existence of a uniquely solvable second-kind ItI-based formulation for the overall scattering problem under consideration. Relying on a modestly demanding scatterer-dependent precomputation stage (requiring in practice a computing cost of the order of operations, with , for an -point discretization and for the relevant Chebyshev accuracy orders used), together with fast (-cost) single-core runs for each incident field considered, the proposed algorithm can effectively solve scattering problems for large and complex objects possibly containing discontinuities and strong refractivity contrasts.},
  archive      = {J_SISC},
  author       = {Oscar P. Bruno and Ambuj Pandey},
  doi          = {10.1137/22M1521547},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1298-A1326},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Direct/Iterative hybrid solver for scattering by inhomogeneous media},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Multivariate hermite interpolation on riemannian manifolds.
<em>SISC</em>, <em>46</em>(2), A1276–A1297. (<a
href="https://doi.org/10.1137/22M1541071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose two methods for multivariate Hermite interpolation of manifold-valued functions. On the one hand, we approach the problem via computing suitable weighted Riemannian barycenters. To satisfy the conditions for Hermite interpolation, the sampled derivative information is converted into a condition on the derivatives of the associated weight functions. It turns out that this requires the solution of linear systems of equations, but no vector transport is necessary. This approach treats all given sample data points equally and is intrinsic in the sense that it does not depend on local coordinates or embeddings. As an alternative, we consider Hermite interpolation in a tangent space. This is a straightforward approach, where one designated point, for example, one of the sample points or (one of) their center(s) of mass, is chosen to act as the base point to which the tangent space is attached. The remaining sampled locations and sampled derivatives are mapped to said tangent space. This requires a vector transport between different tangent spaces. The actual interpolation is then conducted via classical vector space operations. The interpolant depends on the selected base point. The validity and performance of both approaches is illustrated by means of numerical examples. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/RalfZimmermannSDU/MultivarHermiteManifoldInterp_SISC and in the supplementary materials.},
  archive      = {J_SISC},
  author       = {Ralf Zimmermann and Ronny Bergmann},
  doi          = {10.1137/22M1541071},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1276-A1297},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Multivariate hermite interpolation on riemannian manifolds},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Approximating the shape operator with the surface
hellan–herrmann–johnson element. <em>SISC</em>, <em>46</em>(2),
A1252–A1275. (<a href="https://doi.org/10.1137/22M1531968">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a finite element technique for approximating the surface Hessian of a discrete scalar function on triangulated surfaces embedded in , with or without boundary. We then extend the method to compute approximations of the full shape operator of the underlying surface using only the known discrete surface. The method is based on the Hellan–Herrmann–Johnson element and does not require any ad hoc modifications. Convergence is established provided the discrete surface satisfies a Lagrange interpolation property related to the exact surface. The convergence rate, in , for the shape operator approximation is , where is the polynomial degree of the surface, i.e., the method converges even for piecewise linear surface triangulations. For surfaces with boundary, some additional boundary data is needed to establish optimal convergence, e.g., boundary information about the surface normal vector or the curvature in the co-normal direction. Numerical examples are given on nontrivial surfaces that demonstrate our error estimates and the efficacy of the method.},
  archive      = {J_SISC},
  author       = {Shawn W. Walker},
  doi          = {10.1137/22M1531968},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1252-A1275},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Approximating the shape operator with the surface Hellan–Herrmann–Johnson element},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A direct probing method of an inverse problem for the
eikonal equation. <em>SISC</em>, <em>46</em>(2), A1235–A1251. (<a
href="https://doi.org/10.1137/23M1577390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a direct probing method to solve the inverse problem of the Eikonal equation. This problem involves the determination of the inhomogeneous wave-speed distribution from first-arrival time data at measurement surfaces corresponding to distributed point sources. The viscosity solution of the point-source Eikonal equation represents the least traveltime of wave fields from the source to the point at the high-frequency limit. We show that this inverse problem is highly ill-posed. To address this issue, we develop a direct probing method that incorporates solution analysis of the Eikonal equation and several aspects of the velocity models. Specifically, we use the filtered back-projection method to reconstruct the inhomogeneous wave-speed distribution when it has a small variation from the homogeneous medium. For the scenarios involving high-contrast media, we assume a background medium and develop an adjoint-based back-projection method to identify the variations of the medium from the assumed background.},
  archive      = {J_SISC},
  author       = {Kazufumi Ito and Ying Liang},
  doi          = {10.1137/23M1577390},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1235-A1251},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A direct probing method of an inverse problem for the eikonal equation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computation of two-dimensional stokes flows via lightning
and AAA rational approximation. <em>SISC</em>, <em>46</em>(2),
A1214–A1234. (<a href="https://doi.org/10.1137/23M1576876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Low Reynolds number fluid flows are governed by the Stokes equations. In two dimensions, Stokes flows can be described by two analytic functions, known as Goursat functions. Brubeck and Trefethen [SIAM J. Sci. Comput., 44 (2022), pp. A1205–A1226] recently introduced a lightning Stokes solver that uses rational functions to approximate the Goursat functions in polygonal domains. In this paper, we present the LARS algorithm (lightning-AAA rational Stokes) for computing two-dimensional (2D) Stokes flows in domains with smooth boundaries and multiply connected domains using lightning and AAA rational approximation [Y. Nakatsukasa, O. Sète, and L. N. Trefethen, SIAM J. Sci. Comput., 40 (2018), pp. A1494–A1522]. After validating our solver against known analytical solutions, we solve a variety of 2D Stokes flow problems with physical and engineering applications. Using these examples, we show rational approximation can now be used to compute 2D Stokes flows in general domains. The computations take less than a second and give solutions with at least 6-digit accuracy. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/YidanXue/LARS and in the supplementary materials (128848_2_supp_551755_s5tk4s.zip [15.4KB]).},
  archive      = {J_SISC},
  author       = {Yidan Xue and Sarah L. Waters and Lloyd N. Trefethen},
  doi          = {10.1137/23M1576876},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1214-A1234},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Computation of two-dimensional stokes flows via lightning and AAA rational approximation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Parallel randomized tucker decomposition algorithms.
<em>SISC</em>, <em>46</em>(2), A1186–A1213. (<a
href="https://doi.org/10.1137/22M1540363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Tucker tensor decomposition is a natural extension of the singular value decomposition (SVD) to multiway data. We propose to accelerate Tucker tensor decomposition algorithms by using randomization and parallelization. We present two algorithms that scale to large data and many processors, significantly reduce both computation and communication cost compared to previous deterministic and randomized approaches, and obtain nearly the same approximation errors. The key idea in our algorithms is to perform randomized sketches with Kronecker-structured random matrices, which reduces computation compared to unstructured matrices and can be implemented using a fundamental tensor computational kernel. We provide probabilistic error analysis of our algorithms and implement a new parallel algorithm for the structured randomized sketch. Our experimental results demonstrate that our combination of randomization and parallelization achieves accurate Tucker decompositions much faster than alternative approaches. We observe up to a 16X speedup over the fastest deterministic parallel implementation on 3D simulation data.},
  archive      = {J_SISC},
  author       = {Rachel Minster and Zitong Li and Grey Ballard},
  doi          = {10.1137/22M1540363},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1186-A1213},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Parallel randomized tucker decomposition algorithms},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient solution of parameter identification problems with
<span class="math inline"><em>H</em><sup>1</sup></span> regularization.
<em>SISC</em>, <em>46</em>(2), A1160–A1185. (<a
href="https://doi.org/10.1137/22M1520591">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We consider the identification of spatially distributed parameters under regularization. Solving the associated minimization problem by Gauss–Newton iteration results in linearized problems to be solved in each step that can be cast as boundary value problems involving a low-rank modification of the Laplacian. Using an algebraic multigrid as a fast Laplace solver, the Sherman–Morrison–Woodbury formula can be employed to construct a preconditioner for these linear problems which exhibits excellent scaling w.r.t. the relevant problem parameters. We first develop this approach in the functional setting, thus obtaining a consistent methodology for selecting boundary conditions that arise from the regularization. We then construct a method for solving the discrete linear systems based on combining any fast Poisson solver with the Woodbury formula. The efficacy of this method is then demonstrated with scaling experiments. These are carried out for a common nonlinear parameter identification problem arising in electrical resistivity tomography. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available”, as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://doi.org/10.5281/zenodo.6855783.},
  archive      = {J_SISC},
  author       = {Jan Blechta and Oliver G. Ernst},
  doi          = {10.1137/22M1520591},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1160-A1185},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient solution of parameter identification problems with \(H^1\) regularization},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An entropy stable essentially oscillation-free discontinuous
galerkin method for hyperbolic conservation laws. <em>SISC</em>,
<em>46</em>(2), A1132–A1159. (<a
href="https://doi.org/10.1137/22M1524151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Entropy inequalities are crucial to the well-posedness of hyperbolic conservation laws, which help to select the physically meaningful one from among the infinite many weak solutions. Recently, several high order discontinuous Galerkin (DG) methods satisfying entropy inequalities were proposed; see [T. Chen and C.-W. Shu, J. Comput. Phys., 345 (2017), pp. 427–461; J. Chan, J. Comput. Phys., 362 (2018), pp. 346–374; T. Chen and C.-W. Shu, CSIAM Trans. Appl. Math., 1 (2020), pp. 1–52] and the references therein. However, high order numerical methods typically generate spurious oscillations in the presence of shock discontinuities. In this paper, we construct a high order entropy stable essentially oscillation-free DG (OFDG) method for hyperbolic conservation laws. With some suitable modification on the high order damping term introduced in [J. Lu, Y. Liu, and C.-W. Shu, SIAM J. Numer. Anal., 59 (2021), pp. 1299–1324; Y. Liu, J. Lu, and C.-W. Shu, SIAM J. Sci. Comput., 44 (2022), pp. A230–A259], we are able to construct an OFDG scheme with dissipative entropy. It is challenging to make the damping term compatible with the current entropy stable DG framework, that is, the damping term should be dissipative for any given entropy function without compromising high order accuracy. The key ingredient is to utilize the convexity of the entropy function and the orthogonality of the projection. Then the proposed method maintains the same properties of conservation, error estimates, and entropy dissipation as the original entropy stable DG method. Extensive numerical experiments are presented to validate the theoretical findings and the capability of controlling spurious oscillations of the proposed algorithm.},
  archive      = {J_SISC},
  author       = {Yong Liu and Jianfang Lu and Chi-Wang Shu},
  doi          = {10.1137/22M1524151},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1132-A1159},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An entropy stable essentially oscillation-free discontinuous galerkin method for hyperbolic conservation laws},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Dimensions of exactly divergence-free finite element spaces
in 3D. <em>SISC</em>, <em>46</em>(2), A1102–A1131. (<a
href="https://doi.org/10.1137/22M1544579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We examine the dimensions of various inf-sup stable mixed finite element spaces on tetrahedral meshes in three dimensions with exact divergence constraints. More precisely, we compare the standard Scott–Vogelius elements of higher polynomial degree and low-order methods on split meshes, the Alfeld and the Worsey–Farin split. The main tool is a counting strategy to express the degrees of freedom for given polynomial degree and given split in terms of only a few mesh quantities, for which bounds and asymptotic behavior under mesh refinement is investigated. Furthermore, this is used to obtain insights on potential precursor spaces in the Stokes complex for finite element methods on the Worsey–Farin split. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://git-ce.rwth-aachen.de/pub/meshquantities/ and in the supplementary materials (meshquantities-main.zip [3.13KB]).},
  archive      = {J_SISC},
  author       = {L. Ridgway Scott and Tabea Tscherpel},
  doi          = {10.1137/22M1544579},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1102-A1131},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Dimensions of exactly divergence-free finite element spaces in 3D},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Making the nyström method highly accurate for low-rank
approximations. <em>SISC</em>, <em>46</em>(2), A1076–A1101. (<a
href="https://doi.org/10.1137/23M1585039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Nyström method is a convenient strategy to obtain low-rank approximations to kernel matrices in nearly linear complexity. Existing studies typically use the method to approximate positive semidefinite matrices with low or modest accuracies. In this work, we propose a series of heuristic strategies to make the Nyström method reach high accuracies for nonsymmetric and/or rectangular matrices. The resulting methods (called high-accuracy Nyström methods) treat the Nyström method and a skinny rank-revealing factorization as a fast pivoting strategy in a progressive alternating direction refinement process. Two refinement mechanisms are used: alternating the row and column pivoting starting from a small set of randomly chosen columns, and adaptively increasing the number of samples until a desired rank or accuracy is reached. A fast subset update strategy based on the progressive sampling of Schur complements is further proposed to accelerate the refinement process. Efficient randomized accuracy control is also provided. Relevant accuracy and singular value analysis is given to support some of the heuristics. Extensive tests with various kernel functions and data sets show how the methods can quickly reach prespecified high accuracies in practice, sometimes with quality close to SVDs, using only small numbers of progressive sampling steps.},
  archive      = {J_SISC},
  author       = {Jianlin Xia},
  doi          = {10.1137/23M1585039},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1076-A1101},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Making the nyström method highly accurate for low-rank approximations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An incremental tensor train decomposition algorithm.
<em>SISC</em>, <em>46</em>(2), A1047–A1075. (<a
href="https://doi.org/10.1137/22M1537734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present a new algorithm for incrementally updating the tensor train decomposition of a stream of tensor data. This new algorithm, called the tensor train incremental core expansion (TT-ICE), improves upon the current state-of-the-art algorithms for compressing in tensor train format by developing a new adaptive approach that incurs significantly slower rank growth and guarantees compression accuracy. This capability is achieved by limiting the number of new vectors appended to the TT-cores of an existing accumulation tensor after each data increment. These vectors represent directions orthogonal to the span of existing cores and are limited to those needed to represent a newly arrived tensor to a target accuracy. We provide two versions of the algorithm: TT-ICE and TT-ICE accelerated with heuristics (TT-ICE). We provide a proof of correctness for TT-ICE and empirically demonstrate the performance of the algorithms in compressing large-scale video and scientific simulation datasets. Compared to existing approaches that also use rank adaptation, TT-ICE achieves higher compression and up to reduction in computational time. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available in https://github.com/dorukaks/TT-ICE as well as in the accompanying supplementary material.},
  archive      = {J_SISC},
  author       = {Doruk Aksoy and David J. Gorsich and Shravan Veerapaneni and Alex A. Gorodetsky},
  doi          = {10.1137/22M1537734},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1047-A1075},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An incremental tensor train decomposition algorithm},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). High-order mass- and energy-conserving methods for the
nonlinear schrödinger equation. <em>SISC</em>, <em>46</em>(2),
A1026–A1046. (<a href="https://doi.org/10.1137/22M152178X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A class of high-order mass- and energy-conserving methods is proposed for the nonlinear Schrödinger equation based on Gauss collocation in time and finite element discretization in space, by introducing a mass- and energy-correction post-process at every time level. The existence, uniqueness, and high-order convergence of the numerical solutions are proved. In particular, the error of the numerical solution is in the norm after incorporating the accumulation errors arising from the post-processing correction procedure at all time levels, where and denote the degrees of finite elements in time and space, respectively, which can be arbitrarily large. Several numerical examples are provided to illustrate the performance of the proposed new method, including the conservation of mass and energy and the high-order convergence in simulating solitons and bi-solitons. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/jiashhu/ME-Conserved-NLS and in the supplementary materials (ME-Conserved-NLS-main-2-Reproducibility-badge.zip [14.4MB]).},
  archive      = {J_SISC},
  author       = {Genming Bai and Jiashun Hu and Buyang Li},
  doi          = {10.1137/22M152178X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A1026-A1046},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {High-order mass- and energy-conserving methods for the nonlinear schrödinger equation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sparse recovery of elliptic solvers from matrix-vector
products. <em>SISC</em>, <em>46</em>(2), A998–A1025. (<a
href="https://doi.org/10.1137/22M154226X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we show that solvers of elliptic boundary value problems in dimensions can be approximated to accuracy from only matrix-vector products with carefully chosen vectors (right-hand sides). The solver is only accessed as a black box, and the underlying operator may be unknown and of an arbitrarily high order. Our algorithm (1) has complexity and represents the solution operator as a sparse Cholesky factorization with nonzero entries, (2) allows for embarrassingly parallel evaluation of the solution operator and the computation of its log-determinant, (3) allows for complexity computation of individual entries of the matrix representation of the solver that, in turn, enables its recompression to an complexity representation. As a byproduct, our compression scheme produces a homogenized solution operator with near-optimal approximation accuracy. By polynomial approximation, we can also approximate the continuous Green’s function (in operator and Hilbert–Schmidt norm) to accuracy from solutions of the PDE. We include rigorous proofs of these results. To the best of our knowledge, our algorithm achieves the best known trade-off between accuracy and the number of required matrix-vector products. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/f-t-s/sparse_recovery_of_elliptic_solution_operators_from_matrix-vector_products and in the supplementary materials (CompressingSolvers.jl-main.zip [2.50MB], sparse_recovery_of_elliptic_solution_operators_from_matrix-vector_products-main.zip [54.8KB]).},
  archive      = {J_SISC},
  author       = {Florian Schäfer and Houman Owhadi},
  doi          = {10.1137/22M154226X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A998-A1025},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Sparse recovery of elliptic solvers from matrix-vector products},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analytical galerkin boundary integrals of laplace kernel
layer potentials in <span
class="math inline">ℝ<sup><strong>3</strong></sup></span>.
<em>SISC</em>, <em>46</em>(2), A974–A997. (<a
href="https://doi.org/10.1137/23M1547688">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A method for analytical computation of the double surface integrals for all layer potential kernels associated with the Laplace Green’s function in the Galerkin boundary element method in using flat triangular elements with constant densities is presented. The method uses recursive dimensionality reduction from four dimensions based on Gauss’s divergence theorem. Computable analytical expressions for all cases of relative location of the source and receiver triangles are covered for the single and double layer potentials and their gradients with analytical treatment of the singular cases are presented. A trick that enables reduction of the case of gradient of the single layer to the same integrals as for the single layer is introduced using symmetry properties. The method was confirmed using analytical benchmark cases, comparisons with error-controlled computations of regular multidimensional integrals, and a convergence study for singular cases. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/pirl-lab/analytical-quadrature-laplace-galerkin.},
  archive      = {J_SISC},
  author       = {Nail A. Gumerov and Shoken Kaneko and Ramani Duraiswami},
  doi          = {10.1137/23M1547688},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A974-A997},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Analytical galerkin boundary integrals of laplace kernel layer potentials in \(\boldsymbol{\mathbb{R}^3}\)},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A numerical method for the stability analysis of linear
age-structured models with nonlocal diffusion. <em>SISC</em>,
<em>46</em>(2), A953–A973. (<a
href="https://doi.org/10.1137/23M1568971">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We numerically address the stability analysis of linear age-structured population models with nonlocal diffusion, which arise naturally in describing dynamics of infectious diseases. Compared to Laplace diffusion, models with nonlocal diffusion are more challenging since the associated semigroups have no regularizing properties in the spatial variable. Nevertheless, the asymptotic stability of the null equilibrium is determined by the spectrum of the infinitesimal generator associated with the semigroup. We propose a numerical method to approximate the leading part of this spectrum by first reformulating the problem via integration of the age-state and then by discretizing the generator combining a spectral projection in space with a pseudospectral collocation in age. A rigorous convergence analysis proving spectral accuracy is provided in the case of separable model coefficients. Results are confirmed experimentally and numerical tests are presented also for the more general instance. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://gitlab.com/SIMONE.DEREGGI/agenonlocig and in the supplementary materials (DE_REGGI_M156897R_codes.zip [16KB]).},
  archive      = {J_SISC},
  author       = {Dimitri Breda and Simone De Reggi and Rossana Vermiglio},
  doi          = {10.1137/23M1568971},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A953-A973},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A numerical method for the stability analysis of linear age-structured models with nonlocal diffusion},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AAA rational approximation on a continuum. <em>SISC</em>,
<em>46</em>(2), A929–A952. (<a
href="https://doi.org/10.1137/23M1570508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. AAA rational approximation has normally been carried out on a discrete set, typically hundreds or thousands of points in a real interval or complex domain. Here we introduce a continuum AAA algorithm that discretizes a domain adaptively as it goes. This enables fast computation of high-accuracy rational approximations on domains such as the unit interval, the unit circle, and the imaginary axis, even in some cases where resolution of singularities requires exponentially clustered sample points, support points, and poles. Prototype MATLAB (or Octave) and Julia codes aaax, aaaz, and aaai are provided for these three special domains; the latter two are equivalent by a Möbius transformation. Execution is very fast since the matrices whose SVDs are computed have only three times as many rows as columns. The codes include a AAA-Lawson option for improvement of a AAA approximant to minimax, so long as the accuracy is well above machine precision. The result returned is pole-free in the approximation domain. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://epubs.siam.org/doi/10.1137/23M1570508#supplementary-materials.},
  archive      = {J_SISC},
  author       = {Tobin A. Driscoll and Yuji Nakatsukasa and Lloyd N. Trefethen},
  doi          = {10.1137/23M1570508},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A929-A952},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {AAA rational approximation on a continuum},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Accelerating exponential integrators to efficiently solve
semilinear advection-diffusion-reaction equations. <em>SISC</em>,
<em>46</em>(2), A906–A928. (<a
href="https://doi.org/10.1137/23M1562056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we consider an approach to improve the performance of exponential Runge–Kutta integrators and Lawson schemes in cases where the solution of a related, but usually much simpler, problem can be computed efficiently. While for implicit methods such an approach is common (e.g., by using preconditioners), for exponential integrators this has proven more challenging. Here we propose to extract a constant coefficient differential operator from the semilinear advection-diffusion-reaction equation for which, in many situations, efficient methods are known to compute the required matrix functions. Both a linear stability analysis and extensive numerical experiments show that the resulting schemes can be unconditionally stable. In fact, we find that exponential integrators of Runge–Kutta type and Lawson schemes can have better stability properties than similarly constructed implicit-explicit schemes. We also derive two new Lawson-type integrators that further improve on these stability properties. The overall effectiveness of the approach is highlighted by a number of performance comparisons on examples in two and three space dimensions.},
  archive      = {J_SISC},
  author       = {Marco Caliari and Fabio Cassini and Lukas Einkemmer and Alexander Ostermann},
  doi          = {10.1137/23M1562056},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A906-A928},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Accelerating exponential integrators to efficiently solve semilinear advection-diffusion-reaction equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A block lanczos method for large-scale quadratic
minimization problems with orthogonality constraints. <em>SISC</em>,
<em>46</em>(2), A884–A905. (<a
href="https://doi.org/10.1137/23M1568545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Quadratic minimization problems with orthogonality constraints (QMPO) play an important role in many applications of science and engineering. However, some existing methods may suffer from low accuracy or heavy workload for large-scale QMPO. Krylov subspace methods are popular for large-scale optimization problems. In this work, we propose a block Lanczos method for solving the large-scale QMPO. In the proposed method, the original problem is projected into a small-sized one, and the Riemannian trust-region method is employed to solve the reduced QMPO. Convergence results on the optimal solution, the optimal objective function value, the multiplier, and the KKT error are established. Moreover, we give the convergence speed of the approximate solution and show that if the block Lanczos process terminates, then an exact KKT solution is derived. Numerical experiments illustrate the numerical behavior of the proposed algorithm and demonstrate that it is more powerful than many state-of-the-art algorithms for large-scale QMPO.},
  archive      = {J_SISC},
  author       = {Bo Feng and Gang Wu},
  doi          = {10.1137/23M1568545},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A884-A905},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A block lanczos method for large-scale quadratic minimization problems with orthogonality constraints},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A posteriori local subcell correction of high-order
discontinuous galerkin scheme for conservation laws on two-dimensional
unstructured grids. <em>SISC</em>, <em>46</em>(2), A851–A883. (<a
href="https://doi.org/10.1137/22M1542696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present the two-dimensional unstructured grids extension of the a posteriori local subcell correction of discontinuous Galerkin (DG) schemes introduced in [F. Vilar, J. Comput. Phys., 387 (2018), pp. 245–279]. The technique is based on the reformulation of the DG scheme as a finite-volume (FV)-like method through the definition of some specific numerical fluxes referred to as reconstructed fluxes. A high-order DG numerical scheme combined with this new local subcell correction technique ensures positivity preservation of the solution, along with a low oscillatory and sharp shocks representation. The main idea of this correction procedure is to retain as much as possible of the high accuracy and the very precise subcell resolution of DG schemes, while ensuring the robustness and stability of the numerical method, as well as preserving physical admissibility of the solution. Consequently, an a posteriori correction will only be applied locally at the subcell scale where it is needed, but still ensuring the scheme conservativity. Practically, at each time step, we compute a DG candidate solution and check if this solution is admissible (for instance positive, non-oscillating, …). If it is the case, we go further in time. Otherwise, we return to the previous time step and correct locally, at the subcell scale, the numerical solution. To this end, each cell is subdivided into subcells. Then, if the solution is locally detected as bad, we substitute the DG reconstructed flux on the subcell boundaries by a robust first-order numerical flux. For a subcell detected as admissible, we keep the high-order DG reconstructed flux which allows us to retain the very highly accurate resolution and conservation of the DG scheme. As a consequence, only the solution inside troubled subcells and its first neighbors will have to be recomputed; elsewhere, the solution remains unchanged. Another technique blending in a convex combination fashion DG reconstructed fluxes and first-order FV fluxes for admissible subcells in the vicinity of troubled areas will also be presented and prove to improve results in comparison to the original algorithm introduced in [F. Vilar, J. Comput. Phys., 387 (2018), pp. 245–279]. Numerical results on various type of problems and test cases will be presented to assess the very good performance of the designed correction algorithm.},
  archive      = {J_SISC},
  author       = {François Vilar and Rémi Abgrall},
  doi          = {10.1137/22M1542696},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A851-A883},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A posteriori local subcell correction of high-order discontinuous galerkin scheme for conservation laws on two-dimensional unstructured grids},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning the dynamics for unknown hyperbolic conservation
laws using deep neural networks. <em>SISC</em>, <em>46</em>(2),
A825–A850. (<a href="https://doi.org/10.1137/22M1537333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a new data-driven method to learn the dynamics of an unknown hyperbolic system of conservation laws using deep neural networks. Inspired by classical methods in numerical conservation laws, we develop a new conservative form network (CFN) in which the network learns to approximate the numerical flux function of the unknown system. Our numerical examples demonstrate that the CFN yields significantly better prediction accuracy than what is obtained using a standard nonconservative form network, even when it is enhanced with constraints to promote conservation. In particular, solutions obtained using the CFN consistently capture the correct shock propagation speed without introducing nonphysical oscillations into the solution. They are furthermore robust to noisy and sparse observation environments.},
  archive      = {J_SISC},
  author       = {Zhen Chen and Anne Gelb and Yoonsang Lee},
  doi          = {10.1137/22M1537333},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A825-A850},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Learning the dynamics for unknown hyperbolic conservation laws using deep neural networks},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An efficient block rational krylov solver for sylvester
equations with adaptive pole selection. <em>SISC</em>, <em>46</em>(2),
A798–A824. (<a href="https://doi.org/10.1137/23M1548463">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present an algorithm for the solution of Sylvester equations with right-hand side of low rank. The method is based on projection onto a block rational Krylov subspace, with two key contributions with respect to the state of the art. First, we show how to maintain the last pole equal to infinity throughout the iteration, by means of pole reordering, which allows for a cheap evaluation of the true residual at every step. Second, we extend the convergence analysis in [B. Beckermann, SIAM J. Numer. Anal., 49 (2011), pp. 2430–2450] to the block case. This extension allows us to link the convergence with the problem of minimizing the norm of a small rational matrix over the spectra or field-of-values of the involved matrices. This is in contrast with the nonblock case, where the minimum problem is scalar, instead of matrix valued. Replacing the norm of the objective function with a more easily evaluated function yields several adaptive pole selection strategies, providing a theoretical analysis for known heuristics, as well as effective novel techniques. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: Code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://github.com/numpi/rk_adaptive_sylvester and in the supplementary materials (125720_2_supp_537920_object_rzygf9.zip [7.20KB]).},
  archive      = {J_SISC},
  author       = {A. Casulli and L. Robol},
  doi          = {10.1137/23M1548463},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A798-A824},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An efficient block rational krylov solver for sylvester equations with adaptive pole selection},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Using witten laplacians to locate index-1 saddle points.
<em>SISC</em>, <em>46</em>(2), A770–A797. (<a
href="https://doi.org/10.1137/22M1541964">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a new stochastic algorithm to locate the index-1 saddle points of a function , with possibly large. This algorithm can be seen as an equivalent of the stochastic gradient descent which is a natural stochastic process to locate local minima. It relies on two ingredients: (i) the concentration properties on index-1 saddle points of the first eigenmodes of the Witten Laplacian (associated with ) on 1-forms and (ii) a probabilistic representation of a partial differential equation involving this differential operator. Numerical examples on simple molecular systems illustrate the efficacy of the proposed approach. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available in https://github.com/pp500/Stochastic-Saddle-Point-Dynamics and in the supplementary materials (Stochastic-Saddle-Point-Dynamics-main.zip [167KB]).},
  archive      = {J_SISC},
  author       = {Tony Lelièvre and Panos Parpas},
  doi          = {10.1137/22M1541964},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A770-A797},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Using witten laplacians to locate index-1 saddle points},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A grid-overlay finite difference method for the fractional
laplacian on arbitrary bounded domains. <em>SISC</em>, <em>46</em>(2),
A744–A769. (<a href="https://doi.org/10.1137/23M1558562">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A grid-overlay finite difference method is proposed for the numerical approximation of the fractional Laplacian on arbitrary bounded domains. The method uses an unstructured simplicial mesh and an overlay uniform grid for the underlying domain and constructs the approximation based on a uniform-grid finite difference approximation and a data transfer from the unstructured mesh to the uniform grid. The method takes full advantages of both uniform-grid finite difference approximation in efficient matrix-vector multiplication via the fast Fourier transform and unstructured meshes for complex geometries and mesh adaptation. It is shown that its stiffness matrix is similar to a symmetric and positive definite matrix and thus invertible if the data transfer has full column rank and positive column sums. Piecewise linear interpolation is studied as a special example for the data transfer. It is proved that the full column rank and positive column sums of linear interpolation are guaranteed if the spacing of the uniform grid is less than or equal to a positive bound proportional to the minimum element height of the unstructured mesh. Moreover, a sparse preconditioner is proposed for the iterative solution of the resulting linear system for the homogeneous Dirichlet problem of the fractional Laplacian. Numerical examples demonstrate that the new method has convergence behavior similar to that of existing finite difference and finite element methods and that the sparse preconditioning is effective. Furthermore, the new method can be readily incorporated with existing mesh adaptation strategies. Numerical results obtained by combining the method with the so-called MMPDE (moving mesh partial differential equation) method are also presented.},
  archive      = {J_SISC},
  author       = {Weizhang Huang and Jinye Shen},
  doi          = {10.1137/23M1558562},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A744-A769},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A grid-overlay finite difference method for the fractional laplacian on arbitrary bounded domains},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A recursively recurrent neural network (R2N2) architecture
for learning iterative algorithms. <em>SISC</em>, <em>46</em>(2),
A719–A743. (<a href="https://doi.org/10.1137/22M1535310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Metalearning of numerical algorithms for a given task consists of the data-driven identification and adaptation of an algorithmic structure and the associated hyperparameters. To limit the complexity of the metalearning problem, neural architectures with a certain inductive bias towards favorable algorithmic structures can, and should, be used. We generalize our previously introduced Runge–Kutta neural network to a recursively recurrent neural network superstructure for the design of customized iterative algorithms. In contrast to off-the-shelf deep learning approaches, it features a distinct division into modules for generation of information and for the subsequent assembly of this information towards a solution. Local information in the form of a subspace is generated by subordinate, inner, iterations of recurrent function evaluations starting at the current outer iterate. The update to the next outer iterate is computed as a linear combination of these evaluations, reducing the residual in this space, and constitutes the output of the network. We demonstrate that regular training of the weight parameters inside the proposed superstructure on input/output data of various computational problem classes yields iterations similar to Krylov solvers for linear equation systems, Newton–Krylov solvers for nonlinear equation systems, and Runge–Kutta integrators for ordinary differential equations. Due to its modularity, the superstructure can be readily extended with functionalities needed to represent more general classes of iterative algorithms traditionally based on Taylor series expansions.},
  archive      = {J_SISC},
  author       = {Danimir T. Doncevic and Alexander Mitsos and Yue Guo and Qianxiao Li and Felix Dietrich and Manuel Dahmen and Ioannis G. Kevrekidis},
  doi          = {10.1137/22M1535310},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A719-A743},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A recursively recurrent neural network (R2N2) architecture for learning iterative algorithms},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new ParaDiag time-parallel time integration method.
<em>SISC</em>, <em>46</em>(2), A697–A718. (<a
href="https://doi.org/10.1137/23M1568028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Time-parallel time integration has received a lot of attention in the high performance computing community over the past two decades. Indeed, it has been shown that parallel-in-time techniques have the potential to remedy one of the main computational drawbacks of parallel-in-space solvers. In particular, it is well-known that for large-scale evolution problems space parallelization saturates long before all processing cores are effectively used on today’s large-scale parallel computers. Among the many approaches for time-parallel time integration, ParaDiag schemes have proven to be a very effective approach. In this framework, the time stepping matrix or an approximation thereof is diagonalized by Fourier techniques, so that computations taking place at different time steps can be indeed carried out in parallel. We propose here a new ParaDiag algorithm combining the Sherman–Morrison–Woodbury formula and Krylov techniques. A panel of diverse numerical examples illustrates the potential of our new solver. In particular, we show that it performs very well compared to different ParaDiag algorithms recently proposed in the literature.},
  archive      = {J_SISC},
  author       = {Martin J. Gander and Davide Palitta},
  doi          = {10.1137/23M1568028},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A697-A718},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A new ParaDiag time-parallel time integration method},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Asymptotic dispersion correction in general finite
difference schemes for helmholtz problems. <em>SISC</em>,
<em>46</em>(2), A670–A696. (<a
href="https://doi.org/10.1137/22M1531142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Most numerical approximations of frequency-domain wave propagation problems suffer from the so-called dispersion error, which is the fact that plane waves at the discrete level oscillate at a frequency different from the continuous one. In this paper, we introduce a new technique to reduce the dispersion error in general finite difference (FD) schemes for frequency-domain wave propagation using the Helmholtz equation as a guiding example. Our method is based on the introduction of a shifted wavenumber in the FD stencil which we use to reduce the numerical dispersion for large enough numbers of grid points per wavelength (or for small enough meshsize), and thus we call the method asymptotic dispersion correction. The advantage of this technique is that the asymptotically optimal shift can be determined in closed form by computing the extrema of a function over a compact set. For one-dimensional Helmholtz equations, we prove that the standard 3-point stencil with shifted wavenumber does not have any dispersion error, and that the so-called pollution effect is completely suppressed. For higher dimensional Helmholtz problems, we give easy-to-use closed form formulas for the asymptotically optimal shift associated to the second-order 5-point scheme and a sixth-order 9-point scheme in two dimensions, and the 7-point scheme in three dimensions that yield substantially less dispersion error than their standard (unshifted) version. We illustrate this also with numerical experiments.},
  archive      = {J_SISC},
  author       = {Pierre-Henri Cocquet and Martin J. Gander},
  doi          = {10.1137/22M1531142},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A670-A696},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Asymptotic dispersion correction in general finite difference schemes for helmholtz problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Numerical surgery for mean curvature flow of surfaces.
<em>SISC</em>, <em>46</em>(2), A645–A669. (<a
href="https://doi.org/10.1137/22M1531919">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A numerical algorithm for mean curvature flow of closed mean convex surfaces with surgery is proposed. The method uses a finite element–based mean curvature flow algorithm based on a coupled partial differential equation system which directly provides an approximation for mean curvature and outward unit normal. The proposed numerical surgery process closely follows the analytical surgery of Huisken and Sinestrari and of Brendle and Huisken. The numerical surgery approach is described in detail, along with extensions to other geometric flows and methods. Numerical experiments report on the performance of the numerical surgery process.},
  archive      = {J_SISC},
  author       = {Balázs Kovács},
  doi          = {10.1137/22M1531919},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A645-A669},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Numerical surgery for mean curvature flow of surfaces},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Two conjectures on the stokes complex in three dimensions on
freudenthal meshes. <em>SISC</em>, <em>46</em>(2), A629–A644. (<a
href="https://doi.org/10.1137/22M1533943">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In recent years, a great deal of attention has been paid to discretizations of the incompressible Stokes equations that exactly preserve the incompressibility constraint. These are of substantial interest because these discretizations are pressure-robust; i.e., the error estimates for the velocity do not depend on the error in the pressure. Similar considerations arise in nearly incompressible linear elastic solids. Conforming discretizations with this property are now well understood in two dimensions but remain poorly understood in three dimensions. In this work, we state two conjectures on this subject. The first is that the Scott–Vogelius element pair is inf-sup stable on uniform meshes for velocity degree ; the best result available in the literature is for . The second is that there exists a stable space decomposition of the kernel of the divergence for . We present numerical evidence supporting our conjectures.},
  archive      = {J_SISC},
  author       = {Patrick E. Farrell and Lawrence Mitchell and L. Ridgway Scott},
  doi          = {10.1137/22M1533943},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {4},
  number       = {2},
  pages        = {A629-A644},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Two conjectures on the stokes complex in three dimensions on freudenthal meshes},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New SISC section on scientific machine learning.
<em>SISC</em>, <em>46</em>(1), vii–viii. (<a
href="https://doi.org/10.1137/23M160832X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_SISC},
  author       = {Hans De Sterck},
  doi          = {10.1137/23M160832X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {vii-viii},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {New SISC section on scientific machine learning},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). AONN: An adjoint-oriented neural network method for
all-at-once solutions of parametric optimal control problems.
<em>SISC</em>, <em>46</em>(1), C127–C153. (<a
href="https://doi.org/10.1137/22M154209X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Parametric optimal control problems governed by partial differential equations (PDEs) are widely found in scientific and engineering applications. Traditional grid-based numerical methods for such problems generally require repeated solutions of PDEs with different parameter settings, which is computationally prohibitive, especially for problems with high-dimensional parameter spaces. Although recently proposed neural network methods make it possible to obtain the optimal solutions simultaneously for different parameters, challenges still remain when dealing with problems with complex constraints. In this paper, we propose the AONN, an adjoint-oriented neural network method, to overcome the limitations of existing approaches in solving parametric optimal control problems. In an AONN, the neural networks are served as parametric surrogate models for the control, adjoint, and state functions to get the optimal solutions all at once. In order to reduce the training difficulty and handle complex constraints, we introduce an iterative training framework inspired by the classical direct-adjoint looping method so that penalty terms arising from the Karush–Kuhn–Tucker system can be avoided. Once the training is done, parameter-specific optimal solutions can be quickly computed through the forward propagation of the neural networks, which may be further used for analyzing the parametric properties of the optimal solutions. The validity and efficiency of the AONN is demonstrated through a series of numerical experiments with problems involving various types of parameters.},
  archive      = {J_SISC},
  author       = {Pengfei Yin and Guangqiang Xiao and Kejun Tang and Chao Yang},
  doi          = {10.1137/22M154209X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {C127-C153},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {AONN: An adjoint-oriented neural network method for all-at-once solutions of parametric optimal control problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven kernel designs for optimized greedy schemes: A
machine learning perspective. <em>SISC</em>, <em>46</em>(1), C101–C126.
(<a href="https://doi.org/10.1137/23M1551201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Thanks to their easy implementation via radial basis functions (RBFs), meshfree kernel methods have proved to be an effective tool for, e.g., scattered data interpolation, PDE collocation, and classification and regression tasks. Their accuracy might depend on a length scale hyperparameter, which is often tuned via cross-validation schemes. Here we leverage approaches and tools from the machine learning community to introduce two-layered kernel machines, which generalize the classical RBF approaches that rely on a single hyperparameter. Indeed, the proposed learning strategy returns a kernel that is optimized not only in the Euclidean directions, but that further incorporates kernel rotations. The kernel optimization is shown to be robust by using recently improved calculations of cross-validation scores. Finally, the use of greedy approaches, and specifically of the vectorial kernel orthogonal greedy algorithm (VKOGA), allows us to construct an optimized basis that adapts to the data. Beyond a rigorous analysis on the convergence of the so-constructed two-layered (2L)-KOGA, its benefits are highlighted on both synthesized and real benchmark datasets.},
  archive      = {J_SISC},
  author       = {Tizian Wenzel and Francesco Marchetti and Emma Perracchione},
  doi          = {10.1137/23M1551201},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {C101-C126},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Data-driven kernel designs for optimized greedy schemes: A machine learning perspective},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). TNet: A model-constrained tikhonov network approach for
inverse problems. <em>SISC</em>, <em>46</em>(1), C77–C100. (<a
href="https://doi.org/10.1137/22M1526708">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Deep learning (DL), in particular deep neural networks, by default is purely data-driven and in general does not require physics. This is the strength of DL but also one of its key limitations when applied to science and engineering problems in which underlying physical properties—such as stability, conservation, and positivity—and accuracy are required. DL methods in their original forms are often not capable of respecting the underlying mathematical models or achieving desired accuracy even in big-data regimes. On the other hand, many data-driven science and engineering problems, such as inverse problems, typically have limited experimental or observational data, and DL would overfit the data in this case. Leveraging information encoded in the underlying mathematical models, we argue, not only compensates for missing information in low data regimes but also provides opportunities to equip DL methods with the underlying physics, hence promoting better generalization. This paper develops a model-constrained DL approach and its variant TNet—a Tikhonov neural network—which are capable of learning not only information hidden in the training data but also in the underlying mathematical models to solve inverse problems governed by partial differential equations in low data regimes. We provide the constructions and some theoretical results for the proposed approaches for both linear and nonlinear inverse problems. Since TNet is designed to learn inverse solutions with Tikhonov regularization, it is interpretable: in fact it recovers Tikhonov solutions for linear cases while potentially approximating Tikhonov solutions for nonlinear inverse problems. We also prove that data randomization can enhance not only the smoothness of the networks but also their generalizations. Comprehensive numerical results confirm the theoretical findings and show that with even as little as 1 training data sample for one-dimensional (1D) deconvolution, 5 for an inverse 2D heat conductivity problem, 100 for inverse initial conditions for a time-dependent 2D Burgers’s equation, and 50 for inverse initial conditions for 2D Navier–Stokes equations, TNet solutions can be as accurate as Tikhonov solutions while being several orders of magnitude faster. This is possible owing to the model-constrained term, replications, and randomization.},
  archive      = {J_SISC},
  author       = {Hai V. Nguyen and Tan Bui-Thanh},
  doi          = {10.1137/22M1526708},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {C77-C100},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {TNet: A model-constrained tikhonov network approach for inverse problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Bayesian deep learning framework for uncertainty
quantification in stochastic partial differential equations.
<em>SISC</em>, <em>46</em>(1), C57–C76. (<a
href="https://doi.org/10.1137/23M1560574">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Bayesian physics-informed neural networks (B-PINNs) have emerged as an efficient tool for uncertainty quantification in partial differential equations (PDEs). However, their applicability has been limited to accounting for noisy data. They fail to effectively address the uncertainty arising from the randomness of physical parameters in stochastic PDEs (SPDEs). To this end, we propose a novel Bayesian deep learning framework designed for uncertainty quantification in SPDE problems. We model the solution of an SPDE using a Bayesian neural network (BNN), where the posterior distribution of the parameters is constructed by Bayes’ rule. We incorporate the governing physical laws into the likelihood distribution through automatic differentiation and estimate the likelihood using a Gaussian mixture model. To effectively learn the posterior distribution of BNN parameters, we employ a Hamiltonian Monte Carlo method, an efficient method for high-dimensional sampling. We propose a parallel algorithm to mitigate the high computational cost associated with the Hamiltonian Monte Carlo, thereby enhancing its efficiency. We provide numerical examples for both forward and inverse SPDE problems to demonstrate the effectiveness of our proposed method for uncertainty quantification in SPDEs. Notably, it is demonstrated that the computational cost is almost unaffected by the number of BNN parameters and the random dimension of the problem, underscoring its computational efficiency.},
  archive      = {J_SISC},
  author       = {Jeahan Jung and Hyomin Shin and Minseok Choi},
  doi          = {10.1137/23M1560574},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {C57-C76},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Bayesian deep learning framework for uncertainty quantification in stochastic partial differential equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Adaptive precision sparse matrix–vector product and its
application to krylov solvers. <em>SISC</em>, <em>46</em>(1), C30–C56.
(<a href="https://doi.org/10.1137/22M1522619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We introduce a mixed precision algorithm for computing sparse matrix-vector products and use it to accelerate the solution of sparse linear systems by iterative methods. Our approach is based on the idea of adapting the precision of each matrix element to their magnitude: we split the elements into buckets and use progressively lower precisions for the buckets of progressively smaller elements. We carry out a rounding error analysis of this algorithm that provides us with an explicit rule to decide which element goes into which bucket and allows us to rigorously control the accuracy of the algorithm. We implement the algorithm on a multicore computer and obtain significant speedups (up to a factor ) with respect to uniform precision algorithms, without loss of accuracy, on a range of sparse matrices from real-life applications. We showcase the effectiveness of our algorithm by plugging it into various Krylov solvers for sparse linear systems and observe that the convergence of the solution is essentially unaffected by the use of adaptive precision.},
  archive      = {J_SISC},
  author       = {Stef Graillat and Fabienne Jézéquel and Theo Mary and Roméo Molina},
  doi          = {10.1137/22M1522619},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {C30-C56},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Adaptive precision sparse Matrix–Vector product and its application to krylov solvers},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Deep importance sampling using tensor trains with
application to a priori and a posteriori rare events. <em>SISC</em>,
<em>46</em>(1), C1–C29. (<a
href="https://doi.org/10.1137/23M1546981">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We propose a deep importance sampling method that is suitable for estimating rare event probabilities in high-dimensional problems. We approximate the optimal importance distribution in a general importance sampling problem as the pushforward of a reference distribution under a composition of order-preserving transformations, in which each transformation is formed by a squared tensor-train decomposition. The squared tensor-train decomposition provides a scalable ansatz for building order-preserving high-dimensional transformations via density approximations. The use of a composition of maps moving along a sequence of bridging densities alleviates the difficulty of directly approximating concentrated density functions. To compute expectations over unnormalized probability distributions, we design a ratio estimator that estimates the normalizing constant using a separate importance distribution, again constructed via a composition of transformations in tensor-train format. This offers better theoretical variance reduction compared to self-normalized importance sampling and thus opens the door to efficient computation of rare event probabilities in Bayesian inference problems. Numerical experiments on problems constrained by differential equations show little to no increase in the computational complexity of the estimator when the event probability goes to zero, enabling us to compute hitherto unattainable estimates of rare event probabilities for complex, high-dimensional posterior densities. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available”, as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available in https://github.com/DeepTransport/TT-rare.},
  archive      = {J_SISC},
  author       = {Tiangang Cui and Sergey Dolgov and Robert Scheichl},
  doi          = {10.1137/23M1546981},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {C1-C29},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Deep importance sampling using tensor trains with application to a priori and a posteriori rare events},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Space-time reduced basis methods for parametrized unsteady
stokes equations. <em>SISC</em>, <em>46</em>(1), B1–B32. (<a
href="https://doi.org/10.1137/22M1509114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we analyze space-time reduced basis methods for the efficient numerical simulation of hæmodynamics in arteries. The classical formulation of the reduced basis (RB) method features dimensionality reduction in space, while finite difference schemes are employed for the time integration of the resulting ordinary differential equation (ODE). Space-time reduced basis (ST–RB) methods extend the dimensionality reduction paradigm to the temporal dimension, projecting the full-order problem onto a low-dimensional spatio-temporal subspace. Our goal is to investigate the application of ST–RB methods to the unsteady incompressible Stokes equations, with a particular focus on stability. High-fidelity simulations are performed using the finite element (FE) method and BDF2 as a time marching scheme. We consider two different ST–RB methods. In the first one—called ST–GRB—space-time model order reduction is achieved by means of a Galerkin projection; a spatio-temporal velocity basis enrichment procedure is introduced to guarantee stability. The second method—called ST–PGRB—is characterized by a Petrov–Galerkin projection, stemming from a suitable minimization of the FOM residual, that allows us to automatically attain stability. The classical RB method—denoted as SRB–TFO—serves as a baseline for the theoretical development. Numerical tests have been conducted on an idealized symmetric bifurcation geometry and on the patient-specific one of a femoropopliteal bypass. The results show that both ST–RB methods provide accurate approximations of the high-fidelity solutions, while considerably reducing the computational cost. In particular, the ST–PGRB method exhibits the best performance, as it features a better computational efficiency while retaining accuracies in accordance with theoretical expectations.},
  archive      = {J_SISC},
  author       = {Riccardo Tenderini and Nicholas Mueller and Simone Deparis},
  doi          = {10.1137/22M1509114},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {B1-B32},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Space-time reduced basis methods for parametrized unsteady stokes equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Rapid evaluation of newtonian potentials on planar domains.
<em>SISC</em>, <em>46</em>(1), A609–A628. (<a
href="https://doi.org/10.1137/22M1526666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The accurate and efficient evaluation of Newtonian potentials over general two-dimensional domains is important for the numerical solution of Poisson’s equation and volume integral equations. In this paper, we present a simple and efficient high-order algorithm for computing the Newtonian potential over a planar domain discretized by an unstructured mesh. The algorithm is based on the use of Green’s third identity for transforming the Newtonian potential into a collection of layer potentials over the boundaries of the mesh elements, which can be easily evaluated by the Helsing–Ojala method. One important component of our algorithm is the use of high-order (up to order 20) bivariate polynomial interpolation in the monomial basis, for which we provide extensive justification. The performance of our algorithm is illustrated through several numerical experiments.},
  archive      = {J_SISC},
  author       = {Zewen Shen and Kirill Serkh},
  doi          = {10.1137/22M1526666},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A609-A628},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Rapid evaluation of newtonian potentials on planar domains},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). New artificial tangential motions for parametric finite
element approximation of surface evolution. <em>SISC</em>,
<em>46</em>(1), A587–A608. (<a
href="https://doi.org/10.1137/23M1551857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A new class of parametric finite element methods, with a new type of artificial tangential velocity constructed at the continuous level, is proposed for solving surface evolution under geometric flows. The method is constructed by coupling the normal velocity of the geometric flow with an artificial tangential velocity determined by a harmonic map from a fixed reference surface to the unknown surface , formulated at the continuous level as a system of geometric partial differential equations in terms of a Lagrange multiplier. Since the harmonic map is almost angle-preserving, the new method could preserve the mesh quality, i.e., the shapes of the triangles, as long as the mesh quality of the reference surface is good. Extensive numerical experiments and benchmark examples are presented to demonstrate the convergence of the proposed method and the advantages of the method in preserving the mesh quality of the surfaces for mean curvature flow and surface diffusion, in comparison with other available methods such as the parametric finite element methods proposed by Barrett, Garcke, and Nürnberg in 2008 and the DeTurck flow techniques proposed by Elliott and Fritz in 2017.},
  archive      = {J_SISC},
  author       = {Beiping Duan and Buyang Li},
  doi          = {10.1137/23M1551857},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A587-A608},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {New artificial tangential motions for parametric finite element approximation of surface evolution},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Nonlinearly constrained pressure residual (NCPR) algorithms
for fractured reservoir simulation. <em>SISC</em>, <em>46</em>(1),
A561–A586. (<a href="https://doi.org/10.1137/22M1516294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The constrained pressure residual (CPR) algorithm is a family of well-known and industry-standard preconditioners for large-scale reservoir simulation. The CPR algorithm is a two-stage preconditioner to deal with different blocks stage-by-stage, and is often able to effectively improve the robustness behavior and the convergence speed of linear iterations. Nonetheless, as a linear preconditioner, it is hard for the traditional CPR method to be capable of action at the nonlinear level for effectively solving large sparse nonlinear systems of equations with high nonlinearity. In this paper, we present and study the extension of this linear method to the nonlinearly CPR (NCPR) case for solving fractured reservoir problems, to deal with the difficulty of the slow convergence or stagnation from the nonlinear level. In the proposed nonlinear preconditioning, a subspace nonlinear block system is first built and solved to remove the unbalanced nonlinearities of the pressure and the saturation fields, and the fast convergence can then be restored when a variant of semismooth Newton methods is called after the subspace nonlinear block system is solved. Experiments on two or three dimensional porous media applications are presented to demonstrate the applicability and parallel scalability of the aforementioned NCPR method. We also show that the proposed algorithm is superior to the commonly used nonlinear algorithm in terms of the robustness and the positivity-preserving property.},
  archive      = {J_SISC},
  author       = {Haijian Yang and Rui Li and Chao Yang},
  doi          = {10.1137/22M1516294},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A561-A586},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Nonlinearly constrained pressure residual (NCPR) algorithms for fractured reservoir simulation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Stable rank-adaptive dynamically orthogonal runge–kutta
schemes. <em>SISC</em>, <em>46</em>(1), A529–A560. (<a
href="https://doi.org/10.1137/22M1534948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We develop two new sets of stable, rank-adaptive dynamically orthogonal Runge–Kutta (DORK) schemes that capture the high-order curvature of the nonlinear low-rank manifold. The DORK schemes asymptotically approximate the truncated singular value decomposition at a greatly reduced cost while preserving mode continuity using newly derived retractions. We show that arbitrarily high-order optimal perturbative retractions can be obtained, and we prove that these new retractions are stable. In addition, we demonstrate that repeatedly applying retractions yields a gradient-descent algorithm on the low-rank manifold that converges superlinearly when approximating a low-rank matrix. When approximating a higher-rank matrix, iterations converge linearly to the best low-rank approximation. We then develop a rank-adaptive retraction that is robust to overapproximation. Building off of these retractions, we derive two rank-adaptive integration schemes that dynamically update the subspace upon which the system dynamics are projected within each time step: the stable, optimal dynamically orthogonal Runge–Kutta (so-DORK) and gradient-descent dynamically orthogonal Runge–Kutta (gd-DORK) schemes. These integration schemes are numerically evaluated and compared on an ill-conditioned matrix differential equation, an advection-diffusion partial differential equation, and a nonlinear, stochastic reaction-diffusion partial differential equation. Results show a reduced error accumulation rate with the new stable, optimal and gradient-descent integrators. In addition, we find that rank adaptation allows for highly accurate solutions while preserving computational efficiency.},
  archive      = {J_SISC},
  author       = {Aaron Charous and Pierre F. J. Lermusiaux},
  doi          = {10.1137/22M1534948},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A529-A560},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Stable rank-adaptive dynamically orthogonal Runge–Kutta schemes},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Efficient error and variance estimation for randomized
matrix computations. <em>SISC</em>, <em>46</em>(1), A508–A528. (<a
href="https://doi.org/10.1137/23M1558537">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Randomized matrix algorithms have become workhorse tools in scientific computing and machine learning. To use these algorithms safely in applications, they should be coupled with posterior error estimates to assess the quality of the output. To meet this need, this paper proposes two diagnostics: a leave-one-out error estimator for randomized low-rank approximations and a jackknife resampling method to estimate the variance of the output of a randomized matrix computation. Both of these diagnostics are rapid to compute for randomized low-rank approximation algorithms such as the randomized SVD and randomized Nyström approximation, and they provide useful information that can be used to assess the quality of the computed output and guide algorithmic parameter choices.},
  archive      = {J_SISC},
  author       = {Ethan N. Epperly and Joel A. Tropp},
  doi          = {10.1137/23M1558537},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A508-A528},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Efficient error and variance estimation for randomized matrix computations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Data-driven and low-rank implementations of balanced
singular perturbation approximation. <em>SISC</em>, <em>46</em>(1),
A483–A507. (<a href="https://doi.org/10.1137/23M155791X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. Balanced singular perturbation approximation (SPA) is a model order reduction method for linear time-invariant systems that guarantees asymptotic stability and for which there exists an a priori error bound. In that respect, it is similar to balanced truncation (BT). However, the reduced models obtained by SPA generally introduce better approximation in the lower frequency range and near steady-states, whereas BT is better suited for the higher frequency range. Even so, independently of the frequency range of interest, BT and its variants are more often applied in practice, since there exist more efficient algorithmic realizations thereof. In this paper, we aim at closing this practically relevant gap for SPA. We propose two novel and efficient algorithms that are adapted for different settings. First, we derive a low-rank implementation of SPA that is applicable in the large-scale setting. Second, a data-driven reinterpretation of the method is proposed that only requires input-output data and thus is realization-free. A main tool for our derivations is the reciprocal transformation, which induces a distinct view on implementing the method. While the reciprocal transformation and the characterization of SPA are not new, their significance for the practical algorithmic realization has been overlooked in the literature. Our proposed algorithms have well-established counterparts for BT and, as such, a comparable computational complexity. The numerical performance of the two novel implementations is tested for several numerical benchmarks, and comparisons to their counterparts for BT as well as to existing implementations of SPA are made. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at https://doi.org/10.5281/zenodo.7671264 as well as in the accompanying supplementary materials (CodeBalancedSPA.zip [6.62MB]).},
  archive      = {J_SISC},
  author       = {Björn Liljegren-Sailer and Ion Victor Gosea},
  doi          = {10.1137/23M155791X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A483-A507},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Data-driven and low-rank implementations of balanced singular perturbation approximation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Behavior of the discontinuous galerkin method for
compressible flows at low mach number on triangles and tetrahedrons.
<em>SISC</em>, <em>46</em>(1), A452–A482. (<a
href="https://doi.org/10.1137/23M154755X">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this article, we are interested in the behavior of discontinuous Galerkin schemes for compressible flows in the low Mach number limit. We prove that for any numerical flux conserving exactly contacts (e.g., exact Godunov, Roe, HLLC), the numerical scheme is accurate at low Mach number flows on simplicial meshes, which is an extension to higher order of the result proven in [H. Guillard, Comput. Fluids, 38 (2009), pp. 1969–1972]. When the mesh is not simplicial, or when the mesh is simplicial but the numerical flux does not conserve contacts (e.g., Lax–Friedrich, HLL), the scheme is numerically proven to be less accurate in the low Mach number limit.},
  archive      = {J_SISC},
  author       = {Jonathan Jung and Vincent Perrier},
  doi          = {10.1137/23M154755X},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A452-A482},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Behavior of the discontinuous galerkin method for compressible flows at low mach number on triangles and tetrahedrons},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A second-order, linear, <span
class="math inline"><strong>L</strong><sup><strong>∞</strong></sup></span>-convergent,
and energy stable scheme for the phase field crystal equation.
<em>SISC</em>, <em>46</em>(1), A429–A451. (<a
href="https://doi.org/10.1137/23M1552164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we present a second-order accurate and linear numerical scheme for the phase field crystal equation and prove its convergence in the discrete sense. The key ingredient of the error analysis is to justify the boundedness of the numerical solution, so that the nonlinear term, treated explicitly in the scheme, can be bounded appropriately. Benefiting from the existence of the sixth-order dissipation term in the model, we first estimate the discrete norm of the numerical error. The error estimate in the supremum norm is then obtained by the Sobolev embedding, so that the uniform bound of the numerical solution is available. We also show the mass conservation and the energy stability in the discrete setting. The proposed scheme is linear with constant coefficients so that it can be solved efficiently via some fast algorithms. Numerical experiments are conducted to verify the theoretical results, and long-time simulations in two- and three-dimensional spaces demonstrate the satisfactory and high effectiveness of the proposed numerical scheme.},
  archive      = {J_SISC},
  author       = {Xiao Li and Zhonghua Qiao},
  doi          = {10.1137/23M1552164},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A429-A451},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A second-order, linear, \(\boldsymbol{L^\infty}\)-convergent, and energy stable scheme for the phase field crystal equation},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Staggered schemes for compressible flow: A general
construction. <em>SISC</em>, <em>46</em>(1), A399–A428. (<a
href="https://doi.org/10.1137/22M1518566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper is focused on the approximation of the Euler equations of compressible fluid dynamics on a staggered mesh. With this aim, the flow parameters are described by the velocity, the density, and the internal energy. The thermodynamic quantities are described on the elements of the mesh, and thus the approximation is only in , while the kinematic quantities are globally continuous. The method is general in the sense that the thermodynamic and kinetic parameters are described by an arbitrary degree of polynomials. In practice, the difference between the degrees of the kinematic parameters and the thermodynamic ones is set to 1. The integration in time is done using the forward Euler method but can be extended straightforwardly to higher-order methods. In order to guarantee that the limit solution will be a weak solution of the problem, we introduce a general correction method in the spirit of the Lagrangian staggered method described in [R. Abgrall and S. Tokareva, SIAM J. Sci. Comput., 39 (2017), pp. A2345–A2364; R. Abgrall, K. Lipnikov, N. Morgan, and S. Tokareva, SIAM J. Sci. Comput., 2 (2020), pp. A343–A370; V. A. Dobrev, T. V. Kolev, and R. N. Rieben, SIAM J. Sci. Comput., 34 (2012), pp. B606–B641], and we prove a Lax–Wendroff theorem. The proof is valid for multidimensional versions of the scheme, even though most of the numerical illustrations in this work, on classical benchmark problems, are one-dimensional because we have easy access to the exact solution for comparison. We conclude by explaining that the method is general and can be used in different settings, for example, finite volume or discontinuous Galerkin method, not just the specific one presented in this paper.},
  archive      = {J_SISC},
  author       = {Remi Abgrall},
  doi          = {10.1137/22M1518566},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A399-A428},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Staggered schemes for compressible flow: A general construction},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A numerical domain decomposition method for solving elliptic
equations on manifolds. <em>SISC</em>, <em>46</em>(1), A376–A398. (<a
href="https://doi.org/10.1137/23M1546221">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A new numerical domain decomposition method is proposed for solving elliptic equations on compact Riemannian manifolds. The advantage of this method is to avoid global triangulations or grids on manifolds. Our method is numerically tested on some four-dimensional manifolds such as the unit sphere , the complex projective space , and the product manifold .},
  archive      = {J_SISC},
  author       = {Shuhao Cao and Lizhen Qin},
  doi          = {10.1137/23M1546221},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A376-A398},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A numerical domain decomposition method for solving elliptic equations on manifolds},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Computing weak distance between the 2-sphere and its
nonsmooth approximations. <em>SISC</em>, <em>46</em>(1), A360–A375. (<a
href="https://doi.org/10.1137/23M1571216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A novel algorithm is proposed for quantitative comparisons between compact surfaces embedded in the three-dimensional Euclidian space. The key idea is to identify those objects with the associated surface measures and compute a weak distance between them using the Fourier transform on the ambient space. In particular, the inhomogeneous Sobolev norm of negative order for a difference between two surface measures is evaluated via the Plancherel theorem, which amounts to approximating a weighted integral norm of smooth data on the frequency space. This approach allows several advantages, including high accuracy due to fast-converging numerical quadrature rules, acceleration by the nonuniform fast Fourier transform, and parallelization on many-core processors. In numerical experiments, the 2-sphere, which is an example whose Fourier transform is explicitly known, is compared with its icosahedral discretization, and it is observed that the piecewise linear approximations converge to the smooth object at the quadratic rate up to small truncation.},
  archive      = {J_SISC},
  author       = {Kazuki Koga},
  doi          = {10.1137/23M1571216},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A360-A375},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Computing weak distance between the 2-sphere and its nonsmooth approximations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Evaluation of inner products of implicitly defined finite
element functions on multiply connected planar mesh cells.
<em>SISC</em>, <em>46</em>(1), A338–A359. (<a
href="https://doi.org/10.1137/23M1569332">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In recent years, there has been significant interest in the development of finite element methods defined on meshes that include rather general polytopes and curvilinear polygons. In the present work, we provide tools necessary to employ multiply connected mesh cells in planar domains, i.e., cells with holes, in finite element computations. Our focus is efficient evaluation of the semi-inner product and inner product of implicitly defined finite element functions of the types arising in boundary element based finite element methods and virtual element methods. Such functions are defined as solutions of Poisson problems having a polynomial source term and continuous boundary data. We show that the integrals of interest can be reduced to integrals along the boundaries of mesh cells, thereby avoiding the need to perform any computations in cell interiors. The dominating cost of this reduction is solving a relatively small Nyström system to obtain a Dirichlet-to-Neumann map, as well as the solution of two more Nyström systems to obtain an “anti-Laplacian” of a harmonic function, which is used for computing the inner product. Several numerical examples demonstrate the high-order accuracy of this approach. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available” as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available at both https://github.com/samreynoldsmath/PuncturedFEM and the supplementary materials (PuncturedFEM_v0_2_5.zip [1.75MB]).},
  archive      = {J_SISC},
  author       = {Jeffrey S. Ovall and Samuel E. Reynolds},
  doi          = {10.1137/23M1569332},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A338-A359},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Evaluation of inner products of implicitly defined finite element functions on multiply connected planar mesh cells},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Sketching with spherical designs for noisy data fitting on
spheres. <em>SISC</em>, <em>46</em>(1), A313–A337. (<a
href="https://doi.org/10.1137/22M1484377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper proposes a sketching strategy with spherical designs to equip the classical spherical basis function (SBF) approach for massive spherical data fitting. We conduct theoretical analysis and numerical verifications to demonstrate the feasibility of the proposed sketching strategy. From the theoretical side, we prove that sketching based on spherical designs can reduce the computational burden of the SBF approach without sacrificing its approximation capability. In particular, we provide upper and lower bounds for the proposed sketching strategy to fit noisy data on spheres. From the experimental side, we numerically illustrate the feasibility of the sketching strategy by showing its comparable fitting performance with the SBF approach. These interesting findings show that the proposed sketching strategy is effective in fitting massive and noisy data on spheres. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available”, as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available in https://github.com/18357710774/SIAM_Sketching OR in the Supplementary Materials.},
  archive      = {J_SISC},
  author       = {Shao-Bo Lin and Di Wang and Ding-Xuan Zhou},
  doi          = {10.1137/22M1484377},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A313-A337},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Sketching with spherical designs for noisy data fitting on spheres},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A fast minimization algorithm for the euler elastica model
based on a bilinear decomposition. <em>SISC</em>, <em>46</em>(1),
A290–A312. (<a href="https://doi.org/10.1137/23M1552772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The Euler elastica (EE) model with surface curvature can generate artifact-free results compared with the traditional total variation regularization model in image processing. However, strong nonlinearity and singularity due to the curvature term in the EE model pose a great challenge for one to design fast and stable algorithms for the EE model. In this paper, we propose a new, fast, hybrid alternating minimization (HALM) algorithm for the EE model based on a bilinear decomposition of the gradient of the underlying image and prove the global convergence of the minimizing sequence generated by the algorithm under mild conditions. The HALM algorithm comprises three subminimization problems and each is either solved in the closed form or approximated by fast solvers, making the new algorithm highly accurate and efficient. We also discuss the extension of the HALM strategy to deal with general curvature-based variational models, especially with a Lipschitz smooth functional of the curvature. A host of numerical experiments are conducted to show that the new algorithm produces good results with much-improved efficiency compared to other state-of-the-art algorithms for the EE model. As one of the benchmarks, we show that the average running time of the HALM algorithm is at most one-quarter of that of the fast operator-splitting-based Deng–Glowinski–Tai algorithm.},
  archive      = {J_SISC},
  author       = {Zhifang Liu and Baochen Sun and Xue-Cheng Tai and Qi Wang and Huibin Chang},
  doi          = {10.1137/23M1552772},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A290-A312},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A fast minimization algorithm for the euler elastica model based on a bilinear decomposition},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Learning robust marking policies for adaptive mesh
refinement. <em>SISC</em>, <em>46</em>(1), A264–A289. (<a
href="https://doi.org/10.1137/22M1510613">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this work, we revisit the marking decisions made in the standard adaptive finite element method (AFEM). Experience shows that a naïve marking policy leads to inefficient use of computational resources for adaptive mesh refinement (AMR). Consequently, using AMR in practice often involves ad-hoc or time-consuming offline parameter tuning to set appropriate parameters for the marking subroutine. To address these practical concerns, we recast AMR as a Markov decision process in which refinement parameters can be selected on-the-fly at run time, without the need for pre-tuning by expert users. In this new paradigm, the refinement parameters are also chosen adaptively via a marking policy that can be optimized using methods from reinforcement learning. We use the Poisson equation to demonstrate our techniques on - and -refinement benchmark problems, and our experiments suggest that superior marking policies remain undiscovered for many classical AFEM applications. Furthermore, an unexpected observation from this work is that marking policies trained on one family of PDEs are sometimes robust enough to perform well on problems far outside the training family. For illustration, we show that a simple -refinement policy trained on 2D domains with only a single re-entrant corner can be deployed on far more complicated 2D domains, and even 3D domains, without significant performance loss. For reproduction and broader adoption, we accompany this work with an open-source implementation of our methods. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available”, as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available in https://codeocean.com/capsule/0890995/tree OR in the Supplementary Materials (capsule-0890995.zip [526MB]).},
  archive      = {J_SISC},
  author       = {Andrew Gillette and Brendan Keith and Socratis Petrides},
  doi          = {10.1137/22M1510613},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A264-A289},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Learning robust marking policies for adaptive mesh refinement},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A conservative low rank tensor method for the vlasov
dynamics. <em>SISC</em>, <em>46</em>(1), A232–A263. (<a
href="https://doi.org/10.1137/22M1473960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. In this paper, we propose a conservative low rank tensor method to approximate nonlinear Vlasov solutions. The low rank approach is based on our earlier work [W. Guo and J.-M. Qiu, A Low Rank Tensor Representation of Linear Transport and Nonlinear Vlasov Solutions and Their Associated Flow Maps, preprint, https://arxiv.org/abs/2106.08834, 2021]. It takes advantage of the fact that the differential operators in the Vlasov equation are tensor friendly, based on which we propose to dynamically and adaptively build up low rank solution basis by adding new basis functions from discretization of the differential equation, and removing basis from a singular value decomposition (SVD)-type truncation procedure. For the discretization, we adopt a high order finite difference spatial discretization together with a second order strong stability preserving multistep time discretization. While the SVD truncation will remove the redundancy in representing the high dimensional Vlasov solution, it will destroy the conservation properties of the associated full conservative scheme. In this paper, we develop a conservative truncation procedure with conservation of mass, momentum, and kinetic energy densities. The conservative truncation is achieved by an orthogonal projection onto a subspace spanned by 1, and in the velocity space associated with a weighted inner product. Then the algorithm performs a weighted SVD truncation of the remainder, which involves a scaling, followed by the standard SVD truncation and rescaling back. The algorithm is further developed in high dimensions with hierarchical Tucker tensor decomposition of high dimensional Vlasov solutions, overcoming the curse of dimensionality. An extensive set of nonlinear Vlasov examples are performed to show the effectiveness and conservation property of proposed conservative low rank approach. Comparison is performed against the nonconservative low rank tensor approach on conservation history of mass, momentum, and energy.},
  archive      = {J_SISC},
  author       = {Wei Guo and Jing-Mei Qiu},
  doi          = {10.1137/22M1473960},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A232-A263},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A conservative low rank tensor method for the vlasov dynamics},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Riemannian natural gradient methods. <em>SISC</em>,
<em>46</em>(1), A204–A231. (<a
href="https://doi.org/10.1137/22M1509643">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper studies large-scale optimization problems on Riemannian manifolds whose objective function is a finite sum of negative log-probability losses. Such problems arise in various machine learning and signal processing applications. By introducing the notion of Fisher information matrix in the manifold setting, we propose a novel Riemannian natural gradient method, which can be viewed as a natural extension of the natural gradient method from the Euclidean setting to the manifold setting. We establish the almost-sure global convergence of our proposed method under standard assumptions. Moreover, we show that if the loss function satisfies certain convexity and smoothness conditions and the input-output map satisfies a Riemannian Jacobian stability condition, then our proposed method enjoys a local linear—or, under the Lipschitz continuity of the Riemannian Jacobian of the input-output map, even quadratic—rate of convergence. We then prove that the Riemannian Jacobian stability condition will be satisfied by a two-layer fully connected neural network with batch normalization with high probability, provided that the width of the network is sufficiently large. This demonstrates the practical relevance of our convergence rate result. Numerical experiments on applications arising from machine learning demonstrate the advantages of the proposed method over state-of-the-art ones. Reproducibility of computational results. This paper has been awarded the “SIAM Reproducibility Badge: code and data available”, as a recognition that the authors have followed reproducibility principles valued by SISC and the scientific computing community. Code and data that allow readers to reproduce the results in this paper are available in https://github.com/hujiangpku/RNGD OR in the Supplementary Materials (RNGD-main.zip [25.9MB]).},
  archive      = {J_SISC},
  author       = {Jiang Hu and Ruicheng Ao and Anthony Man-Cho So and Minghan Yang and Zaiwen Wen},
  doi          = {10.1137/22M1509643},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A204-A231},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Riemannian natural gradient methods},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Weighted trace-penalty minimization for full configuration
interaction. <em>SISC</em>, <em>46</em>(1), A179–A203. (<a
href="https://doi.org/10.1137/23M1547676">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A novel unconstrained optimization model named weighted trace-penalty minimization (WTPM) is proposed to address the extreme eigenvalue problem arising from the full configuration interaction (FCI) method. Theoretical analysis shows that the global minimizers of the WTPM objective function are the desired eigenvectors, rather than the eigenspace. Analyzing the condition number of the Hessian operator in detail contributes to the determination of a near-optimal weight matrix. With the sparse feature of FCI matrices in mind, the coordinate descent (CD) method is adapted to WTPM and results in the WTPM-CD method. The reduction of computational and storage costs in each iteration shows the efficiency of the proposed algorithm. Finally, the numerical experiments demonstrate the capability to address large-scale FCI matrices.},
  archive      = {J_SISC},
  author       = {Weiguo Gao and Yingzhou Li and Hanxiang Shen},
  doi          = {10.1137/23M1547676},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A179-A203},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Weighted trace-penalty minimization for full configuration interaction},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). BDDC preconditioners for virtual element approximations of
the three-dimensional stokes equations. <em>SISC</em>, <em>46</em>(1),
A156–A178. (<a href="https://doi.org/10.1137/23M1567679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The virtual element method (VEM) is a novel family of numerical methods for approximating partial differential equations on very general polygonal or polyhedral computational grids. This work aims to propose a balancing domain decomposition by constraints (BDDC) preconditioner that allows using the conjugate gradient method to compute the solution of the saddle-point linear systems arising from the VEM discretization of the three-dimensional Stokes equations. We prove the scalability and quasi-optimality of the algorithm and confirm the theoretical findings with parallel computations. Numerical results with adaptively generated coarse spaces confirm the method’s robustness in the presence of large jumps in the viscosity and with high-order VEM discretizations.},
  archive      = {J_SISC},
  author       = {Tommaso Bevilacqua and Franco Dassi and Stefano Zampini and Simone Scacchi},
  doi          = {10.1137/23M1567679},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A156-A178},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {BDDC preconditioners for virtual element approximations of the three-dimensional stokes equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A unified design of energy stable schemes with variable
steps for fractional gradient flows and nonlinear integro-differential
equations. <em>SISC</em>, <em>46</em>(1), A130–A155. (<a
href="https://doi.org/10.1137/23M1554795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. A unified discrete gradient structure of the second order nonuniform integral averaged approximations for the Caputo fractional derivative and the Riemann–Liouville fractional integral is established in this paper. The required constraint of the step-size ratio is weaker than that found in the literature. With the proposed discrete gradient structure, the energy stability of the variable step Crank–Nicolson type numerical schemes is derived immediately, which is essential to the long-time simulations of the time fractional gradient flows and the nonlinear integro-differential models. The discrete energy dissipation laws fit seamlessly into their classical counterparts as the fractional indexes tend to one. In particular, we provide a framework for the stability analysis of variable step numerical schemes based on the scalar auxiliary variable type approaches. The time fractional Swift–Hohenberg model and the time fractional sine-Gordon model are taken as two examples to elucidate the theoretical results at great length. Extensive numerical experiments using the adaptive time-stepping strategy are provided to verify the theoretical results in the time multiscale simulations.},
  archive      = {J_SISC},
  author       = {Ren-jun Qi and Xuan Zhao},
  doi          = {10.1137/23M1554795},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A130-A155},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A unified design of energy stable schemes with variable steps for fractional gradient flows and nonlinear integro-differential equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A multilevel method for many-electron schrödinger equations
based on the atomic cluster expansion. <em>SISC</em>, <em>46</em>(1),
A105–A129. (<a href="https://doi.org/10.1137/23M1565887">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The atomic cluster expansion (ACE) [R. Drautz, Phys. Rev. B, 99 (2019), 014104] yields a highly efficient and interpretable parameterization of symmetric polynomials that has achieved great success in modelling properties of many-particle systems. In the present work we extend the practical applicability of the ACE framework to the computation of many-electron wave functions. To that end, we develop a customized variational Monte Carlo algorithm that exploits the sparsity and hierarchical properties of ACE wave functions. We demonstrate the feasibility on a range of proof-of-concept applications to one-dimensional systems.},
  archive      = {J_SISC},
  author       = {Dexuan Zhou and Huajie Chen and Cheuk Hin Ho and Christoph Ortner},
  doi          = {10.1137/23M1565887},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A105-A129},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A multilevel method for many-electron schrödinger equations based on the atomic cluster expansion},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). An iterative solver for the HPS discretization applied to
three dimensional helmholtz problems. <em>SISC</em>, <em>46</em>(1),
A80–A104. (<a href="https://doi.org/10.1137/21M1463380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This manuscript presents an efficient solver for the linear system that arises from the hierarchical Poincaré–Steklov (HPS) discretization of three dimensional variable coefficient Helmholtz problems. Previous work on the HPS method has tied it with a direct solver. This work is the first efficient iterative solver for the linear system that results from the HPS discretization. The solution technique utilizes GMRES coupled with a locally homogenized block-Jacobi preconditioner. The local nature of the discretization and preconditioner naturally yield the matrix-free application of the linear system. Numerical results illustrate the performance of the solution technique. This includes an experiment where a problem approximately 100 wavelengths in each direction that requires more than a billion unknowns to achieve approximately 4 digits of accuracy takes less than 20 minutes to solve.},
  archive      = {J_SISC},
  author       = {José Pablo Lucero Lorca and Natalie Beams and Damien Beecroft and Adrianna Gillman},
  doi          = {10.1137/21M1463380},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A80-A104},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {An iterative solver for the HPS discretization applied to three dimensional helmholtz problems},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). A new discretely divergence-free positivity-preserving
high-order finite volume method for ideal MHD equations. <em>SISC</em>,
<em>46</em>(1), A50–A79. (<a
href="https://doi.org/10.1137/23M1562081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. This paper proposes and analyzes a novel efficient high-order finite volume method for the ideal magnetohydrodynamics (MHD). As a distinctive feature, the method simultaneously preserves two critical physical constraints: a discretely divergence-free (DDF) constraint on the magnetic field and the positivity-preserving (PP) property, which ensures the positivity of density, pressure, and internal energy. To enforce the DDF condition in each cell, we design a new discrete projection approach that projects the reconstructed point values at the cell interface into a DDF space, without using any approximation polynomials. This projection method is highly efficient, easy to implement, and particularly suitable for the high-order finite volume methods that return only the point values (no explicit approximation polynomials) in the reconstruction. Moreover, we also develop a new finite volume framework for constructing provably PP schemes for the ideal MHD system. The framework comprises the discrete projection technique, a suitable approximation to the Godunov–Powell source terms, and a simple PP limiter. We provide rigorous analysis of the PP property of the proposed finite volume method, demonstrating that the DDF condition and the proper approximation to the source terms eliminate the impact of magnetic divergence terms on the PP property. The analysis is challenging due to the internal energy function’s nonlinearity and the intricate relationship between the DDF and PP properties. To address these challenges, we adopt the recently developed geometric quasilinearization approach [K. Wu and C.-W. Shu, SIAM Rev., 65 (2023), pp. 1031–1073], which transforms a nonlinear constraint into a family of linear constraints. Finally, we validate the effectiveness of the proposed method through several benchmark and demanding numerical examples. The results demonstrate that the proposed method is robust, accurate, and highly effective, confirming the significance of the proposed DDF projection and PP techniques.},
  archive      = {J_SISC},
  author       = {Shengrong Ding and Kailiang Wu},
  doi          = {10.1137/23M1562081},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A50-A79},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {A new discretely divergence-free positivity-preserving high-order finite volume method for ideal MHD equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). On optimal zero-padding of kernel truncation method.
<em>SISC</em>, <em>46</em>(1), A23–A49. (<a
href="https://doi.org/10.1137/23M1550803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. The kernel truncation method (KTM) is a commonly used algorithm to compute the convolution-type nonlocal potential where the convolution kernel might be singular at the origin and/or far-field and the density is smooth and fast decaying. In KTM, in order to capture the Fourier integrand’s oscillations that are brought by the kernel truncation, one needs to carry out a zero-padding of the density, which means a larger physical computation domain and a finer mesh in the Fourier space by duality. The zero-padding factor, was first given as empirical formula for the 2D/3D Coulomb potential in [M. R. Jarvis et al. Phys. Rev. B, 56 (1997), pp. 14972–14978; C. A. Rozzi et al. Phys. Rev. B, 73 (2006), 205119]. In this article, we first rederive the optimal zero-padding factor in a rigorous way for arbitrary space dimension and different nonlocal potentials. Then, we present the error estimates of the density and potential. Next, we investigate the anisotropic density case, and provide details of tensor acceleration [F. Vico, L. Greengard, and M. Ferrando, J. Comput. Phys. 323 (2016), pp. 191–203], which is an important performance improvement. Finally, extensive numerical results are provided to confirm the accuracy, efficiency, optimal zero-padding factor for the anisotropic density, together with some applications to different nonlocal potentials, including the one-dimensional/two-dimensional (2D)/three-dimensional (3D) Poisson, 2D Coulomb, quasi-2D/3D dipole-dipole Interaction, and 3D quadrupolar potential.},
  archive      = {J_SISC},
  author       = {Xin Liu and Qinglin Tang and Shaobo Zhang and Yong Zhang},
  doi          = {10.1137/23M1550803},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A23-A49},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {On optimal zero-padding of kernel truncation method},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
<li><details>
<summary>
(2024). Analysis of schwarz methods for convected helmholtz-like
equations. <em>SISC</em>, <em>46</em>(1), A1–A22. (<a
href="https://doi.org/10.1137/23M1560057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstract. We present and analyze Schwarz domain decomposition methods for a general diffusion problem with complex advection. The complex advection term changes completely the nature of the solution and makes it more Helmholtz like. In the case of constant parameters, we analyze in detail the influence of the outer boundary conditions on the performance of the Schwarz algorithm, including PML conditions to emulate free space problems, and optimized transmission conditions, also for multiple subdomains for decompositions into strips. Our results show that the performance of Schwarz methods for such Helmholtz-like problems is much better on free space configurations than in waveguides or closed cavities. Equations with complex advection appear in diverse applications, for example, the convected Helmholtz equation, the Gross–Pitaevskii equation, Schrödinger equations, and also as an important component in the wave-ray multigrid algorithm for Helmholtz problems. We show as an example the performance of our Schwarz methods for a potential flow around a schematic submarine.},
  archive      = {J_SISC},
  author       = {M. J. Gander and A. Tonnoir},
  doi          = {10.1137/23M1560057},
  journal      = {SIAM Journal on Scientific Computing},
  month        = {2},
  number       = {1},
  pages        = {A1-A22},
  shortjournal = {SIAM J. Sci. Comput.},
  title        = {Analysis of schwarz methods for convected helmholtz-like equations},
  volume       = {46},
  year         = {2024},
}
</textarea>
</details></li>
</ul>

</body>
</html>
